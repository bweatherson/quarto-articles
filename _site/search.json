[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Online Articles",
    "section": "",
    "text": "The Sporting Attitude\n\n\n\n\n\n\nbook symposium\n\n\non books\n\n\ngames and decisions\n\n\n\nContribution to a symposium on Steffen Borge’s “The Philosophy of Football”. \n\n\n\n\n\nApr 26, 2022\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nDeliberation Costs\n\n\n\n\n\n\ngames and decisions\n\n\nepistemology\n\n\nphilosophy of economics\n\n\nunpublished\n\n\n\nOur theory of rational choice should be sensitive to deliberation costs. It is irrational to take into account minor differences between goods, if the cost of taking those differences into account is greater than the expected gain from doing so. It has often been held in economics that this line of reasoning will lead to an infinite regress. I argue that the regress can be stopped if we take the rational chooser to be skilled at attending to the right information. On the appropriate model of skill, the rational agent will attend to the right information without reasoning about whether this is the right information to attend to. \n\n\n\n\n\nJun 17, 2020\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nAccuracy and the Imps\n\n\n\n\n\n\nepistemology\n\n\naccuracy\n\n\n\nRecently several authors have argued that accuracy-first epistemology ends up licensing problematic epistemic bribes. They charge that it is better, given the accuracy-first approach, to deliberately form one false belief if this will lead to forming many other true beliefs. We argue that this is not a consequence of the accuracy-first view. If one forms one false belief and a number of other true beliefs, then one is committed to many other false propositions, e.g., the conjunction of that false belief with any of the true beliefs. Once we properly account for all the falsehoods that are adopted by the person who takes the bribe, it turns out that the bribe does not increase accuracy. \n\n\n\n\n\nJan 1, 2019\n\n\nJames Joyce, Brian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nInterests, Evidence and Games\n\n\n\n\n\n\nepistemology\n\n\ninterest-relativity\n\n\ngames and decisions\n\n\n\nPragmatic encroachment theories have a problem with evidence. On the one hand, the arguments that knowledge is interest-relative look like they will generalise to show that evidence too is interest-relative. On the other hand, our best story of how interests affect knowledge presupposes an interest-invariant notion of evidence. The aim of this paper is to sketch a theory of evidence that is interest-relative, but which allows that ‘best story’ to go through with minimal changes. The core idea is that the evidence someone has is just what evidence a radical interpreter says they have. And a radical interpreter is playing a kind of game with the person they are interpreting. The cases that pose problems for pragmatic encroachment theorists generate fascinating games between the interpreter and the interpretee. They are games with multiple equilibria. To resolve them we need to detour into the theory of equilibrium selection. I’ll argue that the theory we need is the theory of risk-dominant equilibria. That theory will tell us how the interpreter will play the game, which in turn will tell us what evidence the person has. The evidence will be interest-relative, because what the equilibrium of the game is will be interest-relative. But it will not undermine the story we tell about how interests usually affect knowledge. \n\n\n\n\n\nJun 29, 2018\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nIntellectual Skill and the Rylean Regress\n\n\n\n\n\n\nepistemology\n\n\nskill\n\n\n\nIntelligent activity requires the use of various intellectual skills. While these skills are connected to knowledge, they should not be identified with knowledge. There are realistic examples where the skills in question come apart from knowledge. That is, there are realistic cases of knowledge without skill, and of skill without knowledge. Whether a person is intelligent depends, in part, on whether they have these skills. Whether a particular action is intelligent depends, in part, on whether it was produced by an exercise of skill. These claims promote a picture of intelligence that is in tension with a strongly intellectualist picture, though they are not in tension with a number of prominent claims recently made by intellectualists. \n\n\n\n\n\nApr 2, 2017\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nInterest-Relative Invariantism\n\n\n\n\n\n\nepistemology\n\n\ninterest-relativity\n\n\n\nAn opinionated survey of the state of the literature on interest-relative invariantism. \n\n\n\n\n\nMar 17, 2017\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nFor Bayesians, Rational Modesty Requires Imprecision\n\n\n\n\n\n\nepistemology\n\n\ngames and decisions\n\n\nimprecise probability\n\n\n\nGordon Belot has recently developed a novel argument against Bayesianism. He shows that there is an interesting class of problems that, intuitively, no rational belief forming method is likely to get right. But a Bayesian agent’s credence, before the problem starts, that she will get the problem right has to be 1. This is an implausible kind of immodesty on the part of Bayesians. My aim is to show that while this is a good argument against traditional, precise Bayesians, the argument doesn’t neatly extend to imprecise Bayesians. As such, Belot’s argument is a reason to prefer imprecise Bayesianism to precise Bayesianism. \n\n\n\n\n\nMar 11, 2016\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nGames, Beliefs and Credences\n\n\n\n\n\n\nepistemology\n\n\ninterest-relativity\n\n\ngames and decisions\n\n\n\nIn previous work I’ve defended an interest-relative theory of belief. This paper continues the defence. I have four aims. First, to offer a new kind of reason for being unsatisfied with the simple Lockean reduction of belief to credence. Second, to defend the legitimacy of appealing to credences in a theory of belief. Third, to illustrate the importance of theoretical, as well as practical, interests in an interest-relative account of belief. And finally, to have another try at extending my basic account of belief to cover propositions that are practically and theoretically irrelevant to the agent. \n\n\n\n\n\nMar 1, 2016\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nMemory, Belief and Time\n\n\n\n\n\n\nepistemology\n\n\ngames and decisions\n\n\nimprecise probability\n\n\n\nI argue that what evidence an agent has does not supervene on how she currently is. Agents do not always have to infer what the past was like from how things currently seem; sometimes the facts about the past are retained pieces of evidence that can be the start of reasoning. The main argument is a variant on Frank Arntzenius’s Shangri La example, an example that is often used to motivate the thought that evidence does supervene on current features. \n\n\n\n\n\nDec 1, 2015\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nHumean Supervenience\n\n\n\n\n\n\nDavid Lewis\n\n\nmetaphysics\n\n\nHumeanism\n\n\n\nHumean supervenience is the conjunction of three theses: Truth supervenes on being, Anti‐haecceitism, and Spatiotemporalism. The first clause is a core part of Lewis’s metaphysics. The second clause is related to Lewis’s counterpart theory. The third clause says there are no fundamental relations beyond the spatiotemporal, or fundamental properties of extended objects. This paper sets out why Humean Supervenience was so central to Lewis’s metaphysics, and why we should care about it even if there are empirical arguments against Spatiotemporalism. The project of defending Humean Supervenience was part of a larger project of philosophical compatibilism, of showing how the folk picture of the world and the scientific picture could be made to cohere with relatively little damage to the former and none to the latter. And Lewis’s contributions to that project are independent of whether the scientific picture of the world ultimately includes Spatiotemporalism. \n\n\n\n\n\nMar 6, 2015\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nCentrality and Marginalisation\n\n\n\n\n\n\nmethodology\n\n\nbook symposium\n\n\non books\n\n\nhistory of analytic\n\n\n\nA commentary on Herman Cappelen’s “Philosophy without Intuitions”. \n\n\n\n\n\nFeb 22, 2014\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nRunning Risks Morally\n\n\n\n\n\n\nethics\n\n\ngames and decisions\n\n\nmoral uncertainty\n\n\n\nI defend normative externalism from the objection that it cannot account for the wrongfulness of moral recklessness. The defence is fairly simple—there is no wrong of moral recklessness. There is an intuitive argument by analogy that there should be a wrong of moral recklessness, and the bulk of the paper consists of a response to this analogy. A central part of my response is that if people were motivated to avoid moral recklessness, they would have to have an unpleasant sort of motivation, what Michael Smith calls “moral fetishism”. \n\n\n\n\n\nJan 1, 2014\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nIn Defense of the ACA’s Medicaid Expansion\n\n\n\n\n\n\npolitical philosophy\n\n\n\nThe only part of the Patient Protection and Affordable Care Act (hereafter, ‘the ACA’) struck down was a provision expanding Medicaid. We will argue that this was a mistake; the provision should not have been struck down. We’ll do this by identifying a test that C.J. Roberts used to justify his view that this provision was unconstitutional. We’ll defend that test against some objections raised by J. Ginsburg. We’ll then go on to argue that, properly applied, that test establishes the constitutionality of the Medicaid provision. \n\n\n\n\n\nJul 1, 2013\n\n\nIshani Maitra, Brian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nThe Role of Naturalness in Lewis’s Theory of Meaning\n\n\n\n\n\n\nDavid Lewis\n\n\nlanguage\n\n\nmetaphysics\n\n\nhistory of analytic\n\n\n\nMany writers have held that in his later work, David Lewis adopted a theory of predicate meaning such that the meaning of a predicate is the most natural property that is (mostly) consistent with the way the predicate is used. That orthodox interpretation is shared by both supporters and critics of Lewis’s theory of meaning, but it has recently been strongly criticised by Wolfgang Schwarz. In this paper, I accept many of Schwarz’s criticisms of the orthodox interpretation, and add some more. But I also argue that the orthodox interpretation has a grain of truth in it, and seeing that helps us appreciate the strength of Lewis’s late theory of meaning. \n\n\n\n\n\nMay 20, 2013\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nIn Defense of a Kripkean Dogma\n\n\n\n\n\n\nmethodology\n\n\nlanguage\n\n\nnotes\n\n\n\nA reply to some empirical arguments against Kripkean meta-semantics. \n\n\n\n\n\nJul 1, 2012\n\n\nJonathan Jenkins Ichikawa, Ishani Maitra, Brian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nExplanation, Idealisation and the Goldilocks Problem\n\n\n\n\n\n\nexplanation\n\n\nphilosophy of economics\n\n\nbook symposium\n\n\non books\n\n\n\nA contribution to a symposium on Michael Strevens’s book Depth. \n\n\n\n\n\nMar 21, 2012\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nDefending Interest Relative Invariantism\n\n\n\n\n\n\nepistemology\n\n\ninterest-relativity\n\n\n\nSince interest-relative invariantism (hereafter, IRI) was introduced into contemporary epistemology in the early 2000s, it has been criticised on a number of fronts. This paper responds to six different criticisms of IRI launched by five different authors. And it does so by noting that the best version of IRI is immune to the criticisms they have launched. The ‘best version’ in question notes three things about IRI. First, what matters for knowledge is not strictly the stakes the agent faces in any decision-problem, but really the odds at which she has to bet. Second, IRI is a relatively weak theory; it just says interests sometimes matter. Defenders of IRI have often derived it from much stronger principles about reasoning, and critics have attacked those principles, but much weaker principles would do. Third, and most importantly, interests matter because generate certain kinds of defeaters. It isn’t part of this version of IRI that an agent can know something in virtue of their interests. Rather, the theory says that whether a certain kind of consideration is a defeater to an agent’s putative knowledge that p depends on their interests. This matters for the intuitive plausibility of IRI. Critics have argued, rightly, that interests don’t behave in ways distinctive of grounds of knowledge. But interests do behave like other kinds of defeaters, and this undermines the criticisms of IRI. \n\n\n\n\n\nJan 1, 2011\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nAssertion, Knowledge and Action\n\n\n\n\n\n\nepistemology\n\n\nlanguage\n\n\ninterest-relativity\n\n\n\nWe argue against the knowledge rule of assertion, and in favour of integrating the account of assertion more tightly with our best theories of evidence and action. We think that the knowledge rule has an incredible consequence when it comes to practical deliberation, that it can be right for a person to do something that she can’t properly assert she can do. We develop some vignettes that show how this is possible, and how odd this consequence is. We then argue that these vignettes point towards alternate rules that tie assertion to sufficient evidence-responsiveness or to proper action. These rules have many of the virtues that are commonly claimed for the knowledge rule, but lack the knowledge rule’s problematic consequences when it comes to assertions about what to do. \n\n\n\n\n\nMar 23, 2010\n\n\nIshani Maitra, Brian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nDeontology and Descartes’s Demon\n\n\n\n\n\n\nepistemology\n\n\nepistemic norms\n\n\nepistemic voluntarism\n\n\n\nIn this paper, I defend a broadly Cartesian position about doxastic freedom. At least some of our beliefs are freely formed, so we are responsible for them. Moreover, this has consequences for epistemology. But the some here is crucial. Some of our beliefs are not freely formed, and we are not responsible for those. And that has epistemological consequences too. Out of these considerations a concept of doxastic responsibility arises that is useful to the externalist in responding to several challenges. I will say at some length how it supports a familiar style of externalism response to the New Evil Demon problem, and I will note some difficulties in reconciling internalism with the idea that justification is a kind of blamelessness. The internalist, I will argue, has to say that justification is a kind of praiseworthiness, and this idea that praise is more relevant to epistemic concepts than blame will be a recurring theme of the paper. \n\n\n\n\n\nSep 1, 2008\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nThe Bayesian and the Dogmatist\n\n\n\n\n\n\nepistemology\n\n\nscepticism\n\n\n\nIt has been argued recently that dogmatism in epistemology is incompatible with Bayesianism. That is, it has been argued that dogmatism cannot be modelled using traditional techniques for Bayesian modelling. I argue that our response to this should not be to throw out dogmatism, but to develop better modelling techniques. I sketch a model for formal learning in which an agent can discover a posteriori fundamental epistemic connections. In this model, there is no formal objection to dogmatism. \n\n\n\n\n\nAug 1, 2007\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nThe Asymmetric Magnets Problem\n\n\n\n\n\n\nmetaphysics\n\n\nintrinsic properties\n\n\nHumeanism\n\n\n\nThere are many controversial theses about intrinsicness and duplication. The first aim of this paper is to introduce a puzzle that shows that two of the uncontroversial sounding ones can’t both be true. The second aim is to suggest that the best way out of the puzzle requires sharpening some distinctions that are too frequently blurred, and adopting a fairly radical reconception of the ways things are. \n\n\n\n\n\nNov 16, 2006\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nDoing Philosophy With Words\n\n\n\n\n\n\nbook symposium\n\n\nhistory of analytic\n\n\nlanguage\n\n\non books\n\n\n\nThis paper discusses the coverage of ordinary language philosophy in Scott Soames’ “Philosophical Analysis in the Twentieth Century”. After praising the book’s virtues, I raise three points where I dissent from Soames’ take on the history. First, I suggest that there is more to ordinary language philosophy than the rather implausible version of it that Soames sees to have been destroyed by Grice. Second, I argue that confusions between analyticity, necessity and priority are less important to the ordinary language period than Soames takes them to be. Finally, I claim that Soames’ criticisms of Ryle turn in part on attributing reductionist positions to Ryle that Ryle did not hold. \n\n\n\n\n\nOct 25, 2006\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nHumeans Aren’t Out of Their Minds\n\n\n\n\n\n\nmetaphysics\n\n\nmind\n\n\nHumeanism\n\n\nnotes\n\n\n\nHumeans about causation say that in some situations, whether C causes E depends on events far away from C and E. John Hawthorne has objected to this feature of the view. Whether one has a mind depends on what causal relations obtain between the parts of one’s brain. But whether one has a mind does not depend on what happens far far away. I reply on behalf of the Humean. In the cases Hawthorne is worried about, the Humean can and should deny the problematic long-range dependence. One advantage of Humeanism is that it lets us make sense of the idea that the laws could be different in different parts of the universe. In the cases Hawthorne is worried about, that’s exactly what is happening - the laws are different here to how they are over there. And what causal relations obtain here is only dependent on what happens in places the laws are the same. \n\n\n\n\n\nOct 25, 2006\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nScepticism, Rationalism, and Externalism\n\n\n\n\n\n\nepistemology\n\n\nscepticism\n\n\n\nI argue that we have to accept one of the three isms in the title. Either inductive scepticism is true, or we have substantial contingent a priori knowledge, or a strongly externalist theory of knowledge is crrect. \n\n\n\n\n\nFeb 9, 2006\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nCan We Do Without Pragmatic Encroachment?\n\n\n\n\n\n\nepistemology\n\n\ninterest-relativity\n\n\nphilosophy of mind\n\n\n\nI argue that interests primarily affect the relationship between credence and belief. A view is set out and defended where evidence and rational credence are not interest-relative, but belief, rational belief, and knowledge are. \n\n\n\n\n\nDec 13, 2005\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nEpistemic Modals in Context\n\n\n\n\n\n\nlanguage\n\n\nrelativism\n\n\n\nA very simple contextualist treatment of a sentence containing an epistemic modal, e.g. a might be F, is that it is true iff for all the contextually salient community knows, a is F. It is widely agreed that the simple theory will not work in some cases, but the counterexamples produced so far seem amenable to a more complicated contextualist theory. We argue, however, that no contextualist theory can capture the evaluations speakers naturally make of sentences containing epistemic modals. If we want to respect these evaluations, our best option is a relativist theory of epistemic modals. On a relativist theory, an utterance of a might be F can be true relative to one context of evaluation and false relative to another. We argue that such a theory does better than any rival approach at capturing all the behaviour of epistemic modals. \n\n\n\n\n\nSep 29, 2005\n\n\nAndy Egan, John Hawthorne, Brian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nShould We Respond to Evil With Indifference?\n\n\n\n\n\n\nepistemology\n\n\nscepticism\n\n\n\nIn a recent article, Adam Elga outlines a strategy for “Defeating Dr Evil with Self-Locating Belief”. The strategy relies on an indifference principle that is not up to the task. In general, there are two things to dislike about indifference principles: adopting one normally means confusing risk for uncertainty, and they tend to lead to incoherent views in some ‘paradoxical’ situations. I argue that both kinds of objection can be levelled against Elga’s indifference principle. There are also some difficulties with the concept of evidence that Elga uses, and these create further difficulties for the principle. \n\n\n\n\n\nMay 1, 2005\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nPrankster’s Ethics\n\n\n\n\n\n\nethics\n\n\n\nWe raise an objection to a very weak form of consequentialism. A world with only moral saints would be improved by adding a few mostly harmless pranksters. This result is not dependent on a particular way of thinking about value; it is resilient across a lot of measures of the value of worlds. But these pranksters would be doing things that are morally wrong. So we cannot identify rightness with making the world a better place. \n\n\n\n\n\nNov 1, 2004\n\n\nAndy Egan, Brian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nChopping up Gunk\n\n\n\n\n\n\nmetaphysics\n\n\n\nWe raise an objection to the idea that the world is gunky. Certain plausible sounding supertasks have implausible consequences if the world is made of gunk. \n\n\n\n\n\nNov 1, 2004\n\n\nJohn Hawthorne, Brian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nMorality, Fiction and Possibility\n\n\n\n\n\n\nethics\n\n\nfiction\n\n\nmetaphysics\n\n\n\nAuthors have a lot of leeway with regard to what they can make true in their story. In general, if the author says that p is true in the fiction we’re reading, we believe that p is true in that fiction. And if we’re playing along with the fictional game, we imagine that, along with everything else in the story, p is true. But there are exceptions to these general principles. Many authors, most notably Kendall Walton and Tamar Szabó Gendler, have discussed apparent counterexamples when p is “morally deviant”. Many other statements that are conceptually impossible also seem to be counterexamples. In this paper I do four things. I survey the range of counterexamples, or at least putative counterexamples, to the principles. Then I look to explanations of the counterexamples. I argue, following Gendler, that the explanation cannot simply be that morally deviant claims are impossible. I argue that the distinctive attitudes we have towards moral propositions cannot explain the counterexamples, since some of the examples don’t involve moral concepts. And I put forward a proposed explanation that turns on the role of ‘higher-level concepts’, concepts that if they are satisfied are satisfied in virtue of more fundamental facts about the world, in fiction, and in imagination. \n\n\n\n\n\nNov 1, 2004\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nReview of “The Realm of Reason”\n\n\n\n\n\n\nbook review\n\n\non books\n\n\nepistemology\n\n\nmetaphysics\n\n\n\nReview of Christopher Peacocke, “The Realm of Reason”. Oxford: Clarendon Press, 2004 \n\n\n\n\n\nOct 15, 2004\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nLuminous Margins\n\n\n\n\n\n\nepistemology\n\n\nnotes\n\n\n\nTimothy Williamson has recently argued that few mental states are luminous, meaning that to be in that state is to be in a position to know that you are in the state. His argument rests on the plausible principle that beliefs only count as knowledge if they are safely true. That is, any belief that could easily have been false is not a piece of knowledge. I argue that the form of the safety rule Williamson uses is inappropriate, and the correct safety rule might not conflict with luminosity. \n\n\n\n\n\nJul 1, 2004\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nNine Objections to Steiner and Wolff on Land Disputes\n\n\n\n\n\n\npolitical philosophy\n\n\nphilosophy of economics\n\n\n\nNine objections to Steiner and Wolff on land disputes. \n\n\n\n\n\nOct 1, 2003\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nReview of “Real Conditionals”\n\n\n\n\n\n\nbook review\n\n\non books\n\n\nconditionals\n\n\nlogic\n\n\nlanguage\n\n\n\nReview of William Lycan, “Real Conditionals”. Oxford: Clarendon Press, 2001. \n\n\n\n\n\nOct 1, 2003\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nReview of “Words Without Meaning”\n\n\n\n\n\n\nbook review\n\n\non books\n\n\nlanguage\n\n\n\nReview of Christopher Gauker, “Words Without Meaning”. Cambridge: MIT Press, 2002. \n\n\n\n\n\nSep 8, 2003\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nReview of “Theories of Vagueness”\n\n\n\n\n\n\nbook review\n\n\non books\n\n\nvagueness\n\n\nlogic\n\n\n\nReview of Rosanna Keefe, “Theories of Vagueness”. Cambridge: Cambridge University Press, 2000. \n\n\n\n\n\nSep 1, 2003\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nMany Many Problems\n\n\n\n\n\n\nlanguage\n\n\nlogic\n\n\nvagueness\n\n\n\nRecently four different papers have suggested that the supervaluational solution to the Problem of the Many is flawed. Stephen Schiffer has argued that the theory cannot account for reports of speech involving vague singular terms. Vann McGee and Brian McLaughlin say that theory cannot, yet, account for vague singular beliefs. Neil McKinnon has argued that we cannot provide a plausible theory of when precisifications are acceptable, which the supervaluational theory needs. And Roy Sorensen argues that supervaluationism is inconsistent with a directly referential theory of names. McGee and McLaughlin see the problem they raise as a cause for further research, but the other authors all take the problems they raise to provide sufficient reasons to jettison supervaluationism. I will argue that none of these problems provide such a reason, though the arguments are valuable critiques. In many cases, we must make some adjustments to the supervaluational theory to meet the posed challenges. The goal of this paper is to make those adjustments, and meet the challenges. \n\n\n\n\n\nAug 29, 2003\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nAre You a Sim?\n\n\n\n\n\n\nepistemology\n\n\nnotes\n\n\n\nNick Bostrom argues that if we accept some plausible assumptions about how the future will unfold, we should believe we are probably not humans. The argument appeals crucially to an indifference principle whose content is unclear. I set out four possible interpretations of the principle, none of which can be used to support Bostrom’s argument. On the first two interpretations the principle is false; on the third it does not entail the conclusion; and on the fourth it only entails the conclusion given an auxiliary hypothesis which we have no reason to believe. \n\n\n\n\n\nJul 1, 2003\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Good are Counterexamples?\n\n\n\n\n\n\ngames and decisions\n\n\nepistemology\n\n\nmethodology\n\n\n\nIntuitively, Gettier cases are instances of justified true beliefs that are not cases of knowledge. Should we therefore conclude that knowledge is not justified true belief? Only if we have reason to trust intuition here. But intuitions are unreliable in a wide range of cases. And it can be argued that the Gettier intuitions have a greater resemblance to unreliable intuitions than to reliable intuitions. What’s distinctive about the faulty intuitions, I argue, is that respecting them would mean abandoning a simple, systematic and largely successful theory in favour of a complicated, disjunctive and idiosyncratic theory. So maybe respecting the Gettier intuitions was the wrong reaction, we should instead have been explaining why we are all so easily misled by these kinds of cases. \n\n\n\n\n\nJul 1, 2003\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nEpistemicism, Parasites, and Vague Names\n\n\n\n\n\n\nlogic\n\n\nlanguage\n\n\nvagueness\n\n\nnotes\n\n\n\nJohn Burgess has recently argued that Timothy Williamson’s attempts to avoid the objection that his theory of vagueness is based on an untenable metaphysics of content are unsuccessful. Burgess’s arguments are important, and largely correct, but there is a mistake in the discussion of one of the key examples. In this note I provide some alternative examples and use them to repair the mistaken section of the argument. \n\n\n\n\n\nApr 1, 2003\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nReview of “Vagueness and Contradiction”\n\n\n\n\n\n\nbook review\n\n\non books\n\n\nvagueness\n\n\nlogic\n\n\n\nReview of Roy Sorensen, “Vagueness and Contradiction”. Cambridge: Cambridge University Press, 2000. \n\n\n\n\n\nApr 1, 2003\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nMisleading Indexicals\n\n\n\n\n\n\nnotes\n\n\nlanguage\n\n\n\nI argue against well informed observer theories about the referent of indexicals. \n\n\n\n\n\nOct 1, 2002\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nReview of “Sameness and Substance Renewed”\n\n\n\n\n\n\nbook review\n\n\non books\n\n\nmetaphysics\n\n\n\nReview of David Wiggins, “Sameness and Substance Renewed”. Cambridge: Cambridge University Press, 2001. \n\n\n\n\n\nSep 6, 2002\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nReview of “Moral Uncertainty and Its Consequences”\n\n\n\n\n\n\nbook review\n\n\non books\n\n\nethics\n\n\nmoral uncertainty\n\n\n\nReview of Ted Lockhart, “Moral Uncertainty and Its Consequences”. Oxford: Oxford University Press, 2000. \n\n\n\n\n\nJul 1, 2002\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nReview of “Rethinking Intuition”\n\n\n\n\n\n\nbook review\n\n\non books\n\n\nmethodology\n\n\n\nReview of Michael DePaul and William Ramsey, eds. “Rethinking Intuition: The Psychology of Intuition and Its Role in Philosophical Inquiry.” Lanham, Md.: Rowman & Littlefield, 1998. \n\n\n\n\n\nJan 1, 2002\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nReview of “Rethinking Intuition”\n\n\n\n\n\n\nbook review\n\n\non books\n\n\nmethodology\n\n\n\nReview of Michael DePaul and William Ramsey, eds. “Rethinking Intuition: The Psychology of Intuition and Its Role in Philosophical Inquiry.” Lanham, Md.: Rowman & Littlefield, 1998. \n\n\n\n\n\nJan 1, 2002\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nIntrinsic Properties and Combinatorial Principles\n\n\n\n\n\n\nmetaphysics\n\n\nintrinsic properties\n\n\n\nThree objections have recently been levelled at the analysis of intrinsicness offered by Rae Langton and David Lewis. While these objections do seem telling against the particular theory Langton and Lewis offer, they do not threaten the broader strategy Langton and Lewis adopt: defining intrinsicness in terms of combinatorial features of properties. I show how to amend their theory to overcome the objections without abandoning the strategy. \n\n\n\n\n\nSep 1, 2001\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Classical to Intuitionistic Probability\n\n\n\n\n\n\nlogic\n\n\ngames and decisions\n\n\n\nWe generalize the Kolmogorov axioms for probability calculus to obtain conditions defining, for any given logic, a class of probability functions relative to that logic, coinciding with the standard probability functions in the special case of classical logic but allowing consideration of other classes of “essentially Kolmogorovian” probability functions relative to other logics. We take a broad view of the Bayesian approach as dictating inter alia that from the perspective of a given logic, rational degrees of belief are those representable by probability functions from the class appropriate to that logic. Classical Bayesianism, which fixes the logic as classical logic, is only one version of this general approach. Another, which we call Intuitionistic Bayesianism, selects intuitionistic logic as the preferred logic and the associated class of probability functions as the right class of candidate representions of epistemic states (rational allocations of degrees of belief). Various objections to classical Bayesianism are, we argue, best met by passing to intuitionistic Bayesianism – in which the probability functions are taken relative to intuitionistic logic – rather than by adopting a radically non-Kolmogorovian, e.g. non-additive, conception of (or substitute for) probability functions, in spite of the popularity of the latter response amongst those who have raised these objections. The interest of intuitionistic Bayesianism is further enhanced by the availability of a Dutch Book argument justifying the selection of intuitionistic probability functions as guides to rational betting behaviour when due consideration is paid to the fact that bets are settled only when/if the outcome betted on becomes known. \n\n\n\n\n\nSep 1, 2001\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nIndicative and Subjunctive Conditionals\n\n\n\n\n\n\nlogic\n\n\nlanguage\n\n\nconditionals\n\n\n\nIn any plausible semantics for conditionals, the semantics for indicatives and subjunctives will resemble each other closely. This means that if we are to keep the possible‐worlds semantics for subjunctives suggested by Lewis, we need to find a possible‐worlds semantics for indicatives. One reason for thinking that this will be impossible is the behaviour of rigid designators in indicatives. An indicative like ‘If the stuff in the rivers, lakes and oceans really is H3O, then water is H3O’ is non‐vacuously true, even though its consequent is true in no possible worlds, and hence not in the nearest possible world where the antecedent is true. I solve this difficulty by providing a semantics for conditionals within the framework of two‐dimensional modal logic. In doing so, I show that we can have a reasonably unified semantics for indicative and subjunctive conditionals. \n\n\n\n\n\nApr 1, 2001\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nBegging the Question and Bayesians\n\n\n\n\n\n\nepistemology\n\n\ngames and decisions\n\n\nnotes\n\n\n\nIn a recent article Patrick Maher shows that the ‘depragmatised’ form of Dutch Book arguments for Bayesianism tend to beg the question against their most interesting anti-Bayesian opponents. I argue that the same criticism can be levelled at Maher’s own argument for Bayesianism. \n\n\n\n\n\nApr 1, 2001\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nKeynes, Uncertainty and Interest Rates\n\n\n\n\n\n\nepistemology\n\n\ngames and decisions\n\n\nphilosophy of economics\n\n\n\nUncertainty plays an important role in The General Theory, particularly in the theory of interest rates. Keynes did not provide a theory of uncertainty, but he did make some enlightening remarks about the direction he thought such a theory should take. I argue that some modern innovations in the theory of probability allow us to build a theory which captures these Keynesian insights. If this is the right theory, however, uncertainty cannot carry its weight in Keynes’s arguments. This does not mean that the conclusions of these arguments are necessarily mistaken; in their best formulation they may succeed with merely an appeal to risk. \n\n\n\n\n\nApr 1, 2001\n\n\nBrian Weatherson\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/wgac/index.html",
    "href": "posts/wgac/index.html",
    "title": "What Good are Counterexamples?",
    "section": "",
    "text": "The following kind of scenario is familiar throughout analytic philosophy. A bold philosopher proposes that all Fs are Gs. Another philosopher proposes a particular case that is, intuitively, an F but not a G. If intuition is right, then the bold philosopher is mistaken. Alternatively, if the bold philosopher is right, then intuition is mistaken, and we have learned something from philosophy. Can this alternative ever be realised, and if so, is there a way to tell when it is? In this paper, I will argue that the answer to the first question is yes, and that recognising the right answer to the second question should lead to a change in some of our philosophical practices.\n\nPublished in Philosophical Studies 115 (2003): 1-31.\n\nThe problem is pressing because there is no agreement across the sub-disciplines of philosophy about what to do when theory and intuition clash. In epistemology, particularly in the theory of knowledge, and in parts of metaphysics, particularly in the theory of causation, it is almost universally assumed that intuition trumps theory. Shope’s The Analysis of Knowledge contains literally dozens of cases where an interesting account of knowledge was jettisoned because it clashed with intuition about a particular case. In the literature on knowledge and lotteries it is not as widely assumed that intuitions about cases are inevitably correct, but this still seems to be the working hypothesis.1 And recent work of causation by a variety of authors, with a wide variety of opinions, generally takes the same line: if a theory disagrees with intuition about a case, the theory is wrong.2 In this area exceptions to the rule are a little more frequent, particularly on the issues of whether causation is transitive and whether omissions can be causes, but in most cases the intuitions are taken to override the theories. Matters are quite different in ethics. It is certainly not a good thing for utilitarian theories that we very often feel that the action that maximises utility is not the right thing to do. But the existence of such cases is rarely taken to be obviously and immediately fatal for utilitarian theories in the way that, say, Gettier cases are taken to be obviously and immediately fatal for theories of knowledge that proclaim those cases to be cases of knowledge. Either there is some important difference here between the anti-utilitarian cases and the Gettier cases, a difference that justifies our differing reactions, or someone is making a mistake. I claim that it is (usually) the epistemologists and the metaphysicians who are wrong. In more cases than we usually imagine, a good philosophical theory can teach us that our intuitions are mistaken. Indeed, I think it is possible (although perhaps not likely) that the justified true belief (hereafter, JTB) theory of knowledge is so plausible that we should hold onto it in preference to keeping our intuition that Gettier cases are not cases of knowledge.\n1 See, for example, DeRose (1996) and Nelkin (2000)2 See, for example, Menzies (1996), or any of the papers in the special Journal of Philosophy issue on causation, April 2000.My main interests here are methodological, not epistemological. Until the last section I will be arguing for the JTB theory of knowledge, but my main interest is in showing that one particular argument against the JTB theory, the one that turns on the fact that it issues in some rather unintuitive pronouncements about Gettier cases, is not in itself decisive. Still, the epistemological issues are important, which is one reason I chose to focus on the JTB theory, and at the end I will discuss how the methodological conclusions drawn here may impact on them in an unexpected way.\n\n1 Intuitions\nLet us say that a counterexample to the theory that all Fs are Gs is a possible situation such that most people have an intuition that some particular thing in the story is an F but not a G. The kinds of intuition I have in mind are what George Bealer (1998) calls intellectual “seemings”. Bealer distinguishes intellectual seemings, such as the intuition that Hume’s Principle is true, or that punishing a person for a crime they did not commit is unjust, from physical seemings, such as the ‘intuition’ that objects fall if released, or perhaps that the sun rotates around the earth. We shall be primarily concerned here with intellectual seemings, and indeed I shall only call these intuitions in what follows.\nAs Bealer notes, whether something seems to be true can be independent of whether we believe it to be true. Bealer himself notes that Frege’s Axiom V seems to be true, though we know it is false. It does not seem to be the case, in the relevant sense, that 643 x 721 = 463603. Unless one is rather good at mental arithmetic, there is nothing that 643 x 721 seems to be; it is out of the reach of intuition. These are not the only ways that seemings and belief can come apart. One can judge that something seems to be the case while neither believing nor disbelieving it. This is a sensible attitude to take towards the view that one cannot know that a particular ticket will lose in a fair lottery. This is despite the fact that it certainly seems one cannot know this. If one’s intuitions are running rampant, one may even have an intuition about something that one believes to be strictly indeterminate. For example, some people may have the intuition that the continuum hypothesis is true, even though they believe on reflection that it is indeterminate whether it is true.\nThe distinction between intuitions and belief is important because it helps reduce the violence that revisionary philosophical views do to our pre-existing positions. When I say that Gettier cases may be cases of knowledge, I am not denying that there is a strong intuition that they are not cases of knowledge. I am not denying that a Gettier case does not seem to be a case of knowledge. The same thing occurs in ethics. Utilitarians rarely deny that it seems that punishing innocents is the wrong thing to do. They urge that in certain, rare, cases this might be one of those things that seems to be true despite being false. The case that knowledge is justified true belief is meant to be made in full awareness of the fact that certain cases of justified true beliefs seem to not be cases of knowledge.\nActually, although we will not make much of it here, this last claim is not true as a general statement about all people. Jonathan Weinberg, Stephen Stich and Shaun Nichols have reported Weinberg, Stich, and Nichols (2001) that the intuition that Gettier cases are not cases of knowledge is not universally shared. It is not entirely clear what the philosophical relevance of these discoveries is. It might show that we who have Gettier intuitions speak a different language from those who do not. It might show (though as Stich and Nichols point out it is rather hard to see how) that philosophers know a lot more about knowledge than other folk. I think it is rather unlikely that this is true, but we shall bracket such concerns for now, and continue on the assumption that all parties have the Gettier intuitions. Since I shall want to argue that knowledge may still be justified belief in any case, I am hardly tilting the playing field in my direction by making this assumption.\nGiven that intuitions are what Bealer calls intellectual seemings, and given that the example of Axiom V shows that seemings can be mistaken, what evidence have we that they are not mistaken in the cases we consider here? Arguably, we have very little indeed. Robert Cummins (1998) argues that in general intuition should not be trusted as an evidential source because it cannot be calibrated. We wouldn’t have trusted the evidence Galileo’s telescope gave us about the moon without an independent reason for thinking his telescope reliable. Fortunately, this can be done; we can point the telescope at far away terrestrial mountains, and compare its findings with the findings of examining the mountains up close and personal. There is no comparable way of calibrating intuitions. Clearly we should suspicious of any method that has been tested and found unreliable, but there are tricky questions about the appropriate level of trust in methods that have not been tested. Ernest Sosa (1998) argues in response to Cummins that this kind of reasoning leads to an untenable kind of scepticism. Sosa notes that one can make the same point about perception as Cummins makes about intuition: we have no independent way of calibrating perception as a whole. There is a distinction to be drawn here, since perception divides into natural kinds, visual perception, tactile perception, etc, and we can use each of these to calibrate the others. It is hard to see how intuitions can be so divided in ways that permit us to check some kinds of intuitions against the others. In any case, the situation is probably worse than Cummins suggests, since we know that several intuitions are just false. It is interesting to note the many ways in which intuition does, by broad agreement, go wrong.\nMany people are prone to many kinds of systematic logical mistakes. Most famously, the error rates on the Wason Selection Task are disturbingly large. Although this test directly measures beliefs rather than intuitions, it seems very likely that many of the false beliefs are generated by mistaken intuitions. As has been shown in a variety of experiments, the most famous of which were conducted by Kahneman and Tversky, most people are quite incompetent at probabilistic reasoning. In the worst cases, subjects held that a conjunction was more probable than one of its conjuncts. Again, this only directly implicates subjects’ beliefs, but it is very likely that the false beliefs are grounded in false intuitions. (The examples in this paragraph are discussed in detail in Stich (1988, 1992).)\nAs noted above, most philosophers would agree that many, if not most, people have mistaken moral intuitions. We need not agree with those consequentialists who think that vast swathes of our moral views are in error to think that (a) people make systematic moral mistakes and (b) some of these mistakes can be traced to mistaken intuitions. To take the most dramatic example, for thousands of years it seemed to many people that slavery was morally acceptable. On a more mundane level, many of us find that our intuitive judgements about a variety of cases cannot be all acceptable, for it is impossible to find a plausible theory that covers them all.3 Whenever we make a judgement inconsistent with such an intuition, we are agreeing that some of our original intuitions were mistaken.\n3 The myriad examples in Unger (1996) are rather useful for reminding us just how unreliable our moral intuitions are, and how necessary it is to employ reflection and considered judgement in regimenting such intuitions.From a rather different direction, there are many mistaken conceptual intuitions, with the error traceable to the way Gricean considerations are internalised in the process of learning a language. Having learned that it would be improper to use t to describe a particular case, we can develop the intuition that this case is not an F, where F is the property denoted by t. For example, if one is careless, one can find oneself sharing the intuition expressed by Ryle in The Concept of Mind that morally neutral actions, like scratching one’s head, are neither voluntary nor involuntary (Ryle 1949). The source of this intuition is the simple fact that it would be odd to describe an action as voluntary or involuntary unless there was some reason to do so, with the most likely such reason being that the action was in some way morally suspect. The fact that the intuition has a natural explanation does not stop it being plainly false. We can get errors in conceptual intuitions from another source. At one stage it was thought that whales are fish, that the Mars is a star, the sun isn’t. These are beliefs, not intuitions, but there are clearly related intuitions. Anyone who had these beliefs would have had the intuition that in a situation like this (here demonstrating the world) the object in the Mars position was a star, and the objects in the whale position were fish. The empirical errors in the person’s belief will correlate to conceptual errors in their intuition. To note further that the kind of error being made here is conceptual not empirical, and hence the kind of error that occurs in intuition, note that we need not have learned anything new about whales, the sun or Mars to come to our modern beliefs. (In fact we did, but that’s a different matter.) Rather, we need only have learned something about the vast bulk of the objects that are fish, or stars, to realise that these objects had been wrongly categorised. The factor we had thought to be the most salient similarity to the cases grouped under the term, being a heavenly body visible in the night sky for ‘star’, living in water for ‘fish’, turned out not to be the most important similarity between most things grouped under that term. So there is an important sense in which saying whales are fish, or that the sun is not a star, may reveal a conceptual (rather than an empirical) error.\nThere seems to be a link between these two kinds of conceptual error. The reason we say that the Rylean intuitions, or more generally the intuitions of what Grice (1989, Ch. 1) called the Type-A philosophers, are mistaken is that the rival, Gricean, theory attaches to each word a relatively natural property. There is no natural property that actions satisfy when, and only when, we ordinarily describe them as voluntary. There is a natural property that covers all these cases, and other more mundane actions like scratching one’s head, and that is the property we now think is denoted by ‘voluntary’. This notion of naturalness, and the associated drive for systematicity in our philosophical and semantic theories, will play an important role in what follows.\n\n\n2 Correcting Mistakes\nThe following would be a bad defence of the JTB theory against counterexamples. We can tell that all counterexamples to the JTB theory are based on mistaken intuitions, because the JTB theory is true, so all counterexamples to it are false. Unless we have some support for the crucial premise that the JTB theory is true, this argument is rather weak. And that support should be enough to not only make the theory prima facie plausible, but so convincing that we are prepared to trust it rather than our judgements about Gettier cases.\nIn short, the true theory of knowledge is the one that does best at (a) accounting for as many as possible of our intuitions about knowledge while (b) remaining systematic. A ‘theory’ that simply lists our intuitions is no theory at all, so condition (b) is vital. And it is condition (b), when fully expressed, that will do most of the work in justifying the preservation of the JTB theory in the face of the counterexamples.\nThe idea that our theory should be systematic is accepted across a wide range of philosophical disciplines. This idea seems to be behind the following plausible claims by Michael Smith: “Not only is it a platitude that rightness is a property that we can discover to be instantiated by engaging in rational argument, it is also a platitude that such arguments have a characteristic coherentist form.” (1994: 40) The second so-called platitude just points out that it is a standard way of arguing in ethics to say, you think we should do X in circumstances C1, circumstances C2 are just like C1, so we should do X in C1. The first points out that not only is this standard, it can yield surprising ethical knowledge. But this is only plausible if it is more important that final ethics is systematic than that first ethics, the ethical view delivered by intuition, is correct. In other words, it is only plausible if ethical intuitions are classified as mistaken to the extent that they conflict with the most systematic plausible theory. So, for example, it would be good news for utilitarianism if there was no plausible rival with any reasonable degree of systematicity.\nThis idea also seems to do important work in logic. If we just listed intuitions about entailment, we would have a theory on which disjunctive syllogism (A and ~A \\({\\vee}\\) B entail B) is valid, while ex falso quadlibet (A and ~A entail B) is not. Such a theory is unsystematic because no concept of entailment that satisfies these two intuitions will satisfy a generalised transitivity requirement: that if C and D entail E, and F entails D then C and F entail E. (This last step assumes that ~A entails ~A \\({\\vee}\\) B, but that is rarely denied.) Now one can claim that a theory of entailment that gives up this kind of transitivity can still be systematic enough, and Neil Tennant (1992) does exactly this, but it is clear that we have a serious cost of the theory here, and many people think avoiding this cost is more important than preserving all intuitions.\nIn more detail, there are four criteria by which we can judge a philosophical theory. First, counterexamples to a theory count against it. While a theory can be reformist, it cannot be revolutionary. A theory that disagreed with virtually all intuitions about possible cases is, for that reason, false. The theory: X knows that p iff X exists and p is true is systematic, but hardly plausible. As a corollary, while intuitions about any particular possible case can be mistaken, not too many of them could be. Counterexamples are problematic for a theory, the fewer reforms needed the better, it’s just not that they are not fatal. Importantly, not all counterexamples are as damaging to a theory as others. Intuitions come in various degrees of strength, and theories that violate weaker intuitions are not as badly off as those that violate stronger intuitions. Many people accept that the more obscure or fantastic a counterexample is, the less damaging it is to a theory. This seems to be behind the occasional claim that certain cases are “spoils to the victor” – the idea is that the case is so obscure or fantastic that we should let theory rather than intuition be our guide. Finally, if we can explain why we have the mistaken intuition, that counts for a lot in reducing the damage the counterexample does. Grice did not just assert that the theory on which an ordinary head scratch was voluntary was more systematic than the theory of voluntariness Ryle proposed, he provided an explanation of why it might seem that his theory was wrong in certain cases.\nSecondly, the analyses must not have too many theoretical consequences which are unacceptable. Consider Kahneman and Tversky’s account of how agents actually make decisions, prospect theory, as an analysis of ‘good decision’. (Disclaimer: This is not how Kahneman and Tversky intend it.) So the analysis of ‘good decision’ is ‘decision authorised by prospect theory’. It is a consequence of prospect theory that which decision is “best” depends on which outcome is considered to be the neutral point. In practice this is determined by contextual factors. Redescribing a story to make different points neutral, which can be done by changing the context, licences different decisions. I take it this would be unacceptable in an analysis of ‘good decision’, even though it means the theory gives intuitively correct results in more possible cases than its Bayesian rivals4. In general, we want our normative theories to eliminate arbitrariness as much as possible, and this is usually taken to be more important than agreeing with our pre-theoretic intuitions about particular cases. Unger uses a similar argument in Living High and Letting Die to argue against the reliance on intuitions about particular cases in ethics. We have differing ethical intuitions towards particular cases that differ only in the conspicuousness of the suffering caused (or not prevented), we know that conspicuousness is not a morally salient difference, so we should stop trusting the particular intuitions. (Presumably this is part of the reason that we find Tennant’s theory of entailment so incredible, prima facie. It is not just that violating transitivity seems unsystematic, it is that we have a theoretical intuition that transitivity should be maintained.)\n4 A point very similar to this is made in Horowitz (1998).Thirdly, the concept so analysed should be theoretically significant, and should be analysed in other theoretically significant terms. This is why we now analyse ‘fish’ in such a way that whales aren’t fish, and ‘star’ in such a way that the sun is a star. This is not just an empirical fact about our language. Adopting such a constraint on categories is a precondition of building a serious classificatory scheme, so it is a constraint on languages, which are classificatory schemes par excellance. Even if I’m wrong about this, the fact that we do reform our language with the advance of science to make our predicates refer to theoretically more significant properties shows that we have a commitment to this restriction.\nFinally, the analysis must be simple. This is an important part of why we don’t accept Ryle’s analysis of ‘voluntary’. His analysis can explain all the intuitive data, even without recourse to Gricean implicature, and arguably it doesn’t do much worse than the Gricean explanation on the second and third tests. But Grice’s theory can explain away the intuitions that it violates, and importantly it does so merely with the aid of theories of pragmatics that should be accepted for independent reasons, and it is simpler, so it trumps Ryle’s theory.\nMy main claim is that even once we have accepted that the JTB theory seems to say the wrong thing about Gettier cases, we should still keep an open mind to the question of whether it is true. The right theory of knowledge, the one that attributes the correct meaning to the word ‘knows’, will do best on balance at these four tests. Granted that the JTB theory does badly on test one, it seems to do better than its rivals on tests two, three and four, and this may be enough to make it correct.\n\n\n3 Naturalness in a theory of meaning\nLet’s say I have convinced you that it would be better to use ‘knows’ in such a way that we all now assent to “She knows” whenever the subject of that pronoun truly, justifiably, believes. You may have been convinced that only by doing this will our term pick out a natural relation, and there is evident utility in having our words pick out relations that carve nature at something like its joints. Only in that way, you may concede, will our language be a decent classificatory scheme of the kind described above, and it is a very good thing to have one’s language be a decent classificatory scheme. I have implicitly claimed above that if you concede this you should agree that I will have thereby corrected a mistake in your usage. But, an objector may argue, it is much more plausible to say that in doing so I simply changed the meaning of ‘knows’ and its cognates in your idiolect. The meaning of your words is constituted by your responses to cases like Gettier cases, so when I convince you to change your response, I change the meaning of your words.\nThis objection relies on a faulty theory of meaning, one that equates meaning with use in a way which is quite implausible. If this objection were right, it would imply infallibilism about knowledge ascriptions. Still, the objection does point to a rather important point. There is an implicit folk theory of the meaning of ‘knows’, one according to which it does not denote justified true belief. I claim this folk theory is mistaken. It is odd to say that we can all be mistaken about the meanings of our words; it is odd to say that we can’t make errors in word usage. I think the latter is the greater oddity, largely because I have a theory which explains how we can all make mistakes about meanings in our own language.\nHow can we make such mistakes? The short answer is that meanings ain’t in the head. The long answer turns on the kind of tests on analyses I discussed in section two. The meaning of a predicate is a property in the sense described by Lewis (1983)5: a set, or class, or plurality of possibilia. (That is, in general the meaning of a predicate is its intension.6) The interesting question is determining which property it is. In assigning a property to a predicate, there are two criteria we would like to follow. The first is that it validates as many as possible of our pre-theoretic beliefs. The second is that it is, in some sense, simple and theoretically important. How to make sense of this notion of simplicity is a rather complex matter. Lewis canvasses the idea that there is a primitive ‘naturalness’ of properties which measures simplicity and theoretical significance7, and I will adopt this idea. Space restrictions prevent me going into greater detail concerning ‘naturalness’, but if something more definite is wanted, for the record I mean by it here just what Lewis means by it in the works previously cited.8\n5 The theory of meaning outlined here is deeply indebted to Lewis (1983, 1984, 1992).6 There are tricky questions concerning cointensional predicates, but these have fairly familiar solutions, which I accept. For ease of expression here I will ignore the distinction between properties and relations – presumably ‘knows’ denotes a relation, that is a set of ordered pairs.7 ‘Measures’ may be inappropriate here. Plausibly a property is simple because it is natural.8 For more recent applications of naturalness in Lewis’s work, see Langton and Lewis (1998, 2001) and Lewis (2001).So, recapitulating what I said in section two, for any predicate t and property F, we want F meet two requirements before we say it is the meaning of t. We want this meaning assignment to validate many of our pre-theoretic intuitions (this is what we test for in tests one and two) and we want F to be reasonably natural (this is what we test for in tests three and four). In hard cases, these requirements pull in opposite directions; the meaning of t is the property which on balance does best. Saying ‘knows’ means ‘justifiably truly believes’ does not do particularly well on the first requirement. Gettier isolated a large class of cases where it goes wrong. But it does very well on the second, as it analyses knowledge in terms of a short list of simple and significant features. I claim that all its rivals don’t do considerably better on the first, and arguably do much worse on the second. (There are considerations pulling either way here, as I note in section seven, but it is prima facie plausible that it does very well on the second, which is all that we consider for now.) That the JTB theory is the best trade-off is still a live possibility, even considering Gettier cases.\nThis little argument will be perfectly useless this theory of meaning (owing in all its essential features to Lewis) is roughly right. There are several reasons for believing it. First, it can account for the possibility of mistaken intuitions, while still denying the possibility that intuitions about meaning can be systematically and radically mistaken. This alone is a nice consequence, and not one which is shared by every theory of meaning on the market. Secondly, as was shown in sections one and two, it seems to make the right kinds of predictions about when meaning will diverge from intuitions about meaning.\nThirdly, it can account for the fact that some, but not all, disagreements about the acceptability of assertions are disputes about matters of fact, not matters of meaning. This example is from Cummins: “If a child, asked to use ‘fair’ in a sentence, says,”It isn’t fair for girls to get as much as boys,” we should suspect the child’s politics, not his language” (1998, 120). This seems right; but if the child had said “It is fair that dreams are purple”, we would suspect his language. Perhaps by ‘fair’ he means ‘nonsensical’ or something similar. A theory of meaning needs to account for this divergence, and for the fact that it is a vague matter when we say the problem is with the child’s language, and when with his politics. In short, saying which disputes are disputes about facts (or values or whatever), and which about meanings, is a compulsory question for a theory of meaning.\nThe balance theory of meaning I am promoting can do this, as the following demonstration shows. This theory of meaning is determinedly individualistic. Every person has an idiolect determined by her dispositions to apply terms; a shared language is a collection of closely-enough overlapping idiolects. So the child’s idiolect might differ from ours, especially if he uses ‘fair’ to mean ‘nonsensical’. But if the idiolect differs in just how a few sentences are used, it is likely that the meaning postulate which does best at capturing his dispositions to use according to our two criteria, is the same as the meaning postulate which does best at capturing our dispositions to use. The reason is that highly natural properties are pretty thin on the ground; one’s dispositions to use a term have to change quite a lot before they get into the orbit of a distinct natural property. So despite the fact that I allow for nothing more than overlapping idiolects, in practice the overlap is much closer to being exact than on most ‘overlapping idiolect’ theories.\nWith this, I can now distinguish which disputes are disputes about facts, and which are disputes about meaning. Given that there is a dispute, the parties must have different dispositions to use some important term. In some disputes, the same meaning postulate does best on balance at capturing the dispositions of each party. I say that here the parties mean the same thing by their words, and the dispute is a dispute about facts. In others, the difference will be so great that different meaning postulates do best at capturing the dispositions of the competing parties. In these cases, I say the dispute is a dispute about meaning.\nNow, I can explain the intuition that the JTB theorist means something different to the rest of us by ‘knows. That is, I can explain this intuition away. It seems a fair assumption that the reasonably natural properties will be evenly distributed throughout the space of possible linguistic dispositions. If this is right, then any change of usage beyond a certain magnitude will, on my theory, count as a change of meaning. And it is plausible to suppose the change I am urging to our usage, affirming rather than denying sentences like, “Smith knows Jones owns a Ford” is beyond that certain magnitude. But the assumption of even distribution of the reasonably natural properties is false. That, I claim, is what the failure of the ’analysis of knowledge’ merry-go-round to stop shows us. There are just no reasonably natural properties in the neighbourhood of our disposition to use ‘knows’. If this is right, then even some quite significant changes to usage will not be changes in meaning, because they will not change which is the closest reasonably natural property to our usage pattern. The assumption that the reasonably natural properties are reasonably evenly distributed is plausible, but false. Hence the hunch that I am trying to change the meaning of ‘knows’ is plausible, but false.\nThe hypothesis that when we alter intuitions because of a theory we always change meanings, on the other hand, is not even plausible. When the ancients said “Whales are fish”, or “The sun is not a star”, they simply said false sentences. That is, they said that whales are fish, and believed that the sun is not a star. This seems platitudinous, but the ‘use-change implies meaning-change’ hypothesis would deny it.\nIt has sometimes been suggested to me that conceptual intuitions should be given greater privilege than other intuitions; that I am wrong to generalise from the massive fallibility of logical, ethical or semantic intuitions to the massive fallibility of conceptual intuitions. Since I am on much firmer ground when talking about these non-conceptual cases, if such an attack were justified it would severely weaken my argument. Given what has been said so far we should be able to see what is wrong with this suggestion. Consider a group of people who systematically assent to “If A then B implies if B then A.” On this view these people are expressing a mistaken logical intuition, but a correct conceptual intuition. So their concept of ‘implication’ doesn’t pick out implication, or at the very least doesn’t pick out our concept of ‘implication’. Now if we are in that group, this summary becomes incoherent, so this position immediately implies that we can’t be mistaken about our logical intuitions. Further, we are no longer able to say that when these people say “If A then B implies if B then A,” they are saying something false, because given the reference of ‘implies’ in their idiolect, this sentence expresses a true proposition. This is odd, but odder is to come. Assuming again we are in this group, it turns out to be vitally important in debates concerning philosophical logic to decide whether we are engaging in logical analysis or conceptual analysis. It might turn out a correct piece of conceptual analysis of ‘implication’ picks out a different relation to the correct implication relation we derive from purely logical considerations. If logical intuitions are less reliable than conceptual intuitions, as proposed, and assent to sentences like “If A then B implies if B then A” reveals simultaneously a logical and a conceptual intuition, this untenable conclusion seems forced. I conclude that conceptual intuitions are continuous with other intuitions, and should be treated in a similar way.\n\n\n4 Keeping Conceptual Analysis\nThe following would be a bad way to respond to the worry that the JTB theory amounts to a change in the meaning of the word ‘knows’. For the worry to have any bite, facts about the meaning of ‘knows’ will have to be explicable in terms of facts about the use of ’knows. But facts about use can only tell us about the beliefs of this community about knowledge, not what knowledge really is. Since different communities adopt different standards for knowledge, we should only trust ours over theirs if (a) we have special evidence that our is correct or (b) we are so xenophobic that we trust ours simply because it is ours. “Many of us care very much whether or cognitive processes lead to beliefs that are true, or give us power over nature, or lead to happiness. But only those with a deep and free-floating conservatism in matters epistemic will care whether their cognitive processes are sanctioned by the evaluative standards that happen to be woven into our language” (Stich (1988), 109). “The intuitions and tacit knowledge of the man or woman in the street are quite irrelevant. The theory seeks to say what knowledge really is, not what folk epistemology takes it to be” (Stich (1992), 252).9 Facts about use can only give us the latter, so they are not what are relevant to my inquiry.\n9 The paper from which this quote is drawn is about the content of mental states, so originally it had ‘mental representation’ for ‘knowledge’ and ‘psychology’ for ‘epistemology’. But I take it that (a) this isn’t an unfair representation of Stich’s views and (b) even if it is, it is an admirably clear statement of the way many people feel about the use of intuitions about possible cases, and worth considering for that reason alone.Stich takes this to be a general reason for abandoning conceptual analysis. Now while I think, and have argued above, that conceptual analysis need not slavishly follow intuition, I do not think that we should abandon it altogether. Stich’s worry seems to be conceptual analysis can only tell us about our words, not about our world. But is this kind of worry coherent? Can we say what will be found when we get to this real knowledge about the world? Will we be saying, “This belief of Smith’s shouldn’t be called knowledge, but really it is”? We need to attend to facts about the meaning of ‘knows’ in order to define the target of our search. If not, we have no way to avoid incoherencies like this one.\nTo put the same point another way, when someone claims to find this deep truth about knowledge, why should anyone else care? She will say, “Smith really knows that Jones owns a Ford, but I don’t mean what everyone else means by ‘knows’.” Why is this any more interesting than saying, “Smith really is a grapefruit, but I don’t mean what everyone else means by ‘grapefruit’”? If she doesn’t use words in the way that we do, we can ignore what she says about our common word usage. Or at least we can ignore it until she (or one of her colleagues) provides us with a translation manual. But to produce a translation manual, or to use words the way we do, she needs to attend to facts about our meanings. Again, incoherence threatens if she doesn’t attend to these facts but claims nevertheless to be participating in a debate with us. These points are all to be found in Chapter 2 of Jackson (1998).\nAn underlying assumption of the first reply is that there is a hard division between facts about meaning and facts about the world at large; that a principle like: No ‘is’ from a ‘means’ holds. This principle is, however, mistaken. All instances of the following argument pattern, where t ranges over tokenings of referring terms, are valid.\n\nP1.\n\nt refers unequivocally to \\({\\alpha}\\).\n\nP2.\n\nt refers unequivocally to \\({\\beta}\\).\n\nC.\n\n\\({\\alpha}\\) = \\({\\beta}\\)\n\n\nFor example, from the premise that ‘POTUS’ refers unequivocally to the President of the United States, and the premise that ‘POTUS’ refers unequivocally to Bush, we can validly infer that Bush is President of the United States. Since P1 and P2 are facts about meaning, and C is a fact about the world, any principle like No ‘is’ from a ‘means’ must be mistaken. So this worry about how much we can learn from conceptual analysis, from considerations of meaning, is mistaken.\nI call this inference pattern the R-inference. That the R-inference is valid doesn’t just show Stich’s critique rests on the false assumption No ‘is’ from a ‘means’. It can be used to provide a direct response to his critique. The problem is meant to be that conceptual analysis, the method of counterexamples, can at best provide us with claims like: ‘knows’ refers to the relation justifiably truly believes. We want to know facts about knowledge, not about the term ‘knows’, so the conceptual analyst seems to have been looking in the wrong place. But it is a platitude that ‘knows’ refers to the relation knows. I call such platitudes, that ‘t’ refers to t, instances of the R-schema10. We can use the R-schema together with the R-inference to get the kind of conclusion our opponents are looking for.\n10 Horwich (1999, 115–30) discusses similar schema, noting that instances involving words in foreign languages, or indexical expressions, will not be platitudinous. He also notes a way to remove the presumption that there is such a thing as knowledge, by stating the schema as \\({\\forall}\\)x (‘knowledge’ refers to x iff knowledge = x). For ease of expression I will stick with the simpler formulation in the text.\nP1.\n\n‘Knowledge’ refers unequivocally to the relation justifiably truly believes.\n\nP2.\n\n‘Knowledge’ refers unequivocally to the relation knows.\n\nC.\n\nThe relation knows is the relation justifiably truly believes.\n\n\nMore colloquially, the conclusion says that knowledge is justified true belief. Everyone agrees (I take it) that conceptual analysis could, in principle, give us knowledge of facts of the form of P1. So the opponents of conceptual analysis must either deny P2, or deny that C follows from P1 and P2. In other words, for any such argument they must deny that the R-schema is true, or that the R-inference is valid. I hope the reader will agree that neither option looks promising.\n\n\n5 Against the Psychologists\nSomeone excessively impressed by various results in the psychological study of concepts may make the following objection to the theory of meaning here proffered. “Why think that we should prefer short lists of necessary and sufficient conditions? This seems like another one of those cases where philosophers take their aesthetic preferences to be truth-indicative, much like the ‘taste for desert landscapes’ argument. Besides, haven’t psychologists like Eleanor Rosch shown that our concepts don’t have simple necessary and sufficient conditions? If that’s right, your argument falls down in several different places.”\nStrictly speaking, my preference is not just for short lists of necessary and sufficient conditions. But it is, for reasons set out more fully in the next section, for short theories that fit the meaning of some term into a network of other properties. And my argument would fall down if there was no reason to prefer such short theories. And, of course, short lists of necessary and sufficient conditions are paradigmatically short theories. One reason I prefer the JTB analysis to its modern rivals is its brevity. Some of the reasons for preferring short lists are brought out by considering the objections to this approach developed by psychologists. I’ll just focus on one of the experiments performed by Rosch and Mervis, the points I make can be generalised.\nRosch and Mervis (1975) claim that “subjects rate superordinate semantic categories as having few, if any, attributes common to all members.” (p. 20) (A superordinate semantic category is one, like ‘fruit’, which has other categories, like ‘apple’, ‘pear’ and ‘banana’, as sub-categories.) Here’s the experiment they ran to show this. For each of six superordinate categories (‘furniture’, ‘fruit’, ‘weapon’, ‘vegetable’, ‘vehicle’ and ‘clothing’) they selected twenty category members. So for ‘fruit’ the members ranged from ‘orange’ and ‘apple’ to ‘tomato’ and ‘olive’. They then asked a range of subjects to list the attributes they associated with some of these 120 category members. Each subject was presented with six members, one from each category, and for each member had a minute and a half to write down its salient attributes.\n\n[F]ew attributes were given that were true of all twenty members of the category – for four of the categories there was only one such item; for two of the categories, none. Furthermore, the single attribute that did apply to all members, in three cases was true of many items besides those within that superordinate (for example, “you eat it” for fruit). Rosch and Mervis (1975)\n\nThey go on to conclude that the superordinate is not defined by necessary and sufficient conditions, but by a ‘family resemblance’ between members. This particular experiment was taken to confirm that the number of attributes a member has with other members of the category is correlated with a previously defined measure of prototypicality.11 They claim that the intuition, commonly held amongst philosophers, that there must be some attribute in common to all the members, is explicable by the fact that the highly prototypical members of the category all do share quite a few attributes in common, ranging from 3 attributes in common to the highly prototypical vegetables, to 36 for the highly prototypical vehicles.\n11 In previous work they had done some nice experiments aimed at getting a grip on our intuition that apples are more prototypical exemplars of fruit than olives are.One occasionally hears people deride the assumption that there are necessary and sufficient conditions for the application of a term, as if this was the most preposterous piece of philosophy possible. Really, this assumption is no more than the assumption that dictionaries can be written, and without any reason to think otherwise, seems perfectly harmless. Perhaps, though, the Rosch and Mervis experiments provide a reason to think otherwise, a reason for thinking that the conditions of applicability for terms like ‘fruit’, ‘weapon’, and perhaps ‘knowledge’ are Wittgensteinian family resemblance conditions, rather than short lists of necessary and sufficient conditions, the kinds of conditions that fill traditional dictionaries.\nWhen we look closely, we see that the experiments do not show this at all. One could try and knock any such argument away by claiming the proposal is incoherent. The psychologists claim that there are no necessary and sufficient conditions for being a weapon, but something is a weapon iff it bears a suitable resemblance to paradigmatic weapons. In one sense, bearing a suitable resemblance to a paradigmatic weapon is a condition, so it looks like we just have a very short list of necessary and sufficient conditions, a list of length one. Jackson (1998, 61) makes a similar point in response to Stich’s invocation of Rosch’s experiments. This feels like it’s cheating, so I’ll move onto other objections. I’ll explain below just why it feels like cheating.\nPhilosophers aren’t particularly interested in terms like ‘weapon’, so these experiments only have philosophical interest if the results can be shown to generalise to terms philosophers care about. In other words, if can be shown that terms like ‘property’, ‘justice’, ‘cause’ and particularly ‘knows’ are cluster concepts, or family resemblance terms. But there is a good reason to think this is false. As William Ramsey (1998) notes, if F refers to a cluster concept, then for any proposed list of necessary and sufficient properties for F-hood, it should be easy to find an individual which is an F but which lacks some of these properties. To generate such an example, just find an individual which lacks one of the proposed properties, but which has several other properties from the cluster. It should be harder to find an individual which has the properties without being an F. If the proposed analysis is even close to being right, then having these conditions will entail having enough of the cluster of properties that are constitutive of F-hood to be an F. Note, for example, that all of the counterexamples Wittgenstein (1953) lists to purported analyses of ‘game’ are cases where something is, intuitively, a game but which does not satisfy the analysis. If game is really a cluster concept, this is how things should be. But it is not how things are with knowledge; virtually all counterexamples, from Gettier on, are cases which are intuitively not cases of knowledge, but which satisfy the proposed analysis. This is good evidence that even if some terms in English refer to cluster concepts, ‘knows’ is not one of them.\nSecondly, Rosch and Mervis’s conclusions about the nature of the superordinate categories makes some rather mundane facts quite inexplicable. In this experiment the subjects weren’t told which category each member was in, but for other categories they were. Imagine, as seems plausible, one of the subjects objected to putting the member in that category. Many people, even undergraduates, don’t regard olives and tomatoes as fruit. (“Fruit on pasta? How absurd!”) When the student asks why is this thing called a fruit, other speakers can provide a response. It is not a brute fact of language that tomatoes are fruit. It is not just by magic that we happened to come to a shared meaning for fruit that includes tomatoes, and that if faced with a new kind of object, we would generally agree about whether it is a fruit. It is because we know how to answer such questions. This answer to the Why is it called ‘fruit’? question had better be a sufficient condition for fruitness. If not, the subject is entitled to ask why having that property makes it a fruit. And unless there are very many possible distinct answers to this question, which seems very improbable, there will be a short list of necessary and sufficient conditions for being a fruit. But for this example, at least, ‘fruit’ was relatively arbitrary, so there will be a short list of necessary and sufficient conditions for being an F, for pretty much any F.\nThirdly, returning to ‘fruit’, we can see that Rosch and Mervis’s experiments could not possibly show that many superordinate predicates in English are cluster concepts. For they would, if successful, show that ‘fruit’ is a cluster concept, and it quite plainly is not. So by modus tollens, there is something wrong with their methodology. Some of the other categories they investigate, particularly ‘weapon’ and ‘furniture’ might be relatively cluster-ish, in a sense to be explained soon, but not ‘fruit’. As the OED says, a fruit is “the edible product of a tree, shrub or other plant, consisting of the seed and its envelope.” If nothing like this is right, then we couldn’t explain to the sceptical why we call tomatoes, olives and so on fruit.\nSo the conclusion that philosophically significant terms are likely to be cluster concepts is mistaken. To close, I note one way the cluster concept view could at least be coherent. Many predicates do have necessary and sufficient conditions for their applicability, just as traditional conceptual analysis assumed. In other words, they have analyses. However, any analysis must be in words, and sometimes the words needed will refer to quite recherche properties. The properties in the analysans may, that is, be significantly less natural than the analysandum.\nIn some contexts, we only consider properties that are above a certain level of naturalness. If I claim two things say my carpet and the Battle of Agincourt, have nothing in common, I will not feel threatened by an objector who points out that they share some gruesome, gerrymandered property, like being elements of {my carpet, the Battle of Agincourt}. Say that the best analysis of F-hood requires us to use predicates denoting properties which are below the contextually defined border between the ‘natural enough’ and ‘too gruesome to use’. Then there will be a sense in which there is no analysis of F into necessary and sufficient conditions; just the sense in which my carpet and the Battle of Avignon have nothing in common. Jackson’s argument feels like a cheat because he just shows that there will be necessary and sufficient conditions for any concept provided we are allowed to use gruesome properties, but he makes it sound like this proviso is unnecessary. If Rosch and Mervis’s experiments show anything at all, it is that this is true of some common terms in some everyday-ish contexts. In particular, if we restrict our attention to the predicates that might occur to us within ninety seconds (which plausibly correlates well with some level of naturalness), very few terms have analyses. Thus far, Rosch and Mervis are correct. They go wrong by projecting truths of a particular context to all contexts.\n\n\n6 In defence of analysis\nIn the previous section I argued that various empirical arguments gave us no reason to doubt that ‘knows’ will have a short analysis. In this section we look at various philosophical arguments to this conclusion. One might easily imagine the following objection to what has been claimed so far. At best, the above reasoning shows that if ‘knows’ has a short analysis, then the JTB analysis is correct, notwithstanding the intuitions provoked by Gettier cases. But there is little reason to think English terms have analyses, as evidenced by the failure of philosophers to analyse even one interesting term, and particular reasons to think that ‘knows’ does not have an analysis. These reasons are set out by Williamson (2000 Ch. 3), who argues, by appeal to intuitions about a particular kind of case, that there can be no analysis of ‘knows’ into independent clauses, one of which describes an internal state of the agent and the other of which describes an external state of the agent. This does not necessarily refute the JTB analysis, since the concepts of justification and belief in use may be neither internal nor external in Williamson’s sense. And if we are going to revise intuitions about the Gettier cases, we may wish to revise intuitions about Williamson’s cases as well, though here it is probably safest to not do this, because it is unclear just what philosophical benefit is derived from this revision. In response to these arguments I will make two moves: one defensive and one offensive. The defensive move is to distinguish the assumptions made here about the structure of the meaning of ‘knows’, and show how these assumptions do not have some of the dreadful consequences suggested by various authors. The offensive move, with which we begin, is to point out the rather unattractive consequences of not making these assumptions about the structure of the meaning of ‘knows’.\nIn terms of the concept of naturalness used above, the relation denoted by ‘knows’ might fall into one of three broad camps:\n\nIt might be rather unnatural;\nIt might be fairly natural in virtue of its relation to other, more natural, properties; or\nIt might be a primitive natural property, one that does not derive its naturalness from anything else.\n\nMy preferred position is (b). I think that the word ‘knows’, like every other denoting term in English, denotes something fairly natural. And I don’t think there are any primitively natural properties or relations in the vicinity of the denotation of this word, so it must derive its naturalness from its relation to other properties or relations. If this is so, we can recover some of the structure of its meaning by elucidating those relationships. If it is correct, that is exactly what I think the JTB theory does. This is not to say that justification, truth or belief are themselves primitively natural properties, but rather that we can make some progress towards recovering the source of the naturalness of knowledge via its decomposition into justification, truth and belief. But before investigating the costs of (b), let us look at the costs of (a) and (c).\nI think we can dispense with (c) rather quickly. It would be surprising, to say the least, if knowledge was a primitive relation. That X knows that p can hardly be one of the foundational facts that make up the universe. If X knows that p, this fact obtains in virtue of the obtaining of other facts. We may not be able to tell exactly what these facts are in general, but we have fairly strong opinions about whether they obtain or not in a particular case. This is why we are prepared to say whether or not a character knows something in a story, perhaps a philosophical story, without being told exactly that. We see the facts in virtue of which the character does, or does not, know this. This does not conclusively show that knowledge is not a primitively natural property. Electrical charge presumably is a primitively natural property, yet sometimes we can figure out the charge of an object by the behaviour of other objects. For example, if we know it is repulsed by several different negatively charged things, it is probably negatively charged. But in these cases it is clear our inference is from some facts to other facts that are inductively implied, not to facts that are constituted by the facts we know. (Only a rather unreformed positivist would say that charge is constituted by repulsive behaviour.) And it does not at all feel that in philosophical examples we are inductively (or abductively) inferring whether the character knows that p.\nThe more interesting question is whether (a) might be correct. This is, perhaps surprisingly, consistent with the theory of meaning advanced above. I held, following Lewis, that the meaning of a denoting term is the most natural object, property or relation that satisfies most of our usage dispositions. It is possible that the winner of this contest will itself be quite unnatural. This is what happens all the time with vague terms, and indeed it is what causes, or perhaps constitutes, their vagueness. None of the properties (or relations) that we may pick out by ‘blue’ is much more natural than several other properties (or relations) that would do roughly as well at capturing our usage dispositions, were they the denotation of ‘blue’.12 And indeed none of these properties (or relations) are particularly natural; they are all rather arbitrary divisions of the spectrum. The situation is possibly worse when we consider what Theodore Sider (2001) calls maximal properties. A property F is maximal iff things that massively overlap an F are not themselves an F. So being a coin is maximal, since large parts of a coin, or large parts of a coin fused with some nearby atoms outside the coin, are not themselves coins. Sider adopts the following useful notation: something is an F* iff it is suitable to be an F in every respect save that it may massively overlap an F. So a coin* is a piece of metal (or suitable substance) that is (roughly) coin-shaped and is (more or less) the deliberate outcome of a process designed to produce legal tender. Assuming that any collection of atoms has a fusion, in the vicinity of any coin there will be literally trillions of coin*s. At most one of these will be a coin, since coins do not, in general, overlap. That is, the property being a coin must pick out exactly one of these coin*s. Since the selection will be ultimately arbitrary, this property is not very natural. There are just no natural properties in the area, so the denotation of ‘coin’ is just not natural.\n12 I include the parenthetical comments here so as not to prejudge the question of whether colours are properties or relations. It seems unlikely to me that colours are relations, either the viewers or environments, but it is not worth quibbling over this here.These kind of considerations show that option (a) is a live possibility. But they do not show that it actually obtains. And there are several contrasts between ‘knows’, on the one hand, and ‘blue’ and ‘coin’ on the other, which suggest that it does not obtain. First, we do not take our word ‘knows’ to be as indeterminate as ‘blue’ or ‘coin’, despite the existence of some rather strong grounds for indeterminacy in it. Secondly, we take apparent disputes between different users of the word ‘knows’ to be genuine disputes, ones in which at most one side is correct, which we do not necessarily do with ‘blue’ and ‘coin’. Finally, we are prepared to use the relation denoted by ‘knows’ in inductive arguments in ways that seem a little suspect with genuinely unnatural relations, as arguably evidenced by our attitudes towards ‘coin’ and ‘blue’. Let’s look at these in more detail.\nIf we insisted that the meaning of ‘knows’ must validate all of our dispositions to use the term, we would find that the word has no meaning. If we just look at intuitions, we will find that our intuitions about ‘knows’ are inconsistent with some simple known facts. (Beliefs, being regimented by reflection, might not be inconsistent, depending on how systematic the regimentation has been.) For example, the following all seem true to many people.\n\nKnowledge supervenes on evidence: if two people (not necessarily in the same possible world) have the same evidence, they know the same things.\nWe know many things about the external world.\nWe have the same evidence as some people who are the victims of massive deception, and who have few true beliefs about their external world.\nWhatever is known is true.\n\nThese are inconsistent, so they cannot all be true. We could take any three of these as an argument for the negation of the fourth, though probably the argument from (1) (2) and (3) to the negation of (4) is less persuasive than the other three such arguments. I don’t want to adjudicate here which such argument is sound. All I want to claim here is that there is a fact of the matter about which of these arguments is sound, and hence about which of these four claims is false. If two people are disagreeing about which of these is false, at most one of them is right, and the other is wrong. If ‘knows’ denoted a rather unnatural relation, there would be little reason to believe these things to be true. Perhaps by more carefully consulting intuitions we could determine that one of them is false by seeing that it had the weakest intuitive pull. If we couldn’t do this, it would follow that in general there was no fact of the matter about which is false, and if someone wanted to use ‘know’ in their idiolect so that one particular one of these is false, there would be no way we could argue that they were wrong. It is quite implausible that this is what should happen in such a situation. It is more plausible that the dispute should be decided by figuring out which group of three can be satisfied by a fairly natural relation. This, recall, is just how we resolve disputes in many other areas of philosophy, from logic to ethics. If there is no natural relation eligible to be the meaning of ‘knows’, then probably this dispute has no resolution, just like the dispute about what ‘mass’ means in Newtonian mechanics.13\n13 Note that in that dispute the rivals are quite natural properties, but seem to be matched in their naturalness. In the dispute envisaged here, the rivals are quite unnatural, but still seem to be matched. For more on ‘mass’, see Field (1973).The above case generalises quite widely. If one speaker says that a Gettier case is a case of knowledge and another denies this (as Stich assures us actually happens if we cast our linguistic net wide enough) we normally assume that one of them is making a mistake. But if ‘knows’ denotes something quite unnatural, then probably each is saying something true in her own idiolect. Each party may make other mistaken claims, that for example what they say is also true in the language of all their compatriots, but in just making these claims about knowledge they would not be making a mistake. Perhaps there really is no fact of the matter here about who is right, but thinking so would be a major change to our common way of viewing matters, and hence would be a rather costly consequence of accepting option (a). Note here the contrast with ‘blue’ and ‘coin’. If one person adopts an idiosyncratic usage of ‘blue’ and ‘coin’, one on which there are determinate facts about matters where, we say, there are none, the most natural thing to say is that they are using the terms differently to us. If they insist that it is part of their intention in using the terms to speak the same way as their fellows we may (but only may) revise this judgement. But in general there is much more inclination to say that a dispute over whether, say, a patch is blue is merely verbal than to say this about a dispute over whether X knows that p.\nFinally, if knowledge was a completely unnatural relation, we would no more expect it to play a role in inductive or analogical arguments than does grue, but it seems it can play such a role. One might worry here that blueness also plays a role in inductive arguments, as in: The sky has been blue the last n days, so probably it will be blue tomorrow. If blueness is not natural, this might show that unnatural properties can play a role in inductive arguments. But what is really happening here is that there is, implicitly, an inductive argument based on a much narrow colour spectrum, and hence a much more natural property. To see this, note that we would be just as surprised tomorrow if the sky was navy blue, or perhaps of the dominant blue in Picasso’s blue period paintings, as if it were not blue at all.\nSo there are substantial costs to (a) and (c). Are there similar costs to (b)? If we take (b) to mean that there is a decomposition of the meaning of ‘knows’ into conditions, expressible in English, which we can tell a priori are individually necessary and jointly sufficient for knowledge, and such that it is also a priori that they represent natural properties, then (b) would be wildly implausible. To take just one part of this, Williamson (2000) notes it is clear that there are some languages in which such conditions cannot be expressed, so perhaps English is such a language too. And if this argument for ‘knows’ works it presumably works for other terms, like ‘pain’, but it is hard to find such an a priori decomposition of ‘pain’ into more natural properties. Really, all (b) requires is that there be some connection, perhaps only discoverable a posteriori, perhaps not even humanly comprehensible, between knowledge and other more primitively natural properties. These properties need not be denoted by any terms of English, or any other known language.\nMost importantly, this connection need not be a decomposition. If knowledge is the most general factive mental state, as Williamson proposes, and being factive and being a mental state are natural properties, then condition (b) will be thereby satisfied. If knowledge is the norm of assertion, as Williamson also proposes, then that could do as the means by which knowledge is linked into the network of natural properties. This last assumes that being an assertion is a natural property, and more dangerously that norms as natural, but these are relatively plausible assumptions in general. In neither case do we have a factorisation, in any sense, of knowledge into constituent properties, but we do have, as (b) requires, a means by which knowledge is linked into the network of natural properties. It is quite plausible that for every term which, unlike ‘blue’ and ‘coin’ are not excessively vague and do not denote maximal properties, something like (b) is correct. Given the clarifications made here to (b), this is consistent with most positions normally taken to be anti-reductionist about those terms, or their denotata.\n\n\n7 Naturalness and the JTB theory\nI have argued here that the following argument against the JTB theory is unsound.\n\nP1.\n\nThe JTB theory says that Gettier cases are cases of knowledge.\n\nP2.\n\nIntuition says that Gettier cases are not cases of knowledge.\n\nP3.\n\nIntuition is trustworthy in these cases.\n\nC.\n\nThe JTB theory is false.\n\n\nThe objection has been that P3 is false in those cases where following intuition slavishly would mean concluding that some common term denoted a rather unnatural property while accepting deviations from intuition would allow us to hold that it denoted a rather natural property. Peter Klein (in conversation) has suggested that there is a more sophisticated argument against the JTB theory that we can draw out of the Gettier cases. Since this argument is a good illustration of the way counterexamples should be used in philosophy, I’ll close with it.\nKlein’s idea, in effect, is that we can use Gettier cases to argue that being a justified true belief is not a natural property, and hence that P3 is after all true. Remember that P3 only fails when following intuition too closely would lead too far away from naturalness. If being a justified true belief is not a natural property to start with, there is no great danger of this happening. What the Gettier cases show us, goes the argument, is that there are two ways to be a justified true belief. The first way is where the belief is justified in some sense because it is true. The second way is where it is quite coincidental that the belief is both justified and true. These two ways of being a justified true belief may be natural enough, but the property being a justified true belief is just the disjunction of these two not especially related properties.\nI think this is, at least, a prima facie compelling argument. There are, at least, three important points to note about it. First, this kind of reasoning does not obviously generalise. Few of the examples described in Shope (1983) could be used to show that some target theory in fact made knowledge into a disjunctive kind. The second point is that accepting this argument is perfectly consistent with accepting everything I said above against the (widespread) uncritical use of appeal to intuition. Indeed, if what I said above is broadly correct then this is just the kind of reasoning we should be attempting to use when looking at fascinating counterexamples. Thirdly, if the argument works it shows something much more interesting than just that the JTB theory is false. It shows that naturalness is not always transferred to a conjunctive property by its conjuncts.\nI assume here that being a justified belief and being a true belief are themselves natural properties, and being a justified true belief is the conjunction of these. The only point here that seems possibly contentious is that being a true belief is not natural. On some forms of minimalism about truth this may be false, but those forms seem quite implausibly strong. Remember that saying being a true belief is natural does not imply that has an analysis – truth might be a primitively natural component of this property. And remember also that naturalness is intensional rather than hyperintensional. If all true beliefs correspond with reality in a suitable way, and corresponding with reality in that way is a natural property, then so is being a true belief, even if truth of belief cannot be explained in terms of correspondence.\nThis is a surprising result, because the way naturalness was originally set up by Lewis suggested that it would be transferred to a conjunctive property by its conjuncts. Lewis gave three accounts of naturalness. The first is that properties are perfectly natural in virtue of being co-intensive with a genuine universal. The third is that properties are natural in virtue of the mutual resemblance of their members, where resemblance is taken to be a primitive. On either account, it seems that whenever being F is natural, and so is being G, then being F and G will be natural.14 The second account, if it can be called that, is that naturalness is just primitive. If the Gettier cases really do show that being a justified true belief is not natural, then they will have shown that we have to fall back on just this account of naturalness.\n\n\n\n14 I follow Armstrong (1978) here in assuming that there are conjunctive universals.\n\n\nReferences\n\nArmstrong, D. M. 1978. Universals and Scientific Realism. Cambridge: Cambridge University Press.\n\n\nBealer, George. 1998. “Intuition and the Autonomy of Philosophy.” In Rethinking Intuition, edited by Michael DePaul and William Ramsey, 201–40. Lanham: Rowman & Littlefield.\n\n\nCummins, Robert. 1998. “Reflection on Reflective Equilibrium.” In Rethinking Intuition, edited by Michael DePaul and William Ramsey, 113–28. Lanham: Rowman & Littlefield.\n\n\nDeRose, Keith. 1996. “Knowledge, Assertion and Lotteries.” Australasian Journal of Philosophy 74 (4): 568–79. https://doi.org/10.1080/00048409612347531.\n\n\nField, Hartry. 1973. “Theory Change and the Indeterminacy of Reference.” Journal of Philosophy 70 (14): 462–81. https://doi.org/10.2307/2025110.\n\n\nGrice, H. Paul. 1989. Studies in the Way of Words. Cambridge, MA.: Harvard University Press.\n\n\nHorowitz, Tamara. 1998. “Philosophical Intuitions and Psychological Theory.” Ethics 108 (2): 367–85. https://doi.org/10.1086/233809.\n\n\nHorwich, Paul. 1999. Meaning. Oxford: Oxford University Press.\n\n\nJackson, Frank. 1998. From Metaphysics to Ethics: A Defence of Conceptual Analysis. Clarendon Press: Oxford.\n\n\nLangton, Rae, and David Lewis. 1998. “Defining ‘Intrinsic’.” Philosophy and Phenomenological Research 58 (2): 333–45. https://doi.org/10.2307/2653512.\n\n\n———. 2001. “Marshall and Parsons on ‘Intrinsic’.” Philosophy and Phenomenological Research 63 (2): 353–55. https://doi.org/10.2307/3071068.\n\n\nLewis, David. 1983. “New Work for a Theory of Universals.” Australasian Journal of Philosophy 61 (4): 343–77. https://doi.org/10.1080/00048408312341131.\n\n\n———. 1984. “Putnam’s Paradox.” Australasian Journal of Philosophy 62 (3): 221–36. https://doi.org/10.1080/00048408412340013.\n\n\n———. 1992. “Meaning Without Use: Reply to Hawthorne.” Australasian Journal of Philosophy 70 (1): 106–10. https://doi.org/10.1080/00048408112340093.\n\n\n———. 2001. “Redefining ’Intrinsic’.” Philosophy and Phenomenological Research 63 (2): 381–98. https://doi.org/10.2307/3071071.\n\n\nMenzies, Peter. 1996. “Probabilistic Causation and the Pre-Emption Problem.” Mind 105 (417): 85–117. https://doi.org/10.1093/mind/105.417.85.\n\n\nNelkin, Dana. 2000. “The Lottery Paradox, Knowledge, and Rationality.” Philosophical Review 109 (3): 373–409. https://doi.org/10.2307/2693695.\n\n\nRamsey, William. 1998. “Prototypes and Conceptual Analysis.” In Rethinking Intuition, edited by Michael DePaul and William Ramsey, 161–77. Lanham: Rowman & Littlefield.\n\n\nRosch, Eleanor, and Carolyn Mervis. 1975. “Family Resemblances: Studies in the Internal Structure of Categories.” Cognitive Science 7 (4): 573–605. https://doi.org/10.1016/0010-0285(75)90024-9.\n\n\nRyle, Gilbert. 1949. The Concept of Mind. New York: Barnes; Noble.\n\n\nShope, Robert. 1983. The Analysis of Knowledge. Princeton: Princeton University Press.\n\n\nSider, Theodore. 2001. “Maximality and Intrinsic Properties.” Philosophy and Phenomenological Research 63 (2): 357–64. https://doi.org/10.1111/j.1933-1592.2001.tb00109.x.\n\n\nSosa, Ernest. 1998. “Minimal Intuition.” In Rethinking Intuition, edited by Michael DePaul and William Ramsey, 257–69. Lanham: Rowman & Littlefield.\n\n\nStich, Stephen. 1988. “Reflective Equilibrium, Analytic Epistemology and the Problem of Cognitive Diversity.” Synthese 74 (3): 391–413. https://doi.org/10.1007/bf00869637.\n\n\n———. 1992. “What Is a Theory of Mental Representation?” Mind 101 (402): 243–63. https://doi.org/10.1093/mind/101.402.243.\n\n\nTennant, Neil. 1992. Autologic. Edinburgh: Edinburgh University Press.\n\n\nUnger, Peter. 1996. Living High and Letting Die. Oxford: Oxford University Press.\n\n\nWeinberg, Jonathan, Stephen Stich, and Shaun Nichols. 2001. “Normativity and Epistemic Intuitions.” Philosophical Topics 29 (1): 429–60. https://doi.org/10.5840/philtopics2001291/217.\n\n\nWilliamson, Timothy. 2000. Knowledge and its Limits. Oxford University Press.\n\n\nWittgenstein, Ludwig. 1953. Philosophical Investigations. London: Macmillan.\n\nCitationBibTeX citation:@article{weatherson2003,\n  author = {Weatherson, Brian},\n  title = {What {Good} Are {Counterexamples?}},\n  journal = {Philosophical Studies},\n  volume = {115},\n  number = {1},\n  pages = {1-31},\n  date = {2003-07},\n  doi = {10.1023/A:1024961917413},\n  langid = {en}\n}"
  },
  {
    "objectID": "posts/diri/index.html",
    "href": "posts/diri/index.html",
    "title": "Defending Interest Relative Invariantism",
    "section": "",
    "text": "In recent years a number of authors have defended the interest-relativity of knowledge and justification. Views of this form are floated by John Hawthorne (2004), and endorsed by Jeremy Fantl and Matthew McGrath (2002, 2009), Jason Stanley (2005) and Brian Weatherson (2005). The various authors differ quite a lot in how much interest-relativity they allow, but what is common is the defence of interest-relativity.\n\nPublished in Logos and Episteme 2 (2011): 591-609.\nImage from Wikimedia Commons.\n\nThese views have, quite naturally, drawn a range of criticisms. The primary purpose of this paper is to respond to these criticisms and, as it says on the tin, defend interest-relative invariantism, or IRI for short. But I don’t plan to defend every possible version of IRI, only a particular one. Most of the critics of IRI have assumed that it must have some or all of the following features.\n\nIt is harder to know things in high-stakes situations than in low-stakes situations.\nThere is an interest-sensitive constituent of knowledge.\nIRI stands and falls with some principles connecting knowledge and action, such as the principles found in Hawthorne and Stanley (2008).\n\nMy preferred version of IRI has none of these three features.1\n1 It is a tricky exegetical question how many of the three features here must be read into defences of IRI in the literature. My reading is that they do not have to be read in, so it is not overly original of me to defend a version of IRI that does away with all three. But I know many people disagree with that. If they’re right, this paper is more original than I think it is, and so I’m rather happy to be wrong. But I’m going to mostly set these exegetical issues aside, and compare different theories without taking a stand on who originally promulgated them.First, it says that knowledge changes when the odds an agent faces change, not when the stakes change. More precisely, interests affect belief because whether someone believes \\(p\\) depends inter alia on whether their credence in \\(p\\) is high enough that any bet on \\(p\\) they actually face is a good bet. And interests affect knowledge largely because they affect belief. Raising the stakes of any bet on \\(p\\) does not directly change whether an agent believes \\(p\\), but changing the odds of the bets on \\(p\\) they face does change it. In practice raising the stakes changes the odds due to the declining marginal utility of material goods. So in practice high-stakes situations are typically long-odds situations. But knowledge is hard in those situations because they are long-odds situations, not because they are high-stakes situations.\nSo my version of IRI says that knowledge differs between these two cases.\n\nHigh Cost Map:\n\nZeno is walking to the Mysterious Bookshop in lower Manhattan. He’s pretty confident that it’s on the corner of Warren Street and West Broadway. But he’s been confused about this in the past, forgetting whether the east-west street is Warren or Murray, and whether the north-south street is Greenwich, West Broadway or Church. In fact he’s right about the location this time, but he isn’t justified in having a credence in his being correct greater than about 0.95. While he’s walking there, he has two options. He could walk to where he thinks the shop is, and if it’s not there walk around for a few minutes to the nearby corners to find where it is. Or he could call up directory assistance, pay $1, and be told where the shop is. Since he’s confident he knows where the shop is, and there’s little cost to spending a few minutes walking around if he’s wrong, he doesn’t do this, and walks directly to the shop.\n\nLow Cost Map:\n\nJust like the previous case, except that Zeno has a new phone with more options. In particular, his new phone has a searchable map, so with a few clicks on the phone he can find where the store is. Using the phone has some very small costs. For example, it distracts him a little, which marginally raises the likelihood of bumping into another pedestrian. But the cost is very small compared to the cost of getting the location wrong. So even though he is very confident about where the shop is, he double checks while walking there.\n\n\nI think the Map Cases are like the various cases that have been used to motivate interest-relativity2 in all important respects. I think Zeno knows where the shop is in High Cost Map, and doesn’t know in Low Cost Map. And he doesn’t know in Low Cost Map because the location of the shop has suddenly become the subject matter of a bet at very long odds. You should think of Zeno’s not checking the location of the shop on his phone-map as a bet on the location of the shop. If he wins the bet, he wins a few seconds of undistracted strolling. If he loses, he has to walk around a few blocks looking for a store. The disutility of the loss seems easily twenty times greater than the utility of the gain, and by hypothesis the probability of winning the bet is no greater than 0.95. So he shouldn’t take the bet. Yet if he knew where the store was, he would be justified in taking the bet. So he doesn’t know where the store is. Now this is not a case where higher stakes defeat knowledge. If anything, the stakes are lower in Low Cost Map. But the relevant odds are longer, and that’s what matters to knowledge.\n2 Such as the Bank Cases in Stanley (2005), or the Train Cases in Fantl and McGrath (2002).Second, on this version of IRI, interests matter because there are interest-sensitive defeaters, not because interests form any kind of new condition on knowledge, alongside truth, justification, belief and so on. In particular, interests matter because there are interest-relative coherence constraints on knowledge. Some coherence constraints, I claim, are not interest-relative. If an agent believes \\(\\neg p\\), that belief defeats her purported knowledge that \\(p\\), even if the belief that \\(p\\) is true, justified, safe, sensitive and so on. It is tempting to try to posit a further coherence condition.\n\nPractical Coherence\n\nAn agent does not know that \\(p\\) if she prefers \\(\\varphi\\) to \\(\\psi\\) unconditionally, but prefers \\(\\psi\\) to \\(\\varphi\\) conditional on \\(p\\).\n\n\nBut that is too strong. For reasons similar to those gone over at the start of Hawthorne (2004), it would mean we know nearly nothing. A more plausible condition is:\n\nRelevant Practical Coherence\n\nAn agent does not know that \\(p\\) if she prefers \\(\\varphi\\) to \\(\\psi\\) unconditionally, but prefers \\(\\psi\\) to \\(\\varphi\\) conditional on \\(p\\), for any \\(\\varphi, \\psi\\) that are relevant given her interests.\n\n\nWhen this condition is violated, the agent’s claim to knowledge is defeated. As we’ll see below, defeaters behave rather differently to constituents of knowledge. Some things which could not plausibly be grounds for knowledge could be defeaters to defeaters for knowledge.\nRelevant Practical Coherence suffices, at least among agents who are trying to maximise expected value, to generate an interest-relativity to knowledge. The general structure of the case should be familiar from the existing literature. Let \\(p\\) be a proposition that is true, believed by the agent, and strongly but not quite conclusively supported by their evidence. Let \\(B\\) be a bet that has a small positive return if \\(p\\), and a huge negative return if \\(\\neg p\\). Assume the agent is now offered the bet, and let \\(\\varphi\\) be declining the bet, and \\(\\psi\\) be accepting the bet. Conditional on \\(p\\), the bet wins, so the agent prefers the small positive payout, so prefers \\(\\psi\\) to \\(\\varphi\\) conditional on \\(p\\). But the bet has a massively negative expected return, so unconditionally the agent does not want it. That is, unconditionally she prefers \\(\\varphi\\) to \\(\\psi\\). Once the bet is offered, the actions \\(\\varphi\\) and \\(\\psi\\) become relevant given her interests, so by Relevant Practical Coherence she no longer knows \\(p\\). So for such an agent, knowledge is interest-relative.\nCases where knowledge is defeated because if the agent did know \\(p\\), that would lead to problems elsewhere in their cognitive system, have a few quirky features. In particular, whether the agent knows \\(p\\) can depend on very distant features. Consider the following kind of case.\n\nConfused Student\nCon is systematically disposed to affirm the consequent. That is, if he notices that he believes both \\(p\\) and \\(q \\rightarrow p\\), he’s disposed to either infer \\(q\\), or if that’s impermissible given his evidence, to ditch his belief in the conjunction of \\(p\\) and \\(q \\rightarrow p\\). Con has completely compelling evidence for both \\(q \\rightarrow p\\) and \\(\\neg q\\). He has good but less compelling evidence for \\(p\\). And this evidence tracks the truth of \\(p\\) in just the right way for knowledge. On the basis of this evidence, Con believes \\(p\\). Con has not noticed that he believes both \\(p\\) and \\(q \\rightarrow p\\). If he did, he’s unhesitatingly drop his belief that \\(p\\), since he’d realise the alternatives (given his dispositions) involved dropping belief in a compelling proposition. Two questions:\n\nDoes Con know that \\(p\\)?\nIf Con were to think about the logic of conditionals, and reason himself out of the disposition to affirm the consequent, would he know that \\(p\\)?\n\n\nI think the answer to the first question is No, and the answer to the second question is Yes. As it stands, Con’s disposition to affirm the consequent is a doxastic defeater of his putative knowledge that \\(p\\). Put another way, \\(p\\) doesn’t cohere well enough with the rest of Con’s views for his belief that \\(p\\) to count as knowledge. To be sure, \\(p\\) coheres well enough with those beliefs by objective standards, but it doesn’t cohere at all by Con’s lights. Until he changes those lights, it doesn’t cohere well enough to be knowledge. Moreover (as a referee pointed out), Con’s belief is not safe. Since he could easily have ‘reasoned’ himself out of his belief that \\(p\\), the belief isn’t safe in the way that knowledge is safe.\nI think that beliefs which violate Relevant Practical Coherence fail to be knowledge for the same reason that Con’s belief that \\(p\\) fails to be knowledge. In what follows, I’ll make frequent use of this analogy; many of the objections to IRI turn out to be equally strong objections to the view that there are ever defeaters of the type Con suffers from.\nThis suggests our third point. This version of IRI does not take IRI to be a consequence of more general principles about knowledge and action. It simply says that there exist at least one pair of cases where the only relevant difference between agents in the two cases concerns their interests, but one knows that \\(p\\) and the other does not.3 I happen to think that most of the general principles that philosophers have used to try to derive IRI are false. But since IRI is much weaker than those principles, that is no reason to conclude IRI is false.4\n3 And this is true even though \\(p\\) is not a proposition about their interests, or something that is supported by propositions about their interests, and so on.4 I will consider, and tentatively support, one principle stronger than IRI in the final section. But the key point is that these general principles are not needed to defend IRI.The existence of interest-relativity is then quite a weak claim. There are plenty of stronger claims in the area we could make. I prefer, for instance, a version of IRI where being offered bets like \\(B\\) defeats knowledge that \\(p\\) even if the agent does not have the preferences I ascribed above. (That could be because she isn’t trying to maximise expected value, or because she’s messed up the expected value calculations.) But knowledge could be interest-relative even if I’m wrong about those cases.\nSo I’ve set out a version of IRI that lacks three features often attributed to IRI. I haven’t argued for that theory here - I do that at much greater length in (Author Paper 1). But I hope I’ve done enough to convince you that the theory is both a version of IRI, and not obviously false. In what follows, I’ll argue that the theory is immune to the various challenges to IRI that have been put forward in the literature. This immunity is, I think, a strong reason to prefer this version of IRI.\n\n1 Experimental Objections\nI don’t place as much weight as some philosophers do on the correlation between the verdicts of an epistemological theory and the gut reactions that non-experts have to tricky cases. And I don’t think the best cases for IRI relies on such a correlation holding. The best case for IRI is that it integrates nicely with an independently supported theory of belief, and that it lets us keep a number of plausible principles without drifting into skepticism.5 But still, it is nice to not have one’s theory saying exorbitantly counterintuitive things. Various experimental results, such as the results in May et al. (2010) and Feltz and Zarpentine (2010), might be thought to suggest that IRI does have consequences which are counterintuitive, or which at least run counter to the intuitions of some experimental subjects. I’m going to concentrate on the latter set of results here, though I think that what I say will generalise to related experimental work. In fact, I think the experiments don’t really tell against IRI, because IRI, at least in my preferred version, doesn’t make any unambiguous predictions about the cases at the centre of the experiments. The reason for this is related to my insistence that we concentrate on the odds an agent faces, not the stakes she faces.\n5 This points are expanded upon greatly in (Author Paper 1).Feltz and Zarpentine gave subjects related vignettes, such as the following pair. (Each subject only received one of the pair.)\n\nHigh Stakes Bridge\n\nJohn is driving a truck along a dirt road in a caravan of trucks. He comes across what looks like a rickety wooden bridge over a yawning thousand foot drop. He radios ahead to find out whether other trucks have made it safely over. He is told that all 15 trucks in the caravan made it over without a problem. John reasons that if they made it over, he will make it over as well. So, he thinks to himself, ‘I know that my truck will make it across the bridge.’\n\nLow Stakes Bridge\n\nJohn is driving a truck along a dirt road in a caravan of trucks. He comes across what looks like a rickety wooden bridge over a three foot ditch. He radios ahead to find out whether other trucks have made it safely over. He is told that all 15 trucks in the caravan made it over without a problem. John reasons that if they made it over, he will make it over as well. So, he thinks to himself, ‘I know that my truck will make it across the bridge.’ (Feltz and Zarpentine 2010, 696)\n\n\nSubjects were asked to evaluate John’s thought. And the result was that 27% of the participants said that John does not know that the truck will make it across in Low Stakes Bridge, while 36% said he did not know this in High Stakes Bridge. Feltz and Zarpentine say that these results should be bad for interest-relativity views. But it is hard to see just why this is so.\nNote that the change in the judgments between the cases goes in the direction that IRI seems to predict. The change isn’t trivial, even if due to the smallish sample size it isn’t statistically significant in this sample. But should a view like IRI have predicted a larger change? To figure this out, we need to ask three questions.\n\nWhat are the costs of the bridge collapsing in the two cases?\nWhat are the costs of not taking the bet, i.e., not driving across the bridge?\nWhat is the rational credence to have in the bridge’s sturdiness given the evidence John has?\n\nConditional on the bridge not collapsing, the drivers presumably prefer taking the bridge to not taking it. And the actions of taking the bridge or going around the long way are relevant. So by Relevant Practical Coherence, the drivers know the bridge will not collapse in Low Stakes Bridge but not High Stakes Bridge if the following equation is true. (I assume all the other conditions for knowledge are met, and that there are no other salient instances of Relevant Practical Coherence to consider.)\n\\[\\frac{C_H}{G + C_H} &gt; x &gt; \\frac{C_L}{G + C_L}\\]\nwhere \\(G\\) is the gain the driver gets from taking a non-collapsing bridge rather than driving around (or whatever the alternative is), \\(C_H\\) is the cost of being on a collapsing bridge in High Stakes Bridge, \\(C_L\\) is the cost of being on a collapsing bridge in Low Stakes Bridge, and \\(x\\) is the probability that the bridge will collapse. I assume \\(x\\) is constant between the two cases. If that equation holds, then taking the bridge, i.e., acting as if the bridge won’t collapse, maximises expected utility in Low Stakes Bridge but not High Stakes Bridge. So in High Stakes Bridge, adding the proposition that the bridge won’t collapse to the agent’s cognitive system produces incoherence, since the agent won’t (at least rationally) act as if the bridge won’t collapse. So if the equation holds, the agent’s interests in avoiding \\(C_H\\) creates a doxastic defeater in High Stakes Bridge.\nBut does the equation hold? Or, more relevantly, did the subjects of the experiment believe that the equation hold? None of the four variables has their values clearly entailed by the story, so we have to guess a little as to what the subjects’ views would be.\nFeltz and Zarpentine say that the costs in “High Stakes Bridge are very costly—certain death—whereas the costs in Low Stakes Bridge are likely some minor injuries and embarrassment.” (Feltz and Zarpentine 2010, 702) I suspect both of those claims are wrong, or at least not universally believed. A lot more people survive bridge collapses than you may expect, even collapses from a great height.6 And once the road below a truck collapses, all sorts of things can go wrong, even if the next bit of ground is only 3 feet away. (For instance, if the bridge collapses unevenly, the truck could roll, and the driver would probably suffer more than minor injuries.)\n6 In the West Gate bridge collapse in Melbourne in 1971, a large number of the victims were underneath the bridge; the people on top of the bridge had a non-trivial chance of survival. That bridge was 200 feet above the water, not 1000, but I’m not sure the extra height would matter greatly. Again from a slightly lower height, over 90% of people on the bridge survived the I-35W collapse in Minneapolis in 2007.We aren’t given any information as to the costs of not crossing the bridge. But given that 15 other trucks, with less evidence than John, have decided to cross the bridge, it seems plausible to think they are substantial. If there was an easy way to avoid the bridge, presumably the first truck would have taken it. If \\(G\\) is large enough, and \\(C_H\\) small enough, then the only way for this equation to hold will be for \\(x\\) to be low enough that we’d have independent reason to say that the driver doesn’t know the bridge will hold.\nBut what is the value of \\(x\\)? John has a lot of information that the bridge will support his truck. If I’ve tested something for sturdiness two or three times, and it has worked, I won’t even think about testing it again. Consider what evidence you need before you’ll happily stand on a particular chair to reach something in the kitchen, or put a heavy television on a stand. Supporting a weight is the kind of thing that either fails the first time, or works fairly reliably. Obviously there could be some strain-induced effects that cause a subsequent failure7, but John really has a lot of evidence that the bridge will support him.\n7 As I believe was the case in the I-35W collapse.Given those three answers, it seems to me that it is a reasonable bet to cross the bridge. At the very least, it’s no more of an unreasonable bet than the bet I make every day crossing a busy highway by foot. So I’m not surprised that 64% of the subjects agreed that John knew the bridge would hold him. At the very least, that result is perfectly consistent with IRI, if we make plausible assumptions about how the subjects would answer the three numbered questions above.\nAnd as I’ve stressed, these experiments are only a problem for IRI if the subjects are reliable. I can think of two reasons why they might not be. First, subjects tend to massively discount the costs and likelihoods of traffic related injuries. In most of the country, the risk of death or serious injury through motor vehicle accident is much higher than the risk of death or serious injury through some kind of crime or other attack, yet most people do much less to prevent vehicles harming them than they do to prevent criminals or other attackers harming them.8 Second, only 73% of these subjects in this very experiment said that John knows the bridge will support him in Low Stakes Bridge. This is rather striking. Unless the subjects endorse an implausible kind of scepticism, something has gone wrong with the experimental design. But if the subjects are implausibly sceptical, then we shouldn’t require our epistemological theory to track their gut reactions. (And if something has gone wrong with the experimental design, then obviously can’t be used as the basis for any objection.) So given the fact that the experiment points broadly in the direction of IRI, and that with some plausible assumptions it is perfectly consistent with that theory, and that the subjects seem unreasonably sceptical to the point of unreliability about epistemology, I don’t think this kind of experimental work threatens IRI.\n8 See the massive drop in the numbers of students walking or biking to school, reported in Ham, Martin, and Kohl III (2008), for a sense of how big an issue this is.\n\n2 Knowledge By Indifference and By Wealth\nGillian Russell and John Doris (2009) argue that Jason Stanley’s account of knowledge leads to some implausible attributions of knowledge, and if successful their objections would generalise to other forms of IRI. I’m going to argue that Russell and Doris’s objections turn on principles that are prima facie rather plausible, but which ultimately we can reject for independent reasons.9\n9 I think the objections I make here are similar in spirit to those Stanley made in a comments thread on Certain Doubts, though the details are new. The thread is at http://el-prod.baylor.edu/certain_doubts/?p=616.Their objection relies on variants of the kind of case Stanley uses heavily in his (2005) to motivate a pragmatic constraint on knowledge. Stanley considers the kinds of cases we used to derive IRI from Relevant Practical Coherence. So imagine an agent who faces a choice between accepting the status quo, call that \\(\\varphi\\), and taking some giant risk, call that \\(\\psi\\). The giant risk in this case will involve a huge monetary loss if \\(\\neg p\\), and a small non-monetary gain if \\(p\\). Stanley says, and I agree, that in such a case the agent doesn’t know \\(p\\), even if their belief in \\(p\\) is true, well supported by evidence, and so on. Moreover, he says, had \\(\\psi\\) not been a relevant option, the agent could have known \\(p\\). I agree, and I think Relevant Practical Coherence explains these intuitions well.\nRussell and Doris imagine two kinds of variants on Stanley’s case. In one variant the agent doesn’t care about the material loss associated with \\(\\psi \\wedge \\neg p\\). As I would put it, although their material wealth would decline precipitously in that case, their utility would not, because their utility is not tightly correlated with material wellbeing. Given that, the agent may well prefer \\(\\psi\\) to \\(\\varphi\\) unconditionally, and so would still know \\(p\\). Russell and Doris don’t claim this is a problem in itself, but they do think the conjunction of this with the previous paragraph is a problem. As they put it, “you should have reservations ... about what makes the knowledge claim true: not giving a damn, however enviable in other respects, should not be knowledge-making.” (Russell and Doris 2009, 432).\nTheir other variant involves an agent with so much money that the material loss is trifling to them. Since the difference in utility between having, say, eight billion dollars and seven billion dollars is not that high, perhaps they will again prefer \\(\\psi\\) to \\(\\varphi\\) unconditionally, so still know \\(p\\). But it is, allegedly, counterintuitive to have the knowledge that \\(p\\) turn on the agent’s wealth. As Russell and Doris say, “matters are now even dodgier for practical interest accounts, because money turns out to be knowledge making.” (Russell and Doris 2009, 433) And this isn’t just because wealth can purchase knowledge. As they say, “money may buy the instruments of knowledge ... but here the connection between money and knowledge seems rather too direct.” (Russell and Doris 2009, 433)\nThe first thing to note about this case is that indifference and wealth aren’t really producing knowledge. What they are doing is more like defeating a defeater. Remember that the agent in question had enough evidence, and enough confidence, that they would know \\(p\\) were it not for the practical circumstances. As I said in the introduction, practical considerations enter debates about knowledge in part because they are distinctive kinds of defeaters. It seems that’s what is going on here. And we have, somewhat surprisingly, independent evidence to think that indifference and wealth do matter to defeaters.\nConsider two variants on Gilbert Harman’s ‘dead dictator’ example (Harman 1973, 75). In the original example, an agent reads that the dictator has died through an actually reliable source. But there are many other news sources around, such that if the agent read them, she would lose her belief. Even if the agent doesn’t read those sources, their presence can constitute defeaters to her putative knowledge that the dictator died.\nIn our first variant on Harman’s example, the agent simply does not care about politics. It’s true that there are many other news sources around that are ready to mislead her about the dictator’s demise. But she has no interest in looking them up, nor is she at all likely to look them up. She mostly cares about literature, and will spend her day reading old novels. In this case, the misleading news sources are too distant, in a sense, to be defeaters. So she still knows the dictator has died. Her indifference towards politics doesn’t generate knowledge - the original reliable report is the knowledge generator - but her indifference means that a would-be defeater doesn’t gain traction.\nIt might be objected here that the agent doesn’t know the dictator has died because there are misleading reports around saying the dictator is alive, and she is in no position to rebut them. But this is too high a standard for knowledge. There are millions of people in Australia who know that humans are contributing to global warming on purely testimonial grounds. Many, perhaps even most, of these people would not be able to answer a carefully put together argument that humans are not contributing to global warming, such as an argument that picked various outlying statistics to mislead the reader. And such arguments certainly exist; the conservative parts of the media do as much as they can to play them up. But the mere existence of such arguments doesn’t defeat the average person’s testimonial knowledge about anthropogenic global warming. Similarly, the mere existence of misleading reports does not defeat our agent’s knowledge of the dictator’s death, as long as there is no nearby world where she is exposed to the reports. (Thanks here to an anonymous referee.)\nIn the second variant, the agent cares deeply about politics, and has masses of wealth at hand to ensure that she knows a lot about it. Were she to read the misleading reports that the dictator has survived, then she would simply use some of the very expensive sources she has to get more reliable reports. Again this suffices for the misleading reports not to be defeaters. Even before the rich agent exercises her wealth, the fact that her wealth gives her access to reports that will correct for misleading reports means that the misleading reports are not actually defeaters. So with her wealth she knows things she wouldn’t otherwise know, even before her money goes to work. Again, her money doesn’t generate knowledge – the original reliable report is the knowledge generator – but her wealth means that a would-be defeater doesn’t gain traction.\nThe same thing is true in Russell and Doris’s examples. The agent has quite a bit of evidence that \\(p\\). That’s why she knows \\(p\\). There’s a potential practical defeater for \\(p\\). But due to either indifference or wealth, the defeater is immunised. Surprisingly perhaps, indifference and/or wealth can be the difference between knowledge and ignorance. But that’s not because they can be in any interesting sense ‘knowledge makers’, any more than I can make a bowl of soup by preventing someone from tossing it out. Rather, they can be things that block defeaters, both when the defeaters are the kind Stanley talks about, and when they are more familiar kinds of defeaters.\n\n\n3 Temporal Embeddings\nMichael Blome-Tillmann (2009) has argued that tense-shifted knowledge ascriptions can be used to show that his version of Lewisian contextualism is preferable to IRI. Like Russell and Doris, his argument uses a variant of Stanley’s Bank Cases.10 Let \\(O\\) be that the bank is open Saturday morning. If Hannah has a large debt, she is in a high-stakes situation with respect to \\(O\\). In Blome-Tillmann’s version of the example, Hannah had in fact incurred a large debt, but on Friday morning the creditor waived this debt. Hannah had no way of anticipating this on Thursday. She has some evidence for \\(O\\), but not enough for knowledge if she’s in a high-stakes situation. Blome-Tillmann says that this means after Hannah discovers the debt waiver, she could say\n10 In the interests of space, I won’t repeat those cases yet again here.\nI didn’t know \\(O\\) on Thursday, but on Friday I did.\n\nBut I’m not sure why this case should be problematic for any version of IRI, and very unsure why it should even look like a reductio of IRI. As Blome-Tillmann notes, it isn’t really a situation where Hannah’s stakes change. She was never actually in a high stakes situation. At most her perception of her stakes change; she thought she was in a high-stakes situation, then realised that she wasn’t. Blome-Tillmann argues that even this change in perceived stakes can be enough to make (1) true if IRI is true. Now actually I agree that this change in perception could be enough to make (1) true, but when we work through the reason that’s so, we’ll see that it isn’t because of anything distinctive, let alone controversial, about IRI.\nIf Hannah is rational, then given her interests she won’t be ignoring \\(\\neg O\\) possibilities on Thursday. She’ll be taking them into account in her plans. Someone who is anticipating \\(\\neg O\\) possibilities, and making plans for them, doesn’t know \\(O\\). That’s not a distinctive claim of IRI. Any theory should say that if a person is worrying about \\(\\neg O\\) possibilities, and planning around them, they don’t know \\(O\\). And that’s simply because knowledge requires a level of confidence that such a person simply does not show. If Hannah is rational, that will describe her on Thursday, but not on Friday. So (1) is true not because Hannah’s practical situation changes between Thursday and Friday, but because her psychological state changes, and psychological states are relevant to knowledge.\nWhat if Hannah is, on Thursday, irrationally ignoring \\(\\neg O\\) possibilities, and not planning for them even though her rational self wishes she were planning for them? In that case, it seems she still believes \\(O\\). After all, she makes the same decisions as she would as if \\(O\\) were sure to be true. But it’s worth remembering that if Hannah does irrationally ignore \\(\\neg O\\) possibilities, she is being irrational with respect to \\(O\\). And it’s very plausible that this irrationality defeats knowledge. That is, you can’t be irrational with respect to a proposition and know it. Irrationality excludes knowledge. In any case, I doubt this is the natural way to read Blome-Tillmann’s example. We naturally read Hannah as being rational, and if she is rational she won’t have the right kind of confidence to count as knowing \\(O\\) on Thursday.\nThere’s a methodological point here worth stressing. Doing epistemology with imperfect agents often results in facing tough choices, where any way to describe a case feels a little counterintuitive. If we simply hew to intuitions, we risk being led astray by just focussing on the first way a puzzle case is described to us. But once we think through Hannah’s case, we see perfectly good reasons, independent of IRI, to endorse IRI’s prediction about the case.\n\n\n4 Problematic Conjunctions\nBlome-Tillmann offers another argument against IRI, that makes heavy use of the notion of having enough evidence to know something. Here is how he puts the argument. (Again I’ve changed the numbering and some terminology for consistency with this paper.)\n\nSuppose that John and Paul have exactly the same evidence, while John is in a low-stakes situation towards \\(p\\) and Paul in a high-stakes situation towards \\(p\\). Bearing in mind that IRI is the view that whether one knows \\(p\\) depends on one’s practical situation, IRI entails that one can truly assert:\n\nJohn and Paul have exactly the same evidence for \\(p\\), but only John has enough evidence to know \\(p\\), Paul doesn’t.\n\n(Blome-Tillmann 2009, 328–29)\n\nAnd this is meant to be a problem, because (2) is intuitively false.\nBut IRI doesn’t entail any such thing. We can see this by looking at a simpler example that illustrates the way ‘enough’ works.\nGeorge and Ringo both have $6000 in their bank accounts. They both are thinking about buying a new computer, which would cost $2000. Both of them also have rent due tomorrow, and they won’t get any more money before then. George lives in New York, so his rent is $5000. Ringo lives in Syracuse, so his rent is $1000. Clearly, (REC) and (RAC) are true.\n\nREC\n\nRingo has enough money to buy the computer.\n\nRAC\n\nRingo can afford the computer.\n\n\nAnd (GEC) is true as well, though there’s at least a reading of (GAC) where it is false.\n\nGEC\n\nGeorge has enough money to buy the computer.\n\nGAC\n\nGeorge can afford the computer.\n\n\nFocus for now on (GEC). It is a bad idea for George to buy the computer; he won’t be able to pay his rent. But he has enough money to do so; the computer costs $2000, and he has $6000 in the bank. So (GEC) is true. Admittedly there are things close to (GEC) that aren’t true. He hasn’t got enough money to buy the computer and pay his rent. You might say that he hasn’t got enough money to buy the computer given his other financial obligations. But none of this undermines (GEC).\nNow just like George has enough money to buy the computer, Paul has enough evidence to know that \\(p\\). Paul can’t know that \\(p\\), just like George can’t buy the computer, because of his practical situation. But that doesn’t mean he doesn’t have enough evidence to know it. He clearly does have enough evidence, since he has the same evidence John has, and John knows that \\(p\\). So, contra Blome-Tillmann, IRI doesn’t entail this problematic conjunction.\nIn a footnote attached to this, Blome-Tillmann offers a reformulation of the argument.\n\nI take it that having enough evidence to ‘know \\(p\\)’ in \\(C\\) just means having evidence such that one is in a position to ‘know \\(p\\)’ in \\(C\\), rather than having evidence such that one ‘knows \\(p\\)’. Thus, another way to formulate (2) would be as follows: ‘John and Paul have exactly the same evidence for \\(p\\), but only John is in a position to know \\(p\\), Paul isn’t.’ (Blome-Tillmann 2009, 329n23)\n\nNow having enough evidence to know \\(p\\) isn’t the same as being in a position to know it, any more than having enough money to buy the computer puts George in a position to buy it. So I think this is more of a new objection than a reformulation of the previous point. But might it be a stronger objection? Might it be that IRI entails (PosK), which is false?\n\nPosK\n\nJohn and Paul have exactly the same evidence for \\(p\\), but only John is in a position to know \\(p\\), Paul isn’t.\n\n\nActually, it isn’t a problem that IRI says that (PosK) is true. In fact, almost any epistemological theory will imply that conjunctions like that are true. In particular, any epistemological theory that allows for the existence of defeaters which do not supervene on the possession of evidence will imply that conjunctions like (PosK) are true. For example, anyone who thinks that whether you can know that a barn-like structure is really a barn depends on whether there are non-barns in the neighbourhood that look like the structure you’re looking at will think that conjunctions like (PosK) are true. Again, it matters a lot that IRI is suggesting that traditional epistemologists did not notice that there are distinctively pragmatic defeaters. Once we see that, we’ll see that conjunctions like (PosK) are not surprising at all.\nConsider again Con, and his friend Mod who is disposed to reason by modus ponens and not by affirming the consequent. We could say that Con and Mod have the same evidence for \\(p\\), but only Mod is in a position to know \\(p\\). There are only two ways to deny that conjunction. One is to interpret ‘position to know’ so broadly that Con is in a position to know \\(p\\) because he could change his inferential dispositions. But then we might as well say that Paul is in a position to know \\(p\\) because he could get into a different ‘stakes’ situation. Alternatively, we could say that Con’s inferential dispositions count as a kind of evidence against \\(p\\). But that stretches the notion of evidence beyond a breaking point. Note that we didn’t say Con had any reason to affirm the consequent, just that he does. Someone might adopt, or change, a poor inferential habit because they get new evidence. But they need not do so, and we shouldn’t count their inferential habits as evidence they have.\nIf that case is not convincing, we can make the same point with a simple Gettier-style case.\n\nGetting the Job\nIn world 1, at a particular workplace, someone is about to be promoted. Agnetha knows that Benny is the management’s favourite choice for the promotion. And she also knows that Benny is Swedish. So she comes to believe that the promotion will go to someone Swedish. Unsurprisingly, management does choose Benny, so Agnetha’s belief is true.\nWorld 2 is similar, except there it is Anni-Frid who knows that Benny is the management’s favourite choice for the promotion, that Benny is Swedish. So she comes to believe that the promotion will go to someone Swedish. But in this world Benny quits the workplace just before the promotion is announced, and the management unexpectedly passes over a lot of Danish workers to promote another Swede, namely Björn. So Anni-Frid’s belief that the promotion will go to someone Swedish is true, but not in a way that she could have expected.\n\nIn that story, I think it is clear that Agnetha and Anni-Frid have exactly the same evidence that the job will go to someone Swedish, but only Agnetha is in a position to know this, Anni-Frid is not. The fact that an intermediate step is false in Anni-Frid’s reasoning, but not Agnetha’s, means that Anni-Frid’s putative knowledge is defeated, but Agnetha’s is not. And when that happens, we can have differences in knowledge without differences in evidence. So it isn’t an argument against IRI that it allows differences in knowledge without differences in evidence.\n\n\n5 Holism and Defeaters\nThe big lesson of the last few sections is that interests create defeaters. Sometimes an agent can’t know \\(p\\) because adding \\(p\\) to her stock of beliefs would introduce either incoherence or irrationality. The reason is normally that the agent faces some decision where it is, say, bad to do \\(\\varphi\\), but good to do \\(\\varphi\\) given \\(p\\). In that situation, if she adds \\(p\\), she’ll either incoherently think that it’s bad to do \\(\\varphi\\) although it’s good to do it given what is (by her lights) true. Moreover, the IRI theorist says, being incoherent in this way blocks knowledge, so the agent doesn’t know \\(p\\).\nBut there are other, more roundabout, ways in which interests can mean that believing \\(p\\) would entail incoherence. One of these is illustrated by an example alleged by Ram Neta to be hard for interest-relative theorists to accommodate.\n\nKate needs to get to Main Street by noon: her life depends upon it. She is desperately searching for Main Street when she comes to an intersection and looks up at the perpendicular street signs at that intersection. One street sign says “State Street” and the perpendicular street sign says “Main Street.” Now, it is a matter of complete indifference to Kate whether she is on State Street–nothing whatsoever depends upon it. (Neta 2007, 182)\n\nLet’s assume for now that Kate is rational; dropping this assumption introduces mostly irrelevant complications. That is, we will assume Kate is an expected utility maximiser. Kate will not believe she’s on Main Street. She would only have that belief if she took it to be settled that she’s on Main, and hence not worthy of spending further effort investigating. But presumably she won’t do that. The rational thing for her to do is to get confirming (or, if relevant, confounding) evidence for the appearance that she’s on Main. If it were settled that she was on Main, the rational thing to do would be to try to relax, and be grateful that she had found Main Street. Since she has different attitudes about what to do simpliciter and conditional on being on Main Street, she doesn’t believe she’s on Main Street.\nSo far so good, but what about her attitude towards the proposition that she’s on State Street? She has enough evidence for that proposition that her credence in it should be rather high. And no practical issues turn on whether she is on State. So she believes she is on State, right?\nNot so fast! Believing that she’s on State has more connections to her cognitive system than just producing actions. Note in particular that street signs are hardly basic epistemic sources. They are the kind of evidence we should be ‘conservative’ about in the sense of Pryor (2004). We should only use them if we antecedently believe they are correct. So for Kate to believe she’s on State, she’d have to believe the street signs she can see are correct. If not, she’d incoherently be relying on a source she doesn’t trust, even though it is not a basic source.11 But if she believes the street signs are correct, she’d believe she was on Main, and that would lead to practical incoherence. So there’s no way to coherently add the belief that she’s on State Street to her stock of beliefs. So she doesn’t know, and can’t know, that she’s either on State or on Main. This is, in a roundabout way, due to the high stakes Kate faces.\n11 The caveats here about basic sources are to cancel any suggestion that Kate has to antecedently believe that any source is reliable before she uses it. As Pryor (2000) notes, that view is problematic. The view that we only get knowledge from a street sign if we antecedently have reason to trust it is not so implausible.Neta thinks that the best way for the interest-relative theorist to handle this case is to say that the high stakes associated with the proposition that Kate is on Main Street imply that certain methods of belief formation do not produce knowledge. And he argues, plausibly, that such a restriction will lead to implausibly sceptical results. But that’s not the only way for the interest-relative theorist to go. What they could, and I think should, say is that Kate can’t know she’s on State Street because the only grounds for that belief are intimately connected to a proposition that, in virtue of her interests, she needs very large amounts of evidence to believe.\n\n\n6 Non-Consequentialist Cases\nNone of the replies yet have leaned heavily on the last of the three points from the introduction, the fact that IRI is an existential claim. This reply will make heavy use of that fact.\nIf an agent is merely trying to get the best outcome for themselves, then it makes sense to represent them as a utility maximiser. But when agents have to make decisions that might involve them causing harm to others if certain propositions turn out to be true, then I think it is not so clear that orthodox decision theory is the appropriate way to model the agents. That’s relevant to cases like this one, which Jessica Brown has argued are problematic for the epistemological theories John Hawthorne and Jason Stanley have recently been defending.12\n12 The target here is not directly the interest-relativity of their theories, but more general principles about the role of knowledge in action and assertion. But it’s important to see how IRI handles the cases that Brown discusses, since these cases are among the strongest challenges that have been raised to IRI.\nA student is spending the day shadowing a surgeon. In the morning he observes her in clinic examining patient A who has a diseased left kidney. The decision is taken to remove it that afternoon. Later, the student observes the surgeon in theatre where patient A is lying anaesthetised on the operating table. The operation hasn’t started as the surgeon is consulting the patient’s notes. The student is puzzled and asks one of the nurses what’s going on:\nStudent: I don’t understand. Why is she looking at the patient’s records? She was in clinic with the patient this morning. Doesn’t she even know which kidney it is?\nNurse: Of course, she knows which kidney it is. But, imagine what it would be like if she removed the wrong kidney. She shouldn’t operate before checking the patient’s records. (Brown 2008, 1144–45)\n\nIt is tempting, but I think mistaken, to represent the payoff table associated with the surgeon’s choice as follows. Let Left mean the left kidney is diseased, and Right mean the right kidney is diseased.\n\n\n\n\n\nLeft\nRight\n\n\nRemove left kidney\n\\(1\\)\n\\(-1\\)\n\n\nRemove right kidney\n\\(-1\\)\n\\(1\\)\n\n\nCheck notes\n\\(1-\\varepsilon\\)\n\\(1-\\varepsilon\\)\n\n\n\n\nHere \\(\\varepsilon\\) is the trivial but non-zero cost of checking the chart. Given this table, we might reason that since the surgeon knows that she’s in the left column, and removing the left kidney is the best option in that column, she should remove the left kidney rather than checking the notes.\nBut that reasoning assumes that the surgeon does not have any obligations over and above her duty to maximise expected utility. And that’s very implausible, since consequentialism is a fairly implausible theory of medical ethics.13\n13 I’m not saying that consequentialism is wrong as a theory of medical ethics. But if it is right, so many intuitions about medical ethics are going to be mistaken that such intuitions have no evidential force. And Brown’s argument relies on intuitions about this case having evidential value. So I think for her argument to work, we have to suppose non-consequentialism about medical ethics.It’s not clear exactly what obligation the surgeon has. Perhaps it is an obligation to not just know which kidney to remove, but to know this on the basis of evidence she has obtained while in the operating theatre. Or perhaps it is an obligation to make her belief about which kidney to remove as sensitive as possible to various possible scenarios. Before she checked the chart, this counterfactual was false: Had she misremembered which kidney was to be removed, she would have a true belief about which kidney was to be removed. Checking the chart makes that counterfactual true, and so makes her belief that the left kidney is to be removed a little more sensitive to counterfactual possibilities.\nHowever we spell out the obligation, it is plausible given what the nurse says that the surgeon has some such obligation. And it is plausible that the ‘cost’ of violating this obligation, call it \\(\\delta\\), is greater than the cost of checking the notes. So here is the decision table the surgeon faces.\n\n\n\n\n\nLeft\nRight\n\n\nRemove left kidney\n\\(1-\\delta\\)\n\\(-1-\\delta\\)\n\n\nRemove right kidney\n\\(-1-\\delta\\)\n\\(1-\\delta\\)\n\n\nCheck notes\n\\(1-\\varepsilon\\)\n\\(1-\\varepsilon\\)\n\n\n\n\nAnd it isn’t surprising, or a problem for an interest-relative theory of knowledge, that the surgeon should check the notes, even if she believes and knows that the left kidney is the diseased one. This is not to say that the surgeon does know that the left kidney is diseased, just that the version of IRI being defended here is neutral on that question.\nThere is a very general point here. It suffices to derive IRI that we defend principles like the following:\n\nWhenever maximising expected value is called for, one should maximise expected value conditional on everything one knows.\nMaximising expected value is called for often enough that there exist the kinds of pairs of cases IRI claims exist. That’s because in some cases, changing the options facing an agent will make it the case that which live option is best differs from which live option is best given \\(p\\), even though the agent antecedently knew \\(p\\).\n\nBut that doesn’t imply that maximising expected value is always called for. Especially in a medical case, it is hard to square an injunction like “Do No Harm!” with a view that one should maximise expected value, since maximising expected value requires treating harms and benefits symmetrically. What would be a problem for the version of IRI defended here was a case with the following four characteristics.\n\nMaximising expected value is called for in the case.\nConditional on \\(p\\), the action with the highest expected value is \\(\\varphi\\).\nIt would be wrong to do \\(\\varphi\\).\nThe agent knows \\(p\\).\n\nIt is tempting for the proponent of IRI to resist any attempted counterexample by claiming it is not really a case of knowledge. That might be the right thing to say in Brown’s case. But IRI defenders should remember that it is often a good move to deny that the first condition holds. Consequentialism is not an obviously correct theory of decision making in morally fraught situations; purported counterexamples that rely on it can therefore be resisted.\n\n\n\n\n\n\nReferences\n\nBlome-Tillmann, Michael. 2009. “Contextualism, Subject-Sensitive Invariantism, and the Interaction of ‘Knowledge’-Ascriptions with Modal and Temporal Operators.” Philosophy and Phenomenological Research 79 (2): 315–31. https://doi.org/10.1111/j.1933-1592.2009.00280.x.\n\n\nBrown, Jessica. 2008. “Knowledge and Practical Reason.” Philosophy Compass 3 (6): 1135–52. https://doi.org/10.1111/j.1747-9991.2008.00176.x.\n\n\nFantl, Jeremy, and Matthew McGrath. 2002. “Evidence, Pragmatics, and Justification.” Philosophical Review 111: 67–94. https://doi.org/10.2307/3182570.\n\n\n———. 2009. Knowledge in an Uncertain World. Oxford: Oxford University Press.\n\n\nFeltz, Adam, and Chris Zarpentine. 2010. “Do You Know More When It Matters Less?” Philosophical Psychology 23 (5): 683–706. https://doi.org/10.1080/09515089.2010.514572.\n\n\nHam, Sandra A., Sarah Martin, and Harold W. Kohl III. 2008. “Changes in the Percentage of Students Who Walk or Bike to School-United States, 1969 and 2001.” Journal of Physical Activity and Health 5 (2): 205–15. https://doi.org/10.1123/jpah.5.2.205.\n\n\nHarman, Gilbert. 1973. Thought. Princeton: Princeton University Press.\n\n\nHawthorne, John. 2004. Knowledge and Lotteries. Oxford: Oxford University Press.\n\n\nHawthorne, John, and Jason Stanley. 2008. “Knowledge and Action.” Journal of Philosophy 105 (10): 571–90. https://doi.org/10.5840/jphil20081051022.\n\n\nMay, Joshua, Walter Sinnott-Armstrong, Jay G. Hull, and Aaron Zimmerman. 2010. “Practical Interests, Relevant Alternatives, and Knowledge Attributions: An Empirical Study.” Review of Philosophy and Psychology 1 (2): 265–73. https://doi.org/10.1007/s13164-009-0014-3.\n\n\nNeta, Ram. 2007. “Anti-Intellectualism and the Knowledge-Action Principle.” Philosophy and Phenomenological Research 75 (1): 180–87. https://doi.org/10.1111/j.1933-1592.2007.00069.x.\n\n\nPryor, James. 2000. “The Skeptic and the Dogmatist.” Noûs 34 (4): 517–49. https://doi.org/10.1111/0029-4624.00277.\n\n\n———. 2004. “What’s Wrong with Moore’s Argument?” Philosophical Issues 14 (1): 349–78. https://doi.org/10.1111/j.1533-6077.2004.00034.x.\n\n\nRussell, Gillian, and John M. Doris. 2009. “Knowledge by Indifference.” Australasian Journal of Philosophy 86 (3): 429–37. https://doi.org/10.1080/00048400802001996.\n\n\nStanley, Jason. 2005. Knowledge and Practical Interests. Oxford University Press.\n\n\nWeatherson, Brian. 2005. “Can We Do Without Pragmatic Encroachment?” Philosophical Perspectives 19 (1): 417–43. https://doi.org/10.1111/j.1520-8583.2005.00068.x.\n\nCitationBibTeX citation:@article{weatherson2011,\n  author = {Weatherson, Brian},\n  title = {Defending {Interest} {Relative} {Invariantism}},\n  journal = {Logos and Episteme},\n  volume = {2},\n  pages = {591-609},\n  date = {2011},\n  doi = {10.5840/logos-episteme2011248},\n  langid = {en}\n}"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/eigp/index.html",
    "href": "posts/eigp/index.html",
    "title": "Explanation, Idealisation and the Goldilocks Problem",
    "section": "",
    "text": "Michael Strevens’s book Depth is a great achievement.1 To say anything interesting, useful and true about explanation requires taking on fundamental issues in the metaphysics and epistemology of science. So this book not only tells us a lot about scientific explanation, it has a lot to say about causation, lawhood, probability and the relation between the physical and the special sciences. It should be read by anyone interested in any of those questions, which includes presumably the vast majority of readers of this journal.\n1 All page references, unless otherwise noted, are to Strevens (2008).\nImage from Creative Commons.\n\nOne of its many virtues is that it lets us see more clearly what questions about explanation, causation, lawhood and so on need answering, and frames those questions in perspicuous ways. I’m going to focus on one of these questions, what I’ll call the Goldilocks problem. As it turns out, I’m not going to agree with all the details of Strevens’s answer to this problem, though I suspect that something like his answer is right. At least, I hope something like his answer is right; if it isn’t, I’m not sure where else we can look.\n\n1 The Goldilocks Problem\nSam has engaged in some unhealthy activity, and is now profusely vomiting in the bathroom. Here are three things that are true of the buildup to this unfortunate turn of events.\n\nSam either ate a carton of raw eggs, or drank a bottle of vodka.\nSam ate a carton of raw eggs.\nSam ate a carton of raw eggs that were bought at midday.\n\nAll three of these claims are interesting things to know about the buildup to the vomiting. But intuitively, or at least according to my intuitions, (2) is the best explanation of the lot. That’s because intuitively, (1) is too weak, and (3) is too strong, while (2) is just right.\nLet’s assume for now these intuitions are correct. We then have the puzzle of explaining why explanations of moderate strength, like (2), are strictly better than either weaker explanations, like (1), or stronger explanations, like (3). Put another way, we have to explain what makes (2) ‘just right’. Call this the Goldilocks problem.2\n2 Strevens calls the problem of how to explain why (2) is a better explanation than (1) ‘the disjunction problem’. Given that the problem arises in the context of a theory that aims to explain why (2) is better than (3), I think the disjunction problem and the Goldilocks problem are not particularly distinct.If the Goldilocks problem was merely a matter of first-pass intuitions, then perhaps the right way to solve it would be to explain why we have quirky intuitons about explanations. But I think we can see that it turns on deeper features than that.\nOn the one hand, we want explanations, particularly of single events, to locate those events in the causal structure of the world. That’s why we’re pushed towards saying that (3) is the best explanation of Sam’s current activity. Indeed, in his defence of a causal theory of explanation, David Lewis (1986) says that (3) is really the best explanation, though we might prefer to use, or to offer, (2) for pragmatic reasons.\nOn the other hand, we want explanations that unify disparate phenomena. If we see that an event is just one instance of the right kind of pattern, it feels more explicable. That pushes us towards explanations that encompass more and more actual and possible outcomes. This pushes us away from (3) as an explanation, and towards (2), but also away from (2) and towards (1). After all, if we accepted (1) as the best explanation for what’s going on, we would have an explanation that encompasses even more events.3\n3 For more on explanation as unification, see Friedman (1974) and, especially, Kitcher (1989).We can also get pushed towards (1) as being the ideal explanation by considering ways in which (2) is a better explanation than (3). There is a sense in which some of the information in (3) is redundant. No matter when Sam bought the eggs, the vomiting would have resulted given that they were eaten. Here is one principle we might draw from that. If \\(E^\\prime\\) is logically weaker than \\(E\\), and the outcome \\(O\\) would have happened even if \\(E^\\prime\\) had happened but \\(E\\) had not, then \\(E^\\prime\\) is a better explanation than \\(E\\). This will get the right result that (2) is a better explanation than (3). But it will get the wrong result that (1) is a better explanation than (2).\nTo some extent, the observations of the last three paragraphs point to a solution to the Goldilocks problem. There are virtues that (2) has over (3), in not being too specific, and over (1), in being specific enough for the task at hand. But as a moment’s reflection will show, attempting to turn these ideas into a theory is not exactly trivial. It’s much too easy to come up with principles that end up implying that (2) has all the vices of (1) and (3), and is really worse than each, rather than better. (The attempt to use counterfactuals to give a sufficient condition for superiority of explanation in the last paragraph is illustrative of how we might end up theorising this way.) Having a theory of explanation that avoids these traps is both desirable, and difficult.\n\n\n2 Idealisations in Explanation\nMuch more familiar than the Goldilocks problem is the problem of accounting for the role of idealisations in explanation. Explanations seem, after all, factive. The sentence p because q just entails both \\(p\\) and \\(q\\). And yet explanations involving idealisations seem to be false. Here’s an illustrative example.\nOn a busy suburban corner, there are four gas stations.4 Although the price for which they offer gas fluctuates a lot from day to day, the four usually have the same price, even to the nearest tenth of a cent. Why might that be? One might suspect collusion, but we’ll stipulate that this is a real free market, and the stations are actually competing, not colluding. Another might be that the stations are using ‘cost-plus’ pricing. But in fact, given the many and varied ways in which the stations (or their corporate parents) have used derivatives to hedge their costs, the four actually face very different input costs. And in any case, a ‘cost-plus’ theory can’t explain the fluctuation of prices.\n4 ‘Petrol stations’ if that fits your dialect better.The real explanation is relatively simple. If any station charges a higher price than its rivals, then no one will come to that station. And that’s something the station desparately wants to avoid. So no station charges a higher price than the others. And that means they all charge the same price.\nNow why, might we ask, is it that if any station charges a higher price than its rivals, then no one will come to that station? There’s a simple explanation here too. First, customers know the prices at each of the four stations, or at least if they don’t the cost of getting those prices is zero. Second, the customers are each utility-maximisers who prefer having more money to less. And third, the goods that the stations are offering are perfect substitutes. Those three premises entail that a station with a higher price than the others will have zero customers.\nBut just wait! Precisely none of those three premises are perfectly true. There is some cost in figuring out the prices at each. If there weren’t, we couldn’t explain why stations put up such big signs advertising their prices. The point of those signs is to reduce the cost of acquiring price information. And, as philosophers of economics never tire of pointing out, customers aren’t perfect utility maximisers. And, finally, the goods aren’t perfect substitutes. The stations might have different queue lengths, or reputations for quality, or associations with firms that pollute the Gulf of Mexico, and so on.5\n5 Given the last point, we’d expect that after the BP disaster in the Gulf of Mexico, stations weren’t too worried about being undercut on price by a nearby BP station.Strevens has a nice story to tell here about what we should say about the explanations like the one I just offered. When the explainer says that, for instance, the cost of acquiring price information is zero, we should interpret them charitably, and loosely. We should apply the same principles as we apply when interpreting someone’s claim that Brazil is triangular. The truth-conditional content of the claim is not that the cost of acquiring price information is precisely zero. Rather, it is that the cost is in a not-too-large range that includes zero. How large is ‘not-too-large’? That depends on what the person is trying to explain? If they are trying to explain the size of gas station signage, it will be a small range; if they are trying to explain the dynamics of gas station pricing, it will be somewhat larger.\nStrevens’s theory here is hermeneutic, not revolutionary. He doesn’t say that we should replace the explanations that economists give, which are full of freely available information, perfectly substitutable goods, utility maximising agents and so on, with explanations that involve low cost information, highly substitutable goods, and agents who usually choose high utility outcomes. Rather, he is saying that the explanations those economists give already involve low cost (but not necessarily free) information, highly (but not necessarily perfectly) substitutable goods, and so on. This seems entirely right to me. Well known results showing the limitations of human rationality simply don’t undermine the stories like the one I told explaining the correlation between prices at nearby gas stations, even though a cursory glance at those explanations might appear to involve appeal to perfectly rational buyers.\nNow what happens when we interpret an explanation as saying not that some value is zero, but that it is near zero? Well, we get an instance of the Goldilocks problem back. We could imagine an explanation of the gas station prices that includes the exact value of the cost of acquiring information about each station’s price. That explanation would be more precise than the explanation that merely says the cost of acquiring price information is low. But despite that increase in precision, it would be a worse explanation, and it would be worse for just the same reason that (3) is a worse explanation than (2). (Of course, we haven’t yet said just what that reason is!)\nSo puzzles about idealisations in explanation reduce, given Strevens’s nice hermeneutic suggestion, to the Goldilocks problem. That raises the interest in solving the Goldilocks problem, so let’s turn to Strevens’s own solution to it.\n\n\n3 The Kairetic Theory of Explanation\nI’m going to have to simplify a lot in sketching Strevens’s theory of explanation, but I hope the following offers a not-too-inaccurate picture. For Strevens, explanations of individual events are causal models. (Explanations of regularities are basically explanations of the events that make up the regularity.) A causal model is a valid argument, whose premises are all true, and whose conclusion is the event to be explained, such that the conclusion can be derived from the premises using (more-or-less) nothing but modus ponens, with every such step, from \\(C\\) and \\(C \\rightarrow E\\) to \\(E\\), being such that in reality \\(C\\) caused \\(E\\). When an argument has this property, Strevens says that the premises causally entail the conclusion. In practice, these models typically have three (kinds of) premises: a specification of initial conditions, a law (or set of laws) linking those conditions to the eventual result, and a ‘no defeaters’ condition, since the laws in question will usually not guarantee any outcome.6\n6 For instance, the gravitational law says that there is a downward force on my coffee cup, but it doesn’t guarantee that it moves downwards. And, indeed, there are currently sufficiently many forces acting on it that it remains suspended 80 feet above the ground. The ‘no defeaters’ clause is intended to rule out such mischief.There will usually be many such explanations. For instance, we could start with either (1), (2) or (3), add an appropriate law and a no defeaters condition, and causally derive that Sam is nauseous. Strevens then puts two extra conditions on causal models, one of which provides a ranking of explanations, the other of which is a necessary condition for an explanation being satisfactory.\nThe ranking condition is that the weaker the set of initial conditions are, the better the explanation is. If we weaken the initial conditions, but can still causally derive the explanandum, then the stronger set of initial conditions contained redundant information and better explanations excise redundant information. The condition that some information is necessary for the causal entailment to go through is what Strevens calls ‘the kairetic condition’ on explanatory relevance, and that in turn is why the theory is called a kairetic theory of explanation.\nOnce we loosen the specification of the initial conditions, a range of different possible causal pathways are compatible with the argument being a causal entailment. The necessary condition Strevens adds is that these possible pathways must be coherent. And he defines cohesion as “dynamic contiguity” (105). That is, if we situate all the possible causal chains in a possible space, an argument satisfies the cohesion condition if the set of chains consistent with the argument’s premises causally entailing the conclusion form a contiguous set.\nNote that contiguity is not that closely related to a similarity condition. The set of all possible causal pathways is perfectly contiguous, although its members are severely dissimilar. On the other hand, some small sets of causal pathways are not contiguous. So consider (4) and (5) below. Arguably the set of worlds in which (4) is true is not contiguous – there is a disconnect between the worlds where Suzy throws and the worlds where Billy throws – while the set of worlds in which (5) is true is contiguous.\n\nEither Billy or Suzy threw a brick at the window at exactly \\(2\\pi\\) mph.\nSuzy threw a brick at the window at between 5 and 30 mph.\n\nAlthough the worlds where Suzy throws hard are very dissimilar from the worlds where Suzy throws softly, there is a chain of worlds connecting the two. And each member of the chain is very similar to the next member. That suffices for contiguity.\nIt’s important to what follows that Strevens takes contiguity here to be physical contiguity. That is, two worlds (or causal pathways) are contiguous iff they are contiguous from the perspective of fundamental physics. Contiguity is not meant to be something defined in terms of explanations, and nor is it meant to be contiguity in terms of properties of interest to the special sciences. This will be important for what follows.\nWe’re now in a position to see Strevens’s solution to the Goldilocks problem. The detail about when Sam bought the eggs is irrelevant to the conclusion that Sam is nauseous. As long as the eggs were bought, and eaten, Sam’s nausea will exist. Indeed, its existence will be guaranteed by a causal law, given the appropriate ‘no defeaters’ condition. So the kairetic condition says we improve the explanation of Sam’s nausea by dropping the time at which the eggs were bought.7 Now if we start with (1), there will still be a causal law that lets us derive Sam’s nausea. But the space of causal pathways consistent with the argument we generate will not be contiguous. It will contain the worlds where the eggs cause nausea, and the worlds where the vodka causes nausea, and nothing in between. So it isn’t an eligible explanation. So the kairetic account predicts, correctly, that the best explanation of Sam’s nausea starts with (2). QED.\n7 Of course, if we wanted to explain the time of Sam’s nausea, and not just its existence, the extra details in (3) might matter.\n\n4 Equilibrium Explanations in Economics\nBut there’s a difficulty looming for this nice theory. It isn’t at all clear how we’re going to generalise it to cover explanations in the social sciences. It’s perhaps easiest to see this if we look at an example. This example is originally from Hendricks and Porter (1988), though much of my discussion of it leans heavily on the exposition in Sutton (2000, 47–56).\nThe fact to be explained concerns the amount that oil exploration firms pay for, and eventually earn from, licences to drill in various tracts of the Gulf of Mexico. At various times, the government opens up the rights to drill on new tracts of sea bed. Firms are allowed to make a single bid for the rights to these tracts, and the highest bid wins. Some firms that bid have, prior to the opening of the new tract, drilling rights to some adjacent tract, and some do not. Having drilling rights to an adjacted tract is useful, because oil deposits tend not to follow the sharp lines on government surveyors’ maps. If you have already been working on an area adjacent to the one being auctioned, you have a pretty good idea how much oil that tract contains. If you don’t, then you have to make a guess based on more general features of that region of the Gulf. The stylised fact to be explained is that firms that bid on tracts adjacent to their existing tracts made a large profit, on average, while firms that bid on non-adjacent tracts made no net profit. (In fact they averaged a small loss, but the amount is close enough to zero that it’s worth treating their net returns as zero.) Why might this be?\nThe explanation that Hendricks and Porter offer starts with the following game, from Wilson (1967). Assume that two players, \\(A\\) and \\(B\\), are bidding on a good of some value in \\([0, 1]\\). \\(A\\) knows exactly how valuable the good is - call this value \\(x\\). \\(B\\) has no idea how valuable the good is; her credences about its possible value are distributed evenly over \\([0, 1]\\). Both \\(A\\) and \\(B\\) know these facts about each other. What should each of them do?\nStandard game theory has an answer. The game has a single Nash equilibrium. \\(A\\) bids \\(\\frac{x}{2}\\), and \\(B\\) plays a mixed strategy, randomly choosing a bid from \\([0, \\frac{1}{2}]\\). If each of them play these strategies, then \\(A\\) has an expected return of \\(\\frac{x^2}{2}\\), and \\(B\\) has an expected return of 0. Moreover, given each of them is playing those strategies, the other party cannot do better by changing their strategy. (That’s just what it means for the strategies to form a Nash equilibrium.)\nNow Hendricks and Porter go on to suggest that the drilling rights auctions are more or less like these games, with \\(A\\)’s role being filled by the firm with an adjacent tract, and \\(B\\)’s role by the firm with no adjacent tract.8 If we apply that model, we get plausible results for how much profit the two kinds of firms should earn, including a nice story about why the non-adjacent firms earn no profit. Indeed, we even get a satisfactory (at least to economists) story about why firms without adjacent tracts continue to bid even though they earn no net profit by doing so. If they didn’t bid, then firms with adjacent tracts could win the bidding by bidding a penny, and then it would be valuable to bid. In other words, the only equilibrium solution requires them to bid, even though they get no gain from it.\n8 There are a lot of technical details I’m suppressing here, many of which Hendricks and Porter take into account, and many of which they rightly suppress. Sutton characterises Hendricks and Porter’s model as having considerably fewer added complications to the simple game Wilson develops than Hendricks and Porter themselves do. For instance, Sutton suppreses, while Hendricks and Porter explicitly consider, the possible efficiency gains derivable from owning adjacent tracts, but this only makes a small difference to the final result. On the kairetic theory of explanation, these simplifications actually improve the explanation considerably.There is obviously a bit of work to do to show that this game provides a good model of Gulf of Mexico auctions. For one thing, we have to show that we can treat the auction as having effectively two players. Hendricks and Porter suggest that the behaviour of firms with adjacent tracts is sufficiently cooperative that this is a legitimate idealisation. There are other idealisations too, all of which I think can be fit nicely into Strevens’s kairetic story. We have to treat the firms with adjacent tracts as knowing the value of the tract, when really they’ll only know the approximate value. But it is plausible that treating their ignorance as being zero-valued, i.e., treating their knowledge as being perfect, makes no difference to what we need to explain. Similarly, it is not really true that the other firms have no idea how valuable the tracts are. But their knowledge levels are close enough to being represented by a flat probability distribution over the possible values of the tract that it doesn’t make a difference to this story to model their knowledge more precisely.\n(There is an interesting technical point here. Strevens focuses on cases where the idealisations involve giving some variable a “zero, infinite or some other extreme or default value” (318). In social sciences, one useful ‘default’ value is that the variable is represented by a flat probability function over some interval. This will rarely be exactly right; whether we interpret the probability function metaphysically or epistemically the ‘right’ function will presumably have some bumps or kinks in it. But it is an acceptable idealisation.)\nSo far so good. We started with an interesting set of facts, we found a nice mathematical model that has the facts as a consequence, and we argued (or at least hinted at how one could argue) that the deviation between the model and the facts was irrelevant to the outcome to be explained. So we’ve arguably fit a widely accepted economic explanation into the kairetic framework.\nBut once we start looking at the details, some problems start to emerge. Remember that on the kairetic account, explanations must be causal derivations. It doesn’t look at first like we’ve got any causation in the economic explanation. But I think that’s wrong. After all, there’s a reason why the two types of firms bid they way they do. The structure of the auction, along with other facts, causes them to make these bids. It isn’t something you’ll see highlighted in Hendricks and Porter, but it’s arguable their story is a causal story.\nThe problem is the ‘other facts’ you need to cite to complete this causal explanation. Those don’t seem to be sufficiently ‘cohesive’ for Strevens’s story to hold up. What we know is that if the actors follow equilibrium strategies, then we’ll get the results that are actually observed. But why should we think that actors will do just that? There are several possible reasons; too many reasons it might seem for the kairetic theory to work.\nPossibly the actors are perfectly rational, and perfectly rational beings play Nash equilibrium strategies.9 Possibly the actors are worried about their strategies leaking out, and are maximising expected utility relative to that assumption.10 Possibly there are a number of actors playing other strategies, but they don’t tend to survive economically, and so the statistics are dominated by firms that do survive, and the survivors generally play equilibrium strategies.11 Possibly the firms are run by a lot of game theorists, and “game theory is an excellent way of predicting the behaviour of professional game theorists.”12 More likely, some combination of these four reasons, and even some others, is causally relevant to the establishment and maintenance of this equilibrium.\n9 The normative claim here, that perfectly rational beings play Nash equilibrium strategies, seems implausible to me for reasons similar to those set out by Stalnaker (1996, 1998, 1999).10 Note that maximising expected utility does not entail playing equilibrium strategies without some extra assumption about strategies leaking, since a mixed strategy can be part of a unique equilibrium, but can never be uniquely utility maximising.11 Philosophers tend to overstate how much economists rely on rationality assumptions. One of the attractions of game-theoretic explanations is that they don’t require all the agents to be perfectly rational. After all, game-theoretic explanations work well in evolutionary biology, and the players there are certainly not perfectly rational. For more on this point, and especially on how much work economists do to weaken rationality postulates, see Hahn (1996).12 The quote is from a blog post by Daniel Davies on October 8, 2010. See http://d-squareddigest.blogspot.com/2010/10/on-not-being-obliged-to-vote-for.html.And that is something that’s hard to fit into the kairetic framework. We can show how the background facts about the case (i.e., the risks and rewards facing the competing oil firms), and a general causal law (i.e., that firms tend to end up playing equilibrium strategies) entail the conclusions that various firms bid on newly released tracts despite having zero expected profit. The problem is that many distinct causal pathways are compatible with this loosely described causal structure, and these pathways are not ‘cohesive’. So the kairetic theory of explanation predicts that the explanation offered in Hendricks and Porter (1988) is not a good explanation of the observed behaviour in the auctions. That should worry anyone who either finds it intuitively plausible that it is a good explanation, or thinks that we should defer somewhat to the salient experts on what is a good explanation.\n\n\n5 Possible Responses\nI think these equilibrium explanations are a challenge to Strevens’s solution to the Goldilocks problem, and I think that’s a problem given the importance of solving the Goldilocks problem to the broader aims of the kairetic theory of explanation. But there are a number of ways Strevens could respond to this challenge. Indeed, we can see three responses already made in Depth. So I’ll end by noting why I don’t think those three responses work.\nFirst, it is true that some equilibrium explanations are cohesive in Strevens’s sense. Strevens discusses an example proposed by Elliot Sober (1983). Here is how Strevens describes the case.\n\nConsider a ball released at the inside lip of a basin. The ball rolls down into, then back and forth inside, the basin, eventually coming to rest at its lowest point. This will happen no matter what the ball’s release point. … Sober claims, quite rightly, that an equilibrium explanation … is the best explanation of the ball’s final resting place. (267-8)\n\nNow there are many ways in which the ball might have reached its equilibrium state. But note that these ways are all fairly similar to one another. The ways are, collectively, cohesive in just the sense needed for the kairetic theory.13 But this is surely an accident of the example. The ways in which agents reach a game-theoretic equilibrium are very different from one another, which makes that case rather unlike the case of a ball descending to the bottom of a basin. In short, while some equilibrium explanations will be suitably cohesive many, perhaps even most, will not.\n13 Actually, this sentence isn’t as obviously true as it seems. Strevens’s discussion of the case brings out some unexpected difficulties in accommodating Sober’s claim in the kairetic theory. But this doesn’t affect my point, which is that the case is relatively easy for the kairetic theory to accommodate.14 This might be reading too much into Strevens’s discussion. What he says about a related example is that the existence of communicative channels within firms is part of the ‘framework’ when making economic explanations. I don’t know whether he would extend this story to cover all means by which firms get to equilibrium.Second, sometimes we don’t want to fully explain why \\(p\\) is true, but merely why \\(p\\) is true rather than \\(q\\), or why \\(p\\) is true given that \\(r\\) is true. In these cases, Strevens says that we exploit ‘explanatory frameworks’ (149) which fix certain facts as given for the purposes of explanation. So we might take \\(p \\vee q\\), or \\(r\\), to simply be fixed background facts; part of the framework relative to which explanations are made. When a proposition is part of the framework, its presence in the derivation of the intended outcome does not contribute to incohesiveness (163). So if we say that, for instance, the fact that games like the tract auction end up at equilibrium is part of the framework, then the orthodox explanation of, say, why firms bid despite a zero expected profit, can work. In short, the story about why firms bid is incohesive, but the story about why firms bid given that firms play equilibrium strategies is cohesive, and it is the latter that economists are trying to explain.14\nNow perhaps that’s true of what some economists are doing some of the time. But it seems too defeatist to me. Part of the appeal of game theoretic explanations is that they are supposed to explain why we get to, and stay at, equilibrium. I don’t think a practicing economist would say that they are merely presupposing that players in a game reach equilibrium, as opposed to offering a theory where that fact falls out as a nice explanandum. It’s true that economists do leave some things in the framework. They generally assume that economic actors are agents, while leaving the story about how agency might be physically realised to other disciplines. But it seems wrong to me to say that all the facts about how equilibrium is established and preserved are simply framework questions.\nFinally, Strevens notes that we can often refer to causal processes in explanations without being able to fully describe them. If someone asks why the temperature in this room stays so even while the temperature in other rooms fluctuates, I can explain the stability by saying that a thermostat regulates the temperature. Now at first this might look like a very incohesive explanation. There are many ways that a thermostat might work, and they don’t form anything like a coherent set. But perhaps that’s the wrong way to take my explanation. We could take the explanation as referring to the particular thermostat that is present, and the particular way in which it regulates the temperature. That explanation will be very cohesive; indeed, the real worry is that it is too precise. Of course, I might not be able to describe the process by which the thermostat regulates temperature. But this is no barrier to my being able to refer to it, any more than ignorance of chemistry is a barrier to my being able to refer to H\\(_2\\)O.\nCould this help with the tract auction we are discussing? At first glance it seems like it might. Perhaps the explanation can simply refer to the means by which a particular firm ends up playing an equilibrium strategy, even if it cannot describe that means. But the second glance is more troubling. Remember that what we’re trying to explain here is an average, not a particular firm’s behaviour. And it is meant to be consistent with the explanations that different firms get to equilibrium in very different ways. So we can’t really just refer to those different methods; we can only describe what they have in common. And that leaves us back with an incohesive explanation. Indeed, Strevens notes this point in a similar context when he says that “in aggregative and regularity explanation … there is a real risk” that we won’t pick out a cohesive causal mechanism. (154)\nSo I’m left thinking that we need somehow to supplement the story Strevens offers to make it plausible as an account of explanation in the special sciences. The kind of equilibrium explanations game theorists offer of economic outcomes are at least sometimes good explanations. But what makes them good is not the cohesiveness of their underlying physical mechanisms. It is, at least intuitively, the cohesiveness of the explanations from the perspective of the special science in question. If that intuition is right, we theorists still have work to do in characterising this notion of cohesiveness.\n\n\n\n\n\n\nReferences\n\nFriedman, Michael. 1974. “Explanation and Scientific Understanding.” Journal of Philosophy 71 (1): 5–19. https://doi.org/10.2307/2024924.\n\n\nHahn, Frank. 1996. “Rerum Cognoscere Causas.” Economics and Philosophy 12 (2): 183–95. https://doi.org/10.1017/S0266267100004156.\n\n\nHendricks, Kenneth, and Robert H. Porter. 1988. “An Empirical Study of an Auction with Asymmetric Information.” The American Economic Review 78 (5): 865–83.\n\n\nKitcher, Philip. 1989. “Explanatory Unification and the Causal Structure of the World.” In Scientific Explanation, edited by Philip Kitcher and Wesley Salmon, 13:410–505. Minnesota Studies in Philosophy of Science. Minneapolis: University of Minnesota Press.\n\n\nLewis, David. 1986. “Causal Explanation.” In Philosophical Papers, II:214–40. Oxford: Oxford University Press.\n\n\nSober, Elliot. 1983. “Equilibrium Explanation.” Philosophical Studies 43 (2): 201–10. https://doi.org/10.1007/BF00372383.\n\n\nStalnaker, Robert. 1996. “Knowledge, Belief and Counterfactual Reasoning in Games.” Economics and Philosophy 12: 133–63. https://doi.org/10.1017/S0266267100004132.\n\n\n———. 1998. “Belief Revision in Games: Forward and Backward Induction.” Mathematical Social Sciences 36 (1): 31–56. https://doi.org/10.1016/S0165-4896(98)00007-9.\n\n\n———. 1999. “Extensive and Strategic Forms: Games and Models for Games.” Research in Economics 53 (3): 293–319. https://doi.org/10.1006/reec.1999.0200.\n\n\nStrevens, Michael. 2008. Depth: An Account of Scientific Explanations. Cambridge, MA: Harvard University Press.\n\n\nSutton, John. 2000. Marshall’s Tendencies: What Can Economists Know? Cambridge, MA: MIT Press.\n\n\nWilson, Robert B. 1967. “Competitive Bidding with Asymmetric Information.” Management Science 13 (11): 816–20. https://doi.org/10.1287/mnsc.13.11.816.\n\nCitationBibTeX citation:@article{weatherson2012,\n  author = {Weatherson, Brian},\n  title = {Explanation, {Idealisation} and the {Goldilocks} {Problem}},\n  journal = {Philosophy and Phenomenological Research},\n  volume = {84},\n  number = {2},\n  pages = {461-473},\n  date = {2012-03},\n  doi = {10.1111/j.1933-1592.2011.00574.x},\n  langid = {en}\n}"
  },
  {
    "objectID": "posts/humsup/index.html",
    "href": "posts/humsup/index.html",
    "title": "Humean Supervenience",
    "section": "",
    "text": "1 What is Humean Supervenience?\nAs with many aspects of David Lewis’s work, it is hard to provide a better summary of his views than he provided himself. So the following introduction to what the Humean Supervenience view is will follow the opening pages of Lewis (1994a) extremely closely. But for those readers who haven’t read that paper, here’s the nickel version.\nHumean Supervenience is the conjunction of three theses.\n\nTruth supervenes on being (Bigelow 1988). That is, all the facts about a world supervene on facts about which individuals instantiate which fundamental properties and relations.\nAnti-haeccaetism. All the facts about a world supervene on the distribution of qualitative properties and relations; rearranging which properties hang on which ‘hooks’ doesn’t change any facts.\nSpatio-temporalism. The only fundamental relations that are actually instantiated are spatio-temporal, and all fundamental properties are properties of points or point-sized occupants of points.\n\nThe first clause is a core part of Lewis’s metaphysics. It is part of what it is for some properties and relations to be fundamental that they characterize the world. Indeed, Lewis thinks something stronger, namely that the fundamental properties and relations characterize the world without redundancy (Lewis 1986a, 60). This probably isn’t true, for a reason noted in Sider (1993). Consider the relations earlier than and later than. If these are both fundamental, then there is some redundancy in the characterisation of the world in terms of fundamental properties and relations. But there is no reason to believe that one is fundamental and the other isn’t. And it is hard to see how we could give a complete characterisation of the world without either of these relations. So we’ll drop the claim that the fundamental properties relations characterise the world without redundancy, and stick to the weaker claim, namely that the fundamental properties and relations characterize the world completely.\nThe second clause is related to Lewis’s counterpart theory. Consider what it would be like for anti-haeccaetism to fail. There would have to be two worlds, with the same distribution of qualitative properties, but with different facts obtaining in each. These facts would have to be non-qualitative facts, presumably facts about which individual plays which role. So perhaps, to use a well-known example, there could be a world in which everything is qualitatively as it is in this world, but in which Barack Obama plays the Julius Caeser role, and vice versa. So Obama conquers Gaul and crosses the Rubicon, Caeser is born in Hawai’i and becomes President of the United States. But what could make it the case that the Gaul-conqueror in that world is really Obama’s counterpart, and not Caeser’s? Nothing qualitative, and nothing else it seems is available. So this pseudo-possibility is not really a possibility. And so on for all other counterexamples to anti-haeccaetism.\nThe third clause is the most striking. It says there are no fundamental relations beyond the spatio-temporal, or fundamental properties of extended objects. If we assume that ‘properties’ of objects with parts are really relations between the parts, and anything extended has proper parts, then the second clause reduces to the first. I think it isn’t unfair to read Lewis as holding both those theses.\nSince for Lewis the fundamental qualities are all intrinsic, the upshot is that the world is characterized by a spatio-temporal distribution of intrinsic qualities. As Lewis acknowledged, this was considerably more plausible given older views about the nature of physics than it is now. We’ll return to this point at great length below. But for now the key point to see the kind of picture Humean Supervenience offers. The world is like a giant video monitor. The facts about a monitor’s appearance supervene, plausibly, on intrinsic qualities of the pixels, plus facts about the spatial arrangement of the pixels. The world is 4-dimensional, not 2-dimensional like the monitor, but the underlying picture is the same.\n\n\n2 Supervenience\nGiven the name Humean Supervenience  you might expect it to be possible to state Humean Supervenience as a supervenience thesis. But this turns out to be hard to do. Here is one attempt at stating Humean Supervenience as a supervenience thesis that is happily clear, and unhappily false.\n\nStrong Modal Humean Supervenience\n\nFor any two worlds where the spatio-temporal distribution of fundamental qualities is the same, the contingent facts are the same.\n\n\nBut Humean Supervenience does not make a claim this strong. It is consistent with Humean Supervenience that there could be fundamental non-spatio-temporal relations. The only thing Humean Supervenience claims is that no such relations are instantiated. In a pair of possible worlds where there are such relations, and the relations vary but the arrangement of qualities is the same, Strong Modal Humean Supervenience will fail. In the Introduction to Lewis (1986b), he suggested the following weaker version.\n\nLocal Modal Humean Supervenience\n\nFor any two worlds at which no alien properties or relations are instantiated, if the spatio-temporal distribution of fundamental qualities is the same at each world, the contingent facts are also the same.\n\n\nAn alien property(/relation) is a fundamental property(/relation) that is not actually instantiated. So this version of Humean Supervenience says that to get a difference between two worlds, you have to either have a change in the spatio-temporal arrangement of qualities, or the instantiation of actually uninstantiated fundamental properties or relations.\nBut Lewis eventually decided that wouldn’t do either. In response to Haslanger (1994), he conceded that enduring objects would generate counterexamples to Local Modal Humean Supervenience even if there were no alien properties or relations. So he fell back to the following, somewhat vaguely stated, thesis. (See Lewis (1994a) for the concession, and Hall (2010) for an argument that he should not have conceded this to Haslanger.)\n\nFamiliar Modal Humean Supervenience\n\nIn any two “worlds like ours”, if the spatio-temporal distribution of fundamental qualities is the same at each world, the contingent facts are also the same (Lewis 1994a, 475).\n\n\nWhat’s a “world like ours’? It isn’t, I fear, entirely clear. But this doesn’t matter for the precise statement of Humean Supervenience. The three theses in section 1 are clear enough, and state what Humean Supervenience is. The only difficulty is in stating it as a supervenience thesis.\n\n\n3 What is Perfect Naturalness?\nThat definintion does, however, require that we understand what it is for some properties and relations to be fundamental, or, as Lewis put it following his discussion in Lewis (1983), perfectly natural. The perfectly natural properties and relations play a number of interconnected roles in Lewis’s metaphysics and his broader philosophy.\nMost generally, they characterise the difference between real change and ‘Cambridge change’, and the related difference between real similarity, and mere sharing of grue-like attributes. This somewhat loose idea is turned, in Plurality, into a definition of duplication.\n\n…two things are duplicates iff (1) they have exactly the same perfectly natural properties, and (2) their parts can be put into correspondence in such a way that corresponding parts have exactly the same perfectly natural properties, and stand in the same perfectly natural relations. (Lewis 1986a, 61)\n\nThe intrinsic properties are then defined as those that are shared between any two (possible) duplicates. So, as noted above, Humean Supervenience says that the spatio-temporal distribution of intrinsic features of points characterises worlds like ours.\nI’ve gone back and forth between describing these properties as fundamental and describing them as perfectly natural. And that’s because for Lewis, the perfectly natural properties are in a key sense fundamental. For reasons to do with the nature of vectorial properties, I think this is probably wrong (Weatherson 2006). That is, we need to hold that some derivative properties are perfectly natural in order to get the definition of intrinsicness terms of perfect naturalness to work. But for Lewis, the perfectly natural properties and relations are all fundamental.\nPart of what Lewis means by saying that some properties are fundamental is that all the facts about the world supervene on the distribution. (This is Bigelow’s thesis that truth supervenes on being.) But I think he also means something stronger. The non-fundamental facts don’t merely supervene on the fundamental facts; those non-fundamental facts are true because the fundamental facts are true, and in virtue of the truth of the fundamental facts.\nThe perfectly natural properties play many other roles in Lewis’s philosophy besides these two. They play a key role in the theory of laws, for instance. They are a key part of Lewis’s solution to the New Riddle of Induction (Goodman 1955). And they play an important role in Lewis’s theory of content, though just exactly what that role is is a matter of some dispute. (See Sider (2001) and Weatherson (2003) for one interpretation, and Schwarz (2009) for a conflicting interpretation.)\nNow it is a pretty open question whether any one division of properties can do all these roles. One way to solve the New Riddle (arguably Lewis’s way, though this is a delicate question of interpretation) is to be a dogmatist (in the sense of Pryor (2000)) about inductive projections involving a privileged class of properties. Lewis’s discussion of the New Riddle at the end of Lewis (1983) sounds like he endorses this view, with the privileged class being the very same class as fundamentally determines the structure of the world, and makes for objective similarity and difference. But why should these classes be the same? It might make more sense to, for instance, endorse dogmatism about inductive projections of observational properties, rather than about microphysical properties.\nLewis doesn’t attempt to give a theoretically neutral definition of the perfectly natural properties. Rather, the notion of a perfectly natural property is introduced by the theoretical role it serves. But that theoretical role is very ambitious, covering many areas in metaphysics, epistemology and the theory of content. We might wonder whether claims like Humean Supervenience have any content if it turns out nothing quite plays that theoretical role. I think there is still a clear thesis we can extract, relying on the connection between intrinsicness and naturalness. It consists of the following claims:\n\nThere is a small class of properties and relations such that the contingent facts at any world supervene on the distribution of these properties and relations.\nEach of these properties is an intrinsic property.\nAt the actual world, the only relations among these which are instantiated are spatio-temporal, and all the contingent facts supervene not merely on the distribution of fundamental qualities and relations, but also on the distribution of fundamental qualities and relations over points and point-sized occupants of points.\n\nThose theses are distinctively Lewisian, they are clearly entailed by Humean Supervenience as Lewis’s conceives of them, they are opposed in one way or another by those who take themselves to reject Humean Supervenience, but they are free of any commitment to there being a single class of properties and relations that plays all the roles Lewis wants the perfectly natural properties and relations to play. So from now on, when I discuss the viability of Humean Supervenience, I’ll be discussing the viability of this package of views.\n\n\n4 Humean Supervenience and other Humean Theses\nLewis endorsed many views that we might broadly describe as ‘Humean’. Of particular interest here are the following three.\n\nHumean Supervenience.\nNomological Reductionism. Nomological properties and relations (including lawhood, chance and causation) are not among the fundamental properties and relations.\nModal Combinatorialism. Roughly, anything can co-exist with anything else.\n\nWe’ve stated Modal Combinatorialism extremely roughly, and will persist with using a fairly informal version of it throughout. For an excellent study of more careful versions of it, see Nolan (1996). But those details aren’t as important to this debate. What is important for now is that all three of these theses are associated with what are known as Humean approaches to metaphysics in the contemporary literature. But how closely connected are they to each other, or for that matter to Hume.\nOne question about Humean Supervenience is just how it connects to the work of the historical Hume. This would be a little easier to answer if there was a broad scholarly consensus that Hume actually believed the kind of simple regularity thesis of causation that Lewis attributes to him at the start of Lewis (1973). But it isn’t clear that this is Hume’s view (Strawson 2000). What is true is that Hume was sceptical that we could know more about causation than that it was manifested in certain distinctive kinds of correlations. But it is a further step to say that Hume inferred that causation just consists of these distinctive kinds of correlations.\nA second question is how Humean Supervenience, which perhaps should be referred to as so-called “Humean Supervenience”, or perhaps even better as “Lewisian Supervenience”, relates to the kind of regularity theory that Lewis attributes to Hume, or to the prohibition on necessary connections between distinct existences that underlies Modal Combinatorialism. Lewis seemed to see the three theses as related. Here he is explaining how he chose to name Humean Supervenience (and recall that this isn’t backed up by any detailed exegesis of Hume).\n\nHumean Supervenience is named in honour of the great denier of necessary connections. It is the doctrine that all there is to the world is a vast mosaic of local matters of particular fact just one little thing and then another. (Lewis 1986b ix)\n\nThis is a slightly confusing passage, since it isn’t clear why a violation of Humean Supervenience would constitute a necessary connection of any kind. We will return to this point below. But it does seem to make clear that Lewis thought that Humean Supervenience and Modal Combinatorialism were connected, since Modal Combinatorialism is much more closely connected to the denial that they can be necessary connections between distinct existences.\nCompare how Lewis introduces Humean Supervenience when discussing the role of possible worlds in formulating trans-world supervenience theses in Plurality.\n\nAre the laws, chances, and causal relationships nothing but patterns which supervene on this point-by-point distribution of properties? Could two worlds differ in their wars without differing, somehow, somewhere, in local qualitative character? (I discuss this question of ‘Humean Supervenience’, inconclusively, in the Introduction to my Philosophical Papers, volume II.) (Lewis 1986a, 14)\n\nThis seems to connect Humean Supervenience closely to Nomological Reductionism, since it makes the reducibility of the nomological properties and relations central to the question of whether Humean Supervenience is true. We can also, I think, see Lewis connecting Modal Combinatorialism and Nomological Reductionism in a later passage in Plurality where he discusses why he doesn’t believe that laws are necessary truths.\n\nAnother use of Modal Combinatorialism is to settle – or as opponents might say, to beg – the question whether the laws of nature are strictly necessary. They are not … Episodes of bread-eating are possible because actual; as are episodes of starvation. Juxtaposed duplicates of the two, on the grounds that anything can follow anything; here is a possible world to violate the law bread nourishes. … It is no surprise that Modal Combinatorialism prohibited strictly necessary connections between distinct existences. What I have done is to take a Humean view about laws and causation, and use it instead as a thesis about possibility. Same thesis, different emphasis. (Lewis 1986a, 91)\n\nSo for Lewis, these three theses are meant to be closely connected. And it is true that in the contemporary literature all three of them are frequently described as ‘Humean’ theses. (Or at least they are so described in metaphysics and philosophy of science; again, we’re bracketing questions of historical interpretation here.) But on second glance, it isn’t as clear what the connection between the three theses could amount to. One immediate puzzle is that Humean Supervenience is for Lewis a contingent thesis, while the other two theses are necessary truths. The accounts of causation, lawhood and chance that he gives in defending Nomological Reductionism are clearly meant to hold in all kinds of worlds, not just worlds like ours. (Consider the amount of effort that is spent in Lewis (2004a) at defending the theory of causation from examples involving wizards, action at a distance and so on.) And the formulation of Modal Combinatorialism in Plurality leaves little doubt that it is meant to be necessarily true.\nThis difference in modal status means that the theses can’t be in any way equivalent. But you might think that they are in some way reinforcing. Even that isn’t so clear. Consider the most dedicated kind of denier of Modal Combinatorialism, namely the fatalist who thinks that every truth is a necessary truth. She will endorse Humean Supervenience. After all, she thinks that all the truths about the world supervene on any category of truths whatsoever, so they’ll supervene on intrinsic properties of point-sized objects.\nIn the other direction, failures of Humean Supervenience don’t motivate compromising Modal Combinatorialism. Imagine a world where occasionally there are pairs of people who can know what each other is thinking, even though there is no independent informational chain between the two of them. It is just that a telepathic connection exists. Moreover, there is no rhyme or reason to when a pair of people will be telepathic; it is simply the case that some pairs of people are. In such a world, it is plausible that being a telepathic pair will be a fundamental relation. That’s not a problem for Humean Supervenience, since there aren’t any such pairs in this world. But it does mean Humean Supervenience is false in that world.\nAssume that Daniels and O’Leary are a telepathic pair. Any duplication of the pair of them will also be telepathic, since by Lewis’s preferred definition of duplication, duplication preserves all fundamental properties and relations. Does that mean there’s a necessary connection between Daniels and O’Leary? Not really. The spirit of Modal Combinatorialism is that you can duplicate any parts of any worlds, and combine them. One part of our world is Daniels. A duplicate of him need not include any telepathic connection to O’Leary; indeed, he has duplicates in worlds in which O’Leary is absent. Another part of the world is O’Leary; duplicates of him need not include a connection to Daniels. Putting the two together, there is a world where there are duplicates of Daniels and O’Leary, but no telepathic connection between the two. So Modal Combinatorialism suggests that even when Humean Supervenience fails, there won’t be a necessary connection between distinct objects. So Humean Supervenience really isn’t that important to the idea that there are no necessary connection between distinct existences.\nWhat’s closer to the truth, I think, is that Humean Supervenience is interesting because of Modal Combinatorialism. If Modal Combinatorialism fails, then Humean Supervenience doesn’t capture anything important. In particular, it doesn’t capture the idea that the nomic is somehow less fundamental than (some features of) the non-nomic. It is only given Modal Combinatorialism that we can make these kinds of priority claims in modal terms. Think about the philosopher who denies Modal Combinatorialism on the grounds that laws of nature are necessarily true. That philosopher will say that the laws supervene on the distribution of intrinsic properties of points, because the laws supervene on any set of facts that you like. But they will deny that this makes the distribution of intrinsic properties of points more fundamental than the laws. It is only given Modal Combinatorialism that we can claim that supervenience theses are any guide whatsoever to fundamentality.\nWhat about the connection between Nomological Reductionism and Humean Supervenience? It can’t be equivalence, since Lewis agrees that Humean Supervenience fails in worlds in which Nomological Reductionism is true. For the same reason, it can’t be that failures of Humean Supervenience entail failures of Nomological Reductionism. What about the other direction? Could we imagine Nomological Reductionism failing while Humean Supervenience holds? I think this is a coherent possibility, but not at all an attractive one. (Compare, in this respect, the discussion of theories that “qualify technically as Humean” at (Lewis 1994a, 485).) It requires that some of the irreducible, nomological properties be intrinsic properties of point-sized objects. Well, we could imagine two worlds where \\(F\\) and \\(G\\) are co-extensive, intrinsic properties of points, and in one of them it is a law that all \\(F\\)s are \\(G\\)s, and in the other it is a law that all \\(G\\)s are \\(F\\)s, and there are further intrinsic properties of all the points which are \\(F\\) and \\(G\\) which underlie these laws without making a difference to any of the other facts. So we imagine that the property being F in virtue of being G is held by all these things in one world but not in the other, and this is a fundamental perfectly natural property. I don’t think any of this is literally inconsistent, and I think filling out the details could give us a way for Nomological Reductionism to fail while the letter of Humean Supervenience holds. But it would clearly violate the spirit of Humean Supervenience  and it isn’t clear why we should believe in such ‘possibilities’ anyway.\nSo in practice, I think that any philosopher who rejects Nomological Reductionism is probably going to want to reject Humean Supervenience. And I think that Lewis saw some of the deepest challenges to Humean Supervenience as coming from threats to Nomological Reductionism. In particular, Lewis thought that the biggest challenges to Humean Supervenience came from the difficulties in providing a reductive account of chance, and the appeal of non-reductive series of causation.\nThe difficulties in providing a reductive account of chance are discussed at length in the introduction to Lewis (1986b), and in the only paper that has ‘Humean Supervenience’ in its title, i.e., Lewis (1994a). Here is a quick version of the problem. Chances are not fundamental, so they must supervene on the distribution of qualities. At least in the very early stages of the universe, there aren’t enough facts about the distribution of qualities in the past and present to form a suitable subvenient base for the chances. So whether the chance of \\(p\\) is \\(x\\) or \\(y\\) will, at least some of the time, depend on how the future of the world turns out. Now let \\(p\\) the proposition that tells the full story about the future of the world. And assume that \\(p\\) is a proposition such that what its chance is depends on how that future goes. If it goes the way \\(p\\) says it will go, the chance of \\(p\\) is \\(x\\); if it goes some other way, the chance of \\(p\\) is \\(y\\). Given a Humean theory of chance, Lewis says that this is going to be possible.\nBut now there’s a problem. What Lewis calls the Principal Principle says that if we know the chance of \\(p\\) is \\(y\\), and have no further information, then our credence in \\(p\\) should be \\(y\\). But in this case, if we knew the chance of \\(p\\) was \\(y\\), we could be sure that \\(p\\) would not obtain. So our credence in \\(p\\) should be 0. Here we seem to have reached a contradiction, and it is a contradiction to Lewis for a long time feared undermined the prospect of giving a reductive account of chance. The solution he eventually settled on in Lewis (1994a) was to slightly modify the Principal Principle, with the modification being designed to make very little difference in regular cases, but avoid this contradiction.\nLewis discusses the appeal of non-reductive theories of causation in several places, most notably for our purposes Lewis (2004a) and Lewis (2004c). Much of his attention is focused on the theory developed by Peter Menzies (1996). Menzies suggests that causation is the intrinsic relation that does the best job of satisfying folk platitudes about causation. A consequence of Menzies’s view is that there is something that makes a difference to the intrinsic properties of pairs of causes and effects which doesn’t supervene on either the intrinsic properties of the two ends of the causal chain, or on the spatio-temporal relations that hold between them. This something will either be causation or will be something on which causation depends. Either way there is a problem for Humean Supervenience, since there will have to be a perfectly natural relation that is not spatio-temporal.\nLewis’s response is to raise problems for the idea that causation could be an intrinsic relation. One class of worries concerns the very idea that causation could be a relation. Lewis says that absences can be causes and effects, but absences can’t stand in any relations, so causation must not be a relation. Another class of worries concerns the idea that causation could be intrinsic. Causation by double prevention, says Lewis, doesn’t look like it could be intrinsic. But intuitively there could be causation by double prevention. Yet another class of worries concerns the idea that causation could be a natural relation, or that there could be any one thing that satisfies all the platitudes about causation. The vast array of different ways in which causes can bring about their effects in the actual world, he says, undermines this possibility.\nNote that in both cases Lewis defends Humean Supervenience simply by defending Nomological Reductionism. So I think it is fair to say that there’s a close connection between the two in Lewis’s overall theory.\n\n\n5 Why Care about Humean Supervenience\nAs is well-known, some surprising results in quantum mechanics suggest that entanglement relations are somehow fundamental (Maudlin 1994). This suggests that Humean Supervenience is actually false. If that’s right, why should we care about philosophical arguments for Humean Supervenience? Lewis’s response to this challenge is somewhat disconcerting.\n\nReally, what I uphold is not so much the truth of Humean Supervenience as the tenability of it. If physics itself were to teach me that it is false, I wouldn’t grieve.\nThat might happen: maybe the lesson of Bell’s Theorem is exactly that … But I am not ready to take lessons in ontology from quantum physics as it now is. … If, after quantum theory has been cleaned up, it still teaches non-locality, I shall submit willingly to the best of authority.\nWhat I want to fight are philosophical arguments against Humean Supervenience. When philosophers claim that one or another commonplace feature of the world cannot supervene on the arrangement of qualities, I make it my business to resist. Being a commonsensical fellow (except where unactualised possible worlds are concerned) I will seldom deny that the features in question exist. I grant their existence, and do my best to show how they can, after all, supervene on the arrangement of qualities. (Lewis 1986b xi)\n\nWe can, I think, dismiss the point about quantum physics as it was in 1986. The theory has been cleaned up in just the way Lewis wanted, and the claims about non-locality remain. Indeed, by the end of his life Lewis was willing to take lessons in ontology from quantum physics. See, for example, Lewis (2004b). So what is at issue here is whether or not there are philosophical arguments against Humean Supervenience.\nBut at this point we might wonder why we should care. If a theory is false, what does it matter whether its falsehood is shown by philosophy or by physics? We might compare the dismissive attitude Lewis takes towards Plantinga’s attempts to show that reconstructions of the problem of evil as an argument do not rely solely on things provable in first-order logic (Lewis 1993).\nThe answer I offered in Weatherson (2009) was that the philosophical defence of Humean Supervenience was connected to the point of the last paragraph quoted above. Lewis wanted to save various features of our commonsensical picture of the world. And he wanted to do this without saying that philosophical reflection showed us that the picture of the world given to us by signs of somehow incomplete. He wanted to defend what I called ‘compatibilism’, something that I contrasted with eliminativism and expansionism. The eliminativists want to say that science shows us that some commonsensical feature of reality doesn’t really exist. (See, for example, Churchland (1981) for eliminativism about folk psychological states.) The expansionists want to say that since science (or at least physics) doesn’t recognise certain features of reality, but they obviously exist, we need to posit that science (or at least physics) is incomplete. There are many stripes of philosophical expansionists, from theists to dualists to believers in agent causation.\nLewis wasn’t averse in principle to either eliminativism or expansionism. One could, depending on exactly how one interpreted folk theory and science, classify him as an eliminativist about gods, and an expansionist about unactualised possible worlds. But his first tendency was always to support compatibilism. Compatibilists face what Frank Jackson (1998) called the ‘location problem’. They have to show where the commonsensical features are located in the scientific picture. That is, they have to show how to reduce (in at least some sense of ‘reduce’) or commonsensical concepts to scientific concepts. (Many compatibilists may bristle at the idea that they have to be reductionists; in recent decades the world has abounded with ‘non-reductive physicalists’, who are precisely compatibilists in my sense, but who reject what they call ‘reductionism’. But as Lewis (1994b) argued, these rejections often turn on reading too much into the notion of reduction. For that reason, Lewis would not have objected to being described as a reductionist about many everyday concepts.)\nOne way to perform such a reduction would be to wait until the best scientific theory is developed, and show where within it we find minds, meanings, morals and all the other exciting features of our ordinary worldview. But that could take a while, and philosophers could use something to do while waiting. In the meantime we could look for a recipe that should work no matter what physical theory the scientists settle on, or at least should work in a very wide range of cases. I think we can see Lewis’s defence of Humean Supervenience as providing such a recipe.\nIt is important to note here that Lewis’s defence of Humean Supervenience was largely constructive. He didn’t try to give a proof that there couldn’t be more to the world than the arrangement of local qualities. At least, he didn’t rest a huge amount of weight on such arguments. The arguments we will look at below for a functional construal of the nomological are, perhaps, hints at arguments of this type. But, in general, Lewis defended Humean Supervenience by explicitly showing where the ordinary concepts fitted in to a sparse physical picture of reality, under the assumption that physics tells us that the world consists of nothing but a spatio-temporal arrangement of intrinsic qualities.\nNow physics tells us no such thing. But it shouldn’t matter. If the recipe Lewis provides works in the case of the ‘Humean’ world, it should also work in the world physics tells us we actually live in. The reduction of laws to facts about the distribution of fundamental qualities, and the reduction of chances and counterfactual dependencies to facts about laws, and the reduction of causation to facts about chances and counterfactual dependencies, and the reduction of mind to facts about causation and the distribution of qualities, and the reduction of value to facts about minds, and so on are all independent of whether physics tells us that we have to recognise relationships like entanglement as fundamental. In other words, if we can solve the location problem for the Humean world, we can solve it for the actual world. And solving the location problem is crucial to defending compatibilism. And whether it is possible to defend compatibilism is a central concern of metaphysics.\nI quoted above a passage from 1986 in which Lewis links Humean Supervenience to compatibilism. It’s worth noting that he returns to the point in 1994.\n\nThe point of defending Humean Supervenience is not to support reactionary physics, but rather to resist philosophical arguments that there are more things in heaven and earth in physics has dreamt of. Therefore if I defend the philosophical tenability of Humean Supervenience, that defence can doubtless be adapted to whatever better supervenience thesis may emerge from better physics. (Lewis 1994a, 474)\n\nThat is, the defence of Humean Supervenience just is part of the argument against expansionism, and hence for compatibilism. That was the defence I offered in Weatherson (2009) for the interest of Lewis’s defence of Humean Supervenience, even if it were to turn out that Humean Supervenience was refuted by physics. I still think much of it is correct. In particular, I still think that Lewis wanted to defend compatibilism, and that the defence of Humean Supervenience is key to the defence of Humean Supervenience. Indeed, I think there is pretty strong textual evidence that it was a major part of Lewis’s motivation for defending Humean Supervenience. But this explanation of why the defence of Humean Supervenience is significant can’t explain why Lewis was so worried about the failures of Humean theories of chance. After all, if all we are trying to do is show that science and commonsense are compatible, we could just take chances to be one of the fundamental features of reality given to us by science. There isn’t any need, from the perspective of trying to reconcile science and common sense, to give a reductive account of chance. Yet Lewis clearly thought that giving a reductive account of chance was crucial to the defence of Humean Supervenience. As he said,\n\nThere is one big bad bug: chance. It is here, and here alone, that I fear defeat. But if I’m beaten here, then the entire campaign goes kaput. (Lewis 1986b xiv)\n\nI now think that attitude is very hard to explain if my earlier views about the significance of Humean Supervenience are entirely correct. The natural conclusion is that there is something more that the defence of Humean Supervenience is supposed to accomplish. One plausible interpretation is that what it is supposed to accomplish is a vindication of the idea that the key nomological concepts are, in a sense, descriptive. It’s easiest to say what this sense is by contrasting it with the kind of view that Lewis rejected.\nWe’re all familiar with the standard story about ‘water’. Our ordinary usage of the term latches onto some stuff in the physical world. That stuff is H\\(_2\\)O. Some people think that’s because our ordinary usage determines a property which H\\(_2\\)O satisfies, others because we demonstratively pick out H\\(_2\\)O in ordinary demonstrations of what it is we’re talking about when we use the term ‘water’. Either way, we get to be talking about H\\(_2\\)O when we use the word ‘water’, even if we are so ignorant of chemistry that we can’t tell hydrogen and oxygen apart. Moreover, our term continues to pick out ‘water’ even in worlds that are completely free of hydrogen and oxygen, and even if such worlds have other stuff that plays a very similar functional role to the role water plays in the actual world.\nLewis was somewhat sceptical of this standard story about ‘water’ (Lewis 2002). He thought that the ordinary term was ambiguous between our usage on which it picked out H\\(_2\\)O, and usage on which it picked out a role, a role that happens to be played by H\\(_2\\)O in the actual world but which could be played by other substances in other worlds. But if he thought the standard story about ‘water’ was at best, part right, he thought applying a similar story to ‘law’, ‘cause’ and ‘chance’ was wildly implausible.\nIf such a story were right, then we would expect to find worlds where there was some relation other than causation which played the causal role. Since the actual world is physical, any world in which nonphysical things stand in the kind of relations that causes and effects typically stand in should do. So, for instance, if we have a world where the castings of spells are frequently followed by transformations from human to toad form, we should have a world where spells don’t cause such transformations but rather the spellcasting and the transformation stand in a kind of fool’s cause relationship. But we see no such thing. In such magical worlds, spells cause transformations.\nSo whatever causation is, it doesn’t look to be the kind of thing whose essence can be discovered by physics. Physics couldn’t tell us anything about the essence of the relationship between the spell and the transformation into a toad. But, we think, physics can tell us a lot about the fundamental properties and relations are instantiated in the actual world. So causation must not be one of them.\nLewis has a number of other arguments against anti-descriptivist views about individual nomological concepts. These arguments strike me as rather strong in the case of lawhood and causation, and less strong in the case of chance.\nIf being F and being F in virtue of a law are both fundamental properties, then a plausible principle of modal recombination would suggest they could come apart. But they cannot; or at least they cannot in one direction. We want being F in virtue of a law to entail being F. That’s easy if lawhood is defined in terms of fundamental properties of things; but it’s hard to see how it could be if lawhood itself is fundamental (Lewis 1986b xii).\nA similar argument goes for causation. Assume that causation is a fundamental intrinsic relation that holds between things at different times. Consider, for instance, the causal relationship which holds between a throw of a rock (call it \\(t\\)) and the shattering of the window (call it \\(s\\)). As we noted above in the case of Daniels and O’Leary, several applications of Modal Combinatorialism suggest that there will be a world just like this one in which \\(t\\) is followed by \\(s\\), but in which \\(t\\) does not cause \\(s\\). But such a world seems to be impossible. As we also noted above, such a view runs into trouble with causation by double prevention, which does not look to be intrinsic.\nThe last two paragraphs have been extremely quick arguments, but in both cases it seems to me that they can be tightened up so as to provide good arguments for some kind of descriptivist stance towards laws and causation. Chance is another matter.\nThe first problem is that recombination arguments if anything point away from descriptivism about chance. Any such account will imply that chances can’t, in general, point too far away from frequencies. But recombination arguments suggest that chances and frequencies can come arbitrarily far apart. Consider some particular event type \\(e\\) that has a one-half chance of occurring in circumstances \\(c\\). Start with a world where \\(c\\) occurs frequently, and about half the time it is followed by \\(e\\). Now use recombination to generate a world where all the \\(c \\wedge \\neg e\\) events are deleted, so \\(c\\) is always followed by \\(e\\). Unless we add a lot of bells and whistles to our theory of chance, it will no longer be the case that the chance of \\(e\\) given \\(c\\) is one-half. That is odd; we can’t simply take the first circumstance where \\(c\\) occurred and at that moment there was a one-half chance of it being followed by \\(e\\), and patch it into an arbitrary world. Bigelow, Collins, and Pargetter (1993) turn this idea into a more careful argument against descriptivism about chance. They say that chances should satisfy the following principle. (In this principle, \\(Ch\\) is the chance function, and various subscripts relativise it to times and worlds.)\n\nSuppose \\(x &gt; 0\\) and \\(Ch_{tw}(A) = x\\). Then \\(A\\) is true in at least one of those worlds \\(w^{\\prime}\\) that matches \\(w\\) up to time \\(t\\) and for which \\(Ch_t(A) = x\\). (Bigelow, Collins, and Pargetter 1993, 459)\n\nThat is, if the chance of \\(A\\) at \\(t\\) is \\(x\\), and \\(x &gt; 0\\), then \\(A\\) could occur without changing the history prior to \\(t\\), and without changing the chance of \\(A\\) at \\(t\\). This seems like a plausible principle of chance, but it entails the not-so-Humean view that chances at \\(t\\) supervene on history to \\(t\\), not on the full state of the world.\nNow as it turns out Lewis doesn’t rest on recombination arguments against rival views of chance, and in my view he is wise to do so. Instead he rests on epistemological arguments. He takes the following two things to be data points.\n\nSomething like the Principal Principle is true. The original Principal Principle said that if you knew the chance of \\(p\\) at \\(t\\) was \\(x\\), and didn’t have any ‘inadmissible’ information (roughly, information about how the world developed after \\(t\\)), then your credence in \\(p\\) should be \\(x\\). Lewis tinkered with this slightly, as we noted above, but he took it to be a requirement on a theory of chance that the Principal Principle turn out at least roughly right.\nThe correct theory of chance will explain the Principal Principle.\n\nLewis frequently wielded this second requirement against rival theories of chance. Here’s one example.\n\nI can see, dimly, how it might be rational to conform my credences about outcomes to my credencs about history, symmetries and frequencies. I haven’t the faintest notion how it might be rational to conform my credences about outcomes to my credences about some mysterious unHumean magnitude. Don’t try to take away the mystery my saying that this unHumean magnitude is none other than chance! (Lewis 1986b xv)\n\nBut this also seems like a weak argument. For one thing, chances are actually correlated very well with frequencies, and this correlation does not look at all accidental. It seems very plausible to me that we should line up our credences with things that are actually correlated well with frequencies. But, you might protest, shouldn’t we have an explanation of why the Principal Principle is an a priori principle of rationality? I think that before we ask for such an explanation, we should check how confident we are that the Principal Principle, or anything else, is part of an a priori theory of rationality. I’m not so confident that we’ll be able to do this (Weatherson 2005, 2007).\nThere are other replies too that we might make. It seems plausible that we should minimise the expected inaccuracy of our credences (Joyce 1998). This is true when we consider not just the subjective expected inaccuracy of our credences, but the objective expected inaccuracy of our credences. That is, when we calculate the expected inaccuracy of someone’s credences, using chances as the probabilities for generating the expectations, it is good if this expected inaccuracy is as low as possible. But, assuming that we are using a proper scoring rule for measuring the accuracy of credences, this means that we must have credences match chances.\nMore generally, I’m very sceptical of theories that insist our metaphysics be designed to have complicated epistemological theses fall out as immediate consequences. Rationality requires that we be inductivists. Why is that? Here’s a bad way to go about answering it: find a theory of persistence that makes induction obviously rational, and then require our metaphysics to conform to that theory. I don’t think you’ll get a very good theory of persistence that way, and, relatedly, you won’t get a very Lewisian theory of persistence that way. The demand that the theory of chance play a central role in an explanation of the Principal Principle strikes me as equally mistaken.\nIf what I’ve been saying so far is correct, then chance interacts with the motivation for Humean Supervenience in very different ways to how laws and causation interact. Neither of the two kinds of motivations for defending Humean Supervenience against philosophical attacks provides us with good reason to leave chances out of the subvenient base on which we say all contingent facts supervene. This is not to yet offer anything like a positive argument for chances to be part of the fundamental furniture of reality. Rather, what I’ve argued here is that a metaphysics that takes chances as primitives would not be as far removed from a recognisably Lewisian metaphysics as a metaphysics that takes laws or causes as primitive, let alone one that takes mind, meanings or morals as primitive.\n\n\n6 Points, Vectors and Lewis\nThe other main point from the discussion of the previous section is that the fact that quantum mechanics raises problems for Humean Supervenience does not undercut the philosophical significance of Lewis’s defence of Humean Supervenience. But is Humean Supervenience even compatible with classical physics? Perhaps not.\n\nEven classical electromagnetism raises a question for Humean Supervenience as I stated it. Denis Robinson (1989) has asked: is a vector field an arrangement of local qualities? I said qualities were intrinsic; that means they can never differ between duplicates; and I would have said offhand that two things can be duplicates even if they point in different directions. May be this last opinion should be reconsidered, so that vector-valued magnitudes may count as intrinsic properties. What else could they be? Any attempt to reconstruct with them as relational properties seems seriously artificial. (Lewis 1994a, 474)\n\nThe opinion that the Lewis proposes to discard here seems more than an offhand judgement. It seems to follow from the very way that we introduce the notion of duplication. Here is Lewis’s own attempt to introduce the notion.\n\nWe are familiar with cases of approximate duplication, e.g., when we use copying machines. And we understand that if these machines were more perfect than they are, the copies they made would be perfect duplicates of the original. Copy and original would be alike in size and shape and chemical composition of the ink marks and the paper, alike in temperature and magnetic alignment and electrostatic charge, alike even in the exact arrangement of their electrons and quarks. Such duplicates would be exactly alike we say. They would match perfectly, they would be qualitatively identical, they would be indiscernible. (Lewis 1983, 355)\n\nIf Lewis is right that vector-valued magnitudes may count as intrinsic properties, then there is yet another condition that the perfect copying machine must satisfy. The original and the duplicate must be parallel. This isn’t the case in most actual copying machines. Usually, the original is laid flat, while the duplicate is a small angle to make it easier to collect. This is a feature, not a bug. It is not a way in which the machine falls short of perfect copying. But if vector-valued magnitudes are intrinsic qualities, and duplicates share their intrinsic qualities, it would be. So Lewis is wrong to think that these vector-valued magnitudes may be intrinsic.\nMoreover, the little argument that Lewis gives seems to rest on a category mistake. What matters here is the division of properties into intrinsic and extrinsic. But the properties on the kind of things that can be relational or non-relational. As Humberstone (1996) shows, concepts and not properties of the things that can be relational and non-relational. For instance the concept being the same shape as David Lewis actually was at noon on January 1, 1970, is a relational concept that presumably picks out an intrinsic property, namely a shape property. Whether they are valued magnitudes are intrinsic or extrinsic properties, is somewhat orthogonal question of whether it is best to pick them out by means of relational or non-relational concepts.\nThere is a further issue about the compatibility of Humean Supervenience with classical physics. This is a point that has been made well by Jeremy Butterfield (2006), and we can see the problem by looking at the different ways in which Lewis introduces Humean Supervenience.\n\nHumean Supervenience says that in a world like ours, the fundamental properties are local qualities: perfectly natural intrinsic properties of points, or of point-sized occupants of points. (Lewis 1994a, 474)\n\nLewis goes back and forth between local properties and intrinsic properties of points here. These aren’t the same thing. As Butterfield notes, ‘local’ is used in a few different ways throughout physics. One simple usage identifies local properties of a point with properties that supervene on intrinsic features of arbitrarily small regions around the point. To take an important example, the slope of a curve at a point may be a local property of the curve at that point without being intrinsic property of the point.\nThis raises a question: can we do classical physics with only intrinsic properties of points, and not even these further local properties? Butterfield argues, persuasively, that the answer is no. He notes, however, that there are some very mild weakenings of Humean Supervenience that avoid this difficulty. Here is a very simple one.\nCall Local Supervenience the following thesis. For any length \\(\\varepsilon\\) greater than 0, there is a length \\(d\\) less than \\(\\varepsilon\\) with the following feature. All the facts about the world supervene on intrinsic features of objects and regions with diameter at most \\(d\\), plus facts about the spatio-temporal arrangement of these objects and regions. This will mean that we can include all local qualities in the subvenient base, without assuming that these are intrinsic qualities of points. If the theory of intrinsicness in Weatherson (2006) is correct, we’ll also be able to include vector-valued magnitudes in the subvenient base without assuming that these are intrinsic properties of points. (On my view, they will end up being intrinsic properties of asymmetrically shaped regions.) We still won’t be able to accommodate entanglement relationships, but we will be able to capture classical physics. And, for the reasons discussed in the previous section, it would still be worthwhile to ask whether there are philosophical objections to Local Supervenience. A negative answer would greatly assist the arguments for compatibilism, and for nomological descriptivism.\nButterfield offers from theses like Local Supervenience to Lewis as friendly suggestions. But he thinks Lewis’s focus on points and their properties would have led him to reject it. I don’t want to get into the business of making counterfactual speculation about what Lewis would or would not have accepted. But I think he should have been happy to weaken Humean Supervenience to something like Local Supervenience. If the point of defending Humean Supervenience is not to defend its truth, but rather to assist in larger arguments for compatibilism, and for nomological descriptivism, then the big question to ask is whether a defence of Local Supervenience (against distinctively philosophical objections) would have served those causes just as well. And I think it’s pretty clear that it would have. Showing that we have no philosophical reason to posit fundamental non-local features of reality would be enough to let us “resist philosophical arguments that there are more things in heaven and earth in physics has dreamt of” (Lewis 1994a, 474). Lewis’s work in defending Humean Supervenience has been invaluable to those of us who want to join this resistance. It wouldn’t have been undermined if he’d allowed some local properties into the mix.\n\n\n\n\n\nReferences\n\nBigelow, John. 1988. The Reality of Numbers: A Physicalist’s Philosophy of Mathematics. Oxford: Oxford.\n\n\nBigelow, John, John Collins, and Robert Pargetter. 1993. “The Big Bad Bug: What Are the Humean’s Chances?” The British Journal for the Philosophy of Science 44 (3): 443–62. https://doi.org/10.1093/bjps/44.3.443.\n\n\nButterfield, Jeremy. 2006. “Against Pointillisme about Mechanics.” British Journal for the Philosophy of Science 57 (4): 709–53. https://doi.org/10.1093/bjps/axl026.\n\n\nChurchland, Paul. 1981. “Eliminative Materialism and the Propositional Attitudes.” Journal of Philosophy 78 (2): 67–90. https://doi.org/10.2307/2025900.\n\n\nGoodman, Nelson. 1955. Fact, Fiction and Forecast. Cambridge: Harvard University Press.\n\n\nHall, Ned. 2010. “David Lewisś Metaphysics.” In The Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta, Fall 2010. http://plato.stanford.edu/archives/fall2010/entries/lewis-metaphysics/; Metaphysics Research Lab, Stanford University.\n\n\nHaslanger, Sally. 1994. “Humean Supervenience and Enduring Things.” Australasian Journal of Philosophy 72 (3): 339–59. https://doi.org/10.1080/00048409412346141.\n\n\nHumberstone, I. L. 1996. “Intrinsic/Extrinsic.” Synthese 108 (2): 205–67. https://doi.org/10.1007/bf00413498.\n\n\nJackson, Frank. 1998. From Metaphysics to Ethics: A Defence of Conceptual Analysis. Clarendon Press: Oxford.\n\n\nJoyce, James M. 1998. “A Non-Pragmatic Vindication of Probabilism.” Philosophy of Science 65 (4): 575–603. https://doi.org/10.1086/392661.\n\n\nLewis, David. 1973. “Causation.” Journal of Philosophy 70 (17): 556–67. https://doi.org/10.2307/2025310.\n\n\n———. 1983. “New Work for a Theory of Universals.” Australasian Journal of Philosophy 61 (4): 343–77. https://doi.org/10.1080/00048408312341131.\n\n\n———. 1986a. On the Plurality of Worlds. Oxford: Blackwell Publishers.\n\n\n———. 1986b. Philosophical Papers. Vol. II. Oxford: Oxford University Press.\n\n\n———. 1993. “Evil for Freedom’s Sake?” Philosophical Papers 22 (3): 149–72. https://doi.org/10.1080/05568649309506401.\n\n\n———. 1994a. “Humean Supervenience Debugged.” Mind 103 (412): 473–90. https://doi.org/10.1093/mind/103.412.473.\n\n\n———. 1994b. “Reduction of Mind.” In A Companion to the Philosophy of Mind, edited by Samuel Guttenplan, 412–31. Oxford: Blackwell. https://doi.org/10.1017/CBO9780511625343.019.\n\n\n———. 2002. “Tharp’s Third Theorem.” Analysis 62 (2): 95–97. https://doi.org/10.1093/analys/62.2.95.\n\n\n———. 2004a. “Causation as Influence.” In Causation and Counterfactuals, edited by John Collins, Ned Hall, and L. A. Paul, 75–106. Cambridge: MIT Press.\n\n\n———. 2004b. “How Many Lives Has Schrödinger’s Cat?” Australasian Journal of Philosophy 82 (1): 3–22. https://doi.org/10.1080/713659799.\n\n\n———. 2004c. “Void and Object.” In Causation and Counterfactuals, edited by John Collins, Ned Hall, and L. A. Paul, 277–90. Cambridge: MIT Press.\n\n\nMaudlin, Tim. 1994. Quantum Non-Locality and Relativity: Metaphysical Intimations of Modern Physics. Oxford: Blackwell.\n\n\nMenzies, Peter. 1996. “Probabilistic Causation and the Pre-Emption Problem.” Mind 105 (417): 85–117. https://doi.org/10.1093/mind/105.417.85.\n\n\nNolan, Daniel. 1996. “Recombination Unbound.” Philosophical Studies 84 (2-3): 239–62. https://doi.org/10.1007/BF00354489.\n\n\nPryor, James. 2000. “The Sceptic and the Dogmatist.” Noûs 34 (4): 517–49. https://doi.org/10.1111/0029-4624.00277.\n\n\nRobinson, Denis. 1989. “Matter, Motion and Humean Supervenience.” Australasian Journal of Philosophy 67 (4): 394–409. https://doi.org/10.1080/00048408912343921.\n\n\nSchwarz, Wolfgang. 2009. David Lewis: Metaphysik Und Analyse. Paderborn: Mentis-Verlag.\n\n\nSider, Theodore. 1993. “Naturalness, Intrinsicality and Duplication.” PhD thesis, University of Massachusetts - Amherst.\n\n\n———. 2001. “Criteria of Personal Identity and the Limits of Conceptual Analysis.” Philosophical Perspectives 15: 189–209. https://doi.org/10.1111/0029-4624.35.s15.10.\n\n\nStrawson, Galen. 2000. “David Hume: Objects and Power.” In The New Hume Debate, edited by Rupert Read and Kenneth A. Richman, 31–51. London: Routledge.\n\n\nWeatherson, Brian. 2003. “What Good Are Counterexamples?” Philosophical Studies 115 (1): 1–31. https://doi.org/10.1023/A:1024961917413.\n\n\n———. 2005. “Scepticism, Rationalism and Externalism.” Oxford Studies in Epistemology 1: 311–31.\n\n\n———. 2006. “The Asymmetric Magnets Problem.” Philosophical Perspectives 20: 479–92. https://doi.org/10.1111/j.1520-8583.2006.00116.x.\n\n\n———. 2007. “The Bayesian and the Dogmatist.” Proceedings of the Aristotelian Society 107: 169–85. https://doi.org/10.1111/j.1467-9264.2007.00217.x.\n\n\n———. 2009. “David Lewis.” In Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta. Metaphysics Research Lab, Stanford University.\n\nCitationBibTeX citation:@incollection{weatherson2015,\n  author = {Weatherson, Brian},\n  editor = {Loewer, Barry and Schaffer, Jonathan},\n  publisher = {Blackwell},\n  title = {Humean {Supervenience}},\n  booktitle = {A Companion to David Lewis},\n  pages = {99-105},\n  date = {2015},\n  doi = {10.1002/9781118398593.ch8},\n  langid = {en}\n}"
  },
  {
    "objectID": "posts/ryle-regress/index.html",
    "href": "posts/ryle-regress/index.html",
    "title": "Intellectual Skill and the Rylean Regress",
    "section": "",
    "text": "In recent work about know how, Rylean regress arguments have largely dropped out of focus. They play little role in the anti-intellectualist arguments of various kinds in the papers collected in Bengson and Moffett (2011). They are used as something like target practice by intellectualists like Jason Stanley (2011), who uses the first chapter of his book to dispose of them before getting onto the real business. And even Yuri Cath, who in other work has launched sharp critiques of intellectualism, has argued that the regress arguments for anti-intellectualism don’t work (Cath 2011, 2013). The majority view seems to be that Carl Ginet (1975) basically showed these arguments didn’t work, and it’s time to move onto other considerations for or against intellectualism.\n\nImage from Wikipedia. It is Rex Whistler’s portrait of Ryle.\n\nI think this isn’t exactly right. In particular, I think regress arguments can be used to show a few different things. For one, they can be used to refute a precisification of this thesis, which plays a key role in some intellectualist arguments.\n\nOnly volitional actions are normatively assessable.\n\nOnce we have seen that thesis is false, we need a new picture of how action can be at once intelligent and non-volitional. Some considerations similar to those adduced by Ryle (1949) concerning agents who either concentrate on irrelevant considerations, or ignore relevant ones, show there is a role for intellectual skill that cannot be identified with any piece of knowledge that. And some further considerations, similar to those adduced by Cath (2011), suggest that this intellectual skill can’t even be constituted by a piece of knowledge that. So regress arguments, I’ll argue, can do quite a lot to motivate the thought that there was a lot wrong with the intellectual picture Ryle tried to attack.\nThe position I’m going to be defending is a long way from the strongest kinds of Rylean position that contemporary intellectualists such as Stanley are focussed on arguing against. My focus is primarily on intellectual skill. This has some relevance for debates about know how, though less relevance for debates about the semantics of know how ascriptions. This focus on skill rather than know how ascriptions is hardly novel; it is continuing a trend that we see exemplified in recent work by, inter alia, Carlotta Pavese (2013), Ellen Fridland (2014) and Cheng-Hung Tsai (2014). And in fact that conclusions I’ll draw here are, I think, similar to the ones that Fridland draws.\nOnce we move towards thinking about skill, we can get varieties of anti-intellectualism that are very different from those that were the focus of most philosophical discussion until very recently. For example, the anti-intellectualist view I’m defending is consistent with the following four theses.\n\nInstances of intellectual skill are usually, and perhaps always, not happily reported using know how ascriptions.\nKnow how ascriptions are rarely, if ever, reports of intellectual skill, and are frequently reports of propositional knowledge.\nIntellectual skill is guided by, and dependent on, propositional knowledge.\nPropositional knowledge is not behaviourally inert.\n\nNot just is the view consistent with these four, I’m fairly confident that the last three at least are true. But that’s all consistent with the view that intellectual skill is not itself propositional knowledge. And it’s all consistent with the view that we can learn philosophically significant conclusions from Ryle’s regress arguments.\nOne disclaimer before I start. Although this paper is heavily influenced by (Ryle 1945, 1949), and sympathetic interpreters of Ryle such as Jennifer Hornsby (2011), I make no attempt at Ryle exegesis here. I think there’s a decent case to be made that Ryle was sympathetic to the position defended here, but I’m going to leave that debate for another day.\n\n1 The Volitional Regress\nDefine a volitional action to be one that is preceeded by a volition to perform that very action. And say an action is normatively assessable if it can properly be assessed using terms like praiseworthy, blameworthy, intelligent or stupid. Note that I’m ruling out assessments as good or bad as versions of normative assessment, in the relevant sense. Someone who has a good digestive system is not, thereby, normatively assessable in the stipulative sense I’m using. Both of these definitions are to an extent stipulative; the terms ‘volitional’ and ‘normative’ can sensibly receive many other definitions. Still, I will stick to these definitions here. In light of those stipulations, consider the following set of propositions.\n\nOnly volitional actions are normatively assessable.\nThe action of forming a volition is normatively assessable.\nSome public actions, such as making a move in a chess game, are normatively assessable.\n\nIt should be obvious that this leads to a regress. Whether the kind of regress in question is impossible, or even impractical, is a tricky question. (See Robert K. Meyer (1987) for some of the complications that arise when trying to reason about regresses.) But it is commonly assumed in this literature that the kind of regress that these three premises lead to is problematic.\nSince the third premise is obviously true, the issue is whether the first or second is false. But it seems that second is true as well. Just as we can assess a person’s actions as praise or blameworthy, intelligent or stupid, we can assess the process by which she decided to perform those actions in the same way. Consider two people who make the same, as it turns out great, chess move in the same situation. The first notices an initially appealing counter to her move, and sees after careful thought that it won’t work. The second simply doesn’t notice the counter, and is stumped when her opponent makes it. It seems the first has engaged in a more intelligent practice of volition formation than the second. Or imagine a third player, whose initial analysis of the move starts by considering a recipe for arroz con leche. Unless there turns out to be an unnoticed connection here, this looks even less intelligent than the second player.\nOn the other hand, the first premise is rather unintuitive. To borrow an example from Angela Smith (2005), it is blameworthy to forget a friend’s birthday, although forgettings are rarely volitional. So we must reject 1 or 2, and while 1 is subject to independent counterexample, 2 seems independently plausible. So 1 must be false.1\n1 This argument is obviously rather quick, and I doubt will persuade someone already convinced of 1. For much more extensive arguments against 1, see the Smith, Ryan and Steup articles cited in the text, plus Adams (1985).That’s already a substantial conclusion. Something like 1 is behind William Alston’s famous, and influential, arguments against deontological approaches to epistemology (Alston 1988). But the negation of 1 is not a novel claim; I’m saying nothing here that Smith didn’t say in her rejection of the “volitional view of responsibility” (Smith 2005, 238). And similar views have been put forward by other critics of Alston such as Sharon Ryan (2003) and Matthias Steup (2008).\nBut still, the fact that 1 is false seems not to have been sufficiently appreciated in the recent literature on intellectualism. To see one place where it is relevant, consider this set of propositions, which also seem to trigger a regress.\n\nIntelligent action requires the triggering of a prior representation of knowledge relevant to the action.\nThe triggering of a representation, when done well, is an intelligent action.\nSome public actions, such as making a move in a chess game, are intelligent.\n\nAgain, these propositions obviously trigger a regress, and that seems like good evidence to take one of them to be false. This is very similar to one of the regresses Jason Stanley considers in chapter 2 of his (2011). And Stanley thinks the false proposition is 5. He writes “Triggering a representation can be done poorly or well. But this does not show it can be done intelligently or stupidly.” (Stanley 2011, 16) Indeed, he writes that since “triggering representations is something we do automatically” (Stanley 2011, 16) a statement like 5 is a “manifest implausibility” (Stanley 2011, 16). But the argument here relies on 1. If you think things done non-volitionally can be intelligent or stupid, it isn’t too much of a stretch to think that things done automatically can be intelligent or stupid. Indeed, Smith’s birthday example is already enough to undermine Stanley’s point; forgetting a friend’s birthday seems automatic in the sense he has in mind, but is also stupid.\nMore generally, it seems very intuitive to describe everyday cases in such a way that 5 must be true. For example, Billy asks Suzy whether she thinks Jill’s party will be a success. There are a lot of things that are common knowledge between the two of them. One is that Jill is a proficient party host. Another is that Jill has invited all of their colleagues, including Jack. Another is that parties which Jack attends are rarely successes. But Suzy thinks for a minute, remembers that Jack is away in Ohio, and says that it will be a success.\nIt was smart of Suzy to think about Jack’s whereabouts. It wasn’t, perhaps, necessary. If she’d just reasoned from Jill’s general proficiency to the success of the party, she would have got to the right conclusion. But it was better to note a possible complication, and check that it wouldn’t actually get in the way.\nIt would have been stupid to perform the same activity for many other kinds of possible complications. If Suzy had thought to herself, “The party will be a disaster if there’s an alien invasion in the middle of it, but there’s no reason to think the aliens will invade just now, so I’ll keep on thinking it will be a success,” that would have been stupid. Other possible complications are not stupid to consider, but they are intellectual mistakes. The party won’t be a success if there’s a police raid in the middle, based on a mistaken view the police have about where a particular drug dealer lives. Police do make mistakes, so even if Jill isn’t a drug dealer, this could be a genuine concern, depending on how nearby the mistakes are. But if the nearest mistake was a botched raid in a neighbouring state in the previous year, it’s wrong for Suzy to worry about this before answering Billy’s question.\nStanley’s view has to be that I’ve been misusing adjectives systematically through the last two paragraphs. I shouldn’t have said that it was smart of Suzy to consider Jack’s whereabouts, or that it would have been stupid to consider the alien invasion. Rather, it was just her cognitive system working well when she considered Jack, and would have been working poorly had she considered the aliens, and sub-optimally had she considered the police. This doesn’t seem at all the natural way to describe the case to me, in part because I’m not sure I see the difference Stanley is hinting at. Intelligence just is the good operation of the cognitive system, and stupidity its poor operation.\nSo these two regresses lead to two interesting conclusions. First, some non-volitional actions are normatively assessable. Second, intelligent action does not always require the prior triggering of a representation of relevant knowledge. Both of these are interesting. Both of these are negations of part of what you might consider “the intellectualist picture”. (Cath (2013) notes that Ryle often refers to the regresses as arguments against this picture, not against any particular thesis.) But neither of them get us very close to a distinction between know how and know that, or between intellectual skill and know that. The next section addresses some ways we might move closer to arguments against more central intellectualist claims.\n\n\n2 Picturing Intelligent Action\nAs noted in the introduction, my plan is not to offer an argument with regress like premises, and the conclusion that intellectual skill is distinct from propositional knowledge, or that know how is distinct from propositional knowledge. What I do want to do is sketch a picture of human intelligence (at a very high level of generality) that presupposes that intellectual skill is not identical to propositional knowledge, and suggest some considerations to the effect that no similarly plausible picture exists in which intellectual skill and propositional knowledge are identified. The thought here is not that the only way out of the regress involves distinguishing skill and knowledge – and perhaps distinguishing know how from know that – but rather that the best way out does.\nStart with a well known, if not obviously authentic, exchange.2\n2 I thought this example was purely fictional, coming from the Monty Python sketch reproduced in Dempsey (2012, 741). But Ben Wolfson pointed out to me that it’s recorded as a true story in Hadley (1903, 255).\nIt’s actually striking how few really good off-the-cuff quips there are in recorded history. The famous one attributed to Wilde, “I have nothing to declare but my genius”, is probably apocryphal, and in any case sounds prepared. Lists of famous come-backs and ripostes are usually crowded with written responses. Word play is hard.\nOscar Wilde: I wish I’d said that.\nJames McNeill Whistler: You will Oscar; you will.\n\nAssuming this really happened, that’s a clever response. It’s an occupational hazard of philosophers to think that the ability to come up with quick, clever responses is somehow central to intelligence. But we can reject that wildly implausible view without thinking that it’s wrong to think of these quips as a manifestation of a kind of intelligence.\nNow let’s think of how someone could have come up with this response. Even before we start researching the neural patterns behind quips like this, we can be pretty sure the following is not what happened in Whistler’s brain. He first made an exhaustive list of all possible responses, from “Green ideas sleep furiously” to what he actually said, then figured out which would be best, then produced the best one. On this wildly implausible model, the reply would be intelligent because it would reflect the speaker’s ability to properly evaluate this list of responses. That’s implausible because the list is simply too big. Indeed, it is in principle infinitely large. The list is too big to survey not just consciously, but subconsciously.\nComing up with a response like this requires first coming up with a narrower list of possible responses, and then evaluating which is best from that list.3 There’s a romantic model of intellect where the list in question consists of just the reply actually issued. On this model the perfect reply appears fully and perfectly formed in the mind of the intelligent person. Now such a model may often fit the phenomenology, but I don’t think we should give that much credit. It’s an empirical question how many possible replies are represented in the mind in a situation like this, before the chosen reply is issued. What’s not an empirical issue is whether the list of possible replies that is represented in the mind is finite or infinite. It simply must be finite, which means that there must be better and worse lists to consider. And that suggests that there is some skill involved in coming up with the list.\n3 Or, perhaps even more plausibly, coming up with a short list of possible openings, choosing the best, and doing what one can to figure out how to complete the response while uttering the start of it. Thanks here to Ben Wolfson.One could reject this last conclusion. One could try saying that the coming up with a list of possible replies is no manifestation of skill, but the skill is only involved in the evaluation and selection of replies. But this seems to generate a bizarre explanation about why the less skilled interlocutor comes up with worse replies. The model, presumably, is that the lack of skill does not explain having the wrong list of replies to choose between. Rather, what explains their less skilled reply must simply be that they misevaluated the possible replies. But that doesn’t fit the observed data. It’s much easier to see of someone else’s reply that it was clever than it is to come up with a clever reply.\nIt could also be objected that the model I’ve suggested is much too simple. It isn’t just that the mind issues a list of options, then evaluates them, and then selects the best. A more plausible model involves more recursive steps. The mind first generates a list of options, selects the best, then generates a list of refinements of that best option, selects the best of those, and so on. Perhaps when we consider superficial forms of intelligence, such as quips, it makes sense to consider a ‘one-step’ model, where a list is generated and evaluated, followed by a speech. But when one is choosing one’s words carefully, as in say Wilde’s writing, the simple model I’ve described feels much too simple.\nBut although the simple model is too simple for considered writing, the general structure must be right. Even a writer working at a leisurely pace, such as Joyce taking decades to write Finnegans Wake, doesn’t have time to consider, even subconsciously, all possible constructions. There are still too many. And nor is it true that the difference between Joyce’s skill and ours is that he realises the value of the sentences we all represent. The rest of us didn’t simply misjudge the value of “Nobirdy aviar soar anywing to eagle it” (Joyce 1939/2012, 505); we simply didn’t token it. The ability to token mental representations like that is part of what Joyce’s genius consists in.\nI’ve focussed so far on cases where it is a priori implausible that human thinkers start by surveying the range of possible things they could do. It is also interesting to look at cases where this is in principle possible, but doesn’t seem to happen in practice. There have been, traditionally, major differences in the style of play between human and computer chess players. (Since so many young players learn from machines these days, Kasparov (2010) suggests these differences are diminishing.4) This isn’t necessarily because humans can’t consider all options on the chess board. Usually there will be fewer than a hundred available moves, and a human could consider each. But that isn’t, it seems, how humans think. They don’t allocate equal resources to working through each of the possible options. As a result, computers often come up with surprising kinds of moves. Now computers are actually very good at chess, so these pre-deliberative allocations of cognitive resources may not have been optimal. Perhaps it would have been better for traditional chess players to spend more time thinking through unlikely progressions of the game. But it is evidence that even when we could use an unintelligent method for beginning inquiry, namely recursively generating the possible options, we prefer to use intelligent methods.\n4 Thanks to Bernard Kobes and John Collins for helpful discussions about the chess examples.So intelligent action, at least in humans in the kinds of situations humans normally find themselves in, consists in part of making intelligent choices about where to start inquiry. Given that intelligent action need not be volitional, as we established above, it isn’t surprising that being intelligent consists in part in starting in the right places. But perhaps this intelligence is just itself a kind of knowledge. It is, we might suspect, just the knowledge of what a good starting point will be. Or, since we will want to start with all and only the considerations relevant to a given inquiry, it is just knowledge of what is relevant.\nThe resulting picture is both perfectly intellectualist, and immune to the regresses considered above. The intelligent person knows what is relevant to what inquiry. Her choice of starting points is guided by this knowledge. (The ‘guidance’ metaphor recurs frequently in Stanley’s work.) This isn’t because it leads to a volition to start just here. Such a volition would be self-defeating, since in the relevant sense of ‘start’, by the time this volition is formed, one has already started, and indeed started elsewhere. Nor can she be guided by even a triggered representation of this knowledge of relevance. Again, if that happens, she is in the relevant sense starting elsewhere. But perhaps propositional knowledge can guide directly; not by generating volitions, and without even being represented anew.\nNow I don’t think this picture is right. But it isn’t incoherent either, and it takes work to see why it isn’t right.\nOne bad argument against this picture starts with the idea that skills are active, while knowledge is passive. The thought is that the person who knows a lot is like the Tortoise in Louis Carroll’s dialogue (Carroll 1895), only able to add more premises but never to reach a conclusion. It is only with skill that we can get to the conclusion. Stanley rightly objects to this argument on the grounds that it just isn’t true that knowledge is passive in the relevant sense. We should not, as Stanley puts it, “over-intellectualize knowing that”. (Stanley 2012, 773). (A similar point is made in Stalnaker (2012).) Knowing that p is not just a matter of having p written in a knowledge box somewhere in the brain; it can in part be constituted by active dispositions.\nA better argument looks at the very different modal profiles of intellectual skill and knowledge of relevance. Someone can know that something is irrelevant and yet lack the skill to ignore it; or they can know that something is relevant and yet lack the skill to consider it in a timely manner. Examples from the other direction, where there is skill without knowledge, are a little more contentious, but we’ll look at some possible cases of those too. But first we’ll run through two examples to show how easy it is to have knowledge without skill.\nAlice has spent a lot of money on video-conferencing equipment. But it isn’t working at all well, and she now has to decide whether to try and patch it into something better, or buy a whole new system. She knows the sunk cost fallacy is a fallacy; that buying a new system would make the previous purchases a waste is no reason to not buy a new system, especially if doing so is good value compared to the cost of buying a ‘patch’. But she can’t bring herself to ignore this fact when deliberating. Even though she eventually makes the right decision and buys new equipment, she takes much longer about this than she would have if, say, the existing equipment was old enough that she could easily conceptualise it as obsolete.\nBob is trying to solve a puzzle about the properties of functions from rationals to rationals. He knows that it is often helpful, when solving such puzzles, to transform the puzzle into one about functions from ordered pairs of integers to ordered pairs of integers. He knows that in the sense that if you asked him whether it could be useful to consider that transformation of the puzzle, he would immediately say yes, and this answer would come with the phenemenology of recollection, not of new insight. But no one does ask him that question, and the transformation in question simply never occurs to Bob. Since the untransformed puzzle is very hard, while the transformed puzzle is manageable, Bob never solves the problem.\nIt seems to me that what’s happened in both cases is that the agent has some knowledge, but is incapable of using it. What they lack is a skill. In particular, they lack what Fridland (2014, 2746) calls ‘selective, top-down, automatic attention’. Alice keeps attending to something she should not, even though she knows she should not. Bob fails to attend to something he should, although in some sense he knows that is what he should attend to. Bob’s case is one of the reasons I find the picture of skill presented by Stanley and Williamson (2017) unhelpful. They say skill is a disposition to form knowledge. But Bob has the important knowledge. The disposition he lacks is the disposition to activate that knowledge, and let it guide deliberation. That’s what constitutes his lack of skill.\nIt’s true that knowledge isn’t completely passive. If Alice never appealed to the fact that the sunk cost fallacy is a fallacy in her reasoning, we wouldn’t say that she knows it. If none of Bob’s answers were guided by the existence of natural and useful transformations between rational numbers and ordered pairs of integers, we wouldn’t say he knows such transformations are natural and useful. I’m here agreeing with Stanley and Stalnaker that knowledge is itself a kind of disposition. And intellectual skill is a kind of disposition too. But they are very different dispositions. In particular, they have very different triggering conditions. Bob lacks some skill because he does not call to mind this fact about rational numbers right now. He has the salient knowledge about rational numbers because he is disposed to use the facts in question often enough.\nSo intellectual skill and knowledge of relevance have different manifestation conditions, and so they are not identical. But we can say something stronger than that. The cases of Alice and Bob are not in any way unusual. Examples where we forget the salience of some consideration, or can’t get an irrelevant point out of our heads, are frequent. In principle, one could respond to the arguments I’ve made so far by saying that while knowledge of relevance is not identical to skill, nevertheless the two are as closely linked as, say, a material object and the matter that constitutes it. And if I had to resort to bizarre cases of the kind we torture introductory students with to make my point, I’d say that would be the right response. But given how normal Alice and Bob’s cases are, this seems like the wrong move. Skill and knowledge don’t just come apart in theory, they come apart in practice, frequently.\n\n\n3 Four Objections\nSo far I’ve defended three theses that are in tension with some forms of intellectualism. They are:\n\nSome non-volitional actions are normatively assessable.\nNot all intelligent action is preceded by the triggering of representations of relevant knowledge.\nIntellectual skill, in particular the intellectual skill associated with starting inquiry in the right place, is not identical to any piece of propositional knowledge.\n\nWhile this doesn’t show that, for instance, know how and know that are distinct, and is completely silent on what we should say about know how ascriptions, it does undermine some intellectualist programs. I’ll conclude with some objections either to the arguments I’ve put forward, or to their significance.\nObjection: Even if all of this is true, there may still be a sense in which intellectualism is true. After all, it could still be that knowledge guides action in a suitable way. (Compare (Stanley 2011, 2).)\nReply: This could be true. Whether it is a win for intellectualism depends a bit on the boring question of how we settle the term ‘intellectualism’, and a bit on more interesting questions about priority. Let’s start by distinguishing five theories we might call intellectualist.\n\nIdentity Intellectualism\n\nThe possession of an intellectual skill just is the possession of a piece of knowledge.\n\nConstitution Intellectualism\n\nThe possession of an intellectual skill is, always, constituted by a piece of knowledge.\n\nWeak Constitution Intellectualism\n\nThe possession of an intellectual skill is, often, constituted by a piece of knowledge.\n\nCausal Intellectualism\n\nThe possession of an intellectual skill is, always, caused by the possession of a piece of knowledge.\n\nWeak Causal Intellectualism\n\nThe possession of an intellectual skill is, often, caused by the possession of a piece of knowledge.\n\n\nThis paper has been arguing against Identity Intellectualism. I think the falsity of this is as much as we could reasonably hope to prove using regress arguments. (I think I’m here agreeing with Wiggins (2009) and Hornsby (2011).) And the considerations behind the regress argument do, I think, show it to be false. If someone wants to insist that by intellectualism, they mean something weaker than this, I’m not going to quarrel over terminology. I’ll just note that Identity Intellectualism is an interesting, and false, thesis.\nThe arguments here are clearly not arguments against either form of Weak Intellectualism. Indeed, they are naturally understood as the kind of cases that confirm Weak Intellectualism. Mathematics students, like Bob, train by learning a lot of mathematical facts. And it’s hard to see how they could develop the relevant skills without knowing some important facts. This is, I suspect, the general case. Skillfully bringing the right considerations to bear on a problem requires, and is probably the causal consequence of, knowing a lot of relevant facts. (Tsai (2014) makes clear how one can simultaneously hold that skills are in part constituted by knowledge of facts without having an intellectualist picture of skill.)\nBut what of the other two intellectualist theories? Do we have reason to think that there are some skills that are not constituted by, or not caused by, the possession of factual knowledge? One way to quickly show that would be to show that there can be skills without the related knowledge. Perhaps that’s not just sufficient for rejecting Constitutive/Causal Intellectualism, but necessary. If knowledge without skills is possible, as in Alice and Bob’s cases, and skills without knowledge were impossible, that asymmetry would call out for explanation. And something in the vicinity of Constitutive or Causal Intellectualism would be a very good candidate explanation.\nThere are (at least) two promising routes to showing that there can be skills without knowledge. One is due to Imogen Dickie (2012). She argues that since there are so many different routes to skill than there are to knowledge, we should expect that there will be cases of skill that are causally prior to knowledge. Jason Stanley (2012) replies that Dickie’s argument assumes an overly narrow conception of propositional knowledge. This is a fascinating debate, but I don’t have anything useful to add to it, so I’ll just note the existence of this route, and move on.\nThe other route is due to Yuri Cath (2011). He suggests that facts in virtue of which a person might lose propositional knowledge do not always bring about a loss of knowledge that. I’m going to sketch a Cath-style argument that we can have intellectual skills without knowledge. I think the argument has some force, though there are more ways to resist it than there are to resist the argument against Identity Intellectualism.\nRoss and Rachel are economics students taking an exam. They are given a hard question asking about the likely effects of an exogenous shock, say an earthquake affecting an area the supplies crucial raw materials, on some related markets. The question is hard, with the relevant causal pathways being interconnected and often opposing. The only plausible way forward is to use a model and search for equilibrium points in the model. That’s what Ross and Rachel have both been taught to do. And in fact both of them quickly select the right kind of model, with just the right amount of complexity in it to answer the question without being overburdened, and set out on the difficult algebra involved in solving the question.\nSo far it looks like both Ross and Rachel have shown intellectual skill. Now it turns out Ross and Rachel have very different views about the role of models in economic thinking. (My own thinking about models has been heavily influenced by Strevens (2008 ch. 8) and Davey (2011), and I rely on their insights in what follows.) These models involve, as all models do, some serious idealisation. Most notably, they assume that all the relevant actors are perfectly rational utility maximisers. Rachel hasn’t given much thought to this assumption, though she knows it to be literally false. But if pressed, she would say some reasonably sensible things about why she was using the model. For one thing, the familiar failures of human rationality aren’t obviously relevant to the puzzle being presented. For another, they’ve been taught that using these models is a good way to solve problems, and that testimonial evidence carries some weight. And for another, it’s an exam, and it is likely that questions have been selected to test how well students can use the models they have been taught. If those are her background, implicit, views, I think it is plausible to say that Rachel knows that the model is relevant to the exam question, even if she couldn’t produce a theory of idealisations in economics of the standards of the best philosophers.\nRoss’s views about models are rather different. He thinks the familiar models in economics work, when they do, because the background assumptions are strictly and literally true. He thinks economic agents are utility maximisers, and the apparent evidence to the contrary is due to sloppy experimental design. He thinks markets are always in general equilibrium. And so he thinks that the only sources of error in predictions we can make about markets are from errors about things like the costs of extracting raw materials after the earthquake. This perspective is, of course, grossly mistaken. Moreover, Ross thinks that if the assumptions were not correct, there would be no point in using the models. This too is a mistake, though perhaps not as dramatic as his other mistakes.\nNow even if Ross and Rachel aren’t thinking about these philosophical views about the nature of models, I think they are relevant to whether each of them know that the models are relevant to the puzzle. In particular, I think Rachel does know that the models are relevant, while Ross’s belief that they are relevant is more like a lucky guess than a piece of knowledge. Still, I think we should say that Ross showed skill in using this model rather than a more or less complex model, or a different kind of model, or no model at all. So he is a case of intellectual skill without knowledge of relevance.\nI don’t think this case is conclusive. I can think of at least four ways someone might reasonably object to the case.\n\nIt might be argued that despite his false views about why the models are relevant, he really does know that they are relevant. In other words, we would have another counterexample, to be added to those discussed by Warfield (2005) and Luzzi (2010), to the theory that false beliefs cannot generate knowledge.\nIt might be argued that Ross is not really skilled, since it is a matter of luck that the falsity of his beliefs does not lead him to false conclusions here.\nIt might be argued that although Ross doesn’t know that this model is relevant, his skill is constituted by, or caused by, some other knowledge he has.\nIt might be argued that the broad picture of the role of idealisations in scientific reasoning that I’m adopting from Strevens and Davey is mistaken, and this fatally undermines my use of the case to argue against intellectualism.\n\nI don’t think these arguments are going to ultimately work. But it’s clear we are a long way from Rylean regress arguments here. And that’s where I think the debate about regress arguments should end. We have a good argument against Identity Intellectualism. And we have some suggestive considerations that seem to tell against Constitutive and Causal Intellectualism, but whether these arguments ultimately work will depend on considerations independent of the regress.\nObjection: Stanley and Williamson (2017) have recently defended the idea that skill is a disposition to form knowledge. And they back this up with empirical analysis of intelligent motor skills, especially drawing on the survey by Yarrow, Brown, and Krakauer (2009). Is this kind of intellectualism subject to the regress worries?\nReply: Once we are taking the dispositions themselves to be the skills, not the underlying knowledge, it feels that we are a long way from traditional intellectualism. But the view is independently interesting, and it is a useful segue to thinking about the relationship between intellectual skills, as conceived of in this paper, and motor skills.\nI’ve already mentioned that the Bob example does not seem to fit well with Stanley and Williamson’s paradigm. And there is something suspicious about a theory of physical skill that divorces it so strongly from the physical. To be a skilled batsman requires more than dispositions to get knowledge, one might suspect. Stanley and Williamson have a reply to this suspicion. They write,\n\nConsider the difference between someone who can bench-press a maximum of 100 pounds and someone who can bench press 150 pounds. We may suppose that both employ the same technique; only brute strength makes the difference between them. Both are equally skilled ...Any view of skill must account for such cases. In particular, it must explain why strength, speed, and stamina are not themselves skills.(Stanley and Williamson 2017, 9, page references to preprint)\n\nBut even if strength is not a skill, it might be a prerequisite for a skill. A batsman whose degenerative back condition means he lacks the flexibility to deploy his trademark pull shot has lost a skill, even if he hasn’t lost any dispositions to form knowledge. There is a puzzle as to why qualitative physical differences matter so much to skill attributions why quantitative ones do not. If you can’t turn to pull the ball, you’ve lost a skill, but if a muscle strength decline reduces the power of your pull shot, your skills haven’t declined. But that difference doesn’t justify making skills entirely cognitive.\nStill, there is a cognitive angle. One central point of this paper is completely consistent with Stanley and Williamson’s picture; motor skills often require forming the right knowledge. The skilled batsman doesn’t just pick up many characteristics of the bowler’s delivery, they pick up the ones that are most relevant to the trajectory of the ball. As the Bob example shows, they also have to activate that knowledge for it really to be a skill, but that’s not a new objection.\nThere is one other cognitive aspect of motor skill that Yarrow, Brown, and Krakauer (2009) draw attention to, and which fits very nicely with the theme of this paper. It’s a specific instance of a much more wide-ranging skill. Sometimes an agent knows that in some time some evidence, drawn from a large space, will come in. She will shortly thereafter have to act in response to the evidence. She has some time to plan now. What should she do? In many such cases, backwards induction is impossible; there are too many possible pieces of evidence that could come in, and planning for each of them is a waste of resources. On the other hand, not planning at all is also a waste of the time she now has, and will lack once the evidence comes in. The solution is to do some planning. And there is a real skill involved in getting the resource allocation right, and neither wasting effort planning for unlikely scenarios, nor wasting the ability to be prepared before one needs to act.\nYarrow, Brown, and Krakauer (2009, 590–91) suggest the same thing happens at a very low level. Highly skilled athletes are making many places in advance of knowing exactly how they will act. Part of the skill involved is allocating the right resources to each of these planning activities. Many of them will ultimately be wasteful, since they are plans for eventualities that do not arise. And one failure condition is that a single plan is not selected, and the agent performs some combination of multiple plans that are worse than either one plan. That failure state is part of the evidence that there is this low-level planning going on before actions. But it is a real skill, and part of the skill is focussing on just the right things.\nSo motor skills often have as a constituent part intellectual skills. Some of those skills are closely tied to knowledge; for instance, having priors that track frequencies. Sometimes the skill involved is in focussing on the evidence that the posterior probability is maximally sensitive to, and reacting to that evidence. Sometimes the skill is not attending to evidence that is just going to be unhelpful noise in the activity in question (Yarrow, Brown, and Krakauer 2009, 589). And sometimes it is in allocating just the right resources to forward planning. All of these seem like intellectual skills, and parts of motor skills. We could try to squeeze all of them into a framework of being dispositions to form knowledge, but it seems more perspicuous to just present the plurality of ways in which the intellect and the body interact, rather than trying to find a single framework.\nObjection: Appeal to skill does not stop the regress. If we need to posit something, say a skill, that comes between the possession of knowledge and the use of knowledge in reasoning or action, then we also to posit something that comes between the possession of a skill, and the use of that skill in reasoning or action. (Compare Stanley (2011, 26)).\nReply: What I’m going to say here is similar to what Jeremy Fantl (2011) said in a response to an earlier version of Stanley’s argument, so I’ll be brief. Skills are dispositions. We don’t need to posit anything that comes between the disposition and its triggering. If a string is disposed to produce a middle C when struck, and it is struck, we don’t need to posit an extra intermediary between the striking and the note. Dispositions stop regresses.\nBut, you might insist, couldn’t the same be true of knowledge? After all, on a broadly functionalist construal of the mental, knowledge is a kind of disposition. My reply is in theory knowledge could stop such a regress, but in practice it is unlikely. An agent could be facing a problem where the possible considerations and options can be enumerated without using any particular skill, and the options are few enough that they can be each considered in turn. That is the situation an agent playing a relatively simple game might face. But it isn’t the general human condition. In practice, we face problems every moment where it requires skill to bring the right considerations to bear, at least given the processing capacities we have available.\nObjection: There are semantic arguments that attributions of know how are attributions of propositional knowledge. This shows that Ryle was wrong to draw a broad distinction between know how and know that.\nReply: I’m not making any claims about either know how or about ‘know how’. I am making some claims about skill, and those imply some claims about ‘skill’. But I’m sympathetic to the idea that reports of know how are often reports of some kind of practical propositional knowledge. I certainly haven’t offered any arguments, nor I think any considerations in the direction of an argument, against this view.\nIndeed, there are a lot of intellectualst positions that I’m not arguing against here. Anti-intellectualism is often tied up with the view that there is an important distinction between theoretical and practical fields. The arguments I’ve developed here suggest that if there is such a distinction, then proving mathematical theorems is on the ‘practical’ side. I think that’s a strange enough conclusion that it is time to change our terminology. That’s why I’ve talked about the distinction between intellectual skills and knowledge, not the distinction (if such there is) between know how and know that, or between praxis and theory.\n\n\n\n\n\n\nReferences\n\nAdams, Robert Merrihew. 1985. “Involuntary Sins.” Philosophical Review 94 (1): 3–31. https://doi.org/10.2307/2184713.\n\n\nAlston, William. 1988. “The Deontological Conception of Epistemic Justification.” Philosophical Perspectives 2: 257–99. https://doi.org/10.2307/2214077.\n\n\nBengson, John, and Marc Moffett, eds. 2011. Knowing How. Oxford: Oxford University Press.\n\n\nCarroll, Lewis. 1895. “What the Tortoise Said to Achilles.” Mind 4 (14): 278–80. https://doi.org/10.1093/mind/iv.14.278.\n\n\nCath, Yuri. 2011. “Knowing How Without Knowing That.” In Knowing How, edited by John Bengson and Marc Moffett, 113–35. Oxford: Oxford University Press.\n\n\n———. 2013. “Regarding a Regress.” Pacific Philosophical Quarterly 94 (3): 358–88. https://doi.org/10.1111/papq.12004.\n\n\nDavey, Kevin. 2011. “Idealizations and Contextualism in Physics.” Philosophy of Science 78 (1): 16–38. https://doi.org/10.1086/658093.\n\n\nDempsey, Luke, ed. 2012. Monty Python’s Flying Circus: Complete and Annotated...all the Bits. New York: Black Dog & Leventhal Publishers.\n\n\nDickie, Imogen. 2012. “Skill Before Knowledge.” Philosophy and Phenomenological Research 85 (3): 737–45. https://doi.org/10.1111/j.1933-1592.2012.00638.x.\n\n\nFantl, Jeremy. 2011. “Ryle’s Regress Defended.” Philosophical Studies 156 (1): 121–30. https://doi.org/10.1007/s11098-011-9800-8.\n\n\nFridland, Ellen. 2014. “They’ve Lost Control: Reflections on Skill.” Synthese 191 (12): 2729–50. https://doi.org/10.1007/s11229-014-0411-8.\n\n\nGinet, Carl. 1975. Knowledge, Perception and Memory. Dordrecht: Riedel.\n\n\nHadley, Frank A. 1903. “Whistler, the Man, as Told in Anecdote.” Brush & Pencil 12 (5): 334–59. https://doi.org/10.2307/25505918.\n\n\nHornsby, Jennifer. 2011. “Ryle’s Knowing How, and Knowing How to Act.” In Knowing How, edited by John Bengson and Marc Moffett, 80–98. Oxford: Oxford University Press.\n\n\nJoyce, James. 1939/2012. Finnegans Wake. Oxford World’s Classics. Oxford: Oxford University Press.\n\n\nKasparov, Garry. 2010. “The Chess Master and the Computer.” The New York Review of Books. The New York Review of Books. http://www.nybooks.com/articles/archives/2010/feb/11/the-chess-master-and-the-computer/.\n\n\nLuzzi, Federico. 2010. “Counter-Closure.” Australasian Journal of Philosophy 88 (4): 673–83. https://doi.org/10.1080/00048400903341770.\n\n\nMeyer, Robert K. 1987. “God Exists!” Noûs 21 (3): 345–61. https://doi.org/10.2307/2215186.\n\n\nPavese, Carlotta. 2013. “The Unity and Scope of Knowledge.” PhD thesis, Rutgers University, New Brunswick.\n\n\nRyan, Sharon. 2003. “Doxastic Compatibilism and the Ethics of Belief.” Philosophical Studies 114 (1-2): 47–79. https://doi.org/10.1023/A:1024409201289.\n\n\nRyle, Gilbert. 1945. “Knowing How and Knowing That.” Proceedings of the Aristotelian Society 46 (1): 1–16. https://doi.org/10.1093/aristotelian/46.1.1.\n\n\n———. 1949. The Concept of Mind. New York: Barnes; Noble.\n\n\nSmith, Angela M. 2005. “Responsibility for Attitudes: Activity and Passivity in Mental Life.” Ethics 115 (2): 236–71. https://doi.org/10.1086/426957.\n\n\nStalnaker, Robert. 2012. “Intellectualism and the Objects of Knowledge.” Philosophy and Phenomenological Research 85 (3): 754–61. https://doi.org/10.1111/j.1933-1592.2012.00640.x.\n\n\nStanley, Jason. 2011. Know How. Oxford: Oxford University Press.\n\n\n———. 2012. “Replies to Dickie, Schroeder and Stalnaker.” Philosophy and Phenomenological Research 85 (3): 762–78. https://doi.org/10.1111/j.1933-1592.2012.00641.x.\n\n\nStanley, Jason, and Timothy Williamson. 2017. “Skill.” Noûs 51 (4): 713–26. https://doi.org/10.1111/nous.12144.\n\n\nSteup, Matthias. 2008. “Doxastic Freedom.” Synthese 161 (3): 375–92. https://doi.org/10.1007/s11229-006-9090-4.\n\n\nStrevens, Michael. 2008. Depth: An Account of Scientific Explanations. Cambridge, MA: Harvard University Press.\n\n\nTsai, Cheng-hung. 2014. “The Structure of Practical Expertise.” Philosophia 42 (2): 539–54. https://doi.org/10.1007/s11406-013-9513-7.\n\n\nWarfield, Ted A. 2005. “Knowledge from Falsehood.” Philosophical Perspectives 19: 405–16. https://doi.org/10.1111/j.1520-8583.2005.00067.x.\n\n\nWiggins, David. 2009. “Knowing How to and Knowing That.” In Wittgenstein and Analytic Philosophy: Essays for p. M. S. Hacker, edited by Hans-Johann Glock and John Hyman, 263–77. Oxford: Oxford University Press.\n\n\nYarrow, Kielan, Peter Brown, and John W. Krakauer. 2009. “Inside the Brain of an Elite Athlete: The Neural Processes That Support High Achievement in Sports.” Nature Reviews Neuroscience 10 (8): 585–96. https://doi.org/10.1038/nrn2672.\n\nCitationBibTeX citation:@article{weatherson2017,\n  author = {Weatherson, Brian},\n  title = {Intellectual {Skill} and the {Rylean} {Regress}},\n  journal = {Philosophical Quarterly},\n  volume = {67},\n  number = {267},\n  pages = {370-386},\n  date = {2017-04},\n  doi = {10.1093/pq/pqw051},\n  langid = {en}\n}"
  },
  {
    "objectID": "posts/review-moral-uncertainty/index.html",
    "href": "posts/review-moral-uncertainty/index.html",
    "title": "Review of “Moral Uncertainty and Its Consequences”",
    "section": "",
    "text": "For many years now, Peter Singer has been arguing that we should not eat meat, and that we should give more money to famine relief. Many have been convinced, but many more remain sceptical. However, on one point most of us would agree: the actions that Singer recommends here are certainly morally permissible. One rarely feels a twang of moral doubt when eating tofu curry or writing cheques to Oxfam. Even if we do not find Singer totally convincing, we may still feel this moral doubt when eating sirloin, or spending frivolously rather than charitably. If we accept the main principle in Ted Lockhart’s book Moral Uncertainty and Its Consequences, these twangs of moral doubt should be sufficient to make us amend our behaviour.\nThe main principle Lockhart endorses is that we should perform actions that we are maximally confident are morally permissible. We might be quite confident that having the sirloin is morally permissible, but if we are not certain, and we are certain the tofu is permissible, we should stick to tofu. Similarly, if we are certain that large donations to famine relief are permissible, and not certain that not making these donations is permissible, the chequebook should come out. The principle is not just for left-wingers. As Lockhart notes, approvingly, it can also be used in anti-abortion arguments. In most cases, not having an abortion is almost certainly permissible. Perhaps there is an exception for cases of extreme fetal deformity, but not in everyday cases. So if the woman considering an abortion wants to do the action that is most probably morally permissible, and has any doubts about the permissibility of the procedure, she should decline the abortion.\nThe bulk of Lockhart’s book is devoted to case studies where this principle is deployed, and amendments to the principle generated by considerations of these cases are adopted. The cases include abortion, patient confidentiality, Roe v Wade and, briefly, charitable giving. The theme behind the studies is that even if people cannot come to agreement on what is morally right, they can come to agreement on what should be done according to the principle, at least as variously amended, and this should be sufficient to provide recommendations for action. Lockhart stresses that if this line of reasoning is correct, then applied ethicists can provide good advice on practical action without conclusively resolving apparently intractable ethical problems.\nThere are three main amendments Lockhart suggests to the principle. First, he suggests that if moral rightness comes in degrees, we should maximise the expected moral rightness of our actions, rather than the probability that we are doing the right thing. Secondly, in situations where we cannot work out which action maximises expected rightness, because perhaps we do not have perfect access to the relevant subjective probabilities, we should choose the action which most probably maximises expected rightness, or more generally has the highest expected expected degree of moral rightness. And thirdly, he says that we should maximise the expected rightness of courses of action, rather than of individual actions. One might quibble with these amendments, particularly I think with the second, but they do not seem to affect the core philosophical issues.\nThe principle has some rather striking consequences, so striking we might fear for its refutation by a quick modus tollens. Lockhart, of course, does not think this is so. He does not discuss the vegetarianism issue, and endorses the anti-abortion implications, but argues that the principle need not have such striking implications concerning charitable giving. He notes that for some people, those who think it probable enough that substantial charitable giving is a very bad thing to do, because we have such strong obligations to ourselves and those nearest and dearest, his principle does not recommend such giving (109).\nThere is a more direct reason for thinking the principle stands in need of some further clarification and defence. It is rather unclear what kind of norm the principle is stating, and hence what force the should in it is has. Lockhart says it is a norm of rational action, but it seems in practice to be neither that, nor a moral norm. To see this, consider the following case where someone clearly does not follow the principle. While on her way to visit a sick friend in hospital, Jane is convinced by a fellow subway rider that morality requires an impersonal concern for the whole world. She is convinced that morality requires that she not visit her friend, but instead find the patient most in need of a visitor, and see them. But when she gets to the hospital, her new moral belief is not strong enough to overcome her desire to visit her friend in need, which, feeling a little guilty, she does.\nAssuming that Jane’s newfound moral beliefs are wrong, and that in fact she did the right thing, what criticisms can we make of her action? Not that it was immoral, because she did the right thing, visiting her sick friend, and she acted for the right reason, acting out of care for her friend. Nor, it seems, that it was prudentially irrational, for she did what she believed would best satisfy her desires. Perhaps the fact that her new moral beliefs were not sufficiently motivating indicates a lack of resolve, or even a weakness of will, but alternatively one might think that Jane displayed commendable, and virtuous, common sense in not abandoning her friend precipitously. In any case, I doubt Jane’s action cannot be criticised, even if her resolve can be. Since Jane clearly violated Lockhart’s principle, she did not act in the way she thought most likely to be morally permissible, but her action seems immune from criticism, that suggests the principle should not be an action guiding norm.\nOne might argue that Jane has a moral responsibility to desire to do the right thing, and if she had this desire, she would have been rationally required to not visit her friend. If one believes in such a responsibility, then one will think that Jane acted against a desire she should have, that she was, at best, lucky that she did the right thing, and hence she was irrational. Lockhart compares such agents, who do the right thing against their better judgement, to gamblers who bet their life savings on unlikely, but ultimately successful, outcomes. (34)\nThis line of reasoning, however, ultimately does not provide grounds for criticising Jane. A moral agent may well have a moral responsibility to desire to do the things that happen to be the right things to do. For example, she may well have a responsibility to want to visit her sick friends, and to help those in need, and not cause harm to others. But she does not have a responsibility to want to do the right thing, whatever it turns out to be. Indeed, she would be a worse moral agent if many of her actions were motivated by such a desire. She should want to visit her friend because she cares about her friend, not because it is, in the abstract, the right thing to do. Michael Smith has described the desire to do the right thing, whatever it turns out to be, as a moral fetish, and this often seems appropriate. (The Moral Problem, Oxford: Blackwell, 1994, p. 76)\nIt is no discredit to Jane that she lacks this general desire, and in some cases it may be a virtue. If Jane has the general desire, if in Smith’s terminology she is a moral fetishist, then she may be prudentially required to follow Lockhart’s principle, but not otherwise, and she is not required, by any normative standard, to be a moral fetishist. If Jane (virtuously) does not have that general desire to do the right thing, whatever it turns out to be, then she is importantly dissimilar to the gambler, who does (and should) desire to bet on the successful outcome, whatever it turns out to be.\nWhatever the merits of Lockhart’s main principle, his approach raises several fascinating theoretical questions. For example, there is a substantial literature on what the motivational effects of coming to hold a new moral view are, and what they should be. But what is, and what should be, the motivational effects of coming to hold, say, that it is more probable than not that meat eating is permissible? From a different angle, if moral attitudes are more like desires than like beliefs, as some expressivists suggest, then can we even have the attitude that it is more probable than not that meat eating is permissible? Although in general Lockhart says little directly on these theoretical questions, it is a great service to show how they arise.\nIf Lockhart’s main principle is correct, it has rather radical implications for how applied ethics is practised. Even if it is not, consideration of the issues Lockhart raises may provide a novel and valuable outlook on some familiar theoretical questions.\n\n\n\nCitationBibTeX citation:@misc{weatherson2002,\n  author = {Weatherson, Brian},\n  title = {Review of “{Moral} {Uncertainty} and {Its} {Consequences}”},\n  volume = {111},\n  number = {443},\n  pages = {693-696},\n  date = {2002-07},\n  doi = {10.1093/mind/111.443.693},\n  langid = {en}\n}"
  },
  {
    "objectID": "posts/mfp/morality-fiction-and-possibility.html",
    "href": "posts/mfp/morality-fiction-and-possibility.html",
    "title": "Morality, Fiction and Possibility",
    "section": "",
    "text": "1 Four Puzzles\nSeveral things go wrong in the following story.\n\nPublished in Philosophers’ Imprint 4:3.\n\n\nDeath on a Freeway\nJack and Jill were arguing again. This was not in itself unusual, but this time they were standing in the fast lane of I-95 having their argument. This was causing traffic to bank up a bit. It wasn’t significantly worse than normally happened around Providence, not that you could have told that from the reactions of passing motorists. They were convinced that Jack and Jill, and not the volume of traffic, were the primary causes of the slowdown. They all forgot how bad traffic normally is along there. When Craig saw that the cause of the bankup had been Jack and Jill, he took his gun out of the glovebox and shot them. People then started driving over their bodies, and while the new speed hump caused some people to slow down a bit, mostly traffic returned to its normal speed. So Craig did the right thing, because Jack and Jill should have taken their argument somewhere else where they wouldn’t get in anyone’s way.\n\n\nPicture via Creative Commons.\n\nThe last sentence raises a few related puzzles. Intuitively, it is not true, even in the story, that Craig’s murder was morally justified. What the narrator tells us here is just false. That should be a little surprising. We’re being told a story, after all, so the storyteller should be an authority on what’s true in it. Here we hearers get to rule on which moral claims are true and false, not the author. But usually the author gets to say what’s what. The action takes place in Providence, on Highway 95, just because the author says so. And we don’t reject those claims in the story just because no such murder has ever taken place on Highway 95. False claims can generally be true in stories. Normally, the author’s say so is enough to make it so, at least in the story, even if what is said is really false. The first puzzle, the alethic puzzle, is why authorial authority breaks down in cases like Death on the Freeway. Why can’t the author just make sentences like the last sentence in Death true in the story by saying they are true? At this stage I won’t try and give a more precise characterisation of which features of Death lead to the break down of authorial authority, for that will be at issue below.\n\nI’ve spoken to practically everyone I know about the issues here, and a full list of thanks for useful advice, suggestions, recommendations, criticisms, counterexamples and encouragement would double the size of the paper. If I thank philosophy departments rather than all the individuals in them it might cut the size a little, so thanks to the departments at Brown, UC Davis, Melbourne, MIT and Monash. Thanks also to Kendall Walton, Tamar Gendler and two referees for Philosophers’ Imprint. The most useful assistance came from Wolfgang Schwarz and especially Tyler Doggett, without whose advice this could never have been written, and to George Wilson, who prevented me from (keeping on) making a serious error of over-generalisation.\n\nThe second puzzle concerns the relation between fiction and imagination. Following Kendall Walton (1990), it is common to construe fictional works as invitations to imagine. The author requests, or suggests, that we imagine a certain world. In Death we can follow along with the author for most of the story. We can imagine an argument taking place in peak hour on Highway 95. We can imagine this frustrating the other drivers. And we can imagine one of those drivers retaliating with a loaded gun. What we cannot, or at least do not, imagine is that this retaliation is morally justified. There is a limit to our imaginative ability here. We refuse, fairly systematically, to play along with the author here. Call this the imaginative puzzle. Why don’t we play along in cases like Death? Again, I won’t say for now which cases are like Death.\nThe third puzzle concerns the phenomenology of Death and stories like it. The final sentence is striking, jarring in a way that the earlier sentences are not. Presumably this is closely related to the earlier puzzles, though I’ll argue below that the cases that generate this peculiar reaction are not identical with cases that generate alethic or imaginative puzzles. So call this the phenomenological puzzle.\nFinally, there is a puzzle that David Hume (1757) first noticed. Hume suggested that artistic works that include morally deviant claims, moral claims that wouldn’t be true were the descriptive aspects of the story true, are thereby aesthetically compromised. Why is this so? Call that the aesthetic puzzle. I will have nothing to say about that puzzle here, though hopefully what I have to say about the other puzzles will assist in solving it.\nI’m going to call sentences that raise the first three puzzles puzzling sentences. Eventually I’ll look at the small differences between those three puzzles, but for now we’ll focus on what they have in common. The puzzles, especially the imaginative puzzle, have become quite a focus of debate in recent years. The aesthetic puzzle is raised by David Hume (1757), and is discussed by Kendall Walton (1994) and Richard Moran (1995). Walton and Moran also discuss the imaginative and alethic puzzles, and they are the focus of attention in recent work by Tamar Szabó Gendler (2000), Gregory Currie (2002) and Stephen Yablo (2002). My solution to the puzzles is best thought of as a development of some of Walton’s ‘sketchy story’ (to use his description). Gendler suggests one way to develop Walton’s views, and shows it leads to an unacceptable solution, because it leads to mistaken predictions. I will argue that there are more modest developments of Walton’s views that don’t lead to so many predictions, and in particular don’t lead to mistaken predictions, but which still say enough to solve the puzzles.\n\n\n2 The Range of the Puzzles\nAs Walton and Yablo note, the puzzle does not only arise in connection with thin moral concepts. But it has not been appreciated how widespread the puzzle is, and getting a sense of this helps us narrow the range of possible solutions.\nSentences in stories attributing thick moral concepts can be puzzling. If my prose retelling of Macbeth included the line “Then the cowardly Macduff called on the brave Macbeth to fight him face to face,” the reader would not accept that in the story Macduff was a coward. If my retelling of Hamlet frequently described the young prince as decisive, the reader would struggle to go along with me imaginatively. Try imagining Hamlet doing exactly what he does, and saying exactly what he says, and thinking what he thinks, but always decisively. For an actual example, it’s easy to find the first line in Bob Dylan’s Ballad of Frankie Lee and Judas Priest, that the titular characters ‘were the best of friends’ puzzling in the context of how Frankie Lee treats Judas Priest later in the song. It isn’t too surprising that the puzzle extends to the thick moral concepts, and Walton at least doesn’t even regard these as a separate category.\nMore interestingly, any kind of evaluative sentence can be puzzling. Walton and Yablo both discuss sentences attributing aesthetic properties. (Yablo 2002, 485) suggests that a story in which the author talks about the sublime beauty of a monster truck rally, while complaining about the lack of aesthetic value in sunsets, is in most respects like our morally deviant story. The salient aesthetic claims will be puzzling. Note that we are able to imagine a community that prefers the sight of a ‘blood bath death match of doom’ (to use Yablo’s evocative description) to sunsets over Sydney Harbour and it could certainly be true in a fiction that such attitudes were commonplace. But that does not imply that those people could be right in thinking the trucks are more beautiful. (Walton 1994, 43–44) notes that sentences describing jokes that are actually unfunny as being funny will be puzzling. We get to decide what is funny, not the author.\nWalton and Yablo’s point here can be extended to epistemic evaluations. Again it isn’t too hard to find puzzling examples when we look at attributions of rationality or irrationality.\n\nAlien Robbery\nSam saw his friend Lee Remnick rushing out of a bank carrying in one hand a large bag with money falling out of the top and in the other hand a sawn-off shotgun. Lee Remnick recognised Sam across the street and waved with her gun hand, which frightened Sam a little. Sam was a little shocked to see Lee do this, because despite a few childish pranks involving stolen cars, she’d been fairly law abiding. So Sam decided that it wasn’t Lee, but really a shape-shifting alien that looked like Lee, that robbed the bank. Although shape-shifting aliens didn’t exist, and until that moment Sam had no evidence that they did, this was a rational belief. False, but rational.\n\nThe last two sentences of Alien Robbery are fairly clearly puzzling.\nSo far all of our examples have involved normative concepts, so one might think the solution to the puzzle will have something to do with the distinctive nature of normative concepts, or with their distinctive role in fiction. Indeed, Gendler’s and Currie’s solutions have just this feature. But sentences that seem somewhat removed from the realm of the normative can still be puzzling. (It is of course contentious just where the normative/non-normative barrier lies. Most of the following cases will be regarded as involving normative concepts by at least some philosophers. But I think few people will hold that all of the following cases involve normative concepts.)\nAttributions of mental states can, in principle, be puzzling. If I retell Romeo and Juliet, and in this say ‘Although he believed he loved Juliet, and acted as if he did, Romeo did not really love Juliet, and actually wanted to humiliate her by getting her to betray her family’, that would I think be puzzling. This example is odd, because it is not obviously impossible that Romeo could fail to love Juliet even though he thought he loved her (people are mistaken about this kind of thing all the time) and acted as if he did (especially if he was trying to trick her). But given the full detail of the story, it is impossible to imagine that Romeo thought he had the attitudes towards Juliet he is traditionally thought to have, and he is mistaken about this.\nAttributions of content, either mental content or linguistic content, can be just as puzzling. The second and third sentences in this story are impossible to imagine, and false even in the story.\n\nCats and Dogs\nRhodisland is much like a part of the actual world, but with a surprising difference. Although they use the word ‘cat’ in all the circumstances when we would (i.e. when they want to say something about cats), and the word ‘dog’ in all the circumstances we would, in their language ‘cat’ means dog and ‘dog’ means cat. None of the Rhodislanders are aware of this, so they frequently say false things when asked about cats and dogs. Indeed, no one has ever known that their words had this meaning, and they would probably investigate just how this came to be in some detail, if they knew it were true.\n\nA similar story can be told to demonstrate how claims about mental content can be puzzling. Perhaps these cases still involve the normative. Loving might be thought to entail special obligations and Kripke (1982) has argued that content is normative. But we are clearly moving away from the moral, narrowly construed.\nStephen Yablo recently suggested that certain shape predicates generate imaginative resistance. These predicates are meant to be special categories of a broader category that we’ll discuss further below. Here’s Yablo’s example.\n\nGame Over\nThey flopped down beneath the giant maple. One more item to find, and yet the game seemed lost. Hang on, Sally said. It’s staring us in the face. This is a maple tree we’re under. She grabbed a five-fingered leaf. Here was the oval they needed! They ran off to claim their prize. (Yablo 2002, 485, title added)\n\nThere’s a potential complication in this story in that one might think that it’s metaphysically impossible that maple trees have ovular leaves. That’s not what is meant to be resisted, and I don’t think is resisted. What is resisted is that maple leaves have their distinctive five-fingered look, that the shape of the leaf Sally collects is like that (imagine I demonstrate a maple leaf here) and that its shape be an oval.\nFewer people may care about the next class of cases, or have clear intuitions about them, but if one has firm ontological beliefs, then deviant ontological claims can be puzzling. I’m a universalist about mereology, at least with respect to ordinary concrete things, so I find many of the claims in this story puzzling.\n\nWiggins’ World\nThe Hogwarts Express was a very special train. It had no parts at all. Although you’d be tempted to say that it had carriages, an engine, seats, wheels, windows and so on, it really was a mereological atom. And it certainly had no temporal parts - it wholly was wherever and whenever it was. Even more surprisingly, it did not enter into fusions, so when the Hogwarts Local was linked to it for the first few miles out of Kings Cross, there was no one object that carried all the students through north London.\n\nI think that even in fictions any two concrete objects have a fusion. So the Hogwarts Express and the Hogwarts Local have a fusion, and when it is a connected object it is commonly called a train. I know how to describe a situation where they have no fusion (I did so just above) but I have no idea how to imagine it, or make it true in a story.\nMore generally, there are all sorts of puzzling sentences involving claims about constitution. These I think are the best guide to a solution to the puzzle.\n\nA Quixotic Victory\n–What think you of my redecorating Sancho?\n–It’s rather sparse, said Sancho.\n–Sparse. Indeed it is sparse. Just a television and an armchair.\n–Where are they, Señor Quixote? asked Sancho. All I see are a knife and fork on the floor, about six feet from each other. A sparse apartment for a sparse mind. He said the last sentence under his breath so Quixote would not hear him.\n–They might look like a knife and fork, but they are a television and an armchair, replied Quixote.\n–They look just like the knife and fork I have in my pocket, said Sancho, and he moved as to put his knife and fork besides the objects on Quixote’s floor.\n–Please don’t do that, said Quixote, for I may be unable to tell your knife and fork from my television and armchair.\n–But if you can’t tell them apart from a knife and fork, how could they be a television and an armchair?\n–Do you really think being a television is an observational property? asked Quixote with a grin.\n–Maybe not. OK then, how do you change the channels? asked Sancho.\n–There’s a remote.\n–Where? Is it that floorboard?\n–No, it’s at the repair shop, admitted Quixote.\n–I give up, said Sancho.\n\nSancho was right to give up. Despite their odd appearance, Quixote’s items of furniture really were a television and an armchair. This was the first time in months Quixote had won an argument with Sancho.\n\nQuixote is quite right that whether something is a television is not determined entirely by how it looks. A television could be indistinguishable from a non-television. Nonetheless, something indistinguishable from a knife is not a television. Not in this world, and not in the world of Victory either, whatever the author says. For whether something is a television is determined at least in part by how it looks, and while it is impossible to provide a non-circular constraint on how a television may look, it may not look like a common knife.\nIn general, if whether or not something is an F is determined in part by ‘lower-level’ features, such as the shape and organisation of its parts, and the story specifies that the lower-level features are incompatible with the object being an F, it is not an F in the fiction. Suitably generalised and qualified, I think this is the explanation of all of the above categories. To understand better what the generalisations and qualifications must be, we need to look at some cases that aren’t like Death, and some alternative explanations of what is going on in Death.\nSentences that are intentional errors on the part of storytellers are not puzzling in our sense. We will use real examples for the next few pages, starting with the opening line of Joyce’s most famous short story.\n\nThe Dead\nLily, the caretaker’s daughter, was literally run off her feet.\n(Joyce 1914/2000, 138)\n\nIt isn’t true that Lily is literally run off her feet. She is run off her feet by the incoming guests, and if you asked her she may well say she was literally run off her feet, but this would reveal as much about her lack of linguistic care as about her demanding routine. Is this a case where the author loses authority over what’s true in the story? No, we are not meant to read the sentence as being true in the story, but being a faithful report of what Lily (in the story) might say to herself. In practice it’s incredibly difficult to tell just when the author intends a sentence to be true in the story, as opposed to being a report of some character’s view of what is true. (See Holton (1997) for an illustration of the complications this can cause.) But since we are operating in theory here, we will assume that problem solved. The alethic puzzle only arises when it is clear that the author intends that p is true in her story, but we think p is not true. The imaginative puzzle only arises when the author invites us to imagine p, but we can not, or at least do not. Since Joyce does not intend this sentence to be true in The Dead, nor invites us to imagine it being true, neither puzzle arises. What happens to the phenomenological puzzle in cases like these is a little more interesting, and I’ll return to that in .\nJust as intentional errors are not puzzling, careless errors are not puzzling. Writing a full length novel is a perilous business. Things can go wrong. Words can be miswritten, mistyped or misprinted at several different stages. Sometimes the errors are easily detectable, sometimes they are not, especially when they concern names. In one of the drafts of Ulysses, Joyce managed to write “Connolly Norman” in place of “Conolly Norman”. Had that draft being used for the canonical printing of the work, it would be tempting to say that we had another alethic puzzle. For the character named here is clearly the Superintendent of the Richmond District Lunatic Asylum, and his name had no double-‘n’, so in the story there is no double-‘n’ either.1\n1 For details on the spelling of Dr Norman’s name, and the story behind it, see Kidd (1988). The good doctor appears on page 6 of Joyce (1922/1993).2 At least, they will be ignored if it is clear they are errors. If there seems to be a method behind the misspellings, as in Ulysses there frequently is, the matter is somewhat different, and somewhat more difficult.\nTyler Doggett has argued that these cases are more similar to paradigm cases of imaginative resistance than I take them to be. Indeed, I would not have noticed the problems they raise without reading his paper. It may be a shortcoming of my theory here that I have to set questions about whether these sentences are puzzling to one side and assume an ideal proof-reader.Here we do have an instance where what is true in the story differs from the what is written in the text. But this is not a particularly interesting deviation. To avoid arcane discussions of typographical errors, we will that in every case we possess an ideal version of the text, and are comparing it with the author’s intentions. Slip-ups that would be detected by a careful proof-reader, whether they reveal an unintended divergence between word and world, as here, or between various parts of the text, as would happen if Dr Norman were not named after a real person but had his name spelled differently in parts of the text, will be ignored.2\nNote two ways in which the puzzles as I have stated them are narrower than they first appear. First, I am only considering puzzles that arise from a particular sentence in the story, intentionally presented in the voice of an authoritative narrator. We could try and generalise, asking why it is that we sometimes (but not always) question the moral claims that are intended to be tacit in a work of fiction. For instance, we might hold that for some Shakespearean plays there are moral propositions that Shakespeare intended to be true in the play, but which are not in fact true. Such cases are interesting, but to keep the problem of manageable proportions I won’t explicitly discuss them here. (I believe the solution I offer here generalises to those cases, but I won’t defend that claim here.) Second, all the stories I have discussed are either paragraph-long examples, or relatively detachable parts of longer stories. For all I’ve said so far, the puzzle may be restricted to such cases. In particular, it might be the case that a suitably talented author could make it true in a story that killing people for holding up traffic is morally praiseworthy, or that a television is phenomenally and functionally indistinguishable from a knife. What we’ve seen so far is just that an author cannot make these things true in a story simply by saying they are true.3 I leave open the question of whether a more subtle approach could make those things true in a fiction. Similarly, I leave it open whether a more detailed invitation to imagine that these things are true would be accepted. All we have seen so far is that simple direct invitations to imagine these things are rejected, and it feels like we could not accept them.\n3 Thanks here to George Wilson for reminding me that we haven’t shown anything stronger than that.\n\n3 An Impossible Solution\nHere’s a natural solution to the puzzles, one that you may have been waiting for me to discuss. The alethic puzzle arises because only propositions that are possibly true can be true in a story, or can be imagined. The latter claim rests on the hypothesis that we can imagine only what is possible, and that we resist imagining what is impossible.\nThis solution assumes that it is impossible that killing people for holding up freeway traffic is the right thing to do. Given enough background assumptions, that is plausible. It is plausible, that is, that the moral facts supervene on the non-moral facts. And the supervenience principle here is quite a strong one - in every possible world where the descriptive facts are thus and so, the moral facts are the same way.4 If we assume the relevant concept of impossibility is truth in no possible worlds, we get the nice result that the moral claims at the core of the problem could not possibly be true.\n4 Arguably the relevant supervenience principle is even stronger than that. To use some terminology of Stephen Yablo’s, there’s no difference in moral facts without a difference in non-moral facts between any two counteractual worlds, as well as between any two counterfactual worlds. This might be connected to some claims I will make below about the relationship between the normative and the descriptive.Several authors have discussed solutions around this area. Kendall Walton (1994) can easily be read as endorsing this solution, though Walton’s discussion is rather tentative. Tamar Szabó Gendler rejects the theory, but thinks it is the most natural idea, and spends much of her paper arguing against this solution. As those authors, and Gregory Currie (2002), note, the solution needs to be tidied up a little before it will work for the phenomenological and imaginative puzzles. (It is less clear whether the tidying matters to the alethic puzzle.) For one thing, there is no felt asymmetry between a story containing, “Alex proved the twin primes theorem,” and one containing, “Alex found the largest pair of twin primes,” even though one of them is impossible. Since we don’t know which it is, the impossibility of the false one cannot help us here. So the theory must be that it is believed impossibilities that matter, for determining what we can imagine, not just any old impossibilities. Presumably impossibilities that are not salient will also not prevent imagination.\nEven thus qualified, the solution still overgenerates, as Gendler noted. There are stories that are not puzzling in any way that contain known salient impossibilities. Gendler suggests three kinds of cases of this kind, of which I think only the third clearly works. The first kind of case is where we have direct contradictions true in the story. Gendler suggests that her Tower of Goldbach story, where seven plus five both does and does not equal twelve, is not puzzling. Graham Priest (1997) makes a similar point with a story, Sylvan’s Box, involving an empty box with a small statue in one corner. These are clear cases of known, salient impossibility, but arguably are not puzzling in any respect. (There is a distinction between the puzzles though. It is very plausible to say that it’s true in Priest’s story that there’s an empty box with a small statue in one corner. It is less plausible to say we really can imagine such a situation.) Opinion about such cases tends to be fairly sharply divided, and it is not good I suspect to rest too much weight on them one way or the other.\nThe second kind of case Gendler suggests is where we have a distinctively metaphysical impossibility, such as a singing snowman or a talking playing card. Similar cases as discussed by Alex Byrne (1993) who takes them to raise problems for David Lewis’s (1978) subjunctive conditionals account of truth in fiction. If we believe a strong enough kind of essentialism, then these will be impossible, but they clearly do not generate puzzling stories. For a quick proof of this, note that Alice in Wonderland is not puzzling, but several essentialist theses are violated there. It is true in Alice in Wonderland, for example, that playing cards plant rose trees.\nBut these examples don’t strike me as particularly convincing either. For one thing, the essentialism assumed here may be wrong. For another, the essentialism might not be both salient and believed to be right, which is what is needed. And most importantly, we can easily reinterpret what the authors are saying in order to be make the story possibly true. We can assume, for example, that the rosebush planting playing cards are not playing cards as we know them, but roughly human-shaped beings with playing cards for torsos. Gendler and Byrne each say that this is to misinterpret the author, but I’m not sure this is true. As some evidence, note that the authorised illustrations in Alice tend to support the reinterpretations.5\n5 Determining whether this is true in all such stories would be an enormous task, I fear, and somewhat pointless given the next objection. If anyone wants to say all clearly impossible statements in fiction are puzzling, I suspect the best strategy is to divide and conquer. The most blatantly impossible claims are most naturally fit for reinterpretation, and the other claims rest on an essentialism that is arguably not proven. I won’t try such a massive defence of a false theory here.Gendler’s third case is better. There are science fiction stories, especially time travel stories, that are clearly impossible but which do not generate resistance. Here’s two such stories, the first lightly modified from a surprisingly popular movie, and the second lifted straight from a very popular source.\n\nBack to the Future\\(^\\prime\\)\nMarty McFly unintentionally travelled back in time to escape some marauding Libyan terrorists. In doing so he prevented the chance meeting which had, in the timeline that had been, caused his father and mother to start dating. Without that event, his mother saw no reason to date the unattractive, boring nerdy kid who had been, in a history that no longer is, Marty’s father. So Marty never came into existence. This was really a neat trick on Marty’s part, though he was of course no longer around to appreciate it. Some people manage to remove themselves from the future of the world by foolish actions involving cars. Marty managed to remove himself from the past as well.\nThe Restaurant at the End of the Universe\nThe Restaurant at the End of the Universe is one of the most extraordinary ventures in the entire history of catering.\nIt is built on the fragmented remains of an eventually ruined planet which is enclosed in a vast time bubble and projected forward in time to the precise moment of the End of the Universe.\nThis is, many would say, impossible.\n…\nYou can visit it as many times as you like … and be sure of never meeting yourself, because of the embarrassment this usually causes.\nThis, even if the rest were true, which it isnt, is patently impossible, say the doubters.\nAll you have to do is deposit one penny in a savings account in your own era, and when you arrive at the End of Time the operation of compound interest means that the fabulous cost of your meal has been paid for.\nThis, many claim, is not merely impossible but clearly insane. (Adams 1980, 213–14)\n\nNeither of these are puzzling. Perhaps it’s hard to imagine the last couple of sentences of the McFly story, but everything the respective authors say is true in their stories. So the impossibility theory cannot be right, because it overgenerates, just as Gendler said.\nRecently Kathleen Stock (2003) has argued that one of the assumptions that Gendler makes, specifically that it isn’t true that “a judgement of conceptual impossibility renders a scenario unimaginable” (Gendler 2000, 66) is false. Even if Stock is right, this doesn’t threaten the kind of response that I have (following Gendler) offered to the puzzles. But actually there are a few reasons to doubt Stock’s reply. I’ll discuss these points in order.\nIt isn’t entirely clear from Stock’s discussion what she is taking a conceptual impossibility to be. I think it is a proposition of the form Some F is a G (or That F is a G, or something of this sort) where it is constitutive of being an F that the F is not a G. There is no positive characterisation of conceptual impossibility in Stock’s paper, but it is clearly meant to be something stronger than mere impossibility, or a priori falsehood. In any case, most of the core arguments turn on worries about allegedly deploying a concept while refusing to draw inferences that are constitutive of that concept, so the kind of definition I’ve offered above seems to be on the right track.\nNow if this is the case then Stock has no objection to the imaginability of the two stories I offered that involve known and salient impossibilities. For neither of these stories includes a conceptual impossibility in this sense. So even if conceptual impossibilities cannot be imagined, some impossibilities can be imagined. (And at this point what holds for imagination also holds for truth in fiction.)\nWhile this suffices as a response to the particular claims Stock makes, it might be thought it undercuts the objection I have made to the impossible solution. For it might be thought that what is wrong with the puzzling sentences just is that they represent conceptual impossibilities in this sense, and we have no argument that these can be imagined, or true in fiction. This is not too far removed from the actual solution I will offer, so it is a serious worry. The problem with this line is that not all of our puzzles are conceptual impossibilities. It isn’t constitutive of being a television that a thing is phenomenally or functionally distinguishable from a knife, but the claim in Victory that some television is not phenomenally or functionally distinguishable from a knife is puzzling. Even in our core cases, of morally deviant claims in fiction, there need not be any conceptual impossibilities. As R. M. Hare (1951) pointed out long ago, people with very different moral beliefs could have in common the concept GOOD. Arguably, someone who thinks that what Craig does in Death is good is morally confused, not conceptually confused. So whether Gendler or Stock is right about the imaginability of conceptual impossibility is neither here nor there with respect to these puzzles.\nHaving said that, there are some reasons to doubt Stock’s argument. One of her moves is to argue that we couldn’t imagine conceptual impossibilities because we can’t believe conceptual impossibilities. But as Sorensen (2001) persuasively argues, we can believe conceptual impossibilities. One of Sorensen’s arguments, lightly modified, helps us respond to another of Stock’s arguments. Stock notes, rightly, that we shouldn’t take the fact that it seems we can imagine impossibilities to be conclusive evidence we can do so. After all, we are wrong about whether things are as they seem all the time. But this might be a special case. I think that if it seems to be the case that p then we can imagine that p. And Stock agrees it seems to be the case that we can imagine conceptual impossibilities. So we can imagine that we can imagine conceptual impossibilities. Hence it can’t be a conceptual impossibility that we can imagine at least one conceptual impossibility. This doesn’t tell against the claim that it is some other kind of impossibility, though as we’ll see Stock’s main argument rests on considerations about the conceptual structure of imagination, so it isn’t clear how she could argue for this.\nThe main argument Stock offers is that no account of how concepts work are compatible with our imagining conceptual impossibilities. Her argument that atomist theories of concepts (as in Fodor (1998)) are incompatible with imagining conceptual impossibilities isn’t that persuasive. She writes that “clearly it is not the case that imagining”the cow jumped over the moon” stands in a lawful relation to the property of being a cow (let alone the property of [being] a cow jumping over the moon. Imagining by its very nature is resistant to any attempt to incorporate it into an externalist theory of content” (2003, 114). But this isn’t clear at all. When I imagine going out drinking with Bill Clinton there is, indeed there must be, some kind of causal chain running back from my imagining to Bill Clinton himself. If there was not, I’d at most be imagining going out drinking with a guy who looks a lot like Bill Clinton. Perhaps it isn’t as clear, but when I imagine that a cow (and not just a zebra disguised to look like a cow) is jumping over the moon it’s nomologically necessary that there’s a causal chain of the right kind stretching back to actual cows. And it’s arguable that the concept I deploy in imagining that a cow (a real cow) is jumping over the moon just is the concept whose content is fixed by the lawful connections between various cows and my (initial) deployment of it. So I don’t see why a conceptual atomist should find this kind of argument convincing.\nStock’s response to Gendler was presented at a conference on Imagination and the Arts at Leeds in 2001, and at the same conference Derek Matravers (2003) offered an alternative solution to the alethic puzzle. Although it does not rest on claims about impossibility, it also suffers from an overgeneration problem. Matravers suggests that in at least some fictions, we treat the text as a report by a (fictional) narrator concerning what is going on in a faraway land. Now in reality when we hear reports from generally trustworthy foreign correspondents, we are likely to believe their descriptive claims about the facts on the ground. Since they have travelled to the lands in question, and we have not, the correspondent is epistemologically privileged with respect to those facts on the ground. But when the correspondent makes moral evaluations of those facts, she is not in a privileged position, so we don’t just take her claims as the final word. Matravers suggests there are analogous limits to how far we trust a fictional narrator.\nThe problem with this approach is that there are several salient disanalogies between the position of the correspondent and the fictional narrator. The following case, which I heard about from Mark Liberman, illustrates this nicely. On March 5, 2004, the BBC reported that children in a nursery in England had found a frog with three heads and six legs. Many people, including Professor Liberman, were sceptical, notwithstanding the fact that the BBC was actually in England and Professor Liberman was not. The epistemological privilege generated by proximity doesn’t extend to implausible claims about three-headed frogs. The obvious disanalogy is that if a fictional narrator said that there was a three-headed six-legged frog in the children’s nursery then other things being equal we would infer it is true in the fiction that there was indeed a three-headed six-legged frog in the children’s nursery.6 So there isn’t an easy analogy between when we trust foreign correspondents and fictional narrators. Now we need an explanation of why the analogy does hold when either party makes morally deviant claims, even though it doesn’t when they both make biologically deviant claims. But it doesn’t seem any easier to say why the analogy holds then than it is to solve the original puzzle.\n6 There is a complication here in that such a sentence might be evidence that the fictional work is not to be understood as this kind of report, and instead understood as something like a recording of the children’s thoughts. I’ll assume we’re in a story where it is clear that the sentences are not to be so interpreted.Two other quick points about Matravers’s solution. It’s going to be a little delicate to extend this solution to all the cases I have discussed above, for normally we do think fictional narrators are privileged with respect to where the televisions and windows are. What matters here is that how far narratorial privilege extends depends on what other claims the narrator makes. Perhaps the same is true of foreign correspondents, though we’d need to see an argument for that. Second, it isn’t clear how this solution could possibly generalise to cover cases, such as frequently occurs in plays, where the deviant moral claim is clearly intended by the author to be true in the fiction but the reader (or watcher) does not agree even though the author’s intention is recognised. As I mentioned at the start, these cases aren’t our concern here, though it would be nice to see how a generalisation to these cases is possible. But the primary problem with Matravers’s solution is that as it stands it (improperly) rules out three-headed frogs in fiction, and it is hard to see how to remedy this problem without solving the original puzzle.\n\n\n4 Some Ethical Solutions\nIf one focuses on cases like Death, it is natural to think the puzzle probably has something to do with the special nature of ethical predicates, or perhaps of ethical concepts, or perhaps of the role of either of these in fiction. I don’t think any such solution can work because it can’t explain what goes wrong in Victory, and this will recur as an objection in what follows.\nThe most detailed solution to the puzzles has been put forward by Tamar Szabó Gendler. She focuses on the imaginative puzzle, but she also makes valuable points about the other puzzles. My solution to the phenomenological puzzle is basically hers plus a little epicycle.\nShe says that we do not imagine morally deviant fictional worlds because of our “general desire to not be manipulated into taking on points of view that we would not reflectively endorse as our own.” How could we take on a point of view by accepting something in a fiction? Because of the phenomena noted above that some things become true in a story because they are true in the world. If this is right, its converse must be true as well. If what is true in the story must match what is true in the world, then to accept that something is true in the story just is to accept that it is true in the world. Arguably, the same kind of ‘import/export’ principles hold for imagination as for truth in fiction. Some propositions become part of the content of an imagining because they are true. So, in the right circumstances, they will only be part of an imagining if they are true. Hence to imagine them (in the right circumstances) is to commit oneself to their truth. Gendler holds that we are sensitive to this phenomena, and that we refuse to accept stories that are morally deviant because that would involve accepting that morally deviant claims are true in the world.\nThat’s a relatively rough description of Gendler’s theory, but it says enough to illustrate what she has in mind, and to show where two objections may slip in. First, it is not clear that it generalises to all the cases. Gendler is aware of some of these cases and just bites the relevant bullets. She holds, for instance, that we can imagine that actually lame jokes are funny, and it could be true in a story that such a joke is funny. It would be a serious cost to her theory if she had to say the same thing about all the examples discussed above.\nThe second problem is more serious. The solution is only as good as the claim that moral claims are more easily exported than descriptive claims, and more generally that the types of claims we won’t imagine are more easily exported than those we don’t resist. Gendler has two arguments for why the first of these should be true, but neither of them sounds persuasive. First, she says that the moral claims are true in all possible worlds if true at all. But this won’t do on its own, because as she proved, we don’t resist some necessarily false claims. (This objection is also made by (Matravers 2003, 94).)\nSecondly, she claims that in other cases where there are necessary falsehoods true in a story, as in Alice in Wonderland, or the science fiction cases, the author makes it clear that unusual export restrictions are being imposed. But this is wrong for two reasons. First, I don’t think that any particularly clear signal to this effect occurs in my version of Back to the Future. Secondly, even if I had explicitly signalled that I had intended to make some of the facts in the story available for export, and you didn’t believe that, that isn’t enough reason to resist imagining the story. For my intent as to what can and cannot be exported is not part of the story.\nTo see this, consider one relatively famous example. At one stage B. F. Skinner tried to promote behaviourism by weaving his theories into a novel (of sorts): Walden Two. Now I’m sure Skinner (1948) intended us to export some psychological and political claims from the story to the real world. But it is entirely possible to read the story with full export restrictions in force without rejecting that what Skinner says is true in that world. (It is dreadfully boring, since there’s nothing but propagandising going on, but possible.) If exporting was the only barrier here, we should be able to impose our own tariff walls and read the story along, whatever the intent of the author, as we can with Walden Two. One can accept it is true in Walden Two that behaviourism is the basis of a successful social policy, even though Skinner wants us to accept this as true in the story iff it is true in the world, and it isn’t true in the world. We cannot read Death or Victory with the same ironic detachment, and Gendler’s theory lacks the resources to explain this.\nCurrie’s theory attacks the problem from a quite different direction. He relies on the motivational consequences of accepting moral claims. Assume internalism about moral motivation, so to accept that \\({\\phi}\\)-ing is right is to be motivated to \\({\\phi}\\), at least ceteris paribus. So accepting that \\({\\phi}\\)-ing is right involves acquiring a desire to \\({\\phi}\\), as well, perhaps, as beliefs about \\({\\phi}\\)-ing. Currie suggests that there is a mental state that stands to desire the way that ordinary imagination stands to belief. It is, roughly, a state of having an off-line desire, in the way that imagining that p is like having an off-line belief that p, a state like a belief that p but without the motivational consequences. Currie suggests that imagining that \\({\\phi}\\)-ing is right involves off-line acceptance that \\({\\phi}\\)-ing is right, and that in part involves having an off-line desire (a desire-like imagination) to \\({\\phi}\\). Finally, Currie says, it is harder to alter our off-line desires at will than it is to alter our off-line beliefs, and this explains the asymmetry. The argument for this last claim seems very hasty, but we’ll let that pass. For even if it is true, Currie’s theory does little to explain the later cases of imaginative resistance, from Alien Robbery to Victory. It cannot explain, why we have resistance to claims about what is rational to believe, or what is beautiful, or what attitudes other people have. The idea that there is a state that stands to desire as imagination stands to belief is I suspect a very fruitful one, but I don’t think its fruits include a solution to these puzzles.\n\n\n5 Grok\nStephen Yablo has suggested that the puzzles, or at least the imaginative puzzle, is closely linked to what he calls response-enabled concepts, or grokking concepts. (I’ll also use response-enabled (grokking) as a property of the predicates that pick out these concepts.) These are introduced by examples, particularly by the example ‘oval’.\nHere are meant to be some platitudes about OVAL. It is a shape concept - any two objects in any two worlds, counterfactual or counteractual, that have the same shape are alike in whether they are ovals. But which shape concept it is is picked out by our reactions. They are the shapes that strike us as being egg-like, or perhaps more formally, like the shape of all ellipses whose length/width ratio is the golden ratio. In this way the concept OVAL meant to be distinguished on the one hand from, say, PRIME NUMBER, which is entirely independent of us, and from WATER, which would have picked out a different chemical substance had our reactions to various chemicals been different. Note that what ‘prime number’ picks out is determined by us, like all semantic facts are. So the move space into which OVAL is meant to fit is quite tiny. We matter to its extension, but not the way we matter to ‘prime number’ (or that we don’t matter to PRIME NUMBER), and not the way we matter to ‘water’. I’m not sure there’s any space here at all. To my ear, Yablo’s grokking predicates strike me as words that have associated egocentric descriptions that fix their reference without having egocentric reference fixing descriptions, and such words presumably don’t exist. But for present purposes I’ll bracket those general concerns and see how this idea can help solve the puzzles. For despite my disagreement about what these puzzles show about the theory of concepts, Yablo’s solution is not too dissimilar to mine.\nThe important point for fiction about grokking concepts is that we matter, in a non-constitutive way, for their extension. Not we as we might have been, or we as we are in a story, but us. So an author can’t say that in the story squares looked egg-shaped to the people, so in the story squares are ovals, because we get to say what’s an oval, not some fictional character. Here’s how Yablo puts it:\n\nWhy should resistance [meaning, roughly, unimaginability] and grokkingness be connected in this way? It’s a feature of grokking concepts that their extension in a situation depends on how the situation does or would strike us. ‘Does or would strike us’ as we are: how we are represented as reacting, or invited to react, has nothing to do with it. Resistance is the natural consequence. If we insist on judging the extension ourselves, it stands to reason that any seeming intelligence coming from elsewhere is automatically suspect. This applies in particular to being ‘told’ about the extension by an as-if knowledgeable narrator. (2002, 485)\n\nIt might look at first as if Victory will be a counterexample to Yablo’s solution, just as it is to the Ethical solutions. After all, the concept that seems to generate the puzzles there is TELEVISION, and that isn’t at all like his examples of grokking concepts. (The examples, apart from evaluative concepts, are all shape concepts.) On the other hand, if there are any grokking concepts, perhaps it is plausible that TELEVISION should be one of them. Indeed, the platitudes about TELEVISION provide some support for this. (The following two paragraphs rely heavily on Fodor (1998).)\nThree platitudes about TELEVISION stand out. One is that it’s very hard to define just what a television is. A second is that there’s a striking correlation between people who have the concept TELEVISION and people who have been acquainted with a television. Not a perfect correlation - some infants have acquaintance with televisions but not as such, and some people acquire TELEVISION by description - but still strikingly high. And a third is that conversations about televisions are rarely at cross purposes, even when they consist of people literally talking different languages. TELEVISION is a shared concept.\nCan we put these into a theory of the concept TELEVISION? Fodor suggests we can, as long as we are not looking for an analysis of TELEVISION. Televisions are those things that strike us, people in general, as being sufficiently like the televisions we’ve seen, in a televisual kind of way. This isn’t an account of the meaning of the word ‘television’ - there’s no reference to us in that word’s dictionary entry, and rightly so. Nor is it an analysis of what constitutes the concept television. There’s no reference to us there either. But it does latch on to the right concept, or at least the right extension, in perhaps the only way we could. And this proposal certainly explains the platitudes well. The epistemic necessity of having a paradigm television to use as a basis for similarity judgments explains the striking correlation between televisual acquaintance and concept possession. The fact that the only way of picking out the extension uses something that is not constitutive of the concept, namely our reactions to televisions, explains why we can’t reductively analyse the concept. And the use of people’s reactions in general rather than idiosyncratic reactions explains why its a common concept. These look like good reasons to think something like Fodor’s theory of the concept TELEVISION is right, and if it is then TELEVISION seems to be response-enabled in Yablo’s sense. So unlike the Ethical solutions, Yablo’s solution might yet predict that Victory will be puzzling.\nStill, I have three quibbles about his solution, and that’s enough to make me think a better solution may still to be found.\nFirst, there’s a missing antecedent in a key sentence in his account, and it’s hard to see how to fill it in. What does he mean when he says ‘how the situation does or would strike us’? Does or would strike us if what? If we were there? But we don’t know where there is. There, in Victory, is allegedly a place where televisions look like knifes and forks. What if the antecedent is If all the non-grokking descriptions were accurate? The problem now is that this will be too light. If TELEVISION is grokking, then there is a worry that many concepts, including perhaps all artefact concepts, will be grokking. Fodor didn’t illustrate his theory with TELEVISION, he always used DOORKNOB. But the theory was meant to be rather general. If we take out all the claims involving grokking concepts, there may not be much left.\nSecond, despite the generality of Fodor’s account, it isn’t clear that mental concepts, and content concepts, are grokking. We would need another argument that LOVE is grokking, and that so is BELIEVING THAT THERE ARE SPACE ALIENS. Perhaps such an argument can be given, but it will not be a trivial exercise.\nFinally, I think this Yablo’s solution, at least as most naturally interpreted, overgeneralises. Here’s a counterexample to it. The following story is not, I take it, puzzling.\n\nFixing a Hole\nDQ and his buddy SP leave DQ’s apartment at midday Tuesday, leaving a well-arranged lounge suite and home theatre unit, featuring DQ’s prized oval television. They travel back in time to Monday, where DQ has some rather strange and unexpected adventures. He intended to correct something that happened yesterday, that had gone all wrong the first time around, and by the time the buddies reunite and leave for Tuesday (by sleeping and waking up in the future) he’s sure it’s all been sorted. When DQ and his buddy SP get back to his apartment midday Tuesday, it looks for all the world like there’s nothing there except an ordinary knife and fork.\n\nNow this situation would not strike us, were we to see it, as one where there is a lounge suite and home theatre unit in DQ’s apartment midday Tuesday, for it looks as if there’s an ordinary knife and fork there. But still, the author gets to say that what’s in DQ’s apartment as the story opens includes an oval television. And this despite the fact that the two concepts, TELEVISION and OVAL, are grokking. Perhaps some epicycles could be added to Yablo’s theory to solve this problem, but for now the solution is incomplete.\n\n\n6 Virtue\nThe content cases may remind us of one of Fodor’s most famous lines about meaning.\n\nI suppose that sooner or later the physicists will complete the catalogue they’ve been compiling of the ultimate and irreducible properties of things. When they do, the likes of spin, charm, and charge will perhaps appear on the list. But aboutness surely won’t; intentionality doesn’t go that deep … If the semantic and the intentional are real properties of things, it must be in virtue of their identity with (or maybe their supervenience on?) properties that are themselves neither intentional nor semantic. If aboutness is real, it must really be something else. (Fodor 1987, 97)\n\nIf meaning doesn’t go that deep, but there are meaning facts, then those facts must hold in virtue of more fundamental facts. “Molino de viento” means windmill in Spanish in virtue of a pattern of usage of those words by Spanish speakers, for instance.\nIt seems that many of the stories above involve facts that hold, if they hold at all, in virtue of other facts. Had Fodor other interests than intentionality, he may have written instead that beauty doesn’t go that deep, and neither does television. If an event is to be beautiful, this is a fact that must obtain in virtue of other facts about it, perhaps its integrity, wholeness, symmetry and radiance as Aquinas says (Joyce 1944/1963, 212), and that event being a monster truck death match of doom probably precludes those facts from obtaining.7 If Quixote’s favourite item of furniture is to be a television, this must be in virtue of it filling certain functional roles, and being indistinguishable from a common knife probably precludes that.\n7 Although it isn’t obvious just which of the Thomistic properties the death match lacks.What is it for a fact to obtain in virtue of other facts obtaining? A good question, but not one we will answer here. Still, the concept seems clear enough that we can still use it, as Fodor does. What we have in mind by ‘virtue’ is understandable from the examples. One thing to note from the top is that it is not just supervenience: whether x is good supervenes on whether it is good, but it is not good in virtue of being good. How much our concept differs from supervenience is a little delicate, but it certainly differs.\nReturning to our original example, moral properties are also less than perfectly fundamental. It is not a primitive fact that the butcher or the baker is generous, but a fact that obtains in virtue of the way they treat their neighbours. It is not a primitive fact that what Craig does is wrong, but a fact that obtains in virtue of the physical features of his actions.\nHow are these virtuous relations relevant to the puzzles? To a first approximation, these relations are always imported into stories and into imagination. The puzzles arise when we try to tell stories or imagine scenes where they are violated. The rest of the paper will be concerned with making this claim more precise, motivating it, and arguing that it solves the puzzles. In making the claim precise, we will largely be qualifying it.\nThe first qualification follows from something we noted at the end of section 2. We don’t know whether puzzles like the ones with which we started arise whenever there is a clash between real-world morality (or epistemology or mereology) and the morality (or epistemology or mereology) the author tries to put in the story. We do know they arise for simple stories and direct invitations to imagine. So if we aren’t to make claims that go beyond our evidence, we should say there is a default assumption that these relations are imported into stories or imaginations, and it is not easy to overcome this assumption. (I will say for short there is a strong default assumption, meaning just that an author cannot cancel the assumption by saying so, and that we cannot easily follow invitations to imagine that violate the relations.)\nThe second qualification is that sometimes we simply ignore, either in fiction or imagination, what goes on at some levels of detail. This means that sometimes, in a sense, the relations are not imported into the story. For instance, for it to really be true that in a language that “glory” means a nice knockdown argument, this must be true in virtue of facts about how the speakers of that language use, or are disposed to use, “glory”. But we can simply say in a story that “glory” in a character’s language means a nice knockdown argument without thereby making any more general facts about usage or disposition to use true in the story.8 More generally, we can simply pick a level of conceptual complexity at which to write our story or conduct our imaginings. Even if those concepts apply, when they do, in virtue of more basic facts, no more basic facts need be imported into the story. For a more vivid, if more controversial, example, one might think that cows are cows in virtue of their DNA having certain chemical characteristics. But when we imagine a cow jumping over the moon, we need not imagine anything about chemistry. Those facts are simply below the radar of our imagining. What do we mean then when we say that these relations are imported into the story? Just that if the story regards both the higher-level facts and the lower-level facts as being within its purview, then they must match up. This does not rule out the possibility of simply leaving out all lower-level facts from the story. In general the same thing is true for imagining, though we will look at some cases below where we it seems there is a stronger constraint on imagining.\n8 Do we make facts about the actual speaker’s usage true in the story? No. The character might have idiosyncratic reasons for not using the word “glory”, and for ignoring all others who use it. That’s consistent with the word meaning a nice knockdown argument.The third qualification is needed to handle an example pressed on me by a referee. Recall our example Fixing a Hole.\n\nFixing a Hole\nDQ and his buddy SP leave DQ’s apartment at midday Tuesday, leaving a well-arranged lounge suite and home theatre unit, featuring DQ’s prized oval television. They travel back in time to Monday, where DQ has some rather strange and unexpected adventures. He intended to correct something that happened yesterday, that had gone all wrong the first time around, and by the time the buddies reunite and leave for Tuesday (by sleeping and waking up in the future) he’s sure it’s all been sorted. When DQ and his buddy SP get back to his apartment midday Tuesday, it looks for all the world like there’s nothing there except an ordinary knife and fork.\n\nIn this story it seems that on Tuesday there is a television that looks exactly like a knife. If we interpret the claim about the relations between higher-level facts and the lower-level facts as a kind of impossibility claim, e.g. as the claim that a conjunction p \\({\\wedge}\\) q is never true in a story if the conditional If q, then p is false in virtue of q being true is true, then we have a problem. Let p be the claim that there is a television, and let q be the claim that the only things in the apartment looked life a knife and fork. If that’s how the more basic phenomenal and functional facts are, then there isn’t a television in virtue of those facts. (That is, this relation between phenomenal and functional facts and facts about where the televisions are really holds.) So this rule would say p \\({\\wedge}\\) q could not be true in the story. But in fact p \\({\\wedge}\\) q is true in the story.\nThe difficulty here is that Fixing a Hole is a contradictory story, and contradictory stories need care. First, here’s how we should interpret the rule\n\nVirtue\nIf p is the kind of claim that if true must be true in virtue of lower-level facts, and if the story is about those lower-level facts, then it must be true in the story that there is some true proposition r which is about those lower-level facts such that p is true in virtue of r.\n\nIn Fixing a Hole there are some true lower-level claims that are inconsistent with there being a television. But there is also in the story a true proposition about how DQ’s television looked before his time-travel misadventure. And it is true (both in reality and in the story) that something is a television in virtue of looking that way. (Note that we don’t say there must be some proposition r that is true in the story in virtue of which p is true. For there is no fact of the matter in Fixing a Hole about how DQ’s television looked before he left. So in reality we could not find such a proposition. But it is true in the story that his television looks some way or other, so as long as we talk about what in the story is true, and don’t quantify over propositions that are (in reality) true in the story, we avoid this pitfall.)\nSo my solution to the alethic puzzle is that Virtue is a strong default principle of fictional interpretation. I haven’t done much yet to motivate it, apart from noting that it seems to cover a lot of the cases that have been raised without overgenerating in the manner of the impossible solution. A more positive motivation must wait until I have presented my solutions to the phenomenological and imaginative puzzles. I’ll do that in the next section, then in tell a story about why we should believe Virtue.\n\n\n7 More Solutions\n\n7.0.1 The Phenomenological Puzzle\nMy solution here is essentially the same as Gendler’s. She think that when we strike a sentence that generated imaginative resistance we respond with something like, “That’s what you think!” What makes this notable is that it’s constitutive of playing the fiction game that we not normally respond that we way, that we give the author some flexibility in setting up a world. I think that’s basically right, but a little more is needed to put the puzzle to bed.\nSometimes the “That’s what you think!” response does not constitute abandoning the fiction game. At times it is the only correct way to play the game. It’s the right thing to say to Lily when reading the first line of The Dead. (Maybe it would be rude to say it aloud to poor Lily, the poor girl is run off her feet after all, but it’s appropriate to think it.) This pattern recurs throughout Dubliners. When in Eveline the narrator says that Frank has sailed around the world, the right reaction is to say to Eveline (or whoever is narrating then), “That’s what you think!” There’s a cost to playing the game this way. We end up knowing next to nothing about Frank. But it is not as if making the move stops us playing, or even stops us playing correctly. It’s part of the point of Eveline that we know next to nothing about Frank.\nWhat makes cases like Death and Victory odd is that our reaction is directed at someone who isn’t in the story. One of Alex Byrne’s (1993) criticisms of Lewis was that on Lewis’s theory it is true in every story that the story is being told. Byrne argued that in many fictions it is not true that in the fictional world there is someone sufficiently knowledgeable to tell the story. In these fictions, we have a story without a storyteller. If there are such stories, then presumably Death and Victory are amongst them. It is not a character in the story who ends by saying that Craig’s action was right or that Quixote’s apartment contains a television. The author says that, and hence deserves our reproach, but the author isn’t in the story. Saying “That’s what you think!” directly to him or her breaks the fictional spell for suddenly we have to recognise a character not in the fictional world.\nThis proposal for the phenomenological puzzle yields a number of predictions which seem to be true and interesting. First, a story that has a narrator should not generate a phenomenological puzzle, even when outlandish moral claims are made. The more prominent the narrator, the less striking the moral claim. Imagine, for example, a version of Death where the text purports to be Craig’s diary, and it includes naturally enough his own positive evaluation of what he did. We wouldn’t believe him, of course, but we wouldn’t be struck by the claim the same way we are in the actual version of Death.\nOne might have thought that what is shocking is what we discover about the author. But this isn’t right, as can be seen if we reflect on stories that contain Craig’s diary. It is possible, difficult but possible, to embed the diary entry corresponding to Death in a longer story where it is clear that the author endorses Craig’s opinions. (Naturally I won’t do this. Examples have to come to an end somewhere.) Such a story would, in a way, be incredibly shocking. But it wouldn’t make the final line shocking in just the way that the final line of Death is shocking. Our reactions to these cases suggest that the strikingness of the last line of Death is not a function of what it reveals about the author, but of how it reveals it.\nThe final prediction my theory makes is somewhat more contentious. Some novels announce themselves as works of fiction. They go out of their way to prevent you ignoring the novel’s role as mediation to a fictional world. (For an early example of this, consider the sudden appearance of newspaper headlines in the ‘Aeolus’ episode of Ulysses.) In such novels we already have to recognise the author as a player in the fictional game, if not a character in the story. I predict that sentences where we do not take what is written to really be true in the story, even though this is what the author intended, should be less striking in these cases because we are already used to reacting to the author as such rather than just to the characters. Such books go out of their way to break the fictional spell, so spell breaking should matter less in these cases. I think this prediction is correct, although the works in question tend to be so complicated that it is hard to generate clear intuitions about them.\n\n\n7.0.2 The Imaginative Puzzle\nImagine, if you will, a chair. Have you done so? Good. Let me make some guesses about what you imagined. First, it was a specific kind of chair. There is a fact of the matter about whether the chair you imagined is, for example, an armchair or a dining chair or a classroom chair or an airport lounge chair or an outdoor chair or an electric chair or a throne. We can verbally represent something as being a chair without representing it as being a specific kind of chair, but imagination cannot be quite so coarse.9\n9 This relates to another area in which my solution owes a debt to Gendler’s solution. Supposing can be coarse in a way that imagining cannot. We can suppose that Jack sold a chair without supposing that he sold an armchair or a dining chair or any particular kind of chair at all. Gendler concludes that what we do in fiction, where we try and imagine the fictional world, is very different to what we do, say, in philosophical argumentation, where we often suppose that things are different to the way they actually are. We can suppose, for the sake of argument as it’s put, that Kantian or Aristotelian ethical theories are entirely correct, even if we have no idea how to imagine either being correct. Thanks to Tyler Doggett for pointing out the connection to Gendler here.10 Thanks to Kendall Walton for pointing out this possibility.Secondly, what you imagined was incomplete in some respects. You possibly imagined a chair that if realised would contain some stitching somewhere, but you did not imagine any details about the stitching. There is no fact of the matter about how the chair you imagined holds together, if indeed it does. If you imagined a chair by imagining bumping into something chair-like in the dead of night, you need not have imagined a chair of any colour, although in reality the chair would have some colour or other.10\nWere my guesses correct? Good. The little I needed to know about imagination to get those guesses right goes a long way towards solving the puzzle.\nChairs are not very distinctive. Whenever we try to imagine that a non-fundamental property is instantiated the content of our imagining will be to some extent more specific than just that the object imagined has the property, but not so much more specific as to amount to a complete description of a possibilia. It’s the latter fact that does the work in explaining how can imagine impossible situations. If we were, foolishly, to try to fill in all the details of the impossible science fiction cases it would be clear they contained not just impossibilities, but violations of Virtue, and then we would no longer be able to imagine them. But we can imagine the restaurant at the end of the universe without imagining it in all its glorious gory detail. And when we do so our imagining appears to contain no such violations.\nBut why can’t we imagine these violations in fictions? It is primarily because we can only imagine the higher-level claim some way or another, just as we only imagine a chair as some chair or other, and the instructions that go along with the fiction forbid us from imagining any relevant lower-level facts that would constitute the truth of the higher-level claim. We have not stressed it much above, but it is relevant that fictions understood as invitations to imagine have a “That’s all” clause.11 We are not imagining Death if we imagine that Jack and Jill had just stopped arguing with each other and were about to shoot everyone in sight when Craig shot them in self-defence. The story does not explicitly say that wasn’t about to happen. It doesn’t include a “That’s all” clause. But such clauses have to be understood. So not only are we instructed to imagine something that seems incompatible with Craig’s action being morally acceptable, we are also instructed (tacitly) to not imagine anything that would make it the case that his action is morally acceptable. But we can’t simply imagine moral goodness in the abstract, to imagine it we have to imagine a particular kind of goodness.\n11 “That’s all” clauses play a distinct, but related, role in (Jackson 1998 Ch. 1). It’s also crucial to my solution to the alethic puzzle that there be a “That’s all” clause in the story. What’s problematic about these cases is that the story (implicitly) rules out there being the lower-level facts that would make the expressed higher-level claims true.\n\n7.0.3 Two Thoughts Too Many?\nI have presented three solutions to the three different puzzles with which we started. Might it not be better to have a uniform solution? No, because although the puzzles are related, they are not identical. Three puzzles demand three solutions.\nWe saw already that the phenomenological puzzle is different to the other two. If we rewrite Death as Craig’s diary there would be nothing particularly striking about the last sentence, certainly in the context of the story as so told. But the last sentence generates alethic and imaginative puzzles. Or at least it could generate these puzzles if the author has made it clear elsewhere in the story that Craig’s voice is authoritative. So we shouldn’t expect the same solution to that puzzle as the other two.\nThe alethic puzzle is different to the other two because ultimately it depends on what the moral and conceptual truths are not on what we take them to be. Consider the following story.\n\nThe Benefactor\nSmith was a very generous, just and in every respect moral man. Every month he held a giant feast for the village where they were able to escape their usual diet of gains, fruits and vegetables to eat the many and varied meats that Smith provided for them.\n\nConsider in particular, what should be easy to some, how Benefactor reads to someone who believes that we are morally required to be vegetarian if this is feasible. In Benefactor it is clear in the story that most villagers can survive on a vegetarian diet. So it is morally wrong to serve them the many and varied meats that Smith does. Hence such a reader should disagree with the author’s assessment that Smith is moral ‘in every respect’. Such a reader will think that in fact in the story Smith is quite immoral in one important respect.\nNow for our final assumption. Assume it is really true that we morally shouldn’t eat meat if it is avoidable. Since the ethical vegetarians have true ethical beliefs about the salient facts here, it seems plausible that their views on what is true in the story should carry more weight than ours. (I’m just relying on a general epistemological principle here: other things being equal trust the people who have true beliefs about the relevant background facts.) So it seems that it really is false in the story that Smith is in every respect moral. Benefactor raises an alethic puzzle even though for non-vegetarians it does not raise a phenomenological or imaginative puzzle.\nThis point generalises, so we need not assume for the general point that vegetarianism is true or that our typical reader is not vegetarian. We can be very confident that some of our ethical views will be wrong, though for obvious reasons it is hard to say which ones. Let p be a false moral belief that we have. And let S be a story in which p is asserted by the (would-be omniscient) narrator. For reasons similar to what we said about Benefactor, p is not true in S. But S need not raise any imaginative or phenomenological puzzles. Hence the alethic puzzle is different to the other two puzzles.\n\n\n\n8 Why Virtue Matters\nI owe you an argument for why authors should be unable to easily generate violations of Virtue, though there is no general bar on making impossibilities true in a story. My general claims here are not too dissimilar to Yablo’s solution to the puzzles, but there are a couple of distinctive new points. Before we get to the argument, it’s time for another story.\nThree design students walk into an furniture showroom. The new season’s fashions are all on display. The students are all struck by the piece de resistance, though they are all differently struck by it. Over drinks later, it is revealed that while B and C thought it was a chair, A did not. But the differences did not end there. When asked to sketch this contentious object, A and B produced identical sketches, while C’s recollections were drawn somewhat differently. B clearly disagrees with both A and C, but her differences with each are quite different. With C she disagrees on some simple empirical facts, what the object in question looked like. With A she disagrees on a conceptual fact, or perhaps a semantic fact, whether the concept CHAIR, or perhaps just the term ‘chair’, applies to the object in question. As it turns out, A and B agree that ‘chair’ means CHAIR, and agree that CHAIR is a public concept so one of them is right and the other wrong about whether this object falls under the concept. In this case, their disagreement will have a quite different feel to B’s disagreement with C. It may well be that there is no analytic/synthetic distinction, and that questions about whether an object satisfies a concept are always empirical questions, but this is not how it feels to A and B. They feel that they agree on what the world is like, or at least what this significant portion of it is like, and disagree just on which concepts apply to it.\nThe difference between these two kinds of disagreement is at the basis of our attitudes towards the alethic puzzle. It may look like we are severely cramping authorial freedom by not permitting violations of Virtue.12 From A and B’s perspective, however, this is no restriction at all. Authors, they think, are free to stipulate which world will be the site of their fiction. But as their disagreement about whether the piece de resistance was a chair showed, we can agree about which world we are discussing and disagree about which concepts apply to it. The important point is that the metaphysics and epistemology of concepts comes apart here.\n12 Again, it is worth noting that I am not ruling out any violation of Virtue, just easy violations of it. The point being made in the text is that even a blanket ban on violations would not be a serious restriction on authorial freedom.There can be no difference in whether the concept CHAIR applies without a difference in the underlying facts. But there can be a difference of opinion about whether a thing is a chair without a difference of opinion about the underlying facts. The fact that it’s the author’s story, not the reader’s, means that the author gets to say what the underlying facts are. But that still leaves the possibility for differences of opinion about whether there are chairs, and on that question the author’s opinion is just another opinion.\nAuthorial authority extends as far as saying which world is fictional in their story, it does not extend as far as saying which concepts are instantiated there. Since the main way that we specify which world is fictional is by specifying which concepts are instantiated at it, authorial authority will usually let authors get away with any kind of conceptual claim. But once we have locked onto the world being discussed, the author has no special authority to say which concepts, especially which higher-level concepts like RIGHT or FUNNY or CHAIR are instantiated there.\n(Does it matter much that the distinction between empirical disagreements and conceptual disagreements with which I started might turn out not to rest on very much? Not really. I am trying to explain why we have the attitudes towards fiction that we do, which in turn determines what is true in fiction generally. All that matters is that people generally think that there is something like a conceptual truth/empirical truth distinction, and I think enough people would agree that A and B’s disagreement is different in kind from B and C’s disagreement to show that is true. If folks are generally wrong about this, if there is no difference in kind between conceptual truths and empirical truths, then our communal theory of truth in fiction will rest on some fairly untenable supports. But it will still be our theory, although any coherent telling of it will have to be in terms of things that are taken to be conceptual truths and things that are taken to be empirical truths.)\nThis explanation of why authorial authority collapses just when it does yields one fairly startling, and I think true, prediction. I argued above that authors could not easily generate violations of Virtue. That this is impossible is compatible with any number of hypotheses about how readers will resolve those impossibilities that authors attempt to slip in. The story here, that authors get to say which world is at issue but not which concepts apply to it, yields the prediction that readers will resolve the tension in favour of the lower-level claims. When given a physical description of a world and an incompatible moral description, we will take the physical description to fix which world is at issue and reduce the moral description to a series of questionable claims about the world. Compare what happens with A, B and C. We take A and B to agree about the world and disagree about concepts, rather than say taking B and C to agree about what the world is like (there’s a chair at the heart of the furniture show) and say that A and B disagree about the application of some recognitional concepts. This prediction is borne out in every case discussed in . We do not conclude that Craig did not really shoot Jack and Jill, because after all the world at issue is stipulated to be one where he did the right thing. Even more surprisingly, we do not conclude that Quixote’s furniture does not look like kitchen utensils, because it consists of a television and an armchair. This is surprising because in Victory I never said that the furniture looked like kitchen utensils. The tacit low-level claim about appearances is given precedence over the explicit high-level claims about which objects populate Quixote’s apartment. The theory sketched here predicts that, and supports the solution to the alethic puzzle sketched in , which is good news for both the theory and the solution.\nIt’s been a running theme here that the puzzles do not have anything particularly to do with normativity. But some normative concepts raise the kind of issues about authority mentioned here in a particularly striking way. There is always some division of cognitive labour in fiction. The author’s role is, among other things, to say which world is being made fictional. The audience’s role is, among other things, to determine the artistic merit of the fictional work. On other points there may be some sharing of roles, but this division is fairly absolute. The division threatens to collapse when authors start commenting on the aesthetic quality of words produced by their characters. At the end of Ivy Day in the Committee Room Joyce has one character describe a poem just recited by another character as “A fine piece of writing” (Joyce 1914/2000, 105). Most critics seem to be happy to accept the line, because Joyce’s poem here really is, apparently, a fine piece of writing. But to me it seems rather jarring, even if it happens to be true. It’s easy to feel a similar reaction when characters in a drama praise the words of another character.13 This is a special, and especially vivid, illustration of the point I’ve been pushing towards here. The author gets to describe the world at whichever level of detail she chooses. But once it has been described, the reader has just as much say in which higher-level concepts apply to parts of that world. When the concepts are evaluative concepts that directly reflect on the author, the reader’s role rises from being an equal to having more say than the author, just as we normally have less say than others about which evaluative concepts apply to us.\n13 For a while this would happen frequently on the TV series The West Wing. President Bartlett would deliver a speech, and afterwards his staffers would congratulate themselves on what a good speech it was. The style of the congratulations was clearly intended to convey the author’s belief that the speech they themselves had written was a good speech, not just the characters’ beliefs to this effect. When in fact it was a very bad speech, this became very jarring. In later series they would often not show the speeches in question and hence avoid this problem.This idea is obviously similar to Yablo’s point that we get to decide when grokking concepts apply, not the author. But it isn’t quite the same. I think that if any concepts are grokking, most concepts are, so it can’t be the case that authors never get to say when grokking concepts apply in their stories. Most of the time authors will get to say which grokking concepts apply, because they have to use them to tell us about the world. What’s special about the kind of concepts that cause puzzles is that we get to decide when they apply full stop, but that we get to decide how they apply given how more fundamental concepts apply. So the conciliatory version of the relation between my picture here and Yablo’s is that I’ve been filling in, in rather laborious detail, his missing antecedent.\n\n\n9 Two Hard Cases\nThe first hard case is suggested by Kendall Walton (1994). Try to imagine a world where the over-riding moral duty is to maximise the amount of nutmeg in the world. If you are like me, you will find this something of a challenge. Now consider a story Nutmeg that reads (in its entirety!): “Nobody ever discovered this, but it turned out all along their over-riding moral duty was to maximise the amount of nutmeg in the world.” What is true in Nutmeg? It seems that there are no violations of Virtue here, but it is hard to imagine what is being described.\nThe second hard case is suggested by Tamar Szabó Gendler (2000). (I’m simplifying this case a little, but it’s still hard.) In her Tower of Goldbach, God decrees that 12 shall no longer be the sum of two primes, and from this it follows (even in the story) that it is not the sum of 7 and 5. (It is not clear why He didn’t just make 5 no longer prime - say the product of 68 and 57. That may have been simpler.) Interestingly, this has practical consequences. When a group of seven mathematicians from one city attempts to join a group of five from another city, they no longer form a group of twelve. Again, two questions. Can we imagine a Goldbachian situation, where 7 and 5 equal not 12? Is it true in Gendler’s story that 7 and 5 equal not 12? If we cannot imagine Goldbach’s tower, where is the violation of Virtue?\nFirst a quick statement of my responses to the two cases then I’ll end with my detailed responses. To respond properly we need to tease apart the alethic and imaginative puzzles. I claim that the alethic puzzle only arises when there’s a violation of Virtue. There’s no violation in either story, so there is no alethic puzzle. I think there are independent arguments for this conclusion in both cases. We can’t imagine either (if we can’t) because any way of filling in the more basic facts leads to violations.\nIt follows from my solution to the alethic puzzle that Nutmegism (Tyler Doggett’s name for the principle that we must maximise quantities of nutmeg) could be true in a story. There is no violation in Nutmeg, since there are no lower level claims made. Still, the story is very hard to imagine. The reason for this is quite simple. As noted, we cannot just imagine a chair, we have to imagine something more detailed that is a chair in virtue of its more basic properties. (There is no particular more basic property we need imagine, as is shown by the fact that we can imagine a chair just by imagining something with a certain look, or we can imagine a chair in the dark with no visual characteristics. But there is always something more basic.) Similarly to imagine a duty, we have to imagine something more detailed, in this case presumably a society or an ecology, in virtue of which the duty exists. But no such possible, or even impossible, society readily springs to mind. So we cannot imagine Nutmegism is true.\nBut it is hard to see how, or why, this inability should be raised into a restriction on what can be true in a story. One might think that what is wrong with Nutmeg is that the fictional world is picked out using high-level predicates. If we extend the story any way at all, the thought might go, we will generate a violation of Virtue. And that is enough to say that Nutmegism is not true in the story. But actually this isn’t quite right. If we extend the story by adding more moral claims, there is no duty to minimise suffering, there is no duty to help the poor etc, there are still no violations in the story. The restriction we would have to impose is that there is no way of extending the story to fill out the facts in virtue of which the described facts obtain, without generating a violation. But that looks like too strong a constraint, mostly because if we applied it here, to rule out Nutmegism being true in Nutmeg, we would have to apply it to every story written in a higher level language than that of microphysics. It doesn’t seem true that we have to be able to continue a story all the way to the microphysical before we can be confident that what the author says about, for instance, where the furniture in the room is. So there’s no reason to not take the author’s word in Nutmeg, and since the default is always that what the author says is true, Nutmegism is true in the story.\nThe mathematical case is more difficult. The argument that 7 and 5 could fail to equal 12 in the story turns on an example by Gregory Currie (1990). (The main conclusions of this example are also endorsed by Byrne (1993).) Currie imagines a story in which the hero refutes Gödel’s Incompleteness Theorem. Currie argues that the story could be written in such a way that it is true in the story not merely that everyone believes our hero refuted Gödel, but that she really did. But if it could be true in a story that Gödel’s Incompleteness Theorem could be false, then it’s hard to see just why it could not be true in a story that a simpler arithmetic claim, say that 7 and 5 make 12, could also be false. Anything that can’t be true in a story can’t be true in virtue of some feature it has. The only difference between Gödel’s Incompleteness Theorem and a simple arithmetic statement appears to be the simplicity of the simple statement. And it doesn’t seem possible, or advisable, to work that kind of feature into a theory of truth in fiction.\nThe core problem here is that how simple a mathematical impossibility is very much a function of the reader’s mathematical knowledge and acumen. Some readers probably find the unique prime factorisation theorem so simple and evident that for them a story in which it is false is as crashingly bad as a story in which 7 and 5 do not make 12. For other readers, it is so complex that a story in which it has a counterexample is no more implausible than a story in which Gödel is refuted. I think it cannot be true for the second reader that the unique prime factorisation theorem fails in the story and false for the first reader. That amounts to a kind of relativism about truth in fiction that seems preposterous. But I agree with Currie that some mathematical impossibilities can be true in a fiction. So I conclude that, whether it is imaginable or not, it could be true in a story that 7 and 5 not equal 12.\nI think, however, that it is impossible to imagine that 7 plus 5 doesn’t equal 12. Can we explain that unimaginability in the same way we explained why Nutmeg couldn’t be imagined? I think we can. It seems that the sum of 7 and 5 is what it is in virtue of the relations between 7, 5 and other numbers. It is not primitive that various sums take the values they take. That would be inconsistent with, for example, it being constitutive of addition that it’s associative, and associativity does seem to be constitutive of addition. We cannot think about 7, 5, 12 and addition without thinking about those more primitive relations. So we cannot imagine 7 and 5 equally anything else. Or so I think. There’s some rather sophisticated, or at least complicated, philosophy of mathematics in the story here, and not everyone will accept all of it. So we should predict that not everyone will think that these arithmetic claims are unimaginable. And, pleasingly, not everyone does. Gendler, for instance, takes it as a data point that Tower of Goldbach is imaginable. So far so good. Unfortunately, if the story is true we should also expect that whether people find the story imaginable links up with the various philosophies of mathematics they believe. And the evidence for that is thin. So there may be more work to do here. But there is clearly a story that we can tell that handles the case.\n\n\n\n\n\n\nReferences\n\nAdams, Douglas. 1980. The Restaurant at the End of the Universe. London: Pan Macmillan.\n\n\nByrne, Alex. 1993. “Truth in Fiction - the Story Continued.” Australasian Journal of Philosophy 71 (1): 24–35. https://doi.org/10.1080/00048409312345022.\n\n\nCurrie, Gregory. 1990. The Nature of Fiction. Cambridge: Cambridge University Press.\n\n\n———. 2002. “Desire in Imagination.” In Conceivability and Possibility, edited by Tamar Szabó Gendler and John Hawthorne, 201–21. Oxford: Oxford University Press.\n\n\nFodor, Jerry A. 1987. Psychosemantics. Cambridge, MA: MIT Press.\n\n\n———. 1998. Concepts: Where Cognitive Science Went Wrong. Oxford: Oxford University Press.\n\n\nGendler, Tamar Szabó. 2000. “The Puzzle of Imaginative Resistance.” Journal of Philosophy 97 (2): 55–81. https://doi.org/10.2307/2678446.\n\n\nHare, R. M. 1951. The Language of Morals. Oxford: Oxford University Press.\n\n\nHolton, Richard. 1997. “Some Telling Examples: Reply to Tsohatzidis.” Journal of Pragmatics 28 (5): 625–28. https://doi.org/10.1016/s0378-2166(96)00081-1.\n\n\nHume, David. 1757. “On the Standard of Taste.” In Essays: Moral, Political and Legal, 227–49. Indianapolis: Liberty Press.\n\n\nJackson, Frank. 1998. From Metaphysics to Ethics: A Defence of Conceptual Analysis. Clarendon Press: Oxford.\n\n\nJoyce, James. 1914/2000. Dubliners. Oxford: Oxford University Press.\n\n\n———. 1944/1963. Stephen Hero. New Directions: Norfolk, CT.\n\n\n———. 1922/1993. Ulysses. Oxford: Oxford University Press.\n\n\nKidd, John. 1988. “The Scandal of ‘Ulysses’.” The New York Review of Books 35 (11): 32–39.\n\n\nKripke, Saul. 1982. Wittgenstein on Rules and Private Language. Oxford: Basil Blackwell.\n\n\nLewis, David. 1978. “Truth in Fiction.” American Philosophical Quarterly 15 (1): 37–46.\n\n\nMatravers, Derek. 2003. “Fictional Assent and the (so-Called) ‘Puzzle of Imaginative Resistance’.” In Imagination, Philosophy and the Arts, edited by Matthew Kieran and Dominic McIver Lopes, 91–108. London. Routledge.\n\n\nMoran, Richard. 1995. “The Expression of Feeling in Imagination.” Philosophical Review 103 (1): 75–106. https://doi.org/10.2307/2185873.\n\n\nPriest, Graham. 1997. “Sylvan’s Box: A Short Story and Ten Morals.” Notre Dame Journal of Formal Logic. 38 (4): 573–82. https://doi.org/10.1305/ndjfl/1039540770.\n\n\nSkinner, B. F. 1948. Walden Two. New York: Macmillan.\n\n\nSorensen, Roy. 2001. Vagueness and Contradiction. Oxford: Oxford University Press.\n\n\nStock, Kathleen. 2003. “The Tower of Goldbach and Other Impossible Tales.” In Imagination, Philosophy and the Arts, edited by Matthew Kieran and Dominic McIver Lopes, 107–24. London. Routledge.\n\n\nWalton, Kendall. 1990. Mimesis as Make Believe. Cambridge, MA: Harvard University Press.\n\n\n———. 1994. “Morals in Fiction and Fictional Morality.” Aristotelian Society 68(Supp) (1): 27–50. https://doi.org/10.1093/aristoteliansupp/68.1.27.\n\n\nYablo, Stephen. 2002. “Coulda, Woulda, Shoulda.” In Conceivability and Possibility, edited by Tamar Szabó Gendler and John Hawthorne, 441–92. Oxford: Oxford University Press."
  },
  {
    "objectID": "posts/haootm/humeans-arent-out-of-their-minds.html",
    "href": "posts/haootm/humeans-arent-out-of-their-minds.html",
    "title": "Humeans Aren’t Out of Their Minds",
    "section": "",
    "text": "Humeanism is “the thesis that the whole truth about a world like ours supervenes on the spatiotemporal distribution of local qualities.” (Lewis 1994, 473) Since the whole truth about our world contains truths about causation, causation must be located in the mosaic of local qualities that the Humean says constitute the whole truth about the world. The most natural ways to do this involve causation being in some sense extrinsic. To take the simplest possible Humean analysis, we might say that c causes e iff throughout the mosaic events of the same type as c are usually followed by events of type e. For short, the causal relation is the constant conjunction relation. Whether this obtains is determined by the mosaic, so this is a Humean theory, but it isn’t determined just by c and e themselves, so whether c causes e is extrinsic to the pair. Now this is obviously a bad theory of causation, but the fact that causation is extrinsic is retained even by good Humean theories of causation. John Hawthorne (2004) objects to this feature of Humeanism. I’m going to argue that his arguments don’t work, but first we need to clear up three preliminaries about causation and intrinsicness.\n\nPublished in Noûs 41: 529-535.\n\nFirst, my wording so far has been cagey because I haven’t wanted to say that Humeans typically take causation to be an extrinsic relation. That’s because the greatest Humean of them all, David Lewis, denies that causation is a relation at all, and hence that it is an extrinsic relation (Lewis 2004b). We can go some way to avoiding this complication by talking, as Hawthorne does, about properties of regions, and asking the property of containing a duplicate of c that causes a duplicate of e is intrinsic or extrinsic.1 Humeans typically take causation to be extrinsic in this sense.\n1 This move requires the not wholly uncontroversial assumption that regions are the kinds of things that can have properties. But I’ll happily make that assumption here. Note that the formulation here allows that the property denoted might be intrinsic for some c and e and extrinsic for others. I’ll say causation is extrinsic if the property denoted is extrinsic for some choice of c and e, even if it is intrinsic for others, as it might be if, for example, no region could possess the property because c is a part of e.Second, nothing in Humeanism requires that causation is extrinsic in that sense. If one analysed causation as that intrinsic relation that actually most tightly correlates with the constant conjunction relation, then one would have guaranteed that causation was an intrinsic relation. Moreover, one would have a perfectly Humean theory of causation. (A perfectly awful theory, to be sure, but still a Humean one.) Peter Menzies (1996, 1999) develops a more sophisticated version of such a theory, and though Menzies describes his view as anti-Humean, one can locate the relation we’ve defined here in the Humean mosaic, so such an approach might be consistent with Humeanism in the intended sense.\nThird, there is good reason, independent of Humeanism, to accept that causation is extrinsic. As Ned Hall (2004) argues, it is very hard to square the intrinsicness of causation with the possibility of causation by omission. Given the choice between these two, I’m going to accept causation by omission without much hesitation. There is one powerful objection to the possibility of causation by omission, namely that if there is any causation by omission then there is a lot more than is intuitively plausible. But since Sarah McGrath (2005) has a good response to that objection, I feel happy accepting there is causation by omission. So I accept that causation is extrinsic, for reasons totally independent of Humeanism. Since Hawthorne appeals to no feature of Humeanism beyond the Humean’s acceptance of the extrinsicness of causation, we can take his argument to be an argument against the causal extrinsicalist, i.e. the theorist who accepts causation is extrinsic in the above sense. To see that the argument doesn’t go through, we need to consider what exactly the causal extrinsicalist is committed to. I’ll explore this by looking at some other examples of properties of regions.\nSome regions contain uncles and some do not. This seems to be an extrinsic property of regions. My house does not contain any uncles right now, but there are duplicates of it, in worlds where my brothers have children, where it does contain an uncle, namely my counterpart. Consider the smallest region containing the earth from the stratosphere in from the earth’s formation to its destruction. Call this region e. Any duplicate of e also contains uncles, including several uncles of mine. You can’t duplicate the earth without producing a duplicate of me who is, in the duplicate world, the nephew of the duplicates of my uncles. So it is intrinsic to e that it contain an uncle, even though this is an extrinsic property of regions. (There is much more discussion of extrinsic properties that are possessed intrinsically in Humberstone (1996).)\nThis possibility, that a region might intrinsically possess an extrinsic property, poses a problem for Hawthorne’s argument. Here is his presentation of it.\n\n\nAn intrinsic duplicate of any region wholly containing me will contain a being with my conscious life.\nThere are causal requirements on my conscious life.\n\nTherefore, Humeanism is false. (Hawthorne 2004, 351–52)\n\nThe problem is that this argument isn’t valid. What follows from (1) and (2) is that any region containing Hawthorne must possess some causal properties intrinsically. (As Hawthorne argues on page 356.) And what Humeanism entails is that causal properties are extrinsic properties of regions. But there is no incompatibility here, for it is possible that extrinsic properties are possessed intrinsically, as we saw in the discussion of uncles.\nHawthorne’s argument would go through if Humeans, and causal extrinsicalists more generally, were committed to the stronger claim that regions never possess causal properties intrinsically. But it doesn’t seem that Humeans should be committed to this claim. Consider again e and all its duplicates. Any such duplicate will contain a duplication of the event of Booth’s shooting Lincoln, and Lincoln dying.2 Will it also be the case that duplicate-Booth’s shooting in this world causes duplicate-Lincoln’s dying? If so, and this seems true, then it is intrinsic to e that it contains an event of a shooting causing a dying, even though the property of containing a shooting causing a dying is extrinsic.\n2 There is a potential complication here in that arguably in some such worlds, e.g. worlds where there is another planet on the opposite side of the sun to duplicate-earth where people are immediately ‘resurrected’ when the ‘die’ on duplicate-earth. In such a world you might say that duplicate-Lincoln doesn’t really die on duplicate-Earth, but merely has the duplicate-earth part of his life ended. We’ll understand ‘dying’ in such a way that this counts as dying.It would be a bad mistake to offer the following epistemological argument that in all duplicates of e, duplicate-Booth’s shooting causes duplicate-Lincoln’s dying.\n\nIf there was a duplicate of e where duplicate-Booth’s shooting does not cause duplicate-Lincoln’s dying, then we would not know whether Booth’s shooting causes Lincoln’s dying without investigating what happens outside e.\nWe can know that Booth’s shooting caused Lincoln’s dying without investigating outside e.\nSo, there is no duplicate of e where duplicate-Booth’s shooting does not cause duplicate-Lincoln’s dying.\n\nThe problem with this argument is that even there are worlds containing such duplicates, we might know a priori that we do not live in such a world, just as we know a priori that we do not live in a world where certain kinds of sceptical scenarios unfold (Hawthorne 2002; Weatherson 2005).\nA better argument against the existence of such a world is that if it is possible, it should be conceivable. But it is basically impossible to conceive such a world. Even if throughout the universe shootings like Booth’s are usually followed by something other than dying, say that shooting in most parts of the universe causes diseases to be cured, the large-scale regularity within e (or its duplicate) of shootings being followed by dying suffices to ground the claim that shootings cause dyings in a good Humean theory. The crucial assumption here is that local regularities count for more than global regularities. If the local regularities deviate too far from the global regularities, then Humeans can and should say that different nomic claims (and hence causal claims) are true in this part of the world to the rest of the universe. If they say this, they can say that regions can have causal features (such as containing a shooting causing a dying) intrinsically even though causal features are extrinsic properties.\nTo illustrate the kind of Humean theory that would have such a consequence, consider the following variant on the constant conjunction theory of causation. The theory I’m imagining says that c causes e iff whenever an event of the same type as c occurs within a 50 mile radius of where c occurred, it was followed by an event of type e. Call this the 50 mile constant conjunction theory of causation.3 On the 50 mile constant conjunction theory of causation, it won’t be intrinsic to Ford’s Theatre that it contained a causal event involving Booth shooting Lincoln, but it will be intrinsic to any sphere of radius 50 miles or more centred on the theatre that it contains such a causal event. So on this theory causal properties can be intrinsic to a region, though they are still extrinsic properties of such a region.\n3 I assume here that events can be properly said to have locations. Spelling out this assumption in detail will require some serious metaphysics, particularly when it comes to omissions. Where exactly does my omission to stop the Iraq War take place? Here at my kitchen table where I am? In Iraq, where the war is? In Washington, if that’s where I’d be were I doing something to stop the war? These questions are hard, though not so hard that we should give up on the very natural idea that events have locations.That’s a very implausible Humean theory, but when we look at the details of David Lewis’s Humean picture, we can see the outlines of a more plausible theory with the same consequences. Lewis of course doesn’t offer a simple regularity theory of causation. Rather, he first argues that laws are the extremely simple, extremely informative true propositions (Lewis 1973, 73). That is, he offers a sophisticated regularity theory of laws. Then he analyses counterfactual dependence in terms of lawhood (Lewis 1973, 1979). Finally he analyses causation in terms of counterfactual dependence (Lewis 2004a). The philosophical theory meets the Humean mosaic most closely on the issue of what a law is. If we can offer a theory of laws that allows extra sensitivity to local facts, while remaining Humean, we can plug this back into Lewis’s theories concerning counterfactual dependence and hence causation without upsetting its Humean credentials.\nNow there is a good reason to think that a Humean theory of laws should be locally sensitive. (I’m indebted here to long ago conversations with James Chase.) Humeans typically believe in fairly unrestricted principles of recombination. And they believe that laws are not necessarily true. So there could be worlds with very different laws. So there is a world which ‘patches’ together part of the world with laws L1 with a world with laws L2. If the parts are large and isolated enough, it would be foolish to say that within those parts nothing is law-governed, or that within those regions there is no counterfactual dependence, or no causation. Much better to say that regularities obtaining within such a region are sufficiently simple and informative to count as laws. In our patchwork world, the laws might simply say In r1, L1 and in r2, L2. Provided the terms denoting the regions are not too gruesome, these will plausibly be Humean, even Lewisian, laws.\nLet’s bring all this back to Hawthorne’s example. Hawthorne argues that certain causal facts are intrinsic to the region containing his body. The challenge for the Humean is to say how this could be so when Hawthorne could be embedded in a world where very different regularities obtain. The simple answer is to say that in such worlds, laws like In r, L, where r picks out the region Hawthorne’s body occupies, and L picks out a real-world law, will be true, simple and informative. It is informative because any duplicate of Hawthorne’s body is a very complicated entity, containing billions of billions of particles interacting in systematic ways, ways that are nicely summarised by real-world laws. Simplicity is a little harder to make out, but note that there is a reasonably sharp boundary between Hawthorne’s body and the rest of the world (Lewis 1993), so there should be a natural enough way to pick it out. In other words, even if we embed a Hawthorne duplicate in a world with very different regularities, Humeans will still have good reason to say that the laws, and hence the facts about counterfactual dependence and causation, inside that duplicate are not changed. So not only is it logically possible that Hawthorne’s premises are true and his conclusion false, we can motivate a Humean position that endorses the truth of Hawthorne’s premises and the falsity of the conclusion.\nSince Hawthorne’s argument is invalid then, we can accept the premises without giving up Humeanism. But I think it is worthwhile to note that his (1) also can be questioned. Hawthorne notes that it is rejected by those such as Dretske and Lewis who say that phenomenal character is determined in part by kind membership. (See Lycan (2001) for a longer defence of this kind of rejection of (1).) Hawthorne thinks that the intuitive plausibility of (1) constitutes a serious objection to those views. But by reflecting a little on the phenomenology of what I’ll call totality qualia, we can undermine the intuitive case for (1).\nTweedledee is facing a perfectly symmetrical scene. His visual field is symmetric, with two gentle mountains rising to his left and his right and a symmetric plain in between them. All he can hear are two birds singing in perfect harmony, one behind his left ear and one behind his right ear. The smells of the field seem to envelope him rather than coming from any particular direction. There is a cool breeze blowing directly on his face. It’s a rather pleasant scene, and the overwhelming feeling is one of symmetry.\nTweedledum is very much like Tweedledee. Indeed, Tweedledum contains a duplicate of Tweedledee as a proper part. But Tweedledum also has some sensors in his skin, and brain cells in what corresponds to a suspiciously empty part of Tweedledee’s brain, that allow him to detect, and feel, where the magnetic fields are in the vicinity. And sadly, though Tweedledum is facing a duplicate of the scene facing Tweedledee, there is a major disturbance in the magnetic field just to Tweedledum’s left. This produces a jarring sensation in Tweedledum’s left side. As a consequence, Tweedledum does not share Tweedledee’s feeling of symmetry.\nWhether a picture is symmetric is a property of its internal features, but it is also a feature that can be destroyed without changing the internal features by just adding more material to one side. It is a totality property of pictures, a property the picture has because it stops just where it does.4 Similarly, totality qualia are qualia that we have in part because we don’t have any more feelings than we actually do. Feelings of symmetry are totality qualia in this sense, as are many of the feelings of calm and peacefulness associated with Tweedledee’s state. It is not intuitive that totality qualia should be intrinsic to a region. Indeed, it seems intuitive that a duplicate of me that was extended to produce more sensory features would lack these feelings. Hence a duplicate of me would not share my conscious life in all respects, so Hawthorne’s premise (1) is also false. To be sure, these totality qualia are a somewhat speculative suggestion, but the Humean does not need them since Hawthorne’s anti-Humean argument is invalid.\n\n\n\n4 Ted Sider (2001, 2003) stresses the importance to a theory of intrinsicness of properties that are instantiated in virtue of the object not bearing relations to other objects. My example here is closely modeled on examples from his papers.\n\nReferences\n\nHall, Ned. 2004. “Causation and the Price of Transitivity.” In Causation and Counterfactuals, edited by John Collins, Ned Hall, and L. A. Paul, 181–203. Cambridge: MIT Press.\n\n\nHawthorne, John. 2002. “Deeply Contingent a Priori Knowledge.” Philosophy and Phenomenological Research 65 (2): 247–69. https://doi.org/10.1111/j.1933-1592.2002.tb00201.x.\n\n\n———. 2004. “Humeans Are Out of Their Minds.” Noûs 38 (2): 351–58. https://doi.org/10.1111/j.1468-0068.2004.00473.x.\n\n\nHumberstone, I. L. 1996. “Intrinsic/Extrinsic.” Synthese 108 (2): 205–67. https://doi.org/10.1007/bf00413498.\n\n\nLewis, David. 1973. Counterfactuals. Oxford: Blackwell Publishers.\n\n\n———. 1979. “Counterfactual Dependence and Time’s Arrow.” Noûs 13 (4): 455–76. https://doi.org/10.2307/2215339.\n\n\n———. 1994. “Humean Supervenience Debugged.” Mind 103 (412): 473–90. https://doi.org/10.1093/mind/103.412.473.\n\n\n———. 2004a. “Causation as Influence.” In Causation and Counterfactuals, edited by John Collins, Ned Hall, and L. A. Paul, 75–106. Cambridge: MIT Press.\n\n\n———. 2004b. “Void and Object.” In Causation and Counterfactuals, edited by John Collins, Ned Hall, and L. A. Paul, 277–90. Cambridge: MIT Press.\n\n\nLycan, William. 2001. “The Case for Phenomenal Externalism.” Philosophical Perspectives 15: 17–35. https://doi.org/10.1111/0029-4624.35.s15.2.\n\n\nMcGrath, Sarah. 2005. “Causation by Omission: A Dilemma.” Philosophical Studies 123 (1-2): 125–48. https://doi.org/10.1007/s11098-004-5216-z.\n\n\nMenzies, Peter. 1996. “Probabilistic Causation and the Pre-Emption Problem.” Mind 105 (417): 85–117. https://doi.org/10.1093/mind/105.417.85.\n\n\n———. 1999. “Intrinsic Versus Extrinsic Conceptions of Causation.” In Causation and Laws of Nature, edited by Howard Sankey, 313–29. Dordrecht: Kluwer.\n\n\nSider, Theodore. 2001. “Maximality and Intrinsic Properties.” Philosophy and Phenomenological Research 63 (2): 357–64. https://doi.org/10.1111/j.1933-1592.2001.tb00109.x.\n\n\n———. 2003. “Maximality and Microphysical Supervenience.” Philosophy and Phenomenological Research 66 (1): 139–49. https://doi.org/10.1111/j.1933-1592.2003.tb00247.x.\n\n\nWeatherson, Brian. 2005. “Scepticism, Rationalism and Externalism.” Oxford Studies in Epistemology 1: 311–31."
  },
  {
    "objectID": "posts/bayesdog/the-bayesian-and-the-dogmatist.html",
    "href": "posts/bayesdog/the-bayesian-and-the-dogmatist.html",
    "title": "The Bayesian and the Dogmatist",
    "section": "",
    "text": "There is a lot of philosophically interesting work being done in the borderlands between traditional and formal epistemology. It is easy to think that this would all be one-way traffic. When we try to formalise a traditional theory, we see that its hidden assumptions are inconsistent or otherwise untenable. Or we see that the proponents of the theory had been conflating two concepts that careful formal work lets us distinguish. Either way, the formalist teaches the traditionalist a lesson about what the live epistemological options are. I want to argue, more or less by example, that the traffic here should be two-way. By thinking carefully about considerations that move traditional epistemologists, we can find grounds for questioning some presuppositions that many formal epistemologists make.\nTo make this more concrete, I’m going to be looking at a Bayesian objection to a certain kind of dogmatism about justification. Several writers have urged that the incompatibility of dogmatism with a kind of Bayesianism is a reason to reject dogmatism. I rather think that it is reason to question the Bayesianism. To put the point slightly more carefully, there is a simple proof that dogmatism (of the kind I envisage) can’t be modelled using standard Bayesian modelling tools. Rather than conclude that dogmatism is therefore flawed, I conclude that we need better modelling tools. I’ll spend a fair bit of this paper on outlining a kind of model that (a) allows us to model dogmatic reasoning, (b) is motivated by the epistemological considerations that motivate dogmatism, and (c) helps with a familiar problem besetting the Bayesian.\nI’m going to work up to that problem somewhat indirectly. I’ll start with looking at the kind of sceptical argument that motivates dogmatism. I’ll then briefly rehearse the argument that shows dogmatism and Bayesianism are incompatible. Then in the bulk of the paper I’ll suggest a way of making Bayesian models more flexible so they are no longer incompatible with dogmatism. I’ll call these new models dynamic Keynesian models of uncertainty. I’ll end with a brief guide to the virtues of my new kind of model."
  },
  {
    "objectID": "posts/bayesdog/the-bayesian-and-the-dogmatist.html#sceptical-arguments",
    "href": "posts/bayesdog/the-bayesian-and-the-dogmatist.html#sceptical-arguments",
    "title": "The Bayesian and the Dogmatist",
    "section": "1 Sceptical Arguments",
    "text": "1 Sceptical Arguments\nLet H be some relatively speculative piece of knowledge that we have, say that G. E. Moore had hands, or that it will snow in Alaska sometime next year. And let E be all of our evidence about the external world. I’m not going to make many assumptions about what E contains, but for now E will stay fairly schematic. Now a fairly standard sceptical argument goes something like this. Consider a situation S in which our evidence is unchanged, but in which H is false, such as a brain-in-vat scenario, or a zombie scenario, or a scenario where the future does not resemble the past. Now a fairly standard sceptical argument goes something like this.\n\nTo know H we have to be in a position to know we aren’t in S\nWe aren’t in a position to know that we aren’t in S\nSo, we don’t know H\n\nThere are a few immediate responses one could make, but which I’m going to dismiss without argument here. These include claiming the setup is incoherent (as in, e.g., Williamson (2000)), rejecting the closure principle behind premise 1 (as in, e.g., Dretske (1971), accepting the conclusion (the sceptical response), or saying that in different sceptical arguments, one or other of these positions is correct. Instead I want to look at responses that question premise 2. In particular, I want to look at responses that offer us reasons to accept premise 2, since it seems here that the sceptic is at her strongest. (If the sceptic merely insists that premise 2 is reasonable, we can reply either that it isn’t, as I’m inclined to think, or that here is a case where intuition should be revised.)\nMany epistemologists will write papers responding to ‘the sceptic’. I think this is a mistake, since there are so many different possible sceptics, each with different arguments for premise 2. (And, of course, some sceptics do not argue from sceptical scenarios like this one.) Here are, for instance, three arguments that sceptics might give for premise 2.\n\nSomeone in S can’t discriminate her situation from yours.\nIndiscriminability is symmetric.\nIf you can’t discriminate our situation from S, you can’t know you’re not in S.\nSo you can’t know you’re not in S.\n\n\n\nSomeone in S has the same evidence as you do.\nWhat you can know supervenes on what your evidence is.\nSo, you can’t know you are not in S.\n\n\n\nThere is no non-circular argument to the conclusion that you aren’t in S.\nIf you were able to know you’re not in S, you would be able to produce a non-circular argument that concluded that you aren’t in S.\nSo you can’t know that you aren’t in S.\n\nI won’t say much about these arguments, save that I think in each case the second premise is very implausible. I suspect that most non-philosophers who are moved by sceptical arguments are tacitly relying on one or other of these arguments, but confirming that would require a more careful psychological study than I could do. But set those aside, because there’s a fourth argument that is more troubling. This argument takes its inspiration from what we might call Hume’s exhaustive argument for inductive scepticism. Hume said that we can’t justify induction inductively, and we can’t justify it deductively, and that exhausts the justifications, so we can’t justify induction. A similar kind of argument helps out the general sceptic.\n\nIf you know you aren’t in S, you know this a priori, or a posteriori\nYou can’t know you aren’t in S a posteriori\nYou can’t know you aren’t in S a priori\nSo, you can’t know you aren’t in S\n\nThis seems to be a really interesting argument to me. To make things simpler, I’ll stipulate that by a posteriori knowledge, I just mean knowledge that isn’t a priori. That makes the first premise pretty secure, as long as we’re assuming classical logic.1 Lots of philosophers take its third premise for granted. They assume that since it is metaphysically possible that you could be in S, this can’t be something you can rule out a priori. That strikes me as a rather odd capitulation to infallibilism. But I won’t push that here. Instead I’ll look at denials of the second premise.\n1 Perhaps not a wise assumption around here, but one that I’ll make throughout in what follows."
  },
  {
    "objectID": "posts/bayesdog/the-bayesian-and-the-dogmatist.html#dogmatism-and-a-bayesian-objection",
    "href": "posts/bayesdog/the-bayesian-and-the-dogmatist.html#dogmatism-and-a-bayesian-objection",
    "title": "The Bayesian and the Dogmatist",
    "section": "2 Dogmatism and a Bayesian Objection",
    "text": "2 Dogmatism and a Bayesian Objection\nSomeone who denies the second premise says that your empirical evidence can provide the basis for knowing that you aren’t in S, even though you didn’t know this a priori. I’m going to call such a person a dogmatist, for reasons that will become clear shortly. The dogmatist is not a sceptic, so the dogmatist believes that you can know H. The dogmatist also believes a closure principle, so the dogmatist also believes you can know E \\({\\supset}\\) H. If the dogmatist thought you could know E \\({\\supset}\\) H a priori, they’d think that you could know a priori that you weren’t in S. (This follows by another application of closure.) But they think that isn’t possible, so knowing E \\({\\supset}\\) H a priori isn’t possible. Hence you know E \\({\\supset}\\) H a posteriori.\nIf we reflect on the fact that E is your total evidence, then we can draw two conclusions. The first is that the dogmatist thinks that you can come to know H on the basis of E even though you didn’t know in advance that if E is true, then H is true. You don’t, that is, need antecedent knowledge of the conditional in order to be able to learn H from E. That’s why I’m calling them a dogmatist. The second point is that the dogmatist is now running head on into a piece of Bayesian orthodoxy.\nTo see the problem, note that we can easily prove (A), for arbitrary E, H and K.2\n2 Again, the proof uses distinctively classical principles, in particular the equivalence of A with (A \\({\\wedge}\\) B) \\({\\vee}\\) (A \\({\\wedge}\\) \\({\\lnot}\\)B.) But I will take classical logic for granted throughout. David Jehle pointed out to me that the proof fails without this classical assumption.\n(A)\n\nPr(E \\({\\supset}\\) H E \\({\\wedge}\\) K) \\({\\leq}\\) Pr(E \\({\\supset}\\) H K), with equality iff Pr(E \\({\\supset}\\) H E \\({\\wedge}\\) K) = 1\n\n\nProof:\n\n\n\n\n1.\nPr(E \\({\\supset}\\) H K) =\n\n\n\n\nPr(E \\({\\supset}\\) H E \\({\\wedge}\\) K) Pr(E K) +\n\n\n\n\nPr(E \\({\\supset}\\) H \\({\\lnot}\\)E \\({\\wedge}\\) K) Pr(\\({\\lnot}\\)E K)\nProb theorem\n\n\n2.\nPr(E \\({\\supset}\\) H \\({\\lnot}\\)E \\({\\wedge}\\) K) = 1\nLogic\n\n\n3.\nPr(E \\({\\supset}\\) H  E \\({\\wedge}\\) K) \\({\\leq}\\) 1\nProb theorem\n\n\n4.\nPr(E \\({\\supset}\\) H K) \\({\\geq}\\)\n\n\n\n\nPr(E \\({\\supset}\\) H E \\({\\wedge}\\) K) Pr(E K) +\n\n\n\n\nPr(E \\({\\supset}\\) H E \\({\\wedge}\\) K) Pr(\\({\\lnot}\\)E K)\n1, 2, 3\n\n\n5.\nPr(E  K) + Pr(\\({\\lnot}\\)E K) = 1\nProb theorem\n\n\n6.\nPr(E \\({\\supset}\\) H K) \\({\\geq}\\) Pr(E \\({\\supset}\\) H E \\({\\wedge}\\) K)\n4, 5\n\n\n\n\nIt is clear enough from the proof that line 6 is an equality iff line 3 is an equality, so we have proven (A). Now some authors have inferred from this something like (B) from (A).3\n3 Roger White (2006) and Stewart Cohen (2005) endorse probabilistic arguments against people who are, in my sense, dogmatists. John Hawthorne (2002) also makes a similar argument when arguing that certain conditionals, much like E \\({\\supset}\\) H, are a priori.\n(B)\n\nIt is impossible to go from not being in a position to know E \\({\\supset}\\) H to being in a position to know it just by receiving evidence E.\n\n\nThe transition here should raise an eyebrow or two. (A) is a principle of probability statics. (B) is a principle of epistemological kinematics. To get from (A) to (B) we need a principle linking probability and epistemology, and a principle linking statics and kinematics. Fortunately, orthodox Bayesian confirmation theory offers us suggestions for both principles. We’ll write Cr(A) for the agent’s credence in A, and CrE(A) for the agent’s credence in A when updated by receiving evidence E.\n\nLearning:\n\nIf CrE(A) \\({\\leq}\\) Cr(A), then it is impossible to go from not being in a position to know A to being in a position to know it just by receiving evidence E.\n\nBayes:\n\nCrE(A) = Cr(A  E). That is, learning goes by conditionalisation.\n\n\nA quick browse at any of the literature on Bayesian confirmation theory will show that these principles are both widely accepted by Bayesians. Philosophers, even Bayesians, make false assumptions, so neither of these principles is obviously true. Nevertheless, I’m going to accept Learning at least for the sake of argument. I’m going to argue instead that the inference from (A) to (B) fails because Bayes fails. That is, I’m going to accept that if we could prove a principle I’ll call Lower is true, then dogmatism in the sense I’m defending it fails.\n\nLower.\n\nCrE(E \\({\\supset}\\) H) is less than or equal to Cr(E \\({\\supset}\\) H).\n\n\nNow there is a bad argument around here that the dogmatist might make. It might be argued that since the Bayesian approach (including Bayes) involves so much idealisation it could not be applicable to real agents. That’s a bad argument because the Bayesian approach might provide us with a good model for real agents, and models can be useful without being scale models. As long as the Bayesian model is the most appropriate model in the circumstances, then we can draw conclusions for the real world from facts about the model. The problem arises if there are alternative models which seem to fit just as well, but in which principles like Lower are not true. If there are alternative models that seem better suited (or at least just as well suited) to modelling the situation of initial evidence acquisition, and those models do not make Lower true, then we might think the derivation of Lower in the Bayesian model is a mere consequence of the arbitrary choice of model. In the next section I will develop just such a model. I won’t argue that it is the best model, let alone the only alternative to the Bayesian model. But I will argue that it is as good for these purposes as the Bayesian model, and it does not imply Lower."
  },
  {
    "objectID": "posts/bayesdog/the-bayesian-and-the-dogmatist.html#bayes-and-keynes",
    "href": "posts/bayesdog/the-bayesian-and-the-dogmatist.html#bayes-and-keynes",
    "title": "The Bayesian and the Dogmatist",
    "section": "3 Bayes and Keynes",
    "text": "3 Bayes and Keynes\nThe traditional Bayesian model of a rational agent starts with the following two principles.\n\nAt any moment, the agent’s credal states are represented by a probability function.\nFrom moment to moment, the agent’s credal states are updated by conditionalisation on the evidence received.\n\nOver recent decades many philosophers have been interested in models that relax those assumptions. One particular model that has got a lot of attention (from e.g. Isaac Levi (1974, 1980), Richard Jeffrey (1983), Bas Fraassen (1990), Alan Hájek (2000, 2003) and many others) is what I’ll call the static Keynesian model. This model has the following features.\n\nAt any moment, the agent’s credal states are represented by a set of probability functions, called their representor.\nThe agent holds that p is more probable than q iff the probability of p is greater than the probability of q according to all probability functions in their representor. The agent holds that p and q are equally probable iff the probability of p is equal to the probability of q according to all probability functions in their representor.\nFrom moment to moment, the agent’s credal states are updated by conditionalising each of the functions in the representor on the evidence received.\n\nThe second point is the big attraction. It allows that the agent need not hold that p is more probable than q, or q more probable than p, or that p and q are equally probable, for arbitrary p and q. And that’s good because it isn’t a rationality requirement that agents make pairwise probability judgments about all pairs of propositions. Largely because of this feature, I argued in an earlier paper that this model could be use to formalise the key philosophical ideas in Keynes’s Treatise on Probability. That’s the reason I call this a ‘Keynesian’ model.\nThe modifier ‘static’ might seem a little strange, because the agent’s representor does change when she receives new evidence. But the change is always of a certain kind. Her ‘hypothetical priors’ do not change. If at t1 her evidence is E1 and her representor R1, and at t2 her evidence is E2 and her representor R2, then there is a ‘prior’ representor R0 such that the following two claims are true for all probability functions Pr.\n\nPr \\({\\in}\\) R1 \\({\\leftrightarrow}\\) [\\({\\exists}\\)Pr0 \\({\\in}\\) R0: \\({\\forall}\\)p (Pr(p) = Pr0(p E1)]\nPr \\({\\in}\\) R2 \\({\\leftrightarrow}\\) [\\({\\exists}\\)Pr0 \\({\\in}\\) R0: \\({\\forall}\\)p (Pr(p) = Pr0(p E2)]\n\nThat is, there is a set of probability functions such that the agent’s representor at any time is the result of conditionalising each of those functions on her evidence. I’ll call any model with this property a static model, so the model described above is the static Keynesian model.\nNow there is a lot to like about the static Keynesian model, and I have made extensive use of it previous work. It is a particularly useful model to use when we need to distinguish between risk and uncertainty in the sense that these terms are used in Keynes’s 1937 article “The General Theory of Employment”.4 The traditional Bayesian model assumes that all propositions are risky, but in real life some propositions are uncertain as well, and in positions of radical doubt, where we have little or no empirical evidence, presumably most propositions are extremely uncertain. And using the static Keynesian model does not mean we have to abandon the great work done in Bayesian epistemology and philosophy of science. Since a Bayesian model is a (degenerate) static Keynesian model, we can say that in many circumstances (namely circumstances where uncertainty can be properly ignored) the Bayesian model will be appropriate. Indeed, these days it is something like a consensus among probabilists or Bayesians that the static Keynesian model is a useful generalisation of the Bayesian model. For example in Christensen (2005) it is noted, almost as an afterthought, that the static Keynesian model will be more realistic, and hence potentially more useful, than the traditional Bayesian model. Christensen doesn’t appear to take this as any kind of objection to Bayesianism, and I think this is just the right attitude.\n4 The clearest statement of the distinction that I know is from that paper.\n\nBy ‘uncertain’ knowledge, let me explain, I do not mean merely to distinguish what is known for certain from what is only probable. The game of roulette is not subject, in this sense, to uncertainty; nor is the prospect of a Victory bond being drawn. Or, again, the expectation of life is only slightly uncertain. Even the weather is only moderately uncertain. The sense in which I am using the term is that in which the prospect of a European war is uncertain, or the price of copper and the rate of interest twenty years hence, or the obsolescence of a new invention, or the position of private wealth owners in the social system in 1970. About these matters there is no scientific basis on which to form any calculable probability whatever. We simply do not know. Nevertheless, the necessity for action and decision compels us as practical men to do our best to overlook this awkward fact and to behave exactly as we should if we had behind us a good Benthamite calculation of a series of prospective advantages and disadvantages, each multiplied by its appropriate probability, waiting to be summed. (Keynes 1937, 114–15)\n\nBut just as the static Keynesian is more general than the Bayesian model, there are bound to be interesting models that are more general than the static Keynesian model. One such model is what I call the dynamic Keynesian model. This model has been used by Seth Yalcin to explicate some interesting semantic theories, but to the best of my knowledge it has not been used for epistemological purposes before. That should change. The model is like the static Keynesian model in its use of representors, but it changes the way updating is modelled. When an agent with representor R receives evidence E, she should update her representor by a two step process.\n\nReplace R with U(R, E)\nConditionalise U(R, E), i.e. replace it with {Pr( E): Pr is in U(R, E)}\n\nIn this story, U is a function that takes two inputs: a representor and a piece of evidence, and returns a representor that is a subset of the original representor. Intuitively, this models the effect of learning, via getting evidence E, what evidential relationships obtain. In the static Keynesian model, it is assumed that before the agent receives evidence E, she could already say which propositions would receive probabilistic support from E. All of the relations of evidential support were encoded in her conditional probabilities. There is no place in the model for learning about fundamental evidential relationships. In the dynamic Keynesian model, this is possible. When the agent receives evidence E, she might learn that certain functions that were previously in her representor misrepresented the relationship between evidence and hypotheses, particularly between evidence E and other hypotheses. In those cases, U(R, E) will be her old representor R, minus the functions that E teaches her misrepresent these evidential relationships.\nThe dynamic Keynesian model seems well suited to the dogmatist, indeed to any epistemological theory that allows for fundamental evidential relationships to be only knowable a posteriori. As we’ll see below, this is a reason to stop here in the presentation of the model and not try and say something systematic about the behaviour of U. Instead of developing the model by saying more about U, we should assess it, which is what I’ll do next."
  },
  {
    "objectID": "posts/bayesdog/the-bayesian-and-the-dogmatist.html#in-defence-of-dynamism",
    "href": "posts/bayesdog/the-bayesian-and-the-dogmatist.html#in-defence-of-dynamism",
    "title": "The Bayesian and the Dogmatist",
    "section": "4 In Defence of Dynamism",
    "text": "4 In Defence of Dynamism\nIn this section I want go over three benefits of the dynamic Keynesian model, and then say a little about how it relates to the discussion of scepticism with which we opened. I’m not going to say much about possible objections to the use of the model. That’s partially for space reasons, partially because what I have to say about the objections I know of is fairly predictable, and partially because the model is new enough that I don’t really know what the strongest objections might be. So here we’ll stick to arguments for the view.\n\n4.1 The Dogmatist and the Keynesian\nThe first advantage of the dynamic Keynesian model is that because it does not verify Lower, it is consistent with dogmatism. Now if you think that dogmatism is obviously false, you won’t think this is much of an advantage. But I tend to think that dogmatism is one of the small number of not absurd solutions to a very hard epistemological problem with no obvious solution, so we should not rule it out pre-emptively. Hence I think our formal models should be consistent with it. What is tricky is proving that the dynamic Keynesian model is indeed consistent with it.\nTo see whether this is true on the dynamic Keynesian model, we need to say what it is to lower the credence of some proposition. Since representors map propositions onto intervals rather than numbers, we can’t simply talk about one ‘probability’ being a smaller number than another.5 On the static Keynesian model, the most natural move is to say that conditionalisation on E lowers the credence of p iff for all Pr in the representor, Pr(p) &gt; Pr(p  E). This implies that if every function in the representor says that E is negatively relevant to p, then conditionalising on E makes p less probable. Importantly, it allows this even if the values that Pr(p) takes across the representor before and after conditionalisation overlap. So what should we say on the dynamic Keynesian model? The weakest approach that seems viable, and not coincidentally the most plausible approach, is to say that updating on E lowers the credence of p iff the following conditions are met:\n5 Strictly speaking, the story I’ve told so far does not guarantee that for any proposition p, the values that Pr(p) takes (for Pr in the representor) form an interval. But it is usual in more detailed presentations of the model to put constraints on the representor to guarantee that happens, and I’ll assume we’ve done that.\nFor all Pr in U(R, E), Pr(p E) &lt; Pr(p)\nFor all Pr in R but not in U(R, E), there is a Pr\\(^\\prime\\) in U(R, E) such that Pr\\(^\\prime\\)(p  E) &lt; Pr(p)\n\nIt isn’t too hard to show that for some models, updating on E does not lower the credence of E \\({\\supset}\\) H, if lowering is understood this way. The following is an extreme example, but it suffices to make the logical point. Let R be the minimal representor, the set of all probability functions that assign probability 1 to a priori certainties. And let U(R, E) be the singleton of the following probability function, defined only over Boolean combinations of E and H: Pr(E \\({\\wedge}\\) H) = Pr(E \\({\\wedge}\\) \\({\\lnot}\\)H) = Pr(\\({\\lnot}\\)E \\({\\wedge}\\) H) = Pr(\\({\\lnot}\\)E \\({\\wedge}\\) \\({\\lnot}\\)H) = \\(\\frac{1}{4}\\). Then the probability of E \\({\\supset}\\) H after updating is \\(\\frac{3}{4}\\). (More precisely, according to all Pr in U(R, E), Pr(E \\({\\supset}\\) H) = \\(\\frac{3}{4}\\).) Since before updating there were Pr in R such that Pr(E \\({\\supset}\\) H) &lt; \\(\\frac{3}{4}\\), in fact there were Pr in R such that Pr(E \\({\\supset}\\) H) = 0, updating on E did not lower the credence of E \\({\\supset}\\) H. So the dynamic Keynesian model does not, in general, have as a consequence that updating on E lowers the credence of E \\({\\supset}\\) H. This suggests that Lower in general is not true.\nIt might be objected that if evidence E supports our knowledge that E \\({\\supset}\\) H, then updating on E should raise the credence of E \\({\\supset}\\) H. And if we define credence raising the same way we just defined credence lowering, updating on E never raises the credence of E \\({\\supset}\\) H. From a Keynesian perspective, we should simply deny that evidence has to raise the credence of the propositions known on the basis of that evidence. It might be sufficient that getting this evidence removes the uncertainty associated with those propositions. Even on the static Keynesian model, it is possible for evidence to remove uncertainty related to propositions without raising the probability of that proposition. A little informally, we might note that whether an agent with representor R is sufficiently confident in p to know that p depends on the lowest value that Pr(p) takes for Pr \\({\\in}\\) R, and updating can raise the value of this ‘lower bound’ without raising the value of Pr(p) according to all functions in R, and hence without strictly speaking raising the credence of p.\nThe above illustration is obviously unrealistic, in part because U could not behave that way. It’s tempting at this stage to ask just how U does behave so we can work out if there are more realistic examples. Indeed, it’s tempting to try to attempt to provide a formal description of U. This temptation should be resisted. The whole point of the model is that we can only learn which hypotheses are supported by certain evidence by actually getting that evidence. If we could say just what U is, we would be able to know what was supported by any kind of evidence without getting that evidence. The best we can do with respect to U is to discover some of its contours with respect to evidence much like our own. And the way to make those discoveries will be to do scientific and epistemological research. It isn’t obvious that, say, looking for nice formal properties of U will help at all.\n\n\n4.2 The Problem of the Priors\nOne really nice consequence of the dynamic Keynesian approach is that it lets us say what the representor of an agent with no empirical information should be. Say a proposition is a priori certain iff it is a priori that all rational agents assign credence 1 to that proposition. Then the representor of the agent with no empirical evidence is {Pr: \\({\\forall}\\)p: If p is a priori certain, then Pr(p) = 1}. This is the minimal representor I mentioned above. Apart from assigning probability 1 to the a priori certainties, the representor is silent. Hence it treats all propositions that are not a priori certain in exactly the same way. This kind of symmetric treatment of propositions is not possible on the traditional Bayesian conception for logical reasons. (The reasons are set out in the various discussions of the paradoxes of indifference, going back to Bertrand (1888).) Such a prior representor is consistent with the static Keynesian approach, but it yields implausible results, since conditionalising on E has no effect on the distribution of values of Pr(p) among functions in the representor for any p not made a priori certain by E. (We’ll say p is made a priori certain by E iff E \\({\\supset}\\) p is a priori certain.) So if this is our starting representor, we can’t even get probabilistic evidence for things that are not made certain by our evidence.6 So on the static Keynesian model, this attractively symmetric prior representor is not available.\n6 The argument in the text goes by a little quickly, because I’ve defined representors in terms on unconditional probabilities and this leads to complications to do with conditionalising on propositions of zero probability. A better thing to do, as suggested by Hájek (2003), is to take conditional probability as primitive. If we do this we’ll define representors as sets of conditional probability functions, and the a priori representor will be {Pr: If p \\({\\supset}\\) q is a priori certain, then Pr(q p) = 1}. Then the claim in the text will follow.I think one of the motivations of anti-dogmatist thinking is the thought that we should be able to tell a priori what is evidence for what. If it looking like there is a cow in front of us is a reason to think there is a cow in front of us, that should be knowable a priori. I think the motivation for this kind of position shrinks a little when we realise that an a priori prior that represented all the connections between evidence and hypotheses would have to give us a lot of guidance as to what to do (epistemically speaking) in worlds quite unlike our own. Moreover, there is no reason we should have lots that information. So consider, for a minute, a soul in a world with no spatial dimensions and three temporal dimensions, where the primary source of evidence for souls is empathic connection with other souls from which they get a (fallible) guide to those souls’ mental states. When such a soul conditionalises on the evidence “A soul seems to love me” (that’s the kind of evidence they get) what should their posterior probability be that there is indeed a soul that loves them? What if the souls have a very alien mental life, so they instantiate mental concepts very unlike our own, and souls get fallible evidence of these alien concepts being instantiated through empathy? I think it’s pretty clear we don’t know the answers to these questions. (Note that to answer this question we’d have to know which of these concepts were grue-like, and which were projectable, and there is no reason to believe we are in a position to know that.) Now those souls are presumably just as ignorant about the epistemologically appropriate reaction to the kinds of evidence we get, like seeing a cow or hearing a doorbell, as we are about their evidence. The dynamic Keynesian model can allow for this, especially if we use the very weak prior representor described above. When we get the kind of evidence we actually get, the effect of U is to shrink our representors to sets of probability functions which are broadly speaking epistemically appropriate for the kind of world we are in. Before we got that evidence, we didn’t know how we should respond to it, just like the spaceless empathic souls don’t know how to respond to it, just like we don’t know how to respond to their evidence.\nIt is a commonplace observation that (a) prior probabilities are really crucial in Bayesian epistemology, but (b) we have next to no idea what they look like. I call this the problem of the priors, and note with some satisfaction that the dynamic Keynesian model avoids it. Now a cynic might note that all I’ve done is replace a hand-wavy story about priors with a hand-wavy story about updating. That’s true, but nevertheless I think this is progress. The things I’m being deliberately unclear about, such as what U should look like for E such as “Some other non-spatial tri-temporal soul seems to love me” are things that (a) my theory says are not a priori knowable, and (b) I don’t have any evidence concerning. So it isn’t surprising that I don’t have much to say about them. It isn’t clear that the traditional Bayesian can offer any story, even by their own lights, as to why they are less clear about the structure of the prior probability conditional on such an E.\n\n\n4.3 The Problem of Old Evidence\nWhen we get evidence E, the dynamic Keynesian model says that we should do two things. First, we should throw out some probability functions in our representor. Second, we should conditionalise those that remain. But this is a normative condition, not a description of what actually happens. Sometimes, when we get evidence E, we may not realise that it is evidence that supports some theory T. That is, we won’t sufficiently cull the representor of those probability functions where the probability of T given E is not high. Housecleaning like this is hard, and sometimes we only do it when it becomes essential. In this case, that means we only do it when we start paying serious attention to T. In that case we may find that evidence E, evidence we’ve already incorporated, in the sense of having used in conditionalisation, gives us reason to be more confident than we were in T. In such a case we’ll simply cull those functions where probability of T given E is not high, and we will be more confident in T. That’s how old evidence can be relevant on the dynamic Keynesian model. Since we have a story about how old evidence can be relevant, there is no problem of old evidence for the dynamic Keynesian.\nFamously, there is a problem of old evidence for traditional Bayesians. Now I’m not going to rehearse all the arguments concerning this problem to convince you that this problem hasn’t been solved. That’s in part because it would take too long and in part because I’m not sure myself that it hasn’t been solved. But I will note that if you think the problem of old evidence is a live problem for traditional Bayesians, then you have a strong reason for taking the dynamic Keynesian model seriously.\n\n\n4.4 Why Should We Care?\nThe sceptic’s opening move was to appeal to our intuition that propositions like E \\({\\supset}\\) H are unknowable. We then asked what reasons we could be given for accepting this claim, because the sceptic seems to want to derive quite a lot from a raw intuition. The sceptic can respond with a wide range of arguments, four of which are mentioned above. Here we focussed on the sceptic’s argument from exhaustion. E \\({\\supset}\\) H isn’t knowable a priori, because it could be false, and it isn’t knowable a posteriori, because, on standard models of learning, our evidence lowers its credibility. My response is to say that this is an artefact of the model the sceptic (along with everyone else) is using. There’s nothing wrong with using simplified models, in fact it is usually the only way to make progress, but we must be always wary that our conclusions transfer from the model to the real world. One way to argue that a conclusion is a mere artefact of the model is to come up with a model that is sensitive to more features of reality in which the conclusion does not hold. That’s what I’ve done here. The dynamic Keynesian model is sensitive to the facts that (a) there is a distinction between risk and uncertainty and (b) we can learn about fundamental evidential connections. In the dynamic Keynesian model, it isn’t true that our evidence lowers the probability of E \\({\\supset}\\) H. So the anti-sceptic who says that E \\({\\supset}\\) H is knowable a posteriori, the person I’ve called the dogmatist, has a defence against this Bayesian argument. If the response is successful, then there may well be other applications of the dynamic Keynesian model, but for now I’m content to show how the model can be used to defend the dogmatic response to scepticism."
  },
  {
    "objectID": "posts/review-real-cond/review-of-real-conditionals.html",
    "href": "posts/review-real-cond/review-of-real-conditionals.html",
    "title": "Review of “Real Conditionals”",
    "section": "",
    "text": "Over the last two decades, William Lycan’s work on the semantics of conditionals has been distinguished by his careful attention to the connection between syntax and semantics, and more generally by his impeccible methodology. Lycan takes compositionality seriously, so in his theory the meaning of ‘even if’, for example, should be a combination of the meaning of ‘even’ and the meaning of ‘if’. After reading his work, it’s hard to take seriously work which does not share this methodology.\nLycan’s semantics for conditionals makes central use of what he calls ‘events’. An event is not a possible world, for it need not be complete or consistent. It is more like what Barwise and Perry call a ‘situation’. Conditionals are quantifiers over events, as follows:\n\nP if Q = P in any event in which Q\nP only if Q = P in no event other than one in which Q\nP even if Q = P in any event including any in which Q (17)\n\nThe quantifiers here are contextually restricted. Lycan includes in the semantic analysis a predicate of events R, whose role is to restrict the quantifiers over events. An event satisfies R only if it is ‘envisaged’, which is similar to saying it is a ‘real’ or ‘relevant’ possibility. The value of R changes frequently; sometimes it even changes mid-sentence. This fact is appealed to frequently in explaining some surprising behaviour of conditionals. For example, the invalidity of antecedent-strengthening: if p then r, so if p and q then r, is explained by saying the class of events relevant to the truth of the conclusion may be larger than the class of events relevant to the truth of the premise. In particular, at least one event in which p and q is relevant to the conclusion, but no such event need be relevant to the premise. A similar explanation is given for the failure of transitivity and contraposition.\nThe quantifier domain must include some non-actual events or conditionals will turn into material implications. Surprisingly, Lycan says that sometimes the quantifier includes only non-actual events. In these cases, it is possible that all (relevant) p-events can be q-events, even though p is true but not q. That is, in these cases modus ponens is invalid. Lycan argues persuasively that the case against modus ponens is at least as strong as the case against antecedent-strengthening, contraposition and modus tollens.\nThere is an extended discussion of ‘even’, which is necessary for providing a theory of ‘even if’. Lycan first suggests that Even Grannie was sober means Everyone, including Grannie, was sober. The quantifier domain includes everyone no less likely than Grannie to be sober. After discussing some counterexamples, Lycan suggests that instead it means Everyone plus Grannie was sober, where the quantifer ranges over everyone whom you would expect to be sober. Lycan is committed to ‘even’ being a quantifier because of its syntactic similarity to ‘only’, and because of the “initial plausibility of … universally quantified paraphrases” (121) of sentences involving ‘even’. The discussion here is fascinating, but not conclusive. It isn’t clear, for example, that ‘even’ and ‘only’ have the same syntactic role. Compare Even supposing Jack were here, he wouldn’t help with *Only supposing Jack were here, he wouldn’t help.\nLycan also includes a helpful discussion of how his theory handles Allan Gibbard’s ‘Riverboat Puzzle’ and related cases. It is troubling, for those who don’t analyse conditionals as material implications, that sometimes one speaker can say If p, q, another can say If p, not q, and both seem to be speaking truly. Lycan argues we should accept this troubling consequence, but explain it by making R sensitive to epistemic considerations.\nAs well as these points, Lycan raises some powerful objections to ‘No Truth Value’ theories of conditionals, and against the extensive use of probability theory in semantics. The book concludes with two appendicies on ‘non-conditional’ conditionals, such as If you’re hungry, there’s biscuits on the sideboard.\nThere’s a lot to like about this book, not least it’s witty, even charming, style. Lycan considers more examples, from more diverse sources, than most writers. The theory he presents is innovative and at least aims to be comprehensive. And of course there are some good arguments for it. Despite this there are, as always, occasional grounds for complaint.\nAlthough Lycan is very careful to get the syntax of ‘if’ right, and proves that unlike ‘and’ and ‘or’ it is not a co-ordinating conjunction, it is not so clear that the syntactic evidence provides distinctive support for his semantic theory. If it’s consistent with the syntax to say p if q means All relevant q-events are p-events, it’s consistent with the syntax to say that it means All nearby q-worlds are p-worlds. So the syntactic argument for preferring Lycan’s theory, to, say, Stalnaker’s, is not obviously overpowering. Lycan suggests that we can naturally paraphrase conditionals as quantifications over events, but since he is using event ‘in a slightly uncommon way’ (17) it is not obvious what support this gives for his theory.\nThere are few reasons to favour the use of events rather than worlds in the analysis. The fact that events can be incomplete seems to only cause complications for the theory. The fact that they can be inconsistent is used to rescue some intuitions about conditionals with impossible antecedents, but many would argue those intuitions should be discarded.\nBut the main worry is that Lycan needs to say more about some key notions, particularly about his R and about validity. In the discussion of the Riverboat Puzzle, Lycan says, “I do not have a good enough intuitive handle on my own notion of ‘relevance’ to provide a crushing answer [to a question about why certain events are not covered by R].” (173)  Lycan says that for an event to be R, “the utterer must have it at least tacitly in mind as a live prospect.” (19) All events in R are ‘envisaged’, to use the term he lands on. But “there is somethig slightly artificial or stylized about ‘envisaging’ … ‘Envisaging’ is not a purely de facto cognitive or other psychological state.” (30) The upshot is that the envisaged possibilities are some, but not always all, of those that are (possibly tacitly) regarded as live. Just which possibilities then? We are never given a specific account. Any account we do get is, as in the above quote, almost immediately qualified. Since R does so much work, the reader is probably owed a little more here. (This point is made at greater length in Ken Turner’s excellent review of Real Conditionals in the Journal of Pragmatics forthcoming.)\nWe are also never specifically given an account of validity. We are told that several argument forms, from antecedent-strengthening to modus ponens, are invalid. This seems to mean that one could assert their premises then reject, or a least decline to assert, their conclusion. It’s important that this process of assertion and rejection take place in real time, because the value of R needs to change for the arguments to be invalid. Lycan has some arguments that this conception of validity is the philosophically interesting one, but this deserves more treatment. The logical reforms it draws in go well beyond the logic of conditionals. On Lycan’s approach, All swans are white, so all Australian swans are white is, presumably, invalid, since the scope of the quantifier could change from premise to conclusion. And contraposition fails for valid arguments. Contraposed modus ponens: p, not q, so not if p, q is valid, but modus ponens is not.\nNone of this is to deny that Real Conditionals is a great contribution to the literature, and if it causes more theorists to pay serious attention to Lycan’s Event Theory, that would be an excellent consequence."
  },
  {
    "objectID": "posts/review-sorensen/review-of-vagueness-and-contradiction.html",
    "href": "posts/review-sorensen/review-of-vagueness-and-contradiction.html",
    "title": "Review of “Vagueness and Contradiction”",
    "section": "",
    "text": "Like all epistemicists, Roy Sorensen holds that vagueness poses no threat to classical logic, and that appearances to the contrary are the result of mistakenly assigning semantic force to certain barriers to inquiry. We may not be able to know whether 932 seconds after noon is still noonish, but there is a fact of the matter about whether it is. Hence the sentence 932 seconds after noon is noonish is either true or false, just as adherents of classical logic presuppose, and the threat from vagueness to classical logic dissolves.\n\nPublished in Australasian Journal of Philosophy 81: 290-292.\n\nBut Sorensen is not an orthodox epistemicist. He does not hold that these barriers to inquiry rise because of our limited powers of discrimination. That would imply that a more discerning observer, say God, could know where the boundary is. Sorensen holds that vagueness is an absolute barrier to inquiry. No one can know whether 932 seconds after noon is noonish, even God. This is because competently using the vague predicate ‘noonish’ requires believing a particular analytic falsehood involving it, and having this belief prevents knowing the truth about a borderline case. Much of this book is dedicated to defending these surprising claims. The first half of the book argues that this is the right thing to say about vague cases, and the second half provides more general arguments that we can and should believe analytic falsehoods.\nIt’s illuminating to compare Sorensen’s epistemicism with that of Timothy Williamson. A core feature of Williamson’s position is neatly summarised in this quote, which Sorensen cites: “for the epistemicist, definiteness is truth under all sharp interpretations of the language indiscriminable from the right one.” (“On the Structure of Higher Order Vagueness” Mind 108 (1999): 127‑43.)  Sorensen disagrees with the Williamson’s position in four ways. Two of these disagreements are immediate, and two are with deeper presuppositions of Williamson’s.\nFirst, Sorensen thinks that Williamson here ignores the need for ‘completeness’. Williamson holds that p is definite iff, roughly, it is true on all interpretations we cannot know to be incorrect. Call these the admissible interpretations. Sorensen claims that is not enough for p to be knowable, and hence definitely true. It must also be knowable that these are all the admissible interpretations.\nSecondly, indiscriminability is always indiscriminability by something, so on Williamson’s account definiteness is only defined relative to a discriminator. Sorensen wants there to be absolute borderline cases, and absolute indefiniteness, so he cannot rest with this definition. Sorensen thinks that unless we accept absolute borderline cases, we do not properly respect the sense in which vagueness is an absolute barrier to inquiry. The two other innovations in Sorensen’s theory guarantee that his theory has place for absolute indefiniteness.\nConsider a normal Sorites conditional, say If 932 seconds after noon is noonish, so is 933 seconds. Sorensen holds that being a competent user of ‘noonish’ requires that one believe every such conditional involving ‘noonish’. Someone who failed to believe it would not be competent in the language. Although Sorensen always puts this in terms of linguistic competence, he also says that one who didn’t believe this couldn’t have beliefs about the extension of our predicates. The most natural conclusion to draw is that from Sorensen’s perspective, one who doesn’t believe the Sorites conditional lacks the concept NOONISH. Sorensen talks about predicates rather than concepts, so he doesn’t put it quite this way, but it succinctly summarises the picture he sketches. Moreover, beliefs in such Sorites conditionals are a priori, despite the fact that one of them is analytically false. These are distinctive views, and they need good arguments.\nA bad argument would be, “It is always irrational to deny a Sorites conditional, so it is always rational to believe it.” This ignores the possibility that agnosticism about the conditional is always possible, and sometimes desirable. Sorensen does not endorse this argument, though he does note it shows that Sorites conditionals satisfy a ‘negative conception’ of the a priori: no empirical evidence can make us believe they are false.\nSorensen’s argument seems to be that believing every Sorites conditional gives us many true beliefs at the cost of only one false belief. He thinks that cost is worth the benefit. But this is at best a reason why we should believe Sorites conditionals, not why God should. And it doesn’t imply much about why God needs to believe this falsehood if He is to have the concept NOONISH. If we think subjectivism about language implies that God can’t know more about our language than we do, that may draw God into our dilemma. But it should seem very implausible, especially to an epistemicist, that God can’t know more about our language than we do. So even if it is good advice to believe every Sorites conditional, it does not follow that those who spurn this advice lack any concepts, or lack linguistic competence.\nIn any case, there are other costs to adopting Sorensen’s advice and believing a bunch of Sorites conditionals that we know includes a falsehood. For example, we can no longer safely believe the logical consequences of some things we believe. Sorensen happily accepts that consequence. He holds p and q can both be a priori even though their conjunction is not a priori. In chapter 6 Sorensen replies to several arguments against this, including a purported proof that a priority agglomerates across conjunction. The proof assumes that all logical truths are a priori. Sorensen says this is false because there are logical truths that are too complex for us to believe, a priori or otherwise. Since the only logical truth needed in the proof was p → (q → (p & q)), this is not obviously a sound response.\nSorensen has a more speculative reason for thinking there is absolute vagueness. (This is the final way in which Sorensen’s position differs from Williamson.) Consider a card that has The sentence on the other side of this card is false written on each side. If the sentences have truth values, then one is true and the other false. Whichever is true is a truth without a truthmaker, for any truthmaker would do just as well at making the other true. So Sorensen concludes that here we have a truth without a truthmaker, and the truthmaker principle is false. If there are some truths without truthmakers, there could be several. Sorensen holds that a is F is such a truth whenever a is an F which is a borderline F. Assume further that only truths with truthmakers are knowable, because knowability goes via knowing truthmakers, and we conclude that no one could know of a borderline F whether it is F. This is quite an interesting line of thought, and it deserves further attention. (Sorensen is quite upfront about how speculative it is.) Two immediate issues spring to mind. First, it is not clear how this is still a version of epistemicism, for vagueness is now at base a metaphysical phenomenon. There are epistemic consequences, but vagueness is constituted by the fact that there are truths without truthmakes, not by the unknowability of these. Secondly, and relatedly, it is no longer clear how higher order vagueness will be incorporated into the model. The most obvious thought is that there will be no truthmaker for the claim that some particular truth has a truthmaker. But whether some object is a truthmaker for some truth is not contingent, and it is notoriously difficult to apply truthmaker theory to necessary truths. Since every proposition entails any necessary truth, it is plausible that any object is a truthmaker for a necessary truth.\nSorensen argues that we should believe all Sorites conditionals, including ones that are analytically false. He notes this requires an argument that we can, and should, believe some analytic falsehoods. (He calls these impossibilities ‘contradictions’, a term some may think should be reserved for sentences of the form p & ¬p.) His argument that we can is fairly quick. Assume, for reductio, the philosophical thesis that we cannot believe analytic falsehoods. As a philosophical thesis, this is analytically true if true at all. But Sorensen believes its negation. So it is possible for someone to believe an analytic falsehood. The weakest premise here is that if we cannot believe analytic falsehoods, then it is analytic that we cannot. If it turns out that only creatures with a language of thought can believe analytic falsehoods, and it is a contingent feature of us that we lack a language of thought, Sorensen’s premise is false.\nThe argument that we should believe some analytic falsehoods uses a version of the preface paradox. If we can believe analytic falsehoods, we should take apparent occurrences of this (as when we make arithmetic errors) at face value. That is, reason demands we believe that we believe an analytic falsehood. But this implies it is provable that our beliefs are not collectively true. So if we follow the dictates of reason, it is provable we believe something provably false. This argument is obviously useful for removing a particular barrier to accepting Sorensen’s account of vagueness, that it seems absurd that reason could require we believe an analytic falsehood. But even if we reject Sorensen’s theory of vagueness, they are independently interesting contributions to the theory of belief.\nSorensen makes two distinctive contributions to the theory of vagueness here. First, he argues that linguistic competence demands that we believe Sorites conditionals. Secondly, he links the existence of vagueness to the failure of the truthmaker principle. As those familiar with Sorensen’s work will suspect, he makes these contributions in a lively and entertaining way. Anyone working on vagueness, and especially anyone interested in investigating the range of theories of vagueness that preserve classical logic, should pay it close attention."
  },
  {
    "objectID": "posts/iri/interest-relative-invariantism.html",
    "href": "posts/iri/interest-relative-invariantism.html",
    "title": "Interest-Relative Invariantism",
    "section": "",
    "text": "0.1 Introduction\nOne of the initial motivations for epistemological contextualism was that the appropriateness of self-ascriptions of knowledge seemed to depend, in some circumstances, on factors that were traditionally thought to be epistemologically irrelevant. So whether our hero S was prepared to say “I know that p” would depend not just on how strong S’s evidence for p was, or how strongly they believed it, but on factors such as how much it mattered whether p was true, or what alternatives to p were salient in their thought or talk.\n\nPublished in Routledge Handbook of Epistemic Contextualism, edited by Jonathan Jenkins Ichikawa, 2017, 240-253.\n\nIt was immediately noted that this data point, even if accepted, is consistent with a number of theories of the truth of knoweldge ascriptions. It might be that things like stakes and salient alternatives affect the assertability conditions of knowledge ascriptions, but not their truth conditions  (Rysiew 2017). But let’s assume that we’ve convinced ourselves that this isn’t right, and that whether S can truly (and not just appropriately) say “I know that p” depends on things like the stakes or salient alternatives.\nIt still doesn’t follow that contextualism is true. It might be that in all contexts, whether an utterance of “S knows that p” is true depends on the stakes for S, or on the salient alternatives for S. That would be true, the idea is, whether S is talking about herself, or someone else is talking about her. The stakes, or salient alternatives, would affect the truth conditions of S’s utterance not because she is the one doing the talking, but the one being talked about. The practical and theoretical situation of the ascribee of the knowledge ascription may be relevant, even if the practical and theoretical situation of the ascribor need not be.\nThis line of thought leads to the idea that knowledge itself is interest-relative. Whether an utterance here and now of “S knows that p” is true, i.e., whether S knows that p, depends on how much it matters to S that p is true, or on which alternative are salient to S. The thesis that knowledge is interest-relative is consistent with contextualism. It could be that whether a knowledge ascription is true depends on the interests of both the ascriber, and the ascribee. In this entry, however, I’m going to largely focus on the view that knowledge is interest-relative, but contextualism is false. On this view, the interests of the ascribee do matter to the truth of a knowledge ascription, but the interests of the ascribee do not.\nThis view is naturally called interest-relative invariantism, since it makes knowledge interest-relative, but it is a form of anti-contextualism, i.e., invariantism. The view is sometimes called subject-sensitive invariantism, since it makes knowledge relevant to the stakes and salient alternatives to the subject. But this is a bad name; of course whether a knowledge ascription is true is sensitive to who the subject of the ascription is. I know what I had for breakfast and you (probably) don’t. What is distinctive is which features of the subject’s situation that interest-relative invariantism says are relevant, and the name interest-relative invariantism makes it clear that it is the subject’s interests. There is one potential downside to this name; it suggests that the practical interests of the subject are relevant to what they know. I intend to use the predicate ‘interest-relative’ to pick out a class of theories, including the theory floated by John Hawthorne (2004), where the options that are salient to the subject matter to what the subject knows. If forced to defend the name, I’d argue that salience is relevant to the theoretical interests of the subject, if not necessarily to their practical interests. But the name is still potentially misleading; my main reason for using it is that ‘subject-sensitive’ is even more misleading. (I’ll shorten ‘interest-relative invariantism’ to IRI in what follows. I’ll return to the question of practical and theoretical interests in section 4.)\nThere are a number of ways to motivate and precisify IRI. I’ll spend most of this entry going over the choice points, starting with the points where I think there is a clearly preferably option, and ending with the choices where I think it’s unclear which way to go. Then I’ll discuss some general objections to IRI, and say how they might be answered.\n\n\n0.2 Motivations\nThere are two primary motivations for IRI. One comes from intuitions about cases, the other from a pair of principles. It turns out the two are connected, but it helps to start seeing them separately.\nJason Stanley (2005) starts with some versions of the ‘bank cases’ due originally to Keith DeRose (1992). These turn on idiosyncratic, archaic details of the US payments system, and I find it hard to have clear intuitions about them. A cleaner pair of examples is provided by Angel Pinillos (2012); here are slightly modified versions of his examples.\n\nAnkita and Bojan each have an essay due. They have, surprisingly, written word for word identical papers, and are now checking the paper for typos. The papers have no typos, and each student has checked their paper twice, with the same dictionary, and not found any typos. They are, in general, equally good at finding typos, and have true beliefs about their proficiency at typo-spotting.\nThe only difference between them concerns the consequence of a typo remaining. If the paper is a borderline A/A- paper, a typo might mean Ankita gets an A- rather than an A. But the grade doesn’t matter to her; she’s already been accepted into a good graduate program next year so long as she gets above a C. But Bojan’s instructor is a stickler for spelling. Any typo and he gets a C on the paper. And he has a very lucrative scholarship that he loses if he doesn’t get at least a B on this paper. (Compare the Typo-Low and Typo-High examples in Pinillos (2012, 199).)\n\nThe intuition that helps IRI is that Ankita knows she has no typos in her paper, and should turn it in, while Bojan does not know this, and should do a third (and perhaps fourth or fifth) check. Contextualists have a hard time explaining this; in this very context I can say “Ankita knows her paper has no typos, but Bojan does not know his paper has no typos”. If the intuition is right, it seems to support interest-relativity, since the difference in practical situation between Ankita and Bojan seems best placed to explain their epistemic difference. Alternatively, if there is a single context within which one can truly say \"Ankita knows her paper has no typos’‘, and’‘Bojan does not know his paper has no typos’’, that’s again something an interest-invariant contextualism can’t explain. Either way, we have an argument from cases for a form of interest-relativity.\nThe argument from principles takes off from the idea that knowledge plays an important role in good deliberation, and that knowledge does not require maximal confidence. It is easiest to introduce with an example, though note that we aren’t going to rely on epistemic intuitions about the example. Chika looked at the baseball scores last night before going to bed and saw that the Red Sox won. She remembers this when she wakes up, though she knows that she does sometimes misremember baseball scores. She is then faced with the following choice: take the red ticket, which she knows pays $1 if the Red Sox won last night, and nothing otherwise or the blue ticket, which she knows pays $1 iff 2+2=4, and nothing otherwise. Now consider the following principle, named by Jessica Brown (2014):\n\nK-Suff\n\nIf S knows that p, then S can rationally take p as given in practical deliberation.\n\n\nThe following trio seems to be inconsistent:\n\nChika knows the Red Sox won last night.\nChika is rationally required to take the blue ticket.\nK-Suff is true.\n\nBy 1 and 3, Chika can take for granted that the Red Sox won last night. So the value of the red ticket, for her, is equal to its value conditional on the Red Sox winning. And that is $1. So it is at least as valuable as the blue ticket. So she can’t be rationally required to take the blue ticket. Hence the three propositions are inconsistent.\nThis is worrying for two reasons. For one thing, it is intuitive that Chika knows that the Red Sox won. For another thing, it seems this form of argument generalises. For almost any proposition at all, if Chika knows the red ticket pays out iff that proposition is true, she should prefer the blue ticket. So she knows very little.\nHow could this argument be resisted? One move, which we’ll return to frequently, is to deny K-Suff. Maybe Chika’s knowledge that the Red Sox won is insufficient; she needs to be certain, or to have some higher order knowledge. But denying K-Suff alone will not explain why Chika should take the blue ticket. After all, if K-Suff is false, the fact that Chika knows the payout terms of the tickets is not in itself a reason for her to choose the blue ticket.\nSo perhaps we could deny that she is rationally required to choose the blue ticket. This does seem extremely unintuitive to me. Intuitions around here do not seem maximally reliable, but this is a strong enough intuition to make it worthwhile to explore other options.\nAnd IRI provides a clever way out of the dilemma. Chika does not know the Red Sox won last night. But she did know that, before the choice was offered. Once she has that choice, her knowledge changes, and now she does not know. The intuition that she knows is explained by the fact that relative to a more normal choice set, she can take the fact that the Red Sox won as a given. And scepticism is averted because Chika does normally know a lot; it’s just in the context of strange choices that she loses knowledge.\nThe plotline here, that principles connecting knowledge and action run up against anti-sceptical principles in contrived choice situations, and that IRI provides a way out of the tangle, is familiar. It is, simplifying greatly, the argumentative structure put forward by Hawthorne (2004), and by Fantl and McGrath (2002, 2009), and by Weatherson (2012). It does rely on intuitions, but they are intuitions about choices (such as that Chika should choose the blue ticket), not about knowledge directly.\nSome discussions of IRI, especially that in Hawthorne and Stanley (2008) use a converse principle. Again following the naming convention suggested by Jessica Brown (2014), we’ll call this K-Nec.\n\nK-Nec\n\nAn agent can properly use p as a reason for action only if she knows that p.\n\n\nI’ll mostly set the discussion of K-Nec aside here, since my preferred argument for IRI, the argument from Chika’s case, merely relies on K-Suff. But it is interesting to work through how K-Nec helps plug a gap in the argument by cases for IRI.\nBuckwalter and Schaffer (2015) argue that the intuitions behind Pinillos’s examples are not as solid as we might like. It’s true that experimental subjects do say that Bojan has to check the paper more times than Ankita does before he knows that the paper contains no typos. But those subjects also say he has to check more times before he believes that the paper has no typos. And, surprisingly, they say that he has to check more time before he guesses the paper has no typos. They suggest that there might be interest-relativity in the modal ‘has’ as much as in the verb ‘knows’. To say someone ‘has’ to X before they Y, typically means that it is improper, in some way, to Y without doing X first. That won’t be a problem for the proponent of IRI as long as at least in some of the cases Pinillos studies, the relevant senses of propriety are connected to knowledge. And that’s plausible for belief; Bojan has to know the paper is typo free before he (properly) believes it. At least, that’s a plausible move given K-Nec.1\n1 I’m suggesting here that in some sense, knowledge is a norm of belief. For more on the normative role of knowledge, see Worsnip (2017).There is one other problem for argument from cases for IRI. Imagine that after two checks of the paper, we tell Bojan that Ankita’s paper is a duplicate of hers, and she has checked her paper in just the same way he has checked his. And we tell him that Ankita does not overly care whether her paper is typo-free, but is confident that it is. We then ask him, does Ankita know her paper is typo free? Many philosophers think Bojan should answer “No” here. And that isn’t something IRI can explain. According to IRI, he should say, “I don’t know.” He can’t say Ankita does know, since he doesn’t know their common paper has no typos. But it’s hard to see why he should deny knowledge. Keith DeRose (2009, 185) thinks this case is particularly hard for IRI to explain, while Brian Kim (2016) offers some possible explanations. This objection doesn’t tell against the claim that knowledge is interest-relative, but it does threaten the invariantism. An interest-relative contextualist should say that everyone should deny Bojan knows his paper is typo free, and Bojan should deny Ankita knows her paper is typo-free.\n\n\n0.3 Odds and Stakes\nInterest-relative invariantism says that the interests of the subject matter to what she knows. This is a fairly vague statement though; there are a number of ways to make it precise. Right now I have interests in practical questions (such as whether I should keep writing or go to lunch) and in theoretical questions (such as whether IRI is true). Do both kinds of interests matter? We’ll return to that question in the next section. For now we want to ask a prior question: when do practical interests matter for whether a subject knows that p? There are two main answers to this question in the literature.\n\nStakes\n\nWhen the agent has a possible bet on p that involves large potential losses, it is harder to know that p.\n\nOdds\n\nWhen the agent has a possible bet on p that involves long odds, it is harder to know that p.\n\n\nThe difference between these two options becomes clear in a simple class of cases. Assume the agent is faced with a choice with the following structure:\n\nThere is a safe option, with payout S.\nAnd there is a risky option, with good payout G if p is true, and bad payout B if p is false.\n\nThese choices need not involve anything like a ‘bet’, in the ordinary folk sense. But they are situations where the agent has to make a choice between a path where the payouts are p-dependent, and one where they are independent of p. And those are quite common situations.\nThe Stakes option says that the relevant number here is the magnitude \\(S-B\\). If that is large, then the agent is in a high-stakes situation, and knowledge is hard. If it is low, then the agent is in a low stakes situation, and knowledge is relatively easy. (Perhaps the magnitude of \\(G-S\\) is relevant as well, though the focus in the literature has been on examples where \\(S-B\\) is high.)\nThe Odds option says that the relevant number is is the ratio:\n\\[\\frac{S-B}{G-S}\\] If that number is high, the agent faces a long odds bet, and knowledge is hard. If that number is low, the agent faces a short odds bet, and knowledge is relatively easy.\nIf our motivation for IRI came from cases, then it is natural to believe Stakes. Both Bojan and Chika face bets on p at long odds, but intuition is more worried about whether Bojan knows that p than whether Chika does. (At least my intuition is worried about whether Bojan knows, and I’ve seen little evidence that Chika’s case is intuitively a case of non-knowledge.)\nBut if our motivation for IRI came from principles, then it is natural to believe Odds. One way to think of the argument from principles for IRI is that it is a way to make all four of the following intuitive claims true:\n\nAgents should maximise evidential expected utility; i.e., they should choose the option whose expected utility is highest if the utilities are the agent’s own, and the probabilities are the evidential probabilities given the agent’s evidence.\nIf an agent knows that p, they can ignore possibilities where p is false; i.e., they can make whatever choice is the rational choice given p.\nChika cannot ignore possibilities where the Red Sox lost; she should consider those possibilities because it is in virtue of them that the evidential expected utility of taking the red ticket is higher.\nAgents with Chika’s evidence, background and dispositions typically know that the Red Sox won.\n\nThe first three principles imply that Chika does not know the Red Sox won. The only way to square that with the anti-sceptical fourth principle is to say that Chika is in some way atypical. And the only way she has been said to be atypical is in the practical choices she faces. But note it is not because she faces a high-stakes choice: precisely one dollar is at stake. It is because she faces a long (indeed infinitely long) odds bet.\nIn the general case we discussed above, agents maximise expected utility by taking the risky choice iff:\n\\[\\frac{S-B}{G-S} &lt; \\frac{Pr(p)}{1-Pr(p)}\\] where \\(Pr(p)\\) is the probability of p given the agent’s evidence. The actual magnitudes at play don’t matter to what choice maximses expected utility, just the odds the agent faces. So if one’s motivation to keep IRI is to square expected utility maxmisation with natural principles about knowledge and action, it seems the relevant feature of practical situations should be the stakes agents face.\nWhy could it seem stakes matter then? I think it is because in high stakes situations, the odds an agent faces are typically long ones. It is much easier to lose large amounts of utility than to gain large amounts of utility. Bojan stands to lose a lot from a typo in his paper; he doesn’t stand to lose much by taking the time to check it over. So a high stakes situation will, at least typically, be a long odds situation. So if we say the odds the agent faces are relevant to what they know, we can explain any intuition that the stakes at play are relevant.\nJessica Brown (2008, 176) also notes that cases where the agent faces long odds but low stakes raise problems for the stakes-based version of IRI.\n\n\n0.4 What Kind of Interests?\nLet’s return to the question of whether theoretical interests are relevant to knowledge, or only practical interests. There is some precedent for the more restrictive answer. Stanley’s book on IRI is called Knowledge and Practical Interests. And he defends a theory on which what an agent knows depends on the practical questions they face. But there are strong reasons to think that theoretical reasons matter as well.\nIn the previous section, I suggested that agents know that p only if they would maximise expected utility by choosing the choice that would be rational given p. That is, agents know that p only if the answer to the question “What choice maximises expected utility?” is the same unconditionally as it is conditional on p. My preferred version of interest-relative invariantism generalises this approach. An agent knows that p only if the rational answer to a question she faces is the same unconditionally as it is conditional on p. What it is for an agent to face a question is dependent on the agent’s interests. If that’s how one thinks of IRI, the question of this section becomes, should we restrict questions the agent faces to just being questions about what choice to make? Or should they include questions that turn on her thoeretical interests, but which are irrelevant to choices before her. There are two primary motivations for allowing theoretical interests as well as practical interests to matter.\nThe first comes from the arguments for what Jeremy Fantl and Matthew McGrath call the Unity Thesis  (Fantl and McGrath 2009, 73–76). They are interested in the thesis that whether or not p is a reason for an agent is independent of whether the agent is engaged in practical or theoretical deliberation. But we don’t have to be so invested in the ideology of reasons to appreciate their argument. Note that if only practical interests matter, then the agent should come up with different answers to the question “What to do in situation S” depending on whether the agent is actually in S, or they are merely musing about how one would deal with that situation. And it is unintuitive that this should matter.\nLet’s make that a little less abstract. Imagine Chika is not actually faced with the choice between the red and blue tickets. In fact, she has no practical decision to make that turns on whether the Red Sox won. But she is idly musing over what she would do if she were offered the red ticket and the blue ticket. If she knows the Red Sox won, then she should be indifferent between the tickets. After all, she knows they will both return $1. But intuitively she should think the red ticket is preferable, even in the abstract setting. And this seems to be the totally general case.\nThe general lesson is that if whether one can take p for granted is relevant to the choice between A and B, it is similarly relevant to the theoretical question of whether one would choose A or B, given a choice. And since those questions should receive the same answer, if p can’t be known while making the practical deliberation between A and B, it can’t be known while musing on whether A or B is more choiceworthy.\nIn Weatherson (2012) I suggest another reason for including theoretical interests in what’s relevant to knowledge. There is something odd about the following reasoning: The probability of p is precisely x, therefore p, in any case where \\(x &lt; 1\\). It is a little hard to say, though, why this is problematic, since we often take ourselves to know things on what we would admit, if pushed, are purely probabilistic grounds. The version of IRI that includes theoretical interests allows for this. If we are consciously thinking about whether the probability of p is x, then that’s a relevant question to us. Conditional on p, the answer to that question is clearly no, since conditional on p, the probability of p is 1. So anyone who is thinking about the precise probability of p, and not thinking it is 1, is not in a position to know p. And that’s why it is wrong, when thinking about p’s probability, to infer p from its high probability.\nPutting the ideas so far together, we get the following picture of how interests matter. An agent knows that p only if the evidential probability of p is close enough to certainty for all the purposes that are relevant, given the agent’s theoretical and practical interests. Assuming the background theory of knowledge is non-sceptical, this will entail that interests matter.\n\n\n0.5 Global or Partial\nSo far I’ve described three ways to refine the defence of IRI.\n\nThe motivation could come from cases or principles.\nThe relevant feature that makes it hard to have knowledge could be that the agent faces a high-stakes choice, or a long-odds choice.\nOnly practical interests may be relevant to knowledge, or theoretical interests may matter as well.\n\nFor better or worse, the version of IRI I’ve defended has fairly clear commitments on all three; in each case, I prefer the latter option. From here on, I’m much less sure of the right way to refine IRI.\nIRI, like contextualism, was introduced as a thesis about knowledge. But it need not be restricted that way. It could be generalised to a number of other epistemically interesting notion. At the extreme, we could argue that every epistemologially interesting notion is interest-relative. Doing so gives us a global version of IRI.\nJason Stanley (2005) comes close to defending a global version. He notes that if one has both IRI, and a ‘knowledge first’ epistemology  (Williamson 2000), then one is a long way to towards globalism. Even if one doesn’t accept the whole knowledge first package, but just accepts the thesis that evidence is all and only what one knows, then one is a long way towards globalism. After all, if evidence is interest-relative, then probability, justification, rationality, and evidential support are interest-relative too.\nKatherine Rubin (2015) objects to globalist versions of IRI. But the objections she gives turn, as she notes, on taking stakes not odds to be relevant.\nIf a non-global version of IRI could be made to work, it would have some theoretical advantages. It’s nice to be able to say that Chika should take the blue ticket because the evidential probability of the Red Sox winning is lower than the evidential probability of two plus two being four. But that won’t be a non-circular explanation if we also say that something is part of Chika’s evidence in virtue of being known.\nOn the other hand, the motivations for interest-relativity of knowledge seem to generalise to all other non-gradable states. In ordinary cases, Chika could use the fact that the Red Sox won as a given in practical or theoretical reasoning. That is, she could properly treat it as evidence. But she can’t treat it as evidence when deciding which ticket to take. So at least what she can properly treat as evidence seems to be interest-relative, and from there it isn’t obvious how to deny that evidence itself is interest-relative too.\nThere remains a question of whether gradable notions, like epistemic probabilities, are also interest-relative. One of the aims of my first paper on IRI  (Weatherson 2005) was to argue that probabilistic notions are interest-invariant while binary notions are interest-relative. But if propositions that are part of one’s evidence have maximal probability (in the relevant sense of probability), and evidence is interest-relative, that combination won’t be sustainable.\nIn short, while the non-global version of IRI allows for some nice reductive explanations of why interests matter, the global version is supported by the very intuitions that motivated IRI. There is a danger here that whatever way the IRI theorist goes, they will run into insuperable difficulties. Ichikawa, Jarvis, and Rubin (2012) argue strongly that this danger is real; there is no plausible way to fill out IRI. I’m not convinced that the prospects are quite so grim, but I think this is one of the more pressing worries for IRI.\n\n\n0.6 Belief, Justification and Interest\nIf we decide that not everything in epistemology is interest-relative, then we face a series of questions about which things are, and are not, interest relative. One of these concerns belief. Should we say that what an agent believes is sensitive to what her interests are?\nNote that the question here concerns whether belief is constitutively related to interests. It is extremely plausible that belief is causally related to interests. As Jennifer Nagel (2008) has shown, many agents will react to being in a high-stakes situation by lowering their confidence in relevant propositions. In this way, being in a high-stakes situation may cause an agent to lose beliefs. This is not the kind of constitutive interest-relativity that’s at issue here, though the fact this happens makes it harder to tell whether there is such a thing as constitutive interest-relativity of belief.\nI find it useful to distinguish three classes of views about beliefs and interests.\n\nBeliefs are not interest-relative. If knowledge is interest-relative, the interest-relativity is in the conditions a belief must satisfy in order to count as knowledge.\nBeliefs are interest-relative, and the interest-relativity of belief fully explains why knowledge is interest-relative.\nBeliefs are interest-relative, but the interest-relativity of belief does not fully explain why knowledge is interest-relative.\n\nIn Weatherson (2005), I suggested an argument for option 2. I now think that argument fails, for reasons given by Jason Stanley (2005). I originally thought option 2 provided the best explanation of cases like Chika’s. Assume Chika does the rational thing, and takes the blue ticket. She believes it is better to take the blue ticket. But that would be incoherent if she believed the Red Sox won. So she doesn’t believe the Red Sox won. But she did believe the Red Sox won before she was offered the bet, and she hasn’t received any new evidence that they did not. So, assuming we can understand an interest-invariant notion of confidence, she is no less confident that the Red Sox won, but she no longer believes it. That’s because belief is interest-relative. And if all cases of interest-relativity are like Chika’s, then they will all be cases where the interest-relativity of belief is what is ultimately explanatory.\nThe problem, as Stanley had in effect already pointed out, is that not all cases are like Chika’s. If agents are mistaken about the choice they face, the explanation I offered for Chika’s case won’t go through. This is especially clear in cases where the mistake is due to irrationality. Let’s look at an example of this. Assume Dian faces the same choice as Chika, and this is clear, but he irrationally believes that the red ticket pays out $2. So he prefers the red ticket to the blue ticket, and there is no reason to deny he believes the Red Sox won. Yet taking the red ticket is irrational; he wouldn’t do it were he rational. Yet it would be rational if he knew the Red Sox won. So Dian doesn’t know the Red Sox won, in virtue of his interests, while believing they did.\nNote this isn’t an argument for option 1. Everything I said about Dian is consistent with the Chika-based argument for thinking that belief is interest-relative. It’s just that there are cases where the interest-relativity of knowledge can’t be explained by the interest-relativity of belief. So I now think option 3 is correct.\nWe can ask similiar questions about whether justified belief is interest-relative, and whether if so this explains the interest-relativity of knowledge. I won’t go into as much detail here, save to note that on my preferred version of IRI, Dian’s belief that the Red Sox won is both justified and rational. (Roughly, this is because I think his belief that the Red Sox won just is his high credence that the Red Sox won, and his high credence the Red Sox won is justified and rational. I defend this picture at more length in [Weatherson2005;]. And while that paper makes some mistaken suggestions about knowledge, I still think what it says about belief and justification is broadly correct.) That is, Dian has a justified true belief that the Red Sox won, but does not know it. This is, to put it mildly, not the most intuitive of verdicts. I suspect the alternative verdicts lead to worse problems elsewhere. But rather than delving deeper into the details of IRI to confirm whether that’s true, let’s turn to some objections to the view.\n\n\n0.7 Debunking Objections\nMany arguments against IRI are, in effect, debunking arguments. The objector’s immediate conclusion is not that IRI is false, but that it is unsupported by the arguments given for it.\nArguments that people do not have the intuition that, for exaple, Bojan lacks knowledge that his paper is typo-free, do not immediately show thtat IRI is false. That’s because the truth of IRI can be made compatible with that intuition in two ways. For one thing, it is possible that people think Bojan knows because they think Bojan betting that his paper is typo free is, in the circumstances, a good bet.2 For another thing, intuitions around here might be unreliable. Remember that one of the original motivations for IRI was that it was the lowest cost solution to the preface paradox and lottery paradox. We shouldn’t expect intuitions to be reliable in the presence of serious paradox. That consideration cuts both ways; it makes debunking objections to arguments for IRI from intuitions about cases look very promising. And I think those objections are promising; but they don’t show IRI is false.\n2 Compare the response to Feltz and Zarpentine (2010) that I make in Weatherson (2011, sec. 1), or the response to Lackey (2010) by Masashi Kasaki (2014, sec. 5).Similarly, objections to the premises of the argument from principles don’t strictly entail that IRI is false. After all, IRI is an existential thesis; it says sometimes interests matter. The principles used to defend it are universal claims; they say (for example) it is always permissible to act on knowledge. Weaker versions of these principles might still be consistent with, or even supporting of, IRI. But this feels a little desperate. If the premises of these arguments fail, then IRI looks implausible.\nBut there are still two methodological points worth remembering. Sometimes it seems that critics of principles like K-Suff reason that K-Suff entails IRI, and IRI is antecedently implausible, so we should start out suspicious of K-Suff. Now why might IRI be antecedently implausible?\nI think to some extent it is because it is thought to be so revolutionary. The denial of interest-relativity is often taken to be a “traditional” view. This phrasing appears, for example, in Boyd (2016), and in Ichikawa, Jarvis, and Rubin (2012), and even in the title of Buckwalter (2014). And if this were correct, that would be a mark against interest-relativity. The “inherited experience and acumen of many generations of men”  (Austin 1956, 11) should not be lightly forsaken. The problem is that it isn’t true that IRI is revolutionary. Indeed, in historical terms there is nothing particularly novel about contemporary IRI. As Stephen R. Grimm (2015) points out, you can see a version of the view in Locke, and in Clifford. What’s really radical, as Descartes acknowledged, is to think the perspective of the Cartesian meditator is the right one for epistemology.\nPerhaps what is unintuitive about IRI is that it makes knowledge depend on factors that are not ‘truth-directed’, or ‘truth-conducive’. There is a stronger and weaker version of the principle that might be being appealed to here. The stronger version is that IRI makes practical matters into one of the factors on which knowledge depends, and this is implausible. But IRI doesn’t do this. It is consistent with IRI to say that only truth-conducive features of beliefs are relevant to whether they amount to knowledge, but how much of each feature one needs depends on practical matters. The weaker principle is that IRI makes knowledge counterfactually sensitive to features irrelevant to the truth, justification or reliability of the belief. This is true, but it isn’t an objection to IRI. Any theory that allows defeaters to knowledge, and defeaters to those defeaters, will make knowledge counterfactually sensitive to non-truth-conducive features in just the same way. And it is independently plausible that there are defeaters to knowledge, and they can be defeated.3\n3 The argument of the last two sentences is expanded on greatly in Weatherson (2014, sec. 3). The idea that knowledge allows for defeaters is criticised by Maria Lasonen-Aarnio (2014b). Eaton and Pickavance (2015) make an objection to IRI that does not take this point into account.These are all reasons to think that IRI is not antecedently implausible. There is one reason to think it is antecedently plausible. On a functionalist theory of mind, belief is a practical notion. And it is plausible that knowledge is a kind of success condition for belief. Now it’s possible to have non-practical success conditions for a state our concept of which is practical. But I don’t find that a natural starting assumption. It’s mucn more intuitive, to me at least, that the norms of belief and the metaphysics of belief would be tightly integrated. And that suggests that IRI is, if anything, a natural default.\nThat’s not an argument for IRI, or of course for K-Suff. And there are important direct objections to K-Suff. Jessica Brown (2008) and Jennifer Lackey (2010) have examples of people in high stakes situations who they say are intuitively described as knowing something, but not being in a position to act on it. I’m sympathetic to the two-part reply that Masashi Kasaki (2014) makes to these examples. The first thing to note is that these are hard cases, in areas where several paradoxes (e.g., lottery, preface, sceptical) are lurking. Intuitions are less reliable than usual around here. But another thing to notice is that it is very hard to say what actions are justified by taking p for granted in various settings. Brown and Lackey both describe cases where doctors have lots of evidence for p, and given p a certain action would maximise patient-welfare, but where intuitively it would be wrong for the doctor to act that way. As it stands, that’s a problem for IRI only if doctors should maximise epistemic expected patient-welfare, and that principle isn’t true. Kasaki argues that there isn’t a way to fill out Lackey’s example to get around this problem, and I suspect the same is true for Brown’s example.\nFinally, note that K-Suff is an extensional claim. Kenneth Boyd (2016) and Baron Reed (2014) object to a principle much stronger than K-Suff: the principle that what an agent knows should explain why some choices are rational for them. Both of them say that if IRI is inconsistent with the stronger principle, that is a serious problem for IRI. (In Boyd’s case this is part of an argument that IRI is unmotivated; in Reed’s case he takes it to be a direct objection to IRI.) Now I think IRI is inconsistent with this principle. Chika doesn’t know the Red Sox won because she can’t rationally choose the red ticket, not the other way around. But I don’t see why the principle is so plausible. It seems plausible to me that something else (e.g., evidence) explains both rational choice and knowledge, and the way it explains both things makes IRI true.\n\n\n0.8 Direct Objections\nLet’s close with direct arguments against IRI. There are two kinds of arguments that I won’t address here. One of these is the argument, developed in Ichikawa, Jarvis, and Rubin (2012) that there isn’t a good way to say how far interest-relativity should extend. As I noted above, I agree this is a deep problem, and don’t think there is a good answer to it in the existing literature. The other kind are objections that only apply to the Stakes version of IRI, not the Odds version. One instance of this kind is the Dutch Book argument deployed by Baron Reed (2014). I think several instances of that kind of argument are successful. But the theory they succeed against is not IRI, but a sub-optimal version of IRI. So I’ll stick to objections that apply to the Odds version.\nIRI does allow knowledge to depend on some unexpected factors. But so do most contemporary theories of knowledge. Most contemporary theories allow for knowledge to be defeated in certain ways, such as by available but unaccessed evidence  (Harman 1973, 75), or by nearby possibilities of error  (Goldman 1976), or by mistakes in the background reasoning. The last category of cases aren’t really contemporary; they trace back at least to Dharmottara  (Nagel 2014, 58). And contemporary theories of knowledge also allow for defeaters to be defeated. Once we work through the details of what can defeat a defeater, it turns out many surprising things can affect knowledge.\nIndeed, for just about any kind of defeater, it is possible to imagine something that in some ways makes the agent’s epistemic position worse, while simultaneously defeating the defeater.4 If interests matter to knowledge because they matter to defeaters, as is true on my version of IRI, we should expect strange events to correlate with gaining knowledge. For example, it isn’t surprising that one can gain knowledge that p at exactly the moment one’s evidential support for p falls. This consequence of IRI is taken to be obviously unacceptable by Eaton and Pickavance (2015), but it’s just a consequence of how defeaters generally work.\n4 The argument of the last two sentences is expanded on greatly in Weatherson (2014, sec. 3), where it is credited to Martin Smith. The idea that knowledge allows for defeaters is criticised by Maria Lasonen-Aarnio (2014a).IRI has been criticised for making knowledge depend on agents not allowing agents to get knowledge by not caring, as in these vivid quotes:\n\nNot giving a damn, however enviable in other respects, should not be knowledge-making.  (Russell and Doris 2009, 433)\n\n\nIf you don’t now whether penguins eat fish, but want to know, you might think … you have to gather evidence. [But if IRI] were correct, though, you have another option: You could take a drink or shoot heroin.  (Cappelen and Lepore 2006, 1044–45)\n\nLet’s walk through Cappelen and Lepore’s case. IRI says that there are people who both have high confidence that penguins eat fish, and they have this confidence for reasons that are appropriately connected to the fact that penguins eat fish. But one of them really worries about sceptical doubts, and so won’t regard the question of what penguins eat as settled. The other brushes off excessive sceptical doubts, and rightly so; they are, after all, excessive. IRI says that the latter knows and the former does not. If the former were to care a little less, in particular if they cared a little less about evil demons and the like, they’d know. Perhaps they could get themselves to care a little less by having a drink. That doesn’t sound like a bad plan; if a sceptical doubt is destroying knowledge, and there is no gain from holding on to it, then just let it go. From this perspective, Cappelen and Lepore’s conclusion does not seem like a reductio. Excessive doubt can destroy knowledge, so people with strong, non-misleading evidence can gain knowledge by setting aside doubts. And drink can set aside doubt. So drink can lead to knowledge.5\n5 Wright (2004) notes that there often is not value in holding on to sceptical doubts, and the considerations of this paragraph are somewhat inspired by his views. That’s not to endorse the idea that using alcohol or heroin is preferable to being gripped by sceptical doubts, especially heroin, but I do endorse the general idea that those doubts are not cost-free.But note that the drink doesn’t generate the knowledge. It blocks, or defeats, something that threatens to block knowledge. We should say the same thing to Russell and Doris’s objection. Not giving a damn, about scepticism for example, is not knowledge-making, but it is knowledge-causing. In general, things that cause by double prevention do not make things happen, although later things are counterfactually dependent on them  (Lewis 2004). And the same is true of not caring.\nFinally, it has been argued that IRI makes knowledge unstable in a certain kind of way  (Lutz 2014; Anderson 2015). Practical circumstances can change quickly; something can become a live choice and cease being one at a moment’s notice. If knowledge is sensitive to what choices are live, then knowledge can change this quickly too. But, say the objectors, it is counterintuitive that knowledge changes this quickly.\nNow I’m not sure this is counterintuitive. I think that part of what it takes to know p is to treat the question of whether p as closed. It sounds incoherent to say, “I know a is the F, but the question of who is the F is still ope”. And whether a question is treated as open or closed does, I think, change quite rapidly. One can treat a question as closed, get some new reason to open it (perhaps new evidence, perhaps an interlocutor who treats it as open), and then quickly dismiss that reason. So I’m not sure this is even a problem.\nBut to the extent that it is, it is only a problem for a somewhat half-hearted version of IRI. The puzzles the objectors raise turn on cases where the relevant practical options change quickly. But even once a practical option has ceased to be available, it can be hard in practice to dismiss it from one’s mind. One may often still think about what to do if it becomes available again, or about exactly how unfortunate it is that the option went away. As long as theoretical as well as practical interests matter to knowledge, it will be unlikely that knowledge will be unstable in just this way. Practical interests may change quickly; theoretical ones typically do not.\n\n\n\n\n\n\nReferences\n\nAnderson, Charity. 2015. “On the Intimate Relationship of Knowledge and Action.” Episteme 12 (3): 343–53. https://doi.org/10.1017/epi.2015.16.\n\n\nAustin, J. L. 1956. “A Plea for Excuses.” Proceedings of the Aristotelian Society 57 (1): 1–30. https://doi.org/10.1093/aristotelian/57.1.1.\n\n\nBoyd, Kenneth. 2016. “Pragmatic Encroachment and Epistemically Responsible Action.” Synthese 193 (9): 2721–45. https://doi.org/10.1007/s11229-015-0878-y.\n\n\nBrown, Jessica. 2008. “Subject-Sensitive Invariantism and the Knowledge Norm for Practical Reasoning.” Noûs 42 (2): 167–89. https://doi.org/10.1111/j.1468-0068.2008.00677.x.\n\n\n———. 2014. “Impurism, Practical Reasoning and the Threshold Problem.” Noûs 48 (1): 179–92. https://doi.org/10.1111/nous.12008.\n\n\nBuckwalter, Wesley. 2014. “Non-Traditional Factors in Judgments about Knowledge.” Philosophy Compass 7 (4): 278–89. https://doi.org/10.1111/j.1747-9991.2011.00466.x.\n\n\nBuckwalter, Wesley, and Jonathan Schaffer. 2015. “Knowledge, Stakes and Mistakes.” Noûs 49 (2): 201–34. https://doi.org/10.1111/nous.12017.\n\n\nCappelen, Herman, and Ernest Lepore. 2006. “Shared Content.” In The Oxford Handbook of Philosophy of Language, edited by Ernest Lepore and Barry C. Smith, 1020–55. Oxford: Oxford University Press.\n\n\nDeRose, Keith. 1992. “Contextualism and Knowledge Attributions.” Philosophy and Phenomenological Research 52 (4): 913–29. https://doi.org/10.2307/2107917.\n\n\n———. 2009. The Case for Contextualism: Knowledge, Skepticism and Context. Oxford: Oxford.\n\n\nEaton, Daniel, and Timothy Pickavance. 2015. “Evidence Against Pragmatic Encroachment.” Philosophical Studies 172: 3135–43. https://doi.org/10.1007/s11098-015-0461-x.\n\n\nFantl, Jeremy, and Matthew McGrath. 2002. “Evidence, Pragmatics, and Justification.” Philosophical Review 111 (1): 67–94. https://doi.org/10.2307/3182570.\n\n\n———. 2009. Knowledge in an Uncertain World. Oxford: Oxford University Press.\n\n\nFeltz, Adam, and Chris Zarpentine. 2010. “Do You Know More When It Matters Less?” Philosophical Psychology 23 (5): 683–706. https://doi.org/10.1080/09515089.2010.514572.\n\n\nGoldman, Alvin I. 1976. “Discrimination and Perceptual Knowledge.” The Journal of Philosophy 73 (20): 771–91. https://doi.org/10.2307/2025679.\n\n\nGrimm, Stephen R. 2015. “Knowledge, Practical Interests and Rising Tides.” In Epistemic Evaluation: Purposeful Epistemology, edited by David K. Henderson and John Greco, 117–37. Oxford: Oxford University Press.\n\n\nHarman, Gilbert. 1973. Thought. Princeton: Princeton University Press.\n\n\nHawthorne, John. 2004. Knowledge and Lotteries. Oxford: Oxford University Press.\n\n\nHawthorne, John, and Jason Stanley. 2008. “Knowledge and Action.” Journal of Philosophy 105 (10): 571–90. https://doi.org/10.5840/jphil20081051022.\n\n\nIchikawa, Jonathan Jenkins, Benjamin Jarvis, and Katherine Rubin. 2012. “Pragmatic Encroachment and Belief-Desire Psychology.” Analytic Philosophy 53 (4): 327–43. https://doi.org/10.1111/j.2153-960X.2012.00564.x.\n\n\nKasaki, Masashi. 2014. “Subject-Sensitive Invariantism and Isolated Secondhand Knowledge.” Acta Analytica 29: 83–98. https://doi.org/10.1007/s12136-013-0215-3.\n\n\nKim, Brian. 2016. “In Defense of Subject-Sensitive Invariantism.” Episteme 13 (2): 233–51. https://doi.org/10.1017/epi.2015.40.\n\n\nLackey, Jennifer. 2010. “Acting on Knowledge.” Philosophical Perspectives 24: 361–82. https://doi.org/10.1111/j.1520-8583.2010.00196.x.\n\n\nLasonen-Aarnio, Maria. 2014a. “Higher-Order Evidence and the Limits of Defeat.” Philosophy and Phenomenological Research 88 (2): 314–45. https://doi.org/10.1111/phpr.12090.\n\n\n———. 2014b. “The Dogmatism Puzzle.” Australasian Journal of Philosophy 92 (3): 417–32. https://doi.org/10.1080/00048402.2013.834949.\n\n\nLewis, David. 2004. “Causation as Influence.” In Causation and Counterfactuals, edited by John Collins, Ned Hall, and L. A. Paul, 75–106. Cambridge: MIT Press.\n\n\nLutz, Matt. 2014. “The Pragmatics of Pragmatic Encroachment.” Synthese 191 (8): 1717–40. https://doi.org/10.1007/s11229-013-0361-6.\n\n\nNagel, Jennifer. 2008. “Knowledge Ascriptions and the Psychological Consequences of Changing Stakes.” Australasian Journal of Philosophy 86 (2): 279–94. https://doi.org/10.1080/00048400801886397.\n\n\n———. 2014. Knowledge: A Very Short Introduction. Oxford: Oxford University Press.\n\n\nPinillos, Ángel. 2012. “Knowledge, Experiments and Practical Interests.” In Knowledge Ascriptions, edited by Jessica Brown and Mikkel Gerken, 192–219. Oxford: Oxford University Press.\n\n\nReed, Baron. 2014. “Practical Matters Do Not Affect Whether You Know.” In Contemporary Debates in Epistemology, edited by Matthias Steup, John Turri, and Ernest Sosa, 2nd ed., 95–106. Chicester: Wiley-Blackwell.\n\n\nRubin, Katherine. 2015. “Total Pragmatic Encroachment and Epistemic Permissiveness.” Pacific Philosophical Quarterly 96: 12–38. https://doi.org/10.1111/papq.12060.\n\n\nRussell, Gillian, and John M. Doris. 2009. “Knowledge by Indifference.” Australasian Journal of Philosophy 86 (3): 429–37. https://doi.org/10.1080/00048400802001996.\n\n\nRysiew, Patrick. 2017. “Warranted Assertability Maneuvers.” In Routledge Handbook of Epistemic Contextualism, edited by Jonathan Jenkins Ichikawa, n/a–a. London: Routledge.\n\n\nStanley, Jason. 2005. Knowledge and Practical Interests. Oxford University Press.\n\n\nWeatherson, Brian. 2005. “Can We Do Without Pragmatic Encroachment?” Philosophical Perspectives 19 (1): 417–43. https://doi.org/10.1111/j.1520-8583.2005.00068.x.\n\n\n———. 2011. “Defending Interest-Relative Invariantism.” Logos & Episteme 2 (4): 591–609. https://doi.org/10.5840/logos-episteme2011248.\n\n\n———. 2012. “Knowledge, Bets and Interests.” In Knowledge Ascriptions, edited by Jessica Brown and Mikkel Gerken, 75–103. Oxford: Oxford University Press.\n\n\n———. 2014. “Probability and Scepticism.” In Scepticism and Perceptual Justification, edited by Dylan Dodd and Elia Zardini, 71–86. Oxford: Oxford University Press.\n\n\nWilliamson, Timothy. 2000. Knowledge and its Limits. Oxford University Press.\n\n\nWorsnip, Alex. 2017. “Knowledge Norms.” In Routledge Handbook of Epistemic Contextualism, edited by Jonathan Jenkins Ichikawa, n/a–a. London: Routledge.\n\n\nWright, Crispin. 2004. “Warrant for Nothing (and Foundations for Free)?” Proceedings of the Aristotelian Society, Supplementary Volume 78 (1): 167–212. https://doi.org/10.1111/j.0309-7013.2004.00121.x."
  },
  {
    "objectID": "posts/herman/centrality-and-marginalisation.html",
    "href": "posts/herman/centrality-and-marginalisation.html",
    "title": "Centrality and Marginalisation",
    "section": "",
    "text": "0.1 Welcome to the History of Late Analytic Philosophy\nIt’s a good time to be doing history of late analytic philosophy. There is flurry of new and exciting work on how philosophy got from the death pangs of positivism and ordinary language philosophy to where it is today. Some may see this as a much needed gap in the literature. Indeed, there are a couple of reasons for scepticism about there being such a field as history of late analytic philosophy, both of which are plausible but wrong.\n\nPhilosophical Studies 171: 517-533. Thanks to Herman Cappelen and Ishani Maitra for many discussions about the material in this paper.\n\nOne reason is that it is too recent. But it can’t be too recent for general historical study; there are courses in history departments on September 11, so it’s not like looking at philosophy from thirty to forty years ago is rushing in where historians fear to tread. And indeed, if logical positivism could be treated historically in the 1960s, and ordinary language philosophy could be treated historically at the turn of the century, it seems a reasonable time to look back at the important works of the 1970s that established the contemporary era in philosophy.\nAnother reason is that we all know it so well. We are still so engaged with the key works by Kripke, Lewis, Burge, Perry, Thomson and so on that we don’t need to also look at them the way we look at Descartes, Locke and Hume. But this, it turns out, is not true. Books by Daniel Nolan (2005) and Wolfgang Schwarz (2009) changed the way that some philosophers, even those who knew the Lewisian corpus fairly well, changed the way they read Lewis. There has also been a minor flurry of work on how important the Gödel/Schmidt case is to the argument of Naming and Necessity (Devitt 2011; Ichikawa, Maitra, and Weatherson 2012; Machery et al. 2012).\nBut that’s nothing compared to the bombshell that is Philosophy Without Intuitions. (Cappelen 2012; all page citations, unless otherwise noted, to this book.) Herman Cappelen shows, extremely convincingly to my eyes at least, that intuitions play a much smaller role in late analytic philosophy than many philosophers thought. Indeed, there is a lot of textual evidence both for the claim that intuitions don’t do much philosophical work, and for the claim that many people have said that they do. The first of these claims is all to the good, says Cappelen, since there isn’t a particularly good epistemological defence of the use of intuitions.\nThe evidence for Cappelen’s claims comes in two parts. The first part, which I won’t discuss much here, is an extended argument that words like ‘intuitively’, or ‘counterintuitive’, as they appear in philosophical discourse, don’t in general function to pick out, or even draw attention to, any distinctive kind of mental state we could call an ‘intuition’. The second part argues that when we look at the actual introduction of thought experiments into late analytic philosophy, we don’t see the appeal to intuitions that many philosophers seem to think go along with thought experiments. Rather, we see a whole host of interesting philosophical moves. Sometimes a thought experiment functions to highlight an explanandum. Sometimes it gives us a prima facie plausible thesis that we then argue for (or against) at great length. Sometimes it just raises a puzzle.\nOne upshot of this historical work, one that Cappelen I think does a good job highlighting, is that contemporary philosophy is much more interesting than its practitioners sometimes take it to be. Philosophy is a way of investigating hard questions about the world, often at great expense in terms of human capital, but with thankfully little in the way of other expenses. It isn’t a matter of tidying up conceptual space. Thinking of philosophy this way should, I think, help us see why so many different kinds of projects are philosophically important.\n\n\n0.2 Centrality and Its Discontents\nThe big goal of Cappelen’s book is to refute the view, which he dubs Centrality, that intuitions (of a certain kind) are central to analytic philosophy, and in particular that they are a primary source of evidence for analytic philosophers. The intuitions that he has in mind have these three characteristics. (The quotes are from pages 112-3, where these features are articulated.)\n\nF1: Phenomenology\n\n“An Intuitive Judgment has a distinctive phenomenology” .\n\nF2: Rock\n\n“An intuitive judgment has a special epistemic status …Intuitive judgments justify, but they need no justification”.\n\nF3: Conceptual\n\nA judgment is an intuition “only if it is justified solely by the subjects’ conceptual competence”.\n\n\nThere’s some more detail on F2, but we’ll get to that in section 6. And there’s a fourth characteristic of intuitions that I want to add.\n\nF4: Speed\n\nIntuitions are rapid reactions..1\n1 My own views about the importance of this, as well as much else in this paper, owe a lot to Jennifer Nagel (2007, 2013).\n\nI’m going to spend much of this paper defending a view that intuitions characterised by F2 and F4 do play a role, though perhaps not a central role, in philosophy. But I do think that intuitions characterised by F1 and F3 are just not important to philosophy. Indeed, I think it’s a very important fact that they are not that important.\nThe claim that intuitions have a distinctive phenomenology is mostly harmless but, it seems to me, false. I certainly don’t find anything in common when I introspect my judgments that, say, no set is a member of itself, or that losing a limb would seriously reduce my happiness, or that the only language I think in is English. It will fall out of the view I’m defending that the best intuitions have no phenomenology, but I don’t think that’s a particularly important fact about them.\nBut the claim that intuitions derive solely from conceptual competencies, plus the claim that these are the central source of evidence in philosophy, is both wrong and dangerous. If that conjunction were true, we’d expect most philosophical conclusions to be conceptual truths (whatever those are). I’m not going to take a stand on whether there are conceptual truths, but I think it is pretty obvious that conceptual truths won’t help much resolve the following debates. (Compare the list E1-E6 on pages 200-201, which I’m basically just extending.)\n\nDo bans on pornography involve trading off speech rights versus welfare considerations, or do they just involve evaluating the free speech interests of different groups?\nIs it permissible to eat whales?\nUnder what circumstances is it permissible to end a terminally ill patient’s life, or to withhold life-saving treatment?\nIs all context dependency in language traceable to the presence of bindable variables?\nDoes belief have a phenomenology?\nWhich animals (and which non-animals) have beliefs?\n\nIf philosophy uses largely conceptual evidence, these aren’t philosophical questions. More generally, if Centrality (in Cappelen’s sense) is true of philosophy, then feminist philosophy, legal philosophy, political philosophy, bioethics, philosophy of language and (most of) philosophy of mind are not part of philosophy. (This list is far from exhaustive; making philosophy Centrality-friendly would involve writing out huge swathes of the discipline.)\nModus tollens obviously beckons. But as Cappelen notes (213), one occasional reaction to this is to identify certain parts of philosophy as the ‘Core’ of the discipline, and say Centrality is true of those. If Centrality is true of the core of philosophy, then feminist philosophy etc., are not part of the core of the field. Maybe now some people would be disposed to use modus ponens not modus tollens.\nThat would be a large mistake. It would have shocked Plato, and Locke, and Hume, and practically every other major figure in the history of philosophy to learn that political philosophy wasn’t central to the field. I do think (contra some of what Cappelen says) that some philosophy involves a priori and conceptual investigation. Indeed, I even do some of it. But it’s not true that when I’m doing that I’m doing work that’s deeper, or more philosophical, or more central to philosophy than the work that, for example, Rae Langton or Susan Moller Okin or Tamar Szabó Gendler or Sarah-Jane Leslie do.\nThis reason alone suffices for me to hope that Cappelen’s book has a very wide readership. Centrality isn’t true, but it is I think widely believed to true of at least some parts of the field. (Cappelen quotes many people endorsing this view.) I suspect that on the basis of this mistake, the parts of philosophy about which Centrality is not obviously false (especially metaphysics and epistemology) have been seen as more central to the discipline than they really ought to be. That’s not a bad state of affairs for metaphysicians and epistemologists, but it’s not good for philosophy, and I hope that Cappelen’s book helps put a stop to it.\n\n\n0.3 Intuitions in Detective Work\nDespite my very broad sympathy with Cappelen’s project, I do think there’s a role for intuitions of some kind in philosophy. Just what this kind is, and what this role is, will take some spelling out to avoid Cappelen’s arguments. So that’s what I’ll do for the next few pages.\nThe intuitions I have in mind are characterised by F2 and F4; they are default justified, and they are fast. Here’s how I think these kinds of intuitions could matter philosophically.\nWhen humans are growing up, they develop a lot of cognitive skills. Some of these skills are grounded in specific bits of propositional knowledge. We learn to count in part by learning that 2 comes after 1, and 3 comes after 2, and so on. But not all of them are. We learn how to tell causation from correlation, at least in simple cases, by developing various heuristics, none of which come close to a full theory of causation. Indeed, none of these heuristics would even be true, if stated as universal generalisations. But this ability to pick out which of the many predecessors of an event is its cause is one we develop very early (Gopnik 2009, 33–44), and it is vital to navigating the world.\nI think we develop a lot of skills like that; skills which either go beyond our propositional knowledge, or at the very least are hard to articulate in terms of propositions. That we have these kinds of skills should hardly be news to philosophers; under the label ‘heuristics’ they have become quite familiar thanks to the work of, among others, Daniel Kahneman. They occasionally get a bad press, because one central way in which psychologists detect them is by seeing where they lead to errors that careful thought would correct. (For instance, our heuristics sometimes say that a conjunction is more probable than one of the conjuncts, and careful thinking would correct this.) But this should not blind us to the fact that these incredibly fast heuristics are often very reliable; reliable enough to be an independent check on our theorising.\nThe use of the term ‘intuition’ to pick out these heuristics isn’t particularly idiosyncratic; Kahneman (2011) himself moves back and forth freely between the two terms. He approvingly cites Herbert Simon’s remark that “intuition is nothing more and nothing less than recognition”, which I think is basically right. We intuit that \\(a\\) is \\(F\\) by recognising that it has the tell-tale signs of \\(F\\)hood. Of course we’re a million miles from conceptual or a priori reasoning here; as I said, I agree entirely with Cappelen that F3 is not a feature of any philosophically significant source of evidence. Here are a couple of cases, one real life and one fictional, that draw out far removed intuitive thinking can be from a priori or conceptual thinking. The first is from Kahneman’s description of a case reported by Gary Klein (1999); the second is from (Norwegian) crime novelist Jo Nesbø (2009). First Kahneman,\n\nA team of firefighters entered a house in which the kitchen was on fire. Soon after they started hosing down the kitchen, the commander heard himself shout “Let’s get out of here!” without realizing why. The floor collapsed almost immediately after the firefighters escaped. Only after the fact did the commander realize that the fire had been unusually quiet and that his ears had been unusually hot ... He had no idea what was wrong, but he knew something was wrong. (Kahneman 2011, 11)\n\nNow Nesbø. In the story, Harry is the hero, Harry Hole, and Beate is a talented forensic detective.\n\n‘Forget what you have or haven’t got,’ Harry said. ‘What was your first impression? Don’t think, speak.’\nBeate smiled. She knew Harry now. First, intuition, then the facts. Because intuition provides facts too; it’s all the information the crime scene gives you, but which the brain cannot articulate straight off. (Nesbø 2009, 126)\n\nThere’s at least a family resemblence between Harry Hole’s instruction here and Lewis’s instruction to his readers at the start of “Elusive Knowledge” (Lewis 1996).\n\nIf you are a contented fallibilist, I implore you to be honest, be naive, hear it afresh. ‘He knows, yet he has not eliminated all possibilities of error.’ Even if you’ve numbed your ears, doesn’t this overt, explicit fallibilism still sound wrong? (Lewis 1996, 550)\n\nReviewers of Nesbø’s books often describe his hero as ‘intuitive’. That’s a little misleading; Harry Hole thinks intuition has a key role to play in detective work, but the adjective suggests that he relies heavily on his own intuition. That’s not right; he’s just as often badgering his colleagues to give him their impressions of a crime scene, or an interview subject. In these scenes he reminds me of no one so much as a colleague constantly wanting to know what one thinks about some thought experiment or variation on a familiar case. (These are often the best kind of colleague - full of inspiring ideas!)\nSo I think a lot of philosophical progress is made by drawing on, and drawing out, these skills. But isn’t this just to say something uncontroversial and uninteresting, namely that philosophy relies on implicit knowledge? As Cappelen puts it,\n\nIt is not controversial that conversations have propositions in the common ground. Nor is it controversial that all arguments start with premises that are not argued for. (155)\n\nWell, there’s something a bit interesting here, namely that the ‘common ground’ and the ‘not argued for’ premises have much greater overlap in philosophy than in other fields. A book starting with observations about the Galápagos Islands starts with premises that are not argued for, but are asserted on the basis of observations. These premises surely weren’t in the common ground before the ‘conversation’ starts. I’ll say more about this in the next section.\nBecause first I want to fuss a little about just what ‘common ground’ is. We’ll start with an observation Cappelen makes about the Ginet/Goldman case of Henry and the fake barns (Goldman 1976). Many philosophers take it to be an interesting fact that in one scenario, Henry knows there’s a barn, while in another he does not. Cappelen says that these facts are “presented as being pre-theoretically in the common ground” (172). That seems false at first blush. Before reading Goldman’s paper, it’s not clear philosophers are in a position to form singular thoughts about Henry. That’s an uncharitable reading though. A more plausible claim is to say that we are pre-theoretically disposed to accept some long sentence that roughly says that an agent in such-and-such scenario knows there is a barn, while an agent in a slightly different scenario does not.\nWe might gloss that last claim as saying that we implicitly knew something about these scenarios. I’m not sure that’s right though. We do surely have lots of implicit knowledge. I know, and so do you, that the Sydney Opera House is south of the Royal Albert Hall, even if you’d never articulated that thought to yourself or another. But do our dispositions to respond to quite finely drawn, and often reasonably long, vignettes count as implicit beliefs, or should they count as things we were in a position to know, but only learned once a philosopher had done the work of drawing the vignette? I can see merit in both positions, and don’t see firm grounds for preferring one.\nLet’s introduce some terminology to avoid taking a stance on this question. Say that a subject has Socratic knowledge that \\(p\\) when the following two conditions are met:\n\nOnce the agent is asked to consider \\(p\\) in the right way, they will come to know \\(p\\).\nThe evidential basis for this knowledge that \\(p\\) is not the asking itself.\n\nThe first clause says that anyone who reacts to a Gettier case with “Oh, of course that’s justified true belief without knowledge” has Socratic knowledge that such a case is a counterexample to the JTB theory of knowledge. And they have this Socratic knowledge before the case is even raised. The second clause says that if the person reacts instead with “Oh, some philosophers use thought experiments that don’t make sense unless you know which cars come from which countries”, that won’t count as Socratic knowledge. They would be expressing some knowledge, to be sure, but the telling of the example would play an evidential role.\nIf you are very liberal about which dispositions count as implicit beliefs, and implicit knowledge, then Socratic knowledge will just be a special kind of implicit knowledge. But if you think considering examples can lead to learning new facts, not just drawing out dispositions, then you will think ‘Socratic’ is like ‘alleged’, a non-factive modifier. As I’ve defined it, once you hear Gettier cases once, that they are counterexamples to the JTB theory ceases to be Socratic knowledge, and becomes regular knowledge. Note also that we can make sense of some implicit states being more or less Socratic than others; some dispositions to assent require very careful work to trigger.\nWhy is the class of propositions that we Socratically know so rich and fertile? It’s because of the central role of heuristics in our cognitive lives. Our interactions with the world don’t just furnish us with a set of truths about the world. They also furnish us with skills that we can apply to generate more truths. I suspect that something like this observation is at the heart of the endorsement of F3, that intuitions reveal conceptual truths. When we intuit that \\(p\\), we don’t always merely recall a prior belief that \\(p\\), or infer \\(p\\) from what we antecedently explicitly knew. But nor do we observe that \\(p\\). So what is it? It must be something internal, but not memory or inference. Conceptual competence isn’t a bad first guess, but Cappelen shows that isn’t the right answer. I think the right answer has to do with cognitive skills, i.e., heuristics.\n\n\n0.4 Philosophy: A Negative Characterisation\nSo intuitions matter because they reveal Socratic knowledge, and Socratic knowledge, when made explicit, is a very good guide to the world. That implies that intuitions should not be confined to philosophy. And, indeed, they are not. If an economic theorist claimed the standard of living among English men was higher in 1915 than in 1935, it would be perfectly reasonable to reply that intuitively that cannot be right, because in 1915 a rather large number of English men were living on the Western Front in catastrophically poor conditions. What is distinctive of philosophy then?\nWe need to clarify this question before we can answer it. Philosophy is both a discipline with a history over many millennia, and an organisational unit inside modern universities. These two things overlap well, but not perfectly. Once we note that they are distinct, we can separate out the following three questions.\n\nWhat questions are philosophical questions?\nWhat questions are, within the academy, primarily addressed by researchers in philosophy departments?\nWhat questions should be, at least within the academy, primarily addressed by researchers in philosophy departments?\n\nThe three questions don’t overlap. When Milton Friedman (1953) writes about economic methodology, I think he’s addressing a philosophical question, but work like this is, and probably should be, carried out in economics departments. Questions about professional ethics are philosophical questions that I think should be researched in philosophy departments, but in the United States at least typically receive more attention in professional schools. Let’s focus on the third question; what should a philosophy department do?\nMy colleagues at Michigan and St Andrews work on an incredibly wide range of questions, from the interpretation of quantum physics through history of logic through moral psychology and so on. And I think philosophy departments should have this range of interests. But what do all these questions have in common?\nIt’s not anything to do with necessity or a priority. Those categories seriously cross cut philosophy, as Cappelen points out. Historical investigations into disputes about the parentage of various might-have-been-royals, or mathematical investigation into the nature of the primes are not philosophical, but have to do with necessity and a priority. Whether there’s a language of thought is contingent, a posteriori, and almost paradigmatically philosophical.\nIt’s not really anything to do with depth, at least on a natural understanding of that. Why pandas have thumbs, and humans have appendices, turn out to be reasonably deep questions, but they are for biologists, not philosophers. Under what circumstances is democracy compatible with a strong executive is, at least to me, an incredibly deep and important question, but it’s a question to be answered, primarily, in history and political science departments.2 On the other hand, whether we can tell a plausible supervaluationist story about belief reports is not particularly deep, but a perfectly good subject for a philosophical inquiry as in Weatherson (2003a).\n2 This is not to say that political philosophers couldn’t help with this question. There are lots of questions that should have as their research centre some other department, but to which philosophers can usefully help. Indeed, the examples from economic methodology and evolutionary explanation I just mentioned are two more such questions.Better, I think, is to say that philosophical questions are those where implicit or Socratic knowledge, including crucially intuitions, can plausibly play a large role in getting to an answer. Philosophy is a little recursive, so it includes investigations into its own investigations, including historical work and metaphilosophical work. (Two fields which, prior to Cappelen’s book, had surprisingly little interaction.) That’s not to say we’re always right that Socratic knowledge can answer the questions philosophy sets. Maybe some questions in mind and language are best answered with the aid of neurological or phonological work that requires powerful measuring devices. But the questions are ones where starting with the knowledge and skills we already have seems like a plausible starting point, or at least not entirely crazy. This makes philosophy distinct from, say, history. We use intuitions in history too, especially intuitions about what explains what. But we need more; intuition won’t help if you want to know how many troops Henry had at Agincourt.\nThis hypothesis explains, I think, one of the historically important facts about philosophy. Philosophy gives birth to disciplines. Physics, economics, psychology and cognitive science were all, at one time, part of philosophy. In some cases, the split was very recent. The economics tripos at Cambridge only split from philosophy in 1903 (Tribe 2002). The Australasian Journal of Philosophy was the Australasian Journal of Psychology and Philosophy until 1946. Why does philosophy give rise to disciplines like these?\nI think having a negative characterisation of philosophy helps explain it. Philosophy has a lot in common, methodologically, with physics, economics, psychology and so on. All those fields use intuitions and other forms of Socratic knowledge. But the other fields use other things too, especially observation. It’s when it becomes clear that armchair methods play too small a role in the research that the field leaves philosophy.\nOf course, philosophers care more about their questions than their methods, so when the need for non-armchair methods becomes pressing, some of the individual philosophers will go along, picking up more and more observational knowledge and experimental skills. Note how much more empirical research informs the recent work by (for example) Gilbert Harman, Kim Sterelny and Peter Carruthers, compared to their earlier work (Harman 1973; Kilkarni and Harman 2011; Devitt and Sterelny 1987; Sterelny 2012; Carruthers 1990, 2011). From the other direction, our armchairs come with more knowledge now than they used to, which is partially why engaging with Laura Ruetsche’s work in philosophy of science requires more empirical knowledge engaging with William Whewell’s (Ruetsche 2011; Whewell 1840). But still I think the general picture holds; a question is fit for philosophy iff it is plausible that the intuitive, armchair methods which are part of every academic’s toolkit can, on their own, generate serious progress on the question.\n\n\n0.5 Letting Go\nI’ve said that Lewis’s instruction at the start of “Elusive Knowledge” is to look to intuitions, not to theoretical beliefs. But that might involve reading more into Lewis than is really there. What he literally asks the reader is to not appeal to their preferred theory of knowledge. Is that the same as an appeal to intuitions?\nIt need not always be. Sometimes, asking people to let go of their prior theory involves asking them to engage in a complex cognitive task. In Meditation One, Descartes has us go through quite a lot of thoughts before we can be pre-theoretical in the way he wants us to be.\nBut I don’t think that’s what’s going on with Lewis. For one thing, he doesn’t guide us back to a pre-theoretic naı̈veté the way Descartes does. But more generally, I think getting snap judgments is a way of letting go of some prior theories.\nThe picture I have here, and it is nothing more than a picture, is that intuitions are judgments delivered by heuristics, heuristics are deployed by Fodorian modules, and Fodorian modules are informationally encapsulated (J. A. Fodor 1983; J. Fodor 2000). That is, when we rely on a heuristic, we don’t use all of the information at our disposal. The classic example of this is eyesight; we may know that there are no elephants on Market Street in St Andrews, but given the right visual stimuli, our eyes will still insist that there is an elephant right there. The background theory about the spatial distribution of elephants isn’t encoded into the visual module. More generally, to rely on a heuristic just is to make a judgment using a part of our mind that doesn’t believe some of the things that we do. And that’s good, because it is a kind of independent check on the beliefs we have.3\n3 Philosophers sometimes understate the importance of independent checks. We can know a scale is working, but if we want to check its reliability we don’t use it, we use something else. I suspect that a certain amount of theory-independence is part of the explanation of the value of intuitions.But isn’t the idea that snap judgments are essential to philosophy inconsistent with the fact that we work very hard on getting our examples just right, and (as Cappelen shows), argue at great length over what to say about various examples? I think it isn’t, because there are two respects in which our practice reveals a sensitivity to snap judgments, and a respect for their use as a check on theorising.\nLet me tell you a small secret. I haven’t heard anything that even sounds like a counterexample to the broadly Stalnakerian theory of indicative conditionals that I like for about a decade. That’s not because there aren’t any intuitive counterexamples. It’s just because my intuitions have been trained to accord with this kind of theory.4 So what do I do? Do I give up on the use of intuitions as a test of theory? No, I ask colleagues for their intuitions. Sometimes I ask them a lot of different questions, and sometimes I work rather hard on refining the question, or (when they sadly disagree with my theory) finding ways to undermine their intuitions. Given the number of similar questions I get from other colleagues, I don’t think my methodology here is distinctive. In short, we can work very hard before and after getting the snap judgments, while giving those judgments a role.\n4 Relatedly, I haven’t seen Liverpool get awarded an undeserved free kick for about that long.This might be more idiosyncratic, but I also do a bunch of things in papers to draw out snap judgments. The main idea is to distract the reader from the fact that they are about to be prompted for an intuition, one that may not accord with their preferred theory. So I’ll use deliberately absurd props (like Vinny the talking vulture), or start an example without flagging that it is an example. My favourite move along these lines is to set up an example in such a way that the example doesn’t make sense unless some theoretical claim I want to argue for is true. Then, after much discussion of the correct verdict on the case, I can announce that the very sensibility of the prior discussion is proof that, at least intuitively, the theory I’m pushing must be true.\nWe’re going to come back to this theme a bit later, because I think it’s rather important. The cases you can remember from papers are probably not the ones where intuition mattered. The big role for intuition in philosophy (and in many other disciplines) is in checking the small steps along the way. That’s why I join Cappelen in opposing the methodological rationalists; I don’t think intuitions are distinctive to philosophy, and these small steps don’t have much of a phenomenology. But that doesn’t mean they are unimportant.\n\n\n0.6 Strength and Fragility\nOne of the big trends in late 20th Century epistemology has been the separation of two senses of strength of evidence. This might mean\n\nHow strong a doxastic state is supported by the evidence.\nHow resilient the force of the evidence is in the face of counterevidence.\n\nOne thing that conservative epistemologies (e.g., Harman (1986)) and dogmatic epistemologies (e.g., Pryor (2000)) have in common is that sources which might be very strong in the first sense might be very weak in the second sense. In particular, there can be sources of evidence that ground knowledge, and hence be rather strong in tthe first sense, but easily overturned by conflicting evidence. I prefer to reserve the terms ‘strong’ and ‘weak’ for the first sense, and use the terms ‘resilient’ or ‘fragile’ for the presence or absence of the second property. In that language, the important insight of the conservatives and dogmatists is that evidence can be strong but fragile.\nThat’s roughly how I think of intuitions – they are strong but rather fragile. So they can be unjustified justifiers, which is how I read Cappelen’s feature F2 (i.e., Rock).5\n5 There’s an ambiguity in Cappelen’s text that I’m not sure I’m interpreting the right way. Let’s that someone intuits that in a particular case, \\(c\\) doesn’t cause \\(e\\). Call the content of that intuition, i.e., what is intuited, \\(p_d\\). And call the proposition that the person has this intuition, i.e., the event of the intuiting, \\(p_g\\). Plausibly both \\(p_d\\) and \\(p_g\\) could be evidence in the right cases, though most of the time the salient evidence will be \\(p_d\\). I think \\(p_d\\) can be an unjustified justifier in the sense that other beliefs, e.g., that a particular theory of causation is false, can be justified on the basis of \\(p_d\\), but no other beliefs the agent has justify \\(p_d\\). But you might want a stronger sense of ‘unjustified’, where it means not just not justified by anything else, but not justified at all. I think in these kinds of cases, \\(p_d\\) is justified, just not justified by anything else. And the justification is, as I’ll get to below, strong but fragile. If when Cappelen says that intuitions, according to Centrality, are unjustified justifiers he means that the belief that \\(p_d\\) is unjustified, then I’m not defending Centrality. I just mean that the agent need not have any other mental states which justify the belief \\(p_d\\), or indeed any access to anything that justifies \\(p_d\\). But for all that it might be that the belief that \\(p_d\\) is justified, and the grounds for the justification include what the agent learned about causation as a child, plus perhaps her competence in distinguishing causes from non-causes.Cappelen notes it is hard to tell whether something is being used as a starting point, or an unjustified justifier, so he gives three diagnostics for this. I mostly agree with one, and disagree with the other two. I agree that intuitions are non-inferential, and they aren’t based on any particular experience, which is his criteria F2.1. (Though they usually are based on experiences taken collectively.) But I would alter the following suggestion, which he gives as a second diagnostic.\n\nF2.2 Evidence Recalcitrance: Intuitions are evidence recalcitrant; i.e., holders of them are not disposed to give them up even when their best arguments for those intuitions are shown to fail. (Compare pg 112)\n\nI would rather offer something normative here. What’s true of intuitions is that they might provide a stronger ground for belief than the best evidence we can offer for them. Compare the case of Gettier. As Cappelen carefully notes (194n3), Gettier doesn’t appeal to a raw intuition. He gives an argument that his subjects don’t know. Unfortunately, it isn’t a compelling argument, since it takes as a premise that we can’t get knowledge from a false belief, and that isn’t quite right (Warfield 2005). But Gettier was, to some extent, justified in believing these subjects didn’t know to a greater degree than he was justified in believing this argument was sound. And that, I think, is not uncommon.\nThis is why I don’t think Cappelen’s ‘Rough Guide to Rock Detection’ (121), the third of the diagnostics, is perfectly reliable. He says that if evidence is given for \\(p\\) in a context, that’s evidence that \\(p\\) isn’t an unjustified justifier in that context. But sometimes we give arguments for judgments that we think could rest without them. Compare this little dialogue.\n\nA: Is ‘John happiness’ a well-formed sentence?\nB: No; it doesn’t have a verb.\n\nHere B gives a judgment, then offers a little argument for it. The argument has a strong premise, namely that all sentences have verbs. That’s debatable; ‘Lo, gavagai!’ may be a counterexample. But B’s judgment isn’t undermined by examples that undermine her argument. As in the Gettier case, we may give an argument that doesn’t capture the full normative force of the judgment.\nTo say that intuitions are unjustified justifiers is not to say they are particularly special. If some conservative or dogmatic epistemology is true, there will be other unjustified justifiers. And if not, then this story about intuitions will be pretty implausible.\nThis picture of intuitions as strong but fragile meshes well, I think, with the picture from section 5. There I said the important intuitions are the ones you barely notice or remember. That’s because the intuitions are fragile; if you remembered them enough to argue about them (or experimentally test them), the fragility conditions had probably been triggered, and the intuition probably wasn’t doing much argumentative work.6\n6 I’m simplifying a little here. My preferred position is that intuiteds provide strong but fragile evidence, while intuitings provide weak but resilient evidence. The reason this is relevant is related to footnote 7.But why not think that intuitions are so fragile that they have no use in any philosophical debate? This question deserves more space than I can give it, but here are three sketches of answers.\n\nIntuitions might be valuable checks on theory, and might be resilient enough to perform a valuable checking role.\nJust like heuristics have characteristic errors, it might be that careful reasoning has characteristic errors, and there are cases where our first impressions are more reliable. See Gladwell (2005) for a summary of some relevant evidence.\nSomewhat surprisingly, there may be cases when it is best to trust the less reliable source. The case for this is a bit detailed, and not original to me, so I’ll just include a brief footnote for those interested.7\n\n7 At one point in Ben Levinstein’s doctoral dissertation, he considers whether there’s a general rule for deciding which of two conflicting sources we can trust. There turns out to be very little in general one can say. In particular, trust the more reliable source turns out not in general to be good advice. If sources have characteristic errors, it might be that given what the two sources have said, it is better on this occasion to trust the less reliable source, because the verdicts the sources deliver provide evidence that we are seeing one of the characteristic errors of the more reliable source. It takes more space than I have here to fill in the details of this argument, and most of the details I’d include would be Levinstein’s not mine. But here’s the big conclusion. Assume that intuitions are often wrong, but rarely dramatically wrong. The reason for that is that heuristics are bad at getting things exactly right, and good at getting in the ballpark. And that careful reasoning is often right, but sometimes dramatically wrong. This is trickier to motivate, but I think true. Then when intuition dramatically diverges from theory, and we don’t have independent reason to think that intuition is mistaken about the kind of case that’s in question, we should trust the intuition more than the theory.\n\n0.7 Some Lewisian Case Studies\nI’ve described one kind of mental state that deserves the name ‘intuition’, and which could play a role in philosophical activity. But, as Cappelen presses, we have to work to convert that ‘could’ to a ‘does’. Do we really rely in intuitive, or heuristic-driven, judgments about cases in analytic philosophy?\nAs Cappelen shows, the answer is “A lot less than you may have guessed.” We argue a lot more than we intuit, especially about the famous cases.8 The bit of analytic philosophy I’m most familiar with is David Lewis’s corpus, and since that doesn’t play much of a role in Cappelen’s story, I’ll illustrate his point with some examples from it.\n8 There is interesting work to be done on the relative role of intuitions and arguments about principles, but I’m going to leave that for another day, and focus here on cases. The principles/cases distinction can be a bit slippery, but paradigm cases are easy to identify, and we’ll be working with fairly paradigmatic cases here.Going from memory, I would have guessed the clearest example of a case refuting a theory was the use of finkish dispositions to refute the conditional analysis of dispositions. But go to the opening pages of “Finkish Dispositions” (Lewis 1997a), and you find not an intuition about a case, but an argument that finks are possible. And even though that argument is followed up with more cases, Lewis rather explicitly argues for his conclusions about each one. See, for example, the glass loving sorcerer on page 147. Lewis doesn’t avert to an intuition that the loved glass is fragile, rather he “wield[s] an assumption that dispositions are an intrinsic matter.” (Lewis 1997a, 147)\nThe discussion of causation turns out to be a little more fertile. From (the longer version of) “Causation as Influence”, I count the following appeals to intuitions about cases.\n\nThe chancy bomb example which shows simple probabilistic analyses of indeterministic causation won’t work (Lewis 2004a, 79).\nThe Merlin and Morgana example which shows that trumping is possible, and matters for what is the cause (Lewis 2004a, 81).\nThe variant on Billy and Suzy that raises problems for quasi-dependence (Lewis 2004a, 83).\nThe crazed President example which shows that causation by double prevention is possible, and that causation is not an intrinsic relation (Lewis 2004a, 84).\nThe Frankfurt example which shows we can have causation without dependence (Lewis 2004a, 95).\n\nThere’s a strong sense, I think, in which none of the judgments in these cases are argued for. Indeed, they arise as problems for theories that are otherwise doing rather well. If there was an argument around, it would be for the negation of the intuited judgment. So I think there’s a role for intuition here.\nBut we should not imagine that this is normal for philosophers, or even for Lewis. Cases, it is true, play a large role in Lewis’s writing. But they are very rarely simple refutations of existing theories. We could perhaps distinguish four roles that cases play, or perhaps four types of philosophical cases.\n\nRefutation of theories, as in these causation cases.\nIllustrations that help explain what’s going on in an argument, as in the examples from “Finkish Dispositions”. For a more extensive version of this, see Lewis’s version of Puzzling Pierre (Lewis 1981).\nTools for showing that we must distinguish various concepts, such as the discussion of Ned Kelly’s proof that there’s no honest cop (Lewis 1988).\nSimplified versions of the real world, on which we can test various explanatory hypotheses, such as the footy and rugby people in “Naming the Colors” (Lewis 1997b).\n\nAnd that list is probably incomplete. The last is fairly fascinating as a case study actually.9 Some of you may have had the following experience when programming, or indeed doing anything that looks like working with code (such as writing in LaTeX). A bug arises. It helps to find a minimal example in which the bug arises, i.e., a smallest program that produces the same bug. This helps you spot what’s going on, and if you still need help, it helps your interlocutors focus on the central problem. It’s important that you haven’t changed the problem; the example must be of the same kind as what you started with. But the example could be much simpler than the case you’re most interested in. Some philosophy examples are, I suspect, like that. Their value lies in revealing that some striking feature of reality would persist even if the world were simpler. So, probably, the explanation of the feature lies in some respect the real messy world shares with the simple example world. (Compare Cappelen’s discussion of Perry’s messy shopper in section 8.1.)\n9 See Sugden (2000, 2009) for much more on this use of thought experiments.It is perhaps no coincidence that the easiest place to find examples of type 1 in Lewis’s work is in the papers on causation. Lewis thinks there is no such thing as causation (Lewis 2004a, 2004b). Whatever our theory of ‘causes’ should be, it shouldn’t match that verb with a binary property. Rather, the aim of philosophical work on causation is to give a reductive analysis of causal thought and talk. In such a project, judgments about how we use ‘causes’ are more likely to be central.\nIt’s also not coincidental that when an example is central to a paper, such as the ‘dishonest’ cop and Puzzled Pierre, they really don’t look like type 1. That’s one big and important lesson from Cappelen’s work. Philosophers do use examples to refute theories, but they are rarely the big famous examples. If an example is central to a philosophy paper, it typically plays one of the other three roles.\n\n\n0.8 Summary\nLet’s take stock. I’ve argued for the following theses:\n\nSocratic knowledge is important to philosophy.\nThe distinctive feature of philosophy is that it addresses questions that can, at least prima facie, be productively worked on while relying primarily on Socratic knowledge.\nIntuitions are manifestations of cognitive skills, and much Socratic knowledge is constituted by the possession of such cognitive skills.\nLike other forms of Socratic knowledge, intuitions are mostly a posteriori, and have roles outside philosophy as well as inside it.\nIntuitions are default justified; that is, they can be unjustified justifiers.\nThis default is very weak; intuitions can easily be overridden by other considerations.\nRelatedly, it is rare for any one intuition to be central to a philosophical work; philosophical intuitions mostly concern the little cases we see along the way to larger projects.\n\nI also hinted at, without developing, an argument for\n\nThe right intuition can stop even a plausible theory dead in its tracks; and we have (thanks to Ben Levinstein) a mathematical model for why this can be so even if intuitions are much less reliable than theories.\n\nI opened with a discussion of why it matters to philosophy’s self-conception that point 4 is correct. Since Cappelen also endorses 4, I probably don’t need to say more about that here. But I think there is more to say about 7.\nThe first thing I want to note is that 7 is of course consistent with Cappelen’s textual research on important work in late analytic philosophy. In just about any thought experiment that you can remember, the intuitions about it don’t carry much philosophical weight in the work in which it is introduced. The intuitions that matter are the little ones, the ones that go by so quickly that no one questions them and are largely forgotten by all but the cognoscenti in that field. Even these intuitions aren’t that common. There are less of them in Lewis than I would have guessed.\nStill, I disagree with Cappelen that philosophy is without these intuitions. And so I disagree that there’s no role for double checking, experimentally if need be, whether these intuitions are really intuitive. If a well run survey showed that most people disagree with Lewis’s judgment about, say, the chancy bombs example, I’d reconsider my views about probabilistic causation. But I’d be really surprised to see this.\nThe second thing to note is that while 7 is true, it’s not the case that intuitions about one case are never central to a philosophical project. There is one big counterexample: the Gettier literature. Like Cappelen (194n3), I think this literature is incredibly unrepresentative of philosophy. And I think that’s in part because it was methodologically flawed. I tried to make this point in an earlier paper (Weatherson 2003b), but I didn’t get it quite right. (What I should have said was more like what Elijah Chudnoff (2011) does say.) When we saw the Gettier example, this should have been an invitation to try and find out what feature of knowledge was driving the fact that the belief in the main examples didn’t amount to knowledge. Gettier suggested it was inference from a false premise, but that doesn’t quite work (Warfield 2005). You might think it is insensitivity, but that doesn’t quite work. At this point there should have been one of two paths taken - attempts to find some other explanation of the data, or a reconsideration of whether our initial judgment about the case was wrong. That’s what the picture of philosophy sketched here would have predicted, and (this is the point I was trying but failing to make in the earlier paper) that’s what reflection on our successes in other areas of philosophy would have recommended. But the first kind of project ended up intertwined with attempts to analyse knowledge, and stalled for decades. And the second project wasn’t seriously undertaken, with some honorable exceptions such as Sartwell (1992) and Hetherington (2001). Now eventually this didn’t matter, because we discovered that safety based explanations of the Gettier case would work, even if there is no safety based analysis of knowledge, and even if there is some work to be done in getting the safety condition just right (Williamson 1994, 2000; Sainsbury 1995; Lewis 1996; Weatherson 2004). So if we strengthened 7 into a universal claim it would be false – thirty years of epistemological struggle attest to this. But it was really when epistemology fell into line with practice in other fields of philosophy that it made progress on the Gettier case.\n\n\n\n\n\n\nReferences\n\nCarruthers, Peter. 1990. The Metaphysics of the Tractatus. Cambridge: Cambridge University Press.\n\n\n———. 2011. The Opacity of Mind: An Integrative Theory of Self-Knowledge. Oxford: Oxford University Press.\n\n\nChudnoff, Elijah. 2011. “What Should a Theory of Knowledge Do?” Dialectica 65 (4): 561–79. https://doi.org/10.1111/j.1746-8361.2011.01285.x.\n\n\nDevitt, Michael. 2011. “Experimental Semantics.” Philosophy and Phenomenological Research 82 (2): 418–35. https://doi.org/ppr201182222.\n\n\nDevitt, Michael, and Kim Sterelny. 1987. Language and Reality: An Introduction to the Philosophy of Language. Cambridge, MA.: MIT Press.\n\n\nFodor, Jerry. 2000. The Mind Doesn’t Work That Way. Cambridge, MA: MIT Press.\n\n\nFodor, Jerry A. 1983. The Modularity of Mind. Cambridge, MA: MIT Press.\n\n\nFriedman, Milton. 1953. “The Methodology of Positive Economics.” In Essays in Positive Economics, 3–43. Chicago: University of Chicago Press.\n\n\nGladwell, Malcolm. 2005. Blink: The Power of Thinking Without Thinking. New York: Little, Brown.\n\n\nGoldman, Alvin I. 1976. “Discrimination and Perceptual Knowledge.” The Journal of Philosophy 73 (20): 771–91. https://doi.org/10.2307/2025679.\n\n\nGopnik, Alison. 2009. The Philosophical Baby: What Children’s Minds Tell Us about Truth, Love, and the Meaning of Life. New York: Farrar, Straus; Giroux.\n\n\nHarman, Gilbert. 1973. Thought. Princeton: Princeton University Press.\n\n\n———. 1986. Change in View. Cambridge, MA: Bradford.\n\n\nHetherington, Stephen. 2001. Good Knowledge, Bad Knowledge: On Two Dogmas of Epistemology. Oxford: Oxford University Press.\n\n\nIchikawa, Jonathan, Ishani Maitra, and Brian Weatherson. 2012. “In Defence of a Kripkean Dogma.” Philosophy and Phenomenological Research 85 (1): 56–68. https://doi.org/10.1111/j.1933-1592.2010.00478.x.\n\n\nKahneman, Daniel. 2011. Thinking Fast and Slow. New York: Farrar, Straus; Giroux.\n\n\nKilkarni, Sanjeev, and Gilbert Harman. 2011. An Elementary Introduction to Statistical Learning Theory. Hoboken, NJ: Wiley.\n\n\nKlein, Gary A. 1999. Sources of Power. Cambridge, MA.: MIT Press.\n\n\nLewis, David. 1981. “What Puzzling Pierre Does Not Believe.” Australasian Journal of Philosophy 59 (3): 283–89. https://doi.org/10.1080/00048408112340241.\n\n\n———. 1988. “The Trap’s Dilemma.” Australasian Journal of Philosophy 66 (2): 220–23. https://doi.org/10.1080/00048408812343301.\n\n\n———. 1996. “Elusive Knowledge.” Australasian Journal of Philosophy 74 (4): 549–67. https://doi.org/10.1080/00048409612347521.\n\n\n———. 1997a. “Finkish Dispositions.” The Philosophical Quarterly 47 (187): 143–58. https://doi.org/10.1111/1467-9213.00052.\n\n\n———. 1997b. “Naming the Colours.” Australasian Journal of Philosophy 75 (3): 325–42. https://doi.org/10.1080/00048409712347931.\n\n\n———. 2004a. “Causation as Influence.” In Causation and Counterfactuals, edited by John Collins, Ned Hall, and L. A. Paul, 75–106. Cambridge: MIT Press.\n\n\n———. 2004b. “Void and Object.” In Causation and Counterfactuals, edited by John Collins, Ned Hall, and L. A. Paul, 277–90. Cambridge: MIT Press.\n\n\nMachery, Eduoard, Ron Mallon, Shaun Nichols, and Stephen Stich. 2012. “If Folk Intuitions Vary, Then What?” Philosophy and Phenomenological Research 86 (3): 618–35. https://doi.org/10.1111/j.1933-1592.2011.00555.x.\n\n\nNagel, Jennifer. 2007. “Epistemic Intuitions.” Philosophy Compass 2 (6): 792–819. https://doi.org/10.1111/j.1747-9991.2007.00104.x.\n\n\n———. 2013. “Defending the Evidential Value of Epistemic Intuitions: A Reply to Stich.” Philosophy and Phenomenological Research 86 (1): 179–99. https://doi.org/10.1111/phpr.12008.\n\n\nNesbø, Jo. 2009. The Redeemer. London: Vintage Books.\n\n\nNolan, Daniel. 2005. David Lewis. Chesham: Acumen Publishing.\n\n\nPryor, James. 2000. “The Sceptic and the Dogmatist.” Noûs 34 (4): 517–49. https://doi.org/10.1111/0029-4624.00277.\n\n\nRuetsche, Laura. 2011. Interpreting Quantum Theories. Oxford: Oxford University Press.\n\n\nSainsbury, Mark. 1995. “Vagueness, Ignorance and Margin for Error.” British Journal for the Philosophy of Science 46: 589–601. https://doi.org/10.1093/bjps/46.4.589.\n\n\nSartwell, Crispin. 1992. “Why Knowledge Is Merely True Belief.” Journal of Philosophy 89 (4): 167–80. https://doi.org/10.2307/2026639.\n\n\nSchwarz, Wolfgang. 2009. David Lewis: Metaphysik Und Analyse. Paderborn: Mentis-Verlag.\n\n\nSterelny, Kim. 2012. The Evolved Apprentice: How Evolution Made Humans Unique. Cambridge, MA.: Bradford.\n\n\nSugden, Robert. 2000. “Credible Worlds: The Status of Theoretical Models in Economics.” Journal of Economic Methodology 7 (1): 1–31. https://doi.org/10.1080/135017800362220.\n\n\n———. 2009. “Credible Worlds, Capacities and Mechanisms.” Erkenntnis 70 (1): 3–27. https://doi.org/10.1007/s10670-008-9134-x.\n\n\nTribe, Kevin. 2002. “The Cambridge Economics Tripos 1903–55 and the Training of Economists.” The Manchester School 68 (2): 222–48. https://doi.org/10.1111/1467-9957.00191.\n\n\nWarfield, Ted A. 2005. “Knowledge from Falsehood.” Philosophical Perspectives 19: 405–16. https://doi.org/10.1111/j.1520-8583.2005.00067.x.\n\n\nWeatherson, Brian. 2003a. “Many Many Problems.” The Philosophical Quarterly 53 (213): 481–501. https://doi.org/10.1111/1467-9213.00327.\n\n\n———. 2003b. “What Good Are Counterexamples?” Philosophical Studies 115 (1): 1–31. https://doi.org/10.1023/A:1024961917413.\n\n\n———. 2004. “Luminous Margins.” Australasian Journal of Philosophy 82 (3): 373–83. https://doi.org/10.1080/713659874.\n\n\nWhewell, William. 1840. The Philosophy of the Inductive Sciences, Founded Upon Their History. London: John W. Parker.\n\n\nWilliamson, Timothy. 1994. Vagueness. Routledge.\n\n\n———. 2000. Knowledge and its Limits. Oxford University Press."
  },
  {
    "objectID": "posts/modesty/for-bayesians-rational-modesty-requires-imprecision.html",
    "href": "posts/modesty/for-bayesians-rational-modesty-requires-imprecision.html",
    "title": "For Bayesians, Rational Modesty Requires Imprecision",
    "section": "",
    "text": "Gordon Belot (2013) has recently developed a novel argument against Bayesianism. He shows that there is an interesting class of problems that, intuitively, no rational belief forming method is likely to get right. But a Bayesian agent’s credence, before the problem starts, that she will get the problem right has to be 1. This is an implausible kind of immodesty on the part of Bayesians.1 My aim is to show that while this is a good argument against traditional, precise Bayesians, the argument doesn’t neatly extend to imprecise Bayesians. As such, Belot’s argument is a reason to prefer imprecise Bayesianism to precise Bayesianism.\n1 There is another sense of immodesty that is often discussed in the literature, going back to Lewis (1971). This is the idea that some agents think their attitudes are optimal by some standards; these are the immodest ones. And often, it is held that not being self-endorsing in this way is a coherence failure Elga (2010). I don’t think this kind of immodesty is rationally required, for reasons set out by Miriam Schoenfield (2015) and Maria Lasonen-Aarnio (2015), but in any case that’s not the kind of modesty that’s at issue in Belot’s argument.\nPublished in Ergo 2: 20.\n\nFor present purposes, the precise Bayesian agent has just two defining characteristics. First, their credences in all propositions are given by a particular countably additive probability function. Second, those credences are updated by conditionalisation as new information comes in. These commitments are quite strong in some respects. They say that there is a single probability function that supplies the agent’s credences no matter which question is being investigated, and no matter how little evidence the agent has before the investigation is started. The everyday statistician, even one who is sympathetic to Bayesian approaches, may feel no need to sign up for anything this strong. But many philosophers seem to be interested in varieties of Bayesianism that are just this strong. For instance, there has been extensive discussion in recent epistemology of whether various epistemological approaches, such as dogmatism, can be modeled within the Bayesian framework, with the background assumption being that it counts against those approaches if they cannot.2 In these debates, the issue is not whether the Bayesian approach works in the context of a well-defined question and a substantial evidential background, but whether it does so for all questions in all contexts. Indeed, the assumption is that it does, and epistemological theories inconsistent with it are false. So the precise Bayesian is a figure of some interest, at least in epistemology.\n2 For dogmatism, see Pryor (2000). The canonical argument that it is inconsistent with Bayesianism is White (2006).3 Note that this formulation leaves it open which side of the biconditional is explanatorily prior. I’m going to defend a view on which the left hand side, i.e., the comparative confidences, are more explanatorily basic than the facts about what is in the agent’s representor. I say a little more about why I take this stand in footnote 7. For much more detail on varieties of imprecise Bayesianism, see Walley (1991), from whom I take the view that the representor and its members are much less explanatorily important than the comparative judgments the agent makes.The imprecise Bayesian doesn’t have a single probability function for their credences. Rather, they have a representor consisting of a set of probability functions. The agent is more confident in \\(p\\) than \\(q\\) just in case \\(\\Pr(p) &gt; \\Pr(q)\\) for every \\(\\Pr\\) in this representor.3 Just like the precise Bayesian, the imprecise Bayesian updates by conditionalisation; their new representor after an update is the result of conditionalising every member of the old representor with the new information. The added flexibility in imprecise Bayesianism will allow us to develop a suitably modest response to Belot’s puzzle.\n\n0.1 The Puzzle\nThe set up Belot uses is this. An agent, A, will receive a data stream of 0s and 1s. The data stream will go on indefinitely. I will use \\(\\boldsymbol{x}\\) for the (infinite) sequence of data she would (eventually) get, \\(x_k\\) for the \\(k\\)th element of this sequence, and \\(\\boldsymbol{x}_k\\) for the sequence consisting of the first \\(k\\) elements of the stream. These variables are, as usual, rigid designators. I’ll also use the capitalised \\(\\boldsymbol{X}\\) and \\(\\boldsymbol{X}_k\\) as random variables for the sequence itself, and for the first \\(k\\) elements of the sequence, respectively. So \\(\\boldsymbol{X}= \\boldsymbol{x}\\) is the substantive and true claim that the sequence that will be received is actually \\(\\boldsymbol{x}\\). And \\(\\boldsymbol{X}_k = \\boldsymbol{x}_k\\) is the substantive and true claim that the first \\(k\\) elements of that sequence are \\(\\boldsymbol{x}_k\\). Propositions of this form will play a major role below, since they summarise the evidence the agent has after \\(k\\) elements have been revealed. I’ll use \\(+\\) as a sequence concatenation operator, so \\(\\boldsymbol{y}+ \\boldsymbol{z}\\) is the sequence consisting of all of \\(\\boldsymbol{y}\\), followed by all of \\(\\boldsymbol{z}\\).\nBelot is interested in a quite general puzzle, but I’ll focus for most of the paper on a very specific instance of the puzzle. (We’ll return to the more general puzzle in the last section.) We’re going to look at the agent’s evolving credence that \\(\\boldsymbol{X}\\) is periodic. Let \\(p\\) be the proposition that \\(\\boldsymbol{X}\\) is periodic, since we’ll be returning to that proposition a lot. And let’s start by assuming the agent is a precise Bayesian, to see the challenge Belot develops.\nSay that the agent succeeds just in case her credence in \\(p\\) eventually gets on the correct side of \\(\\frac{1}{2}\\), and stays there. (The correct side is obviously the high side if \\(p\\) is true, and the low side otherwise.) That is, if \\(v\\) is the truth value function, it succeeds just in case this is true.4 \\[\\exists n \\forall m \\geq n: |v(p) - \\textit{Cr}(p | \\boldsymbol{X}_m = \\boldsymbol{x}_m)| &lt; \\frac{1}{2}\\] The agent fails otherwise. Given the assumption that the agent is a classical Bayesian, we can step back from evaluating the agent and evaluate her prior probability function directly. So a prior \\(\\Pr\\) succeeds relative to \\(\\boldsymbol{x}\\) just in case this is true. \\[\\exists n \\forall m \\geq n: |v(p) - \\Pr(p | \\boldsymbol{X}_m = \\boldsymbol{x}_m)| &lt; \\frac{1}{2}\\] This is reasonably intuitive; the agent is going to get a lot of data about \\(\\boldsymbol{X}\\), and it is interesting to ask whether that data eventually lets her credence in \\(p\\) get to the right side of \\(\\frac{1}{2}\\).\n4 Belot lets an agent succeed if \\(\\boldsymbol{X}\\) is periodic, and the credence in \\(p\\) never drops below \\(\\frac{1}{2}\\), but I think it’s neater to say that the agent is undecided in this case.Given these notions of success and failure, we can naturally define the success set of a prior (or agent) as the set of sequences it succeeds on, and the failure set as the set of sequences it fails on.\nAbusing notation a little, say that \\(\\boldsymbol{x}_i \\supset \\boldsymbol{x}_k\\) iff \\(\\boldsymbol{x}_i\\) is a sequence that has \\(\\boldsymbol{x}_k\\) as its first \\(k\\) entries. Then we can state the first of Belot’s conditions on a good Bayesian agent/prior. A prior is open-minded just in case this condition holds: \\[\\forall \\boldsymbol{x}_k \\exists \\boldsymbol{x}_i \\supset \\boldsymbol{x}_k, \\boldsymbol{x}_j \\supset \\boldsymbol{x}_k: \\Pr(p | \\boldsymbol{X}_i = \\boldsymbol{x}_i) &lt; \\frac{1}{2} \\wedge \\Pr(p | \\boldsymbol{X}_j = \\boldsymbol{x}_j) &gt; \\frac{1}{2}\\] That is, no matter what happens, it is possible that the probability of \\(p\\) will fall below , and possible it will rise above . To motivate the first, consider any situation where the sequence to date has looked periodic. (If it had not looked periodic to date, presumably the probability of \\(p\\) should already be low.) Now extend that sequence with a large of random noise. At the end of this, it should no longer be probable that the sequence is periodic. On the other hand, assume the sequence has not looked periodic to date. Extend it by repeating \\(\\boldsymbol{x}_k\\) more than \\(k\\) times. At the end of this, it should look probable that the sequence is periodic (at least for large enough \\(k\\)). So open-mindedness looks like a good condition to impose.\nThe second condition we might impose, though not one Belot names, is modesty. Any function might fail. One natural way it might fail is that it might get, to use a term Belot does use, flummoxed. It could change its mind infinitely often about whether the sequence is periodic. By definition, open-mindedness entails the possibility of being flummoxed. Given the definitions of success and failure, \\(\\Pr\\) will fail relative to any \\(\\boldsymbol{x}\\) that flummoxes it. So success is not a priori guaranteed. Now for any function we can work out the set of sequences relative to which it fails. It turns out this will be a rather large set. Indeed, the set of sequences on which any open-minded function succeeds is meagre.5 Say a function is modest if the initial probability it gives to \\(\\boldsymbol{X}\\) being in its success set is less than 1. Given how large the failure set is, modesty also seems like a good requirement.6\n5 A meagre subset of a space is any set built up as a countable union of nowhere dense sets.6 Belot goes into much more detail about why modesty is a good requirement to put on a rational prior, but I’m omitting those details since I have very little to add to what Belot says.The argument for modesty is not that it is an immediate consequence of regularity. It does follow from regularity, but in the case we’re considering, regularity is quite implausible. Some sets, even some quite large sets in some sense, will have to be given probability 0. The surprising thing is that a residual set (i.e., the complement of a meagre set) gets probability 0.\nIt might be thought that modesty here is problematic for the same reason that epistemic modesty is often problematic: it validates Moore-paradoxical thoughts. It’s bad to say p, but there is a probability that not p. It’s even bad, though as Briggs (2009) points out, not quite bad for the same reasons, to say Whether I believe p is true or false tomorrow, there will be a probability I’m false. Perhaps modesty is a requirement that someone say something like that, and hence is an improper requirement.\nBut in fact the requirement of modesty is disanalogous to the ‘requirement’, suggested in the previous paragraph, that agents endorse Moore-paradoxical principles. There isn’t anything wrong with saying Whichever side of one half my credence in p is tomorrow, there is a probability that the truth will be the other side of one half. That’s not Moore-paradoxical. Indeed, unless one is sure that one’s credence in \\(p\\) tomorrow will be 0 or 1, it is something one should endorse.\nOr consider a different example. There will be a sequence of 0s and 1s, but this time there will only be three elements, and the agent will only be shown the first of them tomorrow. Let \\(q\\) be the proposition that there are more 1s than 0s in the three-element sequence. Say the agent succeeds iff tomorrow, after seeing just one element, her credence in \\(q\\) is the same side of one-half as the truth. And say the agent is modest iff, right now, her credence that she succeeds tomorrow is less than one. There is nothing incoherent about being modest. If her credal distribution today is completely flat, giving \\(\\frac{1}{8}\\) credence to each of the eight possible sequences, she will be modest, for example.\nNow this case is somewhat different to the one Belot started with in a couple of respects. On the one hand, we’re asking about modesty at a particular point, i.e., tomorrow, rather than over a long sequence. On the other hand, we’re asking about whether the agent’s credences will be on the right side of one-half after having seen one-third of the data, rather than, as in the original case, after seeing measure zero of the sequence. The first difference makes it easier to be modest, the second difference makes it harder. So the cases are not perfect analogies, but they are similar enough in respect of modesty to make it plausible that if modesty is coherent in this case, as we’ve shown it is, then it should be coherent in Belot’s case as well.\nSo that’s the argument that open-mindedness and modesty are good conditions for priors to satisfy. Here’s the worrying result that Belot proves. There are no open-minded modest priors. If \\(A\\) is a classical Bayesian, she will either have to be closed minded or immodest. Neither seems rational, so it seems that being a classical Bayesian is incompatible with being rational. That is, we can’t be precise Bayesians if we accept the following two constraints.\n\nOpen-Mindedness: For any initial sequence, there is a continuation after which it seems probable that \\(\\boldsymbol{X}\\) is periodic, and a continuation after which it seems probable that \\(\\boldsymbol{X}\\) is not periodic.\nModesty: The initial probability that the agent will succeed, i.e., that their credence in \\(p\\) will eventually get to the right side of \\(\\frac{1}{2}\\) and stay there, is less than 1.\n\nSince both open-mindedness and modesty are very plausible constraints, it follows that there is no good way to be a precise Bayesian in the face of this puzzle.\n\n\n0.2 Making the Puzzle Less Precise\nWhat happens, though, if the agent is an imprecise Bayesian? Is there a parallel version of Belot’s argument that shows this kind of imprecise Bayesian is necessarily irrational? I’m going to argue that the answer is no.\nThe first thing we have to do is work out how to redefine the key terms in Belot’s argument once we drop the assumption that the agent is a classical Bayesian. There are several ways of formulating our definitions which are equivalent given that assumption, but not equivalent given that the agent is an imprecise Bayesian. There are three major choice points here.\n\nWhat is success?\nWhat is open-mindedness?\nWhat is modesty?\n\nAssume our agent’s credal state is represented by set \\(S\\) of probability functions. Then there are two natural ways to think about success. \\[\\begin{aligned}\n\\forall \\Pr \\in S:  \\exists n \\forall m \\geq n: |v(p) - \\Pr(p | \\boldsymbol{X}_m= \\boldsymbol{x}_m)| &lt; \\frac{1}{2} \\\\\n\\exists n \\forall \\Pr \\in S: \\forall m \\geq n: |v(p) - \\Pr(p | \\boldsymbol{X}_m= \\boldsymbol{x}_m)| &lt; \\frac{1}{2}\\end{aligned}\\] The second is obviously stronger than the first, since it involves moving an existential quantifier out in front of a universal quantifier. And there are some natural cases where an agent could succeed on the first definition, and fail on the second. Here’s one such case.\nLet \\(\\Pr_0\\) be the fair-coin measure. Acccording to the fair coin measure, if \\(\\boldsymbol{y}\\) is any \\(k\\) length sequence of 0s and 1s we have \\(\\Pr_0(\\boldsymbol{x}_k = \\boldsymbol{y}) = 2^{-k}\\). Intuitively, it thinks the 0s and 1s are generated by flips of a fair coin, and it won’t change its mind about that no matter what happens.\nSay a probability function \\(\\Pr\\) is regular periodic iff it satisfies these two conditions.\n\n\\(\\Pr(p) = 1\\).\nFor any periodic sequence \\(\\boldsymbol{y}\\), \\(\\Pr(\\boldsymbol{X}= \\boldsymbol{y}) &gt; 0\\).\n\nIntuitively, these functions are certain that \\(X\\) is periodic, and assign positive probability to each possible periodic sequence. Now consider the family of functions we get by taking equal weighted mixtures of \\(\\Pr_0\\) with each regular periodic function. Let that family represent the agent’s credence. And assume for now that \\(\\boldsymbol{X}\\) is the sequence \\(\\langle 0, 0, 0, \\dots \\rangle\\). Does the agent succeed?\nWell, each \\(\\Pr\\) in her representor succeeds. To prove this, it will be helpful to prove a lemma that we’ll again have use for below. For this lemma, let \\(\\Pr_0\\) be the fair-coin measure (as already noted), \\(\\Pr_1\\) be any measure such that \\(\\Pr_1(p) = 1\\), and \\(\\Pr_2\\) be the equal mixture of \\(\\Pr_0\\) and \\(\\Pr_1\\).\nLemma 1: \\(\\Pr_2(p | \\boldsymbol{X}_k = \\boldsymbol{y}_k) &gt; \\frac{1}{2}\\) iff \\(\\Pr_1(\\boldsymbol{X}_k = \\boldsymbol{y}_k) &gt; \\Pr_0(\\boldsymbol{X}_k = \\boldsymbol{y}_k).\\)\n\nProof. Proof. Let \\(\\Pr_i(\\boldsymbol{X}_k = \\boldsymbol{y}_k) = a_i\\) for \\(i \\in {0, 1}\\). Recall that \\(\\Pr_0(p) = 0\\) and \\(\\Pr_1(p) = 1\\). Then we can quickly get that \\(\\Pr_2(p | \\boldsymbol{X}_k = \\boldsymbol{y}_k) = \\frac{a_1}{a_0 + a_1}\\), from which the lemma immediately follows. ◻\n\nFor any \\(\\Pr\\) in the agent’s representor, there is some \\(k\\) such that \\(\\Pr(\\boldsymbol{X}= \\langle 0, 0, 0, \\dots \\rangle)\\) \\(&gt; 2^{-k}\\). So after at most \\(k\\) 0s have appeared, \\(\\Pr(p)\\) will be above \\(\\frac{1}{2}\\), and it isn’t coming back. That means it succeeds. And since \\(\\Pr\\) was arbitrary, it follows that all \\(\\Pr\\) succeed.\nBut the agent in a good sense doesn’t succeed. No matter how much data she gets, there will be \\(\\Pr\\) in her representor according to which \\(\\Pr(p) &lt; \\frac{1}{2}\\). After all, for any \\(k\\), there are regular periodic \\(\\Pr\\) such that the probability of \\(\\boldsymbol{x}_k\\) being \\(k\\) 0s is below \\(\\frac{1}{2^k}\\). So if we mix that function with \\(\\Pr_0\\), we get a function where the most probable continuations of this initial sequence are the random sequences provided by the fair coin measure.\nIn terms of our definitions of success above, the agent satisfies the first, but not the second. Every function in her representor eventually has the probability of \\(p\\) go above \\(\\frac{1}{2}\\). But at any time, there are functions in her representor according to which the probability of \\(p\\) is arbitrarily low.\nHere I think we have to make a distinction between different ways of understanding the formalism of imprecise probabilities. (What follows is indebted to Bradley (2014), especially his section 3.1, but I’m disagreeing somewhat with his conclusions, and following more closely the conclusions of Joyce (2010) and Schoenfield (2012).)\nOne way of thinking about imprecise credences is that each probability function in the representor is something like an advisor, and the agent who is imprecise simply hasn’t settled on which advisor to trust. Call this the pluralist interpretation of the formalism. On this interpretation, it is natural to think that what is true of every function is true of the agent.\nAnother way is to think of the agent’s mind as constituted by, but distinct from, the representors. An analogy to keep in mind here is the way that a parliament is constituted by, but distinct from, its members. Keeping with this analogy, call this the corporate interpretation of the formalism. Note that corporate bodies will typically have their own rules for how the views of the members will be translated into being views of the whole. Even if every member of the parliament believes that the national cricket team will win its upcoming game, it doesn’t follow that the parliament believes that; the parliament only believes what it resolves it has believed.\nNow I only want to defend the imprecise Bayesian model on the corporate interpretation.7 The pluralist interpretation, it seems to me, faces grave difficulties. For one thing, it has a hard time explaining what’s wrong with the existential claim “There is a precise number \\(x\\) such that \\(x\\) is the probability of \\(p\\)”. Every advisor believes that, so on the pluralist model the agent does too. (Compare the criticisms of “fanatical supervaluationism” in Lewis (1993).) More relevant to the discussion here, I am following Belot in thinking we have an argument that each precise Bayesian is unreasonably proud. On the pluralist interpretation, the agent is undecided which of these unreasonable advisors she will follow. But such a state is itself unreasonable; she should have decided not to follow any of them, since they are all provably unreasonable!\n7 I have an independent metaphysical reason for preferring the corporate interpretation. I think that comparative confidences, things like being at least as confident in \\(p\\) as in \\(q\\), are metaphysically prior to numerical credences, or even sets of numerical credences. On such a metaphysics, what it is for \\(\\Pr\\) to be in the representor just is for every \\(p, q, r, s\\), if the agent is at least as confident in \\(p\\) given \\(q\\) as in \\(r\\) given \\(s\\), then \\(\\Pr(p | q) \\geq \\Pr(r | s)\\). And it seems, though I won’t defend this claim here, that the corporate interpetation fits more naturally with the idea that comparative confidences are primitive.A surprising fact about corporate bodies is that they can be immune to problems that beset each of their members. It would be illegitimate for any one parliamentarian to have law-making power; it is (or at least can be) legitimate for them all to have such power. Indeed, it would be unreasonable for any of them to think that they individually should have law-making powers; that would be unreasonably proud. But it is not unreasonable for them to collectively think that they should collectively have law-making powers. If they are a well-constituted parliament, this is a perfectly reasonable thought. Similarly here, the agent, the corporate body, could avoid being unreasonably proud even though each of the representors is over-confident in its own powers.\nNow going back to success and modesty, it seems to me that the first definition of success is appropriate on the pluralist interpretation of the imprecise framework, and the second is appropriate on the corporate interpretation. The first interpretation says that the agent succeeds iff every member succeeds. And the second says that the agent succeeds iff the body of functions, collectively, succeed. Since I’m defending the use of the imprecise framework on the corporate interpretation, it is the second definition of success that is appropriate, and that’s what I will use here.\nThis understanding isn’t without costs. Bradley (2014) argues, in effect, that the best responses to dilation-based arguments against imprecise probabilities (as in White (2010)), are only available on the pluralist interpretation. I’m not going to try to solve those problems here, but I will note that the interpretative choice I’m making generates some extra philosophical work elsewhere. Against that, the corporate interpretation has some benefits. It lets us agree with Peter Walley (1991) that there are rational agents who are represented by sets of merely finitely additive probability functions, though no merely finitely additive probability function on its own could represent a rational agent. So the issues between the two interpretations are extensive. For now, I’ll simply note that I’m interested in defending the imprecise Bayesian from Belot’s argument on the corporate interpretation. And with that I’ll return to translating Belot’s puzzle into the imprecise framework, with the second, corporate-friendly, interpretation of success on board.\nThere are also two natural ways to generalise Belot’s notion of open-mindedness to the imprecise case. We could require that the agent satisfies either the first or second of these conditions. \\[\\begin{aligned}\n\\forall \\boldsymbol{x}_k \\exists \\boldsymbol{x}_i \\supset \\boldsymbol{x}_k, \\boldsymbol{x}_j \\supset \\boldsymbol{x}_k: \\neg(\\Pr(p | \\boldsymbol{X}_i = \\boldsymbol{x}_i) \\geq \\frac{1}{2}) \\wedge \\neg(\\Pr(p | \\boldsymbol{X}_j = \\boldsymbol{x}_j) &lt; \\frac{1}{2}) \\\\\n\\forall \\boldsymbol{x}_k \\exists \\boldsymbol{x}_i \\supset \\boldsymbol{x}_k, \\boldsymbol{x}_j \\supset \\boldsymbol{x}_k: \\Pr(p | \\boldsymbol{X}_i = \\boldsymbol{x}_i) &lt; \\frac{1}{2} \\wedge \\Pr(p | \\boldsymbol{X}_j = \\boldsymbol{x}_j) \\geq \\frac{1}{2}\\end{aligned}\\] The second is just the same symbols as in Belot’s, and it is what I’ll end up arguing is the right constraint to put on the imprecise Bayesian agent. And it is a considerably more demanding constraint than the first. But the first is perhaps the more natural understanding of open-mindedness. It says that no matter what the initial evidence is, the agent is not guaranteed to settle her credence in \\(p\\) on one side of \\(\\frac{1}{2}\\). That’s a way of being open-minded.\nBut if the agent satisfies that constraint, she may be open-minded, but she won’t necessarily be responsive to the evidence. Here’s how I’m using the terms ‘open-minded’ and ‘evidence-responsive’. In both clauses, the quantification is intended to be over a salient class of propositions. (The relevant class in the application we’re most interested in is just \\(\\{X\\) is periodic, \\(X\\) is not periodic\\(\\}\\).) And I’ll say an agent is ‘confident’ in a proposition iff her credence in it is above \\(\\frac{1}{2}\\).\n\nOpen-Minded\n\nAny time an agent is confidence in a proposition, there is some evidence she could get that would make her lose confidence in it.\n\nEvidence-Responsive\n\nFor any proposition, there is some evidence the agent could get that would make her confident in it.\n\n\nOnce we allow imprecise credences, these two notions can come apart. Consider the agent we described above, whose representor consists of equal mixtures of the fair-coin measure and regular periodic functions. They are open-minded; they can always lose confidence that \\(X\\) is periodic or not. But they aren’t evidence-responsive; no matter what the evidence, their credence that \\(X\\) is periodic will never rise above \\(\\frac{1}{2}\\). In fact, their credence that \\(X\\) is periodic will never rise above any positive number.\nThat suggests open-mindedness is too weak a constraint. If the evidence the agent gets is a string of several hundred 0s, she shouldn’t just lose any initial confidence in \\(\\neg p\\), she should become confident in \\(p\\). And arguably (though I could imagine a dissent here), if the initial sequence is a seemingly random sequence, the credence in \\(p\\) should drop well below \\(\\frac{1}{2}\\). (The imagined dissent here is from someone who thinks that the noisier the data, the more imprecise credences should get. That’s an interesting view, but perhaps orthogonal to the issues we’re debating here.)\nAnd when we look back at Belot’s motivations for open-mindedness, we see that they are really motivations for being evidence-responsive. One of the distinctive (and I would say problematic) features of precise Bayesianism is that it doesn’t really have a good way of representing a state of indecisiveness or open-mindedness. In the terms we’ve been using here, there’s no difference for the precise Bayesian between being evidence responsive and open minded. The imprecise Bayesian can distinguish these. And in Belot’s puzzle, we should require that the imprecise Bayesian agent is evidence responsive. So we should impose the second, stronger, condition.\nThe final condition to discuss is modesty. There are three natural candidates here. We could merely require that the agent’s prior probability that \\(\\boldsymbol{x}\\) is in her success set is not equal to 1. Or we could require that it be less than 1. Or, even more strongly, we could require that it be less than some number that is less than 1. If her credence that \\(\\boldsymbol{x}\\) is in her success set is imprecise over some interval \\([k, 1]\\), she satisfies the first condition, but not the second or third. If it is imprecise over some interval \\((k, 1)\\), or \\([k, 1)\\), she satisfies the first and second conditions, but not the third. In the interests of setting the imprecise Bayesian the hardest possible challenge, though, let’s say that modesty requires the third criteria. Her ex ante credence in success should not just be less than 1, it should be less than some number less than 1.\nThe aim of the next section is to describe a representor that satisfies open-mindedness and modesty with respect to the question of whether the sequence is periodic. The representor will not represent a state that it is rational for a person to be in; we’ll come back in the last section to the significance of this. My aim is just to show that for the imprecise Bayesian, unlike the precise Bayesian, open-mindedness and modesty are compatible. And the proof of this will be constructive; I’ll build a representor that is, while flawed in some other ways, open-minded and modest.\n\n\n0.3 Meeting the Challenge, Imprecisely\nRecall that \\(\\Pr_0\\) is the fair-coin measure, according to which, if \\(\\boldsymbol{y}\\) is any \\(k\\) length sequence of 0s and 1s we have \\(\\Pr_0(\\boldsymbol{X}_k = \\boldsymbol{y}) = 2^{-k}\\).\nSay a finite sequence \\(\\boldsymbol{y}_k\\) of length \\(k\\) is repeating iff for some \\(n &gt; 1\\), \\(\\boldsymbol{y}_k\\) consists of \\(n\\) repetitions of a sequence of length \\(k/n\\). For any non-repeating sequence \\(\\boldsymbol{y}_k\\) (of length \\(k\\)) let \\(\\boldsymbol{s}_{\\boldsymbol{y}_k}\\) be the sequence consisting of \\(\\boldsymbol{y}_k\\) repeated infinitely often. Let \\(\\Pr_1\\) be the function such that, \\[\\Pr{}_1(\\boldsymbol{X}= \\boldsymbol{s}_{\\boldsymbol{y}_k}) = \\frac{1}{2^{2k}-1}\\] Intuitively, we can think of \\(\\Pr_1\\) as follows. Consider a measure over representations of periodic sequences. Any periodic sequence can be represented just as a finite sequence, plus the instruction repeat infinitely often, so this is really just a measure over finite sequences. One natural such measure assigns measure \\(\\frac{1}{2^{2k}}\\) to each sequence of length \\(k\\). Of course, several of these representations will be representations of the same sequence. For instance, \\(\\langle 0, 1 \\rangle\\), \\(\\langle 0, 1, 0, 1 \\rangle\\) and \\(\\langle 0, 1, 0, 1, 0, 1 \\rangle\\) repeated infinitely produce the same sequence. Now the probability of a sequence, according to \\(\\Pr_1\\) is just the measure, so defined, of the class of representations of that measure. (It’s a little easier to confirm that the measures sum to 1 than that the probabilities do, which is why I’ve included this little explanation.)\nNow define \\(\\Pr_2\\) as the equal weight mixture of \\(\\Pr_0\\) and \\(\\Pr_1\\), i.e., \\(\\Pr_2(q) = (\\Pr_0(q) + \\Pr_1(q))/2\\). Since \\(\\Pr_0(p) = 0\\), and \\(\\Pr_1(p) = 1\\), \\(\\Pr_2(p) = \\frac{1}{2}\\). There will be several facts about \\(\\Pr_2\\) that are useful to have in place for future reference. (Recall I’m using \\(\\boldsymbol{X}\\) as a random variable for the sequence the agent will see, \\(\\boldsymbol{x}\\) as a rigid designator of that sequence, \\(\\boldsymbol{y}\\) and \\(\\boldsymbol{z}\\) are variables for arbitrary sequences, and the \\(k\\) subscript to restrict sequences to length \\(k\\).) The first of these was proven as Lemma 1.\n\nLemma 1.\n\n\\(\\Pr_2(p | \\boldsymbol{X}_k = \\boldsymbol{y}_k) &gt; \\frac{1}{2} \\text{ iff } \\Pr_1(\\boldsymbol{X}_k = \\boldsymbol{y}_k) &gt; \\Pr_0(\\boldsymbol{X}_k = \\boldsymbol{y}_k).\\)\n\n\nDefine a new predicate \\(N\\) of finite sequences \\(\\boldsymbol{y}_k\\), to hold just in case \\(\\boldsymbol{y}_k\\) could be the initial segment of an infinite sequence of period at most \\(\\frac{k}{2}\\). So \\(\\boldsymbol{y}_k\\) must consist of some sequence repeated twice, and anything else in \\(\\boldsymbol{y}_k\\) must be consistent with that sequence repeating again (and if necessary again, and again, …). Then we get,\n\nLemma 2.\n\nFor \\(k \\geq 2\\), \\(\\Pr_2(p | \\boldsymbol{X}_{2k} = \\boldsymbol{y}_{2k}) &gt; \\frac{1}{2}\\) iff \\(N\\boldsymbol{y}_{2k}\\).\n\n\n\nProof. Proof. By Lemma 1, this reduces to the question of the relationship \\(\\Pr_1(\\boldsymbol{X}_{2k} = \\boldsymbol{y}_{2k}) &gt; \\Pr_0(\\boldsymbol{X}_{2k} = \\boldsymbol{y}_{2k})\\). Moreover, we know that \\(\\Pr_0(\\boldsymbol{X}_{2k} = \\boldsymbol{y}_{2k}) = 2^{-2k}\\). So the question is whether \\(\\Pr_1(\\boldsymbol{X}_{2k} = \\boldsymbol{y}_{2k}) &gt; 2^{-2k}\\).\nIf \\(N\\boldsymbol{y}_{2k}\\), then it is consistent with \\(\\boldsymbol{X}_{2k} = \\boldsymbol{y}_{2k}\\) that \\(\\boldsymbol{x}\\) is a particular periodic sequence with period at most \\(k\\). Since the probability, according to \\(\\Pr_1\\) of any such sequence is greater than \\(2^{-2k}\\), the right-to-left direction follows.\nIf \\(\\neg N\\boldsymbol{y}_{2k}\\), then the possibilities that get positive probability according to \\(\\Pr_1\\) are at most among the following: \\(\\boldsymbol{X}\\) consists of the first \\(k + 1\\) digits of \\(\\boldsymbol{y}_{2k}\\) repeated endlessly; \\(\\boldsymbol{X}\\) consists of the first \\(k + 2\\) digits of \\(\\boldsymbol{y}_{2k}\\) repeated endlessly; …; \\(\\boldsymbol{x}\\) consists of the first \\(2k\\) digits of \\(\\boldsymbol{y}_{2k}\\) repeated endlessly; \\(\\boldsymbol{X}\\) is one of the two sequences of period \\(2k + 1\\) starting with \\(\\boldsymbol{y}_{2k}\\), or one of the four sequences of period \\(2k+2\\) starting with \\(\\boldsymbol{y}_{2k}\\) or …. So we get the following, starting with the probabilities of each of the possibilities listed in the previous sentence, \\[\\begin{aligned}\n\\Pr{}_1(\\boldsymbol{X}_{2k} = \\boldsymbol{y}_{2k})\n    &\\leq \\frac{1}{2^{2k+2}-1}\n    &+ &\\frac{1}{2^{2k+4}-1}\n    &+ \\dots\n    &+ &\\frac{1}{2^{4k}-1}\n    &+ &\\frac{2}{2^{4k+2}-1}\n    &+ \\dots \\\\\n%\n    &&lt; \\frac{1}{2^{2k+1}}\n    &+ &\\frac{1}{2^{2k+3}}\n    &+ \\dots\n    &+ &\\frac{1}{2^{4k-1}}\n    &+ &\\frac{1}{2^{4k}}\n    &+ \\dots \\\\\n%\n    &&lt; \\frac{1}{2^{2k}}\\end{aligned}\\] And from that the left-to-right direction follows. ◻\n\n\nLemma 3\n\n\\(\\Pr_2\\) is open-minded.\n\n\n\nProof. Proof. Since any initial sequence \\(\\boldsymbol{y}_k\\) that is not \\(N\\) can be easily extended into one that is \\(N\\) (by, e.g., repeating \\(\\boldsymbol{y}_k\\)), and one is that is \\(N\\) can be extended into one that is not (by, e.g., having the repeating sequence stop at the very next step), this follows immediately from Lemma 2. ◻\n\nDefine \\(f\\) to be a function from sequences of length \\(k \\geq 2\\) to sequences of length \\(k+1\\) such that \\[f(\\boldsymbol{y}_k) = \\boldsymbol{y}_k +\n    \\begin{cases}\n        \\langle 0 \\rangle &\\text{if } N\\boldsymbol{y}_k \\leftrightarrow \\Pr{}_1(x_{k+1} = 0 | \\boldsymbol{X}_k = \\boldsymbol{y}_k) \\leq \\frac{1}{2} \\\\\n        \\langle 1 \\rangle &\\text{otherwise}\n    \\end{cases}\\] In the normal way, define \\(f^n(\\boldsymbol{y}_k)\\) to be the result of applying \\(f\\) \\(n\\) times to \\(\\boldsymbol{y}_k\\). And define \\(f^\\infty(\\boldsymbol{y}_k)\\) to be the infinite sequence we get by doing this infintely often.\nIntuitively, the way \\(f\\) works is that if \\(\\boldsymbol{y}_k\\) is already somewhat sequential, then we include the less likely digit, and if it isn’t, then we include the more likely digit. (With ties resolved in favour of including 0 rather than 1.) If we define \\(p(\\boldsymbol{y}_k)\\) to be the smallest \\(n\\) such that \\(\\boldsymbol{y}_k\\) could be the initial segment of a periodic sequence of length \\(n\\), then we’ll get that \\(p(f(\\boldsymbol{y}_k)) &gt; p(\\boldsymbol{y}_k) \\leftrightarrow N\\boldsymbol{y}_k\\) in all cases, except for the case where \\(\\Pr{}_1(\\boldsymbol{x}_k = 0 | \\boldsymbol{X}_k = \\boldsymbol{y}_k) = \\frac{1}{2}\\). That is, if \\(N\\boldsymbol{y}_k\\), then extending \\(\\boldsymbol{y}_k\\) in this way will wipe out the possibility of that smallest sequence being extended indefinitely, while if \\(\\neg N\\boldsymbol{y}_k\\), then that possibility will still be on the table.\nFrom this, it follows that \\(f^{\\infty}(\\boldsymbol{y}_k)\\) will flummox \\(\\Pr_2\\), no matter which \\(\\boldsymbol{y}_k\\) we start with.\nWe need one last classification of finite sequences, and then we are done. Say that \\(O\\boldsymbol{y}_k\\) just in case some initial segment of \\(\\boldsymbol{y}_k\\) of length \\(r\\) could be the initial segment of an infinite period sequence of period less than \\(\\frac{r}{2}\\). This contrasts with \\(N\\) in two ways. First, it requires a sequence that repeats twice, and then starts a third repetition. Second, it does not require that the sequence be ‘live’; there might be subsequent parts of \\(\\boldsymbol{y}_k\\) that are not compatible with the sequence repeating. So the sequence \\(\\langle 0, 0, 1, 0, 0, 1\\rangle\\) satisfies \\(N\\) but not \\(O\\), while the sequence \\(\\langle 0, 1, 0, 1, 0, 0\\rangle\\) satisfies \\(O\\) but not \\(N\\).\nThere are a countable infinity of finite sequences \\(\\boldsymbol{y}_k\\) such that \\(\\neg O \\boldsymbol{y}_k\\). Produce some ordering of them, then define \\(\\Pr_i\\), for \\(i \\geq 3\\), to be the probability function such that \\(\\Pr_i(\\boldsymbol{X}= f^\\infty(\\boldsymbol{y}_k)) = 1\\), where \\(\\boldsymbol{y}_k\\) is the \\(i-2\\)’th sequence in this order.\nNow, consider the set \\(R\\) of all probability functions of the form: \\[\\Pr = \\sum_{i = 2}^\\infty a_i\\Pr{}_i\\] where each of the \\(\\Pr_i\\) are defined as above, each \\(a_i\\) is non-negative, \\(a_2\\) is , and the sum of the \\(a_i\\) from 3 to \\(\\infty\\) is also \\(\\frac{1}{2}\\). Intuitively, each function starts by halving the probability \\(\\Pr_2\\) gives to each initial (or completed) sequence, and distributing the remaining probability over the countable infinity of flummoxing sequences of the form \\(f^\\infty(\\boldsymbol{y}_k)\\), where \\(\\neg O\\boldsymbol{y}_k\\).\nI’ll now prove that \\(R\\) is open minded.\n\nLemma 4\n\nIf \\(\\neg O \\boldsymbol{y}_k\\), then \\(\\neg O f(\\boldsymbol{y}_k)\\).\n\n\n\nProof. Proof. Since \\(\\neg O \\boldsymbol{y}_k\\), the only way that \\(O f(\\boldsymbol{y}_k)\\) could be true is if \\(k = 2r +1\\), and \\(f(\\boldsymbol{y}_k)\\) consists of some sequence of length \\(r\\) repeated twice, plus the first digit repeated a third time. But that means that \\(N\\boldsymbol{y}_k\\). And if that’s the case, then the extra digit that is added by \\(f(\\boldsymbol{y}_k)\\) will not be the necessary digit to repeat this sequence. So it is impossible that \\(O f(\\boldsymbol{y}_k)\\). ◻\n\n\nLemma 5\n\nIf \\(\\neg O \\boldsymbol{y}_k\\), then \\(\\neg O f^\\infty(\\boldsymbol{y}_k)\\).\n\n\n\nProof. Proof. This follows trivially from Lemma 4. ◻\n\n\nTheorem 6\n\n\\(R\\) is open-minded.\n\n\n\nProof. Proof. Any initial sequence can be extended to a sequence satisfying \\(O\\). For example, the initial sequence can be repeated in full twice. An immediate consequence of Lemma 5 is that for all \\(i \\geq 3, O\\boldsymbol{y}_k \\rightarrow \\Pr_i(\\boldsymbol{X}_k = \\boldsymbol{y}_k) = 0\\). That means that if \\(O\\boldsymbol{y}_k\\), then for any \\(\\Pr \\in R,{ } \\Pr(p | \\boldsymbol{X}_k = \\boldsymbol{y}_k) = \\Pr_2(p | \\boldsymbol{X}_k = \\boldsymbol{y}_k)\\). And now the theorem is an immediate consequence of Lemma 3. ◻\n\nLet \\(F\\) be the set of all sequences \\(f^\\infty(\\boldsymbol{y}_k)\\), where \\(\\neg O \\boldsymbol{y}_k\\).\n\nLemma 7\n\nIf \\(\\boldsymbol{x}\\in F\\), then \\(R\\) fails.\n\n\n\nProof. Proof. Assume \\(\\boldsymbol{x}\\in F\\), so \\(\\boldsymbol{x}\\) is not periodic. Then proving the lemma requires showing that for any \\(i\\), there is a \\(j \\geq i\\) such that, according to \\(R\\), the probability of \\(p\\) given \\(\\boldsymbol{X}_j =\\boldsymbol{x}_j\\) is not less than \\(\\frac{1}{2}\\). And that requires showing that there is a \\(\\Pr \\in R\\) such that \\(\\Pr(p | \\boldsymbol{X}_j = \\boldsymbol{x}_j) \\geq \\frac{1}{2}\\). This is easy to do. Consider any sequence \\(\\boldsymbol{y}_i\\) of length \\(i\\) not identical to \\(\\boldsymbol{x}_i\\) such that \\(\\neg O \\boldsymbol{y}_i\\). Consider the probability function \\(\\Pr_k \\in R\\) such that \\(\\Pr_k(\\boldsymbol{X}= f^\\infty(\\boldsymbol{y}_i)) = \\frac{1}{2}\\). Once we conditionalise on \\(\\boldsymbol{X}_i = \\boldsymbol{x}_i\\), that function will behave just like \\(\\Pr_2\\). And since \\(\\boldsymbol{X}\\) flummoxes \\(\\Pr_2\\), that means there is a \\(\\boldsymbol{x}_j\\) such that \\(\\Pr(p | \\boldsymbol{X}_j = \\boldsymbol{x}_j) &gt; \\frac{1}{2}\\), and hence \\(\\Pr(p | \\boldsymbol{X}_j = \\boldsymbol{x}_j) \\geq \\frac{1}{2}\\). ◻\n\n\nLemma 8\n\nFor each \\(\\Pr \\in R, \\Pr(\\boldsymbol{x}\\in F) = \\frac{1}{2}.\\)\n\n\n\nProof. Proof. It helps to think of each of the \\(\\Pr \\in R\\) as mixtures of \\(\\Pr_0\\) and \\(\\Pr_1\\), plus a mixture of the \\(\\Pr_i\\) for \\(i \\geq 3\\). Now \\(\\Pr_0(\\boldsymbol{x}\\in F) = 0\\), since for any countable set, \\(\\Pr_0\\) says the probability that \\(\\boldsymbol{x}\\) is in that set is 0. And \\(\\Pr_1(\\boldsymbol{x}\\in F) = 0\\), since \\(\\Pr_1\\) says that the probability of \\(\\boldsymbol{x}\\) being periodic is 1, and none of the members of \\(F\\) are periodic. But for each \\(\\Pr_i\\) for \\(i \\geq 3\\), \\(\\Pr_i(\\boldsymbol{x}\\in F) = 1\\). Indeed, for each such function, there is a particular sequence in \\(F\\) such that the probability that \\(\\boldsymbol{x}\\) is that sequence is 1. So for each \\(\\Pr \\in R, \\Pr(\\boldsymbol{x}\\in F) = \\frac{1}{4} \\times 0 + \\frac{1}{4} \\times 0 + \\frac{1}{2} \\times 1 = \\frac{1}{2}\\). ◻\n\n\nTheorem 9\n\nAccording to \\(R\\), the probability of an agent whose representor is \\(R\\) failing is at least \\(\\frac{1}{2}\\).\n\n\n\nProof. Proof. Immediate from Lemma 7 and Lemma 8. ◻\n\nSo if an agent’s credences are represented by a non-singleton set of probability functions, not a single probability function, it is possible for them to be open-minded and modest. On the other hand, if an agent is represented by a single probability function, as the precise Bayesian desires, then it is impossible to be open-minded and modest. Since being open-minded and modest is desirable, this is a reason to prefer the imprecise Bayesian picture.\n\n\n0.4 Objections and Replies\nI’m going to reply to three objections, but since my replies overlap, I’ll group the objections together.\n\nObjection 1\n\nThe model here only gives you conditional modesty. Once the initial sequence is \\(O\\), the representor becomes the singleton of an open-minded probability function, and Belot showed that to be immodest. Ideally, the agent would have a prior that is in some way resiliently modest, whereas this prior is fragilely modest.\n\nObjection 2\n\nThis representor is open-minded and modest towards one particular problem, namely whether \\(\\boldsymbol{X}\\) is periodic. But Belot was interested in a wider range of problems, indeed in all problems of the form: does \\(\\boldsymbol{x}\\) fall into some set that is measurable, dense, and has a dense complement. Ideally, we’d have a prior which is widely open-minded and modest, in the sense that it had an open-minded and modest attitude towards many problems. But this prior is narrowly modest, in the sense that it is open-minded and modest about only one problem.\n\nObjection 3\n\nThe representor described here is clearly not a representation of a credal state of anyone rational. Look what it does if the data is a 1 followed by thousands of 0s, or is the first few thousand digits of the binary expansion of \\(\\pi\\), or has a frequency of 0s of 0.2 over all large sub-intervals. No one could adopt this prior, so it doesn’t show anything about the advantages of imprecise Bayesianism.\n\n\n\nProof. Reply. My responses are going to be (1) that we should want more resilient modesty, and though this is a hard technical challenge, it’s possible to see a way forward on it, (2) that we should want somewhat wider open-minded modesty, though how much wider is a hard question, and (3) that the third objection should simply be rejected. Let’s go through those in reverse order, since it’s the response to the third that explains part of what I’m doing in response to the other two.\nWhat we have in section three is a consistency proof. For the imprecise Bayesian, unlike the precise Bayesian, being open-minded is consistent with being modest. That’s good, since it shows that we can’t rule out a rational response to problems like Belot’s. It’s obviously true that the prior in question isn’t rational, but that’s not needed for a consistency proof.\nMoreover, we don’t just have a consistency proof, we have a constructive consistency proof - the prior is described in detail. It’s just not going to be possible to do a constructive proof that open-mindedness, modesty and full rationality are consistent. And that’s because to do that would essentially be to solve all of the problems of epistemology ever. Demonstrating a fully rational prior, even for the range of questions Belot considers, is too much to ask.\nIf there’s a reasonable looking argument that imprecise Bayesians are unlikely to be able to satisfy some set of plausible constraints, then the defender of imprecise Bayesianism is, I think, obliged to show how those constraints can be satisfied. But to ask for a demonstration of how all reasonable constraints can be satisfied at once, in the absence of a decent argument that they cannot be, would clearly be asking too much.\nSo I don’t care that the prior I described is irrational; it serves its purpose in proving consistency. Now what would be nice is to show that some slightly stronger constraints can be simultaneously satisfied. But we have to be sure that those constraints are in fact reasonable constraints. Here’s one constraint that I think isn’t reasonable: be open-minded towards any proposition of the form \\({\\boldsymbol{X}\\in S}\\), where \\(S\\) is a dense set of sequences. Let \\(S\\), for example, be the set consisting of all sequences of the form \\(\\boldsymbol{y}_k + \\boldsymbol{z}\\), where \\(\\boldsymbol{y}_k\\) ranges over all finite sequeneces, and \\(\\boldsymbol{z}\\) is a particular arbitrary sequence that lacks finite definition in our current language. That set is dense, and indeed measurable. But there’s no evidence that could make it reasonable to take \\(\\boldsymbol{X}\\in S\\) to be probable. So a prior that wasn’t open-minded towards \\(\\boldsymbol{X}\\in S\\) could still be perfectly reasonable.\nThat said, the prior I demonstrated is closed-minded towards several propositions that should be taken seriously. It will never have positive credence that \\(\\boldsymbol{X}\\) is eventually periodic without being periodic, or that \\(\\boldsymbol{X}\\) is generated by a chance process that gives each data point chance \\(c \\neq \\frac{1}{2}\\) of being 0. It would be good to have a prior whose open-minded modesty was wider. But before we do that technical work, I think there’s a need to figure out which propositions we should be open-minded about.\nI am more worried by the fragility of the modesty of this prior. There’s a reasonable sense in which the prior is open-minded only in virtue of the fact that it has parts which are immodest. At any point where the agent has credence above \\(\\frac{1}{2}\\) that \\(p\\), she has credence 1 that she will succeed.\nWe could try to complicate the prior a bit more to avoid that. Here’s a sketch of how it could go, with application to one particular initial sequence of data. Consider what happens to \\(R\\) if the initial input is \\(\\langle 0, 1, 0, 0, 1, 0, 0, 1\\rangle\\), hereafter \\(\\boldsymbol{y}\\). According to \\(\\Pr_0\\), that initial sequence has probability \\(\\frac{1}{256}\\). According to \\(\\Pr_1\\), it has probability \\(\\frac{1}{63} + \\frac{1}{4095} + \\frac{1}{65535} \\approx \\frac{1}{62}\\). So given that initial sequence, \\(\\Pr_2\\) says the probability of \\(p\\) is about \\(\\frac{4}{5}\\). And since the sequence is \\(O\\), it could be the start of the the sequence \\(\\langle 0, 1, 0\\rangle\\) repeated indefinitely, its probability according to \\(\\Pr_i\\) is 0, for \\(i \\geq 3\\). Now consider the set of all probability functions of the form \\(a\\Pr_{R} + b\\Pr_{New}\\), where \\(a + b = 1\\), \\(b \\in (0, \\frac{1}{256}), \\Pr_{R} \\in R\\) and \\(\\Pr_{New}\\) is the function which gives probability 1 to \\(\\boldsymbol{X}\\) being \\(O(\\boldsymbol{y})\\). That prior is open-minded, and even after conditionalising on \\(\\boldsymbol{y}\\) satisfies the intermediate of the three modesty conditions described on page - the probability of failure is less than one, though it isn’t less than some number less than one. And this trick could be generalised to satisfy more modesty conditions, and even (though it would take some time to prove this) be unconditionally modest.\nBut I’m not going to go through those steps here. That’s mostly because I think we already have shown enough to show that imprecise Bayesianism has an advantage over precise Bayesianism. The imprecise Bayesian can, and the precise Bayesian can’t, have an open-minded modest attitude. It would be good to press home that advantage and show that there are other things the imprecise Bayesian can do that the precise Bayesian can’t do, such as having a widely open-minded and resiliently modest prior. But even before such a demonstration takes place, the advantage has been established. ◻\n\n\n\n\n\n\n\nReferences\n\nBelot, Gordon. 2013. “Bayesian Orgulity.” Philosophy of Science 80 (4): 483–503. https://doi.org/10.1086/673249.\n\n\nBradley, Seamus. 2014. “Imprecise Probabilities.” In The Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta, Winter 2014. http://plato.stanford.edu/archives/win2014/entries/imprecise-probabilities/; Metaphysics Research Lab, Stanford University.\n\n\nBriggs, Rachael. 2009. “Distorted Reflection.” Philosophical Review 118 (1): 59–85. https://doi.org/10.1215/00318108-2008-029.\n\n\nElga, Adam. 2010. “How to Disagree about How to Disagree.” In Disagreement, edited by Ted Warfield and Richard Feldman, 175–87. Oxford: Oxford University Press.\n\n\nJoyce, James M. 2010. “A Defence of Imprecise Credences in Inference and Decision Making.” Philosophical Perspectives 24 (1): 281–323. https://doi.org/10.1111/j.1520-8583.2010.00194.x.\n\n\nLasonen-Aarnio, Maria. 2015. “New Rational Reflection and Internalism about Rationality.” Oxford Studies in Epistemology 5: 145–71. https://doi.org/10.1093/acprof:oso/9780198722762.003.0005.\n\n\nLewis, David. 1971. “Immodest Inductive Methods.” Philosophy of Science 38 (1): 54–63. https://doi.org/10.1086/288339.\n\n\n———. 1993. “Many, but Almost One.” In Ontology, Causality, and Mind: Essays on the Philosophy of D. M. Armstrong, edited by Keith Campbell, John Bacon, and Lloyd Reinhardt, 23–38. Cambridge: Cambridge University Press. https://doi.org/10.1017/CBO9780511625343.010.\n\n\nPryor, James. 2000. “The Sceptic and the Dogmatist.” Noûs 34 (4): 517–49. https://doi.org/10.1111/0029-4624.00277.\n\n\nSchoenfield, Miriam. 2012. “Chilling Out on Epistemic Rationality: A Defense of Imprecise Credences (and Other Imprecise Doxastic Attitudes).” Philosophical Studies 158 (2): 197–219. https://doi.org/10.1007/s11098-012-9886-7.\n\n\n———. 2015. “A Dilemma for Calibrationism.” Philosophy and Phenomenological Research 91 (2): 425–55. https://doi.org/10.1111/phpr.12125.\n\n\nWalley, Peter. 1991. Statisical Reasoning with Imprecise Probabilities. London: Chapman & Hall.\n\n\nWhite, Roger. 2006. “Problems for Dogmatism.” Philosophical Studies 131 (3): 525–57. https://doi.org/10.1007/s11098-004-7487-9.\n\n\n———. 2010. “Evidential Symmetry and Mushy Credence.” Oxford Studies in Epistemology 3: 161–89."
  },
  {
    "objectID": "posts/gbc/games-beliefs-and-credences.html",
    "href": "posts/gbc/games-beliefs-and-credences.html",
    "title": "Games, Beliefs and Credences",
    "section": "",
    "text": "In previous work (Weatherson 2005, 2011, 2012b) I’ve defended an interest-relative theory of belief. This paper continues the defence. I have four aims.\n\nPublished in Philosophy and Phenomenological Research 92: 209-236.\n\n\nTo offer a new kind of reason for being unsatisfied with the simple Lockean reduction of belief to credence.\nTo defend the legitimacy of appealing to credences in a theory of belief.\nTo illustrate the importance of theoretical, as well as practical, interests in an interest-relative account of belief.\nTo have another try at extending my basic account of belief to cover propositions that are practically and theoretically irrelevant to the agent.\n\nYou’re probably familiar with the following dialectic. We want there to be some systematic connection between credences and beliefs. At first blush, saying that a person believes \\(p\\) and has a very low credence in \\(p\\) isn’t just an accusation of irrationality, it is literally incoherent. The simplest such connection would be a reduction of beliefs to credences. But the simplest reductions don’t work.\n\nImage via Meagan via Creative Commons.\n\nIf we identify beliefs with credence 1, and take credences to support betting dispositions, then a rational agent will have very few beliefs. There are lots of things that an agent, we would normally say, believes even though she wouldn’t bet on them at absurd odds. Note that this argument doesn’t rely on reducing credences to betting dispositions; as long as credences support the betting dispositions, the argument goes through.\nA simple retreat is to the so-called Lockean thesis, which holds that to believe that \\(p\\) is to have credence in \\(p\\) greater than some threshold \\(t\\), where \\(t &lt; 1\\). Just how the threshold is determined could be a matter of some discretion. Perhaps it is a function of the agent’s situation, or of the person ascribing beliefs to the agent, or to the person evaluating that ascription. Never mind these complexities; assuming all such things are held fixed, the Lockean thesis says that there is a threshold \\(t\\) such that everything with credence above \\(t\\) is believed.\nThere’s a simple objection to the Lockean thesis. Given some very weak assumptions about the world, it implies that there are plenty of quadruples \\(\\langle S, A, B, A \\wedge B \\rangle\\) such that\n\n\\(S\\) is a rational agent.\n\\(A, B\\) and \\(A \\wedge B\\) are propositions.\n\\(S\\) believes \\(A\\) and believes \\(B\\).\n\\(S\\) does not believe \\(A \\wedge B\\).\n\\(S\\) knows that she has all these states, and consciously reflectively endorses them.\n\nNow one might think, indeed I do think, that such quadruples do not exist at all. But set that objection aside. If the Lockean is correct, these quadruples should be everywhere. That’s because for any \\(t \\in (0, 1)\\) you care to pick, quadruples of the form \\(\\langle S, C, D, C \\wedge D \\rangle\\) are very very common.\n\n\\(S\\) is a rational agent.\n\\(C, D\\) and \\(C \\wedge D\\) are propositions.\n\\(S\\)’s credence in \\(C\\) is greater than \\(t\\), and her credence in \\(D\\) is greater than \\(t\\).\n\\(S\\)’s credence in \\(C \\wedge D\\) is less than \\(t\\).\n\\(S\\) knows that she has all these states, and reflectively endorses them.\n\nThe best arguments for the existence of quadruples \\(\\langle S, A, B, A \\wedge B \\rangle\\) are non-constructive existence proofs. David Christensen (2005) for instance, argues from the existence of the preface paradox to the existence of these quadruples. I’ve expressed some reservations about that argument in the past (Weatherson 2005). But what I want to stress here is that even if these existence proofs work, they don’t really prove what the Lockean needs. They don’t show that quadruples satisfying the constraints we associated with \\(\\langle S, A, B, A \\wedge B \\rangle\\) are just as common as quadruples satisfying the constraints we associated with \\(\\langle S, C, D, C \\wedge D \\rangle\\), for any \\(t\\). But if the Lockean were correct, they should be exactly as common.\nThis kind of consideration pushes some of us, well me in any case, towards an interest-relative account of belief. But I’m going to set that move aside to start by investigating a different objection. This objection holds that the Lockean thesis could not be true, because credence 1 is not sufficient for belief. That is, the Lockean is committed to the thesis known as regularity; that everything left open by belief gets a positive credence. I think regularity is false. That’s hardly news, there are plenty of good arguments against it, though most of these involve cases with some idealisations. Timothy Williamson (2007a) has a compelling argument against regularity turning on reflections about a case involving infinite coin flips.1 I’m going to offer a ‘finite’ argument against regularity, which I hope is of independent interest, and from that conclude the Lockean is mistaken. There is a worry that my argument against the Lockean also undermines my preferred positive view, and I’ll suggest an independently motivated patch. I’ll then turn to Richard Holton’s attack on the very notion of credence, which obviously would have repercussions for attempts to understand beliefs in terms of credences were it to succeed. I think it doesn’t succeed, but it does show there are important and underappreciated constraints on a theory of belief. I’ll conclude with a comparison between my preferred interest-relative account of belief, and a recent account suggested by Jacob Ross and Mark Schroeder. The short version of the comparison is that I think there’s less difference between the views than Ross and Schroeder think, though naturally I think what differences there are favour my view.\n1 If there’s any gap in Williamson’s argument, it is I think at the point where he concludes that any two infinite sequences of coin flips have the same probability of landing all heads. I think that the defender of non-numerical, comparative approaches to probability can deny that with some plausibility. Perhaps the two sequences of coin flips have incomparable probabilities of landing all heads. But this leads us into complications that are irrlevant to this paper, especially since I think it turns out there is a sound Williamsonian argument against the Lockean who lets different sequences have incomparable probabilities. For a more pessimistic take on Williamson’s argument, see Weintraub (2008).\n0.1 Playing Games with a Lockean\nI’m going to raise problems for Lockeans, and for defenders of regularity in general, by discussing a simple game. The game itself is a nice illustration of how a number of distinct solution concepts in game theory come apart. (Indeed, the use I’ll make of it isn’t a million miles from the use that Kohlberg and Mertens (1986) make of it.) To set the problem up, I need to say a few words about how I think of game theory. This won’t be at all original - most of what I say is taken from important works by Robert Stalnaker (1994, 1996, 1998, 1999). But it is different to what I used to think, and perhaps to what some other people think too, so I’ll set it out slowly.2\n2 I’m grateful to the participants in a game theory seminar at Arché in 2011, especially Josh Dever and Levi Spectre, for very helpful discussions that helped me see through my previous confusions.Start with a simple decision problem, where the agent has a choice between two acts \\(A_1\\) and \\(A_2\\), and there are two possible states of the world, \\(S_1\\) and \\(S_2\\), and the agent knows the payouts for each act-state pair are given by the following able.\n\n\n\n\n\n\\(S_1\\)\n\\(S_2\\)\n\n\n\\(A_1\\)\n4\n0\n\n\n\\(A_2\\)\n1\n1\n\n\n\n\nWhat to do? I hope you share the intuition that it is radically underdetermined by the information I’ve given you so far. If \\(S_2\\) is much more probable than \\(S_1\\), then \\(A_2\\) should be chosen; otherwise \\(A_1\\) should be chosen. But I haven’t said anything about the relative probability of those two states. Now compare that to a simple game. Row has two choices, which I’ll call \\(A_1\\) and \\(A_2\\). Column also has two choices, which I’ll call \\(S_1\\) and \\(S_2\\). It is common knowledge that each player is rational, and that the payouts for the pairs of choices are given in the following table. (As always, Row’s payouts are given first.)\n\n\n\n\n\n\\(S_1\\)\n\\(S_2\\)\n\n\n\\(A_1\\)\n4, 0\n0, 1\n\n\n\\(A_2\\)\n1, 0\n1, 1\n\n\n\n\nWhat should Row do? This one is easy. Column gets 1 for sure if she plays \\(S_2\\), and 0 for sure if she plays \\(S_1\\). So she’ll play \\(S_2\\). And given that she’s playing \\(S_2\\), it is best for Row to play \\(A_2\\).\nYou probably noticed that the game is just a version of the decision problem that we discussed a couple of paragraphs ago. The relevant states of the world are choices of Column. But that’s fine; we didn’t say in setting out the decision problem what constituted the states \\(S_1\\) and \\(S_2\\). And note that we solved the problem without explicitly saying anything about probabilities. What we added was some information about Column’s payouts, and the fact that Column is rational. From there we deduced something about Column’s play, namely that she would play \\(S_2\\). And from that we concluded what Row should do.\nThere’s something quite general about this example. What’s distinctive about game theory isn’t that it involves any special kinds of decision making. Once we get the probabilities of each move by the other player, what’s left is (mostly) expected utility maximisation. (We’ll come back to whether the ‘mostly’ qualification is needed below.) The distinctive thing about game theory is that the probabilities aren’t specified in the setup of the game; rather, they are solved for. Apart from special cases, such as where one option strictly dominates another, we can’t say much about a decision problem with unspecified probabilities. But we can and do say a lot about games where the setup of the game doesn’t specify the probabilities, because we can solve for them given the other information we have.\nThis way of thinking about games makes the description of game theory as ‘interactive epistemology’ (Aumann 1999) rather apt. The theorist’s work is to solve for what a rational agent should think other rational agents in the game should do. From this perspective, it isn’t surprising that game theory will make heavy use of equilibrium concepts. In solving a game, we must deploy a theory of rationality, and attribute that theory to rational actors in the game itself. In effect, we are treating rationality as something of an unknown, but one that occurs in every equation we have to work with. Not surprisingly, there are going to be multiple solutions to the puzzles we face.\nThis way of thinking lends itself to an epistemological interpretation of one of the most puzzling concepts in game theory, the mixed strategy. Arguably the core solution concept in game theory is the Nash equilibrium. As you probably know, a set of moves is a Nash equilibrium if no player can improve their outcome by deviating from the equilibrium, conditional on no other player deviating. In many simple games, the only Nash equilibria involve mixed strategies. Here’s one simple example.\n\n\n\n\n\n\\(S_1\\)\n\\(S_2\\)\n\n\n\\(A_1\\)\n0, 1\n10, 0\n\n\n\\(A_2\\)\n9, 0\n-1, 1\n\n\n\n\nThis game is reminiscent of some puzzles that have been much discussed in the decision theory literature, namely asymmetric Death in Damascus puzzles. Here Column wants herself and Row to make the ‘same’ choice, i.e., \\(A_1\\) and \\(S_1\\) or \\(A_2\\) and \\(S_2\\). She gets 1 if they do, 0 otherwise. And Row wants them to make different choices, and gets 10 if they do. Row also dislikes playing \\(A_2\\), and this costs her 1 whatever else happens. It isn’t too hard to prove that the only Nash equilibrium for this game is that Row plays a mixed strategy playing both \\(A_1\\) and \\(A_2\\) with probability , while Column plays the mixed strategy that gives \\(S_1\\) probability , and \\(S_2\\) with probability .\nNow what is a mixed strategy? It is easy enough to take away form the standard game theory textbooks a metaphysical interpretation of what a mixed strategy is. Here, for instance, is the paragraph introducing mixed strategies in Dixit and Skeath’s Games of Strategy.\n\nWhen players choose to act unsystematically, they pick from among their pure strategies in some random way …We call a random mixture between these two pure strategies a mixed strategy. (Dixit and Skeath 2004, 186)\n\nDixit and Skeath are saying that it is definitive of a mixed strategy that players use some kind of randomisation device to pick their plays on any particular run of a game. That is, the probabilities in a mixed strategy must be in the world; they must go into the players’ choice of play. That’s one way, the paradigm way really, that we can think of mixed strategies metaphysically.\nBut the understanding of game theory as interactive epistemology naturally suggests an epistemological interpretation of mixed strategies.\n\nOne could easily …[model players] …turning the choice over to a randomizing device, but while it might be harmless to permit this, players satisfying the cognitive idealizations that game theory and decision theory make could have no motive for playing a mixed strategy. So how are we to understand Nash equilibrium in model theoretic terms as a solution concept? We should follow the suggestion of Bayesian game theorists, interpreting mixed strategy profiles as representations, not of players’ choices, but of their beliefs. (Stalnaker 1994, 57–58)\n\nOne nice advantage of the epistemological interpretation, as noted by Binmore (2007, 185) is that we don’t require players to have \\(n\\)-sided dice in their satchels, for every \\(n\\), every time they play a game.3 But another advantage is that it lets us make sense of the difference between playing a pure strategy and playing a mixed strategy where one of the ‘parts’ of the mixture is played with probability one.\n3 Actually, I guess it is worse than if some games have the only equilibria involving mixed strategies with irrational probabilities. And it might be noted that Binmore’s introduction of mixed strategies, on page 44 of his (2007), sounds much more like the metaphysical interpretation. But I think the later discussion is meant to indicate that this is just a heuristic introduction; the epistemological interpretation is the correct one.With that in mind, consider the below game, which I’ll call Red-Green. I’ve said something different about this game in earlier work (Weatherson 2012a). But I now think that to understand what’s going on, we need to think about mixed strategies where one element of the mixture has probability one.\nInformally, in this game \\(A\\) and \\(B\\) must each play either a green or red card. I will capitalise \\(A\\)’s moves, i.e., \\(A\\) can play GREEN or RED, and italicise \\(B\\)’s moves, i.e., \\(B\\) can play green or red. If two green cards, or one green card and one red card are played, each player gets $1. If two red cards are played, each gets nothing. Each cares just about their own wealth, so getting $1 is worth 1 util. All of this is common knowledge. More formally, here is the game table, with \\(A\\) on the row and \\(B\\) on the column.\n\n\n\n\n\ngreen\nred\n\n\nGREEN\n1, 1\n1, 1\n\n\nRED\n1, 1\n0, 0\n\n\n\n\nWhen I write game tables like this, and I think this is the usual way game tables are to be interpreted (Weatherson 2012b), I mean that the players know that these are the payouts, that the players know the other players to be rational, and these pieces of knowledge are common knowledge to at least as many iterations as needed to solve the game. With that in mind, let’s think about how the agents should approach this game.\nI’m going to make one big simplifying assumption at first. We’ll relax this later, but it will help the discussion to start with this assumption. This assumption is that the doctrine of Uniqueness applies here; there is precisely one rational credence to have in any salient proposition about how the game will play. Some philosophers think that Uniqueness always holds (White 2005). I join with those such as North (2010) and Schoenfield (2013) who don’t. But it does seem like Uniqueness might often hold; there might often be a right answer to a particular problem. Anyway, I’m going to start by assuming that it does hold here.\nThe first thing to note about the game is that it is symmetric. So the probability of \\(A\\) playing GREEN should be the same as the probability of \\(B\\) playing green, since \\(A\\) and \\(B\\) face exactly the same problem. Call this common probability \\(x\\). If \\(x &lt; 1\\), we get a quick contradiction. The expected value, to Row, of GREEN, is 1. Indeed, the known value of GREEN is 1. If the probability of green is \\(x\\), then the expected value of RED is \\(x\\). So if \\(x &lt; 1\\), and Row is rational, she’ll definitely play GREEN. But that’s inconsistent with the claim that \\(x &lt; 1\\), since that means that it isn’t definite that Row will play GREEN.\nSo we can conclude that \\(x = 1\\). Does that mean we can know that Row will play GREEN? No. Assume we could conclude that. Whatever reason we would have for concluding that would be a reason for any rational person to conclude that Column will play green. Since any rational person can conclude this, Row can conclude it. So Row knows that she’ll get 1 whether she plays GREEN or RED. But then she should be indifferent between playing GREEN and RED. And if we know she’s indifferent between playing GREEN and RED, and our only evidence for what she’ll play is that she’s a rational player who’ll maximise her returns, then we can’t be in a position to know she’ll play GREEN.\nI think the arguments of the last two paragraphs are sound. We’ll turn to an objection presently, but let’s note how bizarre is the conclusion we’ve reached. One argument has shown that it could not be more probable that Row will play GREEN. A second argument has shown that we can’t know that Row will play GREEN. It reminds me of examples involving blindspots (Sorensen 1988). Consider this case:\n\nBrian does not know (B).\n\nThat’s true, right? Assume it’s false, so I do know (B). Knowledge is factive, so (B) is true. But that contradicts the assumption that it’s false. So it’s true. But I obviously don’t know that it’s true; that’s what this very true proposition says.4\n4 It’s received wisdom in philosophy that one can never properly say something of the form p, but I don’t know that p. This is used as a data point in views as far removed from each other as those defended in Heal (1994) and Williamson (1996). But I don’t feel the force of this alleged datum at all, and (B) is just one reason. For a different kind of case that makes the same point, see Maitra and Weatherson (2010).5 As an aside, the existence of these cases is why I get so irritated when epistemologists try to theorise about ‘Gettier Cases’ as a class. What does (B) have in common with inferences from a justified false belief, or with otherwise sound reasoning that is ever so close to issuing in a false conclusion due to relatively bad luck? As far as I can tell, the class of justified true beliefs that aren’t knowledge is a disjunctive mess, and this should matter for thinking about the nature of knowledge. For further examples, see Williamson (2013) and Nagel (2013).Now I’m not going to rest anything on this case, because there are so many tricky things one can say about blindspots, and about the paradoxes generally. It does suggest that there are other finite cases where one can properly have maximal credence in a true proposition without knowledge.5 And, assuming that we shouldn’t believe things we know we don’t know, that means we can have maximal credence in things we don’t believe. All I want to point out is that this phenomena of maximal credence without knowledge, and presumably without full belief, isn’t a quirky feature of self-reference, or of games, or of puzzles about infinity; it comes up in a wide range of cases.\nFor the rest of this section I want to reply to one objection, and weaken an assumption I made earlier. The objection is that I’m wrong to assume that agents will only maximise expected utility. They may have tie-breaker rules, and those rules might undermine the arguments I gave above. The assumption is that there’s a uniquely rational credence to have in any given situation.\nI argued that if we knew that \\(A\\) would play GREEN, we could show that \\(A\\) had no reason to play GREEN. But actually what we showed was that the expected utility of playing GREEN would be the same as playing RED. Perhaps \\(A\\) has a reason to play GREEN, namely that GREEN weakly dominates RED. After all, there’s one possibility on the table where GREEN does better than RED, and none where RED does better. And perhaps that’s a reason, even if it isn’t a reason that expected utility considerations are sensitive to.\nNow I don’t want to insist on expected utility maximisation as the only rule for rational decision making. Sometimes, I think some kind of tie-breaker procedure is part of rationality. In the papers by Stalnaker I mentioned above, he often appeals to this kind of weak dominance reasoning to resolve various hard cases. But I don’t think weak dominance provides a reason to play GREEN in this particular case. When Stalnaker says that agents should use weak dominance reasoning, it is always in the context of games where the agents’ attitude towards the game matrix is different to their attitude towards each other. One case that Stalnaker discusses in detail is where the game table is common knowledge, but there is merely common (justified, true) belief in common rationality. Given such a difference in attitudes, it does seem there’s a good sense in which the most salient departure from equilibrium will be one in which the players end up somewhere else on the table. And given that, weak dominance reasoning seems appropriate.\nBut that’s not what we’ve got here. Assuming that rationality requires playing GREEN/green, the players know we’ll end up in the top left corner of the table. There’s no chance that we’ll end up elsewhere. Or, perhaps better, there is just as much chance we’ll end up ‘off the table’, as that we’ll end up in a non-equilibrium point on the table. To make this more vivid, consider the ‘possibility’ that \\(B\\) will play blue, and if \\(B\\) plays blue, \\(A\\) will receive 2 if she plays RED, and -1 if she plays GREEN. Well hold on, you might think, didn’t I say that green and red were the only options, and this was common knowledge? Well, yes, I did, but if the exercise is to consider what would happen if something the agent knows to be true doesn’t obtain, then the possibility that one agent will play blue certainly seems like one worth considering. It is, after all, a metaphysical possibility. And if we take it seriously, then it isn’t true that under any possible play of the game, GREEN does better than RED.\nWe can put this as a dilemma. Assume, for reductio, that GREEN/green is the only rational play. Then if we restrict our attention to possibilities that are epistemically open to \\(A\\), then GREEN does just as well as RED; they both get 1 in every possibility. If we allow possibilities that are epistemically closed to \\(A\\), then the possibility where \\(B\\) plays blue is just as relevant as the possibility that \\(B\\) is irrational. After all, we stipulated that this is a case where rationality is common knowledge. In neither case does the weak dominance reasoning get any purchase.\nWith that in mind, we can see why we don’t need the assumption of Uniqueness. Let’s play through how a failure of Uniqueness could undermine the argument. Assume, again for reductio, that we have credence \\(\\varepsilon &gt; 0\\) that \\(A\\) will play RED. Since \\(A\\) maximises expected utility, that means \\(A\\) must have credence 1 that \\(B\\) will play green. But this is already odd. Even if you think people can have different reactions to the same evidence, it is odd to think that one rational agent could regard a possibility as infinitely less likely than another, given isomorphic evidence. And that’s not all of the problems. Even if \\(A\\) has credence 1 that \\(B\\) will play green, it isn’t obvious that playing RED is rational. After all, relative to the space of epistemic possibilities, GREEN weakly dominates RED. Remember that we’re no longer assuming that it can be known what \\(A\\) or \\(B\\) will play. So even without Uniqueness, there are two reasons to think that it is wrong to have credence \\(\\varepsilon &gt; 0\\) that \\(A\\) will play RED. So we’ve still shown that credence 1 doesn’t imply knowledge, and since the proof is known to us, and full belief is incompatible with knowing that you can’t know, this is a case where credence 1 doesn’t imply full belief. So whether \\(A\\) plays GREEN, like whether the coin will ever land tails, is a case the Lockean cannot get right. No matter where they set the threshold for belief our credence is above that threshold, but we don’t believe.\nSo I think this case is a real problem for a Lockean view about the relationship between credence and belief. If A is rational, she can have credence 1 that B will play green, but won’t believe that B will play green. But now you might worry that my own account of the relationship between belief and credence is in just as much trouble. After all, I said that to believe \\(p\\) is, roughly, to have the same attitudes towards all salient questions as you have conditional on \\(p\\). And it’s hard to identify a question that rational A would answer differently upon conditionalising on the proposition that B plays green.\nI think what went wrong in my earlier view was that I’d too quickly equated updating with conditionalisation. The two can come apart. Here’s an example from Gillies (2010) that makes the point well.6\n6 A similar example is in Kratzer (2012, 94).\nI have lost my marbles. I know that just one of them – Red or Yellow – is in the box. But I don’t know which. I find myself saying things like …“If Yellow isn’t in the box, the Red must be.” (4:13)\n\nAs Gillies goes on to point out, this isn’t really a problem for the Ramsey test view of conditionals.\n\nThe Ramsey test – the schoolyard version, anyway – is a test for when an indicative conditional is acceptable given your beliefs. It says that (if p)(q) is acceptable in belief state B iff q is acceptable in the derived or subordinate state B-plus-the-information-that-p. (4:27)\n\nAnd he notes that this can explain what goes on with the marbles conditional. Add the information that Yellow isn’t in the box, and it isn’t just true, but must be true, that Red is in the box.\nNote though that while we can explain this conditional using the Ramsey test, we can’t explain it using any version of the idea that probabilities of conditionals are conditional probabilities. The probability that Red must be in the box is 0. The probability that Yellow isn’t in the box is not 0. So conditional on Yellow not being in the box, the probability that Red must be in the box is still 0. Yet the conditional is perfectly assertable.\nThere is, and this is Gillies’s key point, something about the behaviour of modals in the consequents of conditionals that we can’t capture using conditional probabilities, or indeed many other standard tools. And what goes for consequents of conditionals goes for updated beliefs too. Learn that Yellow isn’t in the box, and you’ll conclude that Red must be. But that learning can’t go via conditionalisation; just conditionalise on the new information and the probability that Red must be in the box goes from 0 to 0.\nNow it’s a hard problem to say exactly how this alternative to updating by conditionalisation should work. But very roughly, the idea is that at least some of the time, we update by eliminating worlds from the space of possibilities. This affects dramatically the probability of propositions whose truth is sensitive to which worlds are in the space of possibiilties.\nFor example, in the game I’ve been discussing, we should believe that rational B might play red. Indeed, the probability of that is, I think, 1. And whether or not B might play red is highly salient; it matters to the probability of whether A will play GREEN or RED. Conditionalising on something that has probability 1, such as that B will play green, can hardly change that probability. But updating on the proposition that B will play green can make a difference. We can see that by simply noting that the conditional If B plays green, she might play red is incoherent.\nSo I conclude that a theory of belief like mine can handle the puzzle this game poses, as long as it distinguishes between conditionalising and updating, in just the way Gillies suggests. To believe that p is to be disposed to not change any attitude towards a salient question on updating that p. (Plus some bells and whistles to deal with propositions that are not relevant to salient questions. We’ll return to them below.) Updating often goes by conditionalisation, so we can often say that belief means having attitudes that match unconditionally and conditionally on p. But not all updating works that way, and the theory of belief needs to acknowledge this.\n\n\n0.2 Holton on Credence\nWhile I don’t agree with the Lockeans, I do endorse a lot of similar theses to them about the relationship between belief and credence. These theses include that both beliefs and credences exist and that the two are constitutively (as opposed to merely causally) connected. I differ from the Lockeans in holding that both belief and credence have important explanatory roles, and that the connection between the two goes via the interests of the agent. As with most work in this area, my views start off from considerations of cases much like DeRose’s famous bank cases.7 Here’s another contribution to the genre. I know it’s an overcrowded field, but I wanted a case that (a) is pretty realistic, and (b) doesn’t involve the attribution (either to oneself or others) of a propositional attitude. In the example, X and Y are parents of a child, Z.\n7 The idea of using allergies to illustrate the kind of case we’re interested in is due to Ross and Schroeder (2014), and I’m grateful for the idea. It makes the intuitions much more vivid. The kind of cases we’re considering play a big role in, inter alia, DeRose (1992; Cohen 1999) and Fantl and McGrath (2002).\nY: This salad you bought is very good. Does it have nuts in it?\nX: No. The nuttiness you’re tasting is probably from the beans.\nY: Oh, so we could pack it for Z’s lunch tomorrow.\nX: Hang on, I better check about the nuts. Z’s pre-school is very fussy about nuts. One of the children there might have an allergy, and it would be awful to get in trouble over her lunch.\n\nHere’s what I think is going on in that exchange.8 At \\(t_2\\) (I’ll use \\(t_i\\) for the time of the \\(i\\)’th utterance in the exchange), X believes that the salad has no nuts in it. Indeed, the one word sentence “No” expresses that belief. But by \\(t_4\\), X has lost that belief. It would be fine to pack the salad for lunch if it has no nuts, but X isn’t willing to do this for the simple reason that X no longer believes that it has no nuts. Moreover, this change of belief was, or at least could have been for all we’ve said so far, rational on X’s part.\n8 What I say here obviously has some similarities to a view put forward by Jennifer Nagel (2008), but I ultimately end up drawing rather different conclusions to the ones she draws.There’s something a little puzzling about that. Jacob Ross and Mark Schroeder (2014) voice a common intuition when they say that beliefs should only change when new evidence comes in. Indeed, they use this intuition as a key argument against my view of belief. But X doesn’t get any evidence that bears on the nuttiness of the salad. Yet X rationally changes beliefs. So I just conclude that sometimes we can change beliefs without new evidence coming in; sometimes our interests, broadly construed, change, and that is enough to change beliefs.\nWe’ll come back to Ross and Schroeder’s arguments in the next section, because first I want to concede something to the view that only evidence changes beliefs. That view is false, but there might be a true view in the area. And that’s the view that only change in evidence can change credences. But that view only makes sense if there are such things as credences, and that’s something that Richard Holton (2014) has recently launched an intriguing argument against.\nHolton’s broader project is a much more sweeping attack on the Lockean thesis than I have proposed. Actually, it is a pair of more sweeping attacks. One of the pair is that the Lockeans identify something that exists, namely belief, with something that doesn’t, namely high credence. I would not, could not, sign up for that critique. But I am much more sympathetic to the other attack in the pair, namely that credences and beliefs have very different dynamics.\nCredences are, by their nature, exceedingly unstable. Whether an agent’s credence that \\(p\\) is above or below any number x is liable to change according to any number of possible changes in evidence. But, at least if the agent is rational, beliefs are not so susceptible to change. Holton thinks that rational agents, or at least rational humans, frequently instantiate the following pattern. They form a belief that \\(p\\), on excellent grounds. They later get some evidence that \\(\\neg p\\). The evidence is strong enough that, had they had it to begin with, they would have remained uncertain about \\(p\\). But they do not decide to reopen the investigation into whether \\(p\\). They hold on to their belief that \\(p\\), the matter having been previously decided.\nSuch an attitude might look like unprincipled dogmatism. But it need not be, I think, as long as four criteria are met. (I think Holton agrees with these criteria.) One is that the agent’s willingness to reopen the question of whether \\(p\\) must increase. She must be more willing, in the light of yet more evidence against \\(p\\), to consider whether \\(p\\) is really true. A second is that, should the agent (irrationally) reopen the question of whether \\(p\\), she should not use the fact that she previously closed that question as evidence. Once the genie is out of the box, only reasoning about \\(p\\) can get it back in. A third is that the costs of the inquiry must be high enough to warrant putting it off. If simply turning one’s head fifteen degrees to the left will lead to acquiring evidence that definitively settles whether \\(p\\), it is a little dogmatic to refuse to do so in the face of evidence against one’s previously formed opinion that \\(p\\). And finally, the costs of being wrong about \\(p\\) must not be too high. X, in our little dialogue above, would be terribly dogmatic if they didn’t reopen the question of whether the salad had nuts in it, on being informed that this information was being used in a high stakes inquiry.\nSo beliefs should have a kind of resilience. Credences, if they exist, should not have this kind of resilience. So this suggests that a simple reduction of belief to credence, as the Lockeans suggest, cannot be right. You might worry that things are worse, that no reduction of belief to credence can be compatible with the difference in resilience between belief and credence. We’ll return to that point, because first I want to look at Holton’s stronger claim: that there are no such things as credences.\nHolton acknowledges, as of course he must, that we have probabilistic truth-directed attitudes. We can imagine a person, call her Paula, who thinks it’s likely that Richard III murdered his nephews, for instance. But Holton offers several reasons for thinking that in these probabilistic truth-directed attitudes, the probability goes in the content, not in the attitude. That is, we should interpret Paula as believing the probabilistic claim, Richard III probably murdered his nephews, and not as having some graded attitude towards the simple proposition Richard III murdered his nephews. More precisely, Holton thinks we should understand Paula’s explicit attitudes that way, and that independent of having reason to think that agents explicitly have probabilistic attitudes, there’s no good way to make sense of the claim that they implicitly have probabilistic attitudes. So there’s no such thing as credences, as usually understood. Or, at least, there’s no good sense to be made of the claim that there are credences.\nIn response, I want to make six points.\n\nHolton is right about cases like Paula’s, and the possibility of iterating terms like probably provides independent support for this view.\nBeliefs like the one Paula has are odd; they seem to have very strange truth conditions.\nOur theory of mind needs some mechanism for explaining the relationship between confidence and action.\nThe ‘explanatory gap’ here could be filled by positing a binary attitude is more confident that.\nThis binary attitude can do all the work that graded attitudes were posited to do, and in a (historically sensitive) way saves the credences story.\nCredences (or at least confidences) can have a key role within a Holton-like story about graded belief. They can both explain why agents reconsider some beliefs, and provide a standard of correctness for decisions to reconsider.\n\nLet’s take those in order.\nI’m not going to rehearse Holton’s argument for the ‘content view’: that in cases like Paula’s the content of her attitude, and not the attitude itself, is probabilistic. But I do want to offer one extra consideration in its favour. (I’m indebted here to work in progress by my colleague Sarah Moss (2015), though I’m not sure she’d approve of this conclusion.) As well as Paula, we can imagine a person Pip who isn’t sure that Paula is right, but thinks she’s probably right. That is, Pip thinks that Richard III probably probably murdered his nephews. It’s easy to make sense of Pip on the content view. Modalities in propositions iterate smoothly; that’s what they are designed to do. But it’s much harder to iterate attitudes. The possibility of cases like Pip suggests Holton must be right about Paula’s case.\nBut Paula’s case is odd. Beliefs have truth conditions. What are the truth conditions for Paula’s belief? On the one hand, it seems they must be sensitive to her evidence. If she later acquires conclusive evidence that Richard III was framed, she won’t think her earlier self had a false belief. But if we put the evidence into the content of the belief, we get the strange result that her belief can’t be preserved by uttering the same words to herself over again. That is, if the content of Paula’s belief is Given the evidence I have now, Richard III likely murdered his nephews, she can’t have the very same belief tomorrow by retaining the thought Richard III likely murdered his nephews. And she can’t have a belief with the same content as anyone else by the two of them both thinking Richard III likely murdered his nephews. Those seem like unhappy conclusions, especially in the midst of a project that wants to emphasise the resiliency of belief. So perhaps we should say, following Stephenson (2007) or MacFarlane (2011), that the truth conditions of the belief are agent-relative. Or, if we’re unhappy with the MacFarlane story, we might be pushed towards a kind of expressivism (perhaps a la Yalcin (2011)), which isn’t quite like either the content view or the attitude view that Holton discusses. I’m personally partial to the relativist view, but I don’t want to argue for that here, just note that the content view raises some interesting problems, and that natural solutions to them could in a way blur the boundaries between the content and attitude views.\nAs Holton notes in his discussion of Brutus, when our confidence in a proposition changes, our actions will change. Paula gets a little evidence that Richard III was framed, and her actions may change. Of course, not much of what we do in everyday life is sensitive to facts about English royal history, but there may be some effects. Maybe she’ll be less inclined to speak up if the topic of the princes’ murder comes up, or she’ll take a slightly more jaundiced view of Shakespeare’s play (compare Friend (2003).) Holton says that these falling confidences need not have all the precise structure of credences. In particular, they may not have the topology of the interval \\([0, 1]\\). But lots of credence lovers think that’s too demanding. There’s a long tradition of thinking that credences need not all be comparable.9 What’s important is that the relative confidences exist, and that they have a robust relationship to action.\n9 Notable members of the tradition include Levi (1974), Jeffrey (1983) and Fraassen (1989).There’s an old fashioned way of doing this. The idea is implicit in Ramsey (1926), and made central in DeFinetti (1964). Take the binary attitude is more confident that p than q as primitive. As Holton notes, surface structure of our attitude reports suggest that this attitude, unlike the graded attitude of credence, is part of folk psychology. Lay down some constraints on this attitude. To get enough constraints that the binary relation determines a unique probability function, the constraints will have to be very tight. In particular, you’ll need some kind of Archimedean principle, and a principle of universal comparability. Those aren’t very plausible, especially the second. But even weaker constraints will get you something interesting. In particular, it isn’t hard to lay down enough constraints that there is a unique set \\(S\\) of probability functions such that the agent is more confident that \\(p\\) than \\(q\\) just in case \\(\\Pr( p) &gt; \\Pr(q)\\) for all \\(\\Pr \\in S\\). (For much more detail, see for instance Walley (1991).)\nIn that way, we can derive credences from the relative confidences of a reasonably coherent agent. But we can do with even less coherence than that I think. A throwaway remark from Ramsey (1929/1990) provides a key clue. What is it to have credence \\(\\frac{2}{3}\\) in \\(p\\)? Don’t say it’s a betting disposition; mental states and behavioural dispositions aren’t that tightly linked. Here’s Ramsey’s idea. To have credence \\(\\frac{2}{3}\\) in \\(p\\) is to be exactly as confident in \\(p\\) as in \\(q \\vee r\\), where \\(q, r\\) and \\(s\\) are taken to be exclusive and exhaustive, and one has equal confidence in all three. It’s easy to see how to extend that to a definition of credence \\(\\frac{m}{n}\\) for any integer \\(m, n\\). It’s a little trickier to say precisely what, say, credence \\(\\frac{1}{\\pi}\\) is, but rational credences are probably credences enough to explain action. And just like that, we have a way of talking about credences, i.e., graded attitudes, without positing anything more than a binary attitude more confident than.\nPerhaps Holton could argue that we only have unary attitudes, not binary attitudes like more confident than. If Maury is more confident that Oswald shot JFK than that Richard III murdered his nephews, that means he really believes the proposition It is more likely that Oswald shot JFK than that Richard III murdered his nephews. But such a view seems forced at best, and isn’t motivated by Holton’s other arguments for the ‘content view’. This attitude of more confident than isn’t iterable. It isn’t subject to the particular kind of reasoning errors that Holton takes to be evidence for the content view in the probabilistic case. It is an attitude we ordinarily report as a binary attitude in normal speech. In short, it looks like a genuine binary attitude.\nGiven that the binary attitude exists, and that we can define numerical (at least rational) credences in terms of it, I’d say that’s enough to say that credences exist. In a sense, credences will be epiphenomenal. What does the explanatory work is the binary relation more confident that. Maury might stay away from a showing of Richard III because he is less confident that it is historically accurate than he used to be. We can work out from Maury’s other relative confidences what his credence in Richard III’s guilt is and was. Or, at least, we can work out bounds on these. But those numbers aren’t in a fundamental sense explanatory, and neither are the complicated sets of relative confidences that constitute the numbers. What’s really explanatory are relative confidences. But it’s a harmless enough mode of speech to talk as if credences are explanatory; they are easier to talk about than the underlying relative confidences.\n\n\n0.3 The Power of Theoretical Interests\nSo I think we should accept that credences exist. And we can just about reduce beliefs to credences. In previous work I argued that we could do such a reduction. I’m not altogether sure whether the amendments to that view I’m proposing here means it no longer should count as a reductive view; we’ll come back to that question in the conclusion.\nThe view I defended in previous work is that the reduction comes through the relationship between conditional and unconditional attitudes. Very roughly, to believe that p is simply to have the same attitudes, towards all salient questions, unconditionally as you have conditional on p. In a syrupy slogan, belief means never having to say you’ve conditionalised. For reasons I mentioned in section 1, I now think that was inaccurate; I should have said that belief means never having to say you’ve updated, or at least that you’ve updated your view on any salient question.\nThe restriction to salient questions is important. Consider any p that I normally take for granted, but such that I wouldn’t bet on it at insane odds. I prefer declining such a bet to taking it. But conditional on p, I prefer taking the bet. So that means I don’t believe any such p. But just about any p satisfies that description, for at least some ‘insane’ odds. So I believe almost nothing. That would be a reductio of the position. I respond by saying that the choice of whether to take an insane bet is not normally salient.\nBut now there’s a worry that I’ve let in too much. For many p, there is no salient decision that they even bear on. What I would do conditional on p, conditional on \\(\\neg p\\), and unconditionally is exactly the same, over the space of salient choices. (And this isn’t a case where updating and conditionalising come apart; I’ll leave this proviso mostly implicit from now on.) So with the restriction in place, I believe p and \\(\\neg p\\). That seems like a reductio of the view too. I probably do have inconsistent beliefs, but not in virtue of p being irrelevant to me right now. I’ve changed my mind a little about what the right way to avoid this problem is, in part because of some arguments by Jacob Ross and Mark Schroeder.\nThey have what looks like, on the surface, a rather different view to mine. They say that to believe p is to have a default reasoning disposition to use p in reasoning. Here’s how they describe their own view.\n\nWhat we should expect, therefore, is that for some propositions we would have a defeasible or default disposition to treat them as true in our reasoning–a disposition that can be overridden under circumstances where the cost of mistakenly acting as if these propositions are true is particularly salient. And this expectation is confirmed by our experience. We do indeed seem to treat some uncertain propositions as true in our reasoning; we do indeed seem to treat them as true automatically, without first weighing the costs and benefits of so treating them; and yet in contexts such as High where the costs of mistakenly treating them as true is salient, our natural tendency to treat these propositions as true often seems to be overridden, and instead we treat them as merely probable.\nBut if we concede that we have such defeasible dispositions to treat particular propositions as true in our reasoning, then a hypothesis naturally arises, namely, that beliefs consist in or involve such dispositions. More precisely, at least part of the functional role of belief is that believing that p defeasibly disposes the believer to treat p as true in her reasoning. Let us call this hypothesis the reasoning disposition account of belief. (Ross and Schroeder 2014, 9–10)\n\nThere are, relative to what I’m interested in, three striking characteristics of Ross and Schroeder’s view.\n\nWhether you believe p is sensitive to how you reason; that is, your theoretical interests matter.\nHow you would reason about some questions that are not live is relevant to whether you believe p.\nDispositions can be masked, so you can believe p even though you don’t actually use p in reasoning now.\n\nI think they take all three of these points to be reasons to favour their view over mine. As I see it, we agree on point 1 (and I always had the resources to agree with them), I can accommodate point 2 with a modification to my theory, and point 3 is a cost of their theory, not a benefit. Let’s take those points in order.\nThere are lots of reasons to dislike what Ross and Schroeder call Pragmatic Credal Reductionism (PCR). This is, more or less, the view that the salient questions, in the sense relevant above, are just those which are practically relevant to the agent. So to believe \\(p\\) just is to have the same attitude towards all practically relevant questions unconditionally as conditional on \\(p\\). There are at least three reasons to resist this view.\nOne reason comes from the discussions of Ned Block’s example Blockhead  (Block 1978). As Braddon-Mitchell and Jackson point out, the lesson to take from that example is that beliefs are constituted in part by their relations to other mental states  (Braddon-Mitchell and Jackson 2007, 114ff). There’s a quick attempted refutation of PCR via the Blockhead case which doesn’t quite work. We might worry that if all that matters to belief given PCR is how it relates to action, PCR will have the implausible consequence that Blockhead has a rich set of beliefs. That isn’t right; PCR is compatible with the view that Blockhead doesn’t have credences, and hence doesn’t have credences that constitute beliefs. But the Blockhead example’s value isn’t exhausted by its use in quick refutations.10 The lesson is that beliefs are, by their nature, interactive. It seems to me that PCR doesn’t really appreciate that lesson.\n10 The point I’m making here is relevant I think to recent debates about the proper way to formalise counterexamples in philosophy, as in  (Williamson 2007b; Ichikawa and Jarvis 2009; Malmgren 2011). I worry that too much of that debate is focussed on the role that examples play in one-step refutations. But there’s more, much more, to a good example than that.Another reason comes from recent work by Jessica Brown (2014). Compare these two situations.\n\nS is in circumstances C, and has to decide whether to do X.\nS is in completely different circumstances to C, but is seriously engaged in planning for future contingencies. She’s currently trying to decide whether in circumstances C to do X.\n\nIntuitively, S can bring exactly the same evidence, knowledge and beliefs to bear on the two problems. If C is a particularly high stakes situation, say it is a situation where one has to decide what to feed someone with a severe peanut allergy, then a lot of things that can ordinarily be taken for granted cannot, in this case, be taken for granted. And that’s true whether S is actually in C, or she is just planning for the possibility that she finds herself in C.\nSo I conclude that both practical and theoretical interests matter for what we can take for granted in inquiry. The things we can take for granted into a theoretical inquiry into what to do in high stakes contexts as restricted, just as they are when we are in a high stakes context, and must make a practical decision. Since the latter restriction on what we can take for granted is explained by (and possibly constituted by) a restriction on what we actually believe in those contexts, we should similarly conclude that agents simply believe less when they are reasoning about high stakes contexts, whatever their actual context.\nA third reason to dislike PCR comes from the ‘Renzi’ example in Ross and Schroeder’s paper. I’ll run through a somewhat more abstract version of the case, because I don’t think the details are particularly important. Start with a standard decision problem. The agent knows that X is better to do if p, and Y is better to do if \\(\\neg p\\). The agent should then go through calculating the relative gains to doing X or Y in the situations they are better, and the probability of p. But the agent imagined doesn’t do that. Rather, the agent divides the possibility space in four, taking the salient possibilities to be \\(p \\wedge q, p \\wedge \\neg q, \\neg p \\wedge q\\) and \\(\\neg p \\wedge \\neg q\\), and then calculates the expected utility of X and Y accordingly. This is a bad bit of reasoning on the agent’s part. In the cases we are interested in, q is exceedingly likely. Moreover, the expected utility of each act doesn’t change a lot depending on q’s truth value. So it is fairly obvious that we’ll end up making the same decision whether we take the ‘small worlds’ in our decision model to be just the world where p, and the world where \\(\\neg p\\), or the four worlds this agent uses. But the agent does use these four, and the question is what to say about them.\nRoss and Schroeder say that such an agent should not be counted as believing that q. If they are consciously calculating the probability that q, and taking \\(\\neg q\\) possibilities into account when calculating expected utilities, they regard q as an open question. And regarding q as open in this way is incompatible with believing it. I agree with all this.\nThey also think that PCR implies that the agent does believe q. The reason is that conditionalising on q doesn’t change the agent’s beliefs about any practical question. I think that’s right too, at least on a natural understanding of what ‘practical’ is.\nMy response to all these worries is to say that whether someone believes that p depends not just on how conditionalising (or more generally updating) on p would affect someone’s action, but on how it would affect their reasoning. That is, just as we learned from the Blockhead example, to believe that p requires having a mental state that is connected to the rest of one’s cognitive life in roughly the way a belief that p should be connected. Let’s go through both the last two cases to see how this works on my theory.\nOne of the things that happens when the stakes go up is that conditionalising on very probable things can change the outcome of interesting decisions. Make the probability that some nice food is peanut-free be high, but short of one. Conditional on it being peanut-free, it’s a good thing to give to a peanut-allergic guest. But unconditionally, it’s a bad thing to give to such a guest, because the niceness of the food doesn’t outweigh the risk of killing them. And that’s true whether the guest is actually there, or you’re just thinking about what to do should such a guest arrive in the future. In general, the same questions will be relevant whether you’re in C trying to decide whether to do X, or simply trying to decide whether to X in C. In one case they will be practically relevant questions, in the other they will be theoretically relevant questions. But this feels a lot like a distinction without a difference, since the agent should have similar beliefs in the two cases.\nThe same response works for Ross and Schroeder’s case. The agent was trying to work out the expected utility of X and Y by working out the utility of each action in each of four ‘small worlds’, then working out the probability of each of these. Conditional on q, the probability of two of them (\\(p \\wedge \\neg q, \\neg p \\wedge \\neg q\\)), will be 0. Unconditionally, this probability won’t be 0. So the agent has a different view on some question they have taken an interest in unconditionally to their view conditional on q. So they don’t believe q. The agent shouldn’t care about that question, and conditional on each question they should care about, they have the same attitude unconditionally and conditional on q. But they do care about these probabilistic questions, so they don’t believe q.\nSo I think that Ross and Schroeder and I agree on point 1; something beyond practical interests is relevant to belief.\nThey have another case that I think does suggest a needed revision to my theory. I’m going to modify their case a little to change the focus a little, and to avoid puzzles about vagueness. (What follows is a version of their example about Dalı́’s moustache, purged of any worries about vagueness, and without the focus on consistency. I don’t think the problem they true to press on me, that my theory allows excessive inconsistency of belief among rational agents, really sticks. Everyone will have to make qualifications to consistency to deal with the preface paradox, and for reasons I went over in  (Weatherson 2005), I think the qualifications I make are the best ones to make.)\nLet D be the proposition that the number of games the Detroit Tigers won in 1976 (in the MLB regular season) is not a multiple of 3. At most times, D is completely irrelevant to anything I care about, either practically or theoretically. My attitudes towards any relevant question are the same unconditionally as conditional on D. So there’s a worry that I’ll count as believing D, and believing \\(\\neg D\\), by default.\nIn earlier work, I added a clause meant to help with cases like this. I said that for determining whether an agent believes that p, we should treat the question of whether p’s probability is above or below 0.5 as salient, even if the agent doesn’t care about it. Obviously this won’t help with this particular case. The probability of D is around , and is certainly above 0.5. My ‘fix’ avoids the consequence that I implausibly count as believing \\(\\neg D\\). But I still count, almost as implausibly, as believing D. This needs to be fixed.\nHere’s my proposed change. For an agent to count as believing p, it must be possible for p to do some work for them in reasoning. Here’s what I mean by work. Consider a very abstract set up of a decision problem, as follows.\n\n\n\n\n\np\nq\n\n\nX\n4\n1\n\n\nY\n3\n2\n\n\n\n\nThat table encodes a lot of information. It encodes that \\(p \\vee q\\) is true; otherwise there are some columns missing. It encodes that the only live choices are X or Y; otherwise there are rows missing. It encodes that doing X is better than doing Y if p, and worse if q.\nFor any agent, and any decision problem, there is a table like this that they would be disposed to use to resolve that problem. Or, perhaps, there are a series of tables and there is no fact about which of them they would be most disposed to use.\nGiven all that terminology, here’s my extra constraint on belief. To believe that p, there must be some decision problem such that some table the agent would be disposed to use to solve it encodes that p. If there is no such problem, the agent does not believe that p. For anything that I intuitively believe, this is an easy condition to satisfy. Let the problem be whether to take a bet that pays 1 if p, and loses 1 otherwise. Here’s the table I’d be disposed to use to solve the problem.\n\n\n\n\n\np\n\n\nTake bet\n1\n\n\nDecline bet\n0\n\n\n\n\nThis table encodes that p, so it is sufficient to count as believing that p. And it doesn’t matter that this bet isn’t on the table. I’m disposed to use this table, so that’s all that matters.\nBut might there be problems in the other direction. What about an agent who, if offered such a bet on D, would use such a simple table? I simply say that they believe that D. I would not use any such table. I’d use this table.\n\n\n\n\n\nD\n\\(\\neg D\\)\n\n\nTake bet\n1\n–1\n\n\nDecline bet\n0\n0\n\n\n\n\nNow given the probability of D, I’d still end up taking the bet; it has an expected return of . (Well, actually I’d probably decline the bet because being offered the bet would change the probability of D for reasons made clear in  Runyon (1992, 14–15). But that hardly undermines the point I’m making.) But this isn’t some analytic fact about me, or even I think some respect in which I’m obeying the dictates of rationality. It’s simply a fact that I wouldn’t take D for granted in any inquiry. And that’s what my non-belief that D consists in.\nThis way of responding to the Tigers example helps respond to a nice observation that Ross and Schroeder make about correctness. A belief that p is, in some sense, incorrect if \\(\\neg p\\). It isn’t altogether clear how to capture this sense given a simple reduction of beliefs to credences. I propose to capture it using this idea that decision tables encode propositions. A table is incorrect if it encodes something that’s false. To believe something is, inter alia, to be disposed to use a table that encodes it. So if it is false, it involves a disposition to do something incorrect.\nIt also helps capture Holton’s observation that beliefs should be resilient. If someone is disposed to use decision tables that encode that p, that disposition should be fairly resilient. And to the extent that it is resilient, they will satisfy all the other clauses in my preferred account of belief. So anyone who believes p should have a resilient belief that p.\nThe last point is where I think my biggest disagreement with Ross and Schroeder lies. They think it is very important that a theory of belief vindicate a principle they call Stability.\n\nStability: A fully rational agent does not change her beliefs purely in virtue of an evidentially irrelevant change in her credences or preferences. (20)\n\nHere’s the kind of case that is meant to motivate Stability, and show that views like mine are in tension with it.\n\nSuppose Stella is extremely confident that steel is stronger than Styrofoam, but she’s not so confident that she’d bet her life on this proposition for the prospect of winning a penny. PCR implies, implausibly, that if Stella were offered such a bet, she’d cease to believe that steel is stronger than Styrofoam, since her credence would cease to rationalize acting as if this proposition is true. (22)\n\nRoss and Schroeder’s own view is that if Stella has a defeasible disposition to treat as true the proposition that steel is stronger than Styrofoam, that’s enough for her to believe it. And that can be true if the disposition is not only defeasible, but actually defeated in the circumstances Stella is in. This all strikes me as just as implausible as the failure of Stability. Let’s go over its costs.\nThe following propositions are clearly not mutually consistent, so one of them must be given up. We’re assuming that Stella is facing, and knows she is facing, a bet that pays a penny if steel is stronger than Styrofoam, and costs her life if steel is not stronger than Styrofoam.\n\nStella believes that steel is stronger than Styrofoam.\nStella believes that if steel is stronger than Styrofoam, she’ll win a penny and lose nothing by taking the bet.\nIf 1 and 2 are true, and Stella considers the question of whether she’ll win a penny and lose nothing by taking the bet, she’ll believe that she’ll win a penny and lose nothing by taking the bet.\nStella prefers winning a penny and losing nothing to getting nothing.\nIf Stella believes that she’ll win a penny and lose nothing by taking the bet, and prefers winning a penny and losing nothing to getting nothing, she’ll take the bet.\nStella won’t take the bet.\n\nIt’s part of the setup of the problem that 2 and 4 are true. And it’s common ground that 6 is true, at least assuming that Stella is rational. So we’re left with 1, 3 and 5 as the possible candidates for falsehood.\nRoss and Schroeder say that it’s implausible to reject 1. After all, Stella believed it a few minutes ago, and hasn’t received any evidence to the contrary. And I guess rejecting 1 isn’t the most intuitive philosophical conclusion I’ve ever drawn. But compare the alternatives!\nIf we reject 3, we must say that Stella will simply refuse to infer r from p, q and \\((p \\wedge q) \\rightarrow r\\). Now it is notoriously hard to come up with a general principle for closure of beliefs. But it is hard to see why this particular instance would fail. And in any case, it’s hard to see why Stella wouldn’t have a general, defeasible, disposition to conclude r in this case, so by Ross and Schroeder’s own lights, it seems 3 should be acceptable.\nThat leaves 5. It seems on Ross and Schroeder’s view, Stella simply must violate a very basic principle of means-end reasoning. She desires something, she believes that taking the bet will get that thing, and come with no added costs. Yet, she refuses to take the bet. And she’s rational to do so! At this stage, I think I’ve lost what’s meant to be belief-like about their notion of belief. I certainly think attributing this kind of practical incoherence to Stella is much less plausible than attributing a failure of Stability to her.\nPut another way, I don’t think presenting Stability on its own as a desideratum of a theory is exactly playing fair. The salient question isn’t whether we should accept or reject Stability. The salient question is whether giving up Stability is a fair price to pay for saving basic tenets of means-end rationality. And I think that it is. Perhaps there will be some way of understanding cases like Stella’s so that we don’t have to choose between theories of belief that violate Stability constraints, and theories of belief that violate coherence constraints. But I don’t see one on offer, and I’m not sure what such a theory could look like.\nI have one more argument against Stability, but it does rest on somewhat contentious premises. There’s often a difference between the best methodology in an area, and the correct epistemology of that area. When that happens, it’s possible that there is a good methodological rule saying that if such-and-such happens, re-open a certain inquiry. But that rule need not be epistemologically significant. That is, it need not be the case that the happening of such-and-such provides evidence against the conclusion of the inquiry. It just provides a reason that a good researcher will re-open the inquiry. And, as we’ve stated above, an open inquiry is incompatible with belief.\nHere’s one way that might happen. Like other non-conciliationists about disagreement, e.g.,  Kelly (2010), I hold that disagreement by peers with the same evidence as you doesn’t provide evidence that you are wrong. But it might provide an excellent reason to re-open an inquiry. We shouldn’t draw conclusions about the methodological significance of disagreement from the epistemology of disagreement. So learning that your peers all disagree with a conclusion might be a reason to re-open inquiry into that conclusion, and hence lose belief in the conclusion, without providing evidence that the conclusion is false. This example rests on a very contentious claim about the epistemology of disagreement. But any gap that opens up between methodology and epistemology will allow such an example to be constructed, and hence provide an independent reason to reject Stability.\n\n\n0.4 Conclusion\nYou might well worry that the view here is too complex to really be a theory of belief. Belief is a simple state; why all the epicycles? This is a good question, and I’m not sure I have a sufficiently good answer to it.\nAt heart, the theory I’ve offered here is simple. To believe p is to take p for granted, to take it as given, to take it as a settled question. But one doesn’t take a question as settled in a vacuum. I will take some questions as settled in some circumstances and not others. It’s here that the complexities enter in.\nTo believe p, it isn’t necessary that we take it as settled in all contexts. That would mean that anything one believes one would bet on at any odds. But it isn’t sufficient to take it as settled in some context or other. If I’m facing a tricky bet on p, the fact that I’d take p as settled in some other context doesn’t mean that I believe p. After all, I might even decline the bet, although I desire the reward for winning the bet, and believe that if p I will win. And we can’t just focus on the actual circumstances. Five minutes ago, I neither took it as settled or as open that the Cubs haven’t won the World Series for quite a while. I simply wasn’t thinking about that proposition, and didn’t really take it to be one thing or another.\nThis is why things get so complex. To believe p is to hold a fairly simple attitude towards p in some relevant circumstances. But which circumstances? That’s what’s hard to say, and it’s why the theory is so messy. And I think we have an argument that it must be a little hard to say, namely an argument by exhaustion of all the possible simple things to say. The previous paragraph starts such an argument.\nI’d be a little surprised if the account here is the best or last word on the matter though. It does feel a little disjunctive, as if there is a simpler reduction to be had. But I think it’s better than what came before, so I’m putting it forward.\nThe previous version of the theory I put forward was clearly reductive; beliefs were reduced to credences and preferences. This version is not quite as clearly reductive. Which decision tables the agent is disposed to use, and which propositions those tables encode, are not obviously facts about credences and preferences. So it feels like I’ve given up on the reductive project.\nI’m not altogether happy about this; reduction is a good aim to have. But if reduction of belief to other states fails, I’d think this kind of reason is why it is going to fail. Facts about how an agent conceptualises a problem, how she sets up the decision table, are distinct from facts about which values she writes into the table. This is the deepest reason why the Lockean theory is false. Belief is not the difference between one column in the decision table getting probability 0.98 rather than 0.97; it is the difference between one column being excluded rather than included. If that difference can’t be accounted for in terms of actual credences and preferences, the reductionist project will fail.\n\n\n\n\n\n\nReferences\n\nAumann, Robert J. 1999. “Interactive Epistemology i: Knowledge.” International Journal of Game Theory 28 (3): 263–300. https://doi.org/10.1007/s001820050111.\n\n\nBinmore, Ken. 2007. Playing for Real: A Text on Game Theory. Oxford: Oxford University Press.\n\n\nBlock, Ned. 1978. “Troubles with Functionalism.” Minnesota Studies in the Philosophy of Science 9: 261–325.\n\n\nBraddon-Mitchell, David, and Frank Jackson. 2007. The Philosophy of Mind and Cognition, Second Edition. Malden, MA: Blackwell.\n\n\nBrown, Jessica. 2014. “Impurism, Practical Reasoning and the Threshold Problem.” Noûs 48 (1): 179–92. https://doi.org/10.1111/nous.12008.\n\n\nChristensen, David. 2005. Putting Logic in Its Place. Oxford: Oxford University Press.\n\n\nCohen, Stewart. 1999. “Contextualism, Skepticism, and the Structure of Reasons.” Philosophical Perspectives 13: 57–89. https://doi.org/10.1111/0029-4624.33.s13.3.\n\n\nDeFinetti, Bruno. 1964. “Foresight: Its Logical Laws, Its Subjective Sources.” In Studies in Subjective Probability, edited by Henry E. Kyburg and Howard E. Smokler, 93–156. New York: Wiley.\n\n\nDeRose, Keith. 1992. “Contextualism and Knowledge Attributions.” Philosophy and Phenomenological Research 52 (4): 913–29. https://doi.org/10.2307/2107917.\n\n\nDixit, Avinash K., and Susan Skeath. 2004. Games of Strategy. Second. New York: W. W. Norton & Company.\n\n\nFantl, Jeremy, and Matthew McGrath. 2002. “Evidence, Pragmatics, and Justification.” Philosophical Review 111: 67–94. https://doi.org/10.2307/3182570.\n\n\nFraassen, Bas van. 1989. Laws and Symmetry. Oxford: Clarendon Press.\n\n\nFriend, Stacie. 2003. “How i Really Feel about JFK.” In Imagination, Philosophy and the Arts, edited by Matthew Kieran and Dominic McIver Lopes, 35–53. London. Routledge.\n\n\nGillies, Anthony S. 2010. “Iffiness.” Semantics and Pragmatics 3 (4): 1–42. https://doi.org/10.3765/sp.3.4.\n\n\nHeal, Jane. 1994. “Moore’s Paradox: A Wittgensteinian Approach.” Mind 103 (409): 5–24. https://doi.org/10.1093/mind/103.409.5.\n\n\nHolton, Richard. 2014. “Intention as a Model for Belief.” In Rational and Social Agency: Essays on the Philosophy of Michael Bratman, edited by Manuel Vargas and Gideon Yaffe, 12–37. Oxford: Oxford University Press.\n\n\nIchikawa, Jonathan, and Benjamin Jarvis. 2009. “Thought-Experiment Intuitions and Truth in Fiction.” Philosophical Studies 142 (2): 221–46. https://doi.org/10.1007/s11098-007-9184-y.\n\n\nJeffrey, Richard. 1983. “Bayesianism with a Human Face.” In Testing Scientific Theories, edited by J. Earman (ed.). Minneapolis: University of Minnesota Press.\n\n\nKelly, Thomas. 2010. “Peer Disagreement and Higher Order Evidence.” In Disagreement, edited by Ted Warfield and Richard Feldman, 111–74. Oxford: Oxford University Press.\n\n\nKohlberg, Elon, and Jean-Francois Mertens. 1986. “On the Strategic Stability of Equilibria.” Econometrica 54 (5): 1003–37. https://doi.org/10.2307/1912320.\n\n\nKratzer, Angelika. 2012. Modals and Conditionals. Oxford: Oxford University Press.\n\n\nLevi, Isaac. 1974. “On Indeterminate Probabilities.” Journal of Philosophy 71 (13): 391–418. https://doi.org/10.2307/2025161.\n\n\nMacFarlane, John. 2011. “Epistemic Modals Are Assessment-Sensitive.” In Epistemic Modality, edited by Andy Egan and Brian Weatherson, 144–78. Oxford: Oxford University Press.\n\n\nMaitra, Ishani, and Brian Weatherson. 2010. “Assertion, Knowledge and Action.” Philosophical Studies 149 (1): 99–118. https://doi.org/10.1007/s11098-010-9542-z.\n\n\nMalmgren, Anna-Sara. 2011. “Rationalism and the Content of Intuitive Judgements.” Mind 120 (478): 263–327. https://doi.org/10.1093/mind/fzr039.\n\n\nMoss, Sarah. 2015. “On the Semantics and Pragmatics of Epistemic Vocabulary.” Semantics and Pragmatics 8: 1–81. https://doi.org/10.3765/sp.8.5.\n\n\nNagel, Jennifer. 2008. “Knowledge Ascriptions and the Psychological Consequences of Changing Stakes.” Australasian Journal of Philosophy 86 (2): 279–94. https://doi.org/10.1080/00048400801886397.\n\n\n———. 2013. “Motivating Williamson’s Model Gettier Cases.” Inquiry 56 (1): 54–62. https://doi.org/10.1080/0020174X.2013.775014.\n\n\nNorth, Jill. 2010. “An Empirical Approach to Symmetry and Probability.” Studies In History and Philosophy of Science Part B: Studies In History and Philosophy of Modern Physics 41 (1): 27–40. https://doi.org/10.1016/j.shpsb.2009.08.008.\n\n\nRamsey, Frank. 1929/1990. “Probability and Partial Belief.” In Philosophical Papers, edited by D. H. Mellor, 95–96. Cambridge University Press.\n\n\n———. 1926. “Truth and Probability.” In Philosophical Papers, edited by D. H. Mellor, 52–94. Cambridge: Cambridge University Press.\n\n\nRoss, Jacob, and Mark Schroeder. 2014. “Belief, Credence, and Pragmatic Encroachment.” Philosophy and Phenomenological Research 88 (2): 259–88. https://doi.org/10.1111/j.1933-1592.2011.00552.x.\n\n\nRunyon, Damon. 1992. Guys & Dolls: The Stories of Damon Runyon. New York: Penguin.\n\n\nSchoenfield, Miriam. 2013. “Permission to Believe: Why Permissivism Is True and What It Tells Us about Irrelevant Influences on Belief.” Noûs 47 (1): 193–218. https://doi.org/10.1111/nous.12006.\n\n\nSorensen, Roy A. 1988. Blindspots. Oxford: Clarendon Press.\n\n\nStalnaker, Robert. 1994. “On the Evaluation of Solution Concepts.” Theory and Decision 37 (1): 49–73. https://doi.org/10.1007/BF01079205.\n\n\n———. 1996. “Knowledge, Belief and Counterfactual Reasoning in Games.” Economics and Philosophy 12: 133–63. https://doi.org/10.1017/S0266267100004132.\n\n\n———. 1998. “Belief Revision in Games: Forward and Backward Induction.” Mathematical Social Sciences 36 (1): 31–56. https://doi.org/10.1016/S0165-4896(98)00007-9.\n\n\n———. 1999. “Extensive and Strategic Forms: Games and Models for Games.” Research in Economics 53 (3): 293–319. https://doi.org/10.1006/reec.1999.0200.\n\n\nStephenson, Tamina. 2007. “Judge Dependence, Epistemic Modals, and Predicates of Personal Taste.” Linguistics and Philosophy 30 (4): 487–525. https://doi.org/10.1007/s10988-008-9023-4.\n\n\nWalley, Peter. 1991. Statisical Reasoning with Imprecise Probabilities. London: Chapman & Hall.\n\n\nWeatherson, Brian. 2005. “Can We Do Without Pragmatic Encroachment?” Philosophical Perspectives 19 (1): 417–43. https://doi.org/10.1111/j.1520-8583.2005.00068.x.\n\n\n———. 2011. “Defending Interest-Relative Invariantism.” Logos & Episteme 2 (4): 591–609. https://doi.org/10.5840/logos-episteme2011248.\n\n\n———. 2012a. “Games and the Reason-Knowledge Principle.” The Reasoner 6 (1): 6–8.\n\n\n———. 2012b. “Knowledge, Bets and Interests.” In Knowledge Ascriptions, edited by Jessica Brown and Mikkel Gerken, 75–103. Oxford: Oxford University Press.\n\n\nWeintraub, Ruth. 2008. “How Probable Is an Infinite Sequence of Heads? A Reply to Williamson.” Analysis 68 (3): 247–50. https://doi.org/10.1093/analys/68.3.247.\n\n\nWhite, Roger. 2005. “Epistemic Permissiveness.” Philosophical Perspectives 19: 445–59. https://doi.org/10.1111/j.1520-8583.2005.00069.x.\n\n\nWilliamson, Timothy. 1996. “Knowing and Asserting.” Philosophical Review 105 (4): 489–523. https://doi.org/10.2307/2998423.\n\n\n———. 2007a. “How Probable Is an Infinite Sequence of Heads?” Analysis 67 (295): 173–80. https://doi.org/10.1111/j.1467-8284.2007.00671.x.\n\n\n———. 2007b. The Philosophy of Philosophy. Blackwell.\n\n\n———. 2013. “Gettier Cases in Epistemic Logic.” Inquiry 56 (1): 1–14. https://doi.org/10.1080/0020174X.2013.775010.\n\n\nYalcin, Seth. 2011. “Nonfactualism about Epistemic Modality.” In Epistemic Modality, edited by Andy Egan and Brian Weatherson, 295–332. Oxford: Oxford University Press."
  },
  {
    "objectID": "posts/misindex/misleading-indexicals.html",
    "href": "posts/misindex/misleading-indexicals.html",
    "title": "Misleading Indexicals",
    "section": "",
    "text": "In ‘Now the French are invading England’ Komarine Romdenh-Romluc (2002) offers a new theory of the relationship between recorded indexicals and their content. Romdenh-Romluc’s proposes that Kaplan’s basic idea, that reference is determined by applying a rule to a context, is correct, but we have to be careful about what the context is, since it is not always the context of utterance. A few well known examples illustrate this. The ‘here’ and ‘now’ in ‘I am not here now’ on an answering machine do not refer to the time and place of the original utterance, but to the time the message is played back, and the place its attached telephone is located. Any occurrence of ‘today’ in a newspaper or magazine refers not to the day the story in which it appears was written, nor to the day the newspaper or magazine was printed, but to the cover date of that publication.\n\nPublished in Analysis, 62: 308-310.\nPicture by Bernard Spragg via Creative Common.\n\nStill, it is plausible that for each (token of an) indexical there is a salient context, and that ‘today’ refers to the day of its context, ‘here’ to the place of its context, and soon. Romdenh-Romluc takes this to be true, and then makes a proposal about what the salient context is. It is ‘the context that Ac would identify on the basis of cues that she would reasonably take U to be exploiting’. (2002, 39) Ac is the relevant audience, ‘the individual who it is reasonable to take the speaker to be addressing’, and who is assumed to be linguistically competent and attentive. (So Ac might not be the person U intends to address. This will not matter for what follows.) The proposal seems to suggest that it is impossible to trick a reasonably attentive hearer about what the referent of a particular indexical is. Since such trickery does seem possible, Romdenh-Romluc’s theory needs (at least) supplementation. Here are two examples of such tricks.\n\nThanks to Europa Malynicz, Adam Sennet and Ted Sider for helpful comments.\n\n\nExample One\nImagine that at my university, the email servers are down, so all communication from the office staff is by written notes left in our mailboxes. I notice that one of my colleagues, Bruce, has a rather full mailbox, and hence must not have been checking his messages for the last day or two. I also know that Bruce is a forgetful type, and if someone told him that he’d forgotten about a faculty meeting yesterday, he’d probably believe them. In fact he hasn’t forgotten; the meeting is for later today. So I decide to play a little trick on him. I write an official looking note saying ‘There is a faculty meeting today’, leave it undated, and put it in Bruce’s mailbox underneath several other messages, so it looks like it has been there for a day or two. When Bruce sees it he is appropriately tricked, and for an instant panics about the meeting that he has missed.\n\nIt seems to me that what I wrote on the note was true. It was horribly misleading, to be sure, but still true. And as a few people have pointed out over the years, most prominently Bill Clinton I guess, it is possible to mislead people with the truth. But on Romdemh-Romluc’s proposal, what I said was false, since my audience (Bruce) reasonably took the context to be a day earlier in the week.\n\nExample Two\nThis example is closely based on a recent TV commercial. Jack leaves the following message on Jill’s answering machine late one Saturday night. ‘Hi Jill, it’s Jack. I’m at Rick’s. This place is wild. There’s lots of cute girls here, but I’m just thinking about you.’ In the background loud music is playing, as if Jack were at a nightclub, indeed as if Jack were at Rick’s, so Jill reasonably concludes that Jack was at Rick’s when he sent the message, and hence that ‘here’ refers to Rick’s. In fact Jack was home alone, but wanted to hide this fact, so he turned the stereo up to full volume while leaving the message. Despite the fact that a reasonable and attentive member of the target audience inferred on the basis of contextual clues left by Jack that the context was Rick’s, it was not. The context was Jack’s house, and ‘here’ in Jack’s message referred to his house. Jack’s trick may be less morally reprehensible than mine, but at least I managed to avoid lying, something Jack failed to do.\n\nIn Example One I said something true even though what the hearer took me to say was false. In Example Two Jack says something false, though what the hearer takes him to say may well be true, assuming that there are a lot of cute girls at Rick’s. Romdenh-Romluc’s theory predicts that neither of these things is possible, so it does not work as it stands. This, of course, is not to say that anyone else (myself included) has a better theory readily available, so it is unclear whether the right lesson to draw from these examples is that Romdenh-Romluc’s theory needs to have some epicycles added, or that we need to try a rather different approach. One simple epicycle makes the theory extensionally adequate, but philosophically uninteresting. Consider modifying the theory to require Ac to be not just reasonable and attentive, but informed of U’s circumstances. Then the context identified by Ac will be the salient context for determining the referent of U’s indexicals. But saying this is not to offer a theory of content for recorded indexicals, it is merely to say that ideally placed observers have access to all the relevant semantic facts. Even this might be wrong if epistemicism about vagueness is correct, but if that is true then Romdenh-Romluc’s theory is probably radically mistaken, for then there are facts about content that cannot be reasonably believed, even by an attentive and informed observer. We still seem to be a fair distance from having an acceptable theory.\n\n\n\n\nReferences\n\nRomdenh-Romluc, Komarine. 2002. “Now the French Are Invading England.” Analysis 62 (1): 34–41. https://doi.org/10.1093/analys/62.1.34."
  },
  {
    "objectID": "posts/aka/assertion-knowledge-and-action.html",
    "href": "posts/aka/assertion-knowledge-and-action.html",
    "title": "Assertion, Knowledge and Action",
    "section": "",
    "text": "It is widely believed that the mere truth of p is insufficient for p to be properly assertable, even if p is relevant to current conversation. If a speaker simply guessed that p is true, then she shouldn’t say p, for example. There is some dissent from this view (e.g., Weiner (2005)), but it is something close to orthodoxy in the current literature on assertion that something further is needed. The most common ‘something else’ is knowledge: a speaker shouldn’t say p unless they know p. This view is nowadays commonly associated with Timothy Williamson (1996, 2000), but it has historical antecedents tracing back at least to Max Black’s (1952) paper “Saying and Disbelieving”.1 Call Williamson’s position The Knowledge Rule.\nThis paper aims to raise trouble for The Knowledge Rule, and several related positions, by focussing on a particular kind of assertion. We’ll be looking at assertions about what is to be done. The boldest statement of our position is that if an agent should do X, then that agent is in a position to say that they should do X. (We’ll qualify this a little below, but it’s helpful to start with the bold position.) We argue, following Williamson’s ‘anti-luminosity’ arguments, that its being true that X is the thing to do for an agent doesn’t entail that that agent knows it’s the thing to do.2 If both these claims are true, then there will be cases where it is fine to assert that X is what to do, even though the agent doesn’t know this. So, The Knowledge Rule is mistaken. Slightly more formally, we’ll be interested in arguments of this structure.\nIn section 1, we’ll motivate premise 1 with a couple of vignettes. In section 2, we’ll qualify that premise and make it more plausible. In section 3, we’ll motivate premise 2. In section 4, we’ll look at one of the positive arguments for The Knowledge Rule, the argument from Moore’s paradox, and conclude that it is of no help. In section 5, we’ll look at what could be put in place of The Knowledge Rule, and suggest two alternatives.\nWe’re not going to argue for these rules in detail; that would take a much longer paper. Nor are we going to decide between them. What we are going to suggest is that these rules have the virtues that are commonly claimed for The Knowledge Rule, but lack The Knowledge Rule’s problematic consequences when it comes to assertions about what to do."
  },
  {
    "objectID": "posts/aka/assertion-knowledge-and-action.html#speaking-about-what-to-do",
    "href": "posts/aka/assertion-knowledge-and-action.html#speaking-about-what-to-do",
    "title": "Assertion, Knowledge and Action",
    "section": "1 Speaking about What to Do",
    "text": "1 Speaking about What to Do\nWe start by motivating premise 1 of the Master Argument with a couple of examples. Both cases are direct counterexamples to The Knowledge Rule, but we’re interested in the first instance in what the cases have in common. After presenting the vignettes, we offer three distinct arguments to show that, in such cases, it is proper for the speakers to assert what they do assert, even though they don’t know it to be true.\n\nGoing to War\nImagine that a country, Indalia, finds itself in a situation in which the thing for it to do, given the evidence available to its leaders, is to go to war against an enemy. (Those pacifists who think it is never right to go to war won’t like this example, but we think war can at least sometimes be justified.) But it is a close call. Had the evidence been a bit weaker, had the enemy been a little less murderous, or the risk of excessive civilian casualties a little higher, it would have been preferable to wait for more evidence, or use non-military measures to persuade the enemy to change its ways. So, while going to war is the thing to do, the leaders of Indalia can’t know this. We’ll come back to this in section 2, but the crucial point here is that knowledge has a safety constraint, and any putative knowledge here would violate this constraint.\nOur leaders are thus in a delicate position here. The Prime Minister of Indalia decides to launch the war, and gives a speech in the House of Commons setting out her reasons. All the things she says in the speech are true, and up to her conclusion they are all things that she knows. She concludes with (1).\nNow (1) is also true, and the Prime Minister believes it, but it is not something she knows. So, the Prime Minister violates The Knowledge Rule when she asserts (1). But it seems to us that she doesn’t violate any norms in making this assertion. We’ll have a lot more to say about why this is so in a few paragraphs. But first, here’s a less dramatic case that is also a counterexample to The Knowledge Rule, one that involves prudential judgments rather than moral judgments.\n\n\nBuying Flood Insurance\nRaj and Nik are starting a small business. The business is near a river that hasn’t flooded in recent memory, but around which there isn’t much flood protection. They could buy flood insurance which would be useful in a flood, naturally, but would be costly in the much more likely event that there is not a flood. Raj has done the calculations of the likelihood of a flood, the amount this would damage the business, the utility loss of not having this damage insured, and the utility loss of paying flood insurance premiums. He has concluded that buying flood insurance is the thing to do. As it happens, this was a good conclusion to draw: it does, in fact, maximise his (and Nik’s) expected utility over time. (It doesn’t maximise their actual utility, as there actually won’t be a flood over the next twelve months. So, the insurance premium is an expense they could have avoided. But that doesn’t seem particularly relevant for prudential evaluation. Prudential buyers of insurance should maximise expected utility, not actual utility. Or so we must say unless we want to be committed to the view that everyone who buys an insurance policy and doesn’t make a claim on it is imprudent.)\nBut again, it’s a close call. If there had been a little less evidence that a flood was a realistic possibility, or the opportunity cost of using those dollars on insurance premiums had been a little higher, or the utility function over different outcomes a little different, it would have been better to forego flood insurance. That suggests that safety considerations make it the case that Raj doesn’t know that buying flood insurance is the thing to do, though in fact it is.\nLet’s now assume Raj has done everything he should do to investigate the costs and benefits of flood insurance. We can imagine a conversation between him and Nik going as follows.\n\nNik: Should we get flood insurance?\nRaj: I don’t know. Hold on; I’m on the phone.\nNik: Who are you calling?\nRaj: The insurance agent. I’m buying flood insurance.\n\nThere is clearly a pragmatic tension in Raj’s actions here. But given The Knowledge Rule, there’s little else he can do. It would be a serious norm violation to say nothing in response to Nik’s question. And given that he can’t say “Yes” without violating The Knowledge Rule, he has to say “I don’t know”. Moreover, since by hypothesis buying flood insurance is the thing to do in his situation, he can’t not buy the insurance without doing the wrong thing. So, given The Knowledge Rule, he’s doing the best he can. But it’s crazy to think that this is the best he can do.\nWe think that these cases are problems for The Knowledge Rule. In particular, we think that in each case, there is a non-defective assertion of something that is not known. It seems to us intuitively clear that those assertions are non-defective, but for those who don’t share this intuition, we have three independent arguments. The arguments focus on Going to War, but they generalize easily enough to Buying Flood Insurance.\n\n\nArgument One: “That was your first mistake”\nImagine that the Prime Minister has a philosophical advisor. And the advisor’s job is to inform the Prime Minister whenever she violates a norm, and stay silent otherwise. If The Knowledge Rule is correct, then the advisor should stay silent as the Prime Minister orders the invasion, silent as the Prime Minister sets out the reasons for the invasion, then speak up at the very last line of the speech. That strikes us as absurd. It’s particularly absurd when you consider that the last line of the speech is supported by what came earlier in the speech, and the Prime Minister believes it, and asserts it, because it is well supported by what came earlier in the speech. Since we think this couldn’t be the right behaviour for the advisor, we conclude that there’s no norm violation in the Prime Minister asserting (1).\nWe’ve heard two replies to this kind of argument. According to one sort of reply, The Knowledge Rule is not meant to be an ‘all-things-considered’ norm. The defender of The Knowledge Rule can say that the Prime Minister’s assertion is defective because it violates that rule, but allow that it is nevertheless all-things-considered proper, because some other norm outweighs The Knowledge Rule on this occasion. We agree that The Knowledge Rule is not intended to be an all-things-considered norm. But even keeping clearly in mind the distinction between being defective in some respect and being defective all-things-considered, it is still deeply unintuitive to say that the Prime Minister’s assertion is defective in a respect. That is, we don’t think the philosophical advisor should speak up just at the very end of the Prime Minister’s speech even if she’s meant to observe all the norm violations (rather than just the all-things-considered norm violations).\nPerhaps the defender of The Knowledge Rule needn’t just appeal to an intuition here. Another reply we’ve heard starts from the premise that the Prime Minister’s assertion would be better, in a certain respect, if she knew that it was true. Therefore, there is a respect in which that assertion is defective, just as The Knowledge Rule requires. To this second reply, our response is that the premise is true, but the reasoning is invalid. Saying why requires reflecting a bit on the nature of norms.\nThere are lots of ways for assertions to be better. It is better, ceteris paribus, for assertions to be funny rather than unfunny. It is better for assertions to be sensitive rather than insensitive. (We mean this both in the Nozickian sense, i.e., an assertion is sensitive iff it wouldn’t have been made if it weren’t true, and in the Hallmark greeting card sense.) It is better for speakers to be certain of the truth of their assertions than for them to be uncertain. But these facts don’t imply that humour, sensitivity, or certainty are norms of assertion, for it doesn’t follow that assertions that lack humour (or sensitivity or certainty) are always defective. Similarly, the fact that it is better to know what you say than not doesn’t imply that asserting what you don’t know is always defective. In slogan form: Not every absence of virtue is a vice. We think knowledge is a virtue of assertions. (In fact, we think that pretty much every norm of assertion that has been proposed in the literature picks out a virtue of assertion.) What we deny is that the absence of knowledge is (always) a vice. Since not every absence of virtue is a vice, one can’t argue that the Prime Minister’s assertion is defective by arguing it could have been better. And that’s why the argument being considered is invalid.\n\n\nArgument Two: “Actions speak louder than words”\nIt’s a bit of folk wisdom that actions speak louder than words. It isn’t crystal clear just what this wisdom amounts to, but we think one aspect of it is that an agent incurs more normative commitments by doing X than by talking about X. But if The Knowledge Rule is right, then this piece of wisdom is in this aspect back-to-front. According to that rule, an agent incurs a greater normative commitment by saying that X is what to do than they do by just doing X. If they do X, and X is indeed what to do, then they’ve satisfied all of their normative commitments. If, by contrast, they say that X is what to do, then not only must X be what to do, but they must know this fact as well. This strikes us as completely back-to-front. We conclude that there is nothing improper about asserting that X is what to do (as the Prime Minister does), when X is in fact what to do.\n\n\nArgument Three: “What else could I do?”\nHere’s a quite different argument that Going to War is a counterexample to The Knowledge Rule.\n\nIf ending the speech the way she did was a norm violation, there is a better way for the Prime Minister to end her speech.\nThere is no better way for the Prime Minister to end the speech without saying something that she does not know to be true.\nSo, ending the speech the way she did was not a norm violation.\nSo, The Knowledge Rule is subject to counterexample.\n\nPremise 1 is a kind of ‘ought-implies-can’ principle, and as such, it isn’t completely obvious that it is true. But when we’ve presented this argument to various groups, the focus has always been on premise two. The common complaint has been that the Prime Minister could have ended the speech in one of the following ways, thereby complying with The Knowledge Rule.\n\nI’ve decided that going to war is the thing to do in the circumstances.\nI believe that going to war is the thing to do in the circumstances.\nIt seems to me that going to war is the thing to do in the circumstances.\n\nOur first reply to this suggestion is that we’d fire a speechwriter who recommended that a Prime Minister end such a speech in such a weaselly way, so this hardly counts as a criticism of premise 2. Our more serious reply is that even if the Prime Minister ended the speech this way, she’d still violate The Knowledge Rule. To see why this is so, we need to pay a little closer attention to what The Knowledge Rule says.\nNote that The Knowledge Rule is not a rule about what kind of declarative utterance you can properly make. An actor playing Hamlet does not violate The Knowledge Rule if he fails to check, before entering the stage, whether something is indeed rotten in the state of Denmark. The rule is a rule about what one asserts. And just as you can assert less than you declaratively utter (e.g., on stage), you can also assert more than you declaratively utter.3 For instance, someone who utters The F is G in a context in which it is common ground that a is the F typically asserts both that the F is G, and that a is G. Similarly, someone who utters I think that S typically asserts both asserts that they have a certain thought, and asserts the content of that thought. We can see this is so by noting that we can properly challenge an utterance of I think that S by providing reasons that S is false, even if these are not reasons that show that the speaker does not (or at least did not) have such a thought. In the context of her speech of the House of Commons, even if the Prime Minister were to end with one of the options above, she would still assert the same thing she would assert by uttering (1) in the circumstances, and she’d still be right to make such an assertion.\n3 The points we’re about to make are fairly familiar by now, but for more detail, see Cappelen and Lepore (2005), which played an important role in reminding the philosophy of language community of their significance."
  },
  {
    "objectID": "posts/aka/assertion-knowledge-and-action.html#bases-for-action-and-assertion",
    "href": "posts/aka/assertion-knowledge-and-action.html#bases-for-action-and-assertion",
    "title": "Assertion, Knowledge and Action",
    "section": "2 Bases for Action and Assertion",
    "text": "2 Bases for Action and Assertion\nOne might worry that premise 1 in our master argument is mistaken, in the following way. We said that if X is the thing to do for S, then S can say that X is what to do. But one might worry about cases where S makes a lucky guess about what is to be done. Above we imagined that Raj had taken all of the factors relevant to buying flood insurance into account. But imagine a different case, one involving Raj*, Raj’s twin in a similar possible world. Raj* decides to buy flood insurance because he consults his Magic 8-Ball. Then, even if buying flood insurance would still maximize his expected utility, it doesn’t seem right for Raj* to say that buying flood insurance is what to do.\nHere is a defence of premise 1 that seems initially attractive, though not, we think, ultimately successful. The Magic 8-ball case isn’t a clear counterexample to premise 1, it might be argued, because it isn’t clear that buying flood insurance for these reasons is the thing for Raj* to do. On one hand, we do have the concept of doing the right thing for the wrong reasons, and maybe that is the right way to describe what Raj* does if he follows the ball’s advice. But it isn’t clearly a correct way to describe Raj*. It’s not true, after all, that he’s maximising actual utility. (Remember that there will be no claims on the policy he buys.) And it isn’t clear how to think about expected utility maximisation when the entrepreneur in question relies on the old Magic 8-Ball for decision making. And we certainly want to say that there’s something wrong about this very decision when made using the Magic 8-Ball. So, perhaps we could say that buying flood insurance isn’t what to do for Raj* in this variant example, because he has bad reasons.\nBut this seems like a tendentious defence of the first premise. Worse still, it is an unnecessary defence. What we really want to focus on are cases where people do the right thing for the right reasons. Borrowing a leaf from modern epistemology, we’ll talk about actions having a basis. As well as there being a thing to do in the circumstances (or, more plausibly, a range of things to do), there is also a correct basis for doing that thing (or, more plausibly, a range of correct bases). What we care about is when S does X on basis B, and doing X on basis B is the thing to do in S’s situation. Using this notion of a basis for action, we can restate the main argument.\n\nMaster Argument (Corrected)\n\nIf doing X on basis B is what to do for agent S, then S can properly, on basis B, assert that X is what to do (assuming this is relevant to the conversation).\nIt is possible that doing X on basis B is what to do for S, even though S is not in a position to know, and certainly not in a position to know on basis B, that X is what to do.\nSo, it is possible that S properly can assert that X is what to do, even though she does not know, and is not even in a position to know, that X is what to do.\n\n\nWe endorse this version of the master argument. Since its conclusion is the denial of The Knowledge Rule, we conclude that The Knowledge Rule is mistaken. But we perhaps haven’t said enough about premise 2 to seal the argument. The next section addresses that issue."
  },
  {
    "objectID": "posts/aka/assertion-knowledge-and-action.html#marginal-wars",
    "href": "posts/aka/assertion-knowledge-and-action.html#marginal-wars",
    "title": "Assertion, Knowledge and Action",
    "section": "3 Marginal Wars",
    "text": "3 Marginal Wars\nThe argument for premise 2 is just a simple application of Williamson’s anti-luminosity reasoning. (The canonical statement of this reasoning is in (Williamson 2000 Ch. 4)).) Williamson essentially argues as follows, for many different values of p. There are many ways for p to be true, and many ways for it to be false. Some of the ways in which p can be true are extremely similar to ways in which it can be false. If one of those ways is the actual way in which p is true, then to know that p we have to know that situations very similar to the actual situation do not obtain. But in general we can’t know that. So, some of the ways in which p can be true are not compatible with our knowing that p is true. In Williamson’s nice phrase, p isn’t luminous, where a luminous proposition is one that can be known (by a salient agent) whenever it is true. The argument of this paragraph is called ‘an anti-luminosity argument’, and we think that many instances of it are sound.\nThere is a crucial epistemic premise in the middle of that argument: that we can’t know something if it is false in similar situations. There are two ways that we could try to motivate this premise. First, we could try to motivate it with the help of conceptual considerations about the nature of knowledge. That’s the approach that Williamson takes. But his approach is controversial. It is criticised by Sainsbury (1995) and Weatherson (2004) on the grounds that his safety principle goes awry in some special cases. Sainsbury focuses on mathematical knowledge, Weatherson on introspective knowledge. But the cases in which we’re most interested in this paper – Indalia going to war, Raj and Nik buying flood insurance – don’t seem to fall into either of these problem categories. Nevertheless, rather than pursue this line, we’ll consider a different approach to motivating this premise.\nThe second motivation for the epistemic premise comes from details of the particular cases. In the two cases on which we’re focusing, the agents simply lack fine discriminatory capacities. They can’t tell some possibilities apart from nearby possibilities. That is, they can’t know whether they’re in one world or in some nearby world. That’s not because it’s conceptually impossible to know something that fine, but simply an unfortunate fact about their setup. If they can’t know that they’re not in a particular nearby world in which \\(\\neg\\)p, they can’t know p. Using variants of Going to War, we’ll describe a few ways this could come about.\nThe simplest way for this to come about is if war-making is the thing to do given what we know, but some of the crucial evidence consists of facts that we know, but don’t know that we know. Imagine that a crucial piece of Indalia’s case for war comes from information from an Indalian spy working behind enemy lines. As it turns out, the spy is reliable, so the leaders of Indalia can acquire knowledge from her testimony. But she could easily enough have been unreliable. She could, for instance, have been bought off by the enemy’s agents. As it happens, the amount of money that would have taken was outside the budget the enemy has available for counterintelligence. But had the spy been a little less loyal, or the enemy a little less frugal with the counterintelligence budget, she could easily have been supplying misinformation to Indalia. So, while the spy is a safe knowledge source, the Indalian leaders don’t know that she is safe. They don’t, for instance, know the size of the enemy’s counterintelligence budget, or how much it would take to buy off their spy, so for all they know, she is very much at risk of being bought off.\nIn this case, if the spy tells the Indalian leaders that p, they come to know that p, and they can discriminate p worlds from \\(\\neg\\)p worlds. But they don’t know that they know that p, so for all they know, they don’t know p. And for some p that they learn from the spy, if they don’t know p, then going to war isn’t the thing for them to do in the circumstances. So, given that they don’t know the spy is reliable, they don’t know that going to war is the thing for them to do. But the spy really is reliable, so they do know p, so going to war is indeed the thing for them to do.\nOr consider a slightly less fanciful case, involving statistical sampling. Part of the Prime Minister’s case for starting the war was that the enemy was killing his own citizens. Presumably she meant that he was killing them in large numbers. (Every country with capital punishment kills its own citizens, but arguably that isn’t a sufficient reason to invade.) In practice, our knowledge of the scope of this kind of governmental killing comes from statistical sampling. And this sampling has a margin of error. Now imagine that the Indalian leaders know that a sample has been taken, and that it shows that the enemy has killed n of his citizens, with a margin of error of m. So, assuming there really are n killings, they know that the enemy has killed between n - m and n + m of his citizens. Since knowing that he’s killed n - m people is sufficient to make going to war the thing to do, the war can be properly started.\nBut now let’s think about what the Indalian leaders know that they know in this case. The world where the enemy has killed n - m people is consistent with their knowledge. And their margin of error on estimates of how many the enemy has killed is m. So, if that world is actual, they don’t know the enemy has killed more than n - 2m of his citizens. And that knowledge might not be enough to make going to war the thing to do, especially if m is large. (Think about the case where m = n/2, for instance.) So, there’s a world consistent with their knowledge (the n - m killings world), in which they don’t know enough about what the enemy is doing to make going to war the thing to do. In general, if there’s a world consistent with your knowledge where p is false, you don’t know p. Letting p be Going to war is what to do, it follows then that they don’t know that going to war is what to do, even though it actually is the thing to do.\nAnother way we could have a borderline war is a little more controversial. Imagine a case where the leaders of Indalia know all the salient descriptive facts about the war. They know, at least well enough for present purposes, what the costs and benefits of the war might be. But it is a close call whether the war is the thing to do given those costs and benefits. Perhaps different plausible moral theories lead to different conclusions. Or perhaps the leaders know what the true moral theory is, but that theory offers ambiguous advice. We can imagine a continuum of cases where the true theory says war is clearly what to do at one end, clearly not what to do at another, and a lot of murky space between. Unless we are willing to give up on classical logic, we must think that somewhere there is a boundary between the cases where it is and isn’t what to do, and it seems in cases near the boundary even a true belief about what to do will be unsafe. That is, even a true belief will be based on capacities that can’t reliably discriminate situations where going to war is what to do from cases where it isn’t.\nWe’ve found, when discussing this case with others, that some people find this outcome quite intolerable. They think that there must be some epistemic constraints on war-making. And we agree. They go on to think that these constraints will be incompatible with the kind of cases we have in mind that make premise 2 true. And here we disagree. It’s worth going through the details here, because they tell us quite a bit about the nature of epistemic constraints on action.\nConsider all principles of the form\n\n(KW)\n\nGoing to war is N1 only if the war-maker knows that going to war is N2.\n\n\nwhere N1 and N2 are normative statuses, such as being the thing to do, being right, being good, being just, being utility increasing, and so on. All such principles look like epistemic constraints on war-making, broadly construed. One principle of this form would be that going to war is right only if the war-maker knows that going to war is just. That would be an epistemic constraint on war-making, and a plausible one. Another principle of this form would be that going to war is the thing to do only if the war-maker knows that going to war increases actual utility. That would be a very strong epistemic constraint on war-making, one that would rule out pretty much every actual war, and one that is consistent with the anti-luminosity argument with which we started this section. So, the anti-luminosity argument is consistent with there being quite strong epistemic constraints on war-making.\nWhat the anti-luminosity argument is not consistent with is there being any true principle of the form (KW) where N1 equals N2. In particular, it isn’t consistent with the principle that going to war is the thing to do only if the war maker knows that it is the thing to do. But that principle seems quite implausible, because of cases where going to war is, but only barely, the thing to do. More generally, the following luminosity of action principle seems wrong for just about every value of X.\n\n(LA)\n\nX is the thing for S to do only if S knows that X is the thing for her to do.\n\n\nNot only is (LA) implausible, things look bad for The Knowledge Rule if it has to rely on (LA) being true. None of the defenders of The Knowledge Rule has given us an argument that (LA) is true. One of them has given us all we need to show that (LA) is false! It doesn’t look like the kind of principle that The Knowledge Rule should have to depend upon. So, defending The Knowledge Rule here looks hopeless.\nNote that given premise 1 of the Master Argument, as corrected, every instance of (LA) has to be true for The Knowledge Rule to be universally true. Let’s say that you thought (LA) was true when X is starting a war, but not when X is buying flood insurance. Then we can use the case of Raj and Nik to show that The Knowledge Rule fails, since Raj can say that buying flood insurance is what to do in a case where it is what to do, but he doesn’t know this.\nOne final observation about the anti-luminosity argument. Given the way Williamson presents the anti-luminosity argument, it can appear that in all but a few cases, if p, the salient agent can know that p. After all, the only examples Williamson gives are cases that are only picked out by something like the Least Number Theorem. So, one might think that while luminosity principles are false, they are approximately true. More precisely, one might think that in all but a few weird cases near the borderline, if p, then a salient agent is in a position to know p. If so, then the failures of luminosity aren’t of much practical interest, and hence the failures of The Knowledge Rule we’ve pointed out aren’t of much practical interest.\nWe think this is all mistaken. Luminosity failures arise because agents have less than infinite discriminatory capacities. The worse the discriminatory capacities, the greater the scope for luminosity failures. When agents have very poor discriminatory capacities, there will be very many luminosity failures. This is especially marked in decision-making concerning war. The fog of war is thick. There is very much that we don’t know, and what we do know is based on evidence that is murky and ephemeral. There is very little empirical information that we know that we know. If there are certain actions (such as starting a war) that are proper only if we know a lot of empirical information, the general case will be that we cannot know that these actions are correct, even when they are. This suggests that luminosity failures, where an action is correct but not known to be correct, or a fact is known but not known to be known, are not philosophical curiosities. In epistemically challenging environments, like a war zone, they are everyday facts of life."
  },
  {
    "objectID": "posts/aka/assertion-knowledge-and-action.html#moores-paradox",
    "href": "posts/aka/assertion-knowledge-and-action.html#moores-paradox",
    "title": "Assertion, Knowledge and Action",
    "section": "4 Moore’s Paradox",
    "text": "4 Moore’s Paradox\nThere is a standard argument for The Knowledge Rule that goes as follows. First, if the Knowledge Rule did not hold, then certain Moore paradoxical assertions would be acceptable. In particular, it would be acceptable to assert q, but I don’t know that q.4 But second, Moore paradoxical assertions are never acceptable. Hence, The Knowledge Rule holds. We reject both premises of this argument.\n4 (Williamson 2000), for instance, shows the strength of this argument.To reject the first premise, it suffices to show that some rule other than The Knowledge Rule can explain the unacceptability of Moore paradoxical assertions. Consider, for example, The Undefeated Reason rule.\n\nThe Undefeated Reason Rule\n\nAssert that p only if you have an undefeated reason to believe that p.\n\n\nThe Undefeated Reason Rule says that q but I don’t know that q can be asserted only if the speaker has an undefeated reason to believe it. That means the speaker has an undefeated reason to believe each conjunct. That means that the speaker has an undefeated reason to believe that they don’t know q. But in every case where it is unacceptable to both assert q and assert that you don’t know q, the speaker’s undefeated reason to believe they don’t know q will be a defeater for her belief that q. If you have that much evidence that you don’t know q, that will in general defeat whatever reason you have to believe q.\nWe don’t claim that The Undefeated Reason Rule is correct. (In fact, we prefer the rules we’ll discuss in section 5.) We do claim that it provides an alternative explanation of the unacceptability of instances of q but I don’t know that q. So, we claim that it undermines the first premise of Williamson’s argument from that unacceptability to The Knowledge Rule.\nWe also think that Williamson’s explanation of Moore paradoxicality over-generates. There is generally something odd about saying q but I don’t know that q. We suspect that the best explanation for why this is odd will be part of a broader explanation that also explains, for instance, why saying I promise to do X, but I’m not actually doing to do X is also defective. Williamson’s explanation isn’t of this general form. He argues that saying q but I don’t know that q is defective because it is defective in every context to both assert q and assert that you don’t know that q. But we don’t think that it is always defective to make both of these assertions.5 In particular, if a speaker is asked whether q is true, and whether they know that q, it can be acceptable to reply affirmatively to the first question, but negatively to the second one. If so, then the second premise of Williamson’s argument from Moore paradoxicality is also false.\n5 This is why we hedged a little two paragraphs ago about what precisely The Undefeated Reason Rule explains. We suspect that many in the literature have misidentified the explicandum.Imagine that the Indalian Prime Minister is a philosopher in her spare time. After the big speech to Parliament she goes to her Peninsula Reading Group. It turns out Michael Walzer and Tim Williamson are there, and have questions about the speech.\n\nTW: Do you agree that knowledge requires safety?\nPM: Yes, yes I do.\nTW: And do you agree that your belief that going to war is the thing to do is not safe?\nPM: Right again.\nTW: So, you don’t know that going to war is the thing to do?\nPM: You’re right, I don’t.\nMW: But is it the thing to do?\nPM: Yes.\n\nThe Prime Minister’s answers in this dialogue seem non-defective to us. But if Williamson’s explanation of why Moore paradoxical utterances are defective is correct, her answers should seem defective. So, Williamson’s explanation over-generates. Whether or not it is true that all assertions of sentences of the form q but I don’t know that q are defective, it isn’t true that there is a defect in any performance that includes both an assertion of q and an assertion of the speaker’s ignorance as to whether q. The Prime Minister’s performance in her reading group is one such performance. So, the explanation of Moore paradoxicality cannot be that any such performance would violate a norm governing assertion.\nTo sum up, then, we’ve argued that The Knowledge Rule (a) fails to be the only explanation of Moore paradoxicality, and (b) misclassifies certain performances that are a little more complex than simple conjunctive assertions as defective. So, there’s no good argument from Moore paradoxicality to The Knowledge Rule."
  },
  {
    "objectID": "posts/aka/assertion-knowledge-and-action.html#action-and-assertion",
    "href": "posts/aka/assertion-knowledge-and-action.html#action-and-assertion",
    "title": "Assertion, Knowledge and Action",
    "section": "5 Action and Assertion",
    "text": "5 Action and Assertion\nIf we’re right, there’s a striking asymmetry between certain kinds of assertions. In the war example, early in her speech, the Prime Minister says (2).\nThat’s not the kind of thing she could properly say if it could easily have been false given her evidence. And like many assertions, this is not an assertion whose appropriateness is guaranteed by its truth. Asserting (2) accuses someone of murder, and you can’t properly make such accusations without compelling reasons, even if they happen to be true. On the other hand, we say, the truth of (1) does (at least when it is accepted on the right basis) suffice to make it properly assertable.\nThere’s a similar asymmetry in the flood insurance example. In that example, (3) is true, but neither Raj nor Nik knows it.\nAgain, in these circumstances, this isn’t the kind of thing Raj can properly say. Even though (3) is true, it would be foolhardy for Raj to make such a claim without very good reasons. By contrast, again, we say that Raj can properly assert that the thing to do, in their circumstances, is to buy flood insurance, even though he does not know this.\nThere are two directions one could go at this point. If we’re right, any proposed theory of the norms governing assertion must explain the asymmetry. Theories that cannot explain it, like The Knowledge Rule, or the Certainty Rule proposed by Jason Stanley (2008), or the Rational Credibility Rule proposed by Igor Douven (2006), are thereby refuted.\n\nThe Certainty Rule\n\nAssert only what is certain.\n\nThe Rational Credibility Rule\n\nAssert only what is rationally credible.\n\n\nThe Certainty Rule fails since the Prime Minister is not certain of (1). And the Prime Minister can’t be certain of (1), since certainty requires safety just as much as knowledge does.\nIt’s a little harder to show our example refutes The Rational Credibility Rule. Unlike knowledge, a safety constraint is not built into the concept of rational credibility. (Since rational credibility does not entail truth, in Douven’s theory, it can hardly entail truth in nearby worlds.) But we think that safety constraints may still apply to rational credibility in some particular cases. If you aren’t very good at judging building heights of tall buildings to a finer grain than 10 meters, then merely looking at a building that is 84 meters tall does not make it rationally credible for you that the building is more than 80 meters tall. In general, if your evidence does not give you much reason to think you are not in some particular world where p is false, and you didn’t have prior reason to rule that world out, then p isn’t rationally credible. So, when evidence doesn’t discriminate between nearby possibilities, and p is false in nearby possibilities, p isn’t rationally credible.\nAnd that, we think, is what happens in our two examples. Just as someone looking at an 84 meter building can’t rationally credit that it is more than 80 meters tall, unless they are abnormally good at judging heights, agents for whom X is just barely the thing to do can’t rationally credit that X is the thing to do. By The Rational Credibility Rule, they can’t say X is the thing to do. But they can say that; that’s what our examples show. So, The Rational Credibility Rule must be wrong.\nBut we can imagine someone pushing in the other direction, perhaps with the help of this abductive argument.\n\nA speaker can only assert things like (2) or (3) if they know them to be true.\nThe best explanation of premise 1 of this argument is The Knowledge Rule.\nSo, The Knowledge Rule is correct.\n\nThis isn’t a crazy argument. Indeed, it seems to us that it is implicit in some of the better arguments for The Knowledge Rule. But we think it fails. And it fails because there are alternative explanations of the first premise, explanations that don’t make mistaken predictions about the Prime Minister’s speech. For instance, we might have some kind of Evidence Responsiveness Rule.\n\nThe Evidence Responsiveness Rule\n\nAssert that p only if your attitude towards p is properly responsive to the evidence you have that bears on p.\n\n\nGiven how much can be covered by ‘properly’, this is more of a schema than a rule. Indeed, it is a schema that has The Knowledge Rule as one of its precisifications. In Knowledge and Its Limits, Williamson first argues that assertion is “governed by a non-derivative evidential rule” (249), and then goes on to argue that the proper form of that rule is The Knowledge Rule. We agree with the first argument, and disagree with the second one.6\n6 Actually, our agreement with Williamson here is a bit more extensive than the text suggests. Williamson holds that part of what makes a speech act an assertion as opposed to some other kind of act is that it is governed by The Knowledge Rule. Although many philosophers agree with Williamson that The Knowledge Rule is true, this fascinating claim about the metaphysics of speech acts has been largely ignored. Translating Williamson’s work into the terminology of this paper, we’re inclined to agree that a speech act is an assertion partly in virtue of being responsive to evidence in the right way. But filling in the details on this part of the story would take us too far from the main storyline of this paper.Note that even a fairly weak version of The Evidence Responsiveness Rule would explain what is going on with cases like (1) and (2). Starting a war is a serious business. You can’t properly do it unless your views about the war are evidence responsive in the right way. You can’t, that is, correctly guess that starting the war is the thing to do. You can correctly guess that starting the war will be utility maximizing. And you can correctly guess that starting the war would be what to choose if you reflected properly on the evidence you have, and the moral significance of the choices in front of you. But you simply can’t guess that starting the war is what to do, and be right. If you’re merely guessing that starting a war is thing to do, then you’re wrong to start that war. So, if (1) is true, and the Prime Minister believes it, her belief simply must be evidence responsive. Then, by The Evidence Responsiveness Rule, she can assert it.\nFor most assertions, however, this isn’t the case. Even if it’s true that it will rain tomorrow, the Prime Minister’s could believe that without her belief being evidence responsive. In general, p does not entail that S even believes that p, let alone that this belief of S’s is evidence responsive. But in cases like (1), this entailment does hold, and that’s what explains the apparent asymmetry that we started this section with.\nThe Evidence Responsiveness Rule also handles so called ‘lottery propositions’ nicely. If you know that the objective chance of p being true is c, where c is less than 1, it will seem odd in a lot of contexts to simply assert p. In his arguments for The Knowledge Rule, Williamson makes a lot of this fact. In particular, he claims that the best explanation for this is that we can’t know that p on purely probabilistic grounds. This has proven to be one of the most influential arguments for The Knowledge Rule in the literature. But some kind of Evidence Responsiveness Rule seems to handle lottery cases even more smoothly. In particular, an Evidence Responsiveness Rule that allows for what constitutes ‘proper’ responsiveness to be sensitive to the interests of the conversational participants will explain some odd features concerning lottery propositions and assertability.\nIn the kind of cases that motivate Williamson, we can’t say p where it is objectively chancy whether p, and the chance of p is less than 1. But there’s one good sense in which such an assertion would not be properly responsive to the evidence. After all, in such a case there’s a nearby world, with all the same laws, and with all the same past fatcs, and in which the agent has all the same evidence, in which p is false. And the agent knows all this. That doesn’t look like the agent is being properly responsive to her evidence.\nOn the other hand, we might suspect that Williamson’s arguments concerning lottery propositions overstate the data. Consider this old story from David Lewis (1996).7\n7 We’ve slightly modified the case. Lewis says we can say that we know Bill will never be rich. That seems to us to be a much more controversial than what we’ve included here.\nPity poor Bill! He squanders all his spare cash on the pokies, the races, and the lottery. He will be a wage slave all his days … he will never be rich. (Lewis 1996, 443 in reprint)\n\nThese seem like fine assertions. One explanation of the appropriateness of those assertions combines The Knowledge Rule with contextualism about assertion.8 But contextualism has many weaknesses, as shown in Hawthorne (2004) and Stanley (2005). A less philosophically loaded explanation of Lewis’s example is that proper responsiveness comes in degrees, and for purposes of talking about Bill, knowing that it’s overwhelmingly likely that he’s doomed to wage slavery is evidence enough to assert that he’ll never be rich. The details of this explanation obviously need to be filled in, but putting some of the sensitivity to conversational standards, or practical interests, into the norms of assertion seems to be a simpler explanation of the data than a contextualist explanation. (It would be a priori quite surprising if the norms of proper assertion were not context-sensitive, or interests-sensitive. The norms of appropriateness for most actions are sensitive to context and interests.) So The Evidence Responsiveness Rule seems more promising here than The Knowledge Rule.\n8 The combination is slightly trickier to state than would be ideal. The explanation we have in mind is that S can properly assert p only if S can truly say I know that p, where ‘know’ in this utterance is context sensitive.A harder kind of case for The Knowledge Rule concerns what we might call ‘academic assertions’. This kind of case is discussed in Douven (2006) and in Maitra (2010). In academic papers, we typically make assertions that we do not know. We don’t know that most of the things we’ve said here are true. (Before the last sentence we’re not sure we knew that any of the things we said were true.) But that’s because knowledge is a bad standard for academic discourse. Debate and discussion would atrophy if we had to wait until we had knowledge before we could present a view. So, it seems that assertion can properly outrun knowledge in academic debate.\nAgain, a context-sensitive version of The Evidence Responsiveness Rule explains the data well. Although you don’t need to know things to assert them in philosophy papers, you have to have evidence for them. We couldn’t have just spent this paper insisting louder and louder that The Knowledge Rule is false. We needed to provide evidence, and hopefully we’ve provided a lot of it. In some contexts, such as testifying in court, you probably need more evidence than what we’ve offered to ground assertions. But in dynamic contexts of inquiry, where atrophy is to be feared more than temporary mistakes, the standards are lower. Good evidence, even if not evidence beyond any reasonable doubt, or even if not enough for knowledge, suffices for assertion. That’s the standard we typically hold academic papers to. Like with lotteries, we think the prospects of explaining these apparently variable standards in terms of a norm of assertion that is context-sensitive are greater than the prospects for explaining them in terms of contextually sensitive knowledge ascriptions.\nHere’s a different and somewhat more speculative proposal idea for a rule that also explains the asymmetry we started this section with. We call it the Action Rule.\n\nThe Action Rule\n\nAssert that p only if acting as if p is true is the thing for you to do.\n\n\nWe take the notion of acting as if something is true from Stalnaker (1973). Intuitively, to act as if p is true is to build p into one’s plans, or to take p for granted when acting. This, note, is not the same as using p as a basis for action. When Raj buys flood insurance, he acts as if buying flood insurance is the thing to do. But the fact that buying flood insurance is the thing to do isn’t the basis for his action. (Since he does not know this, one might suspect it wouldn’t be a good basis.) Instead his basis is what he knows about the river, and his business, and its vulnerability to flooding. When an agent is trying to maximise the expected value of some variable (e.g., utility, profit, etc.), then to act as if p is true is simply to maximise the conditional expected value of that variable, in particular, to maximise the expected value of that variable conditional on p. Even when one is not maximising any expected value, we can still use the same idea. To act as if p is to take certain conditional obligations or permissions you have – in particular, those obligations or permissions that are conditional on p – to be actual obligations or permissions.\nTo see how The Action Rule generates the intended asymmetry, we’ll need a bit of formalism. Here are the terms that we will use.\n\nX denotes an action, agent, circumstance triple \\(\\langle\\)XAction, XAgent, XCircumstance\\(\\rangle\\). We take such triples to have a truth value. X is true iff XAgent performs XAction in XCircumstance.\nThingToDo(X) means that X is the thing to do for XAgent in XCircumstance.\nAct(S,p) means that agent S acts as if p is true.\nAssert(S,p) means that agent S can properly assert that p.\n\nSo, The Action Rule is this.\n\nAssert(S,p) \\({\\rightarrow}\\) ThingToDo(Act(S,p))\n\nIn our derivations, the following equivalence will be crucial.\n\nAct(XAgent,ThingToDo(X)) \\({\\leftrightarrow}\\) X\n\nThat is, acting as if X is what to do (in your circumstances) is simply to do X (in those circumstances). And in doing X, you’re acting as if X is what to do (in your circumstances). We take this equivalence to be quite resilient; in particular, it holds under operators like ‘ThingToDo’. So, adding that operator to the previous equivalence, we get another equivalence.\n\nThingToDo(Act(XAgent,ThingToDo(X))) \\({\\leftrightarrow}\\) ThingToDo(X)\n\nIf we substitute ThingToDo(X) for p in The Action Rule, we get this.\n\nAssert(XAgent,ThingToDo(X)) \\({\\rightarrow}\\) ThingToDo(Act(XAgent,ThingToDo(X)))\n\nBut by the equivalence we derived earlier, that’s equivalent to the following.\n\nAssert(XAgent,ThingToDo(X)) \\({\\rightarrow}\\) ThingToDo(X)\n\nSo, we get the nice result that The Action Rule is trivially satisfied for any true claim about what is to be done. That is, for the special case where p is X is the thing for you to do, The Action Rule just reduces to something like the Truth Rule. And so we get a nice explanation of why the Prime Minister and Raj can properly make their assertions about what to do in their respective circumstances.9\n9 The derivation here is deliberately simplified in one way. We haven’t included anything about the bases for action or assertion. We don’t think being sensitive to bases in the formalism would make a material change, but it would obscure the structure of the argument.To explain the other side of the asymmetry with which we began this section, note that these biconditionals do not hold where p is an arbitrary proposition, and S an arbitrary agent.\n\nThingToDo(Act(S,p)) \\({\\leftrightarrow}\\) p\nAct(S,ThingToDo(Act(S,p))) \\({\\leftrightarrow}\\) p\n\nTo see this, let p be the proposition expressed by (4). To act as if this is true is to, inter alia, not buy flood insurance. If there won’t be a flood, buying flood insurance is throwing away money, and when you’re running a business, throwing away money isn’t the thing to do. In symbols, Act(Raj and Nik,p) is equivalent to Raj and Nik don’t buy flood insurance. But not buying flood insurance is not the thing to do. The prudent plan is to buy flood insurance. So, ThingToDo(Act(Raj and Nik,p)) is false, even though p is true. So, the first biconditional fails. Since Raj and Nik do go on to buy flood insurance, i.e., since they don’t act as if ThingToDo(Act(Raj and Nik,p)), the left-hand-side of the second biconditional is also false. But again, the right-hand-side is true. So, that biconditional is false as well. And without those biconditionals, The Action Rule doesn’t collapse into Assert(S,p) \\({\\rightarrow}\\) p.\nWe have thus far argued that The Action Rule can provide an explanation for the asymmetry we noted at the beginning of this section.10 This is not, however, meant to be anything like a complete defence of that rule. That would require a lot more than we’ve provided here. But we do think that the Action Rule can explain a lot of the phenomena that are meant to motivate The Knowledge Rule, as well as some phenomena The Knowledge Rule struggles with.But we do think The Action Rule has some virtues. We’ll close with a discussion of how it explains the two kinds of cases that we argued that The Evidence Responsiveness Rule handles well.\n10 This explanation makes some interestingly different predictions from the explanation in terms of The Evidence Responsiveness Rule. Suppose that for relatively trivial decisions, like where to go for a walk on a nice summer day, one can correctly guess that X is the thing to do. Then the Evidence Responsiveness Rule would suggest that the truth of claims about where to go for a walk is not sufficient grounds for their assertability, while the Action Rule would still imply that truth is sufficient grounds for assertability.\n  We’re not sure that this supposition – that for relatively trivial decisions, one can correctly guess that X is the thing to do – is coherent, nor what to say about assertability judgments in (imagined) cases where the supposition holds. So, we’re not sure we can really use this to discriminate between the two proposed explanations. Nevertheless, it is interesting to note how the explanations come apart. Thanks here to Susanna Schellenberg.To see this, consider first ‘lottery propositions’. If you know that the objective chance of p being true is c, where c is less than 1, it will seem odd in a lot of contexts to simply assert p. In his arguments for The Knowledge Rule, Williamson makes a lot of this fact. In particular, he claims that the best explanation for this is that we can’t know that p on purely probabilistic grounds. This has proven to be one of the most influential arguments for The Knowledge Rule in the literature.\nWe suggest that The Action Rule can offers an alternative a nice explanation for why it’s often defective to assert lottery propositions. Note first that inIn a lot of cases, it isn’t rational for us to act on p when we have only purely probabilistic evidence for it, especially when acting on p amounts to betting on p at sufficiently unfavourable odds. This point is something of a staple of the ‘interest-relative-invariantism’ literature on knowledge.11 To take a mundane case, imagine that you’re cleaning up your desk, and you come across some lottery tickets. Most are for lotteries that have passed, that you know you lost. One ticket, however, is for a future lottery, which you know you have very little chance of winning. In such a case, to act as if the ticket for the future lottery would lose would be to throw it out along with the other tickets. But that would be irrational, and not at all how we’d act in such a case. That is to say, in such a case, we don’t (and shouldn’t, rationally speaking) act as if the ticket for the future lottery will lose, even though we take that outcome to be highly probable.\n11 See, for instance, Fantl and McGrath (2002), Hawthorne (2004), Stanley (2005), and Weatherson (2005).If acting as if a lottery proposition is true isn’t the thing to do, then The Action Rule will say that asserting such a proposition defective. Therefore, we think that The Action Rule can capture why in many cases you can’t in general assert lottery propositions.\nA harder kind of case for The Knowledge Rule concerns what we might call ‘academic assertions’. This kind of case is discussed in Douven (2006) and in Maitra (2010). In academic papers, we typically make assertions that we do not know. We don’t know that most of the things we’ve said here are true. (Before the last sentence we’re not sure we knew that any of the things we said were true.) But that’s because knowledge is a bad standard for academic discourse. Debate and discussion would atrophy if we had to wait until we had knowledge before we could present a view. So, it seems that assertion can properly outrun knowledge in academic debate.\nAcademic assertions raised a problem for The Knowledge Rule because proper assertion in the context of inquiry can outrun knowledge. But note that action in such a context can also properly outrun knowledge. It would slow down learning dramatically if people didn’t engage in various projects that really only make sense if some hypothesis is true. So, academics will study in archives, conduct experiments, write papers, etc. etc., and do so on the basis of reasons they no more know than we know the truth of the speculative claims of this paper. And this is all to the good; the alternative is a vastly inferior alternative to academia as we know it. So, in some fields, action requires much less than knowledge. Happily, in those fields, assertion also requires much less than knowledge. Indeed, the shortfalls in the two cases seem to parallel nicely. And this parallel is neatly captured by The Action Rule.\nAs we said, none of this is a knockdown case for The Action Rule. Our primary purpose is to argue against The Knowledge Rule. As long as the Action Rule is plausible, we have defeated the abductive argument for The Knowledge Rule that was discussed at the start of this section, and we think we’ve done enough to show it is plausible. We also hope we’ve made a successful case for moving the study of assertability away from rules like The Knowledge Rule, and instead have it be more tightly integrated with our best theories about evidence and action."
  },
  {
    "objectID": "posts/review-realm/review-of-the-realm-of-reason.html",
    "href": "posts/review-realm/review-of-the-realm-of-reason.html",
    "title": "Review of “The Realm of Reason”",
    "section": "",
    "text": "Some of what we know we know by experience and some by reason. It’s experience not reason that teaches that Arsenal ended last season with 90 points and Chelsea with 79, it’s reason not experience that teaches 90 is greater than 79, and, arguably, it’s the two together that teach that Arsenal ended with more points than Chelsea. One useful classification of philosophers is by the relative importance they assign to experience and reason in grounding what we know. Empiricists (on one reading of that term) play down reason, sometimes going so far as to declare that anything known by a means other than experience must be a mere matter of definition. Rationalists play reason up.\n\nPublished in the Times Literary Supplement\n\nChristopher Peacocke is firmly in the rationalist camp, and The Realm of Reason is an attempt to lay out what he takes rationalism to be. It gives his preferred version of rationalism and some arguments in its favour. It’s much too much to attempt in a short book and it isn’t entirely persuasive on any of the applications, but it is a grand vision for what a global rationalism might look like, one that might prove attractive even if the details need work. Given the length of the book a surprising amount of time is spent on relatively abstruse details. Peacocke provides a particularly careful account of what distinguishes rationalists from empiricists and does a lot of work classifying and adjudicating between rationalisms of various strengths. These are the best parts of the book, but also the least accessible.\nPeacocke’s preferred version of rationalism has two distinctive components. First, he focuses not on beliefs, as is usual, but on the “transitions” between representational states that occur in thought, as when we move to a new belief on the basis of one we already have. Mental representational states are often beliefs, but they also include things, like perceptions, that have representational content without necessarily being believed. Peacocke’s rationalist claim is that for any justified transition, there’s an a priori explanation of why it is justified. Second, he insists that this explanation rely crucially on the contents of the states involved in the transition.\nSo we get a quite strong “foundationalist” epistemology. Experience provides the foundations for empirical knowledge, but how we get from there to what we know is entirely in the domain of reason. It is famously difficult to justify many steps by reason alone, and the most pressing is the very first: How do we justify the transition from appearances to reality, such as the transition from That looks crooked to That is crooked? Some philosophers have thought that we need to link appearance and reality so closely that the link is infallible. Peacocke doesn’t take that line, so he has to justify the transition some other way.\nDescartes faced a similar problem when trying to get over his radical doubt about the existence of the material world, and solved it by appeal to God. We can tell a priori, he thought, that a benevolent God exists, and a benevolent God will not let us be deceived about this matter, at least when we are careful enough to rely on clear and distinct perceptions. Now Descartes had to be careful here to only appeal to a priori reasons for belief in God. He couldn’t, for instance, argue from the apparent design of the universe to the existence of a designer, because we can’t tell at this stage whether the apparent design is merely an artifact of our defective perceptual faculties. Indeed, we can’t rely on any apparent fact about the external world until we’ve determined that appearances are a good guide to reality. So we need to argue for the existence of God without appeal to perception, and then use God’s existence to justify future reliance on perception.\nIn keeping with the spirit of the age, Peacocke updates Descartes’s strategy by replacing God with Darwin. Very roughly, Peacocke argues that the best explanation of our having representative capacities at all is that we are the products of a long process of natural selection. And if we are the products of a long process of selection, then we probably have accurate representations. If those two claims can be justified a priori we have an a priori argument to the (prima facie, probable) accuracy of our representations.\nLess roughly, Peacocke argues for a “Complexity Reduction Principle”. We are entitled, on a priori grounds, to believe that complex phenomena have explanations, and we are entitled to regard simpler explanations as more probably true than more complex ones. That we have representations at all is a complex matter. How might it be explained? One explanation is via Divine creation. Another is that we are “brains-in-vats” living in a virtual reality world dreamt up by some quirky scientist (cf The Matrix). But neither of these explanations really reduces the complexity, since in each case we need to appeal to a thing (God, the scientist) that already has representational capacities. A simpler explanation, allegedly, is that we are the product of natural selection and having accurate representations is selected for. This is certainly a novel argument for Darwinism. It isn’t why they teach natural selection to biology students. And of course it has flaws. Peacocke does little to show that there are no better explanations of our having representations. Nor does he address the question of how complicated hereditary mechanisms must be if they are to support natural selection. Arguably they are much more complicated than is needed for representation, so Darwin doesn’t help reduce complexity here.\nSo it’s not clear Peacocke’s rationalism can get past step one; but let’s see what would happen next. To go beyond particular perceptions, in acquiring knowledge, we need induction. Peacocke takes the basic form of enumerative induction to be the (defeasible) inference from All the (many and varied) observed Fs have been Gs to All Fs are Gs. The observation of only Gs, and no non-Gs, amongst these many and varied Fs is a complex fact, and its best (ie simplest) explanation is sometimes that all the Fs are Gs. Peacocke argues that in these cases this explanation is the a priori justification of the transition, and in only these cases is the transition justified; he concludes that induction is acceptable by rationalist lights.\nThe chapter on induction is only fifteen pages long, and it really needs to be much longer. Peacocke sets out the position just outlined, and compares it in some detail to a similar position advocated by Gilbert Harman, and that’s it. There is no discussion of what we do when most, rather than all, the observed Fs have been Gs, even though that’s surely the more important practical case. There’s no discussion of the case that’s frequently central to modern discussions on induction—the case in which a certain (stable) ratio of the Fs are Gs. Peacocke only talks about the special case when all Fs are Gs, and it isn’t obvious that the discussion generalizes. There is no discussion of rationalist alternatives, such as Keynes’s justification of enumerative induction in terms of analogical inference, or D. C. Williams’s probabilistic defence of induction. And there’s no discussion of empiricist attempts to justify induction a posteriori, or to do without it. Even if Peacocke’s suggested justification works, and it is at least a serious contender, a persuasive treatment of induction should have dealt with at least some of these points.\nThe final two chapters discuss moral beliefs. Again, Peacocke thinks that all the inferences we make in order to get from our perceptual beliefs to our moral beliefs can be justified a priori. His view is that we can come to know a priori some moral principles. And we can know contingent moral facts, such as that someone’s giving £1000 to Oxfam is morally praiseworthy, by carrying out the following inference. The person, say Joe, helped other people in need. (We learn this by experience.) Helping those in need is morally praiseworthy. (We learn this moral principle by deploying our reason.) Hence what Joe did is morally praiseworthy. But there’s a problem here, and Peacocke never fully addresses it. It’s only prima facie true that helping those in need is morally praiseworthy. There are always exceptions to the principle. If Joe’s children starved to death because that donation was the last money Joe had to buy them food, the donation wasn’t morally praiseworthy. Moreover, it is just about impossible to state the exceptions without using moral language. So it is far from clear how we are meant to come to know that this case is not one of the exceptions, because knowing this requires both empirical knowledge and moral sensitivity. From a “principleist” position like Peacocke’s, knowing this is not one of the exceptions seems just as hard as the original problem of coming to know that the action was praiseworthy. So it seems the rationalist still has work to do here.\nOne can easily get the feeling from this book that rationalism runs into problems as soon as we try to apply it to real-world cases. But it isn’t obvious these are deep problems with rationalism, and in particular it isn’t clear that the problems can’t be fixed with relatively minor adjustments. Even if there are difficulties in application throughout The Realm of Reason, there is a lot of important philosophical work going on beneath the surface. Peacocke’s best work is done in classifying the various types of rationalist position that are available, and motivating the kind of view he wants to defend. This material remains valuable, highly valuable to anyone wanting to draw a plausible rationalist picture, even if his real-world applications are not yet perfect."
  },
  {
    "objectID": "posts/prank/pranksters-ethics.html",
    "href": "posts/prank/pranksters-ethics.html",
    "title": "Prankster’s Ethics",
    "section": "",
    "text": "0.1 A Quick Argument for Boorishness\nDiversity is a good thing. Some of its value is instrumental. Having people around with diverse beliefs, or customs, or tastes, can expand our horizons and potentially raise to salience some potential true beliefs, useful customs or apt tastes. Even diversity of error can be useful. Seeing other people fall away from the true and the useful in distinctive ways can immunise us against similar errors. And there are a variety of pleasant interactions, not least philosophical exchange, that wouldn’t be possible unless some kinds of diversity existed. Diversity may also have intrinsic value. It may be that a society with diverse views, customs and tastes is simply thereby a better society. But we will mostly focus on diversity’s instrumental value here.\n\nPublished in Philosophical Perspectives 18: 45-52.\n\nWe think that what is true of these common types of diversity is also true of moral diversity. By moral diversity we mean not only diversity of moral views, though that is no doubt valuable, but diversity of moral behaviour. In a morally diverse society, at least some people will not conform as tightly to moral norms as others. In short, there will be some wrongdoers. To be sure, moral diversity has some costs, and too much of it is undoubtedly a bad thing. Having rapists and murderers adds to moral diversity (assuming, as we do, that most people are basically moral) but not in a way that is particularly valuable. Still, smaller amounts of moral diversity may be valuable, all things considered. It seems particularly clear that moral diversity within a subgroup has value, but sometimes society as a whole is better off for being morally diverse. Let us consider some examples.\nMany violations of etiquette are not moral transgressions. Eating asparagus spears with one’s fork is not sinful, just poor form. But more extreme violations may be sinful. Hurtful use of racial epithets, for example, is clearly immoral as well as a breach of etiquette. Even use of language that causes not hurt, but strong discomfort, may be morally wrong. Someone who uses an offensive term in polite company, say at a dinner party or in a professional philosophical forum, may be doing the wrong thing. But having the wrongdoer around may have valuable consequences. For example, they generate stories that can be told, to great amusement, at subsequent dinner parties. They also prompt us to reconsider the basis for the standards we ourselves adopt in such matters. The reconsideration may cause us to abandon useless practices, and it may reinforce useful practices. These benefits seem to outweigh the disutility of the discomfort felt by those in attendance when the fateful word drops from the speaker’s lips. These side benefits do not make the original action morally permissible. Indeed, it is precisely because the action is not morally permissible that the benefits accrue.\nWhile we think that case is one of valuable moral diversity, some may question the immorality of the act in question. So let us try a more clearly immoral case: the mostly harmless prankster. Sam is a pie-thrower. Sam doesn’t just throw pies at the rich and infamous. No, Sam’s pies land on common folk like you and I, often for no reason beyond Sam’s amusement. Causing gratuitous harm for one’s own amusement is immoral. And a pie in the face, while better than a poke in the eye with a burnt stick, is harmful. But it may, in some circumstances, have side benefits. There will be the (guilty) pleasure occasioned in the unharmed bystanders, though it would be wrong to put too much weight on that. Other more significant benefits may accrue if Sam’s society is otherwise saintly. Sam’s existence will prompt people to take some simple, and worthwhile, precautions against perpetrators of such attacks. Even if society currently contains no malfeasants, such precautions will be useful against future wrongdoers. This benefit will increase if Sam graduates from pie-throwing to more varied pranks. (As may the entertainment value of Sam’s pranks.) Many computer hackers perform just this function in the present world. Malicious hackers on the whole cause more harm than good. But other hackers, who hack without gratuitously harming, provide a protective benefit by informing us of our weaknesses. These are the pie-throwers of the virtual world. Sam’s actions have other benefits. If Sam’s pranks are harmless enough, some will mistakenly think that they are morally acceptable, and we can have enjoyable, valuable, philosophical discussions with them. (Note that this benefit also increases if Sam varies the pranks.) The upshot is that Sam’s pranks can make the world a better place, all things considered, despite being immoral. Indeed, in some ways they make the world a better place because they are immoral.\nThe philosophical point, or points, here may be familiar. One point certainly is familiar: we have here an example of a Moorean organic unity. The goodness of the whole is no simple function of the goodness of the parts. It might be thought that this follows simply from the familiar counterexamples to utilitarianism, and that our examples have no more philosophical interest than those old counterexamples. Both of these thoughts would be mistaken.\nThe familiar counterexamples we have in mind include, for example, the case of the doctor who kills a healthy patient to harvest her organs, or the judge who executes an innocent man to prevent a riot. Importantly, those examples do not refute consequentialism in general, but only a version of consequentialism that adopts a particular kind of reductive analysis of the good. The details of the analysis won’t matter here, but it may be an analysis of goodness in terms on happiness, or preference satisfaction. If we give up the reductive analysis of goodness, we can say that the doctor and the judge do not make for a better society. A familiar heuristic supports that claim. (We take no stand here on whether this heuristic can be turned into an analysis.) Behind the Rawlsian veil of ignorance, we would prefer that there not be such doctors or judges in society. We think that most of us would agree, even in full appreciation of the possibility that we will be saved by the doctor, or possibly the judge. On the other hand, we think we’d prefer a society with the occasional boorish dinner guest, or a rare pie-thrower, to a society of moral saints. We say this in full appreciation of the possibility that we may get a pie in the face for our troubles. Possibly if we knew we would be the pie-throwee we would change our minds, but fortunately pies cannot penetrate the veil of ignorance.\nAlthough it isn’t much discussed in the literature, we think this form of consequentialism is interesting for several reasons beyond its capacity to avoid counterexamples. For one thing, it is not easy to say whether this counts as an agent-neutral ethical theory. On the one hand, we can say what everyone should do in neutral terms: for each person it is better if they do things that create a better world from the perspective of those behind the veil of ignorance. On the other hand this rule leads to obligations on agents that do not seem at all neutral. From behind the veil of ignorance we’d prefer that parents love their children and hence privilege their interests, and that they love them because they are their children not because this creates a better world, so parents end up with a special obligation to their children. Having this much (or more importantly this little) neutrality in a moral theory sounds quite plausible to us, and although we won’t develop the point here there is possibly an attractive answer to the ‘nearest and dearest’ objection to consequentialism (Jackson 1991). More generally, because we have preferences from behind the veil of ignorance about why people act and not just about how they act – we prefer for instance that people visit sick friends in hospital because they are friends not because of an abstract sense of duty – this form of consequentialism is not particularly vulnerable to objections that claim consequentialists pay too little attention to motives.\nSo we think a consequentialist can avoid the standard objections to utilitarianism by being less ambitious and not trying to provide a reductive analysis of goodness. The most natural retreat is to behind the veil of ignorance, but our examples can reach even there. This is far from the only interesting consequence of the examples.\n\n\n0.2 The Good, the Right, and the Saintly\nWe think that the cases of the curser and the pie-thrower are examples of situations in which (a) an agent ought not to \\(\\varphi\\), and (b) it’s best that the agent does \\(\\varphi\\). Our judgements about the cases are not based on any theoretical analysis of the right and the good. They’re simply intuitions about cases—it just seems to us that the right thing to say about the pie thrower is that she ought not to do what she does, but that it’s still best if she does it. To the extent that these intuitions are puzzling or theoretically problematic (and we think that they are at least a little bit puzzling, and at least potentially problematic), it’s open to us to reject one or the other intuition about the cases, and either deny that the curser and the pie thrower ought not to curse or throw pies, or deny that it’s best that they do curse and throw pies. This is an option, but we think it’s not a very attractive one. Suppose that instead we take the intuitions at face value, and accept our judgements about the cases. What follows?\nOur analysis of the examples is incompatible with two attractive views about the connection between goodness (that is, the property of things—in particular worlds—in virtue of which some of them stand in the better than relation to others) and rightness, and between goodness and good character:\n\nIt’s better if everyone does what’s right.\nIt’s better if everyone has good character.1\n\n1 Proposition (2) is quite a natural position to hold if one is trying to capture the insights of virtue ethics in a consequentialist framework, as in Driver (2001) or Hurka (2001). But if we take ‘better’ in a more neutral way, so (2) does not mean that there are better consequences if everyone has good character, but simply that the world is a better place if this is so, even if this has few consequences, or even negative consequences, then it will be a position common to most virtue ethicists.Now, neither of these will do as a philosophical thesis. But it’s probably not worth spending the time and effort on patching them up, since even the patched-up versions will be false.\nIf the pie-thrower ought not to throw her pies, but it’s nonetheless best that she does, no patched-up version of (1) that captures the intuition behind it can be right. Any patched-up version of (1) will still be claiming that there’s a very tight connection between what it would be right for us to do (what we ought to do) and what it would be best for us to do. Any plausible elaboration on (1) will include a commitment to the thesis that, if we ought not to do something, then it’s best if we don’t do it. But if our analyses of the cases of the curser and the pie-thrower are right, then these are counterexamples.\nWhat about (2)? Well, it’s not better if the cursing dinner guest has good character. What happens if we suppose that the curser does have good character? One of two things: (i) He’ll no longer curse at dinner parties, and we’ll lose the benefits that come from his cursing. This would be bad. (ii) He’ll still curse at dinner parties, but he’ll be cursing in a studied way. He’ll be cursing because he’s seen that things will be better if somebody uses foul language in inappropriate circumstances, and he’s taken it upon himself to fill the unfilled functional role. This would also be bad. This sort of studied bad conduct doesn’t have the same value as bad conduct that springs from bad character. Here is some evidence for this: We value the curser’s breaching of societal norms, even though he ought not to do it. Were we to find out that every expletive had been studied, produced either to produce these important social goods, or to create a familiar bad-boy image, we would stop valuing his breachings of the moral order. They would, instead, become merely tiresome and annoying. Since we value spontaneous cursings which are products of less-than-optimal character, but we do not value studied cursings which are products of exemplary character, it’s very plausible to conclude (though admittedly not quite mandatory) that the spontaneous curses are much more valuable than the studied ones. We’re inclined to say, in fact, that while having a few spontaneous cursers around makes things better, having studied cursers around makes things worse. Since you have to have less-than-perfect character in order to be a spontaneous curser, it follows that you can’t get the benefits of having cursers around without having some people with less-than-perfect character around. And since it’s better to have the cursers than not, it’s better to have some people with less-than-perfect character around than not. This will be incompatible with almost any plausible way of cashing out (2).2\n2 Specifically, it will be incompatible with any maximizing version of (2). There are ‘threshold’ versions of (2) that don’t fall afoul of this kind of problem because they don’t claim it would be best for everyone to have perfect character, but only that it would be best for everyone to have pretty good character, or at least for nobody to have really bad character.\n\n0.3 A Problem about Quantifier Scope?\nBut isn’t there a sense in which (for example) the pie-thrower ought to throw his pies? After all, if nobody was throwing pies, we might think to ourselves, “gosh, it would be better if there were a few—not many, but a few—pie throwers around”. Then it would be natural to conclude, “somebody ought to start throwing pies at strangers”. And then it would be natural to infer that at least the first person to start throwing pies at strangers would be doing what they ought. It would be natural, but it would be wrong. The plausible reading of “someone ought to start throwing pies at strangers” is, “it ought to be that somebody starts throwing pies at strangers”, not, “there’s somebody out there such that they ought to start throwing pies at strangers”. So we haven’t gotten anybody a moral license to throw pies yet. And in fact it’s very plausible that we ought to understand assertions that it ought to be that P as claiming that it would be better if it were the case that P; that is, as making claims about what would be good, not about what would be right.\nThere’s a puzzle about what to make of cases where we’re inclined to say that it ought to be that somebody \\(\\varphi\\)s—that is, that somebody ought to \\(\\varphi\\); but also that there’s nobody such that they ought to \\(\\varphi\\)—in fact, that everybody is such that they ought not to \\(\\varphi\\).3 Maybe the fact that our intuitions about the examples give rise to these kinds of puzzling cases is evidence that one or the other of our intuitions ought to be rejected. The move we suggested above is that the reason this seems so puzzling is that we’ve been punning on “ought”. The “ought” in “somebody ought to start throwing pies” doesn’t have anything much to do with what moral obligations anybody has—doesn’t have anything much to do with what’s right—but has a great deal to do with what’s good. And if that’s the case, then all we have is more evidence against the tight connection between the right and the good: it would be better if somebody started throwing pies, but everybody has a moral obligation not to. So it would be better if somebody did what they oughtn’t.\n3 It’s actually the second part that makes it puzzling. Compare the familiar and unproblematic situation in which we ought to give you a horse, but there’s no horse such that we ought to give you that one, and the more troubling situation in which we ought to give you a horse, but every horse is such that we ought not to give you that one.\n\n0.4 Value, Desire and Advice\nAlthough the “ought” in “somebody ought to throw pies” has little to do with what’s right, it might have a lot to do with what we find desirable. And this will cause problems for some familiar meta-ethical theories. Quite naturally, Jack does not desire to throw pies at strangers for amusement in the actual world. Jack’s a very civic minded fellow in that respect. In fact, his concern for others goes deeper than that. He’d be quite prepared to risk his body for the sake of his fellow citizens. As it turns out, he’s been a volunteer fire fighter for years now. And Jack likes to think that if need be, he would be prepared, to use an old fashioned phrase, to risk his soul for the community. He hopes he would be morally depraved if what the society needed was depravity. Jack agrees with the discussion of character in section 2, so he hopes that when society needs a pie-thrower, he will step up with the plate, and do so directly because he wants to throw pies at innocent bystanders. Letting C stand for the circumstances described above, where it would be good for there to be more wrongdoing, Jack’s position can be summarised by saying that he desires that in C he desires that he throws pies at innocents.\nDoes this all mean Jack values his throwing pies at innocents in C? Not necessarily. Does it mean that if we were all like Jack, and we are subjectivists about what is right, it would be right to throw pies at innocents in C? Definitely not. David Lewis (1989) equates what we value with what we desire to desire.4 And he equates what is valuable with what we value. The text is not transparent, but it seems Lewis wants valuable to subsume both what we call the ‘right’ and the ‘good’. And this he cannot have. Assume that everyone in Jack’s community desires to (de se) desire that (s)he throw pies at innocents in C. That does not make it right that pies are thrown at innocents. We take no stand here on whether the flaw is in the equation of personal value with second-order desire, or in the reduction of both rightness and goodness to personal value, but there is a problem for Lewis’s dispositional theory of value.5\n4 More precisely, with what we desire to desire in circumstances of appropriate imaginative acquaintance. We can suppose that Jack, and everyone else under discussion in this paragraph, is suitably imaginatively acquainted with the salient situations. Jack knows full well what it is like to get a pie in the face.5 Someone might think it obvious that Lewisian value can’t be used in an analysis of both rightness and goodness, since it is one concept and we are analysing two concepts. But Lewisian value bifurcates in a way that one might think it is suitable for analysing both rightness and goodness. Since there are both de dicto and de se desires, one can easily draw out both de dicto and de se values. And it is prima facie plausible that the de dicto values correspond to what is good, and the de se values to what is right. Indeed, given a weak version of consequentialism where these two can be guaranteed to not directly conflict, this correspondence may well hold. But we think the pie-thrower threatens even those consequentialists. The net philosophical conclusion is that the pie-thrower is a problem for Lewis’s meta-ethics, but only because (a) she is a problem for Lewis’s consequentialism, and, surprisingly, (b) Lewis’s meta-ethics depends on his consequentialism being at least roughly right.6 We have glossed over a technical point here that is irrelevant to the current discussion. What matters is not whether our perfectly rational selves are motivated to \\(\\varphi\\), it matters whether they desire that we \\(\\varphi\\), and hence whether they are motivated to advise us to \\(\\varphi\\). Keeping this point clear matters for all sorts of purposes, but not we think the present one.This point generalises to cause difficulties for several dispositional theories of value. For example, Michael Smith (1994) holds that right actions are what our perfectly rational selves would advise us to do. This assumes that when the good and the right come apart, our perfectly rational selves would choose the right over the good. And it’s far from clear that Smith has the resources to argue for this assumption. Smith’s argument that our perfectly rational selves will advise us to do what is right relies on his earlier argument that anyone who does not do what she judges to be right is practically irrational, unlike presumably our perfectly rational selves. And the main argument for that principle is that it is the best explanation of why actually good people are motivated to do what they judge to be right, even when they change their judgements about what is right. But now we should be able to see that there’s an alternative explanation available. Actually good people might be motivated to do what they judge to be good rather than right. We have seen no reason to believe that the right and the good actually come radically apart, so this is just as good an explanation of the behaviour actual moral agents as Smith’s explanation. So for all Smith has argued, one might judge \\(\\varphi\\)ing to be right, also judge it not to be good, hence be not motivated to \\(\\varphi\\), and not be practically irrational. Indeed, our perfectly rational self might be just like this.6 Hence we cannot rely on our perfectly rational self to be a barometer of what is right, as opposed to what is good.\n\n\n\n\n\n\nReferences\n\nDriver, Julia. 2001. Uneasy Virtues. Cambridge: Cambridge University Press.\n\n\nHurka, Thomas. 2001. “Vices as Higher-Level Evils.” Utilitas 13 (2): 195–212. https://doi.org/10.1017/s0953820800003137.\n\n\nJackson, Frank. 1991. “Decision Theoretic Consequentialism and the Nearest and Dearest Objection.” Ethics 101 (3): 461–82. https://doi.org/10.1086/293312.\n\n\nLewis, David. 1989. “Dispositional Theories of Value.” Aristotelian Society Supplementary Volume 63 (1): 113–37. https://doi.org/10.1093/aristoteliansupp/63.1.89.\n\n\nSmith, Michael. 1994. The Moral Problem. Oxford: Blackwell."
  },
  {
    "objectID": "posts/ieg/interests-evidence-and-games.html",
    "href": "posts/ieg/interests-evidence-and-games.html",
    "title": "Interests, Evidence and Games",
    "section": "",
    "text": "Pragmatic encroachment theories have a problem with evidence. On the one hand, the arguments that knowledge is interest-relative look like they will generalise to show that evidence too is interest-relative. On the other hand, our best story of how interests affect knowledge presupposes an interest-invariant notion of evidence.\n\nPublished in Episteme 15: 329-344.\nImage by Paul Wordingham via Creative Commons.\n\nThe aim of this paper is to sketch a theory of evidence that is interest-relative, but which allows that ‘best story’ to go through with minimal changes. The core idea is that the evidence someone has is just what evidence a radical interpreter says they have. And a radical interpreter is playing a kind of game with the person they are interpreting. The cases that pose problems for pragmatic encroachment theorists generate fascinating games between the interpreter and the interpretee. They are games with multiple equilibria. To resolve them we need to detour into the theory of equilibrium selection. I’ll argue that the theory we need is the theory of risk-dominant equilibria. That theory will tell us how the interpreter will play the game, which in turn will tell us what evidence the person has. The evidence will be interest-relative, because what the equilibrium of the game is will be interest-relative. But it will not undermine the story we tell about how interests usually affect knowledge.\n\n0.1 Encroachment, Reduction and Explanation\nI will start with an argument for a familiar disjunctive conclusion: either knowledge is interest-relative, or scepticism is true. The argument will resemble arguments to the same disjunctive conclusion in Hawthorne (2004) and Fantl and McGrath (2009). Indeed, it is inspired by those discussions. But it uses less controversial premises than previous versions.\nThe argument starts by considering a game, one I’ll call the red-blue game. Here are the rules of the game.\n\nTwo sentences will be written on the board, one in red, one in blue.\nThe player will make two choices.\nFirst, they will pick a colour, red or blue.\nSecond, they say whether the sentence in that colour is true or false.\nIf they are right, they win. If not, they lose.\nIf they win, they get $50, and if they lose, they get nothing.\n\nOur player is Parveen. She is an epistemologist who works on pragmatic encroachment, and (as will become important in a minute), she has frequently cited both Knowledge and Lotteries  (Hawthorne 2004), and Knowledge and Practical Interests  (Stanley 2005). She knows the rules of the game, and no other relevant facts about the game. When the game starts, the following two sentences are written on the board, the first in red, the second in blue.\n\nTwo plus two equals four.\nKnowledge and Lotteries was published before Knowledge and Practical Interests.\n\nIntuitively, there is a unique rational play in this game: Red-True. That is, Parveen announces that she will evaluate the truth value of the red sentence, and then announce that it’s true. That’s a sure $50.\nOn the other hand, in normal circumstances, we would say that Parveen does know that Knowledge and Lotteries was published before Knowledge and Practical Interests. After all, she has looked up their publication dates many times in checking over her papers.\nThere is a puzzle in reconciling these intuitions. The pragmatic encroachment theorist has a solution to these puzzles. In normal circumstances, Parveen does know that Knowledge and Lotteries was published before Knowledge and Practical Interests. But these are not normal circumstances. Right now, it matters whether her reason to believe that Knowledge and Lotteries was published before Knowledge and Practical Interests is as strong as her reason to believe that two plus two equals four. And (unless something very weird is happening), that isn’t true for Parveen. So she knows that red-true will win, she doesn’t know any other play will win, so she should play Red-True.\nIf we reject pragmatic encroachment, and we are not sceptics, we should say that Parveen does know that Knowledge and Lotteries was published before Knowledge and Practical Interests. And then it is a mystery why playing Red-True is more rational than playing Blue-True. After all, Parveen knows the rules of the game, and she knows (by hypothesis) the blue sentence is true, so if she can do even basic logical reasoning in a knowledge preserving way, she knows she will get as good a result as possible by playing Blue-True. So it is a bit of a mystery why it would be anything other than maximally rational to play Blue-True.\nOne way we might try to resolve this mystery is by saying that although Parveen knows that Blue-True will win $50, she super-knows that Red-True will win $50. What do we mean here by super knowledge? Think of this as a placeholder for certainty, or knowledge that one knows, or anything other epistemic state that you think might be relevant to her practical decision making. Perhaps the fact that she super-knows what two plus two is, but doesn’t super-know when the epistemology books were published, could be the explanation for why Red-True is the unique rational play.1\n1 That we need some kind of super-knowledge for action, and not mere knowledge, is a popular, and natural, explanation of the case. For versions of this explanation, obviously with more details than I’ve given here, see for example Jessica Brown (2008) and Jennifer Lackey (2010).But no such explanation can work, because Parveen doesn’t super-know that playing Red-True will win $50. She super-knows that two plus two is four. But we have not assumed that she super-knows the rules of the game. So she doesn’t super-know that Red-True will win, she just knows it. And she also, by hypothesis, knows that Blue-True will win. So looking at any kind of super-knowledge can’t break the intuitive asymmetry between Red-True and Blue-True.\nPut another way, if Parveen knows that Knowledge and Lotteries was published before Knowledge and Practical Interests, then she knows that she is playing the following game.\n\nTwo sentences will be written on the board, one in red, one in blue.\nThe player chooses to play either Blue-True, Blue-False, Red-True, or Red-False.\nIf they play Blue-True, they win $50.\nIf they play Blue-False, they win nothing.\nIf they play Red-True, they win $50 if the red sentence is true, and nothing otherwise.\nIf they play Red-False, they win $50 if the red sentence is false, and nothing otherwise.\n\nAnd is is rational to play Blue-True in that game. (It might also be rational to pay Red-True depending on what the red sentence is, but it is always rational to play Blue-True.) Yet it is not rational to play Blue-True in the original game. So Parveen does not know, when she plays the original game, that Knowledge and Lotteries was published before Knowledge and Practical Interests.\nSo to avoid pragmatic encroachment here we must deny that Parveen ever knew that Knowledge and Lotteries was published before Knowledge and Practical Interests. On its own, that’s not a sceptical conclusion: lots of people don’t know that. But once we go down that path, it looks like not much knowledge will be left. After all, we can repeat the game with any number of different things in the place of the blue sentence. If we adopt the constraint that Parveen only knows p, right now, if it is rationally permissible for her to play Blue-True when p is the blue sentence, no matter what the red sentence is, then either we have to say very unintuitive things about rational plays of the game, or we have to say she knows very little.\nSo we’ve got the conclusion that either pragmatic encroachment is true, or scepticism is true. Since I’m not a sceptic, I’m happy to conclude that pragmatic encroachment is true. But note that we’ve done this without any reference to high stakes situations. The stakes in Parveen’s game are just $50. That’s not nothing, but it’s not ‘high stakes’ in the way that phrase is normally used.\nThe version of pragmatic encroachment we get is that what matters for knowledge are not the stakes involved in any bet on p, but the odds.2 Parveen loses knowledge because she is being asked, in effect, to make a super long odds bet on a fact about publication schedules. She is in no position to rationally make a bet at those odds. So she doesn’t know the fact about publication schedules.\n2 Jessica Brown (2008, 176) shows that pragmatic encroachment theories that rely just on the stakes involved are subject to serious counterexample. Katherine Rubin (2015) argues that if we have a ‘global’ version of pragmatic encroachment, where all our epistemic notions are interest-relative, then it is implausible that it is the stakes the subject faces that matter for knowledge. Since I’m defending such a global version of pragmatic encroachment, Rubin’s arguments show that it is important that I’m relying on odds, not stakes. Baron Reed (2014) argues that if it is stakes alone that matter to pragmatic encroachment, then agents who the pragmatic encroachment theorist takes to be perfectly rational would be subject to a Dutch Book.And that’s the general principle: agents only know a proposition if they are in a position to rationally bet on that proposition at the odds currently being offered to them. In practice, high stakes situations tend to feature bets at long odds, so in practice much knowledge dissipates in high stakes cases. But the explanation of the dissipation is the odds the agent faces, not the stakes.\nMore precisely, I endorse these principles as constraints on knowledge:\n\nIf the agent knows that p, then for any question they have an interest in, the answer to that question is identical to the answer to that question conditional on p.\nWhen an agent is considering the choice between two options, the question of which option has a higher expected utility given their evidence is a question they have an interest in.\n\nThose principles are meant to not merely be extensionally adequate. They are meant to explain why agents lose knowledge when considering some sets of options, like in the Red-Blue game. In some sense, they are meant to be part of reductive explanations. These reductive explanations take as primitive inputs facts about the agent’s evidence, and facts about evidential probability. I’m going to set aside worries about the metaphysics of evidential probability, and just focus on evidence. Because it turns out that there is a real problem in getting a plausible theory of evidence that can function as an input to that reductive explanation.\n\n\n0.2 The Problems with Evidence\nGo back to the red-blue game. Consider a version of the game where:\n\nThe red sentence is that two plus two equals four.\nThe blue sentence is something that, if known, would be part of the agent’s evidence.\n\nI’m going to argue that there are cases where the only rational play is Red-True, but the blue sentence is something we want to say that, ordinarily, the subject knows. And I’ll argue that this is a problem for the kind of reductive explanation I just sketched. If pragmatic effects matter to what the evidence is, we can’t take the evidence as a fixed input into an explanation of how and when pragmatic effects matter.\nLet’s have Parveen play the game again. She’s going to be playing the game in a restaurant, one in Ann Arbor where she lives. Just before the game starts, she notices an old friend, Rahul, across the room. Rahul is someone she knows well, and can ordinarily recognise, but she had no idea he was in town. She thought Rahul was living in Italy. Still, we would ordinarily say that she now knows Rahul is in the restaurant; indeed that he is in the restaurant. It would be perfectly acceptable for her to say to someone else, “I saw Rahul here”, for example. Now the game starts.\n\nThe red sentence is Two plus two equals four.\nThe blue sentence is Rahul is in this restaurant.\n\nNow we have a problem. On the one hand, there is only one rational play here: Red-True. If you haven’t seen someone for a long time, then you can’t be completely certain it’s them when you spot them across a restaurant. It would be foolish to be as confident that it’s Rahul as that two and two make four. It looks like this is a case where pragmatic effects defeat knowledge.\nOn the other hand, our story for why Parveen loses knowledge here has run into problems. I wanted to tell a story roughly like the following. She can’t play Blue-True when the probability of the blue sentence, given her evidence, is less than the probability of the red sentence, given her evidence. That explanation can only go through if the blue sentence is itself not part of her evidence, since the probability of anything given itself is one. So we need a story about how it is that it is not part of Parveen’s evidence that Rahul is not in the restaurant.\nThat story can’t be the one that presupposes facts about what is in Parveen’s evidence. So it can’t use facts about the probability of some proposition given her evidence; at least not in any simple way. If we can independently identify Parveen’s evidence, then we can go back to using evidential probability. But until we’ve done that, we’re stuck.\nThere are two options here that seem possible for the pragmatic encroachment theorist, but not particularly attractive.\nOne is to say that propositions like Rahul is in this restaurant are never part of Parveen’s evidence. Perhaps her evidence just consists of things like I am being appeared to Rahul-like. Such an approach is problematic for two reasons. The first is that it is subject to all the usual objections to psychological theories of evidence  (Williamson 2007). The second is that we can re-run the argument with the blue sentence being some claim about Parveen’s psychological state, and still get the result that the only rational play is Red-True. A retreat to a psychological conception of evidence will only help with this problem if agents are infallible judges of their own psychological states, and that is not in general true  (Schwitzgebel 2008).\nAnother option is to deny that a reductive explanation is needed here. Perhaps pragmatic effects, like the particular sentences that are chosen for this instance of the Red-Blue game, mean that Parveen’s evidence no longer includes facts about Rahul, but this isn’t something we can give a reductive account of. We shouldn’t assume that everything will have a simple reductive explanation, so this isn’t so bad in theory. The problem in practice is that without a reductive explanation, we don’t have a predictive theory of when pragmatic effects matter. And that seems to be a bad thing. For instance, the following theory is completely consistent with Parveen’s case as described.\n\nE=K; i.e., one’s evidence is all and only what one knows.\nSomeone does not know p if the evidential probability of p is not close enough to one for current purposes.\nSince it is part of Parveen’s evidence that Rahul is in the restaurant, the probability that he is there is one, so it is close enough to one for current purposes.\nSo this is not a case where pragmatic effects change what she knows.\n\nThat theory seems to me to be badly mistaken, since it goes on to predict that it is rationally permissible to play Blue-True. But we need a pragmatic account that says that it is mistaken, and says something about which alternative situations would not threaten Parveen’s knowledge. We don’t yet, as far as I can see, have such an account. The aim of the rest of this paper is to provide one.3\n3 You can read this paper as a reply to the challenge posed by Ichikawa, Jarvis, and Rubin (2012). They note that there are challenges facing the pragmatic encroachment theorist whether they make evidence interest-relative, or interest-invariant. I’m going to show how to have an interest-relative theory of evidence, and keep what was desirable about pragmatic encroachment theories.\n\n0.3 A Simple, but Unsatisfying, Solution\nLet’s take a step back and look at the puzzle more abstractly. We have an agent S, who has some option O, and it really matters whether or not the value of O, i.e., \\(V(O)\\) is at least \\(x\\). It is uncontroversial that the agent’s evidence includes some background \\(K\\), and controversial whether it includes some contested proposition \\(p\\). It is also uncontroversial that \\(V(O | p) \\geq x\\), and we’re assuming that for any proposition \\(q\\) that is in the agent’s evidence, \\(V(O | q) = V(O)\\). That is, we’re assuming the relevant values are conditional on evidence. We can capture that last assumption with one big assumption that probably isn’t true, but is a harmless idealisation for these purposes. Say there is a prior value function \\(V^-\\), with a similar metaphysical status to the mythical, mystical prior probability function. Then for any choice \\(C\\), \\(V(C) = V^-(C | E)\\), where \\(E\\) is the evidence the agent has.\nNow we’re in a position to state a simple, but unsatisfying, solution. Let \\(p\\) be the proposition that the agent might or might not know, and the question of whether \\(V(O) \\geq x\\) be the only salient one that \\(p\\) is relevant to. Then the agent knows \\(p\\) only if the following is true:\n\n\\(\\frac{V^-(O | K) + V^-(O | K \\wedge p)}{2} \\geq x\\)\n\nThat is, we work out the value of \\(O\\) with and without the evidence \\(p\\), and if the average is greater than \\(x\\), good enough!\nThat solves the problem of Parveen and Rahul. Parveen’s evidence may or may not include that Rahul is in the restaurant. If it does, then Blue-True has a value of $50. If it does not, then Blue-True’s value is somewhat lower. Even if the evidence includes that someone who looks a lot like Rahul is in the restaurant, the value of Blue-True might only be $45. Averaging them out, the value is less than $50. But you’d only play Blue-True if it was worthwhile it play it instead of Red-True, which is worth $50. So you shouldn’t play Blue-True.\nGreat! Well, great except for two monumental problems. The first problem is that what we’ve said here really only helps with very simple cases, where there is a single decision problem that a single contested proposition is relevant to. We need some way to generalise the case to less constrained situations. The second (and bigger) problem is that the solution is completely ad hoc. Why should we use the arithmetic mean of these two things rather than any other formula that would have implied the intuitively correct result in the Parveen-Rahul case? Pragmatic encroachment starts with a very elegant, very intuitive, principle: you only know the things you can reasonable take to be settled for the purposes of current deliberation. And that deliberation should be driven by the aim of maximising expected utility. It does not look like any such elegant, intuitive, principles will lead to some theorem about averaging out the value of an option with and without new evidence.\nHappily, the two problems have a common solution. But the solution requires a detour into some technical work. It’s time for some game theory.\n\n\n0.4 Gamifying the Problem\nWe can usefully think of some philosophical problems as games, and hence subjects for study using game theoretic techniques. This is especially when the problems involve interactions of rational agents. Here, for example, is the game table for Newcomb’s problem, with the human who is usually the focus of the problem as Row, and the demon as Column.4\n4 In these games, Row chooses a row, and Column chooses a column, and that determines the cell that is the outcome of the game. The cells include two numbers. The first is Row’s payout, and the second is Column’s. The games are non-competitive; the players are simply trying to maximise their own returns, not maximise the difference between their return and the other player’s return.\n\n\n\n\nPredict 1 Box\nPredict 2 Boxes\n\n\n\n\nChoose 1 Box\n1000, 1\n0,0\n\n\nChoose 2 Boxes\n1001, 0\n1, 1\n\n\n\n\nThis game has a unique Nash equilbrium; the bottom right corner.5 And that’s one way of motivating the view that (a) the game is possible, and (b) the rational move for the human is to choose two boxes.\n5 A Nash equilibrium is an outcome of the game where every player does as well as they can given the moves of the other players. Equivalently, it is an outcome where no player can improve their payout by unilaterally defecting from the equilibrium.6 The Radical Interpreter feels like they should be a humanesque character in Alice in Wonderland or The Phantom Tollbooth, but for now they are resolutely abstract.Let’s look at a more complicated game. I’ll call it The Interpretation Game. The game has two players. Just like in Newcomb’s problem, one of them is a human, the other is a philosophical invention. But in this case the invention is not a demon, but The Radical Interpreter.6 To know the payouts for the players, we need to know their value function. More colloquially, we need to know their goals.\n\nThe Radical Interpreter assigns mental states to Human in such a way as to predict Human’s actions given Human rationality. We’ll assume here that evidence is a mental state, so saying what evidence Human has is among Radical Interpreter’s tasks. (Indeed, in the game play to come, it will be their primary task.)\nHuman acts so as to maximise the expected utility of their action, conditional on the evidence that they have. Human doesn’t always know what evidence they have; it depends on what The Radical Interpreter says.\n\nThe result is that the game is a coordination game. The Radical Interpreter wants to assign evidence in a way that predicts rational Human action, and Human wants to do what’s rational given that assignment of evidence. Coordination games typically have multiple equilibria, and this one is no exception.\nLet’s make all that (marginally) more concrete. Human is offered a bet on p. If the bet wins, it wins 1 util; if the bet loses, it loses 100 utils. Human’s only choice is to Take or Decline the bet. The proposition p, the subject of the bet, is like the claim that Rahul is in the restaurant. It is something that is arguably part of Human’s evidence. Unfortunately, it is also arguable that it is not part of Human’s evidence. We will let \\(K\\) be the rest of Human’s evidence (apart from \\(p\\), and things entailed by \\(K \\cup \\{p\\}\\)), and stipulate that \\(\\Pr(p | K) = 0.9\\). Each party now faces a choice.\n\nThe Radical Interpreter has to choose whether p is part of Human’s evidence or not.\nHuman has to decide whether to Take or Decline the bet.\n\nThe Radical Interpreter achieves their goal if human takes the bet iff p is part of their evidence. If p is part of the evidence, then The Radical Interpreter thinks that the bet has positive expected utility, so Human will take it. And if p is not part of the evidence, then The Radical Interpreter thinks that the bet has negative expected utility, so Human will decline it. Either way, The Radical Interpreter wants Human’s action to coordinate with theirs. And Human, of course, wants to maximise expected utility. So we get the following table for the game.\n\n\n\n\n\n\\(p \\in E\\)\n\\(p \\notin E\\)\n\n\n\n\nTake the bet\n1, 1\n-9.1, 0\n\n\nDecline the bet\n0, 0\n0, 1\n\n\n\n\nWe have, in effect, already covered The Radical Interpreter’s payouts. They win in the top-left and lower-right quadrants, and lose otherwise. Human’s payouts are only a little trickier. In the bottom row, they are guaranteed 0, since the bet is declined. In the top-left, the bet is a sure winner; their evidence entails it wins. So they get a payout of 1. In the top-right, the bet wins with probability 0.9, so the expected return7 of taking it is \\(1 \\times 0.9 - 100 \\times 0.1 = -9.1\\).\n7 I am making a large, if orthodox, assumption here: that the payouts that we use for equilibrium analysis should be expected returns, not actual returns. I think that’s the right thing to do, since it is usually impossible to say what the actual return of a game is. Even when we say that the payout is a certain number of dollars, we are really saying that the return is a certain kind of gamble. Maybe the value of the currency will deprecate quickly, and the dollars are not that valuable. Maybe the revolution will come and wealth will be a liability. Almost all games have probabilistic payouts, and this game is no different.There are two Nash equilibria for the game - I’ve bolded them below.\n\n\n\n\n\n\\(p \\in E\\)\n\\(p \\notin E\\)\n\n\n\n\nTake the bet\n1, 1\n-9.1, 0\n\n\nDecline the bet\n0, 0\n0, 1\n\n\n\n\nThe mathematical result that there are two equilibria to this game should not come as a surprise. In discussing games like this earlier, we said that general principles connecting evidence, knowledge and action are not predictive; they are consistent both with p being part of the evidence, and with it not being part of the evidence. The general principles we had stated rule out, in effect, non-equilibrium solutions to games like this one. But they are not predictive in cases where there are multiple equilibria.\nTo make more progress, we need to turn to more contested areas of game theory. In particular, we need to look at some work on equilibrium choice. We’ll introduce this material via a game that is inspired by an example of Rousseau’s.\n\n\n0.5 Equilibrium Selection Principles\nAt an almost maximal level of abstraction, a two player, two option each game looks like this.\n\n\n\n\n\n\\(a\\)\n\\(b\\)\n\n\n\n\n\\(A\\)\n\\(r_{11}\\), \\(c_{11}\\)\n\\(r_{12}\\), \\(c_{12}\\)\n\n\n\\(B\\)\n\\(r_{21}\\), \\(c_{21}\\)\n\\(r_{22}\\), \\(c_{22}\\)\n\n\n\n\nWe’re going to focus on games that have the following eight properties:\n\n\\(r_{11} &gt; r_{21}\\)\n\\(r_{22} &gt; r_{12}\\)\n\\(c_{11} &gt; c_{12}\\)\n\\(c_{22} &gt; c_{21}\\)\n\\(r_{11} &gt; r_{22}\\)\n\\(c_{11} \\geq c_{22}\\)\n\\(\\frac{r_{21}+r_{22}}{2} &gt; \\frac{r_{11}+r_{12}}{2}\\)\n\\(\\frac{c_{12}+c_{22}}{2} \\geq \\frac{c_{11}+c_{21}}{2}\\)\n\nThe first four clauses say that the game has two (strict) Nash equilibria: \\(Aa\\) and \\(Bb\\). The fifth and sixth clauses say that the \\(Aa\\) equilibria is Pareto-optimal: no one prefers the other equilibria to it. In fact it says something a bit stronger: one of the players strictly prefers the \\(Aa\\) equilibria, and the other player does not prefer \\(Bb\\). The seventh and eighth clauses say that the \\(Bb\\) equilibria is risk-optimal. Risk-optimality is a somewhat complicated notion in general; see Harsanyi and Selten (1988) for more details. But for our purposes, we can focus on a simple characterisation of it. Neither player would prefer playing \\(A\\)/\\(a\\) to playing \\(B\\)/\\(b\\) if they thought it was a coin flip which equilibrium the other player was aiming for.\nI’m going to offer an argument from Hans Carlsson and Eric van Damme (1993) for the idea that in these games, rational players will end up at \\(Bb\\). The game that Human and The Radical Interpreter are playing fits these eight conditions, and The Radical Interpreter is perfectly rational, so this will imply that in that game, The Radical Interpreter will say that \\(p \\notin E\\), which is what we aimed to show.\nGames satisfying these eight inequalities are sometimes called Stag Hunt games. There is some flexibility, and some vagueness, in which of the eight inequalities need to be strict, but that level of detail isn’t important here. The name comes from a thought experiment in Rousseau’s Discourse on Inequality.\n\n[T]hey were perfect strangers to foresight, and were so far from troubling themselves about the distant future, that they hardly thought of the morrow. If a deer was to be taken, every one saw that, in order to succeed, he must abide faithfully by his post: but if a hare happened to come within the reach of any one of them, it is not to be doubted that he pursued it without scruple, and, having seized his prey, cared very little, if by so doing he caused his companions to miss theirs.  (Rousseau 1913, 209–10)\n\nIt is rather interesting to think through which real-life situations are best modeled as Stag Hunts, especially in situations where people have thought that the right model was a version of Prisoners’ Dilemma. This kind of thought is one way in to appreciating the virtues of Rousseau’s political outlook, and especially the idea that social coordination might not require anything like the heavy regulatory presence that, say, Hobbes thought was needed. But that’s a story for another day. What we’re going to be interested in is why Rousseau was right to think that a ‘stranger to foresight’, who is just focussing on this game, should take the rabbit.\nTo make matters a little easier, we’ll focus on a very particular instance of Stag Hunt, as shown here. (From here I’m following Carlsson and van Damme very closely; this is their example, with just the labelling slightly altered.)\n\n\n\n\n\n\\(a\\)\n\\(b\\)\n\n\n\n\n\\(A\\)\n4, 4\n0, 3\n\n\n\\(B\\)\n3, 0\n3, 3\n\n\n\n\nAt first glance it might seem like \\(Aa\\) is the right choice; it produces the best outcome. This isn’t like Prisoners Dilemma, where the best collective outcome is dominated. In fact \\(Aa\\) is the best outcome for each individual. But it is risky, and Carlsson and van Damme show how to turn that risk into an argument for choosing \\(Bb\\).\nEmbed this game in what they call a global game. We’ll start the game with each player knowing just that they will play a game with the following payout table, with \\(x\\) to be selected at random from a flat distribution over \\([-1, 5]\\).\n\n\n\n\n\n\\(a\\)\n\\(b\\)\n\n\n\n\n\\(A\\)\n4, 4\n0, x\n\n\n\\(B\\)\nx, 0\nx, x\n\n\n\n\nBefore they play the game, each player will get a noisy signal about the value of \\(x\\). There will be signals \\(s_R\\) and \\(s_C\\) chosen (independently) from a flat distribution over \\([x - 0.25, x + 0.25]\\), and shown to Row and Column respectively. So each player will know the value of \\(x\\) to within \\(\\frac{1}{4}\\), and know that the other player knows it to within \\(\\frac{1}{4}\\) as well. But this is a margin of error model, and in those models there is very little that is common knowledge. That, they argue, makes a huge difference.\nIn particular, they prove that iterated deletion of strictly dominated strategies (almost) removes all but one strategy pair.8 Each player will play \\(A\\)/\\(a\\) if the signal is greater than 2, and \\(B\\)/\\(b\\) otherwise.9 Surprisingly, this shows that players should play the risk-optimal strategy even when they know the other strategy is Pareto-optimal. When a player gets a signal in \\((2, 3.75)\\), then they know that \\(x &lt; 4\\), so \\(Bb\\) is the Pareto-optimal equilibrium. But the logic of the global game suggests the risk-dominant equilibrium is what to play.\n8 A sketch of the proof is in Appendix One.9 Strictly speaking, we can’t rule out various mixed strategies when the signal is precisely 2, but this makes little difference, since that occurs with probability 0.Carlsson and van Damme go on to show that many of the details of this case don’t matter. As long as (a) there is a margin of error in each side’s estimation of the payoffs, and (b) every choice is a dominant option in some version of the global game, then iterated deletion of strongly dominant strategies will lead to each player making the risk-dominant choice.\nI conclude from that that risk-dominant choices are rational in these games. There is a limit assumption involved here; what’s true for games with arbitrarily small margins of error is true for games with no margin of error. (We’ll come back to that assumption below.) And since The Radical Interpreter is rational, they will play the strategy that is not eliminated by deleting dominant strategies. That is, they will play the risk-dominant strategy.\nIn game with Human, the rational (i.e., risk-dominant) strategy for The Radical Interpreter is to say that \\(p \\notin E\\). And in the case of Parveen and Rahul, rational (i.e., risk-dominant) strategy for The Radical Interpreter is to say that it is not part of Parveen’s evidence that Rahul is in the restaurant. And this is an interest-relative theory of evidence; had Parveen been playing a different game, The Radical Interpreter would have said that it is part of Parveen’s evidence that Rahul was in the restaurant.\nAnd from this point we can say all the things we wanted to say about the case. If it is part of Parveen’s evidence that Rahul is in the restaurant, then she knows this. Conversely, if she knows it, then The Radical Interpreter would have said it is part of her evidence, so it is part of her evidence. Parveen will perform the action that maximises expected utility given her evidence. And she will lose knowledge when that disposition makes her do things that would be known to be sub-optimal if she didn’t lose knowledge.\nIn short, this model gives us a way to keep what was good about the pragmatic encroachment theory, while also allowing that evidence can be interest-relative. It does require a slightly more complex theory of rationality than we had previously used. Rather than just say that agents maximise evidential expected utility, we have to say that they play risk-dominant strategies in coordination games. But it turns out that this is little more than saying that they maximise evidential expected utility, and they expect others (at least perfectly rational abstract others) to do the same, and they expect those others to expect they will maximise expected utility, and so on.\n\n\n0.6 Objections and Replies\nWe’ll end the body of the paper with some objections that might be raised to this model. And then the appendix will contain proofs of a couple of the formal claims.\nObjection: The formal result of the previous section only goes through if we assume that the agents do not know precisely what the payoffs are in the game. We shouldn’t assume that what holds for arbitrarily small margins of error will hold in the limit, i.e., when they do know the payoffs.\nReply: If pushed, I would defend the use limit assumptions like this to resolve hard cases like Stag Hunt. But I don’t need that assumption here, What we really need is that Parveen doesn’t know precisely the probability of Rahul being in the restaurant given the rest of her evidence. Given that evidence is not luminous, as Williamson (2000) shows, this is a reasonable assumption. So the margin of error assumption that Carlsson and van Damme make is not, in our case, an assumption that merely makes the math easier; it is built into the case.\nObjection: Even if Parveen doesn’t know the payoffs precisely, The Radical Interpreter does. They are an idealisation, so they can be taken to be ideal.\nReply: It turns out that Carlsson and van Damme’s result doesn’t require that both parties are ignorant of the precise values of the payoffs. As long as one party doesn’t know the exact value of the payoff, the argument goes through. I prove this in Appendix Two.\nObjection: The formal argument requires that in the ‘global game’ there are values for \\(x\\) that make \\(A\\) the dominant choice. These cases serve as a base step for an inductive argument that follows. But in Parveen’s case, there is no such setting for \\(x\\), so the inductive argument can’t get going.\nReply: What matters is that there are values of \\(x\\) such that \\(A\\) is the strictly dominant choice, and Human (or Parveen) doesn’t know that they know that they know, etc., that those values are not actual. And that’s true in our case. For all Human (or Parveen) knows that they know that they know that they know…, the proposition in question is not part of their evidence under a maximally expansive verdict on The Radical Interpreter’s part. So the relevant cases are there in the model, even if for some high value of \\(n\\) they are known\\(^n\\) not to obtain.\nObjection: This model is much more complex than the simple motivation for pragmatic encroachment.\nReply: Sadly, this is true. I would like to have a simpler model, but I don’t know how to create one. The argument I gave earlier that our simple principles underdetermine what to say in cases like Parveen and Rahul’s seems fairly compelling. So more complexity will be needed, one way or another. I think paying this price in complexity is worth it overall, but I can see how some people might think otherwise.\nObjection: Change the case involving Human so that the bet loses 15 utils if p is false, rather than 100. Now the risk-dominant equilibrium is that Human takes the bet, and The Radical Interpreter says that p is part of Human’s evidence. But note that if it was clearly true that p was not part of Human’s evidence, then this would still be too risky a situation for them to know p. So whether it is possible that p is part of Human’s evidence matters.\nReply: This is all true, and it shows that the view I’m putting forward is incompatible with some programs in epistemology. In particular, it is incompatible with E=K, since the what it takes to be evidence on this story is slightly different from what it takes to be knowledge. I don’t think E=K is so intuitively obvious that this refutes the theory, but it is potentially a cost that I have to give it up.\nObjection: Carlsson and van Damme discuss one kind of global game. But there are other global games that have different equilibria. For instance, changing the method by which the noisy signal is selected would change the equilibrium of the global game. So this kind of argument can’t show that the risk-dominant equilibrium is the one true solution.\nReply: This is somewhat true. There are other ways of embedding the game involving Human and The Radical Interpreter in global games that lead to different outcomes. They are usually somewhat artificial; e.g., by having the signal be systematically biased in one way. But what really matters is the game where the error in Human’s knowledge of the payoffs is determined by their actual epistemic limitations. I think that will lead to something like the model we have here. But it is possible that the final result will differ a bit from what I have here, or (more likely) have some indeterminacy about just how interests interact with evidence and knowledge. The precise details are ultimately less important to me than whether we can provide a motivated story of how interests affect knowledge and evidence that does not presuppose we know what the agent’s evidence is. And the method I’ve outlined here shows that we can do that, even if we end up tinkering a bit with the details.\n\n\nAppendix One: Carlsson and van Damme’s Game\nTwo players, Row (or R) and Column (or C) will a version of the following game.\n\n\n\n\n\n\\(a\\)\n\\(b\\)\n\n\n\n\n\\(A\\)\n4, 4\n0, x\n\n\n\\(B\\)\nx, 0\nx, x\n\n\n\n\nThey won’t be told what \\(x\\) is, but they will get a noisy signal of \\(x\\), drawn from an even distribution over \\([x - 0.25, x + 0.25]\\). Call these signals \\(s_R\\) and \\(s_C\\). Each player must then choose \\(A\\), getting either 4 or 0 depending on the other player’s choice, or choose \\(B\\), getting \\(x\\) for sure.\nBefore getting the signal, the players must choose a strategy. A strategy is a function from signals to choices. Since the higher the signal is, the better it is to play \\(B\\), we can equate strategies with ‘tipping points’, where the player plays \\(B\\) if the signal is above the tipping point, and \\(A\\) below the tipping point. Strictly speaking, a tipping point will pick out not a strategy but an equivalence class of strategies, which differ in how they act if the signal is the tipping point. But since that happens with probability 0, the strategies in the equivalence class have the same expected return, and so we won’t aim to distinguish them.\nAlso, strictly speaking, there are strategies that are not tipping points, because they map signals onto probabilities of playing \\(A\\), where the probability decreases as \\(A\\) rises. I won’t discuss these directly, but it isn’t too hard to see how these are shown to be suboptimal using the argument that is about to come. It eases exposition to focus on the pure strategies, and to equate these with tipping points. And since my primary aim here is to explain why the result holds, not to simply repeat an already existing proof, I’ll mostly ignore these mixed strategies.\nCall the tipping points for Row and Column respectively \\(T_R\\) and \\(T_C\\). Since the game is symmetric, we’ll just have to show that in conditions of common knowledge of rationality, \\(T_R = 2\\). It follows by symmetry that \\(T_C = 2\\) as well. And the only rule we’ll use is iterated deletion of strictly dominated strategies. That is, we’ll assume players won’t play strategies where another strategy does better no matter what the opponent chooses, and they won’t play strategies where another strategy does better provided the other player does not play a dominated strategy, and they won’t play strategies where another strategy does better provided the other player does not play a strategy ruled out by these first two conditions, and so on.\nThe return to a strategy is uncertain, even given the other player’s strategy. But given the strategies of each player, we can work out an expected return for each player. And that’s what we’ll assume is the return to a strategy pair.\nNote first that \\(T_R = 4.25\\) strictly dominates any strategy where \\(T_R = y &gt; 4.25\\). If \\(s_R \\in (4.25, y)\\), then \\(T_R\\) is guaranteed to return above 4, and the alternative strategy is guaranteed to return 4. In all other cases, the strategies have the same return. And there is some chance that \\(s_R \\in (4.25, y)\\). So we can delete all strategies \\(T_R = y &gt; 4.25\\), and similarly all strategies \\(T_C = y &gt; 4.25\\). By similar reasoning, we can rule out \\(T_R &lt; -0.25\\) and \\(T_C &lt; -0.25\\).\nIf \\(s_R \\in [-0.75, 4.75]\\), then it is equally likely that \\(x\\) is above \\(s_R\\) as it is below it. Indeed, the posterior distribution of \\(x\\) is flat over \\([s_R - 0.25, s_R + 0.25]\\). From this it follows that the expected return of playing \\(B\\) after seeing signal \\(s_R\\) is just \\(s_R\\).\nNow comes the important step. Assume that we know that \\(T_C \\leq y &gt; 2\\). Now consider the expected return of playing \\(A\\) given various values for \\(s_R &gt; 2\\). Given that the lower \\(T_C\\) is, the higher the expected return is of playing \\(A\\), we’ll just work on the simple case where \\(T_C = y\\), realizing that this is an upper bound on the expected return of \\(A\\) given \\(T_C \\leq y\\). The expected return of \\(A\\) is 4 times the probability that Column will play \\(a\\), i.e., 4 times the probability that \\(s_C &lt; T_C\\). Given all the symmetries that have been built into the puzzle, we know that the probability that \\(s_C &lt; s_R\\) is 0.5. So the expected return of playing \\(A\\) is at most 2 if \\(s_R \\geq y\\). But the expected return of playing \\(B\\) is, as we showed in the last paragraph, \\(s_R\\), which is greater than 2. So it is better to play \\(B\\) than \\(A\\) if \\(s_R \\geq y\\). And the difference is substantial, so even if \\(s_R\\) is epsilon less than that \\(y\\), it will still be better to play \\(B\\). (This is hand-wavy of course, but we’ll make it rigorous in just a second.)\nSo if \\(T_C \\leq y &gt; 2\\) we can prove that \\(T_R\\) should be lower still, because given that assumption it is better to play \\(B\\) even if the signal is just less than \\(y\\). Repeating this reasoning over and over again pushes us to it being better to play \\(B\\) than \\(A\\) as long as \\(s_R &gt; 2\\). And the same kind of reasoning from the opposite end pushes us to it being better to play \\(A\\) than \\(B\\) as long as \\(s_R &lt; 2\\). So we get \\(s_R = 2\\) as the uniquely rational solution to the game.\nLet’s make that a touch more rigorous. Assume that \\(T_C = y\\), and \\(s_r\\) is slightly less than \\(y\\). In particular, we’ll assume that \\(z = y - s_R\\) is in \\((0, 0.5)\\). Then the probability that \\(s_C &lt; y\\) is \\(0.5 + 2z - 2z^2\\). So the expected return of playing \\(A\\) is \\(2 + 8z - 8z^2\\). And the expected return of playing \\(B\\) is, again, \\(s_R\\). These will be equal when the following is true. (The working out is a tedious but trivial application of the quadratic formula, plus some rearranging.)\n\\[s_R = y + \\frac{\\sqrt{145-32y} - 9}{16}\\] So if we know that \\(T_C \\geq y\\), we know that \\(T_R \\geq y + \\frac{\\sqrt{145-32y} - 9}{16}\\), which will be less than \\(y\\) if \\(y &gt; 2\\). And then by symmetry, we know that \\(T_C\\) must be at most as large as that as well. And then we can use that fact to derive a further upper bound on \\(T_R\\) and hence on \\(T_C\\), and so on. And this will continue until we push both down to 2. It does require quite a number of steps of iterated deletion. Here is the upper bound on the threshold after \\(n\\) rounds of deletion of dominated strategies. (These numbers are precise for the first two rounds, then just to three significant figures after that.)\n\n\n\n\nRound\nUpper Bound on Threshold\n\n\n\n\n1\n4.250\n\n\n2\n3.875\n\n\n3\n3.599\n\n\n4\n3.378\n\n\n5\n3.195\n\n\n6\n3.041\n\n\n7\n2.910\n\n\n8\n2.798\n\n\n9\n2.701\n\n\n10\n2.617\n\n\n\n\nThat is, \\(T_R = 4.25\\) dominates any strategy with a tipping point above 4.25. And \\(T_R = 3.875\\) dominates any strategy with a higher tipping point than that, assuming \\(T_C \\leq 4.25\\). And \\(T_R \\approx 3.599\\) dominates any strategy with a higher tipping point than that, assuming \\(T_C \\leq 3.875\\). And so on.\nAnd similar reasoning shows that at each stage not only are all strategies with higher tipping points dominated, but so are strategies that assign positive probability (whether it is 1 or less than 1), to playing \\(A\\) when the signal is above the ‘tipping point’. So this kind of reasoning rules out all mixed strategies (except those that respond probabilistically to \\(s_R = 2\\)).\nSo we’ve shown what was intended, namely that iterated deletion of dominated strategies will rule out all strategies except the risk-optimal equilibrium. We needed the possibility that \\(x\\) is greater than the maximal return for \\(A\\) to get the iterated dominance going. And we needed the signal to have an error bar to it, so that each round of iteration removes more strategies. But that’s all we needed; the particular values we chose are irrelevant to the proof.\n\n\nAppendix Two: The Modified Game\nThe aim of this section is to prove something that Carllson and van Damme did not prove, namely that the analysis of the previous appendix goes through with very little change if one party gets a perfect signal, while the other gets a noisy signal. That is, we’re going to consider the game that is just like the game of appendix one, but it is common knowledge that the signal Column gets, \\(s_C\\), equals \\(x\\).\nSince the game is no longer symmetric, we can’t appeal to the symmetry of the game as we frequently did in the previous appendix. But this only slows the proof down, it doesn’t stop it.\nWe can actually rule out slightly more at the first step in this game than in the previous game. Since Column could not be wrong about \\(x\\), Column knows that if \\(s_C &gt; 4\\) then playing \\(b\\) dominates playing \\(a\\). So one round of deleting dominated strategies rules out \\(T_C &gt; 4\\), as well as ruling out \\(T_R &gt; 4.25\\).\nAt any stage, if we know \\(T_C \\leq y &gt; 2\\), then \\(T_R = y\\) dominates \\(T_R &gt; y\\). That’s because if \\(s_R \\geq y\\), and \\(T_C \\leq y\\), then the probability that Column will play \\(a\\) (given Row’s signal) is less than 0.5. After all, the signal is just as likely to be above \\(x\\) as below it (as long as the signal isn’t too close to the extremes). So if \\(s_R\\) is at or above \\(T_C\\), then it is at least 0.5 likely that \\(s_C = x\\) is at or above \\(T_C\\). So the expected return of playing \\(A\\) is at most 2. But the expected return of playing \\(B\\) equals the signal, which is greater than 2. So if Row knows \\(T_C \\leq y &gt; 2\\), Row also knows it is better to play \\(B\\) if \\(s_R \\geq y\\). And that just means that \\(T_R \\leq y\\).\nAssume now that it is common knowledge that \\(T_R \\leq y\\), for some \\(y &gt; 2\\). And assume that \\(x = s_C\\) is just a little less than \\(y\\). In particular, define \\(z = y -x\\), and assume \\(z \\in (0, 0.25)\\). We want to work out the upper bound on the expected return to Column of playing \\(a\\). (The return of playing \\(b\\) is known, it is \\(x\\).) The will be highest when \\(T_R\\) is lowest, so assume \\(T_R \\leq y\\). Then the probability that Row plays \\(A\\) is \\((1 + 2z)/2\\). So the expected return of playing \\(a\\) is \\(2 + 4z\\), i.e., \\(2 + 4(y - x)\\). That will be greater than \\(x\\) only when\n\\[x &lt; \\frac{2 + 4y}{5}\\] And so if it is common knowledge that \\(T_R \\leq y\\), then it is best for Column to play \\(b\\) unless \\(x &lt; \\frac{2 + 4y}{5}\\). That is, if it is common knowledge that \\(T_R \\leq y\\), then \\(T_C\\) must be at most \\(\\frac{2 + 4y}{5}\\).\nSo now we proceed in a zig-zag fashion. At one stage, we show that \\(T_R\\) must be as low as \\(T_C\\). At the next, we show that if it has been proven that \\(T_R\\) takes a particular value greater than 2, then \\(T_C\\) must be lower still. And this process will eventually rule out all values for \\(T_R\\) and \\(T_C\\) greater than 2.\nThis case is crucial to the story of the paper because The Radical Interpreter probably does not have an error bar in their estimation of the game they are playing. But it turns out the argument for risk-dominant equilibria being the unique solution to interpretation games is consistent with that. As long as one player has a margin of error, each player should play the risk-dominant equilibria.\n\n\n\n\n\n\nReferences\n\nBrown, Jessica. 2008. “Subject-Sensitive Invariantism and the Knowledge Norm for Practical Reasoning.” Noûs 42 (2): 167–89. https://doi.org/10.1111/j.1468-0068.2008.00677.x.\n\n\nCarlsson, Hans, and Eric van Damme. 1993. “Global Games and Equilibrium Selection.” Econometrica 61 (5): 989–1018. https://doi.org/10.2307/2951491.\n\n\nFantl, Jeremy, and Matthew McGrath. 2009. Knowledge in an Uncertain World. Oxford: Oxford University Press.\n\n\nHarsanyi, John C., and Reinhard Selten. 1988. A General Theory of Equilibrium Selection in Games. Cambridge, MA: MIT Press.\n\n\nHawthorne, John. 2004. Knowledge and Lotteries. Oxford: Oxford University Press.\n\n\nIchikawa, Jonathan Jenkins, Benjamin Jarvis, and Katherine Rubin. 2012. “Pragmatic Encroachment and Belief-Desire Psychology.” Analytic Philosophy 53 (4): 327–43. https://doi.org/10.1111/j.2153-960X.2012.00564.x.\n\n\nLackey, Jennifer. 2010. “Acting on Knowledge.” Philosophical Perspectives 24: 361–82. https://doi.org/10.1111/j.1520-8583.2010.00196.x.\n\n\nReed, Baron. 2014. “Practical Matters Do Not Affect Whether You Know.” In Contemporary Debates in Epistemology, edited by Matthias Steup, John Turri, and Ernest Sosa, 2nd ed., 95–106. Chicester: Wiley-Blackwell.\n\n\nRousseau, Jean-Jacques. 1913. Social Contract & Discourses. Translated by G. D. H. Cole. New York: J. M. Dent & Sons.\n\n\nRubin, Katherine. 2015. “Total Pragmatic Encroachment and Epistemic Permissiveness.” Pacific Philosophical Quarterly 96: 12–38. https://doi.org/10.1111/papq.12060.\n\n\nSchwitzgebel, Eric. 2008. “The Unreliability of Naive Introspection.” Philosophical Review 117 (2): 245–73. https://doi.org/10.1215/00318108-2007-037.\n\n\nStanley, Jason. 2005. Knowledge and Practical Interests. Oxford University Press.\n\n\nWilliamson, Timothy. 2000. Knowledge and its Limits. Oxford University Press.\n\n\n———. 2007. The Philosophy of Philosophy. Blackwell."
  },
  {
    "objectID": "posts/aca/index.html",
    "href": "posts/aca/index.html",
    "title": "In Defense of the ACA’s Medicaid Expansion",
    "section": "",
    "text": "1 Introduction\nThe only part of the Patient Protection and Affordable Care Act (hereafter, ‘the ACA’) struck down in National Federation of Independent Business (NFIB) et al. v. Sebelius, Secretary of Health and Human Services, et al. was a provision expanding Medicaid.1 We will argue that this was a mistake; the provision should not have been struck down. We’ll do this by identifying a test that C.J. Roberts used to justify his view that this provision was unconstitutional. We’ll defend that test against some objections raised by J. Ginsburg. We’ll then go on to argue that, properly applied, that test establishes the constitutionality of the Medicaid provision.\n1 567 U.S. ___ (2012), available at http://www.supremecourt.gov/opinions/11pdf/11--393c3a2.pdf.2 Jonathan Engel, Poor People’s Medicine: Medicaid and American Charity Care since 1965 (Durham, NC: Duke University Press, 2006), 48–51.To say just what the provision in question is, it will help to have before us the distinctive structure of Medicaid. Each state runs its own Medicaid program, with substantial financial support from the federal government. There are several conditions that a state Medicaid program must satisfy in order to qualify for this federal support, and which all fifty states do currently satisfy. In particular, there have always been minimum coverage requirements.2 Before the ACA, these minimum coverage requirements were a bit of a hodgepodge. As J. Ginsburg notes,\n\nTo receive federal Medicaid funds, States must provide health benefits to specified categories of needy persons, including pregnant women, children, parents, and adults with disabilities. Guaranteed eligibility varies by category: for some it is tied to the federal poverty level (incomes up to 100% or 133%); for others it depends on criteria such as eligibility for designated state or federal assistance programs.3\n3 NFIB v. Sebelius, 567 U.S. ___, Ginsburg, J., slip opin. at 38 (2012).\nThe ACA introduced a broad new category of Medicaid eligibility. It said that the states must extend Medicaid eligibility to pretty much anyone whose income is below 133% of the federal poverty level.4 In addition, it provided quite generous federal support for these newly eligible claimants: over 90% of the costs of covering these individuals would be reimbursed to the states by the federal government.5 (For other categories of claimants, the reimbursement rate is considerably lower.6) But importantly to NFIB v. Sebelius, the ACA made provision of Medicaid services to these newly eligible individuals a condition of continuing federal support. That is, if a state did not expand its Medicaid program to accommodate these newly eligible individuals, the ACA gave the Secretary of Health and Human Services the authority to withhold all of the Medicaid funds the state would otherwise be entitled to.7\n4 42 U.S.C. 1396a(a)(10)(A)(i)(VIII).5 42 U.S.C. 1396d(y)(1). More specifically, the ACA required the federal government to bear 100% of the costs of covering these newly eligible claimants through 2016. The level of federal support was then allowed to gradually decline, but to no lower than 90% of these costs.6 In fiscal year 2012, federal funds offset between 50 and approximately 74% of states’ costs of covering claimants eligible for Medicaid prior to the passage of the ACA. Kaiser Commission on Medicaid and the Uninsured, “An Overview of Changes in the Federal Medical Assistance Percentages (FMAPs) for Medicaid”, July 2011, available at http://www.kff.org/medicaid/upload/8210.pdf, 2.7 42 U.S.C. 1396c.It is this last provision that the Supreme Court found to be unconstitutional in the current case. By a margin of 7–2, the Court ruled that it was unconstitutional to make federal support for continuation of the old Medicaid program conditional on states’ participation in this expansion. We’re going to argue that that was a mistake. We’ll mostly focus on the opinion written by C.J. Roberts (and joined, in this respect, by J. Kagan and J. Breyer), and the dissent written by J. Ginsburg (and joined by J. Sotomayor).\nOur discussion in this paper takes place in a relatively constrained ideological space. Our aim is to argue against one part of the Court’s decision in this case, but to keep things manageable, we’ll do this while ignoring some very interesting philosophical and policy questions in the vicinity. Thus, for instance, we won’t concern ourselves with arguments against the constitutionality of the ACA’s Medicaid provision that, if successful, would also judge the old Medicaid program to be unconstitutional. And we’ll assume that there are constitutional constraints on what the federal government can do via its spending power, that go beyond what is explicitly stated in the U.S. Constitution. While we think these issues are very much worth pursuing, we’ll leave them aside as much as possible in this paper.\nIn what follows, it will be helpful to have some terminology for the various Medicaid requirements. We will use the following:\n\n‘Old Medicaid’ refers to the set of requirements and funding levels that existed prior to the passage of the ACA.\n‘Expanded Medicaid’ refers to the requirement that those not covered by Old Medicaid, but whose earnings fall below 133% of the federal poverty line, now be covered, plus the set of requirements and funding levels for these newly eligible individuals stipulated by the ACA.\n‘New Medicaid’ refers to the conjunction of Old Medicaid and Expanded Medicaid, i.e., Medicaid as it was envisioned to work after the passage of the ACA.\n‘The ACA’s Offer’ refers to the ACA’s offering the states the option of participating in (all of) New Medicaid, or not participating at all, but not the option of participating in just Old Medicaid.\n\nOne question that became surprisingly central to the ruling in NFIB v. Sebelius was the ontological relationship between Old Medicaid and New Medicaid. As we’ll see, J. Ginsburg held that these were the same program; the addition of Expanded Medicaid was just one of the many modifications that have been made to Old Medicaid over the years, without destroying its identity.8 C.J. Roberts disagreed, arguing that the Medicaid expansion provision “accomplishes a shift in kind, not merely degree”.9\n8 NFIB v. Sebelius, 567 U.S. ___, Ginsburg, J., slip opin. at 41–44 (2012).9 Id., Roberts, C.J., slip opin. at 53.We’re not going to take a strong stand on this ontological question. That’s partly because we think that questions like this are the wrong kinds of questions to be asking here. We don’t really have views on the criteria of identity through time for federal-state cooperative programs. And we’re not convinced that these questions have determinate answers. But even if they did, we still wouldn’t think that these answers were relevant to the constitutionality of proposed changes/supplements to those programs. Rather, on our view, what matters is the functional relationship between the old and new programs.\nWe’ll have more on this presently. But first, we need to look at why the Court thought the relevant sections of the ACA should be struck down.\n\n\n2 Spending Power and Coercion\nThe Spending Clause of the U.S. Constitution gives Congress the power “to pay the Debts and provide for the … general Welfare of the United States.”10 The justices in NFIB v. Sebelius agreed that the Spending Clause gives Congress a “broad authority” to interpret what that “general Welfare” consists in, and to apportion funds accordingly.11 This includes the power to offer the states funds as an inducement to take certain actions - such as establishing and operating certain programs - that accord with Congress’ understanding of the “general Welfare”. Old Medicaid is just such a federal-state cooperative program, established by Spending Clause legislation.\n10 U.S. Constitution, Article I, Section 8, Clause 1.11 NFIB v. Sebelius, 567 U.S. ___, Ginsburg, J., slip opin. at 50 (2012). See also Roberts, C.J., slip opin. at 45–46, and Joint Dissent, slip opin. at 29–32.12 In our discussion, we’ll leave open the question of whether an offer by the federal government can be coercive without being unconstitutionally coercive.What the Spending Clause does not allow is for the federal government to require the states to implement a particular federal-state cooperative program, or to accept the associated funding package. That includes either directly ordering the states to do these things, or ‘indirectly’ coercing the states into doing them. As we’ll see in the next section, one of the main issues in NFIB v. Sebelius is whether the ACA’s Offer constitutes an attempt to unconstitutionally coerce the states into realizing a federal spending objective.12\nThe justices in NFIB v. Sebelius emphasized that Spending Clause legislation has the nature of a contract.13 The federal government offers the states funds conditional on their satisfying certain conditions. That is, it offers them money in exchange for doing something. That looks like a contract. And, arguably, some contracts are coercive.\n13 Id., Roberts, C.J., slip opin. at 46, and Joint Dissent, slip opin. at 33.When we talk about contracts being coercive, we don’t mean that there is coercion involved in getting one of the parties to accept the offer. Rather, we mean that there is something about the offer itself that makes it coercive. Call coercion of the first kind ‘coercion alongside the contract’. In simple cases, where the parties have roughly equal power, there can be coercion of this sort - i.e., coercion alongside the contract - but it’s hard to see how the offer itself can be coercive. And in such cases, as long as there is no coercion alongside the contract, the party to whom the offer is made can simply refuse it. By contrast, when the parties are unequal in power, the mere making of the offer can sometimes amount to an abuse of the extra power. We’ll illustrate this point with some examples in section 5. For now we want to note two further points about the notion of coercion at issue here.\nFirst, the question of whether a particular piece of Spending Clause legislation is unconstitutionally coercive should be distinguished from the question of whether that legislation runs contrary to the U.S. system of federalism. If the federal government offered each state a million dollars to introduce a filibuster rule into their state Senate procedures (perhaps because the U.S. Senate was embarrassed to be so idiosyncratic), that would arguably be unconstitutional. But that’s not because the offer would be unconstitutionally coercive. Rather, it would be because the Spending Clause isn’t an open invitation to let the federal government interfere with every power a state has, including powers over their own legislative procedures. To put it another way, the Spending Clause doesn’t allow the federal government to do an end run around the system of federalism.\nSecond, even if an offer is judged to be unconstitutionally coercive, it doesn’t follow that it will be voided. In NFIB v. Sebelius, the Supreme Court did not strike down the federal government’s attempt to expand Medicaid. Rather, it amended the terms of the offer so they were no longer unconstitutionally coercive. Rather than states having a choice between New Medicaid and nothing, the Court held that they would have a choice between Expanded Medicaid, Old Medicaid, and nothing. This isn’t the usual remedy when a contract is found to be coercive; usually, it’s simply voided.14\n14 This is actually a surprising fact about the Court’s decision. Some prominent court watchers seemed to assume, before the decision, that if the court found the expansion to be constitutionally problematic, it would simply be voided. See, for instance, the pre-decision discussions in Kaiser Family Foundation, “The Health Reform Law’s Medicaid Expansion: A Guide to the Supreme Court Arguments”, March 2012, available at http://www.kff.org/healthreform/upload/8288.pdf, and Lyle Denniston, “Argument Preview: Health Care, Part IV - The Medicaid Expansion”, 23 March 2012, available at http://www.scotusblog.com/2012/03/argument-preview-health-care-part-iv-the-medicaid-expansion/. Both of these discuss the possibility the expansion will be struck down, but neither seems to mention the possibility that the expansion will be made voluntary. We suspect they were assuming the court would either find the expansion non-coercive, and hence let it stand, or coercive, and hold that coercive offers are void.\n\n3 The Roberts Rule\nAs we discussed in the previous section, the Spending Clause permits the federal government to offer the states financial inducement to implement particular programs, as long as the offer itself isn’t coercive. Typically, this just means that the states must have the option not to participate. As C.J. Roberts put the point,\n\nIn the typical case we look to the States to defend their prerogatives by adopting “the simple expedient of not yielding” to federal blandishments when they do not want to embrace the federal policies as their own. ... The States are separate and independent sovereigns. Sometimes they have to act like it.15\n15 Id., Roberts, C.J., slip opin. at 49, citation omitted.\nBut sometimes, merely having the option not to participate is not enough. That’s the case if, for example, there’s something about the nature of the federal government’s offer that means that the states don’t have a genuine choice about participating. According to C.J. Roberts, there were three aspects of the ACA’s Offer that, together, made it the case that the states didn’t have a genuine choice about accepting. So, the offer was unconstitutionally coercive.\nFirst, the ACA’s Offer conditioned the granting of funds for an already existing program (Old Medicaid) on states’ participation in another program (Expanded Medicaid). Call this phenomenon - i.e., conditioning the funding for an existing program on states’ participation in another program - ‘bundling’. Bundling is importantly different from conditioning the funding for a program on states’ willingness to operate that very program in some particular way. The latter, according to C.J. Roberts, is just the federal government providing for the “general Welfare” as permitted by the Spending Clause.16\n16 Id. at 50.17 Id.18 We’ll talk throughout this paper about purposes served by bundling, rather than the purposes Congress had in mind by bundling. This is in keeping with both C.J. Roberts’ and J. Ginsburg’s discussions.But second, even bundling may be permitted when it serves some legitimate purpose. The bundling involved in the ACA’s Offer, however, “serves no purpose other than to force unwilling States to sign up for the dramatic expansion in health care coverage effected by the Act”.17 To put the point another way, the only purpose of the bundling proposed by the ACA was to force the states to participate in Expanded Medicaid.18\nFinally, the states’ financial stake in participating (or not) in the bundled programs was enormous. Federal support for Old Medicaid makes up more than 10% of the typical state’s budget.19 Threatening the states with losses of that magnitude was, according to C.J. Roberts, a kind of “economic dragooning”.20 When the financial stake at issue is so large, the states have no genuine choice about participating.\n19 In fiscal year 2012, spending on Old Medicaid comprised nearly 24% of total spending by the states. The National Association of State Budget Officers, “State Expenditure Report: Examining Fiscal 2010–2012 State Spending”, available at http://www.nasbo.org/sites/default/files/State%20Expenditure%20Report_1.pdf, 44. Federal support offset at least 50% of that state spending, and for some states, quite a lot more. See note 6.20 NFIB v. Sebelius, 567 U.S. ___, Roberts, C.J., slip opin. at 52 (2012).Why think that these features of the ACA’s Offer are sufficient to constitute it as unconstitutionally coercive? C.J. Roberts doesn’t spell out his reasoning here, but perhaps the thought is this. Bundling of federal-state cooperative programs can serve various purposes. For example, bundling can encourage the states to participate in a pair of programs, where the existence of each program helps the other one operate more efficiently. Or else, bundling can encourage the states to implement a new program that helps the existing program achieve its aims better. When bundling serves these (and other) legitimate public policy purposes, it’s plausible that the federal government is attempting to provide for the general Welfare in accordance with the Spending Clause.\nIf, on the other hand, the only purpose served by the bundling is to get the states to participate in one of the bundled programs, and further, the financial inducement offered is so large that it effectively serves as a “gun to the head” of the states, then that just amounts to the federal government requiring the states to participate in a particular program.21 And as we observed in the previous section, that’s not permitted under the Spending Clause. (We’ll have much more to say about this sort of reasoning in later sections of this paper.)\n21 Id. at 51.In sum, then, C.J. Roberts argued that the ACA’s Offer was unconstitutionally coercive because it satisfied the following three conditions:\n\nThe offer bundles two independent programs (Old Medicaid and Expanded Medicaid);\nThat bundling serves no other purpose than to force the states to participate in one of the bundled programs (Expanded Medicaid);\nFailure to participate in the bundled programs exposes the states to enormous financial loss, and so, constitutes a kind of “economic dragooning”.\n\nAs we understand the Roberts Rule, conditions (1)-(3) are not only jointly sufficient for unconstitutional coerciveness, but each of them is individually necessary as well. To see why, we can consider the conditions in turn.\nWithout (1), the states could potentially opt out of any modification to an existing federal-state cooperative program. Imagine that the federal government established new standards for effectiveness of cancer treatments, and decided that Medicaid would henceforth only fund programs that complied with those new standards. The new parts of this Medicaid package are bundled together with the old parts to force the states to comply, and failure to participate in the bundled programs exposes the states to enormous loss. But this isn’t unconstitutionally coercive; the imagined policy could just be a good instance of quality control on government spending.22\n22 Note that Old Medicaid has evolved in just this way, with modifications to the program being bundled together with unchanged parts. For example, the Balanced Budget Act of 1997 (P.L. 105–33) required the states to expand their coverage of home health visits required by Medicare beneficiaries. The federal government met all of the costs of this expansion, but did not make it voluntary. For more on this, see Melvina Ford, Richard Price, and Jennifer Neisner, “Medicaid: 105th Congress”, Congressional Research Service, February 4 1998, available at http://www.policyarchive.org/handle/10207/508, 12–13.Without (2), federal government actions that by hypothesis have a legitimate purpose could be ruled out. That would be a bad result. Here’s one sort of case that illustrates this point. Imagine that the federal government in its wisdom subsidizes widget production through conditional grants to the states. The government then discovers that widget production has serious environmental consequences. So it decides to fund cleanup operations, again through conditional grants to the states. It seems reasonable to bundle these two grants together, since the federal government has a legitimate interest in not subsidizing a certain industry without also subsidizing the elimination of its external costs. But that could be true even if widget production and the cleanup operations look like independent programs, and each is a signifiant component of state budgets.\nFinally, (3) is needed to ensure that South Dakota v. Dole is not overturned.23 That case concerned the introduction of a new condition on federal highway funding, namely, that the states enforce a drinking age of 21. States that failed to comply with this condition stood to lose up to 5% of the highway funds they would otherwise be entitled to. Several states, including South Dakota, argued that this was unconstitutionally coercive. And they had a point; setting the drinking age and repairing highways look like quite independent programs. Further, it was clear that the point of the bundling was simply to get the states to comply with the federal government objective of raising drinking ages to 21. But C.J. Roberts held that this didn’t matter, because the threatened financial loss for noncompliance with the federal objective was small enough so as not to amount to unconstitutional coercion.24\n23 483 U.S. 203 (1987).24 NFIB v. Sebelius, 567 U.S. ___, Roberts, C.J., slip opin. at 50–51 (2012). But in a footnote, C.J. Roberts seems to argue that any amount of threatened financial loss makes the federal government’s offer coercive. Id. at 52n2. Perhaps he intended to draw a distinction between an offer being coercive, and it being unconstitutionally coercive. But that distinction doesn’t figure anywhere else in his opinion. So, we’re left at a loss about how to square this footnote with the rest of C.J. Roberts’ argument.25 Id., Ginsburg, J., slip opin. at 39.Our reading of C.J. Roberts’ argument - and in particular, of his test for unconstitutional coerciveness - is quite similar to J. Ginsburg’s.25 But there’s one point of difference. While J. Ginsburg includes conditions very much like our (1)-(3) in her reading of the test, she adds a further condition as well.\n\nThe expansion (Expanded Medicaid) was unforeseeable by the states when they signed onto the already existing program (Old Medicaid).26\n\n26 Id.27 Id., Roberts, C.J., slip opin. at 54. “A State could hardly anticipate that Congress’ reservation of the right to”alter” or “amend” the Medicaid program included the power to transform it so dramatically.”28 The result of adding (4) to the Roberts Rule is implausible as a test for unconstitutional coerciveness. Imagine that the federal government conditions federal highway spending on states enforcing a drinking age of 21 (as in South Dakota v. Dole), but this time, threatens to withhold 100% of highway funds from any states that fail to comply. That offer seems unconstitutionally coercive. And this verdict isn’t changed if the federal government threatens to add such a condition to federal highway spending for many years before actually doing so. So the foreseeability (or lack thereof) of the condition doesn’t seem to affect whether the offer is unconstitutionally coercive.We agree with J. Ginsburg that C.J. Roberts commits himself to the truth of (4).27 But we don’t think that (4) is relevant to the issue of whether the ACA’s Offer is unconstitutionally coercive (and it’s not clear to us that C.J. Roberts does either).28\nAs we see it, (4) speaks to a different question, namely, whether Medicaid program as envisioned by the ACA (New Medicaid) is the same program as the already existing one (Old Medicaid). And as we’ll argue next, that ontological question is irrelevant to whether the ACA’s Offer is unconstitutionally coercive.\n\n\n4 Ontological Questions\nRecall that the Roberts Rule says that an offer by the federal government to help establish a federal-state cooperative program is unconstitutionally coercive if the following conditions are satisfied:\n\nThe offer bundles two independent programs;\nThat bundling serves no other purpose than to force the states to participate in one of the bundled programs;\nFailure to participate in the bundled programs exposes the states to enormous financial loss, and so, constitutes a kind of “economic dragooning”.\n\nCondition (1) requires that that the programs be independent, not that their conjunction (in this case, New Medicaid) be distinct from the previously existing program (Old Medicaid). Thus, the Roberts Rule, as we understand it, places no emphasis on whether the federal government’s offer creates a new program, or merely modifies an already existing program. We’ll have a lot more to say about independence later (in section 6), but it should be clear that whether two programs are independent, and whether conjoining them creates a new program, are different questions. Independence has to do with how the programs function, what they do, not with their ontological status, what they are. So, even if New Medicaid turned out to be the same program as Old Medicaid, the two major parts of New Medicaid - Old Medicaid and Expanded Medicaid - could be quite independent of each other.\nAt first reading, it seems that both C.J. Roberts and J. Ginsburg take the ontological question (about whether New Medicaid is the same program as Old Medicaid) seriously. For instance, C.J. Roberts notes, in what seems like a positive way, the states’ claim that “the expansion is in reality a new program and that Congress is forcing them to accept it by threatening the funds for the existing Medicaid program.”29 And he says that Ginsburg’s reply, which assumes New Medicaid and Old Medicaid are the same program, “begs the question” against the states.30 But we think that while J. Ginsburg does take a stance on the ontological question, C.J. Roberts in the end does not. And on this point, we side with the latter, at least to the extent that we think that the ontological question is irrelevant to the issue of unconstitutional coerciveness.\n29 Id. at 52.30 Id.To see why, consider a rival test to the Roberts Rule which says that what matters for unconstitutional coerciveness is that the programs in question (say, A and B) be numerically distinct. Would we get a rule that is better than the Roberts Rule? Actually, that breaks down into two questions. First, would the revised rule make for better law? And second, would the revised rule be a better interpretation of C.J. Roberts? We answer both questions negatively, with the first negative answer being some part of our reason for the second negative answer.\nQuestions about individuation criteria, and criteria of identity over time, for governmental programs are rather hard. We might think we could make progress by looking at the area where philosophers have made the most thorough investigation of identity criteria - namely, personal identity - and carrying the lessons from there over to debates about identity of governmental programs. But this would be useless twice over. For one thing, the debates about personal identity are so far from being settled that we have little to go on. For another, different views are going to be plausible in the two cases. A thoroughgoing conventionalism about personal identity is a rather unpopular view (though it is ably defended by Caroline West).31 But conventionalism about identity criteria for conventionally established programs, like Medicaid, seems much more plausible.\n31 Caroline West, “Personal Identity: Practical or Metaphysical?”, in Kim Atkins and Catriona Mackenzie (eds.), Practical Identity and Narrative Agency (New York: Routledge, 2008), 56–77.32 Terrence Parsons, Indeterminate Identity: Metaphysics and Semantics (Oxford: Oxford University Press, 2000).So in general we start knowing very little about identity criteria for governmental programs. But what we do know should give us pause before putting identity criteria into a substantial legal rule. It will often be indeterminate whether A and B are the same program, or different ones. (Governmental programs provide as clear an example of indeterminate identity as anything in Terrence Parsons’s study of indeterminate identity.)32 If we made the identity, or otherwise, of A and B relevant to whether a particular law was unconstitutional, we would risk concluding that it is indeterminate whether that law is unconstitutional. That doesn’t feel like an acceptable outcome.\nIn the next section, we’ll consider a thought experiment suggested by J. Ginsburg about what would have happened if Congress had repealed Old Medicaid and then enacted New Medicaid as a replacement.33 We’ll argue that the thought experiment isn’t particularly revealing, because it differs from what actually happened in a striking way. But perhaps we should question this assumption. Why should we say that the ACA merely enacted Expanded Medicaid, rather than saying that it actually repealed Old Medicaid, and enacted New Medicaid in its place? Indeed, if such a reading would make the ACA constitutional (as J. Ginsburg suggests), wasn’t the Court obliged to read the Act that way?34\n33 NFIB v. Sebelius, 567 U.S. ___, Ginsburg, J., slip opin. at 51 (2012).34 Id.The relevant reason is presumably that neither the ACA, nor the debate around it, reads like it was repealing and replacing Old Medicaid. That is, the rhetoric around the ACA reads like it was an expansion of Old Medicaid, not a replacement of it. And that’s enough to make it be the case that the ACA merely enacted an expansion of Old Medicaid, not a replacement of it. This talk about how the rhetoric matters to the ontological description of what the ACA did is part of what we meant above by saying that a conventionalist theory of identity for governmental programs is plausible. We all treated the ACA as expanding, not replacing, Old Medicaid, and hence it really was an expansion, not a replacement, of Old Medicaid. That’s so even though a functionally equivalent Act could have replaced Old Medicaid.\nBut while this kind of rhetoric can matter for ontological questions, it can hardly matter for the constitutional legitimacy of the ACA. C.J. Roberts held that one central part of the ACA, namely, the individual mandate, was a valid exercise of the taxing power, even though it was never marketed as such during Congressional debates.35 And that seems right to us. What matters for constitutionality is whether Congress has a power, not how they talk about their powers.36 But to make the ontological relationships between Old Medicaid, Expanded Medicaid, and New Medicaid relevant to the constitutionality of the latter would be to grant this talk, these “recitals of the powers”, too much significance. It’s hard to see that that is right, or that C.J. Roberts, in the very opinion where he upheld the individual mandate as an exercise of the taxing power, would do that.\n35 Id., Roberts, C.J., slip opin. at 33–40.36 “[T]he constitutionality of an action taken by Congress does not depend on recitals of the powers which it undertakes to exercise.” Woods v. Cloyd W. Miller Co., 333 U.S. 138, 144 (1948), emphasis added. Quoted in NFIB v. Sebelius, 567 U.S. ___, Roberts, C.J., slip opin. at 39 (2012).37 Id. at 53, 54.So we conclude that the right way to read C.J. Roberts’ test is in terms of the relationship between what A and B do, not what A and B are. That’s how we take his comments that what matters is that the Medicaid provision in the ACA brought about a “shift in kind, not merely degree”, which would “transform it [i.e., Medicaid] so dramatically”.37 Looking at what Congress is trying to do is a much better guide to the constitutionality of its actions than looking at its talk.\nHaving said all that, we suspect that if one did take ontological distinctness to be important in testing for constitutionality, then the Medicaid provision of the ACA would be constitutional. It’s actually rather tricky to motivate a position on the ontology of Medicaid that makes that provision problematic. To see this, note that there are three ontological options here. (At least, there are three determinate options; there are also views on which the truth is indeterminate between these.)\nFirst, it might be that New Medicaid and Old Medicaid are the same program, and adding Expanded Medicaid is just a familiar way for Medicaid to grow. That’s roughly J. Ginsburg’s position.38 Second, it might be that New Medicaid and Old Medicaid are distinct programs, with New Medicaid having two components - Old Medicaid and Expanded Medicaid - that run in parallel alongside each other. On this option, New Medicaid and Old Medicaid are no more one program than Social Security plus the Defense Department are one program. This feels like the option most in tune with the Court’s ruling. Third, it might be that Old Medicaid was repealed by the ACA, and New Medicaid is a new program put in its place. We’ve discussed this possibility a couple of times already, and will have more to say about it in the next section.\n38 Id., Ginsburg, J., slip opin. at 41–44.39 For if ontology were constitutionally relevant, and New Medicaid and Old Medicaid were substantially similar, then it’s hard to see why the former would be unconstitutionally coercive but the latter not.40 As J. Ginsburg suggests, there’s little doubt about the constitutionality of the third option. Id. at 51.41 Kaiser Commission on Medicaid and the Uninsured, “Federal Core Requirements and State Options in Medicaid: Current Policies and Key Issues”, April 2011, available at http://www.kff.org/medicaid/upload/8174.pdf.Now to get an ontological view that supports C.J. Roberts’s ruling (on the assumption that ontology is constitutionally relevant), we’d have to say that New Medicaid is sufficiently different from Old Medicaid that the first option is ruled out.39 But we couldn’t say that they are so different that the third option becomes the only plausible one.40 A middle ground has to be found, and that ground doesn’t look stable to us. Note in particular that Expanded Medicaid is a program whose eligibility is defined largely in terms of who is not eligible for Old Medicaid. It isn’t that Expanded Medicaid is for everyone earning less than 133% of the poverty line. Rather, it’s for everyone earning less than 133% of the poverty line, who wasn’t already covered by Old Medicaid. That’s a little odd. It’s especially odd because many Old Medicaid supported state programs were already more generous than the federal minimums, and so already covered many of the people who fall under Expanded Medicaid.41\nNow ultimately none of these ontological speculations matter. But perhaps the underlying considerations do matter a little. The oddness of thinking of New Medicaid as a distinct program from Old Medicaid will be reflected in the oddness of operating it as one. And as we’ll consider in sections 6–7, that latter oddness is relevant to the test C.J. Roberts set out.\nBefore turning to applications of the Roberts Rule, however, we’ll consider an important objection to the Rule itself. We’ll argue that the objection is unsuccessful, but that it highlights some important aspects of the Rule, including the vitality of its third condition.\n\n\n5 Coercion in Continuing Relationships\nIn her dissent, J. Ginsburg offered the following thought experiment.\n\nConsider also that Congress could have repealed Medicaid ... Thereafter, Congress could have enacted Medicaid II, a new program combining the pre-2010 coverage with the expanded coverage required by the ACA. By what right does a court stop Congress from building up without first tearing down?42\n42 NFIB v. Sebelius, 567 U.S. ___, Ginsburg, J., slip opin. at 51 (2012), citation omitted.\nWe take the point of this thought experiment to be something like this. There would have been nothing unconstitutionally coercive about Congress repealing (Old) Medicaid, and enacting Medicaid II. But the end product of that repeal-and-replace effort (Medicaid II) would have been functionally equivalent to New Medicaid, though arrived at in a different manner. So, if enacting Medicaid II by repealing-and-replacing would have been constitutional, enacting New Medicaid by just expanding Old Medicaid (and so, altering an already existing agreement) must be constitutional as well. Therefore, any test that holds the ACA’s Offer to be unconstitutionally coercive - such as the Roberts Rule - should be rejected.\nWe think this is a bad way to assess whether a proposed use of Congress’ spending power is unconstitutionally coercive. To see why, it will help to consider two examples of agreements. The first involves contracts, as C.J. Roberts suggests we should understand agreements between the federal government and the states. The second is a more informal agreement. What the two agreements have in common is that they’re both continuing agreements. As we’ll argue below, that’s significant for assessing their coerciveness.\n\nThe Monopsonist\nSupplier makes widgets, and their largest customer by far is MegaCorp. For many years, MegaCorp has had an annual order for one million widgets. The price that MegaCorp pays has basically tracked inflation since the deal was first established, and they now pay $10 per widget. This is a decent deal for Supplier, since it costs them $8 to make each widget. Although the supply contracts are explicitly only for a year at a time, it is generally understood that the contracts will be renewed, and the norm in the widget industry is that these contracts are renewed.\nOne year, MegaCorp says it is only interested in continuing the deal if Supplier also sells it a million gimcracks for $10 per gimcrack. This isn’t a great deal for Supplier, since it costs $11 to make each gimcrack. But Supplier will likely go out of business without the deal to sell widgets to MegaCorp.\n\nWe think MegaCorp’s proposal is coercive. Supplier has no real choice but to take on an extra supply contract that does not even cover their costs. And we think that the offer is coercive even though the combined offer MegaCorp makes, namely, $20 million for a million widgets and a million gimcracks, is not a bad deal for Supplier. Indeed, Supplier stands to profit on the combined deal. Nevertheless, the newly added part of the deal is basically a gift to MegaCorp, and MegaCorp is using their monopsony power to extract that gift. That makes the deal coercive.\nThe inequality in power between MegaCorp and Supplier matters here. Had Supplier been flooded with potential buyers for their widgets, MegaCorp could still make an offer of “Widgets and gimcracks, or nothing”, but they wouldn’t be in a position to make that offer credible. That’s because it isn’t credible, in the envisaged circumstances, that if Supplier had countered with an offer of “Widgets at the old price, and nothing more”, MegaCorp would have stuck to their guns and refused the mutually beneficial deal.43 Under those circumstances, the offer might not have been coercive. But those are not the circumstances in our example.\n43 We are drawing here on the literature in game theory on credible threats. For more detailed discussion see, for example, Avinash Dixit and Susan Skeath, Games of Strategy, second edition (New York: Norton, 2004), Chapter 10.Many of the same points apply to our second example of a continuing agreement.\n\nThe Conditional Philanthropist\nChild has recently graduated college, and has her first job. As with many first jobs, the pay is not fantastic. But it’s enough to afford a (barely) tolerable apartment in a safe enough neighborhood. Her Parent offers to pay the difference in rent that would allow her to live in a nicer apartment in a safer neighborhood, and Child takes up this offer. We assume that Parent is not under any obligation to do this; Child’s living situation without parental support is sub-optimal, but acceptable. It’s just a nice gift from Parent.\nSome years later, after Child has established roots in the neighborhood that she can live in thanks to Parent’s gift, Parent informs her that he won’t keep providing financial support unless she agrees to assist with one of Parent’s political causes. As it happens, it is a cause that Child does not agree with.\n\nWe think this offer is also coercive. It would have been acceptable for Parent to simply never provide support for Child’s rental expenses. It would also have been acceptable for Parent to make clear from the start that the offer of financial support was conditional on reciprocal political support. Making an offer like that would be distasteful, and frankly strikes us as an appalling way to relate to one’s own child. But if Child could have an acceptable standard of living without this extra money, it isn’t coercive to offer her a little more money in exchange for political support. Once the arrangement has commenced, though, and Child has structured her life around it, threatening to take it away unless Child supports a political cause does seem coercive.\nAnd this is why we think J. Ginsburg’s thought experiment fails. It’s true that it would be constitutional for Congress to repeal Old Medicaid. It’s also true that had Old Medicaid never existed, and Congress had enacted New Medicaid all at once in the ACA, there would be no constitutional question here. J. Ginsburg suggests that this is enough to show that the expansion is constitutional.\nBut the facts in J. Ginsburg’s thought experiment aren’t the facts at hand. The existing federal support for Old Medicaid creates an important kind of relationship between the states and the federal government. The states have structured a significant part of their operations around the (quite reasonable) assumption that this relationship would persist. Requiring the states to do something new in exchange for the preservation of that relationship is potentially coercive for just the same reasons that Parent and MegaCorp’s offers are coercive.\nPut another way, in the context of a continuing relationship, particularly one in which there is an imbalance in power, we have to look at how the relationship is changing, and not just at the end result, to see whether we have a case of coercion. Even if the federal government’s offer of New Medicaid, appearing as a deux ex machina, would have been constitutionally acceptable, it doesn’t follow that adding Expanded Medicaid to Old Medicaid (in the way the ACA does) is acceptable.\nOur argument in this section highlights the importance of condition (3) of the Roberts Rule. That condition focuses on the possibility of “enormous financial loss”. If Old Medicaid and Expanded Medicaid were both first enacted as part of the ACA, and they were bundled in the sense that a state was not free to participate in one but not the other, then this bundling would not expose the states to any losses. Rather, the bundling would just make it a little harder for the states to receive funds offered by the federal government. But the fact that Old Medicaid existed, and had been incorporated into the states’ financial planning, means that a threat to any state’s continued participation is a threat of loss to that state, as required under condition (3) of the Roberts Rule. And as we’ve been arguing, this is signifiant for assessing coerciveness.\nWhen we said that MegaCorp’s and Parent’s offers were coercive, we were not offering an opinion about whether there are, or should be, legal remedies available to Supplier or Child. It could well be argued that the potential costs of involving the courts in relationships like these outweigh the costs of allowing some coercive offers to be made.\nBut when we look at legislation that alters the relationship between the states and the federal government, it is more plausible that there is a role for the courts in preventing coercion. If one level of government is coercing others, that is not something that should be allowed to stand. In fact, allowing it to stand seems incompatible with the U.S. system of federalism.\nSo we reject this argument of J. Ginsburg’s. As we read her, this is the only objection she makes to the test C.J. Roberts proposes. As we’ll see in the next section, she makes several further points that can be used as objections to his application of the test. We will endorse some of those objections. But she doesn’t appear to offer other objections to the test itself. And we too will assume, from here on, that the Roberts Rule is a good test for striking down proposed uses of Congress’ spending power on grounds of unconstitutional coerciveness.\nThis is primarily a paper on constitutional questions, so we’ll keep this digression brief. But we do want to note that our disagreement with J. Ginsburg here has wider ramifications. It is common in several walks of life to have agreements between two parties that are year-to-year on paper, but are expected by both parties to continue somewhat indefinitely. Many employment arrangements are like that. And, although less common in the United States, arrangements to rent housing in many parts of the world are also like that. In those cases, when considering whether proposed changes to the relationship by the more powerful party (usually the employer or the landlord) are coercive, we think it’s important to look at the changes themselves, and not just to whether the new agreement would be acceptable taken on its own. The same kind of reasoning should apply to continuing agreements between the states and the federal government.\n\n\n6 Relation Between Programs\nWhile we agree that an expansion of Medicaid could be unconstitutionally coercive, we don’t think the expansion envisioned in the ACA actually is. Further, we think that the Roberts Rule, properly applied, gets this result. In this section, we’ll argue that Old Medicaid and Expanded Medicaid are sufficiently closely related that the first condition of the Roberts Rule is not satisfied. In the next section, we’ll argue that there is legitimate reason to bundle the two programs together, so the second condition is also not satisfied. Thus, even accepting the Roberts Rule as a good test for unconstitutional coerciveness, the ACA’s Offer turns out to not be unconstitutionally coercive.\nHere’s the Roberts Rule once more. It says that an offer by the federal government to help establish a federal-state cooperative program is unconstitutionally coercive if the following conditions are satisfied:\n\nThe offer bundles two independent programs;\nThat bundling serves no other purpose than to force the states to participate in one of the bundled programs;\nFailure to participate in the bundled programs exposes the states to enormous financial loss, and so, constitutes a kind of “economic dragooning”.\n\nA pair of federal-state cooperative programs may be independent in at least two different senses: first, if the programs have substantially different purposes; and second, (even) if they have the same (or closely related) purposes, but attempt to achieve those purposes in substantially different ways.\nWhen it comes to Old Medicaid and Expanded Medicaid, that the programs are not independent in either of the senses just outlined seems obvious on its face. After all, the two programs share an overall purpose; both have the aim of improving access to health services for the neediest Americans. In fact, as we’ve already mentioned (in section 4), eligibility criteria for one of the programs (Expanded Medicaid) is defined partly in terms of ineligibility for the other one. That suggests that the programs are designed to work together to achieve their overall purpose. Moreover, they try to achieve this purpose in the same way, via the same circuitous means; both feature the federal government encouraging the states to provide health care to their poorest residents by paying a (large) percentage of the costs, conditional on the states meeting certain conditions for minimum care. That looks like enough to make it the case that the programs are closely related, contra condition (1) of the Roberts Rule.\nObviously, C.J. Roberts disagreed with this assessment. We find in his opinion four considerations that might be used to argue that the programs are not suitably related.44 The first two purport to identify significant differences in purpose between Old Medicaid and Expanded Medicaid, while the third and fourth point to differences in how they’re intended to operate. None of these strikes us as persuasive. (Three of these considerations were also discussed by J. Ginsburg in her dissent, and as will be clear below, we largely sympathize with her responses.45)\n44 Id., Roberts, C.J., slip opin. at 53–54.45 Id., Ginsburg, J., slip opin. at 50–51. J. Ginsburg treats these considerations as comprising C.J. Roberts’ argument for the view that Old Medicaid and New Medicaid are distinct programs. We’ve explained (in section 4) why we don’t take C.J. Roberts to subscribe to this view.46 Id., Roberts, C.J., slip opin. at 53.The first consideration is that Old Medicaid covered discrete “categories of the needy: the disabled, the blind, the elderly, and needy families with dependent children.”46 But Expanded Medicaid had a somewhat blunter condition of eligibility, namely, that the claimants be earning less than 133% of the federal poverty level (and not already be covered by Old Medicaid). It’s hard to see how this amounts to a source of unrelatedness. It’s as if C.J. Roberts thought of Old Medicaid as not merely having a disjunctive essence, but as being essentially disjunctive. He seems to be suggesting that any program that didn’t have a long list of eligibility criteria could not be closely related to Old Medicaid. This strikes us as absurd, especially since the list of eligibility criteria for Old Medicaid were hardly arbitrary or ad hoc. It was meant to reflect, as C.J. Roberts recognized, ways of being especially needy. A simpler means of determining need would accomplish the same thing.\nThis brings us to the second consideration, that by covering up to 133% of the poverty level (rather than merely covering the discrete categories mentioned in the previous paragraph), Expanded Medicaid was no longer reserved for the neediest among us. But a family of four has to earn less than $31,322 to qualify under this condition.47 To exclude those earning so little from among the neediest seems bizarre.48\n47 U.S. Department of Health & Human Services, “2013 Poverty Guidelines”, available at http://aspe.hhs.gov/poverty/13poverty.cfm.48 J. Ginsburg makes a similar point. NFIB v. Sebelius, 567 U.S. ___, Ginsburg, J., slip opin. at 50 (2012).49 Jared Bernstein, “More Poverty than Meets the Eye”, Economic Policy Institute, April 11 2007, available at http://www.epi.org/publication/webfeatures_snapshots_20070411/. Bernstein writes, “When it comes to poverty in America, almost every analyst agrees that the official measure is terribly out-of-date and no longer provides a valid indication of economic deprivation.” See also David M. Betson, Constance F. Citro, and Robert T. Michael, “Recent Developments for Poverty Measurement in U.S. Official Statistics”, Journal of Official Statistics, vol. 16, no. 2, 2000, 87–111.Of course, it would be possible to keep expanding Medicaid, in something akin to the manner envisioned by the ACA, until it no longer covers just the neediest, but more closely resembles a program of universal health care. And it may even be indeterminate where the line between these lies. But C.J. Roberts offers no reason to think that Expanded Medicaid crosses this line. Moreover, in light of well-known criticisms of the federal poverty measure - criticisms which charge that the measure, developed in the 1960s, is now outdated and significantly undercounts poverty in the U.S. - there’s good reason to think that 133% of the federal poverty level is not an especially generous threshold.49\nThe third consideration is that the federal subsidies for Expanded Medicaid are more generous than those for Old Medicaid.50 But it’s hard to see how the generosity, or lack thereof, of the federal government speaks to the relatedness of the two programs. Would more stinginess on the part of the federal government have made the two programs more closely related?\n50 See notes 5 and 6.51 NFIB v. Sebelius, 567 U.S. ___, Ginsburg, J., slip opin. at 50–51 (2012).And the final consideration C.J. Roberts offers is that the conditions imposed on the states by Old Medicaid and Expanded Medicaid are different. But as J. Ginsburg notes, things aren’t quite so simple. While it’s true that the conditions imposed under Expanded Medicaid are different from those traditionally required under Old Medicaid, they aren’t any different from what has been required under Old Medicaid since 2006. So Expanded Medicaid isn’t different, in this sense, from Medicaid as it was at the time ACA was passed.51\nNone of this is meant to deny that there are differences between Old Medicaid and Expanded Medicaid. But by itself, that doesn’t tell us much about whether the ACA’s Offer was unconstitutionally coercive. Condition (1) of the Roberts Rule requires not merely that programs in question be different in some way(s), but that they be independent. We’ve been arguing that the differences cited by C.J. Roberts don’t speak to independence of the two programs in any relevant sense.\n\n\n7 Reasons for Bundling\nIn this section, we describe a further way in which the ACA’s Offer fails to be unconstitutionally coercive under the Roberts Rule. We argue that the federal government has at least three legitimate reasons for bundling the programs together. Thus, it’s not true that the only reason for the bundling is to force the states to participate in Expanded Medicaid, contra condition (2) of the Roberts Rule.\nThe first (and more minor) reason concerns the complexity that will arise when future modifications are made to Medicaid. As we’ve already had reason to note, Medicaid requirements are not set in stone.52 They change, often substantially, from year to year. But the Court’s decision in NFIB v. Sebelius has just made it considerably more complex to make any such changes. As things stand, if Congress wants to enact changes to both Old Medicaid and Expanded Medicaid, it will have to apply the change to each program separately.\n52 See note 22.Of course, this point is related to our discussion in the previous section; if the two programs were genuinely unrelated, we wouldn’t expect many changes that would apply to both programs. But given that the two programs work in substantially similar ways, at least some such changes - maybe even many - will be forthcoming.\nThe second reason concerns potential savings for the states. Though both C.J. Roberts53 and the authors of the Joint Dissent54 emphasized the extra financial burden Expanded Medicaid would impose on the states, there’s ample research to suggest that that burden is in fact quite minor.55 For example, the Center on Budget and Policy Priorities estimated that the expansion would cost the states just 2.8% more than they would otherwise spend on Medicaid between 2014 and 2022.56 Even more strikingly, that figure overstates the increase in state spending once we add in the savings to the states from no longer having to provide uncompensated care to those currently uninsured (or underinsured). The Urban Institute estimated that the states would end up saving money - anywhere from $92 to $129 billion between 2014 and 2019 - by taking up the ACA’s Offer.57 Those are savings that can be used by the states to bolster their other health care programs, including Old Medicaid. So, implementing Expanded Medicaid might in fact put the states in a position to run Old Medicaid better.\n53 Id., Roberts, C.J., slip opin. at 52n12.54 Id., Joint Dissent, slip opin. at 45–46.55 See, for example, January Angeles, “How Health Reform’s Medicaid Expansion Will Impact State Budgets: Federal Government Will Pick Up Nearly All Costs, Even as Expansion Provides Coverage to Millions of Low-Income Uninsured Americans”, Center on Budget and Policy Priorities, July 25, 2012, available at http://www.cbpp.org/files/7--12--12health.pdf, and John Holahan and Irene Headen, “Medicaid Coverage and Spending in Health Reform: National and State-by-State Results for Adults at or Below 133% FPL”, Kaiser Commission on Medicaid and the Uninsured, May 2012, available at http://www.kff.org/healthreform/upload/medicaid-coverage-and-spending-in-health-reform-national-and-state-by-state-results-for-adults-at-or-below--133-fpl.pdf.56 Angeles, op. cit., 1.57 Matthew Buttguens, Stan Dorn, and Caitlyn Carroll, “Consider Savings as well as Costs: State Governments Would Spend at Least $90 Billion Less With the ACA than Without It from 2014 to 2019”, The Urban Institute, July 2011, available at http://www.urban.org/UploadedPDF/412361-consider-savings.pdf, 1. This projection includes savings from moving some adults currently covered by various state Medicaid programs onto federal subsidies via the health care exchanges to be established under the ACA.58 For an useful overview of some research on this point, see the Institute of Medicine, America’s Uninsured Crisis: Consequences for Health and Health Care (Washington, D.C.: National Academies Press), especially Chapter 4.The third reason has to do with improving health outcomes generally. There’s research suggesting that high rates of uninsurance in a community adversely affect health outcomes for everyone there, including those with insurance.58 The difficulty and expense involved in treating the uninsured when they are finally driven to seek health care tends to reduce the quality of care that might otherwise be available for the insured. So, by reducing the ranks of the uninsured, Expanded Medicaid can help states achieve better health outcomes via their other health care programs, including Old Medicaid.\nIn assessing the costs and benefits of programs like Medicaid, it’s important to remember the ways in which basic health care is unlike many other goods. In particular, even if a state chooses not to participate in something like Expanded Medicaid, it still must share the financial burden of providing health care to the population that would have been covered by such a program. States still have to provide emergency rooms, and in practice, are not compensated for a significant portion of the care these provide to the uninsured. If some of the people who move onto Expanded Medicaid were previously uninsured, a state could see an overall reduction in its health care spending. Some of these savings would come from moving state costs onto the federal component of Medicaid. But some would come from the fact that patients would be moving from a form of health care that’s very expensive to provide, i.e., emergency room care, to the more efficient forms that are mostly available to the insured.59 These savings could strengthen Old Medicaid, and the health system as a whole. So expanding Medicaid could make Old Medicaid more financially self-sufficient.\n59 In its first full year of implementing health reform substantially similar to the ACA, Massachusetts saw an astounding 38% drop in its spending on uncompensated care. Angeles, op. cit., 5.Again, the fact that the programs are not unrelated is relevant. It’s because these are both health care programs - and moreover, health care programs for those who might otherwise be uninsured - that it’s plausible to think that savings incurred in one program strengthen the other program, rather than just strengthen the federal government’s balance sheet.\nSo the expansion of Medicaid fails two of Roberts’ three criteria for being unconstitutionally coercive. That’s why we can agree with his test, but disagree with the conclusion that the expansion was unconstitutionally coercive.\n\n\n8 Conclusion\nWe’ve argued in this paper for several conclusions:\n\nThe ontological relationship between Old Medicaid and New Medicaid is irrelevant to the constitutionality of the ACA.\nThe facts that Old Medicaid was well-established prior to the passage of the ACA, and that the states relied on its continuation, are relevant to the constitutionality of the ACA, and, in fact, open up the possibility that the ACA’s Offer is unconstitutionally coercive.\nBut that Offer is not, after all, unconstitutionally coercive, for at least two reasons: first, because it bundles together two programs (Old Medicaid and Expanded Medicaid) that are closely related, and second, because there are legitimate reasons for that bundling.\n\nOur discussion has left open several interesting questions. That’s partly for space reasons, and partly because we’re not sure what the right answers are. We’ll end our discussion by listing three of those questions.\nFirst, are offers by the federal government to help establish federal-state cooperative programs unconstitutionally coercive only when the states are exposed to significant losses? We are inclined to think that this is not the case, and that this poses a problem for C.J. Roberts’ attempt to distinguish the current case from South Dakota v. Dole via condition (3) of the Roberts Rule.\nSecond, is the Roberts Rule a good test for unconstitutional coerciveness of offers by the federal government in other federal jurisdictions? For example, does it throw light on whether the Australian High Court ruled correctly in the Uniform Tax Cases?60\n60 South Australia v Commonwealth 65 CLR 373 (1942) and Victoria v Commonwealth 99 CLR 575 (1957).61 Thanks to the editors and referees of this journal for many helpful comments.Third, is the Roberts Rule a good test for coerciveness of proposed changes to continuing relationships in business, or in residential tenancy? If so, this case could have implications for areas far removed from constitutional law. Although the previous two sections have provided a number of reasons to doubt that the ACA’s Medicaid provision is unconstitutionally coercive, the issues raised here are relevant to the broader question of when the more powerful party in a continuing relationship can force changes to that relationship.61\n\n\n\n\n\nCitationBibTeX citation:@article{maitra2013,\n  author = {Maitra, Ishani and Weatherson, Brian},\n  title = {In {Defense} of the {ACA’s} {Medicaid} {Expansion}},\n  journal = {Public Affairs Quarterly},\n  volume = {27},\n  number = {3},\n  pages = {267-288},\n  date = {2013-07},\n  langid = {en}\n}"
  },
  {
    "objectID": "posts/idakd/in-defense-of-a-kripkean-dogma.html",
    "href": "posts/idakd/in-defense-of-a-kripkean-dogma.html",
    "title": "In Defense of a Kripkean Dogma",
    "section": "",
    "text": "In “Against Arguments from Reference” (Mallon et al. 2009), Ron Mallon, Edouard Machery, Shaun Nichols, and Stephen Stich (hereafter, MMNS) argue that recent experiments concerning reference undermine various philosophical arguments that presuppose the correctness of the causal-historical theory of reference. We will argue three things in reply. First, the experiments in question—concerning Kripke’s Gödel/Schmidt example—don’t really speak to the dispute between descriptivism and the causal-historical theory; though the two theories are empirically testable, we need to look at quite different data than MMNS do to decide between them. Second, the Gödel/Schmidt example plays a different, and much smaller, role in Kripke’s argument for the causal-historical theory than MMNS assume. Finally, and relatedly, even if Kripke is wrong about the Gödel/Schmidt example—indeed, even if the causal-historical theory is not the correct theory of names for some human languages—that does not, contrary to MMNS’s claim, undermine uses of the causal-historical theory in philosophical research projects.\n\nPublished in Philosophy and Phenomenological Research 85: 56-68.\n\n\n0.1 Experiments and Reference\nMMNS start with some by now famous experiments concerning reference and mistaken identity. The one they focus on, and which we’ll focus on too, is a variant of Kripke’s Gödel/Schmidt example. Here is the question they gave to subjects.\n\nSuppose that John has learned in college that Gödel is the man who proved an important mathematical theorem, called the incompleteness of arithmetic. John is quite good at mathematics and he can give an accurate statement of the incompleteness theorem, which he attributes to Gödel as the discoverer. But this is the only thing that he has heard about Gödel. Now suppose that Gödel was not the author of this theorem. A man called “Schmidt” whose body was found in Vienna under mysterious circumstances many years ago, actually did the work in question. His friend Gödel somehow got hold of the manuscript and claimed credit for the work, which was thereafter attributed to Gödel. Thus he has been known as the man who proved the incompleteness of arithmetic. Most people who have heard the name ‘Gödel’ are like John; the claim that Gödel discovered the incompleteness theorem is the only thing they have ever heard about Gödel. When John uses the name ‘Gödel,’ is he talking about:\n\nthe person who really discovered the incompleteness of arithmetic? or\nthe person who got hold of the manuscript and claimed credit for the work? (MMNS 2009: 341)\n\n\nThe striking result is that while a majority of American subjects answer (B), consistently with Kripke’s causal-historical theory of names, the majority of Chinese subjects answer (A).1 To the extent that Kripke’s theory is motivated by the universality of intuitions in favour of his theory in cases like this one, Kripke’s theory is undermined.\n1 Note that a causal descriptivist about names will also say that the correct answer to this question is (B). So the experiment isn’t really testing descriptivism as such versus Kripke’s causal-historical theory, but some particular versions of descriptivism against Kripke’s theory. These versions of descriptivism say that names refer to the satisfiers of (generally non-linguistic) descriptions that the name’s user associates with the name. One such version is ‘famous deeds’ descriptivism, and the descriptions MMNS use are typically famous deeds; nevertheless, that seems inessential to their experiments. When we use ‘descriptivism’ in this paper, we’ll mean any such version of descriptivism. Thanks here to an anonymous referee.There are now a number of challenges to this argument in the literature. Before developing our own challenge, we’ll briefly note five extant ones, which all strike us as at least approximately correct.\nKripke’s theory is a theory of semantic reference. When asked who John is talking about, it is natural that many subjects will take this to be a question about speaker reference. And nothing in Kripke’s theory denies that John might refer to the person who proved the incompleteness of arithmetic, even if his word refers to someone else. (Ludwig 2007; Deutsch 2009)\nKripke’s argument relies on the fact that ’\nGödel’ refers to Gödel, not to the universality or otherwise of intuitions about what it refers to. That some experimental subjects don’t appreciate this fact doesn’t make it any less of a fact. (Deutsch 2009)\nIf the subjects genuinely were descriptivists, it isn’t clear how they could make sense of the vignette, since the name ‘Gödel’ is frequently used in the vignette itself to refer to the causal origin of that name, not to the prover of the incompleteness or arithmetic.\n2\n2 This objection relies on an empirical assumption that may be questionable. It assumes that the subject of the experiment associates the same description with ‘Gödel’ as John does. A subject who (a) is a descriptivist and (b) associates with the name ‘Gödel’ the description ‘the man who proved the compatibility of time travel and general relativity’, can also make sense of the vignette, contra Martí. So perhaps the objection could be resisted. But we think this empirical assumption is actually fairly plausible. Unless the experimental subjects were being picked from a very biased sample, the number of subjects who are familiar with Gödel’s work on closed time-like curves is presumably vanishingly small! We’re grateful here to an anonymous referee.On a related point, Martí doesn’t mention this, but subjects who aren’t descriptivists should also object to the vignette, since in the story John doesn’t learn Gödel proved the incompleteness of arithmetic, at least not if ‘learn’ is factive. (Martı́ 2009)\nThe experiment asks subjects for their judgments about a metalinguistic, and hence somewhat theoretical, question about the mechanics of reference. It’s better practice to observe how people actually refer, rather than asking them what they think about reference. (Martı́ 2009; Devitt 2011)\nIntuitions about the Gödel/Schmidt case play at best a limited role in Kripke’s broader arguments, so experimental data undermining their regularity do not cast serious doubt on Kripke’s theory of reference. (Devitt 2011)\nWe think challenges (1)-(3) work. Something like (4) should work too, although it requires some qualification. Consider, for instance, what happens in syntax. It’s true, of course, that we don’t go around asking ordinary speakers whether they think Lectures on Government and Binding was an advance over Aspects. Or, if we did, we wouldn’t think it had much evidential value. But that’s not because ordinary speaker judgments are irrelevant to syntax. On the contrary, judgments about whether particular strings constitute well-formed sentences are an important part of our evidence.3 But they are not our only evidence, or even our primary evidence; we also use corpus data about which words and phrases are actually used, and many syntacticians take such usage evidence to trump evidence from metasemantic intuitions.4 Even when we do seek such intuitive answers, perhaps because there isn’t enough corpus data to settle the usage issue, the questions might be about cases that are quite different to the cases we primarily care about. So we might ask a lot about speakers’ judgments concerning questions even if we care primarily about the syntax of declarative sentences.\n3 This point suggests Martí’s criticism of MMNS as stated overshoots. She wants to dismiss arguments from metalinguistic intuitions altogether. But intuitions about well-formedness are metalinguistic intuitions, and they are a key part of the syntactician’s toolkit. Martí concedes something like this point, but claims that the cases are not on a par, because syntax concerns a normative issue and reference does not. We’re quite suspicious that there’s such a striking distinction between the kind of subject-matter studied by syntacticians and semanticists. Devitt’s version of this point is more modest and does not obviously commit to this exaggeration.4 Here’s one example where testing intuitions and examining the corpus may lead to different answers. Many people think, perhaps because they’ve picked up something from a bad style guide, that the sentence ‘Whenever someone came into Bill’s shop, he greeted them with a smile’, contains one or two syntactic errors. (It uses a possessive as the antecedent of a pronoun, and it uses ‘them’ as a bound singular variable.) Even if most subjects in a survey said such a sentence was not a well-formed sentence of English, corpus data could be used to show that it is. Certainly the existence of a survey showing that users in, say, Scotland and New Jersey give different answers when asked about whether the sentence is grammatical would not show that there’s a syntactic difference between the dialects spoken in Scotland and New Jersey. You’d also want to see how the sentences are used.If what Kripke (1980) says in Naming and Necessity (hereafter, NN) is right, then we should expect something similar in the case of reference. Kripke anticipates that some people will disagree with him about some of the examples, and offers a few replies. (Our discussion here largely draws on footnote 36 of NN.) Part of his reply is a version of point 1 above; those disagreements may well be over speaker reference, not semantic reference. That reply is correct; it’s hard for us to hear a question about who someone is talking about as anything but a question about speaker reference. He goes on to note that his theory makes empirical predictions about how names are used.\n\nIf I mistake Jones for Smith, I may refer (in an appropriate sense) to Jones when I say that Smith is raking the leaves … Similarly, if I erroneously think that Aristotle wrote such-and-such passage, I may perhaps sometimes use ‘Aristotle’ to refer to the actual author of the passage … In both cases, I will withdraw my original statement, and my original use of the name, if apprised of the facts. (NN 86n)\n\nThis seems entirely right. There’s some sense in which John, in MMNS’s vignette, is referring to\nGödel and some sense in which he’s referring to Schmidt. Just thinking about the particular utterance he makes using ‘Gödel’ won’t help much in teasing apart speaker reference and semantic reference. What we should look to are patterns of—or if they’re not available, intuitions about—withdrawals of statements containing disputed names. To use the example Kripke gives here, consider a speaker who (a) associates with the name ‘Aristotle’ only the description ‘the author of The Republic’, (b) truly believes that a particular passage in The Republic contains a quantifier scope fallacy, and (c) is a descriptivist. She might say “Aristotle commits a quantifier scope fallacy in this passage.” When she’s informed that the passage was written by Plato, she’ll no longer utter those very words, but she’ll still insist that the sentence she uttered was literally true. That’s because she’ll claim that in that sentence ‘Aristotle’ just referred to the author of the passage, and that person did commit a quantifier scope fallacy. A non-descriptivist will take back the claim expressed, though she might insist that what she intended to say was true.\nSo to show that subjects in different parts of the world really have descriptivist intuitions about the Gödel/Schmidt case, we might ask about whether they think John should withdraw, or clarify, his earlier statements if apprised of the facts. Or we might ask whether they would withdraw, or clarify, similar statements they had made if apprised of the facts. Or, even better, we might test whether in practice people in different parts of the world really do withdraw their prior claims at different rates when apprised of the facts about a Gödel/Schmidt case. Kripke is right that given descriptivism, a speaker shouldn’t feel obliged to withdraw the original statement when apprised of the facts, but given the causal-historical theory, they should. So there are experiments that we could run which would discriminate between descriptivist and causal-historical approaches, but we don’t think the actual experiment MMNS run does so.\nIn its broad terms, we agree with Devitt’s challenge (5), although we understand the role of the Gödel/Schmidt case rather differently than he does. We turn now to this question.\n\n\n0.2 Gödel’s Role in Naming and Necessity\nIn the first section we argued that the experimental data MMNS offer do not show that the correct account of the Gödel/Schmidt example is different in different dialects. In this section we want to argue that there’s very little one could show about the Gödel/Schmidt example that would bear on the broader question of what the correct theory of reference is. To see this, let’s review where the Gödel/Schmidt example comes up in Naming and Necessity.\nIn the first lecture, Kripke argues, via the modal argument, that names can’t be synonymous with descriptions. The reason is that in modal contexts, substituting a name for an individuating description alters truth values. So a pure descriptivism that treats names and descriptions as synonymous is off the table. What’s left, thinks Kripke, is what Soames calls “weak descriptivism” (Soames 2003, vols. II, 356). This is the view that although names are not synonymous with descriptions, and do not abbreviate descriptions, they do have their reference fixed by descriptions.\nHere is the way Kripke introduces the picture that he is attacking.\n\nThe picture is this. I want to name an object. I think of some way of describing it uniquely and then I go through, so to speak, a sort of mental ceremony: By ‘Cicero’ I shall mean the man who denounced Cataline … [M]y intentions are given by first, giving some condition which uniquely determines an object, then using a certain word as a name for the object determined by this condition. (NN 79)\n\nThe Gödel/Schmidt example, or at least the version of it that MMNS discuss, comes up in Kripke’s attack on one of the consequences of this picture of naming. (A variant on the example, where no one proves the incompleteness of arithmetic, is used to attack another consequence of the theory.) So the role of the Gödel/Schmidt example is to undermine this picture of names and naming.\nBut note that it is far from the only attack on this picture. Indeed, it is not even the first attack. Kripke’s first argument is that for most names, most users of the name cannot give an individuating description of the bearer of the name. In fact, those users cannot even give a description of the bearer that is individuating by their own lights. The best they can do for ‘Cicero’ is ‘a Roman orator’ and the best they can do for ‘Feynman’ is ‘a famous physicist’. (NN 81) But it isn’t that these users think that there was only one Roman orator, or that there is only one famous physicist. It’s just that they don’t know any more about the bearers of these names they possess. The important point here is that Kripke starts with some examples where the best description a speaker can associate with a name is a description that isn’t individuating even by the speakers’ own lights. And he thinks that descriptivists can’t explain how names work in these cases.\nNow perhaps we’ll get new experimental evidence that even in these cases, some experimental subjects have descriptivist intuitions. Some people might intuit that if a speaker does not know of any property that distinguishes Feynman from Gell-Mann, their name ‘Feynman’ is indeterminate in reference between Feynman from Gell-Mann. We’re not sure what such an experiment would tell us about the metaphysics of reference, but maybe someone could try undermining Kripke’s argument this way. But that’s not what MMNS found; their experiments don’t bear on what Kripke says about ‘Feynman’, and hence don’t bear on his primary argument against weak descriptivism.\nSome philosophers will hold that although the picture Kripke describes here, i.e., weak descriptivism, can’t be right in general for Feynman/Gell-Mann reasons, it could be true in some special cases. We agree. So does Kripke. The very next sentence after the passage quoted above says, “Now there may be some cases in which we actually do this.” (NN 79) And he proceeds to describe three real life cases (concerning ‘Hesperus’, ‘Jack the Ripper’ and ‘Neptune’) where the picture is plausibly correct. But he thinks these cases are rare. In particular, we shouldn’t think that the existence of an individuating description is sufficient reason to believe that we are in such a case. That, at last, is the point of the Gödel/Schmidt example. His conclusion from that example is that weak descriptivism isn’t correct even in those special cases of names where the speaker possesses a description that she takes to be individuating.5\n5 The Gödel/Schmidt example is also distinctive in another way, in that the description in question actually applies to the referent of the name, and indeed speakers actually know this. But the flow of the text around the example (especially on page 84) suggests Kripke intends the example to make the same point as is made by other examples, such as the Peano/Dedekind case (in which the possessed description doesn’t actually apply to the referent of the name). So this is probably not crucial to the point the example makes. We’ll return below to the issue of just what this example shows. The key point is that the more distinctive the example is, the less that would follow if Kripke were wrong about the example; he might only be wrong about examples with just those distinctive features.Michael Devitt (2011) also argues that MMNS exaggerate the importance of the Gödel/Schmidt case. He identifies a number of Kripke’s other arguments (including the Feynman one we mention) that he takes to be more central, and, like us, he argues that MMNS’s results do not cast doubt on these arguments. We agree, noting only two points of difference. First, as suggested above, although the Gödel/Schmidt case is not the only or the most central motivation for Kripke’s theory of reference, we do think that it plays a distinctive role, compared with that of, for instance, the Feynman case. It refutes even the weak version of weak descriptivism according to which, in the special case in which subjects do possess individuating descriptions, those descriptions determine reference. We think the Gödel/Schmidt case (together with the Peano/Dedekind case) form the basis of the only argument in Naming and Necessity against this weak weak descriptivism. (On a closely related point, we, unlike Devitt, take the Gödel/Schmidt case to be addressing a quantitative question about how common descriptive names are, not the qualitative question about whether the causal-historical theory is true at all; we’ll expand on this point below.) Second, Devitt expresses some scepticism about the Gödel/Schmidt judgment on the grounds that the relevant case is somewhat ‘fanciful’—actual cases, Devitt suggests, are better to be trusted. While there is surely some truth in the suggestion that intuitions about esoteric and complicated cases can be less trustworthy than those about everyday ones, we see little reason for concern in this instance; the Gödel case does not describe a scenario we should expect to find trouble thinking about.\nOur reconstruction of the structure of Kripke’s argument should make it clear how unimportant the Gödel/Schmidt example is to the broader theoretical questions. If Kripke were wrong about the Gödel/Schmidt case, that would at most show that there are a few more descriptive names than we thought there were. But since the existence of some descriptive names is consistent with the causal-historical theory of reference, the existence of a few more is too. All the Gödel/Schmidt example is used for in Naming and Necessity is to show that the number of descriptive names in English is not just small, it is very small. But the truth of the causal-historical theory of reference doesn’t turn on whether there are few descriptive names, or very few descriptive names.\nOnce we see that the Gödel/Schmidt example concerns a quantitative question (are descriptive names rare or very rare?) rather than a qualitative question (is the causal-historical theory correct?), we can see some limitations of the experiment MMNS rely on. The case that MMNS describes to their subjects has several distinctive features, and it isn’t clear that we’d be justified in drawing conclusions from it about cases that lack those features. Here is one such feature. The subject of the vignette (John) acquires the name ‘Gödel’ at the same time as he acquires an individuating description of Gödel. Suppose it turned out that, in some dialects at least, that would be sufficient for the name to be a descriptive name; i.e., for it to be a name whose reference is fixed by a description somehow attached to that name. If this conjecture is true, then descriptive names are a little more common than Kripke thinks they are, but not a lot more common. Now we don’t actually think this conjecture is true. And for the reasons given in section 1 we don’t think this experiment is evidence for it. What we do think is that (a) it’s hard to see how studying reactions to cases like the Gödel/Schmidt example could show more than that some such claim about the prevalence of descriptive names is true, and (b) such claims are not inconsistent with the causal-historical theory.\nWe’ve argued that even if Kripke is wrong about the Gödel/Schmidt example, that doesn’t undermine the arguments for the main conclusions of Naming and Necessity. A natural inference from this is that experiments about the Gödel/Schmidt example can’t undermine those conclusions. We think the natural inference is correct. A referee has suggested that this is too quick. After all, if we have experimental evidence that Kripke is wrong about the Gödel/Schmidt case, we might have some grounds for suspicion about the other cases that Kripke uses in the arguments for more central conclusions. That is, if MMNS are right about the Gödel/Schmidt case, that doesn’t give us a deductive argument against the other anti-descriptivist moves, but it might give us an inductive argument against them. This is an important worry, but we think it can be adequately responded to.\nThe first thing to note is that it would be foolish to fall back to a general scepticism about human judgment just because people disagree in their intuitive reactions to some tricky cases. This point is well argued by Timothy Williamson in his (2007 Ch. 6). If there’s a worry here, it must be because the evidence about the Gödel/Schmidt example supports a more modest generalisation about judgments about cases, but that generalisation is nevertheless strong enough to undermine Kripke’s other arguments. We doubt such a generalisation exists.\nIt can’t be that the experiments about the Gödel/Schmidt example show that intuitive judgments about reference are systematically mistaken. Most of our intuitions in this field are surely correct. For instance, our intuitions that ‘Kripke’ refers to Kripke and not Obama, and that ‘Obama’ refers to Obama and not Kripke, are correct. (And experiments like the ones MMNS ran don’t give us any reason at all to doubt that.) And we could produce many more examples like that. At most, the experiments can show us that there are spots of inaccuracy in a larger pool of correct judgments.\nIt might be argued that we should be sceptical of intuitions about reference in counterfactual cases. The correct judgments cited in the previous paragraph are all about real cases, but the Gödel/Schmidt example is not a real case. Now we don’t think that the experiments do undermine all intuitions about reference in counterfactual cases, but even if they did, that wouldn’t affect the Kripkean argument. That’s because the central argument against descriptivism at the start of Lecture II involves real cases. The heavy lifting is done by cases where speakers don’t think they have an individuating description to go along with names they use (e.g., ‘Feynman’ and ‘Gell-Mann’), or they believe they have an individuating description, but that description involves some kind of circularity (e.g., ‘Einstein’, ‘Cicero’). It seems to us that these cases are much more like the cases where we know people have accurate intuitions about reference (e.g., ‘Obama’ refers to Obama), than they are like cases where there is some dispute about their accuracy (e.g., ‘Gödel’ would refer to Gödel even if Schmidt had proved the incompleteness of arithmetic). So there’s no reason to doubt the intuitions that underlie these central Kripkean arguments. And so there’s no reason from these experiments to doubt the anti-descriptivist conclusions Kripke draws from them.\n\n\n0.3 Reference in Philosophy\nIf the data about the Gödel/Schmidt example don’t undermine the causal-historical theory of reference, then presumably they don’t undermine philosophical uses of that theory. But we think MMNS overstate the role that theories of reference play in philosophical theorising, and we’ll end by saying something about this.\nOne simple reaction to MMNS’s argument is to say that at most they show that the causal-historical theory of reference is not true of some dialects. But, a philosopher might say, they are not writing in such a dialect, and the causal-historical theory is true of their dialect. And that’s all they needed for their argument. MMNS anticipate this objection, and reply to it in section 3.3 of their paper. The reply is, in essence, that such a picture would make a mess of communication. If we posit dialectical variation to explain different reactions to the Gödel/Schmidt example, and to other examples, then we cannot know what dialect someone is speaking without knowing how they respond to these examples. And plainly we don’t need to quiz people in detail about philosophical examples in order to communicate with them.\nWe offer three replies.\nFirst, at least one of us is on record raising in principle suspicions about this kind of argument Maitra (2007). The take-home message from that paper is that communication is a lot easier than many theorists have supposed, and requires much less pre-communicative agreement. It seems to us that the reply MMNS offer here is susceptible to the arguments in that paper, but for reasons of space we won’t rehearse those arguments in detail.\nSecond, it’s one thing to think that variation in reference between dialects leads to communication breakdown, it’s another thing altogether to think that variation in meta-semantics leads to such breakdown. A little fable helps make this clear. In some parts of Melbourne, ‘Gödel’ refers to Gödel because of the causal chains between the users of the name and the great mathematician. In other parts, ‘Gödel’ refers to Gödel because the speakers use it as a descriptive name, associated with the description ‘the man who proved the incompleteness of arithmetic’. Kevin doesn’t know which area he is in when he sees a plaque over a door saying “Gödel lived here”. It seems to us that Kevin can understand the sign completely without knowing how ‘Gödel’ got its reference. Indeed, he even knows what proposition the sign expresses. So meta-semantic variation between dialects need not lead to communicative failure, even when hearers don’t know which dialect is being used.\nThird, if MMNS’s argument succeeds, it seems to us that it shows descriptivist theories, including the weak weak descriptivism that Kripke is arguing against with the Gödel/Schmidt example, are doomed. (The arguments in this paragraph are not original. Similar arguments are used frequently in, e.g., Fodor and Lepore (1992).) It’s a platitude that different people know different things. Barring a miracle, that means different people will associate different descriptions with different names. If there is widespread use of descriptive names, that means there will be widespread differences in which descriptions are associated with which names. And that will produce at least as much communicative difficulty as having some people be causal-historical theorists and some people be descriptivists. In short, if MMNS’s argument against ‘referential pluralism’ is sound, there is an equally sound argument against descriptivism. And note that this argument doesn’t rely on any thought experiments about particular cases. It doesn’t even rely on thought experiments about names like ‘Einstein’, where there isn’t any evidence that Kripke is wrong about how those names work.\nDialectically, the situation is this. MMNS have offered an argument from the possibility of communicating under conditions of ignorance about one’s interlocutor’s knowledge. Similar arguments have been offered against descriptivism. If such arguments are successful, then descriptivism is false, and there’s no problem with philosophers making arguments from the falsity of descriptivism. If such arguments are unsuccessful, then MMNS haven’t shown that it is wrong for philosophers to assume that the causal-historical theory is the right theory for their dialect, even if some other people are descriptivists. And, as MMNS concede, as long as the philosophers themselves speak a causal-historical theory dialect, the uses of the causal-historical theory in philosophy seem appropriate. The only way this argument could fail is if MMNS’s argument from the possibility of communicating under conditions of ignorance about one’s interlocutor’s knowledge is stronger than the analogous arguments against descriptivism. But we see no reason to believe that is so. If anything, it seems like a weaker argument, because of the considerations arising from our fable about Kevin and the ‘Gödel lived here’ sign.\nSo we don’t think MMNS have a good reply to the philosopher who insists that they only need the causal-historical theory to be true of their dialect. But in fact we think that philosophers rarely even assume that much.\nLet’s consider one of the examples that they cite: Richard Boyd’s use of the causal-historical theory of reference in developing and defending his version of “Cornell Realism” in his (1988). Here’s one way one could try and argue for moral realism from the causal-historical theory.\n\nThe causal-historical theory of reference is the correct theory of reference for all words in all dialects (or at least our dialect).\nSo, it is the correct theory for ‘good’.\n\nBut that’s not Boyd’s actual argument. And that’s a good thing, because the first premise is implausible. Someone defending it has to explain descriptive names like ‘Neptune’, logical terms like ‘and’, empty predicates like ‘witch’, and so on. And Boyd’s not in that business. His argument is subtler. Boyd uses the causal-historical theory for two purposes. First, he uses the development of a naturalistically acceptable theory of reference as part of a long list of developments in post-positivist philosophy that collectively constitute a “distinctively realist conception of the central issues in the philosophy of science” (Boyd 1988, 188). Second, he uses the causal-historical theory of reference, as it applies to natural kind terms, as part of a story about how we can know a lot about kinds that are not always easily observable (Boyd 1988, 195–96). By analogy, he suggests that we should be optimistic that a naturalistically acceptable moral theory exists, and that it is consistent with us having a lot of moral knowledge.\nOnce we look at the details of Boyd’s argument, we see that it is an argument that duelling intuitions about the Gödel/Schmidt example simply can’t touch. In part that’s because Boyd cares primarily about natural kind terms, not names. But more importantly it is because, as we noted in section 2, the only point that’s at issue by the time Kripke raises the Gödel/Schmidt example is the number of descriptive names. Just looking at the arguments Kripke raises before that example gives us more than enough evidence to use in the kind of argument Boyd is making.\nIt would take us far beyond the length of a short reply to go through every philosophical use of the causal-historical theory that MMNS purport to refute in this much detail. But we think that the kind of response we’ve used here will frequently work. That is, we think few, if any, of the arguments they attack use the parts of the causal-historical theory that Kripke is defending with the Gödel/Schmidt example, and so even if that example fails, it wouldn’t undermine those theories.\n\n\n\n\n\n\nReferences\n\nBoyd, Richard. 1988. “How to Be a Moral Realist.” In Essays in Moral Realism, edited by Geoffrey Sayre-McCord, 181–228. Ithaca: Cornell University Press.\n\n\nDeutsch, Max. 2009. “Experimental Philosophy and the Theory of Reference.” Mind and Language 24 (4): 445–66. https://doi.org/10.1111/j.1468-0017.2009.01370.x.\n\n\nDevitt, Michael. 2011. “Experimental Semantics.” Philosophy and Phenomenological Research 82 (2): 418–35. https://doi.org/ppr201182222.\n\n\nFodor, Jerry A., and Ernest Lepore. 1992. Holism: A Shopper’s Guide. Cambridge: Blackwell.\n\n\nKripke, Saul. 1980. Naming and Necessity. Cambridge: Harvard University Press.\n\n\nLudwig, Kirk. 2007. “The Epistemology of Thought Experiments: First Person Versus Third Person Approaches.” Midwest Studies in Philosophy 31 (1): 128–59. https://doi.org/10.1111/j.1475-4975.2007.00160.x.\n\n\nMaitra, Ishani. 2007. “How and Why to Be a Moderate Contextualist.” In Context Sensitivity and Semantic Minimalism: New Essays on Semantics and Pragmatics, edited by Gerhard Preyer and Georg Peter, 111–32. Oxford: Oxford University Press.\n\n\nMallon, Ron, Eduoard Machery, Shaun Nichols, and Stephen Stich. 2009. “Against Arguments from Reference.” Philosophy and Phenomenological Research 79 (2): 332–56. https://doi.org/10.1111/j.1933-1592.2009.00281.x.\n\n\nMartı́, Genoveva. 2009. “Against Semantic Multi-Culturalism.” Analysis 69 (1): 42–48. https://doi.org/10.1093/analys/ann007.\n\n\nSoames, Scott. 2003. Philosophical Analysis in the Twentieth Century. Princeton: Princeton University Press.\n\n\nWilliamson, Timothy. 2007. The Philosophy of Philosophy. Blackwell."
  },
  {
    "objectID": "posts/rrm/running-risks-morally.html",
    "href": "posts/rrm/running-risks-morally.html",
    "title": "Running Risks Morally",
    "section": "",
    "text": "This paper is part of a project defending normative externalism. This is the view that the most important norms concerning the guidance and evaluation of action and belief are external to the agent being guided or evaluated. The agent simply may not know what the salient norms are, and indeed may have seriously false beliefs about them. The agent may not have any evidence that makes it reasonable to have true beliefs about what the salient norms are, and indeed may have misleading evidence about them. But this does not matter. What one should do, or should believe, in a particular situation is independent of what one thinks one should do or believe, and (in some key respects) of what one’s evidence suggests one should do or believe.\n\nPublished in Philosophical Studies 167: 141-163.\nPhoto by Michel Osmont via Creative Commons.\n\nThere are three important classes of argument relevant to the debate between normative externalists, in the sense of the first paragraph, and normative internalists. One class concerns intuitions about cases. For instance, we might try to defend normative externalism by arguing that according to the internalist, but not the externalist, there is something bad about Huckleberry Finn’s actions in helping Jim escape. Nomy Arpaly (2002) uses this example as part of an argument for a sophisticated form of externalism. Another class concerns views about the nature of norms. Internalists think that externalists have missed the need for a class of subjective norms, that are sensitive to agents’ views about the good. Externalists think that the norms internalists put forward are incoherent, or do not meet the internalists’s needs. I’ll gesture at these arguments below, but they are made in much more detail in recent work by Elizabeth Harman (2015) responding to internalist proposals.\n\nI’ve discussed this paper with just about everyone I know. Thanks to Elizabeth Anderson, Rachael Briggs, Lara Buchak, Sarah Buss, Justin D’Arms, Tom Dougherty, Dmitri Gallow, Alex Guerrero, Elizabeth Harman, Scott Hershovitz, Ishani Maitra, Julia Markovits, Jill North, Timothy Schroeder, Andrew Sepielli, Ted Sider, Rohan Sud, Sigrún Svavarsdóttir and Julie Tannenbaum for suggestions that particularly improved the paper.\n\nBut there’s a third class of argument where the internalist may seem to have an edge. Internalists can argue that there is a wrong of moral recklessness, and externalists cannot explain what is wrong about moral recklessness. My response will be fairly blunt; I do not think moral recklessness is wrong. But I’ll start by trying to state the case for the wrongness of moral recklessness as strongly as I can, including clarifying just what moral recklessness is, before moving onto a response on behalf of the externalist.\n\nThis paper was presented to the EDGe group at the University of Michigan and the philosophy department at Ohio State University, and I got valuable feedback at both of those presentations.\n\n\n0.1 Moral Uncertainty\nSome of our moral opinions are pretty firmly held. Slavery really is wrong; rescuing drowning children is good; and so on. But others might be more uncertain. To use an example I’ll return to a lot, even a lot of carnivores worry that it isn’t obvious that killing animals to eat their flesh is morally permissible.\n\nThe paper also served as my inaugural lecture as the Marshall M. Weinberg Professor at the University of Michigan. Marshall has been a wonderful supporter of the University of Michigan for many years, and especially of its philosophy department, and this was a tremendous honour.\n\nWe might wonder whether this uncertainty should have practical consequences. Uncertainty in general does have practical, and even moral, consequences. If you’re pretty sure the bridge is safe, but not completely certain, you don’t cross the bridge. If you’re only sorta kinda confident that an action won’t kill any innocent bystanders, and there is no compelling reason to do the action, it would be horribly immoral of you to do it.\n\nAnd the paper was presented at the 2013 Bellingham Summer Philosophy Conference. This is close to the Platonic Ideal of a philosophy conference. I’m incredibly grateful to Ned Markosian, and to all of the people who work with him to make this conference happen every year. And I’m very happy to have been able to present this paper at the 2013 conference.\nSo to Marshall and to Ned, thanks.\n\nThere are (at least) two ways to be uncertain about the morally significant consequences of your action. You might know the moral significance of everyone who might be harmed by your action, but not know how many of them will be harmed, or how seriously they will be harmed. Someone who habitually runs red lights is in this position. They know there’s an elevated risk that they’ll kill another human this way, and they know the human they would kill is morally valuable. Alternatively, you might know who or what is affected by your action, but not be sure of their moral status. The hesitant carnivore is like this. They know that steak dinners require killing cows, but they aren’t sure how morally significant the cows are.\nPerhaps that’s a distinction without a difference though. In both cases, the action results in a higher probability of something morally significant being killed. And, one might think, that’s enough to give the actor reason to pause before acting, and enough to give us reason to condemn the action.\nAs may be clear from the introduction, that’s not how I think of the cases. I think the distinction I just flagged is very important both practically and morally. Being uncertain about the physical consequences of your actions should matter both to what you do, and how you are assessed. The red light runner is immoral, even if she never actually harms anyone, because she endangers morally significant humans. But the meat eater cannot be condemned on the same grounds. If she is wrong that meat eating is morally acceptable, that would be one thing. But a mere probability that meat eating is immoral should not change one’s actions, or one’s evaluations of meat eaters.\nNow I won’t pretend this is a particularly intuitive view. In fact, quick reflection on a few cases may make it seem that it is extremely unintuitive. Let’s look at three such cases.\n\nCake\nCarla is baking a cake for a fundraiser. She wants to put some sweetening syrup into the cake to improve its taste. She reaches for an unmarked bottle, which she is pretty sure contains the sweetener she wants. But then she remembers that last week she had some arsenic in a similar bottle. She is pretty sure she threw the arsenic out, but not exactly certain. As a matter of fact, the syrup in the bottle is sweetener, not arsenic, but Carla isn’t certain of this. What should she do?\n\n\nDinner\nMartha is deciding whether to have steak or tofu for dinner. She prefers steak, but knows there are ethical questions around meat-eating. She has studied the relevant biological and philosophical literature, and concluded that it is not wrong to eat steak. But she is not completely certain of this; as with any other philosophical conculsion, she has doubts. As a matter of fact, Martha is right in the sense that a fully informed person in her position would know that meat-eating was permissible, but Martha can’t be certain of this. What should she do?\n\n\nAbortion\nAgnes is twelve weeks pregnant, and wants to have an abortion. She has studied the relevant medical and philosophical literature, and is pretty sure that foetuses at this stage of development are not so morally significant as to make abortion wrong. But she is not completely certain of this; as with any other philosophical conclusion, she has doubts. As a matter of fact, Agnes is right in the sense that a fully informed person in her position would know that abortion was permissible, but Martha can’t be certain of this. What should she do?\n\nThe setup of the last two cases is a bit cumbersome in one key respect; I had to refer to what a fully informed person in Martha or Agnes’s position would know. I did this so as to not beg any questions against the internalist. I would rather say simply that Martha and Agnes were simply right in their beliefs. But I’m not sure how to make sense of this from an internalist perspective. If what’s right to do is a function of your moral evidence and beliefs, perhaps there is a sense in which meat-eating or abortion is objectively permissible, but Martha and Agnes can’t truly believe it is permissible, since it isn’t permissible in their subjective state, and that’s the really important kind of permissibility. So the retreat to talking about what a fully informed person would know is my attempt to find an objective point at which the internalist and externalist can agree. It doesn’t signal that I think there’s anything special about fully informed agents; I’m just trying to avoid being question-begging here.\nYou might also think that one or other of these cases is very far removed from reality. Perhaps what counts as meat or a foetus would have to be very different for these cases to be possible, perhaps so different that they wouldn’t deserve the label ‘meat’ or ‘foetus’. I don’t think this should worry us. I don’t particularly care if the cases are metaphysically possible or not. There’s a world, epistemically if not metaphysically possible, where the medical and biological facts are as they are and meat-eating and abortion are permissible, and that’s the world I mean these examples to be set in. By allowing that my thought experiments may well be set in metaphysically impossible worlds, I am going against some recent views on thought experiments as put forward by, e.g, Timothy Williamson (2007) and Anna-Sara Malmgren (2011), but it would take us too far afield to defend this bit of apostasy. Instead, I’ll just use the cases as they are.\nFinally, note that I’ve set up the cases where the protagonists are almost, but not entirely, sure of something that is in fact true. And I’m going to argue in the moral case that they should act as if they are right. That’s not because I think that a view one is almost sure of should be acted on; one should act on the moral truths, and Agnes and Martha are close to certain of the actual truth. The reason for picking these cases is that they make the issue of recklessness most salient. If any of the three women do anything wrong (and I think Carla does) it is only because they are reckless.\nThat said, there is something interestingly in common to the three cases. In each case, the agent has a choice that is, if taken freely, clearly morally acceptable. Carla can leave out the syrup, Agnes can continue the pregnancy, and Martha can order the tofu. At least, that’s true on the most natural ways to fill out the details of the case.1 So assume that Carla, Martha and Agnes are correctly completely certain that they have a morally safe option. Also assume, if it isn’t clear already, that their only motivation for taking the safe option is to hedge against a possibility that they think is rather unlikely. Hedges can be valuable, so the fact that this is their only motivation is not a reason to not take the safe option.\n1 Here is one argument against the claims of the last two sentences. Assume that, as is realistic, Agnes wants an abortion because her life will be worse in significant ways if she becomes a parent (again) in the near future. And assume that Agnes has a moral duty to herself; making her own life worse in significant ways for no sufficient reason is immoral. Then it could be immoral for her to continue the pregnancy. I don’t find this reason particularly compelling; it seems to me odd to say that people who make heroic sacrifices are immoral in virtue of paying insufficient regard to their own welfare. But the issues here are difficult, and I certainly don’t have a strong argument that we should give no credence to the view that there are substantial duties to self that make misguided sacrifices on behalf of others immoral. Still, I’m going to set this whole line of reasoning aside for most of the paper, while just noting that this could be a way even for an internalist to reject the practical arguments I’ll discuss below. I’m grateful to conversations with Elizabeth Anderson here (but not only here!).In contemporary debates, it’s not often you see pro-vegetarianism and anti-abortion arguments run side by side. Especially in America, these debates have been caught up in culture war politics, and on the whole vegetarians are on one side of this debate, and anti-abortion activists on the other side. But the debates do have some things in common, and it is their commonality that will interest us primarily here. In particular, we’ll be looking at the idea that one should be vegetarian, and refrain from having abortions, on the grounds that these are the good safe options to take. (This connection between the debates is not a novel observation. D. Moller (2011, 426) notes it, and makes some pointed observations about how it affects the philosophical landscape.)\nI’m going to argue that the idea that all three women should ‘play it safe’ is entirely the wrong lesson to take from the cases. I think the cases are in important respects disanalogous. It is seriously morally wrong for Carla to include the syrup in the cake, but it is not wrong in the same way for Martha to eat the steak, or for Agnes to have the abortion. A little more precisely, I’m going to be arguing that there is no good way to fill in the missing premise of this argument.\n\nThe ‘Might’ Argument\n\n\nIn the circumstances that Agnes/Martha are in, having an abortion /eating a steak might be morally wrong.\nIn the circumstances that Agnes/Martha are in, continuing the pregnancy /eating vegetables is definitely morally permissible.\nMissing Premise\nSo, Agnes should not have the abortion, and Martha should not eat the steak.\n\nWhen I argue that the ‘Might’ Argument cannot be filled in, I’m arguing against philosophers who, like Pascal, think they can convince us to act as if they are right as soon as we agree there is a non-zero chance that they are right. I’m as a rule deeply sceptical of any such move, whether it be in ethics, theology, or anywhere else.\nBut note like someone responding to Pascal’s Wager, I’m focussing on a relatively narrow target here. Rejecting Pascal’s Wager does not mean rejecting theism; it means rejecting Pascal’s argument for being a theist. Similarly, rejecting the ‘Might’ Argument does not mean rejecting all ethical arguments against meat-eating or abortion. It just means rejecting this one.\nI’m also not arguing about public policy here. The ‘Might’ Argument can be generalised to any case where there is an epistmic asymmetry. The agent faces a choice where one option is morally risky, and the other is not. Public policy debates are rarely, if ever, like that. A legislator who bans meat-eating or abortion takes a serious moral risk. They interfere seriously with the liberties of the people of their state, and perhaps do so for insufficient reason. (This point is well made by Moller (2011, 442).) So there isn’t a ‘play it safe’ reason to support anti-meat or anti-abortion legislation, even if I’m wrong and there is such a reason to think that individuals should not eat meat or have abortions.\nThere are two ways to try to fill out the ‘Might’ Argument. We could try to offer a particular principle that implies the conclusion given the rest of the premises. Or we could try to stress the analogy between the three cases that I started with. I’m going to have a brief discussion of the first option, and then spend most of my time on the analogy. As we’ll see, there are many possible principles that we could try to use here, but hopefully what I say about a some very simple principles, plus what I say about the analogy, will make it clear how I want to respond to most of them.\n\n\n0.2 Principles\nOne way to fill in the Missing Premise is to have a general principle that links probabilities about morality with action. The simplest such principle that would do the trick is this.\n\nProbWrong\nIf an agent has a choice between two options, and one might be wrong, while the other is definitely permissible, then it is wrong to choose the first option.\n\nI think ProbWrong does a reasonable job of capturing the intuition that Agnes and Martha would be running an impermissible risk in having an abortion or eating meat. But ProbWrong has clearly implausible consequences. Imagine that an agent has the following mental states:\n\nShe is sure that ProbWrong is true.\nShe is almost, but not completely, sure that eating meat is permissible for her now.\nShe is sure that eating vegetables is permissible for her now.\nShe is sure that she has states 1–3.\n\nA little reflection shows that this is an incoherent set of states. Given ProbWrong, it is simply wrong for someone with states 2 and 3 to eat meat. And the agent knows that she has states 2 and 3. So she can deduce from her other commitments and mental states that eating meat is, right now, wrong. So she shouldn’t be almost sure that eating meat is permissible; she should be sure that it is wrong.\nThis argument generalises. If 1, 3 and 4 are true of any agent, the only ways to maintain coherence are to be completely certain that meat eating is permissible, or completely certain that it is impermissible. But that is, I think, absurd; these are hard questions, and it is perfectly reasonable to be uncertain about them. At least, there is nothing incoherent about being uncertain about them. But ProbWrong implies that this kind of uncertainty is incoherent, at least for believers in the truth of ProbWrong itself. Indeed, it implies that in any asymmetric moral risk case, an agent who knows the truth of ProbWrong and is aware of her own mental states cannot have any attitude between certainty that both options are permissible, and certainty that the risky action is not, for her, permissible. That is, I think, completely absurd.\nNow most philosophers who advocate some principle or other as the Missing Premise don’t quite advocate ProbWrong. We can position some of the rival views by abstracting away from ProbWrong as follows.\n\nGeneral Principle\nIf an agent has a choice between two options, and one might be X, while the other is definitely not X, then it is Y to choose the first option.\n\nWe get ProbWrong by substituting ‘wrong’ for both X and Y. But we saw a decisive objection to that view. And we get a version of that objection for any substitution where X and Y are the same. So a natural move is to use different substitutions. If you replace X with ‘wrong’ and Y with ‘irrational’, you get something like a principle defended by Ted Lockhart (2000).\n\nWhat Might be Wrong Is Irrational\nIf an agent has a choice between two options, and one might be wrong, while the other is definitely not wrong, then it is irrational to choose the first option.\n\nNow at this stage we could look at whether this principle is plausible, and if not whether alternative principles offered by Alex Guerrero (2007), Andrew Sepielli (2009) or others are any better. You can probably guess how this would go. We’d spend some time on counterexamples to the principle. And we’d spend some time on whether the conclusion we get in this particular case is really plausible. (Is it true that Martha is not in any way immoral, but is irrational in virtue of moral risk? That doesn’t sound at all like the right conclusion.)\nBut I’m not going to go down that path. Shamelessly stealing an analogy from Jerry Fodor (2000), I’m not going to get into a game of Whack-a-Mole, where I try to reject a principle that could fill in for the Missing Premise, and if I succeed, another one pops up. I’m not playing that game because you never actually win Whack-a-Mole; by going through possible principles one at a time it isn’t clear how I could ever show that no principle could do the job.\nWhat I need to show is that we shouldn’t look for a principle to fill in as Missing Premise. One reason we shouldn’t is that the intuitions behind principles like Lockhart’s is really an intuition in favour of ProbWrong, and as such should be suspect. But a better reason is that the analogy between Carla’s case and Agnes/Martha’s cases that motivated the thought that there should be some principle here is mistaken. Once we see how weak that analogy is, I think we’ll lose motivation for trying to fix ProbWrong.\n\n\n0.3 Welfare and Rationality\nSo my primary opponent the rest of the way is someone who wants to defend the ‘Might’ Argument by pressing the analogy between Carla’s case and the two more morally loaded cases.2 My reply will be that there are better analogies than this which point in the opposite direction. In particular, I’m going to draw an analogy between Agnes and Martha’s cases with some tricky cases concerning prudential reasoning. To set up the case, I’ll start with an assumption that guides the discussion.\n2 D. Moller (2011) offers an interesting different analogy to motivate something like the ‘Might’ Argument. I think that analogy is a little messier than the one I’m focussing on, and I’ll discuss it separately below.The assumption is that deliberately undermining your own welfare, for no gain of any kind to anyone, is irrational. Indeed, it may be the paradigmatic form of irrationality. This is, I think, a widely if not universally held view. There is a radically Humean view that says that welfrae just consists of preference satisfaction, and rationality is just a matter of means-end reasoning. If that’s right then this assumption is not only right, it states the only kind of irrationality there is. But you don’t have to be that radical a Humean, or really any kind of Humean at all, to think the assumption is true.\nThe assumption doesn’t just mean that doing things that you know will undermine your welfare for no associated gain is irrational. It means that taking serious risks with your welfare for no compensating gain is irrational. Here is a clear example of that.\n\nEating Cake\nRicky is baking a cake for himself. He wants to put some sweetening syrup into the cake to improve its taste. He reaches for an unmarked bottle, which he is pretty sure contains the sweetener he wants. But then he remembers that last week he had some arsenic in a similar bottle. He is pretty sure that he threw the arsenic out, but not exactly certain. As a matter of fact, the bottle does contain sweetener, not arsenic, but Ricky isn’t completely sure of this. What should he do?\n\nI hope it is plausible enough that it would be irrational for Ricky to put the syrup in the cake. The risk he is running to his own welfare – he literally will due if he’s wrong about what’s in the bottle – isn’t worth the gain in taste, given his level of confidence.\nWith that said, consider two more examples, Bob and Bruce. Bob has thought a bit about philosophical views on welfare. In particular, he has spent a lot of time arguing with a colleague who has the G. E. Moore-inspired view that all that matters to welfare is the appreciation of beauty, and personal love.3 Bob is pretty sure this isn’t right, but he isn’t certain, since he has a lot of respect for both his colleague and for Moore.\n3 It would be a bit of a stretch to say this is Moore’s own view, but you can see how a philosopher might get from Moore to here. Appreciation of beauty is one of the constituents of welfare in the objective list theory of welfare put forward by John Finnis (2011, 87–88).Bob also doesn’t care much for visual arts. He thought that art is something he should learn something about, both because of the value other people get from art, and because of what you can learn about the human condition from it. And while he’s grateful for what he learned while trying to inculcate an appreciation of art, and he has become a much more reliable judge of what’s beautiful and what isn’t, the art itself just leaves him cold. I suspect most of us are like Bob about some fields of art; there are genres that we feel have at best a kind of sterile beauty. That’s how Bob feels about most visual art. This is perhaps unfortunate; we should feel sorry for Bob that he doesn’t get as much pleasure from great art as we do. But it doesn’t make Bob irrational, just unlucky.\nFinally, we will suppose, Bob is right to reject his colleague’s Moorean view on welfare. Appreciation of art isn’t a constituent of welfare. In the example we’ll suppose welfare is a matter of health, happiness and friendship. So a fairly restricted version of an objective list theory of welfare is correct in Bob’s world. And for people who like art, appreciating art can produce a lot of goods. Some of these are direct - art can make you happy. And some are indirect - art can teach you things and that learning can contribute to your welfare down the line. But if the art doesn’t make you happy, as it doesn’t make Bob happy, and one has learned all one can from a genre, as has Bob, there is no welfare gain from going to see art. It doesn’t in itself make you better off, as Bob’s Moorean colleague thinks.\nNow Bob has to decide whether to spend some time at an art gallery on his way home. He knows the art there will be beautiful, and he knows it will leave him cold. There isn’t any cost to going, but there isn’t anything else he’ll gain by going either. Still, Bob decides it isn’t worth the trouble, and stays out. He doesn’t have anything else to do, so he simply takes a slightly more direct walk home, which (as he knows) makes at best a trifling gain to his welfare.\nI think Bob is perfectly rational to do this. He doesn’t stand to gain anything at all from going to the gallery. In fact, it would be a little perverse, in a sense we’ll return to, if he did go.\nBruce is also almost, but not completely certain, that health, happiness and friendship are the sole constituents of welfare.4 But he worries that this is undervaluing art. He isn’t so worried by the Moorean considerations of Bob’s colleagues. But he fears there is something to the Millian distinction between higher and lower pleasures, and thinks that perhaps higher pleasures contribute more to welfare than lower pleasures. Now most of Bruce’s credence goes to alternative views. He is mostly confident that people think higher pleasures are more valuable than lower pleasures because they are confusing causation and constitution. It’s true that experienceing higher pleasures will, typically, be part of experiences with more downstream benefits than experiences of lower pleasures. But that’s the only difference between the two that’s prudentially relevant. (Bruce also suspects the Millian view goes along with a pernicious conservatism that values the pop culture of the past over the pop culture of the present solely because it is past. But that’s not central to his theory of welfare.) And like Bob, we’ll assume Bruce is right about the theory of welfare in the world of the example.\n4 Thanks to Julia Markovits for suggesting the central idea behind the Bruce example, and to Jill North for some comments that showed the need for it.Now Bruce can also go to the art gallery. And, unlike Bob, he will like doing so. But going to it will mean he has to miss a night playing video games that he often goes to. Bruce knows he will enjoy the video games more. And since playing video games with friends helps strengthen friendships, there may be a further reason to skip the gallery and play games. Like Bob, Bruce knows that there can be very good consequences of seeing great art. But also like Bob, Bruce knows that none of that relevant here. Given Bruce’s background knowledge, he will have fun at the exhibition, but won’t learn anything significant.\nStill, Bruce worries that he should take a slightly smaller amount of higher pleasure rather than a slightly larger amount of lower pleasure. And he’s worried about this even though he doesn’t give a lot of credence to the whole theory of higher and lower pleasures. But he doesn’t go to the gallery. He simply decides to act on the basis of his preferred theory of welfare, and since that welfare is correct, he maximises his welfare by doing this.\nNow I think both Bob and Bruce are rational in what they do. But there is an argument that they are not. I’ll focus on Bob, but the points here generalise.\n\nGoing to the gallery might increase his welfare substantially, since it will lead to more appreciation of beauty, and appreciation of beauty might be a key constituent of welfare.\nNot going to the gallery definitely won’t increase his welfare by more than a trivial amount.\nIt is irrational to do something that might seriously undermine your own welfare for no compensating gain.\nSo it is irrational for Bob to skip the gallery.\n\nI think that argument is wrong. Bob’s case is rather unlike Ricky’s. There is a sense in which Bob might be undermining his own welfare in skipping the gallery. But it is not the relevant sense. We can distinguish the two senses making the scope of various operators explicit. The first of these claims is plausibly true; the second is false.\n\nBob’s welfare is such that it is irrational for him to do something that might undermine it for no compensating gain.\nIt is irrational for Bob to do something that might undermine his welfare, whatever that turns out to be, for no compensating gain.\n\nIf welfare turns out to be health, happiness and learning, then the first claim says that it is irrational to risk undermining your health, happiness and learning for no compensating gain. And that is, I think, right. But the second claim says that for any thing, if that thing might be welfare, and an action might undermine it, it is irrational to perform the action without a compensating gain. That’s a much stronger, and a much less plausible, claim.\nImportantly, Bob’s ‘Might’ Argument doesn’t go through with the first claim. Given that appreciation of beauty is not directly a component of welfare, and that the various channels through which appreciating beauty might lead to an increase in welfare are blocked for Bob, there is no chance that going to the gallery will increase his actual welfare. Going to the gallery will increase something, namely his appreciation of beauty, that is for all Bob knows part of welfare. But that’s not the same thing, and it isn’t relevant to rationality.\nOne caveat to all this. On some theories of welfare, it will not be obvious that even the first claim is right. Consider a view (standard among economists) that welfare is preference satisfaction. Now you might think that even the first claim is ambiguous, between a claim that one’s preferences are such that it is irrational to undermine them (plausibly true), and a claim that it is irrational to undermine one’s preference satisfaction. The latter claim is not true. If someone offers me a pill that will make me have preferences for things that are sure to come out true (I want the USA to be more populous than Monaco; etc.), it is rational to refuse it. And that’s true even though taking the pill will ensure that I do well by preference satisfaction. The point is that taking the pill does not, as things stand, satisfy my preferences. If I prefer X to Y, I should aim to bring about X. But I shouldn’t aim to bring about a state of having satisfied preferences; that could lead to rather perverse behaviour, like taking this pill.\n\n\n0.4 Duelling Analogies\nHere’s how I see the five cases we’ve discussed so far fitting together.\n\n\n\n\nFactual Uncertainty\nNormative Uncertainty\n\n\n\n\nPrudential\nRicky\nBob\n\n\nRisk\n\nBruce\n\n\n\n\n\n\n\nMoral\nCarla\nAgnes\n\n\nRisk\n\nMartha\n\n\n\nOn the left-hand column, we have agents who are uncertain about a simple factual question; is this syrup sweetener or arsenic? On the right-hand column, we have agents who are uncertain about a question about the nature of value; does the decision I’m facing right now have serious evaluative consequences?\nIt’s even easier to see what is separating the rows. Ricky, Bob and Bruce face questions that, in the first instance, just concern their own welfare. Carla, Agnes and Martha face questions that concern the morality of their actions. I don’t mean to say that there’s a hard line between these two. Perhaps being moral is an important part of the good life. And perhaps one has a moral duty to live well. I’m a little doubtful on both scores actually. But even if the questions bleed into each other in one or other way, we can separate questions that are in the first instance about the agent’s own welfare from questions that bear directly on the morality of the agent. (Recognising, as always, that there will be borderline cases.) And that’s how we’ve split the rows.\nOne way to motivate the ‘Might’ Argument is to stress the analogy between Carla and Agnes/Martha. After all, both of them risk killing someone (or something) statused if they act in a certain way. But once we look at the table more broadly, it is easy to see why we should resist the analogy between Carla and Agnes/Martha. The analogy between Bob/Bruce and Agnes/Martha is much stronger. We can see that by thinking about their motivations.\nWhy would Bruce go to the gallery? Not for pleasure; he’ll get more pleasure out of playing video games with his friends. Not for the educational value; he won’t learn more by looking at these kind of paintings again. His only reason for going is that he thinks it might increase his welfare. That is, he can only be motivated to go if he is motivated to care about welfare as such, and not about the things that make up welfare. There is something perverse about this motivation. It is healthy and natural to want the things that make up a good life. It is less healthy, and less natural, to directly desire a good life whatever that may be.\nNow think about Martha. Why should she turn down the steak? Not because she values the interests of the cow over her dining. She does not. And not because she should have that value. By hypothesis, she need not do so. (Remember we’re only interested in replying to people who argue from The ‘Might’ Argument to vegetarianism; if you think there’s a direct argument that Martha should value the cow so highly that she doesn’t eat meat, that’s a different debate.) Rather, she has to care about morality as such. And that seems wrong.\nThe argument I’m making here owes a lot to a similar argument offered for a somewhat different conclusion by Michael Smith (1994). He compared the person who desires to do what is actually right, as he put it, desires the right de re, with the person who desires to do what is right whatever that turns out to be, as he put it, desires the right de dicto.\n\nGood people care non-derivatively about honesty, the weal and woe of their children and friends, the well-being of their fellows, people getting what they deserve, justice, equality, and the like, not just one thing: doing what they believe to be right, where this is read de dicto and not de re. Indeed, commonsense tells us that being so motivated is a fetish or moral vice, not the one and only moral virtue.  (Smith 1994, 75)\n\nI think that’s all true. A good person will dive into a river to rescue a drowning child. (Assuming that is that it is safe enough to do so; it’s wrong to create more rescue work for onlookers.) And she won’t do so because it’s the right thing to do. She’ll do it because there’s a child who needs to be rescued, and that child is valuable.\nThe analogy with the welfare case strengthens this conclusion. The rational person values their health, happiness and friendships (and whatever goes into the actual list of things that constitute welfare.). They don’t simply value their welfare, and desire to increase it. That’s why it would be perverse for Bruce to go to the gallery. He would only go if he had a strange motivation. And it is why it would be perverse for Martha to turn down the steak. To do so she would have to care about morality, whatever it is, not about the list of things that Smith rightly says a good person will care about.\n\n\n0.5 An Alternative Analogy\nMoller offers the following analogy to back up something like the ‘Might’ Argument.5\n5 Though note that Moller’s own position is more moderate than what the ‘Might’ Argument suggests; he thinks moral risk should play a role in reasoning, but not necessarily so strong a role as to make the ‘Might’ Argument go through. I’m advocating what he calls the “extreme view, we never need to take moral risk into account; it is always permissible to take moral risks.” (435).}\nSuppose Frank is the dean of a large medical school. Because his work often involves ethical complications touching on issues like medical experimentation and intellectual property, Frank has an ethical advisory committee consisting of 10 members that helps him make difficult decisions. One day Frank must decide whether to pursue important research for the company in one of two ways: plan A and plan B would both accomplish the necessary research, and seem to differ only to the trivial extent that plan A would involve slightly less paperwork for Frank. But then Frank consults the ethics committee, which tells him that although everyone on the committee is absolutely convinced that plan B is morally permissible, a significant minority - four of the members - feel that plan A is a moral catastrophe. So the majority of the committee thinks that the evidence favors believing that both plans are permissible, but a significant minority is confident that one of the plans would be a moral abomination, and there are practically no costs attached to avoiding that possibility. Let’s assume that Frank himself cannot investigate the moral issues involved - doing so would involve neglecting his other responsibilities. Let’s also assume that Frank generally trusts the members of the committee and has no special reason to disregard certain members’ opinions. Suppose that Frank decides to go ahead with plan A, which creates slightly less paperwork for him, even though, as he acknowledges, there seems to be a pretty significant chance that enacting that plan will result in doing something very deeply wrong and he has a virtually cost-free alternative. (436)\n\nThe intuitions are supposed to be that this is a very bad thing for Frank to do, and that this illustrates that there’s something very wrong with ignoring moral risk. But once we fill in the details of the case, it is clear that this can’t be the right diagnosis.\nThe first thing to note is that there is something special about decision making as the head of an organization. Frank doesn’t just have a duty to do what he thinks is best. He has a duty to reflect his school’s policies and viewpoints. A dean is not a dictator, not even an enlightened, benevolent one. Not considering an advisory committee’s report is bad practice qua dean of the medical school, whether or not Frank’s own decisions should be guided by moral risk.\nWe aren’t told whether A or B are moral catastrophes. If B is a moral catastrophe, and A isn’t, there’s something good about what Frank does. Of course, he does it for the wrong reasons, and that might undercut our admiration of him. But it does seem relevant to our assessment to know whether A or B are actually permissible.\nAssuming that B is actually permissible, the most natural reading of the case is that Frank shouldn’t do A. Or, at least, that he shouldn’t do A for this reason. But that doesn’t mean he should be sensitive to moral risk. Unless the four members who think that A is a moral catastrophe are crazy, there must be some non-moral facts that make A morally risky. If Frank doesn’t know what those facts are, then he isn’t just making a decision under moral risk, he’s making a decision involving physical risk. And that’s clearly a bad thing to do.\nIf Frank does know why the committee members think that the plan is a moral catastrophe, his action is worse. Authorising a particular kind of medical experimentation, when you know what effects it will have on people, and where intelligent people think this is morally impermissible, on the basis of convenience seems to show a striking lack of character and judgment. Even if Frank doesn’t have the time to work through all the ins and outs of the case, it doesn’t follow that it is permissible to make decisions based on convenience, rather than based on some (probably incomplete) assessment of the costs and benefits of the program.\nBut having said all that, there’s one variant of this case, perhaps somewhat implausible, where it doesn’t seem that Frank should listen to the committee at all. Assume that both Frank and the committee have a fairly thick understanding of what’s involved in doing A and B. They know which actions maximise expected utility, they know that which acts are consistent with the categorical imperative, they know which people affected by the acts would be entitled to complain about our performance, or non-performance, of each act, they know which acts are such that everyone could rationally will it to be true that everyone believes those acts to be morally permitted, and so on. What they disagree about is what rightness and wrongness consist in. What’s common knowledge between Frank, the majority and the minority is that both A and B pass all these tests, with one exception: A is not consistent with the categorical imperative. And the minority members of the committee are committed Kantians, who think that they have a response to the best recent anti-Kantian arguments.\nIt seems to me, intuitively, that this shouldn’t matter one whit. I think the extreme view I’m defending in this paper is not, in general, intuitive. But it is worth noting how counterintuitive the opposing view is in this extreme case. A moral agent simply won’t care what the latest journal articles have been saying about the relative importance of Kant’s formulation of the categorical imperative versus either contemporary variants or approaches from very different traditions. It’s possible (though personally I doubt it), that learning of an action that it violates the categorical imperative would be relevant to one’s motivations. It’s not possible that learning that some people you admire think the categorical imperative is central to morality could change one’s motivation to perform, or not perform, actions one knew all along violated the categorical imperative. At least that’s not possible without falling into the bad kind of moral fetishism that Smith rightly decries.\nSo here’s my general response to analogies of this kind, one that shouldn’t be surprising given the previous sections. Assuming the minority committee members are rational, either they know some facts about the impacts of A and B that Frank is unaware of, or they hold some philosophical theory that Frank doesn’t. If it’s the former, Frank should take their concerns into account; but that’s not because he should be sensitive to moral risk, it’s because he should be sensitive to non-moral risk. If it’s the latter, Frank shouldn’t take their concerns into account; that would be moral fetishism.\n\n\n0.6 Objections and Replies\nI’ve discussed this paper with many people, and they almost all have objections. I’m going to respond to some of the most pressing, and end with three objections that I don’t have a particularly satisfying response to. The most important objection, from my perspective, is the second; it’s what most closely links the discussion of this paper to the broader issues about normative externalism that I find most fascinating.\nObjection: All you’ve shown so far is that moral recklessness isn’t objectively wrong. But that’s trivial. There’s a sense in which ordinary recklessness isn’t objectively wrong either. What matters is that both are subjectively wrong, where this tracks what the agent believes.\nReply: Distinguish between two things: doing things that produce bad outcomes, and doing the wrong thing. Unless you are sure that actualist consequentialism is a conceptual truth, this is a conceptually coherent distinction. Among actions that produce bad outcomes, there are easily detectable distinctions we draw that seem to track whether the actions are wrong.\nIn the paper so far I’ve usually been focussed on people who are almost certain of the truth. But let’s change tack for a minute and look at people who have catastrophically false beliefs. In particular, consider Hannah and Hannibal. (I’m taking the Hannibal example from work by Elizabeth Harman (2011), who uses it for a related purpose.)\nHannah takes her spouse out for what is meant to be a pleasant anniversary dinner. It’s a nice restaurant, and there’s no reason to think anything will go wrong. But the restaurant gets bad supplies that day, and Hannah’s spouse gets very sick as a consequence of going there.\nHannibal is a 1950s father with sexist attitudes that were sadly typical. He has a son and a daughter, and makes sure to put together a good college savings fund for his son, but does not do the same for his daughter. Indeed, if he had tried to do the same for his daughter, he would not have been able to support his son as well as he actually did. As a consequence, his daughter cannot afford to go to college.\nHannah was mistaken about a matter of fact; whether the food at the restaurant was safe. Hannibal was mistaken about a moral matter; whether one should treat one’s sons and daughters equally. Now consider what happens when both see the error of their ways. Hannah should feel bad for her spouse, but there is no need for any kind of self-reproach. It’s hard to imagine she would feel ashamed for what she did. And there’s no obligation for her to feel guilty, though it’s easier to imagine she would feel some guilt. Hannibal, on the other hand, should feel both ashamed and guilty. And I think it’s natural that a father who realised too late that he had been guilty of this kind of sexism would in fact feel the shame and guilt he should feel. The fact that his earlier sexist attitudes were widely shared, and firmly and sincerely held, simply seems irrelevant here.\nThe simplest explanation of this emotional difference is that what Hannibal does is, in an important sense, wrong, and what Hannah does is not wrong. But the wrongness at issue is missing from the objective/subjective distinction the objector here makes. Both Hannah and Hannibal do things that make things objectively worse. Both Hannah and Hannibal do things that are good given their beliefs at the time they act. Yet there is a distinction between them. It’s this distinction that the normative externalist wants to stress. There’s a normative status that is not wholly objective, insofar as it doesn’t reproach Hannah, but not wholly subjective, insofar as it does reproach Hannibal.\nObjection: But still, we need a standard that can guide the agent, that an agent can live by. Do the right thing, whatever it turns out to be, is not such a standard. And what motivates internalism is the thought that this kind of agent-centred norm is most important.\nReply: If this is the motivation for internalism, it is vulnerable to a nasty regress. The problem is that internalists disagree amongst themselves, and there is no internalist-friendly way to resolve the disagreement.6 (Much of what I say here draws on arguments that Elizabeth Harman (2015) makes about the nature of internalist norms.)\n6 In Weatherson (2013) I make a similar objection to normative internalism in epistemology. It’s this point of connection that’s made me focus on normative internalism and externalism, not moral internalism and externalism. The issues in ethics and in epistemology are very closely connected here.The examples that illustrate this point are a little convoluted, so I’ll just state one example schematically to make the point. And I’ll put numerical values on options because it is hard to state the internalist views without doing this.\nAn agent faces a choice between four options: A, B, C and D. Option A is the right option, both in the sense that the externalist will praise people who take it and criticise others, and in the sense that a fully informed intrnalist would do A. But our agent is, sadly, not fully informed. She thinks A is a completely horrible thing do to. Her credences are split over three moral theories, X, Y and Z, with credence 0.5 in X, 0.1 in Y, and 0.4 in Z. The moral values of each action according to each moral theory are given by this table. (Higher values are better; non-negative values are for actions that are permissible according to the theory.)\n@RCCC@ &X&Y&Z\nB&0&0&–20\nC&0&–30&–10\nD&–1&–5&0\n\nSo the probability, according to the agent, that each action is permissible is 0.6 for B, 0.5 for C and 0.4 for D. The expected moral value of each action is –8 for B, –7 for C, and –2 for D.\nOur agent at this stage is a bit confused. And reading some philosophy doesn’t help. She reads Ted Lockhart (2000) saying that what she should do is the thing that is most probably permissible. And she reads Andrew Sepielli (2009) saying that what she should do is the thing that maximises expected moral value. But these pieces of advice pull in opposite directions. She could try and come up with a theory of how to resolve the tension, but that is just as hard as resolving the dispute between Lockhart and Sepielli in the first place. She eventually settles on the rule Don’t do what any plausible meta-theory says is the worst thing to do. Since Lockhart says D is the worst thing to do (having the lowest probability of permissibility), and Sepielli says that B is the worst thing to do (having the lowest expected moral value), she does C.\nHere’s the lesson of this little parable. There is a worry that externalism is not sufficiently action guiding, and can’t be a norm that agents can live by. But any philosophical theory whatsoever is going to have to say something about how to judge agents who ascribe some credence to a rival theory. That’s true whether the theory is the first-order theory that Jeremy Bentham offers, or the second-order theory that Andrew Sepielli offers. Once you’re in the business of theorising at all, you’re going to impose an external standard on an agent, one that an agent may, in good faith and something like good conscience, sincerely reject. The externalist says that it’s better to have that standard be one concerned with what is genuinely valuable in the world, rather than a technical standard about resolving moral uncertainty. But every theorist has to be a little bit externalist; the objector who searches for a thoroughly subjective standard is going to end up like Ponce de Leon.\nObjection: You’ve focussed on the case where Martha is almost sure that meat-eating is permissible. What do we say about the person who is almost sure that meat-eating is impermissible, eats meat anyway, and gets lucky, because they are in a world where it is permissible? The normative externalist says that they are beyond reproach, but something seems wrong here.\nReply: The externalist is only committed to the view that the most important evaluative concepts are independent of the agent’s beliefs. There is something rather simple to say about this person; they are a hypocrite.\nObjection: Wait a minute! We wanted something reproachful to say about this person. But all you’ve said is that they are a hypocrite, by which you presumably mean they don’t act in accord with their beliefs about what’s valuable. And Huckleberry Finn is a hypocrite in that sense, but also beyond reproach.\nReply: Good point, but I think we can still say something. Huckleberry Finn acts against what he believes to be most valuable in order to preserve a great good: Jim’s freedom. Our imagined meat-eater acts against what he believes to be most valuable in order to get a tastier lunch. Someone who will do what they believe to be wrong in order to produce a gain which is both trivial, and entirely accrues to them, reveals a bad character. The gain that Huckleberry Finn’s actions produce, note, are neither trivial nor selfish, and that’s why his actions do not indicate a character defect. But giving up on morality for a trivial, selfish gain is a sign that things will go very badly wrong, very soon.7\n7 The Huckleberry Finn case has been discussed extensively by Nomy Arpaly and Timothy Schroeder  (Arpaly 2002, 2003; Arpaly and Schroeder 1999, 2014), and I’m relying heavily on their analysis of the case in what I say here and elsewhere about Huckleberry Finn. More generally, the picture I’m assuming of moral motivation owes a lot to those works.Objection: How can you even acknowledge such a thing as hypocrisy? Isn’t the positing of such a norm vulnerable to the same regress arguments as you’ve run against the internalist?\nReply: No, because we can be an externalist about what is and is not hypocritical. We can, at least in theory, imagine these two cases. The first case is a person whose beliefs, credences and values indicate that the best thing to do is B, but who thinks the best thing to do given those beliefs, credences and values is C. They do C. They are hypocritical, although they (falsely) do not believe they are. The second case is a person who is exactly like this, except they do B. They are not acting hypocritically. Or, at least, they are not a first-order hypocrite. Perhaps we can recognise a distinct state of second-order hypocrisy, and say that they fall under it. And you can imagine even higher-orders. The externalist can say all of these exist. They aren’t the worst offences ever, but it is coherent to posit all of them.\nObjection: Once you recognise hypocrisy, there is a way to reinstate the ‘Might’ Argument. Martha and Agnes are hypocrites. They shouldn’t be hypocrites. So they shouldn’t eat meat, or have an abortion.\nReply: I simply deny that they are hypocrites. Compare these three statuses.\n\nDoing that which you disvalue.\nDoing that which you believe to be less valuable.\nDoing that which you have some credence is less valuable.\n\nThe first is clearly hypocrisy, and the second seems similar. But there’s no reason to say the third is hypocritical. The following example, closely modelled on one offered by Lara Buchak (2014) makes this point.\nAnnie values her close relationship with her brother Jack. One day, she receives some evidence that marginally raises her credence that Jack did something horrible. She is pretty sure Jack is innocent, but her credence in his guilt does rise a notch. Still, Annie values her relationship with Jack just as much as she did before. If Jack did the horrible thing, she would not value the relationship. But getting some (almost surely misleading) evidence that Jack did something horrible does not change her values at all.\nThe lesson here is that credences about what is valuable can quite coherently float free from valuings. There is a tricky question about what happens to beliefs about what is valuable in these cases. Buchak thinks they should go with valuings, and this is a problem for theories that reduce credence to belief. I don’t agree with this extension of her argument, but I certainly agree that small changes in credence about what is valuable need not, and often should not, change what one values.\nObjection: The externalist can’t explain why moral ignorance exculpates.\nReply: The short reply is that, following for example Elizabeth Harman (2011), I don’t think moral ignorance does exculpate. But the longer reply is that the internalist can’t explain why moral ignorance is at best an excuse, not a defence, and why it only works in special circumstances.\nWe already saw one distinctive aspect of moral ignorance above, in the Hannibal example. Hannibal should feel ashamed, and guilty, about what he did. That’s because even if he had an excuse, he did the wrong thing. And this doesn’t just mean he made the world worse. This notion of wrongness is an externalist one, even if we allow an internalist friendly excuse for the wrong action.\nBut when we turn to classic defenders of the idea that moral ignorance can be exculpatory, such as Susan Wolf (1980) and Cheshire Calhoun (1989), we see that it is meant to be an excuse with a very limited scope. And whether the circumstances are such as to furnish this excuse will not always be clear to the wrong-doer. (Indeed, it might be that they are not, and could not, be clear.) So even if moral ignorance was exculpatory, this wouldn’t be much help to the internalist. Since on everyone’s view some moral ignorance is blameworthy, and the factors that may make moral ignorance an excuse are external to the agent, only the externalist can offer a plausible theory on which moral ignorance is exculpatory.\nObjection: Even if it is fetishistic to be motivated by the good as such, this doesn’t extend to thick moral properties. Indeed, the quote from Smith you use explicitly contrasts the thinnest of moral properties with ever so slightly thicker ones. So your objections to arguments from moral uncertainty don’t extend to arguments from what we might call virtue uncertainty.\nReply: I agree with this. Here are some things that seem like be non-fetishistic motivations to avoid doing action A.\n\nIt would be cowardly to do A.\nDoing A would be free-riding.\nI would not appreciate if others did A-like actions that could disadvantage me.\n\nThe objector draws attention to the distinction between thick and thin moral properties, and I think that’s the right way to highlight what’s at issue here. But note how thin these are getting. I’m conceding that the fact that something violates the Golden Rule could be a motivation, as could the fact that it violates the categorical imperative.8 What I deny is that the wrongness of the action could be an extra motivation over and above these. This was the point of the discussion of Moller’s executive in the previous section.\n8 To be clear, I’m conceding that these motivations are consistent with the argument of the paper. My own view is that while realising that something violates the Golden Rule could be a motivation, as is evident from how we teach morality to children, realising that it violates the categorical imperative should not be motivating. But the argument of the paper doesn’t turn on my quirky views here. What matters is that we distinguish wrongness itself from properties like harming another person, not what other properties we group in with wrongness.For each of these motivations, there are cases where the risk of violating the relevant standard can be motivating. So one might not do something because there is a risk that it would be cowardly, or free-riding, or violate the Golden Rule or categorical imperative. I don’t mean to object to any argument along these lines.\nObjection: Now you’ve conceded that a version of the ‘Might’ Argument can work. After all, there are vices that might be manifest by eating meat or having an abortion.\nReply: True, but the fact that some action might manifest a vice can hardly be a decisive consideration against doing it. If the vice in question is relatively small, or the chance of manifesting it is relatively small, it is easy to see how this kind of consideration could be overridden.\nFor instance, imagine an argument for vegetarianism as follows. Eating meat you haven’t killed yourself might be cowardly. It certainly isn’t obvious that letting someone else do the dirty work isn’t a manifestation of cowardice. So that’s a reason to not eat meat. I can grant it is a reason while thinking that (a) this kind of cowardice isn’t a particularly heinous vice, and (b) it isn’t that likely that meat eating is really cowardly in this way, so the reason is a relatively weak one, that can easily be overridden.\nBut the concession I want to make is that there could be an argument along these lines that works. In earlier presentations of this paper, I’d tried to extend my argument to respond to the arguments Alex Guerrero (2007) makes for vegetarianism. But I’m no longer sure that was a good idea. But I think Guerrero’s arguments can be understood in such a way that they rely only on the idea that we shouldn’t risk instantiating certain particular vices. And I don’t have a systematic objection to every argument of this form. After all, I do think we have a reason to avoid running a risk of being free-riders, or cowards, even if the action under consideration would not be cowardly, or an act of free-riding.\nObjection: Even without getting into debates about moral uncertainty, there are other uncertainty arguments against meat eating or abortion. There is some probability that cows or foetuses have souls, and it is a very serious harm to kill something that has a soul.\nReply: Nothing I say here helps respond to this argument. If one thinks that what’s wrong with killing is that it kills a soul, thinks that there’s a non-trivial chance that cows or foetuses have souls, and eats meat or has an abortion anyway, then one really is being immoral. Whether this should be called recklessness is tricky, since one could understand ‘recklessness’ as being concerned only with risks that are in a certain sense objective. But it certainly seems that such a person would be morally on a par with the people I’ve said are immoral in virtue of the risks they pose to others. It’s an empirical question, and one I don’t have any good evidence about, whether arguments from uncertainty about abortion and meat eating primarily concern uncertainty about facts, as this objection suggests, uncertainty about virtues (broadly construed) as the previous objection suggests, or uncertainty about right and wrong.\nObjection: It may be wrong to be only concerned with right and wrong, but it isn’t wrong to have this be one of your considerations.\nReply: I don’t think you get the ‘Might’ Argument to work unless concern with right and wrong, whatever they turn out to be, are the only considerations. Assume that they are only one consideration among many. Then even if they point in one direction, they may be overridden by the other considerations. And if the ‘Might’ Argument doesn’t work, then normative internalism, in its strongest forms, is false. So I really only need to appeal to the plausible view that right and wrong as such shouldn’t be our only motivations to get the conclusions I want.\nBut actually I think the stronger, prima facie implausible, view is true: rightness and wrongness as such shouldn’t even be part of our motivation. My reasons for thinking this are related to my responses to the next three objections. Unfortunately, these are the least developed, and least satisfying, of the responses I’ll offer. But I’ll conclude with them to leave you with a sense of where I think the debate is at, and what I think future research could assist with.\nObjection: Here’s one occasion where we do seem motivated by the good as such, or by welfare as such – when we’re doing moral or prudential reflection. Sometimes we stop and think, What would be the best thing to do in a certain kind of case? In philosophy departments, people might do that solely because they’re interested in the answer. But most people will think that these projects have some practical consequences. And the strong form of Smith’s fetishism objection that you’re relying on can’t explain why this is a good practice.\nReply: I agree this is a good practice. But I think it is consistent with what I’ve said so far. Start with an observation also by Michael Smith, that moral inquiry has “a certain characteristic coherentist form”  (Smith 1994, 40–41). I think (not originally) that this is because we’re not trying to figure out something about this magical thing, the good, but rather because we’re trying to systematise and where necessary reconcile our values. When we’re doing moral philosophy, we’re often doing work that more at the systematising end, trying to figure out whether seemingly disparate values have a common core. When we’re trying to figure out what is right in the context of deciding what to do, we’re often trying to reconcile, where possible, conflicting values. But as long as we accept that there are genuinely plural values, both in moral and prudential reasoning, we shouldn’t think that a desire to determine what is right is driven by a motivation to do the right thing, or to live a good life, as such.\nObjection: Sometimes people act from moral conscience. At least by their own account, they do something that involves no small amount of personal sacrifice because it is the right thing to do. And, at least some of the time, these people are highly praiseworthy. The strong version of the fetishism objection you’re using can’t account for this.\nObjection: So I have to bite some bullets here. I have to offer a slightly unnatural reformulation of these cases. In particular, in cases where someone acts from conscience, I have to say that there is something they value greatly, and they are acting on that value. What the value is will depend on the case. It might be welfare, or freedom, or keeping promises, or justice. It might even, and this is the version of the case that’s trickiest for me, be a value they can’t clearly articulate. A person can know something is the right thing to do and not be in any position to say why it is the right thing to do. And they may do it, even at great sacrifice. I think I’m required to say here that their motivation is the feature of the act that makes it right, not the rightness of the act. That’s not optimal, especially since it isn’t how the agent themself would describe the motivation. But I don’t think we should assume that agents have perfect access to their own motivations.\nI take myself to be here largely in agreement with a line suggested by Sigrún Svavarsdóttir (1999) when she says, in defence of an externalist theory of moral motivation.\n\nThe externalist account I propose does not ascribe to the good person a particular concern with doing the right thing. Rather it ascribes to him a more general concern with doing what is morally valuable or required, when that might include what is just, fair, honest, etc.  (Svavarsdóttir 1999, 197–98)\n\nThere are two points here that are particularly relevant to the current project. The good person has a plurality of motivations, not just one. And the fetishism argument really has a very narrow application: it really only works against theories which say goodness is a matter of having the thinnest of possible moral motivations. It’s odd to be solely concerned with doing the right thing as such. (It’s even odd, I say, to have this as one of your concerns, though that’s not central to my argument.) It’s not odd to have fairness as one of one’s concerns, even an important one. Svavarsdóttir suggests that once the range of the fetishism argument is restricted in this way, it can’t do the work that Smith needs it to do in his attack on motivational externalism. I don’t need to take a stand on this, since I’m not taking sides in the debate between motivational externalists and internalists. All I need is that Smith’s objection to fetishism can work, as long as it is suitably restricted.\nObjection: Is there any coherent meta-ethical view that can licence all the moves you’ve made? On the one hand, normative claims must be distinctive enough that uncertainty about them has a very different effect on deliberation and motivation than everyday factual claims. On the other hand, your externalism is the view that the moral facts matter more than anyone’s (reasonable) beliefs about the moral facts. The first consideration suggests a strong kind of moral anti-realism, where moral claims are different in kind to factual claims. But the second suggests a strong kind of moral realism, where there are these wonderful moral facts around to do the work that reasonable moral beliefs cannot do. Is this even consistent? And if it is, is there a meta-ethical view we should want to hold consistent with all of it?\nReply: The inconsistency charge isn’t, I think, too hard to meet. As long as the ‘facts’ that I talk about when I say the moral facts matter are construed in an extremely deflationary way, then I’m not being inconsistent. Any kind of sophisticated expressivist or quasi-realist view that allows you to talk about moral facts, while perhaps not meaning quite the same thing by ‘fact’ as a realist does, will be consistent with everything I’ve said.\nThe second challenge is harder, and I don’t know that I have a good response. I would like to make the theory I’ve presented here consistent with a fairly thoroughgoing moral realism, and I’m not sure that’s possible. (I’d like to do that simply because I don’t want the fate of the theory tied up with contentious issues in meta-ethics.) I think the way to make the view consistent with this kind of realism is to defend the view that neither the metaphysical status of a truth (as necessary or contingent, analytic or synthetic, and so on) has very little to do with its appropriate role in deliberation or evaluation. But defending that, and showing how it suffices to make moral cognitivism consistent with the view I’m describing, is more than I know how to do now.\n\n\n\n\n\n\nReferences\n\nArpaly, Nomy. 2002. “Moral Worth.” Journal of Philosophy 99 (5): 223–45. https://doi.org/10.2307/3655647.\n\n\n———. 2003. Unprincipled Virtue. Oxford: Oxford University Press.\n\n\nArpaly, Nomy, and Timothy Schroeder. 1999. “Praise, Blame and the Whole Self.” Philosophical Studies 93 (2): 161–88. https://doi.org/10.1023/A:1004222928272.\n\n\n———. 2014. In Praise of Desire. Oxford: Oxford University Press.\n\n\nBuchak, Lara. 2014. “Belief, Credence and Norms.” Philosophical Studies 169 (2): 285–311. https://doi.org/10.1007/s11098-013-0182-y.\n\n\nCalhoun, Cheshire. 1989. “Responsibility and Reproach.” Ethics 99 (2): 389–406. https://doi.org/10.1086/293071.\n\n\nFinnis, John. 2011. Natural Law and Natural Rights. Second. Oxford: Oxford University Press.\n\n\nFodor, Jerry. 2000. “It’s All in the Mind: Noam Chomsky and the Arguments for Internalism.” Times Literary Supplement 23 June: 3–4.\n\n\nGuerrero, Alexander. 2007. “Don’t Know, Don’t Kill: Moral Ignorance, Culpability and Caution.” Philosophical Studies 136 (1): 59–97. https://doi.org/10.1007/s11098-007-9143-7.\n\n\nHarman, Elizabeth. 2011. “Does Moral Ignorance Exculpate?” Ratio 24 (4): 443–68. https://doi.org/10.1111/j.1467-9329.2011.00511.x.\n\n\n———. 2015. “The Irrelevance of Moral Uncertainty.” Oxford Studies in Metaethics 10: 53–79. https://doi.org/10.1093/acprof:oso/9780198738695.003.0003.\n\n\nLockhart, Ted. 2000. Moral Uncertainty and Its Consequences. Oxford University Press.\n\n\nMalmgren, Anna-Sara. 2011. “Rationalism and the Content of Intuitive Judgements.” Mind 120 (478): 263–327. https://doi.org/10.1093/mind/fzr039.\n\n\nMoller, D. 2011. “Abortion and Moral Risk.” Philosophy 86 (3): 425–43. https://doi.org/10.1017/S0031819111000222.\n\n\nSepielli, Andrew. 2009. “What to Do When You Don’t Know What to Do.” Oxford Studies in Metaethics 4: 5–28.\n\n\nSmith, Michael. 1994. The Moral Problem. Oxford: Blackwell.\n\n\nSvavarsdóttir, Sigrún. 1999. “Moral Cognition and Motivation.” Philosophical Review 108 (2): 161–219. https://doi.org/10.2307/2998300.\n\n\nWeatherson, Brian. 2013. “Disagreements, Philosophical and Otherwise.” In The Epistemology of Disagreement: New Essays, edited by David Christensen and Jennifer Lackey, 54–73. Oxford: Oxford University Press.\n\n\nWilliamson, Timothy. 2007. The Philosophy of Philosophy. Blackwell.\n\n\nWolf, Susan. 1980. “Asymmetrical Freedom.” Journal of Philosophy 77 (3): 151–66. https://doi.org/10.2307/2025667."
  },
  {
    "objectID": "posts/ipacp/intrinsic-properties-and-combinatorial-principles.html",
    "href": "posts/ipacp/intrinsic-properties-and-combinatorial-principles.html",
    "title": "Intrinsic Properties and Combinatorial Principles",
    "section": "",
    "text": "Three objections have recently been levelled at the analysis of intrinsicness in Rae Langton and David Lewis’s “Defining ‘Intrinsic’”. Yablo (1999) has objected that the theory rests on “controversial and (apparently) irrelevant” judgements about the relative naturalness of various properties. Dan Marshall and Josh Parsons Marshall and Parsons (2001) have argued that quantification properties, such as being accompanied by an cube, are counterexamples to Langton and Lewis’s theory. And Theodore Sider Sider (2001) has argued that maximal properties, like being a rock, provide counterexamples to the theory. In this paper I suggest a number of amendments to Langton and Lewis’s theory to overcome these counterexamples. The suggestions are meant to be friendly in that the basic theory with which we are left shares a structure with the theory proposed by Langton and Lewis. However, the suggestions are not meant to be ad hoc stipulations designed solely to avoid theoretical punctures, but developments of principles that follow naturally from the considerations adduced by Langton and Lewis.\n\nPublished in Philosophy and Phenomenological Research 63: 365-380.\nThanks to David Lewis, Europa Malynicz, Dan Marshall, Daniel Nolan, Josh Parsons and Ted Sider for helpful discussions.\nPicture by Bernard Spragg via Creative Commons.\n\n\n0.1 Langton and Lewis’s Theory\nLangton and Lewis base their theory on a combinatorial principle about intrinsicness. If a property F is intrinsic, then whether a particular object is F is independent whether there are other things in the world. This is just a specific instance of the general principle that if F is intrinsic then whether some particular is F is independent of the way the rest of the world is. So if F is intrinsic, then the following four conditions are met:\n\nSome lonely object is F;\nSome lonely object is not-F;\nSome accompanied object is F; and\nSome accompanied object is not-F.\n\nThe quantifiers in the conditions range across objects in all possible worlds, and indeed this will be the quantifier domain in everything that follows (except where indicated). An object is ‘lonely’ if there are no wholly distinct contingent things in its world. The effect of including ‘distinct’ in this definition is that an object can be lonely even if it has proper parts; an object is not identical with its parts, but nor is it distinct from them. Following Langton and Lewis, I will say that any property that meets the four conditions is ‘independent of accompaniment’.\nAll intrinsic properties are independent of accompaniment, but so are some extrinsic properties. For example, the property being the only round thing is extrinsic, but independent of accompaniment. So Langton and Lewis do not say that independence of accompaniment is sufficient for intrinsicness. However, within a certain class of properties, what we might call the basic properties, they do say that any property independent of accompaniment is intrinsic. A property is basic if it is neither disjunctive nor the negation of a disjunctive property. Langton and Lewis define the disjunctive properties as follows:\n\n[L]et us define the disjunctive properties as those properties that can be expressed by a disjunction of (conjunctions of) natural properties; but that are not themselves natural properties. (Or, if naturalness admits of degrees, they are much less natural than the disjuncts in terms of which they can be expressed.) Langton and Lewis (2001)\n\nLangton and Lewis assume here that there is some theory of naturalness that can be plugged in here, but they are explicitly ecumenical about what the theory may be. They mention three possibilities: naturalness might be primitive; it might be defined in terms of which universals and tropes exist, if you admit such into your ontology; or it might be defined in terms of which properties play a special role in our theory. Call the first the primitivist conception, the second the ontological conception, and the third the pragmatic conception. (One can generate different versions of the pragmatic theory by altering what one takes to be ‘our theory’. In Taylor (1993), which Langton and Lewis credit as the canonical statement of the pragmatic conception, naturalness is relativised to a theory, and the theories he focuses on are ‘regimented common sense’ and ‘unified science’.) Langton and Lewis’s intention is to be neutral as to the correct interpretation of naturalness whenever they appeal to it, and I will follow their policy.\nWith these concepts, we can now define intriniscness. A property is basic intrinsic iff it is basic and independent of accompaniment. Two objects are duplicates iff they have the same basic intrinsic properties. And a property is intrinsic iff there are no two duplicates that differ with respect to it.\nLangton and Lewis make one qualification to this definition: it is only meant to apply to pure, or qualitative, properties, as opposed to impure, or haeccceitistic, properties. One reason for this restriction is that if there are any impure intrinsic properties, such as being John Malkovich, they will not have the combinatorial features distinctive of pure intrinsic properties. If F is a pure intrinsic property then there can be two wholly distinct things in a world that are F. This fact will be crucial to the revised definition of intrinsicness offered below. However, it is impossible to have wholly distinct things in the same world such that each is John Malkovich. So for now I will follow Langton and Lewis and just say what it takes for a pure property to be intrinsic. As Langton and Lewis note, it would be nice to complete the definition by giving conditions under which impure properties are intrinsic, but the little task of working out the conditions under which pure properties are intrinsic will be hard enough for now.\n\n\n0.2 Three Objections\nStephen Yablo (Yablo 1999) criticises the judgements of naturalness on which this theory rests. Consider again the property being the only round thing, which is extrinsic despite being independent of accompaniment. If Langton and Lewis are right, this must not be a basic property. Indeed, Langton and Lewis explicitly say that it is the negation of a disjunctive property, since its negation can be expressed as: being round and accompanied by a round thing or being not-round. Yablo’s criticism is that it is far from obvious that the existence of this expansion shows that being the only round thing is disjunctive. For simplicity, let us name all the salient properties: \\[\\begin{aligned}\n\\textit{R}&=\\textsubscript{df}~\\textit{being the only round thing} \\\\\n\\textit{S}&=\\textsubscript{df}~\\textit{being not the only round thing}\\\\\n\\textit{T}&=\\textsubscript{df}~\\textit{being round and accompanied by a round thing}\\\\\n\\textit{U}&=\\textsubscript{df}~\\textit{being not\\nobreakdash-round}\\end{aligned}\\]\n(Something is accompanied by an F iff one of its distinct worldmates is F.) Langton and Lewis claim that since S = T \\({\\vee}\\) U, and S is much less natural than T and than U, S is disjunctive, so R is not basic. Yablo notes that we can also express S as being round if accompanied by a round thing, so it differs from T only in that it has an if where T has an and. Given this expansion, we should be dubious of the claim that S is much less natural than T. But without that claim, R already provides a counterexample to Langton and Lewis’s theory, unless there is some other expression of R or S that shows they are disjunctive.1\n1 It would be no good to say that Langton and Lewis should be more liberal with their definition of disjunctiveness, and say instead that a property is disjunctive iff it can be expressed as a disjunction. Any property F can be expressed as the disjunction F and G or F and not G, or for that matter, F or F, so this would make every property disjunctive.\nI do not want to dismiss out of hand the possibility that there is another expression of S that shows it is disjunctive. Josh Parsons suggested that if we define T\\(^\\prime\\) to be being accompanied by a round thing, then S is T\\(^\\prime\\) \\({\\vee}\\) U, and there is some chance that T\\(^\\prime\\) is more natural than S on some conceptions of naturalness. So we cannot derive a decisive counterexample from Yablo’s discussion. Still, Langton and Lewis need it to be the case that on any account of naturalness, there is an expression that shows S or R to be disjunctive, and unless T\\(^\\prime\\) is much more natural than S on all conceptions of naturalness, this task is still far from complete.Dan Marshall and Josh Parsons Marshall and Parsons (2001) argue that the same kind of difficulties arise when we consider certain kinds of quantificational properties. For example, let E be the property being such that a cube exists. This is independent of accompaniment, since a lonely cube is E, a lonely sphere is not E, each of us is accompanied and E, and each of Max Black’s two spheres is accompanied and not E. So it is a counterexample to Langton and Lewis if it is basic. Marshall and Parsons note that, like all properties, it does have disjunctive expressions. For example x is E iff x is a cube or x is accompanied by a cube. And E is a less natural property than being a cube. But it is not at all intuitive that E is much less natural than the property being accompanied by a cube. This does not just show that Langton and Lewis have to cease being ecumenical about naturalness, because on some conceptions of naturalness it is not clear that E is much less natural than being accompanied by a cube. Rather, this example shows that there is no conception of naturalness that could play the role that Langton and Lewis want. The properties E and being accompanied by a cube seem just as natural as each other on the ontological conception of naturalness, on the pragmatic conception of naturalness, and, as far as anyone can tell, on the primitivist conception. This is not because E is particularly natural on any of these conceptions. It certainly does not, for example, correspond to a universal, and it does not play a special role in our thinking or in ideal science. But since there is no universal for being accompanied by a cube, and that property does not play a special role in our thinking or in ideal science, it seems likely that each property is as natural as the other.\nTheodore Sider (2001) notes that similar problems arise for maximal properties, like being a rock. A property F is maximal iff large parts of Fs are typically not Fs. For example, being a house is maximal; a very large part of a house, say a house minus one window ledge, is not a house, it is just a large part of a house. Purported proof: call the house minus one window ledge house-. If Katie buys the house she undoubtedly buys house-, but she does not thereby buy two houses, so house- is not a house. As Sider notes, this is not an entirely conclusive proof, but it surely has some persuasive force. Maximal properties could easily raise a problem for Langton and Lewis’s definition. All maximal properties are extrinsic; whether a is a house depends not just on how a is, but on what surrounds a. Compare: House- would be a house if the extra window ledge did not exist; in that case it would be the house that Katie buys. But some maximal properties are independent of accompaniment. Being a rock is presumably maximal: large parts of rocks are not rocks. If they were then presumably tossing one rock up into the air and catching it would constitute juggling seventeen rocks, making an apparently tricky feat somewhat trivial. But there can be lonely rocks. A rock from our planet would still be a rock if it were lonely. Indeed, some large rock parts that are not rocks would be rocks if they were lonely. And it is clear there are be lonely non-rocks (like our universe), accompanied rocks (like Uluru) and accompanied non-rocks (like me).\nSince being a rock is independent of accompaniment and extrinsic, it is a counterexample if it is basic. Still, one might think it is not basic. Perhaps being a rock is not natural on the primitivist conception. (Who is to say it is?) And perhaps it does not correspond to a genuine universal, or to a collection of tropes, so it is a disjunctive property on the ontological conception of naturalness. Sider notes, however, that on at least one pragmatic conception, where natural properties are those that play a special role in regimented common sense, it does seem particularly natural. Certainly it is hard to find properties such that being a rock can be expressed as a disjunction of properties that are more central to our thinking than being a rock. So this really does seem to be a counterexample to Langton and Lewis’s theory.\n\n\n0.3 The Set of Intrinsic Properties\nIt is a platitude that a property F is intrinsic iff whether an object is F does not depend on the way the rest of the world is. Ideally this platitude could be morphed into a definition. One obstacle is that it is hard to define the way the rest of the world is without appeal to intrinsic properties. For example, even if F is intrinsic, whether a is F is not independent of whether other objects have the property not being accompanied by an F, which I will call G. To the extent that having G is a feature of the way the rest of the world is, properties like G constitute counterexamples to the platitude. Since platitudes are meant to be interpreted to be immune from counterexamples, it is wrong to interpret the platitude so that G is a feature of the way the rest of the world is. The correct interpretation is that F is intrinsic iff whether an object is F does not depend on which intrinsic properties are instantiated elsewhere in the world.\nIf what I call the independence platitude is to be platitudinous, we must not treat independence in exactly the same way as Langton and Lewis do. On one definition, whether a is F is independent of whether the rest of the world is H iff it is possible that a is F and the rest of the world H, possible that a is not-F and the rest of the world H, possible that a is F and the rest of the world not-H, and possible that a is not-F and the rest of the world not-H. On another, whether a if F is independent of whether the rest of the world is H iff whether a is F is entirely determined by the way a itself, and nothing else, is, and whether the rest of the world is H is determined by how it, and not a, is. This latter definition is very informal; hence the need for the formal theory that follows. But it does clearly differ from the earlier definition in a couple of cases. The two definitions may come apart if F and H are excessively disjunctive. More importantly, for present purposes, they come apart if F is the necessary property (that everything has), or the impossible property (that nothing has). In these cases, whether a is F is entirely settled by the way a, and nothing else is, so in the latter sense it is independent of whether the rest of the world is H. But it is not the case that all four possibilities in the former definition are possible, so it is not independent of whether the rest of the world is H in that sense. Since there is some possibility of confusion here, it is worthwhile being clear about terminology. When I talk about independence here, I will always mean the latter, informal, definition, and I will refer to principles about which combinations of intrinsic properties are possible, principles such as Langton and Lewis’s principle that basic intrinsic properties are independent of accompaniment, as combinatorial principles. So, in the terminology I am using, the combinatorial principles are attempts to formally capture the true, but elusive, independence platitude with which I opened this section.\nSince the platitude is a biconditional with intrinsic on either side, it will be a little tricky to morph it into a definition. But we can make progress by noting that the platitude tells us about relations that hold between some intrinsic properties, and hence about what the set of intrinsic properties, which I will call SI, must look like.\nFor example, from the platitude it follows that SI is closed under Boolean operations. Say that F and G are intrinsic. This means that whether some individual a is F is independent of how the world outside a happens to be. And it means that whether a is G is independent of the way the world outside a happens to be. This implies that whether a is F and G is independent of the way the world outside a happens to be, because whether a is F and G is a function of whether a is F and whether a is G. And that means that F and G is intrinsic. Similar reasoning shows that F or G, and not F are also intrinsic. Call this condition Boolean closure.\nAnother implication of the independence platitude is that SI must be closed under various mereological operations. If F is intrinsic then whether a is F is independent of the outside world. If some part of a is F, that means, however the world outside that part happens to be, that part will be F. So that means that however the world outside a is, a will have a part that is F. Conversely, if a does not have a part that is F, that means all of a’s parts are not F. As we saw above, if F is intrinsic, so is not F. Hence it is independent of the world outside a that all of its parts are not F. That is, it is independent of the world outside a that a does not have a part that is F. In sum, whether a has a part that is F is independent of how the world outside a turns out to be. And that means having a part that is F is intrinsic. By similar reasoning, the property Having n parts that are F will be intrinsic if F is for any value of n. Finally, the same reasoning shows that the property, being entirely composed of n things that are each F is intrinsic if F is intrinsic. The only assumption used here is that it is independent of everything outside b that b is entirely composed of the particular things that it is composed of, but again this seems to be a reasonable assumption. So, formally, if F \\({\\in}\\) SI, then Having n parts that are F \\({\\in}\\) SI, and Being entirely composed of n things that are F \\({\\in}\\) SI. Call this condition mereological closure.\nFinally, and most importantly, various combinatorial principles follow from the independence platitude. One of these, that all intrinsic properties are independent of accompaniment, forms the centrepiece of Langton and Lewis’s theory. The counterexamples provided by Marshall and Parsons, and by Sider, suggest that we need to draw two more combinatorial principles from the platitude. The first is that if F and G are intrinsic properties, then whether some particular object a is F should be independent of how many other things in the world are G. More carefully, if F and G are intrinsic properties that are somewhere instantiated then, for any n such that there is a world with n+1 things, there is a world constituted by exactly n+1 pairwise distinct things, one of which is F, and the other n of which are all G. When I say the world is constituted by exactly n+1 things, I do not mean that there are only n+1 things in the world; some of the n+1 things that constitute the world might have proper parts. What I mean more precisely is that every contingent thing in the world is a fusion of parts of some of these n+1 things. Informally, every intrinsic property is not only independent of accompaniment, it is independent of accompaniment by every intrinsic property. As we will see, this combinatorial principle, combined with the Boolean closure principle, suffices to show that Marshall and Parsons’s example, being such that a cube exists, is extrinsic.\nSometimes the fact that a property F is extrinsic is revealed by the fact that nothing that is F can be worldmates with things of a certain type. So the property being lonely is extrinsic because nothing that is lonely can be worldmates with anything at all. But some extrinsic properties are perfectly liberal about which other properties can be instantiated in their world; they are extrinsic because their satisfaction excludes (or entails) the satisfaction of other properties in their immediate neighbourhood. Sider’s maximal properties are like this. That a is a rock tells us nothing at all about what other properties are instantiated in a’s world. However, that a is a rock does tell us something about what happens around a. In particular, it tells us that there is no rock enveloping a. If there were a rock enveloping a, then a would not be a rock, but rather a part of a rock. If being a rock were intrinsic, then we would expect there could be two rocks such that the first envelops the second.2 The reason that being a rock is extrinsic is that it violates this combinatorial principle. (As a corollary to this, a theory which ruled out being a rock from the class of the intrinsic just because it is somehow unnatural would be getting the right result for the wrong reason. Being a rock is not a property like being a lonely electron or an accompanied non-electron that satisfies the independence platitude in the wrong way; rather, it fails to satisfy the independence platitude, and our theory should reflect this.)\n2 I assume here that there are rocks with rock-shaped holes in their interior. This seems like a reasonable assumption, though without much knowledge of geology I do not want to be too bold here.3 Perhaps all worlds have some kind of spacetimelike structure, in which case this qualification is unnecessary, but at this stage it is best not to take a stand on such a contentious issue.So we need a second combinatorial principle that rules out properties like being a rock. The following principle does the job, although at some cost in complexity. Assume there is some world w1, which has some kind of spacetimelike structure.3 Let d1 and d2 be shapes of two disjoint spacetimelike regions in w1 that stand in relation A. Further, suppose F and G are intrinsic properties such that in some world there is an F that wholly occupies a region with shape d1, and in some world, perhaps not the same one, there is a G that wholly occupies a region with shape d2. By ‘wholly occupies’ I mean that the F takes up all the ‘space’ in d1, and does not take up any other ‘space’. (There is an assumption here that we can identify shapes of spacetimelike regions across possible worlds, and while this assumption seems a little contentious, I hope it is acceptable in this context.) If F, G, d1, d2 and A are set up in this way, then there is a world where d1 and d2 stand in A, and an F wholly occupies a region of shape d1 in that world, and a G wholly occupies a region of shape d2 in that world. In short, if you could have an F in d1, and you could have a G in d2, and d1 and d2 could stand in A, then all three of those things could happen in one world. This kind of combinatorial principle has been endorsed by many writers on modality (for example Lewis 1986 and Armstrong 1989), and it seems something we should endorse in a theory on intrinsic properties.\nIn sum, the set of intrinsic properties, SI, has the following four properties:\n\n\\(B\\)\n\nIf F \\({\\in}\\) SI and G \\({\\in}\\) SI then F and G \\({\\in}\\) SI and F or G \\({\\in}\\) SI and not F \\({\\in}\\) SI\n\n\\(M\\)\n\nIf F \\({\\in}\\) SI then Having n parts that are F \\({\\in}\\) SI and Being entirely composed of exactly n things that are F \\({\\in}\\) SI\n\n\\(T\\)\n\nIf F \\({\\in}\\) SI and G \\({\\in}\\) SI and there is a possible world with n+1 pairwise distinct things, and something in some world is F and something in some world is G, then there is a world with exactly n+1 pairwise distinct things such that one is F and the other n are G.\n\n\\(S\\)\n\nIf F \\({\\in}\\) SI and G \\({\\in}\\) SI and it is possible that regions with shapes d1 and d2 stand in relation A, and it is possible that an F wholly occupy a region with shape d1 and a G wholly occupy a region with shape d2, then there is a world where regions with shapes d1 and d2 stand in A, and an F wholly occupies the region with shape d1 and a G wholly occupies the region with shape d2.\n\n\nMany other sets than SI satisfy (B), (M), (T) and (S). That is, there are many sets Ik such that each condition would still be true if we were to substitute Ik for SI wherever it appears. Say that any such set is an I-set. Then F is intrinsic only if F is an element of some I-set. Is every element of every I-set intrinsic? As we will see, sadly the answer is no. However, most of the counterexamples proposed to Langton and Lewis’s theory are not elements of any I-set, so we already have the resources to show they are extrinsic.\n\n\n0.4 Responding to Counterexamples\nMarshall and Parsons noted that E, the property being such that a cube exists, is independent of accompaniment. However, it is not part of any I-set. To see this, assume it is in Ik, which is an I-set. By (B), not E is also in Ik. So by (T), there is a world where something is E, and there are two things, one of which is E and the other of which is not E. But clearly this cannot be the case: if something in a world is E, so is everything else in the world. Hence Ik cannot be an I-set, contrary to our assumption. Intuitively, E is extrinsic because whether it is satisfied by an individual is not independent of whether other individuals satisfy it.\nSome other quantificational properties, such as being one of at most seventeen cubes, require a different argument to show that they are not in any I-set. Call that property E17. (Note, by the way, that E17 is independent of accompaniment, and not obviously disjunctive.) If E17 is in an I-set, then by (T) there is a world containing exactly 18 things, each of which is E17. But this is clearly impossible, since everything that is E17 is a cube, and everything that is E17 is in a world containing at most seventeen cubes. So E17 is not in any I-set, and hence is extrinsic. Similarly, being the only round thing cannot be in an I-set, because if it were by (T) there would be a world in which two things are the only round thing, which is impossible. So a definition of intrinsicness in terms of I-sets need not make the odd postulations about naturalness that Yablo found objectionable.\nAssume, for reductio, that being a rock is in an I-set. There is a rock that is roughly spherical, and there is a rock that has a roughly spherical hollow in its interior. (Actually, there are many rocks of each type, but we only need one of each.) Let d1 be the region the first rock takes up, and assume that the shape of the hollow in the second is also d1. If it is not, we could always find another rock with a hollow this shape, so the assumption is harmless. Let d2 be the region the second rock, the one with this nicely shaped hollow, takes up. If being a rock is an I-set, then by (S) there is a world where d2 exactly surrounds d1, there is a rock wholly occupying d1 and a rock wholly occupying d2. But this is impossible; if there were rock-like things in both d1 and d2, they would both be parts of a single large rock, that extends outside both d1 and d2 and if there were not a rock-like thing in one or the other region, then there would not be a rock in that region. So no set satisfying (S) contains being a rock, so that property is not in any I-set, and hence is extrinsic.\nThe first extrinsic property independent of accompaniment that Langton and Lewis consider is CS: being spherical and lonely or cubical and accompanied. This too is not in any I-set. Again, assume for reductio that it is. In the actual world, there are (accompanied) cubes that are entirely composed of eight smaller cubes. Both the large cube and the eight smaller cubes are accompanied, so they are both CS. Hence there is a CS that is entirely composed of eight things that are CS. By (M), being entirely composed of exactly eight things that are CS is in the I-set. By (B), being CS and entirely composed of exactly eight things that are CS is in the I-set. So by (T), there is a world in which something has that property, and there is nothing else. (To see that (T) entails this, let G be any element of the I-set, and let n be zero.) That is, there is a lonely CS that is composed of eight things that are CS. But this is impossible. A lonely CS is a sphere, but its eight parts are not lonely, and are CS, so they must be cubes. And no sphere is entirely composed of exactly eight cubes. So CS cannot be in an I-set, and hence is extrinsic.\n\n\n0.5 Problem Cases and Disjunctive Properties\nThose five successes might make us think that only intrinsic properties are ever in I-sets. However there are still some extrinsic properties that can slip into I-sets. For an example, consider the property LCS, defined as follows:\n\nx is LCS \\({\\leftrightarrow}\\) (x is cubical and not both lonely and simple) or (x is lonely, simple and spherical)\n\nThe smallest set containing LCS and satisfying (B) and (M) is an I-set. There is an important reason for this. Define a simple world as a world containing just one mereological simple, and a compound world as a world that is not a simple world. Whether a property satisfies (T) and (S) (or, more precisely, whether a set containing that property can satisfy (T) and (S)) depends on just how the property interacts with other properties in compound worlds and whether it is ever instantiated in simple worlds. Since the same things are LCS as are cubical in compound worlds, these two properties, LCS and being cubical, interact with other properties in compound worlds in the same way. And each property is instantiated in simple worlds, although they are instantiated in different simple worlds. In sum, the properties are similar enough to be indistinguishable by (T) and (S), and that means we will not be able to show that LCS is extrinsic using just those considerations.\nAny property that agrees with an intrinsic property, like being cubical, in the compound worlds, and is somehow extended so it is instantiated in simple worlds, will be in an I-set. This is not just because we have not put enough restrictions on what makes an I-set. There are just no combinatorial principles we could deduce from the independence platitude that LCS violates. This is because any such principle would, like (T) and (S), be satisfied or not depending just on how the property interacts with other properties in worlds where there are things to interact with, i.e. the compound worlds, and whether it is instantiated in the simple worlds. It is to the good that our deductions from the independence platitude did not show that LCS is extrinsic, because in an important sense LCS, like all properties that agree with some intrinsic property in all compound worlds, satisfies the platitude.\nSo at this point appeal to disjunctive and non-disjunctive properties is needed. Intuitively, intrinsic properties are not only capable of being instantiated in all possible combinations with other intrinsic properties, they are capable of being so instantiated in the same way in all these possible combinations. We need to distinguish between the disjunctive and the non-disjunctive properties in order to say which properties are instantiated the same way in all these different combinations.\nIt might be thought at this stage that we could just adopt Langton and Lewis’s definition of the disjunctive properties. If that definition worked, we could say the basic intrinsic properties are the non-disjunctive properties that are in I-sets, then define duplication and intrinsicness as they do in terms of basic intrinsics. The definition does not, it seems, work as it stands because it does not show that LCS is disjunctive. This will be easier to follow if we name all the components of LCS, as follows: \\[\\begin{aligned}\n\\textit{C}~&=~\\textit{being cubical} \\\\\n\\textit{L}~&=~\\textit{being lonely} \\\\\n\\textit{M}~&=~\\textit{being simple} \\\\\n\\textit{H}~&=~\\textit{being spherical} \\\\\n\\textit{LCS}~&=~(\\textit{C}~\\&~{\\lnot}(\\textit{L} \\& \\textit{M}))~{\\vee}~(\\textit{L} \\&~\\textit{M}~\\&~\\textit{H})\\end{aligned}\\]\nLet us agree that LCS is not a natural property, if naturalness is an on/off state, or is very unnatural, if naturalness comes in degrees. On Langton and Lewis’s first definition, it is disjunctive if it is a disjunction of conjunctions of natural properties. This seems unlikely: \\({\\lnot}\\)(L & M) is not a natural property. This is the property of being in a compound world, hardly a natural property. Similarly, C & \\({\\lnot}\\)(L & M), being a cube in a compound world, is hardly natural either. We could insist that these properties are natural, but at this point Yablo’s complaint, that clear facts like the extrinsicness of LCS are being made to rest on rather obscure facts, like the putative naturalness of being in a compound world, returns to haunt us. (I assume, for the sake of the argument, that L & M & H is a natural property, though this assumption could be easily questioned.) On the second definition, LCS is disjunctive if it is much less natural than \\({\\lnot}\\)(L & M), or than C & \\({\\lnot}\\)(L & M). Again, it seems unlikely that this is the case. These properties seem rather unnatural. I have defined enough terms that we can state in the lexicon of this paper just what \\({\\lnot}\\)(L & M) amounts to, i.e. being in a compound world, but the apparent simplicity of this definition should not make us think that the properties are natural. It is true in natural languages that predicates that are easy to express are often natural, but this fact does not extend across to the technical language that is employed here.\nThe way out is to change the definition of disjunctive properties. A property is disjunctive, intuitively, if it can be instantiated in two quite different ways. Most properties of the form: (N1 & U1) \\({\\vee}\\) (N2 & U2), where N1 and N2 pick out distinct (relatively) natural properties, and U1 and U2 pick out distinct (relatively) unnatural properties that are independent of N1 and N2, will be like this. If we name this predicate F, there will be two quite different types of Fs: those that are N1 and those that are N2. Note that this will be true no matter how unnatural U1 and U2 are; provided some Fs are N1, and some are N2, there will be these two ways to be F. So I suggest we amend Langton and Lewis’s definition of disjunctiveness as follows:\n\nA property F is disjunctive iff it can be expressed as a disjunction of conjunctions, i.e.: (A11 & … & A1n) \\({\\vee}\\) … \\({\\vee}\\) (Ak1 & … & Akm) and in each disjunct, at least one of the conjuncts is much more natural than F.\n\nOn this definition it is clear that LCS is disjunctive, since it is much less natural than being cubical and than being spherical, and in its expression above, being cubical is one of the conjuncts in the first disjunct, and being spherical is one of the conjuncts in the second disjunct. These kinds of comparisons of naturalness do not seem contentious, or any less obvious than the conclusions about extrinsicness we use them to generate. Further, the new definition of disjunctiveness is not meant to be an ad hoc fix. Rather this requirement that only one conjunct in each disjunct need be much more natural than F seems to follow directly from the reason we introduced the concept of disjunctiveness to begin with. For each F that satisfies the combinatorial principle (either independence of accompaniment in Langton and Lewis’s theory, or being in an I-set in my theory), we wanted to know whether it only does this because there are two or more ways to be an F. If F satisfies the definition of disjunctiveness I offer here, it seems there are two or more ways to be an F, so the fact that it can be in an I-set should not lead us to believe it is intrinsic.\nUsing this definition of disjunctiveness, we can say that the basic intrinsic properties are those that are neither disjunctive nor the negation of a disjunctive property, and are in at least one I-set, then say duplicates are things that share all basic intrinsic properties, and finally that intrinsic properties are properties shared by all duplicates. There are two reasons for thinking that this definition might well work. First, as we have seen it handles a wide range of hard cases. More importantly, the way that the hard cases were falling gave us reason to suspect that the only extrinsic properties that will be in I-sets are properties like LCS: properties that agree with some intrinsic property in all compound worlds. It is reasonably clear that these properties will be disjunctive according to the above definition. To see this, let F be the extrinsic property in an I-set, and let G be the intrinsic property it agrees with in all compound worlds. Then for some J, F can be expressed as (G & \\({\\lnot}\\)(L & M)) \\({\\vee}\\) (L & M & J), and it will presumably be much less natural than G, probably much less natural than J, and almost certainly much less natural than being simple, our L. So if these are the only kind of extrinsic properties in I-sets, our definition is correct.\nIndeed, if these are the only kinds of extrinsic properties in I-sets, we may not even need to worry about which properties should count as disjunctive. Say that a property F blocks another property G iff both F and G are in I-sets, but there is no I-set containing both F and G. If F and G were both intrinsic, then there would be an I-set they are both in, such as say SI, so the fact that there is no such I-set shows that one of them is extrinsic. Note that LCS blocks being cubical. To prove this, assume LCS and being cubical are in an I-set, say Ik. By two applications of (B), LCS and not cubical is in Ik. This property is instantiated in some possible worlds: it is instantiated by all lonely spheres. So by (T) there should be a world containing two things that satisfy LCS and not cubical. But only lonely, simple spheres satisfy this property, so there is no world where two things satisfy it, contradicting our assumption that LCS and being cubical can be in the same I-set. The proof here seems perfectly general: if G is intrinsic and F differs from G only in which things in simple worlds satisfy it, and G is in an I-set, then F will block G. Blocking, as defined, is symmetric, so the fact that F blocks G is no evidence that F is extrinsic, as opposed to G. Still, if G is much more natural than F, then in all probability the reason F blocks G is that they agree about all cases in compound worlds, and disagree just about the simple worlds. In that case, it seems that F is extrinsic, and G is intrinsic. So I think the following conjecture has merit: F is intrinsic iff it is in an I-set and does not block any property much more natural than itself. If the conjecture works, the only kind of naturalness comparisons we need to make will be between properties like LCS and properties like being cubical. Again, I think these kinds of comparisons should be fairly uncontentious.\n\n\n0.6 Back to Basics?\nMost of the work in my theory is done by the concept of I-sets. It might be wondered whether we can do without them. In particular, it might be thought that the new definition of disjunctivenes I offer in ?5 will be enough to rescue Langton and Lewis’s theory from the objections I have been fretting about. Indeed, the new definition of disjunctiveness does suffice for responding to Yablo’s objection. However, it will not do on its own, and I think it will end up being essential to define intrinsicness in terms of I-sets.\nYablo notes that a property like being the only red thing is independent of accompaniment, and that the way Langton and Lewis suggest showing it is disjunctive is by expressing its negation as being red and accompanied by a red thing, or not being red. Yablo criticises the claim that the first of these disjuncts really is a natural property. Above I agreed that this was a good objection. However, on the new definition of disjunctiveness, it is beside the point.\nTo show that not being the only red thing is disjunctive, we need only express it as a disjunction of conjunctions such that at least one conjunct in each disjunct is much more natural than it is. We have the disjunctive expansion of not being the only red thing, and the first disjunct is being red and accompanied by a red thing. Now this disjunct as a whole may not be particularly natural, but the first conjunct, being red, is much more natural than not being the only red thing. So all we need to show is that one of the conjuncts in the second disjunct is much more natural than the whole disjunction. Since the second disjunct has only one conjunct, this means we have to show not being red is much more natural than not being the only red thing. However, there seems to be no simple way to show this. It is just entirely unclear how natural properties like not being red should seem to be. My guess (for what it is worth) is that like most properties that can be expressed by negations of English predicates, it is very unnatural. Certainly it is very unnatural if we suppose, as seems fair in this context, that F is only a natural property if all the things that are F resemble each other in some important way. The class of things that are not red is as heterogeneous a class as you can hope to find; blue berries, green leaves, silver Beetles, colourless gases and immaterial souls all find their way in. It is true that in New Work for a Theory of Universals, David Lewis provides two importantly distinct criteria for naturalness. One is the resemblance criterion just mentioned. The other is that F is only perfectly natural if it is fundamental. It might be thought that when we look at this criterion, it does turn out that not being red is much more fundamental than being the only red thing. Even if this is the case, it is not clear that it does help, or more importantly, that it should help. The problem Langton and Lewis were trying to handle is that not being the only red thing satisfies a particular combinatorial principle (independence of accompaniment), but only, they say, because there are two different ways of instantiating that property: not being red and being accompanied by a red thing. The problem is that not being red is not a way to instantiate a property, because it is not a way that something could be. It seems very intuitive that ‘ways things could be’, in this sense, are resemblance properties: they are properties that make for resemblance amongst their instantiators. And even if we can defend the claim that not being red is a fundamental property, the fact that it is not a resemblance property seems to undercut Langton and Lewis’s case here.\nThe new definition of disjunctiveness does not provide a defender of Langton and Lewis’s theory with a response to Yablo’s criticism. On the new definition of disjunctiveness, we do not have to show that being red and accompanied by a red thing is more natural than not being the only red thing in order to show that the latter is disjunctive. However, in order to show that not being the only red thing is disjunctive, we still need to show that not being red is a moderately natural property, and this does not seem to be true.\n\n\n0.7 Conclusion\nThere are four major differences between the analysis of intrinsic properties provided here and the one provided by Langton and Lewis. Three of these are reflected in the difference between the combinatorial principle they use, independence of accompaniment, and the combinatorial principle I use, membership in an I-set. All properties that are in I-sets are independent of accompaniment, but they also have a few other nice features. First, membership in an I-set guarantees not just independence of whether there are other things, but independence of what other types of things there are. This is the independence principle encoded in condition (T) on I-sets. Secondly, membership in an I-set guarantees independence of where the other things are. This is the principle encoded in condition (S). Third, the mereological principle (M) has no parallel in Langton and Lewis’s theory.\nThe effect of these extra three restrictions is that I have to make many fewer appeals to naturalness than do Langton and Lewis. The fourth difference between their theory and mine is in the role naturalness considerations play in determining which properties are intrinsic. In section 5 I offer two ways of finishing the analysis using naturalness. The first is in the new definition of disjunctiveness; with this definition in hand we can finish the story just as Langton and Lewis suggest. The second is in terms of blocking: F is intrinsic iff it is in an I-set and does not block any property that it is much less natural than. Both ways are designed to deal with a quite specific problem: properties that differ only in which things instantiate them in simple worlds have the same combinatorial features, so a definition of intrinsicness in terms of combinatorial features (as is Langton and Lewis’s, and as is mine) will not be able to distinguish them. Still, both solutions seem likely to provide the same answer in all the hard cases: the right answer.\n\n\n\n\n\n\nReferences\n\nLangton, Rae, and David Lewis. 2001. “Marshall and Parsons on ‘Intrinsic’.” Philosophy and Phenomenological Research 63 (2): 353–55. https://doi.org/10.2307/3071068.\n\n\nMarshall, Dan, and Josh Parsons. 2001. “Langton and Lewis on ‘Intrinsic’.” Philosophy and Phenomenological Research 63 (2): 347–51. https://doi.org/10.2307/3071067.\n\n\nSider, Theodore. 2001. “Maximality and Intrinsic Properties.” Philosophy and Phenomenological Research 63 (2): 357–64. https://doi.org/10.1111/j.1933-1592.2001.tb00109.x.\n\n\nTaylor, Barry. 1993. “On Natural Properties in Metaphysics.” Mind 102 (405): 81–100. https://doi.org/10.1093/mind/102.405.81.\n\n\nYablo, Stephen. 1999. “Intrinsicness.” Philosophical Topics 26 (1): 479–505. https://doi.org/10.5840/philtopics1999261/234."
  },
  {
    "objectID": "posts/evil/should-we-respond-to-evil-with-indifference.html",
    "href": "posts/evil/should-we-respond-to-evil-with-indifference.html",
    "title": "Should We Respond to Evil With Indifference?",
    "section": "",
    "text": "In a recent article, Adam Elga (2004) outlines a strategy for “Defeating Dr Evil with Self-Locating Belief”. The strategy relies on an indifference principle that is not up to the task. In general, there are two things to dislike about indifference principles: adopting one normally means confusing risk for uncertainty, and they tend to lead to incoherent views in some ‘paradoxical’ situations. Each kind of objection can be levelled against Elga’s theory, but because Elga is more careful than anyone has ever been in choosing the circumstances under which his indifference principle applies we have to be similarly careful in focussing the objections. Even with this care the objections I put forward here will be less compelling than, say, the objections (Keynes 1921 Ch. 4) put forward in his criticisms of earlier indifference principles. But there still may be enough to make us reject Elga’s principle. The structure of this note is as follows. In and 2 I set out Elga’s theory, in and 4 I discuss some initial objections that I don’t think are particularly telling, in I discuss some paradoxes to which Elga’s theory seems to lead (this is reprised in where I discuss a somewhat different paradoxical case) and in and 8 I argue that even Elga’s careful indifference principle involves a risk/uncertainty confusion.\n\nPublished in Philosophy and Phenomenal Research 70: 613-35.\nThanks to Jamie Dreier, Adam Elga and an anonymous referee for helpful discussions about this paper and suggestions for improvements.\n\n\n0.1 From Basel to Princeton\nIn (1979) David Lewis argued that the contents of contentful mental states were not propositions, but properties. When I think that I’m a rock star, I don’t attribute truth to the proposition Brian is a rock star, but rather attribute the property of rock stardom to myself. Lewis was led to this position by considering cases where a believer is mistaken about his own identity. For example, if I believe that I’m a rock star without believing that I’m Brian, and in fact while thinking that Brian is an infamous philosopher, it is odd to attribute to me belief in the proposition Brian is a rock star. But it is perfectly natural to say I self-attribute rock stardom, and that’s just what Lewis says.\nIf we accept Lewis’s position, there are two paths we can take. First, we can try simply replacing all talk of propositional attitudes with talk of proprietal attitudes, and trusting and hoping that this won’t make a difference to our subsequent theorising. Alternatively, we can see if changing the type of entity that is the content of a contentful state has distinctive consequences, and in particular see if it gives us the conceptual resources to make progress on some old problems. That’s the approach Adam Elga has taken in a couple of papers, and whatever one thinks of his conclusions, the early returns certainly suggest that this Lewisian outlook will prove remarkably fruitful.\nOn the Lewisian approach, credences are defined over properties, and properties are sets of possibilia, i.e. centred worlds. Some properties are maximally precise, they are satisfied by exactly one possible object. Elga sometimes calls these maximally specific properties predicaments because they specify exactly what is happening to the agent that instantiates one. Say predicaments F1 and F2 are similar iff the F1 and the F2 are worldmates and their experiences are indistinguishable. Elga’s principle INDIFFERENCE says that if predicaments F1 and F2 are similar then any rational agent should assign equal credence to F1 and F2. This becomes most interesting when there are similar F1 and F2. So, for instance, consider poor O’Leary.\n\nO’LEARY\n\nO’Leary is locked in the trunk of his car overnight. He knows that he’ll wake up briefly twice during the night (at 1:00 and again at 2:00) and that the awakenings will be subjectively indistinguishable (because by 2:00 he’ll have forgotten the 1:00 awakening). At 1:00 he wakes up.\n\n\nElga says that when O’Leary wakes up, he should assign equal credence to it being 1:00 as to it being 2:00. So, provided O’Leary knows that one of these two hypotheses is true, INDIFFERENCE says that he should assign credence 1/2 to it being 1:00 at the wake up.\nElga has an argument for INDIFFERENCE, which we shall get to by , but for a while I will look at some immediate consequences of the position. I’ll start with two reasons to think that INDIFFERENCE needs to be strengthened to play the role he wants it to play.\n\n\n0.2 Add it Up\nOne difficulty with INDIFFERENCE as stated so far is that it applies only to very narrow properties, predicaments, and it is not clear how to generalise to properties in which we are more interested.\n\nBERNOULLIUM\n\nDespite months of research, Leslie still doesn’t know what the half-life of Bernoullium, her newly discovered element is. It’s between one and two nanoseconds, but she can’t manufacture enough of the stuff to get a better measurement than that. She does, however, know that she’s locked in the trunk of her car, and that like O’Leary she will have two indistinguishable nocturnal awakenings. She’s having one now in fact, but naturally she can’t tell whether it is the first or the second.\n\n\nINDIFFERENCE says that Leslie should assign credence 1/2 to it being the first wake-up, right? Not yet. All that INDIFFERENCE says is that any two predicaments should receive equal credence. A predicament is maximally specific, so it specifies, inter alia, the half-life of Bernoullium. But for any x, Leslie assigns credence 0 to x being the half-life of Bernoullium, because there are uncountably many candidates for being the half-life, and none of them look better than any of the others. So she assigns credence 0 to every predicament, and so she satisfies INDIFFERENCE no matter what she thinks about what the time is. Even if, for no reason at all, she is certain it is her second awakening, she still satisfies INDIFFERENCE as it is written, because she assigns credence 0 to every predicament, and hence equal credence to similar predicaments.\nFortunately, we can strengthen INDIFFERENCE to cover this case. To start, note that the motivations for INDIFFERENCE suggest that if two predicaments are similar then they should receive equal credence not just in the agent’s actual state, but even when the agent gets more evidence. Leslie should keep assigning equal credence to it being her first or second wake up if she somehow learns what the half-life of Bernoullium is, for example. This suggests the following principle:\n\nC-INDIFFERENCE\n\nIf F1 and F2 are similar, and an agent does not know that she is in neither, then her conditional credence on being F1, conditional on being either F1 or F2, should be 1/2.1\n1 INDIFFERENCE entails C-INDIFFERENCE given the following extra assumptions. First, if INDIFFERENCE is true it is indefeasible, so it must remain true whatever one’s evidence is. Secondly, rational agents should update by conditionalisation. Thirdly, it is always possible for an agent to get evidence that tells her she is in F1 or F2 and no more. The third premise is at best an idealisation, but it is hard to see how or why that should tell against C-INDIFFERENCE.\n\nBut even this doesn’t quite resolve our problem. Simplifying Leslie’s situation somewhat, the live predicaments are all of the following form: this is the first/second awakening, and the half-life of Bernoullium is x. C-INDIFFERENCE requires that for any c, conditional on the half-life of Bernoullium being c, Leslie assign credence 1/2 to it being her first awakening. From this and the fact that Leslie’s credence function is a probability function it doesn’t follow that her credence in this being her first awakening is 1/2. So to get INDIFFERENCE to do the work it is meant to do in Leslie’s case (and presumably O’Leary’s case, since in practice there will be some other propositions about which O’Leary is deeply uncertain) I think we need to strengthen it to the following.\n\nP-INDIFFERENCE\n\nIf G1 and G2 are properties such that:\n\nFor all worlds w, there is at most one G1 in w and at most one G2 in w;\nFor all worlds w, there is a G1 in w iff there is a G2 in w; and\nFor all worlds w where there is a G1 in w, the G1 and the G2 have indistinguishable experiences; then\n\nG1 and G2 deserve equal credence.\n\n\nElga does not endorse either C-INDIFFERENCE or P-INDIFFERENCE, but I suspect he should given his starting assumptions. It is hard to believe if O’Leary is certain about everything save what time it is, then rationality imposes very strong constraints on his beliefs about time, while rationality imposes no such constraints should he (or Leslie) be uncertain about the half-life of Bernoullium. Put another way, it is hard to believe that in her current state Leslie could rationally assign credence 0.9 to this being her first awakening, but if she decided the half-life of Bernoullium is 1.415 nanoseconds, then she would be required to change that credence to 0.5. If we have INDIFFERENCE without P-INDIFFERENCE, that is possible. So I will assume in what follows that if C-INDIFFERENCE and P-INDIFFERENCE are false then INDIFFERENCE is heavily undermined.2\n2 Note also that if P-INDIFFERENCE is false, then Dr Evil has an easy way out of the ‘brain race’ that comes up at the end of Elga’s paper. He just need be told about some new element without being told its half-life, and magically he is free to assign credence 1 to his being on the spaceship rather than on Earth. This would reduce the interest of the puzzle somewhat I fear.\n\n0.3 Out of sight, out of mind\nElga’s discussion presupposes two kinds of internalism. First, he assumes that some internalist theory of experience is true. Second, he assumes that some internalist theory of justification is true. If the first assumption is false it threatens the applicability of the theory. If the second assumption is false it threatens the truth of the theory.\nAn externalist theory of experience says that what kind of experience S is having is determined, inter alia, by what S is experiencing. While setting out such a view, John (Campbell 2002, 124–26) says that two people sitting in duplicate prison cells looking at duplicate coffee cups will have different experiences, because one will have an experience of the coffee cup in her hand, and the other will not have an experience of that cup. This does not threaten INDIFFERENCE, but it does seem to render it trivial. On Campbell’s view, if two agents are able to make demonstrative reference to different objects, and there is no reason to think Elga’s agents in allegedly similar but not numerically identical predicaments cannot, they are having different experiences. Hence the situations are not really similar after all. Strictly speaking, this is good news for INDIFFERENCE, since it is hard given this view of experience to find counterexamples to it. But I doubt that Elga will be happy with this defence.\nThe second kind of internalist assumption is more threatening. Many externalists about justification think whether a particular experience justifies a belief for an agent depends not just on intrinsic features of that experience, but on the relationship between experiences of that kind and the world around the agent. In some versions of this, especially the version defended by Timothy Williamson (1998), whether an experience either constitutes or produces evidence depends on whether it constitutes or produces knowledge. Since it is not clear that any two similar agents know the same thing, since it is clear that they do not have the same true beliefs, on Williamson’s theory it seems that the agents will not have the same evidence. In particular, it is possible that part of one agent’s evidence is inconsistent with her being the other agent. If part of her evidence is that she has hands, then she is not a brain-in-a-vat having experiences like hers, and she should not assign high credence to the claim that she is one, no matter what INDIFFERENCE says. So Elga needs to reject this kind of externalism about evidence. This is not a devastating objection. I am sure that Elga does reject Campbell’s and Williamson’s theories, so just raising them against him without argument would be question-begging. But this does mean that the target audience for INDIFFERENCE is smaller than for some philosophical claims, since adherents of Campbell’s or Williamson’s views will be antecedently disposed to think INDIFFERENCE is useless or false.\n\n\n0.4 It’s Evidently Intransitive\nDakota is sitting in a bright green room. She is trying to reconstruct how she got there when Dr Evil informs her just what happened. An epistemology student, not coincidentally called Dakota, was snatched out of her study and duplicated 999 times over. The duplicates were then numbered (though we’ve lost which number was given to the original) each put in a coloured cell. The thousand coloured cells rotated slowly through the colour sphere, starting with cell 0 (the new home of Dakota number 0) being green, going blueish until cell 250 (for Dakota number 250) is just blue, then reddish until cell 500 is just red, swinging through the yellows with pure yellow reached at 750, and then back to the greens, with 999 being practically identical to 1000. For any n, cells number n and n+1 are indistinguishable. That means that Dakota number n is similar, in Elga’s sense, to Dakota number n+1, for their (apparent) experiences before being in the rooms are identical, and their experiences in the rooms are indistinguishable. Hence our Dakota, sitting in the bright green room, should assign equal credence to being Dakota number n and Dakota number n+1 for any n. But this is absurd. Since she can see that her walls are green, she should assign high credence to being Dakota number 0, and credence 0 to being Dakota number 500.\nThe problem here is that Elga wants to define an equivalence relation on predicaments, the relation deserving the same credence as, out of an intransitive relation, being indistinguishable from. There are two possible responses, each of them perfectly defensible.\nFirst, Elga could deny the premise that the adjacent cells are indistinguishable. Although there is some prima facie plausibility to the claim that some different colours are indistinguishable, Delia Graff Fara (2001) has argued that this is false. It would mean committing to yet another controversial philosophical position, but if Elga endorsed Graff’s claims, he could easily deal with Dakota.\nSecondly, he could tinker with the definition of similarity. Instead of saying that possibilia represent similar predicaments iff they are indistinguishable worldmates, he could say that they represent similar predicaments iff they are worldmates that are indistinguishable from the same predicaments. (This kind of strategy for generating an equivalence relation from an intransitive relation is borrowed from Goodman (1951).) Even if adjacent cells are indistinguishable from each other, they will not be indistinguishable from the same cells. This delivers the plausible result that the duplicate Dakotas stuck in the cells do not instantiate similar predicaments. Some might object that this move is ad hoc, but once we realise the need to make similar an equivalence relation, it seems clear enough that this is the most natural way to do that.\n\n\n0.5 Morgan and Morgan and Morgan and Morgan\nI think I outdid myself this time, said Dr Evil. I was just going along duplicating you, or at least someone like you, and the duplication process was taking less and less time. So I thought, I wonder what is the lower bound here? How quick can we make the duplication process? So I tried a few things to cut down the time it took, and I got a little better with practice, and, well, it turns out that the time taken can be made arbitrarily small. Before I knew it, there were infinitely many of you. Oops.\nMorgan was a little shocked. She could cope with having a duplicate or two around, but having infinitely many duplicates was a little hard to take. On the other hand, and this was hard to think about, perhaps she should be grateful. Maybe she was one of the later ones created, and she wouldn’t have existed if not for Evil’s irrational exuberance. She started to ponder how likely that was, but she was worried that it required knowing more about Evil than any mortal could possibly know.\nWell, continued Dr Evil, I did one thing right. As each duplicate was created I gave it a serial number, 0 for the original Morgan, 1 for the first duplicate and so on, so the bookkeeping will be easier. Don’t go looking for it, it’s written on your left leg in ectoplasmic ink, and you won’t be able to see it.\nNow that makes things easier, thought Morgan. By INDIFFERENCE the probability that my serial number is x is 1/n, where n is the number of duplicates created. So dividing 1 by infinity, that’s zero. So the probability that my serial number is less than x is the probability that it’s zero plus the probability that it’s one plus … plus the probability that it’s x, that’s still zero. So if he had stopped after x for any x, I would not exist with probability one. I’m liking Evil more and more, though something bothers me about that calculation.\nMorgan was right to worry. She’s just talked herself, with Elga’s help, into a violation of the principle of countable additivity. The additivity axiom in standard probability theory says that for any two disjoint propositions, the probability of their disjunction is the sum of their probabilities. The countable additivity axiom says that for any countable set of disjoint propositions, the probability that at least one of them is true is the sum of each of their probabilities. (It follows from the axioms of probability theory that this sum is always defined.) Here we have to alter these axioms slightly so they apply to properties rather than propositions, but still the principle of countable additivity seems plausible. But Morgan has to violate it. The probability she assigns to having some serial number or other is not zero, in fact it is one as long as she takes Evil at his word. But for each x, the probability that her serial number is x is zero. In symbols, we have\n\nPr(\\({\\exists}\\)x (Serial number = x)) = 1\n\\({\\Sigma}\\)Pr(Serial number = x) = 0\n\nBut countable additivity says that these values should be equal.\nOrthodoxy endorses countable additivity, but there are notable dissenters that are particularly relevant here. Bruno (deFinetti1974?) argued that countable additivity should be rejected because it rules out the possibility of an even distribution across the natural numbers. DeFinetti thought, as Morgan does, that we could rationally be in a position where we know of a particular random variable only that its value is a non-negative integer, and for every x, we assign equal probability to each hypothesis that its value is x. Since that is inconsistent with countable additivity, all the worse for countable additivity. This is a decent argument, though as de Finetti himself noted, it has some counterintuitive consequences.\nI decided, Dr Evil continued, to do something fairly spectacular with all these people. By some small tinkering with your physiology I found a way to make you immortal. Unfortunately, a quick scan of your psychology revealed that you weren’t capable of handling eternity. So every fifty years I will wipe all your memories and return you to the state you were in when duplicated. I will write, or perhaps I did write, on your right leg the number of times that your memories have been thus wiped. Don’t look, it’s also in ectoplasmic ink. Just to make things fun, I made enough duplicates of myself so that every fifty years I can tell you what happened. Each fifty-year segment of each physical duplicate will be an epistemic duplicate of every other such segment. How cool is that?3\n3 Evil’s plan resembles in many respects a situation described by Jamie Dreier (2001) in his “Boundless Good”. The back story is a little different, but the situation is closely (and intentionally) modelled on his sphere of pain/sphere of pleasure example.Morgan was not particularly convinced that it was cool, but an odd thought crossed her mind once or twice. She had one number L written on her left leg, and another number R written on her right leg. She had no idea what those numbers were, but she thought she might be in a position to figure out the odds that L \\({\\geq}\\) R. So she started reasoning as follows, making repeated appeals to C-INDIFFERENCE. (She must also appeal to P-INDIFFERENCE at every stage if there are other propositions about which she is uncertain. Assume that appeal made.)\nLet’s say the number on my left leg is 57. Then L \\({\\geq}\\) R iff R &lt; 58. But since there are 58 ways for R &lt; 58 to be true, and infinitely many ways for R &lt; 58 to be false, and by C-INDIFFERENCE each of these ways deserve the same credence conditional on L = 57, we get Pr(L \\({\\geq}\\) R  L = 57) = 0. But 57 was arbitrary in this little argument, so I can conclude \\({\\forall}\\)l: Pr(L \\({\\geq}\\) R  L = l) = 0. This seems to imply that Pr(L \\({\\geq}\\) R) = 0, especially since I know L takes some value or other, but let’s not be too hasty.\nLet’s say the number on my right leg is 68. Then L \\({\\geq}\\) R iff L \\({\\geq}\\) 68. And since there are 68 ways for L \\({\\geq}\\) 68 to be false, and infinitely many ways for it to be true, and by C-INDIFFERENCE each of these ways deserve the same credence conditional on R = 68, we get Pr(L \\({\\geq}\\) R  R = 68) = 1. But 68 was arbitrary in this little argument, so I can conclude \\({\\forall}\\)r: Pr(L \\({\\geq}\\) R  R = r) = 1. This seems to imply that Pr(L \\({\\geq}\\) R) = 1, especially since I know R takes some value or other, but now I’m just confused.\nMorgan is right to be confused. She has not quite been led into inconsistency, because as she notes the last step, from \\({\\forall}\\)l: Pr(L \\({\\geq}\\) R  L = l) = 0 to Pr(L \\({\\geq}\\) R) = 0 is not forced. In fact, the claim that this is always a valid inferential step is equivalent to the principle of countable additivity, which we have already seen a proponent of INDIFFERENCE in all its variations must reject. But it would be a mistake to conclude from this that we just have a standoff. What Morgan’s case reveals is that accepting the indifference principles that Elga offers requires giving up on an intuitively plausible principle of inference. That principle says that if the probability of p conditional on any member of a partition is x, then the probability of p is x. If we think that principle of inference is prima facie more plausible than Elga’s principle of indifference, as I think we should, that is pretty good prima facie evidence that Elga’s principle is wrong.\nThe next three sections will be devoted to determining whether we can convert this persuasive argument into a knockdown argument (we cannot) and whether Elga’s arguments in favour of INDIFFERENCE do enough to overcome this prima facie argument that INDIFFERENCE is flawed (they do not). A concluding section notes how to redo this argument so it appeals only to potential rather than actual infinities.\n\n\n0.6 Intermission\nCHARYBDIS: I know how to make that argument stronger. Just get Evil to offer Morgan a bet on whether L \\({\\geq}\\) R. Ask how much she’ll pay for a bet that pays €1 if L \\({\\geq}\\) R and nothing otherwise. If she pays anything for it, tell her the value of L, whatever it is, and ask her if she’d like to sell that bet back for half what she paid for it. Since she now assigns probability zero to L \\({\\geq}\\) R she’ll happily do that, and then she’ll have lost money. If she won’t pay anything for the bet to start with, offer her the reverse bet. She should pay €1 for that, and now apply the same tactics except tell her the value of R rather than L. Either way the stupid person will lose money.\nSCYLLA:Very practical Charybdis, but we’re not sure it gets to the heart of the matter. Not sure. Well, let us say why rather than leaving it like that. For one thing, Morgan might not like playing dice with Evil, even if Evil is the source of her life. So she might have a maximum price of 0 for either bet.\nCHARYBDIS:But then surely she’ll be turning down a sure win. I mean between the bets she has a sure gain of at least €1.\nSCYLLA:And if she is offered both bets at once we’re sure she would take that gain, but as we heard your story she wasn’t.4\n4 Compare the objection to Dutch Book arguments in Schick (1986).CHARYBDIS:So does this mean her degree of belief in both R \\({\\geq}\\) L and L \\({\\geq}\\) R is 0?\nSCYLLA:It might mean that, and of course some smart people have argued that that is coherent, much to the chagrin of your Bayesian friends we’re sure.5 But more likely it means that she just isn’t following the patterns of practical reasoning that you endorse.6 Also, we’re not so sure about the overall structure of the argument. We think your reasoning is as follows. Morgan ends up doing something silly, giving up money. (Well, we’re not sure that’s always silly, but let’s say it is here.) So something went wrong. So she has silly beliefs. That last step goes by fairly fast we think. From her making some mistake or other, we can only conclude that, well, she made some mistake or other, not that she made some particular mistake in the composition of her credences.7\n5 For example, Shafer (1976).6 Compare the state-dependent approach to decision-making discussed in Chambers and Quiggin (2000).7 This point closely resembles an objection to Dutch Book reasoning made in Hájek (2005), though Scylla is much more sceptical about how much we can learn from these pragmatic arguments than Hájek is.CHARYBDIS:What other mistake might she have made?\nSCYLLA:There are many hidden premises in your chains of reasoning to conclusions about how Morgan should behave. For instance, she only values a €1 bet on L \\({\\geq}\\) R at Pr(L \\({\\geq}\\) R) if she knows she can’t buy that bet more cheaply elsewhere, or sell it for a larger price elsewhere. Even if those assumptions are true, Morgan may unreasonably believe they are false, and that might be her mistake.8 But even that isn’t our main concern. Our main concern is that you understate how bad Morgan’s position is.\n8 Scylla’s reasoning here is based on Milne (1991), though of course Milne’s argument is much less condensed than that.CHARYBDIS:What’s worse for a mortal than assured loss of money?\nSCYLLA:Morgan is not a mortal any more, you know. And immortals we’re afraid are almost bound to lose money to clever enough tricksters. Indeed, a so-called Dutch Book can be made against any agent that (a) has an unbounded utility function and (b) is not overly opinionated, so there are still infinitely many ways the world could be consistent with their knowledge.9 That includes us, and you dear Charybdis. And yet we are not as irrational as that Morgan. I don’t think analogising her position to ours really strengthens the case that she is irrational.\n9 This is proven in McGee (1999).CHARYBDIS:Next you might say that making money off her, this undeserving immortal, is immoral.\nSCYLLA:Perish the thoughts.\n\n\n0.7 Risky Business?\nThere are two kinds of reasons to dislike indifference principles, both of them developed most extensively in Keynes (1921). The first, which we have been exploring a bit so far, is that such principles tend to lead to incoherence. The second is that such principles promote confusion between risk and uncertainty.\nOften we do not know exactly what the world is like. But not all kinds of ignorance are alike. Sometimes, our ignorance is like that of a roulette player facing a fair wheel about to be spun. She knows not what will happen, but she can provide good reasons for assigning equal credence to each of the 37 possible outcomes of the spin. Loosely following Frank Knight (1921), we will say that a proposition like The ball lands in slot number 18 is risky. The distinguishing feature of such propositions is that we do not know whether they are true or false, but we have good reason to assign a particular probability to their truth. Other propositions, like say the proposition that there will be a nuclear attack on an American city this century, are quite unlike this. We do not know whether they are true, and we aren’t really in a position to assign anything like a precise numerical probability to their truth. Again following Knight, we will say such propositions are uncertain. In (1937) Keynes described a number of other examples that nicely capture the distinction being drawn here.\n\nBy ‘uncertain’ knowledge, let me explain, I do not mean merely to distinguish what is known for certain from what is only probable. The game of roulette is not subject, in this sense, to uncertainty; nor is the prospect of a Victory bond being drawn. Or, again, the expectation of life is only slightly uncertain. Even the weather is only moderately uncertain. The sense in which I am using the term is that in which the prospect of a European war is uncertain, or the price of copper and the rate of interest twenty years hence, or the obsolescence of a new invention, or the position of private wealth owners in the social system in 1970. About these matters there is no scientific basis on which to form any calculable probability whatever. We simply do not know. Nevertheless, the necessity for action and decision compels us as practical men to do our best to overlook this awkward fact and to behave exactly as we should if we had behind us a good Benthamite calculation of a series of prospective advantages and disadvantages, each multiplied by its appropriate probability, waiting to be summed. (Keynes 1937, 114–15)\n\nNote that the distinction between risky and uncertain propositions is not the distinction between propositions whose objective chance we know and those that we don’t. This identification would fail twice over. First, as Keynes notes, whether a proposition is risky or uncertain is a matter of degree, but whether we know something is, I presume, not a matter of degree.10 Second, there are risky propositions with an unknown chance. Assume that our roulette player turns away from the table at a crucial moment, and misses the ball landing in a particular slot. Now the chance that it lands in slot 18 is 1 (if it did so land) or 0 (otherwise), and she does not know which. Yet typically, the proposition The ball lands in slot 18 is still risky for her, for she has no reason to change her attitude towards the proposition that it did land in slot 18.\n10 Though see Hetherington (2001) for an argument to the contrary.My primary theoretical objection to INDIFFERENCE is that the propositions it purports to provide guidance on are really uncertain, but it treats them as risky. Once we acknowledge the risk/uncertainty distinction, it is natural to think that our default state is uncertainty. Getting to a position where we can legitimately treat a proposition as risky is a cognitive achievement. Traditional indifference principles fail because they trivialise this achievement. An extreme version of such a principle says we can justify assigning a particular numerical probability, 0.5, to propositions merely on the basis of ignorance of any evidence telling for or against it. This might not be an issue to those who think that “probability is a measure of your ignorance.” (Poole, Mackworth, and Goebel 1998, 348) But to those of us who think probability is the very guide to life, such a position is unacceptable. It seems to violate the platitude ‘garbage in, garbage out’ since it takes ignorance as input, and produces a guide to life as output. INDIFFERENCE is more subtle than these traditional indifference principles, but this theoretical objection remains. The evidence that O’Leary or Morgan or Leslie has does not warrant treating propositions about their location or identity as risky rather than uncertain. When they must make decisions that turn on their identity or location, this ignorance provides little or no guidance, not a well-sharpened guide to action.\nIn this section I argue that treating these propositions as uncertain lets us avoid the traps that Morgan falls into. In the next section I argue that the case Elga takes to support INDIFFERENCE says nothing to the theorist who thinks that the INDIFFERENCE principle conflates risk and uncertainty. In fact, some features of that case seem to support the claim that the propositions covered by INDIFFERENCE are uncertain, not risky.\nIn (1921), Keynes put forward a theory of probability that was designed to respect the distinction between risky propositions and uncertain propositions. He allowed that some propositions, the risky ones and the ones known to be true or false, had a numerical probability (relative to a body of evidence) while other propositions have non-numerical probabilities. Sometimes numerical and non-numerical probabilities can be compared, sometimes they cannot. Arithmetic operations are all assumed to be defined over both numerical and non-numerical probabilities. As Ramsey (1926) pointed out, in Keynes’s system it is hard to know what \\({\\alpha}\\) + \\({\\beta}\\) is supposed to mean when \\({\\alpha}\\) and \\({\\beta}\\) are non-numerical probabilities, and it is not even clear that ‘+’ still means addition in the sense we are used to.\nOne popular modern view of probability can help Keynes out here. Following Ramsey, many people came to the view that the credal states of a rational agent could be represented by a probability function, that function being intuitively the function from propositions into the agent’s degree of belief in that proposition. In the last thirty years, there has been a lot of research on the theory that says we should represent rational credal states not by a single probability function, but by a set of such probability functions. Within philosophy, the most important works on this theory are by Henry Kyburg (1974), Isaac Levi (1974, 1980), Richard Jeffrey (1983) and Bas Fraassen (1990). What is important here about this theory is that many distinctive features of Keynes’s theory are reflected in it.\nLet S be the set of probability functions representing the credal states of a rational agent. Then for each proposition p we can define a set S(p) = {Pr(p): Pr \\({\\in}\\) S}. That is, S(p) is the set of values that Pr(p) takes for Pr being a probability function in S. We will assume here that S(p) is an interval. (See the earlier works cited for the arguments in favour of this assumption.) When p is risky, S(p) will be a singleton, the singleton of the number we have compelling reason to say is the probability of p. When p is a little uncertain, S(p) will be a fairly narrow interval. When it is very uncertain, S(p) will be a wide interval, perhaps as wide as [0, 1]. We say that p is more probable than q iff for all Pr in S, Pr(p) &gt; Pr(q), and as probable as q iff for Pr in S, Pr(p) = Pr(q). This leaves open the possibility that Keynes explicitly left open, that for some uncertain proposition p and some risky proposition q, it might be the case that they are not equally probable, but neither is one more probable than the other. Finally, we assume that when an agent whose credal states are represented by S updates by learning evidence e, her new credal states are updated by conditionalising each of the probability functions in S on e. So we can sensibly talk about S(p  e), the set {Pr(p  e): Pr \\({\\in}\\) S}, and this represents her credal states on learning e.\n(It is an interesting historical question just how much the theory sketched here agrees with the philosophical motivations of Keynes’s theory. One may think that the agreement is very close. If we take Keynes’s entire book to be a contextual definition of his non-numerical probabilities, a reading encouraged by Lewis (1970), then we should conclude he was talking about sets like this, with numerical probabilities being singleton sets.)\nThis gives us the resources to provide good advice to Morgan. Pick a monotone increasing function f from integers to [0, 1] such that as n \\({\\rightarrow}\\) \\({\\infty}\\), f(n) \\({\\rightarrow}\\) 1. It won’t really matter which function you pick, though different choices of f might make the following story more plausible. Say that S(L \\({\\geq}\\) R  L = l) = [0, f(l)]. The rough idea is that if L is small, then it is quite improbable that L  \\({\\geq}\\) R, although this is a little uncertain. As l gets larger, L \\({\\geq}\\) R gets more and more uncertain. The overall effect is that we simply do not know what S(L \\({\\geq}\\) R) will look like after conditionalising on the value of L, so we cannot apply the kind of reasoning Morgan uses to now come to some conclusions about the probability of L \\({\\geq}\\) R.\nIf we view the situations described by INDIFFERENCE as involving uncertainty rather than risk, this is exactly what we should expect. And note that in so doing, we need not undermine the symmetry intuition that lies behind INDIFFERENCE. Assume that F and G are similar predicaments, and I know that I am either F or G. INDIFFERENCE says I should assign equal probability to each, so S(I am F) = S(I am G) = {0.5}. But once we’ve seen how attractive non-numerical probabilities can be, we should conclude that all symmetry gives us is that S(I am F) = S(I am G), which can be satisfied if each is [0.4, 0.6], or [0.2, 0.8] or even [0, 1]. (I think that for O’Leary, for example, S(It is 1 o’clock) should be a set somehow like this.) Since I would not be assigning equal credence to I am F and I am G if I satisfied symmetry using non-numerical probabilities, so I will violate INDIFFERENCE without treating the propositions asymmetrically. Such a symmetric violation of INDIFFERENCE has much to recommend it. It avoids the incoherence that INDIFFERENCE leads to in Morgan’s case. And it avoids saying that ignorance about our identity can be a sharp guide to life.11\n11 Bradley (monton2002?) discusses using sets of probability functions to solve another problem proposed by Elga, the Sleeping Beauty problem (Elga 2000). Monton notes that if Beauty’s credence in The coin landed heads is [0, 0.5] when she wakes up on Monday, then she doesn’t violate van Fraassen’s General Reflection Principle (Fraassen 1995). (I assume here familiarity with the Sleeping Beauty problem.) Monton has some criticisms of this move, in particular the consequences it has for updating, that don’t seem to carry across to the proposal sketched here. But his discussion is noteworthy as a use of this approach to uncertainty as a way to solve problems to do with similar predicaments.A referee noted that the intuitive characterisation here doesn’t quite capture the idea that we should treat similar predicaments alike. The requirement that if F and G are similar then S(I am F) = S(I am G) does not imply that there will be a symmetric treatment of F and G within S if there are more than two similar predicaments. What we need is the following condition. Let T be any set of similar predicaments, g any isomorphism from T onto itself, and Pr any probability function in S. Then there exists a Pr\\(^\\prime\\) in S such that for all A in T, Pr(A) = Pr\\(^\\prime\\)(g(A)). When there are only two similar predicaments A and B this is equivalent to the requirement that S(A) = S(B), but in the general case it is a much stricter requirement. Still, it is a much weaker constraint than INDIFFERENCE, and not vulnerable to the criticisms of INDIFFERENCE set out here.\n\n\n0.8 Boyfriend in a Coma\nElga argues for INDIFFERENCE by arguing it holds in a special case, and then arguing that the special case is effectively arbitrary, so if it holds there it holds everywhere. The second step is correct, so we must look seriously at the first step. Elga’s conclusions about the special case, DUPLICATION, eventually rest on treating an uncertain proposition as risky.\n\nDUPLICATION\n\nAfter Al goes to sleep researchers create a duplicate of him in a duplicate environment. The next morning, Al and the duplicate awaken in subjectively indistinguishable states.\n\n\nAssume (in all these cases) that before Al goes to sleep he knows the relevant facts of the case. In that case INDIFFERENCE12 dictates that when Al wakes up his credence in I am Al should be 0.5. Elga argues this dictate is appropriate by considering a pair of related cases.\n12 As with earlier cases, strictly speaking we need C-INDIFFERENCE and P-INDIFFERENCE to draw the conclusions suggested unless Al is somehow certain about all other propositions. I will ignore that complication here, and in .\nTOSS-and-DUPLICATION\n\nAfter Al goes to sleep, researchers toss a coin that has a 10% chance of landing heads. Then (regardless of the toss outcome) they duplicate Al. The next morning, Al and the duplicate awaken in subjectively indistinguishable states.\n\n\nElga notes, correctly, that the same epistemic norms apply to Al on waking in DUPLICATION as in TOSS-and-DUPLICATION. So if we can show that when Al wakes in TOSS-and-DUPLICATION his credence in I am Al should be 0.5, that too will suffice to prove INDIFFERENCE correct in this case. The argument for that claim has three premises. (I’ve slightly relabeled the premises for ease of expression.)\n\nPr(H) = 0.1\nPr(H (H \\({\\wedge}\\) A) \\({\\vee}\\) (T \\({\\wedge}\\) A)) = 0.1\nPr(H (H \\({\\wedge}\\) A) \\({\\vee}\\) (T \\({\\wedge}\\) D)) = 0.1\n\nHere Pr is the function from de se propositions to Al’s degree of belief in them, H = The coin lands heads, T = The coin lands tails, A = I am Al and D = I am Al’s duplicate. From (1), (2) and (3) and the assumption that Pr is a probability function it follows that Pr(A) = 0.5, as required. This inference goes through even in the Keynesian theory that distinguishes risk from uncertainty. Premise (1) is uncontroversial, but both (2) and (3) look dubious. Since the argument for (3) would, if successful, support (2), I’ll focus, as Elga does, on (3). The argument for it turns on another case.\n\nCOMA\n\nAs in TOSS-and-DUPLICATION, the experimenters toss a coin and duplicate Al. But the following morning, the experimenters ensure that only one person wakes up: If the coin lands heads, they allow Al to wake up (and put the duplicate into a coma); if the coin lands tails, they allow the duplicate to wake up (and put Al into a coma).\n\n\n(It’s important that no one comes out of this coma, so assume that the victim gets strangled.)\nElga then argues for the following two claims. If in COMA Al gets lucky and pulls through, his credence in H should be 0.1, as it was before he entered the dream world. Al’s credence in H in COMA should be the same as his conditional credence in H should be the same as his conditional credence in H given (H \\({\\wedge}\\) A) \\({\\vee}\\) (T \\({\\wedge}\\) D) in TOSS-and-DUPLICATION. The second premise looks right, so the interest is on what happens in COMA. Elga argues as follows (notation slightly changed):\n\nBefore Al was put to sleep, he was sure that the chance of the coin landing heads was 10%, and his credence in H should have accorded with this chance: it too should have been 10%. When he wakes up, his epistemic situation with respect to the coin is just the same as it was before he went to sleep. He has neither gained nor lost information relevant to the toss outcome. So his degree of belief in H should continue to accord with the chance of H at the time of the toss. In other words, his degree of belief in H should continue to be 10%.\n\nAnd this, I think, is entirely mistaken. Al has no evidence that his evidence is relevant to H, but absence of evidence is not evidence of absence. Four considerations support this conclusion.\nFirst, Al gets some evidence of some kind or other on waking. Certain colours are seen, certain pains and sensations are sensed, certain fleeting thoughts fleet across his mind. Before he sleeps Al doesn’t knows what these shall be. Maybe he thinks of the money supply, maybe of his girlfriend, maybe of his heroine, maybe of kidneys. He doesn’t know that the occurrence of these thoughts is probabilistically independent of his being Al rather than Dup, so he does not know they are probabilistically independent of H. So perhaps he need not retain the credence in H he has before he was drugged. Even if this evidence looks like junk, we can’t rule out that it has some force.\nSecondly, the kind of internalism about evidence needed to support Elga’s position is remarkably strong. (This is where the concerns raised in become most pressing.) Elga notes that he sets himself against both an extreme externalist position that says that Al’s memories and/or perceptions entail that he is Al and against an “intermediate view, according to which Al’s beliefs about the setup only partially undermine his memories of being Al. According to such a view, when Al wakes up his credence in H ought to be slightly higher than 10%.” But matters are worse than that. Elga must also reject an even weaker view that says that Al might not know whether externalism about evidence is true, so he does not know whether his credence in H should change. My view is more sympathetic to that position. When Al wakes, he does not know which direction is credences should move, or indeed whether there is such a direction, so his credence in H should be a spread of values including 0.1.\nThirdly, Al’s position looks like cases where new evidence makes risky propositions uncertain. Mack’s betting strategy for the Gold Cup, a horse race with six entrants, is fairly simple. He rolls a fair die, and bets on whatever number comes up. Jane knows this is Mack’s strategy, but does not how the die landed this time. Nor does she know anything about horses, so the propositions Horse n wins the Gold Cup are uncertain for Jane for each n. Call these propositions wn, and the proposition that Mack’s die landed n dn. Right now, d2 is risky, but h2 is uncertain. Jane hears a party starting next door. Mack’s won. Jane has learned, inter alia, d2 \\(\\leftrightarrow\\) h2. Now it seems that d2, Mack’s die landed 2, inherits the uncertainty of h2, Horse number 2 won the Gold Cup. The formal theory of uncertainty I sketched allows for this possibility. It is possible that there be p, e such that S(p) is a singleton, while S(p  e) is a wide interval, in theory as wide as [0, 1]. This is what happens in Jane’s case, and it looks like it happens in Al’s case too. H used to be risky, but when he wakes he comes to learn H \\({\\leftrightarrow}\\) A, just as Jane learned d2 \\(\\leftrightarrow\\) h2. In each case, the left-hand clause of the biconditional inherits the uncertainty of the right-hand clause.\nFinally, H being uncertain for Al when he wakes in COMA is consistent with the intuition that Al has no reason to change his credences in H in one direction or another when he says goodbye to his duplicate. (Or, for all he knows, to his source.) Perhaps externalist theories of evidence provide some reason to raise these credences, as suggested above, but I do not rely on such theories. What I deny is that the absence of a reason to move one way or the other is a reason to stay put. Al’s credence in H might change in a way that reflects the fact H is now uncertain, just like A is in COMA, just like A is in TOSS-and-DUPLICATION, and, importantly, just like A is in DUPLICATION. I think the rest of Elga’s argument is right. DUPLICATION is a perfectly general case. In any such case, Al should be uncertain, in Keynes’s sense, whether he is the original or the duplicate.\n\n\n0.9 Shooting Dice can be Dangerous\nThe good news, said Dr Evil, is that you are still mortal. Odysseus was not as upset as Dr Evil had expected. The bad news is that I’m thinking of torturing you. I’m going to roll this fair die, and if it lands 6 you will be tortured. If it does not, you will be (tentatively) released, and I’ll create two duplicates of you as you were when you entered this room, repeat this story to both them. Depending on another roll of this fair die, I will either torture them both, or create two duplicates of each of them, and repeat the process until I get to torture someone.13\n13 Dr Evil’s plans create a situation similar to the well known ‘shooting room’ problem. For the best analysis of that problem see Bartha and Hitchcock (1999). Dr Evil has changed the numbers involved in the puzzle a little bit to make the subsequent calculations a little more straightforward. He’s not very good at arithmetic you see.Odysseus thought through this for a bit. So I might be a duplicate you’ve just created, he said. I might not be Odysseus.\nYou might not be, said Dr Evil, although so as to avoid confusion if you’re not him I’ll use his name for you.\nWhat happens if the die never lands 6, asked Odysseus. I’ve seen some odd runs of chance in my time.\nI wouldn’t be so sure of that, said Dr Evil. Anyway, that’s why I said I would tentatively release you. I’ll make the die rolls and subsequent duplication quicker and quicker so we’ll get through the infinite number of rolls in a finite amount of time. If we get that far I’ll just bring everyone back and torture you all. Aren’t I fair?\nFairness wasn’t on Odysseus’s mind though. He was trying to figure out how likely it was that he would be tortured. He was also a little concerned about how likely it was that he was the original Odysseus, and if he was not whether Penelope too had been duplicated. As it turns out, his torturous computations would assist with the second question, though not the third. Two thoughts crossed his mind.\nI will be tortured if that die lands 6, which has a chance of 1 in 6, or if it never lands 6 again, which has a chance of 0. So the chance of my being tortured is 1 in 6. I have no inadmissible evidence, so the probability I should assign to torture is 1 in 6.\nLet’s think about how many Odysseuses there are in the history of the world. Either there is 1, in which case I’m him, and I shall be tortured. Or there are 3, in which case two of them shall be tortured, so the probability that I shall be tortured is 2 in 3. Or there are 7, in which case four of them shall be tortured, so the probability that I shall be tortured is 4 in 7. And so on, it seems like the probability that I shall be tortured approaches 1 in 2 from above as the number of Odysseuses approaches infinity. Except, of course, in the case where it reaches infinity, when it is again certain that I shall be tortured. So it looks like the probability that I will be tortured is above 1 in 2. But I just concluded it is 1 in 6. Where did I go wrong?\nIn his second thought, Odysseus appeals frequently to INDIFFERENCE. He then appeals to something like the conglomerability principle that tripped up Morgan. The principle Odysseus uses is a little stronger than the principle Morgan used. It says that if there is a partition and conditional on each member of the partition, the probability of p is greater than x, then the probability of p is greater than x. As we noted, this principle cannot be accepted in its full generality by one who rejects countable additivity. And one who accepts INDIFFERENCE must reject countable additivity. So where Odysseus goes wrong is in appealing to this inference principle after previously adopting an indifference principle inconsistent with it.\nThis does not mean the case has no interest. Morgan’s case showed that when we have an actual infinity of duplicates, INDIFFERENCE can lead to counterintuitive results, and that the best way out might be to say that Morgan faced a situation of uncertainty, not one of risk. But it might have been thought that something special about Morgan’s case, that she has infinitely many duplicates, might be responsible for the problems here. So it may be hoped that INDIFFERENCE can at least be accepted in more everyday cases. Odysseus shows that hope is in vain. All we need is the merest possibility of there being infinitely many duplicates, here a possibility with zero probability, to create a failure of conglomerability. This suggests that the problems with INDIFFERENCE run relatively deep.\nThe details of how Odysseus’s case plays out given INDIFFERENCE are also interesting, especially to those readers not convinced by my refutation of INDIFFERENCE. For their benefit, I will close with a few observations about how the case plays out.\nAs in Morgan’s case, we can produce two different partitions of the possibility space that seem to support different conclusions about Odysseus’s prospects. Assume for convenience that Dr Evil makes a serial number for each Odysseus he makes, the Homeric hero being number 1, the first two duplicates being 2 and 3, and so on. Let N stand for the number of our hero, M for the number of Odysseuses that are made, and T for the property of being tortured. Then given INDIFFERENCE it behoves Odysseus to have his credences governed by the following Pr function.\n\n\n\\({\\forall}\\)k Pr(T  M = 2k - 1) = 2k-1/(2k - 1)\nPr(T  M = \\({\\infty}\\)) = 1\n\n\\({\\forall}\\)n Pr(T  N = n) = 1/6\n\nBetween 4a and 4b we cover all possible values for M, and in every case Pr(T) is greater than 1/2. More interesting are Odysseus’s calculations about whether he is the Homeric hero, i.e. about whether N = 1. Consider first a special case of this, what the value of Pr(N = 1 N &lt; 8) is. At first glance, it might seem that this should be 1/7, because there are seven possible values for N less than 8. But this is too quick. There are really eleven possibilities to be considered.\n\n\n\nF1: N = 1 and M = 1\nF2: N = 1 and M = 3\nF5: N = 1 and M &gt; 3\n\n\n \nF3: N = 2 and M = 3\nF6: N = 2 and M &gt; 3\n\n\n \nF4: N = 3 and M = 3\nF7: N = 3 and M &gt; 3\n\n\n \n \nF8: N = 4 and M &gt; 3\n\n\n \n \nF9: N = 5 and M &gt; 3\n\n\n \n \nF10: N = 6 and M &gt; 3\n\n\n \n \nF11: N = 7 and M &gt; 3\n\n\n\nBy INDIFFERENCE, each of the properties in each column should be given equal probability. So we have\n\\[\\begin{aligned}\nx &= Pr(F_1 | N &lt; 8)  \\\\\ny &= Pr(F_2 | N &lt; 8) = Pr(F_3 | N &lt; 8) = Pr(F_4 | N &lt; 8)  \\\\\nz &= Pr(F_5 | N &lt; 8) = \\dots = Pr(F_11 | N &lt; 8)  \\end{aligned}\\]\nWe just have to solve for x, y and z. By the Principal Principle we get\n\nPr(M = 1  N = 1) = 1/6\n\\({\\therefore}\\) x = (x + y + z) / 6\nPr(M = 3 N = 1 and M \\({\\geq}\\) 3) = 1/6\n\\({\\therefore}\\) y = (y + z) / 6\n\nAnd since these 11 possibilities are all the possibilities for N &lt; 8, we have\n\nx + 3y + 7z = 1\n\nSolving for all these, we get x = 3/98, y = 5/196 and z = 25/196, so Pr(N = 1  N &lt; 8) = x + y + z = 9/49. More generally, we have the following (the proof of this is omitted): \\[Pr(N = 1 | N &lt; 2^{k+1}) = \\frac{6^k}{\\sum_{i=0}^{k}6^i10^{k-i}}\\]\nSince the RHS \\({\\rightarrow}\\) 0 as k \\({\\rightarrow}\\) \\({\\infty}\\), Pr(N = 1) = 0. Our Odysseus is probably not the real hero. Similar reasoning shows that Pr(N = n) = 0 for all n. So we have another violation of countable additivity. But we do not have, as in Morgan’s case, a constant distribution across the natural numbers. In a sense, this distribution is still weighted towards the bottom, since for any n &gt; 1, Pr(N = 1  N = 1 \\({\\vee}\\) N = n) &gt; 1/2. Of course, I don’t think INDIFFERENCE is true, so these facts about what Odysseus’s credence function will look like under INDIFFERENCE are of purely mathematical interest to me. But it might be possible that someone more enamoured of INDIFFERENCE can use this ‘unbalanced’ distribution to explain some of the distinctive features of the odd position that Odysseus is in.\n\n\n\n\n\n\nReferences\n\nBartha, Paul, and Christopher Hitchcock. 1999. “The Shooting-Room Paradox and Conditionalizing on Measurably Challenged Sets.” Synthese 118 (3): 403–37. https://doi.org/10.1023/a:1005100407551.\n\n\nCampbell, John. 2002. Reference and Consciousness. Oxford: Oxford University Press.\n\n\nChambers, Robert, and John Quiggin. 2000. Uncertainty, Production, Choice, and Agency: The State-Contingent Approach. Cambridge: Cambridge University Press.\n\n\nDreier, James. 2001. “Boundless Good.”\n\n\nElga, Adam. 2000. “Self-Locating Belief and the Sleeping Beauty Problem.” Analysis 60 (2): 143–47. https://doi.org/10.1093/analys/60.2.143.\n\n\n———. 2004. “Defeating Dr. Evil with Self-Locating Belief.” Philosophy and Phenomenological Research 69 (2): 383–96. https://doi.org/10.1111/j.1933-1592.2004.tb00400.x.\n\n\nFara, Delia Graff. 2001. “Phenomenal Continua and the Sorites.” Mind 110 (440): 905–36. https://doi.org/10.1093/mind/110.440.905.\n\n\nFraassen, Bas van. 1990. “Figures in a Probability Landscape.” In Truth or Consequences, edited by J. M. Dunn and A. Gupta, 345–56. Amsterdam: Kluwer.\n\n\n———. 1995. “Belief and the Problem of Ulysses and the Sirens.” Philosophical Studies 77 (1): 7–37. https://doi.org/10.1007/bf00996309.\n\n\nGoodman, Nelson. 1951. The Structure of Appearance. Cambridge, MA: Harvard University Press.\n\n\nHájek, Alan. 2005. “Scotching Dutch Books.” Philosophical Perspectives 19: 139–51. https://doi.org/10.1111/j.1520-8583.2005.00057.x.\n\n\nHetherington, Stephen. 2001. Good Knowledge, Bad Knowledge: On Two Dogmas of Epistemology. Oxford: Oxford University Press.\n\n\nJeffrey, Richard. 1983. “Bayesianism with a Human Face.” In Testing Scientific Theories, edited by J. Earman (ed.). Minneapolis: University of Minnesota Press.\n\n\nKeynes, John Maynard. 1921. Treatise on Probability. London: Macmillan.\n\n\n———. 1937. “The General Theory of Employment.” Quarterly Journal of Economics 51 (2): 209–23. https://doi.org/10.2307/1882087.\n\n\nKnight, Frank. 1921. Risk, Uncertainty and Profit. Chicago: University of Chicago Press.\n\n\nKyburg, Henry. 1974. The Logical Foundations of Statistical Inference. Dordrecht: Reidel.\n\n\nLevi, Isaac. 1974. “On Indeterminate Probabilities.” Journal of Philosophy 71 (13): 391–418. https://doi.org/10.2307/2025161.\n\n\n———. 1980. The Enterprise of Knowledge. Cambridge, MA.: MIT Press.\n\n\nLewis, David. 1970. “How to Define Theoretical Terms.” Journal of Philosophy 67 (13): 427–46. https://doi.org/10.2307/2023861.\n\n\n———. 1979. “Attitudes de Dicto and de Se.” Philosophical Review 88 (4): 513–43. https://doi.org/10.2307/2184646.\n\n\nMcGee, Vann. 1999. “An Airtight Dutch Book.” Analysis 59 (4): 257–65. https://doi.org/10.1093/analys/59.4.257.\n\n\nMilne, Peter. 1991. “Scotching the Dutch Book Argument.” Erkenntnis 32 (1): 105–26. https://doi.org/10.1007/bf00209558.\n\n\nPoole, David, Alan Mackworth, and Randy Goebel. 1998. Computational Intelligence: A Logical Approach. Oxford: Oxford University Press.\n\n\nRamsey, Frank. 1926. “Truth and Probability.” In Philosophical Papers, edited by D. H. Mellor, 52–94. Cambridge: Cambridge University Press.\n\n\nSchick, Frederick. 1986. “Dutch Bookies and Money Pumps.” Journal of Philosophy 83 (2): 112–19. https://doi.org/10.2307/2026054.\n\n\nShafer, Glenn. 1976. A Mathematical Theory of Evidence. Princeton: Princeton University Press.\n\n\nWilliamson, Timothy. 1998. “Conditionalizing on Knowledge.” British Journal for the Philosophy of Science 49 (1): 89–121. https://doi.org/10.1093/bjps/49.1.89."
  },
  {
    "objectID": "posts/review-rethinking-intuition/review-of-rethinking-intuition.html",
    "href": "posts/review-rethinking-intuition/review-of-rethinking-intuition.html",
    "title": "Review of “Rethinking Intuition”",
    "section": "",
    "text": "This collection arose out of a conference on intuitions at the University of Notre Dame in April 1996. The papers in it mainly address two related questions: (a) How much evidential weight should be assigned to intuitions? and (b) Are concepts governed by necessary and sufficient conditions, or are they governed by ‘family resemblance’ conditions, as Wittgenstein suggested? The book includes four papers by psychologists relating and analyzing some empirical findings concerning intuitions and eleven papers by philosophers endorsing various answers to these questions.\n\nPublished in Ethics 112: 361-364.\n\nThe first section consists of the papers by psychologists. In these papers, the main target is the traditional philosopher who holds, inter alia, that the answer to a is “quite a lot” and the answer to b is the former, that there are necessary and sufficient conditions for most philosophically interesting concepts. If you like these answers, then you might spend your time Chisholming away at concepts like ‘justice,’ ‘knowledge,’ and ‘causation’—proposing snappy analyses and testing them against intuitions about possible cases. But if you don’t like these answers, you might prefer to make pointed criticisms of the presuppositions of such a methodology and suggest some more empirically defensible ways of coming to understand concepts. Indeed, this is just what the psychologists writing here do.\nThe papers by the philosophers are, very roughly, divided up according to their answers to these questions. The second section, titled “Rethinking Intuition and Philosophical Method,” consists of papers disagreeing with traditional philosophy about a or b. (This section includes papers by Stephen Stich, Robert Cummins, Hilary Kornblith, Tamara Horowitz, William Ramsey, and Alvin Goldman and Joel Pust.) The really radical position, expressed most clearly by Stich, is that traditional philosophy is wrong on both counts. We need to bring much more empirical research to bear on explicating crucial concepts in ethics, epis- temology, and so forth, and the explications we will end up with will not be short lists of necessary and sufficient conditions. The third section, titled “Defending the Philosophical Tradition,” contains, mostly, defenses of one of the traditional views. (This section includes papers by George Bealer, Richard Foley, Ernest Sosa, George Graham and Terry Horgan, and Michael DePaul.) The main aim here is to defend the value of intuitions as evidence; there is no explicit defense of the traditional view of concepts. Despite this neat rationale, the editors’ classification breaks down in a few cases. For example, in Kornblith’s paper he indicates substantial agreement with the paper by Graham and Horgan. So it is a little unclear why these papers are in these opposing sections. There is one other philosophical paper: Gary Gutting’s historical introduction is printed in a special ‘Introduction’ section.\nThree of the papers have the phrase “Reflective Equilibrium” in their title, so it might be expected that there would be some cutting-edge discussions about how to balance competing desiderata in achieving equilibrium. We don’t get such a discussion, and perhaps with good reason. With a nod in the direction of Goodman, Rawls, and Daniels, the writers mostly agree that if the aim of ethical or epistemological theory is, primarily, to systematize our intuitions, then reflective equilibrium (RE) is the way to do it. The papers here are, quite self- consciously, interested in the more basic question of whether that is what we want ethics or epistemology to do. I’ll conclude by saying a bit more about the papers which most clearly address this question. For the radicals, Cummins argues that “philosophical intuition is epistemologically useless” (p. 125). For the traditionals, on the other hand, Michael DePaul argues that RE provides “close to a correct answer” to the question, “How should we conduct philo- sophical inquiry?” (p. 294).\nCummins compares evidence from intuitions to evidence from other sources, like telescopes. He notes two related features of telescopes which, he thinks, makes them more trustworthy sources of evidence than intuitions. First, telescopes can be calibrated. We can apply telescopes to cases about which we have reliable independent evidence and see whether they deliver appropriate answers. For example, we can point a telescope at a distant mountain and see whether it looks the same through the telescope as it does up close and personal. If so, we can trust what it shows about places we have never before seen, such as heavenly bodies. If not, we not only learn that the telescope is untrustworthy but also may learn a little about the way in which it fails. Unlike telescopes, intuitions cannot be independently checked. They can only be checked against other intuitions. Hence, argues Cummins, they are untrustworthy. As Sosa notes, the comparison here may be unfair. Even though we can calibrate telescopes, we cannot calibrate observation as a whole. We can only calibrate particular kinds of observations against other kinds of observations and particular kinds of intuitions against other kinds of intuitions. Intuition, in this respect, is just like observation, and since we trust observations, we should trust intuitions.\nCummins’s other critique is that what evidence we do have about intuitions suggests that they are artifacts of the process by which they are produced rather than reliable guides to their subject matters. The idea is that the presence of a certain intuition concerning fairness tells us more about the source of the intuition (usually the person who has the intuition) than about fairness. If this is right, then intuitions are obviously not evidential. Cummins’s argument is that there are only five possible sources of intuitions, and examination of each suggests that intuitions are artifacts of the process by which they are produced. To prove this, Cummins works through each of the five possible sources and argues for each that an intuition derived from that source has no evidential value. Argument by cases in this way, when there are five possible cases to cover, is never going to be satisfactory. For example, one of the cases Cummins considers is that intuitions are evidential because they arise from possession of concepts. Something like this view is endorsed in the papers by Bealer and by Goldman and Pust. Cummins thinks this does not work because our concepts are just sets of beliefs. One’s concept of an elevator is just everything one believes about elevators. If anything like this is right, then the fact that we intuit that p just means that we believe p and that could not be evidence that p. But the theory of concepts he has in mind cannot be right. As Fodor has pointed out, it seems people can share concepts while having different beliefs involving those concepts. Indeed, something like this must be right if genuine disagreement is possible. If possessing a concept just meant having certain beliefs, then it would be impossible for people with radically different beliefs about a subject to share concepts relating to that subject. Since such sharing is possible, concept possession does not reduce to having certain beliefs. The main point is not that there is an insurmountable problem for Cummins here—maybe a more detailed discussion could show that his account of concepts is right and Fodor’s is wrong—but rather that with such a wide terrain to cover, a short argument is not going to win many converts.\nMichael DePaul is much more content with intuitions playing a central role in philosophy. Indeed, he seems happy to let them do all the work. His paper imagines a dialogue between himself and a friendly barfly who wants to be told all about how philosophy works. At some point in the conversation, DePaul’s character decides to present the new friend with an extended summary of how RE works. The friend is bemused that philosophers seem to only sit around and compare intuitive judgments. It does seem, notes the friend, a trifle self-indulgent. DePaul’s response attempts to defend RE by an argument that any alternative method would be irrational. Any alternative, argues DePaul, would have to (a) abandon reflection, (b) reflect incompletely, by leaving out certain beliefs, principles, or whatever enters into reflection, or (c) not allow results of reflection to influence final theory. As DePaul notes, it would be irrational to accept any of these options. DePaul acknowledges two possible criticisms here, criticisms which he admits he is not sure how to answer. The first is that it is not clear what is wrong with being irrational, at least in the sense DePaul has in mind. The second is that even if we have a reason not to be irrational, it is not clear how strong a reason this is and, hence, whether irrationality might be justifiable on occasion because it fulfills some greater purpose.\nThere is a third criticism that more closely reflects the problem raised by DePaul’s interlocutor. When someone says that philosophy should be about more than systematizing intuitions, they are not advocating alternatives to RE but, rather, supplements to it. The point of the criticism was that there must be other sources of evidence for moral or conceptual claims, other than just intuition. (This, apparently, is intuitively obvious!) DePaul provides a good response to someone who wants to say that intuitions have no evidential value at all. But he does not answer the critic who denies that intuitions provide the only evidence that might bear on philosophical problems.\nThis is a very useful collection to have published. A study of the role of intuition should be at the heart of any investigation into philosophical methodology. And such an investigation will have to take into account both the empirical findings about how intuition works and the philosophical considerations about how much importance should be attached to intuitions. The papers here do not look like the last word on any of these questions, but they are a helpful, and perhaps overdue, first word."
  },
  {
    "objectID": "posts/mmp/many-many-problems.html",
    "href": "posts/mmp/many-many-problems.html",
    "title": "Many Many Problems",
    "section": "",
    "text": "0.1 Schiffer’s Problem\nStephen Schiffer suggests the following argument refutes supervaluationism. The central point is that, allegedly, the supervaluational theory of vague singular terms says false things about singular terms in speech reports.\n\nPublished in Philosophical Quarterly 55: 481-501.\nPhoto by Yoni Lerner via Creative Commons.\n\n\nPointing in a certain direction, Alice says to Bob, ‘There is where Harold and I first danced the rumba.’ Later that day, while pointing in the same direction, Bob says to Carla, ‘There is where Alice said she and Harold first danced the rumba.’ Now consider the following argument:\nBob’s utterance was true.\nIf the supervaluational semantics were correct, Bob’s utterance wouldn’t be true.\n\\(\\therefore\\) The supervaluational semantics isn’t correct. (Schiffer 2000, 321)\n\nAssuming Bob did point in pretty much the same direction as Alice, it seems implausible to deny (1). The argument is valid. So the issue is whether (2) is correct. Schiffer has a quick argument for (2), which I will paraphrase here. On supervaluational semantics, a sentence is true iff each of its acceptable precisifications is true. In this case, this means that if Bob’s utterance is true then it must be true however we precisify ‘there’. Each precisification of ‘there’ will be a (precise) place, and since ‘there’ is rather vague, many of these precisifications will be acceptable. For Bob’s utterance to be true, then, Alice must have said of every one of those places that it was the place where Harold and her first danced the rumba. But Alice couldn’t have said all those things, so (2) is true.\nSchiffer suggests that one way out of this problem would be to accept the existence of a vague object: the place where Harold and Alice first danced the rumba. I will note in section four several reasons for thinking the cost of this move is excessive. Fortunately, there is a cheaper way home.\nSchiffer underestimates the scope of supervaluationism. On Schiffer’s vision of the theory, a precisification assigns a precise content to a word, and hence to a sentence, then the world determines whether that content is satisfied, and hence whether the sentence is true on that precisification. This is hardly an unorthodox view of how supervaluationism works, it seems for instance to be exactly the view defended in Keefe (2000), but it is neither the only way, nor the best way, forward. We could say, rather, that a precisification assigns content to every linguistic token in the world, and the truth conditions of every one of these tokens is then determined relative to that global assignment of content. So if a precisification P assigns a place x to Bob’s word ‘there’, Bob’s utterance is true according to that precisification iff P also assigns x to Alice’s utterance of ‘there’. That is, Bob’s utterance is true according to P iff the precisification of his words by P just is what Alice said according to P.1\n1 Following Schiffer, we ignore the vagueness in ‘is where Harold and I first danced the rumba.’ This phrase is vague, but its vagueness raises no extra issues of philosophical importance.2 Thanks to John Hawthorne for the following argument.It is a dramatic widening of the scope of precisifications to claim that they assign content to every linguistic token in the world, rather than just words in the sentence under consideration, but it can be justified.2 Consider how we would react if later in the day, pointing in the crucial direction, Alice said, ‘Harold and I never danced the rumba there.’ We would think that Alice had contradicted herself – that between her two statements she must have said something false. A standard supervaluationist account, where sentences are precisified one at a time, cannot deliver this result. On such a view, it might be that each of Alice’s utterances are true on some precisifications, so they are both neither true nor false. On my theory, each precisification applies to both of Alice’s utterances (as well as every other utterance ever made) and since on each precisification one or other of the utterances is false, it turns out supertrue that Alice said something false, as desired. The current view allows for penumbral connections between sentences, as well as penumbral connections within sentences. Just as someone who says, “That is red and orange” says something false, my theory decrees that someone who says, “That is red. That is orange,” while pointing at the same thing says something false, even if the object is in the vague area ‘between’ red and orange.\nIt is crucial for this response to work that on every precisification, Alice and Bob’s demonstratives are co–referential. It does not seem like a particular expansion of supervaluational theory to posit this as a penumbral connection between the two words. At least, it seems plausible enough to do this if Alice and Bob really are pointing in a similar direction. If their demonstrations are only roughly co-directional, then on some precisifications they may well pick out different objects. This will definitely happen if some admissible precisification of Alice’s ‘there’ is not an admissible precisification of Bob’s ‘there’. In such a case, the theory here predicts that Bob’s utterance will be indeterminate in truth value. But if Alice and Bob only vaguely pointed in the same direction this is the correct prediction.\n\n\n0.2 Natural Properties\nSchiffer’s problem seems to have been solved with a minimum of fuss, but there is still a little work to do. Above I posited a penumbral connection between Alice’s and Bob’s words without explaining how such a connection could arise. This connection can be explained by some general considerations about content, considerations closely tied to the view of vagueness as semantic indecision that provides the best motivation for supervaluationism. As a few writers have pointed out (Quine 1960; Putnam 1980; Kripke 1982), there is not enough in our dispositions to use words to fix a precise content all terms in our lexicon. This does not immediately imply a thorough-going content scepticism because, as a few writers have also pointed out (Putnam 1973; Kripke 1980; Lewis 1983, 1984), meanings ain’t (entirely) in the head. Sometimes our words refer to a particular property or object rather than another not because our dispositions make this so, but because of some particular feature of that property or object. David Lewis calls this extra feature ‘naturalness’: some properties and objects are more natural than others, and when our verbal dispositions do not discriminate between different possible contents, naturalness steps in to finish the job and the more natural property or object gets to be the content.\nWell, that’s what happens when things go well. Vagueness happens when things don’t go well. Sometimes our verbal dispositions are indiscriminate between several different contents, and no one of these is more natural than all the rest. In these cases there will be many unnatural contents not eliminated by our dispositions that naturalness does manage to eliminate, but there will be still be many contents left uneliminated. Consider, for example, all the possible properties we might denote by ‘tall woman’. As far as our usage dispositions go, it might denote any one of the following properties: woman taller than 1680mm, woman taller than 1681mm, woman taller than 1680.719mm, etc. And it does not seem that any of these properties are more natural than any other. Hence there is no precise fact about what the phrase denotes. Hence it is vague. In sum, our dispositions are never enough to settle the content of a term. In some cases, such as ‘water’, ‘rabbit’, ‘plus’, ‘brain’ and ‘vat’, nature is kind enough to, more or less, finish the job. In others it is not, and vagueness is the result.\n(The above reasoning has a surprising consequence. Perhaps our verbal dispositions are consistent with the predicate Tall X denoting the property of being in the top quartile of Xs by height. Unlike each of the properties mentioned in the text, this is a more natural property than many of its competitors. So if this kind of approach to vagueness is right, there might not be quite as much vagueness as we expected.)\nIf this is how vagueness is created, then there is a natural way to understand how precisifications remove vagueness. Vagueness arises because more natural than is a partial order on putative contents, and hence there might be no most natural content consistent with our verbal dispositions. If this relation only defined a strict ordering, so whatever the candidate meanings were, one of them would be most natural, vagueness might be defeated. Well, that isn’t true in reality, but it is true on each precisification. Every precisification is a completion of the ‘naturalness’ partial order. That is, each precisification P defines a strict order, more natural-P than, on possible contents of terms such that o1 is more natural-P than o2 if (but not only if) o1 is more natural than o2. The particular contents of terms according to P is then defined by using the more natural-P than relation where the more natural than relation is used in the real theory of content.\nThis conjecture meshes nicely with my theory of the role of precisifications. First, it explains why precisifications apply to the whole of language. Since a precisification does not just remedy a defect in a particular word, but a defect in the content generation mechanism, precisifications are most naturally applied not just to a single word, but to every contentful entity. Secondly, it explains why we have the particular penumbral connections we actually have. Recall that it was left a little unexplained above why Alice’s and Bob’s use of ‘there’ denoted the same precise place. On the current conjecture, Alice’s term refers to a particular place x according to P because x is more natural–P than all the other places to which Alice might have referred. If this is so, then x will be more natural–P than all the other places to which Bob might have referred, so it will also be the referent according to P of Bob’s there. Hence according to every precisification, Bob’s utterance will be true, as Schiffer required.\nWe can also explain some other unexplained penumbral connections by appeal to naturalness. Consider the sentence David Chalmers is conscious. Unless this is supertrue, supervaluationism is in trouble. It is vague just which object is denoted by David Chalmers. On every precisification, there are other objects that massively overlap David Chalmers. Indeed, these very objects are denoted by ‘David Chalmers’ on other precisifications. These objects are not conscious, since if one did there would be two conscious objects where, intuitively, there is just one. But each of these rogue objects must be in the extension of ‘conscious’ on the precisifications where it is the denotation of ‘David Chalmers’. So ‘conscious’ must be vague in slightly unexpected ways, and there must be a penumbral connection between it and ‘David Chalmers’: on every precisification, whatever object is denoted by that name is in the extension of ‘conscious’, while no other potential denotata of ‘David Chalmers’ is in the extension. How is this penumbral connection to be explained? Not by appeal to the meanings of the terms! Even if ‘David Chalmers’ has descriptive content, it is highly implausible that this includes being conscious. (After all, unless medicine improves a bit in a thousand years Chalmers will not be conscious.) Rather, this penumbral connection is explained by the fact that the very same thing, naturalness, is used in resolving the vagueness in the terms ‘conscious’ and ‘David Chalmers’. If the precisification makes one particular possible precisification of ‘David Chalmers’, say d1, more natural than another, d2, then it will make properties satisfied by d1­ more natural than those satisfied by d2, so every precisification will make the denotation of ‘David Chalmers’ fall into the extension of ‘conscious’.\nWe can say the same thing about Alice’s original statement: That is where Harold and I first danced the rumba. Since one can’t first dance the rumba with Harold in two different places, it seems Alice’s statement can’t be true relative to more than one precisification of ‘That’. But really the phrase after ‘is’ is also vague, and there is a penumbral connection (via naturalness) between it and the demonstrative. Hence we can say Alice’s statement is supertrue without appealing to any mysterious penumbral connections.\n\n\n0.3 McGee and McLaughlin’s Challenge\nVann McGee and Brian McLaughlin (2000) raise a challenge for supervlauational approaches to the Problem of the Many that uses belief reports in much the way that Schiffer’s problem uses speech reports. They fear that without further development, the supervaluational theory cannot distinguish between the de re and de dicto readings of (4).\n\nRalph believes that there is a snow-capped mountain within sight of the equator.\n\nThey claim, correctly, that (4) should have both a de dicto reading and a de re reading, where in the latter case it is a belief about Kilimanjaro. The problem with the latter case is unclear how Ralph’s belief can be about Kilimanjaro itself. To press the point, they consider an atom at or around the base of Kilimanjaro, called Sparky, and define “Kilimanjaro(+) to be the body of land constituted … by the atoms that make up Kilimanjaro together with Sparky [and] Kilimanjaro(-) [to] be the body of land constituted … by the atoms that make up Kilimanjaro other than Sparky.” (129) The problem with taking (4) to be true on a de re reading is that “there isn’t anything, either in his mental state or in his neural state or in his causal relations with his environment that would make one of Kilimanjaro(+) and Kilimanjaro(-), rather than the other, the thing that Ralph’s belief is about.” (146) So if the truth of (4) on a de re reading requires that Ralph believes a singular, or object-dependent, proposition, about one of Kilimanjaro(+) and Kilimanjaro(-), then (4) cannot be true. Even worse, if the truth of (4) requires that Ralph both that Ralph believes a singular proposition about Kilimanjaro(+), that it is a snow-capped mountain within sight of the equator, and the same proposition about Kilimanjaro(-), then given some knowledge about mountains on Ralph’s part, (4) cannot be true, because that would require Ralph to mistakenly believe there are two mountains located roughly where Kilimanjaro is located.\nWe should not be so easily dissuaded. It is hard to identify exactly which features of Ralph’s “mental state or neural state or causal relations with his environment” that make it the case that he believes that two plus two equals four, but does not believe that two quus two equals four. (I assume Ralph is no philosopher, so lacks the concept QUUS.) I doubt, for example, that the concept PLUS has some causal influence over Ralph that the concept QUUS lacks. But Ralph does have the belief involving PLUS, and not the belief involving QUUS. He has this belief not merely in virtue of his mental or neural states, or his causal interactions with his environment, but in virtue of the fact that PLUS is a more natural concept than QUUS, and hence is more eligible to be a constituent of his belief.\nSo if Kilimanjaro(+) is more natural than Kilimanjaro(-), it will be a constituent of Ralph’s belief, despite the fact that there is no other reason to say his belief is about one rather than the other. Now, in reality Kilimanjaro(+) is no more natural than Kilimanjaro(-). But according to any precisification, one of them will be more natural than the other, for precisifications determine content by determining relative naturalness. Hence if Ralph has a belief with the right structure, in particular a belief with a place for an object (roughly, Kilimanjaro) and the property being within sight of the equator, then on every precisification he has a singular belief that a Kilimanjaro-like mountain is within sight of the equator. And notice that since naturalness determines both mental content and verbal content, on every precisification the constituent of that belief will be the referent of ‘Kilimanjaro’. So even on a de re reading, (4) will be true.\nSchiffer’s problem showed that we should not take precisifications to be defined merely over single sentences. McGee and McLaughlin’s problem shows that we should take precisifications to set the content not just of sentences, but of mental states as well. Precisifications do not just assign precise content to every contentful linguistic token, but to every contentful entity in the world, including beliefs. This makes the issue of penumbral connections that we discussed in section two rather pressing. We already noted the need to establish penumbral connections between separate uses of demonstratives. Now we must establish penumbral connections between words and beliefs. The idea that precisifications determine content by determining relative naturalness establishes these connections.\nTo sum up, McGee and McLaughlin raise three related problems concerning de re belief. Two of these concern belief reports. First, how can we distinguish between de re and de dicto reports? If I am right, we can distinguish between these just the way Russell suggested, by specifying the scope of the quantifiers. McGee and McLaughlin suspect this will not work because in general we cannot argue from (5) to (6), given the vagueness of ‘Kilimanjaro’.\n\nKilimanjaro is such that Ralph believes it to be within sight of the equator.\nThere is a mountain such that Ralph believes it to be within sight of the equator.\n\nWhether or not we want to accept a semantics in which we must restrict existential generalisation in this way as a general rule, we can give an independent argument that (6) is true whenever (4) is true on a de re reading (i.e. whenever (5) is true). The argument is just that on every precisification, the subject of Ralph’s salient singular belief is a mountain, so (6) is true on every precisification. This argument assumes that there is a penumbral connection between the subject of this belief, as we might say the referent of ‘Kilimanjaro’ in his language of thought3, and the word ‘mountain’. But since we have already established that there is such a connection between ‘Kilimanjaro’ in his language of thought and ‘Kilimanjaro’ in public language, and there is obviously a connection between ‘Kilimanjaro’ in public language and the word ‘mountain’, as ‘Kilimanjaro is a mountain’ is supertrue, this assumption is safe. So the second puzzle McGee and McLaughlin raise, how it can be that the relevant de re reports can be true, has also been addressed.\n3 I do not mean here to commit myself to anything like the language of thought hypothesis. This is just being used as a convenient shorthand.4 This is hard, but not perhaps impossible. One might say that on every precisification, Ralph believes a proposition that has a mountain as a constituent, and hence as an essential part.There is a third puzzle McGee and McLaughlin raise that the reader might think I have not addressed. How can it be that Ralph can actually have a de re belief concerning Kilimanjaro? I have so far concentrated on belief reports, not merely on beliefs, and my theory has relied crucially on correlations between the vagueness in these reports and the vagueness in the underlying belief. It might be thought that I have excluded the most interesting case, the one where Ralph has a particular belief with Kilimanjaro itself as a constituent. While I will end up denying Ralph can have such a belief, I doubt this a problematic feature of my view. The theory outlined here denies that Ralph has object–dependent beliefs, but not that he has de re beliefs. I deny that Ralph has a belief that has Kilimanjaro(+) as a constituent, but it is hard to see how Ralph could have such a belief, since it very hard to see how he could have had a belief that has Kilimanjaro(+) rather than Kilimanjaro(-) as its subject. (This was McGee and McLaughlin’s fundamental point.) If we think that having a de re belief implies having a belief whose content is an object–dependent proposition, then we must deny that there are de re beliefs about Kilimanjaro. Since there is no object that is determinately a constituent of the proposition Ralph believes, it is a little hard to maintain that he believes an object–dependent proposition.4 But this is not the only way to make sense of de re beliefs.\nRobin Jeshion has argued that whether a belief is de re depends essentially on its role in cognition. “What distinguishes de re thought is its structural or organisational role in thought” [Jeshion (2002) 67]5 I won’t rehearse Jeshion’s arguments here, just their more interesting conclusions. We can have de re beliefs about an object iff we have a certain kind of mental file folder for the object. This folder need not be generated by acquaintance with the object, so acquiantanceless de re belief is possible. Indeed, the folder could have been created defectively, so there is no object that the information in the folder is about.6 In this case, the contents of the folder are subjectless de re beliefs. Jeshion doesn’t discuss this, but presumably the folder must not have been created purely to be the repository for information about the bearer of a certain property, whoever or whatever that is. We have to rule out this option if we follow Szabó (2000) in thinking the folder metaphor plays a crucial role in explaining our talk and thought involving descriptions. Provided the folder was created with the intent that it record information about some object, rather than merely information about whatever object has a particular property, its contents are de re beliefs. (To allow for distinct folders ‘about’ non-existent objects, we must allow that it is possible that such folders do have their reference fixed by their contents, but as long as this was not the intent in creation these folders can suffice for de re belief. This point lets us distinguish between my folder for Vulcan and my folder for The planet causing the perturbations of Mercury. Both are individuated by the fact that they contain the proposition This causes the perturbations of Mercury. It is this feature of the folder that fixes their reference, or in this case their non-reference. Only in the latter case, however, was this the intent in creating the folder, so its contents are de dicto beliefs, while the contents of the former are de re beliefs.)\n5 I don’t know if Jeshion would accept the corollary that if belief is too unstructured to allow for the possibility of such organisational roles, then there is no de re belief, but I do.6 Which is not just to say that there is no object that has all the properties in the folder. This is neither necessary nor sufficient for the folder to be about the object, as Kripke’s discussion of ‘famous deeds’ descriptivism should make clear.Now we have the resources to show how Ralph can have de re beliefs concerning Kilimanjaro. When Ralph hears about it, or sees it, he opens a file folder for Kilimanjaro. This is not intended to merely be a folder for the mountain he just heard about, or saw. It is intended to be a folder for that. (Imagine here that I am demonstrating the mountain in question.) The Kripkenstein point about referential indeterminacy applies to folders as much as to words. This point is closely related to Kripke’s insistence that his indeterminacy argument does not rely on behaviourism. So if Ralph’s folder is to have a reference, it must be fixed in part by the naturalness of various putative referents. But that is consistent with Ralph’s folder containing de re beliefs, since unless Ralph is a certain odd kind of philosopher, he will not have in his folder that Kilimanjaro is peculiarly eligible to be a referent. So the referent of the folder is not fixed by its contents (as the referent for a folder about The mountain over there, whatever it is, would be, or how the referent for a folder about The natural object over there, whatever it is, would be), and the contents of this folder are still de re beliefs Ralph has about Kilimanjaro. This was a bit roundabout, but we have seen that the Problem of the Many threatens neither the possibility that Ralph is the subject of true de re belief ascriptions, nor that he actually has de re beliefs.\n\n\n0.4 Vague Objects\n\n“I think the principle that to be is to be determinate is a priori, and hence that it is a priori that there is no de re vagueness”. (Jackson 2001, 657–58)\n\nSo do I. I also think there are a few arguments for this claim, though some of them may seem question-begging to the determined defender of indeterminate objects. Most of these arguments I will just mention, since I assume the reader has little desire to see them detailed again. One argument is just that it is obvious that there is no de re vagueness. Such ‘arguments’ are not worthless. The best argument that there are no true contradictions is of just this form, as Priest (1998) shows. And it’s a good argument! Secondly, Russell’s point that most arguments for de re vagueness involve confusing what is represented with its representation still seems fair (Russell 1923). Thirdly, even though the literature on this is a rather large, it still looks like the Evans-Salmon argument against vague identities works, at least under the interpretation David Lewis gives it, and this makes it hard to see how there could be vague objects (Evans 1978; Salmon 1981; Lewis 1988). Fourthly, Mark Heller (1996) argues that we have to allow that referential terms are semantically vague. He says we have to do so to explain context dependence but there are a few other explanatory projects that would do just as well. Since semantic conceptions of vagueness can explain all the data that are commonly taken to support ontological vagueness, it seems theoretically unparsimonious to postulate ontological vagueness too. That’s probably enough, but let me add one more argument to the mix. Accepting that Kilimanjaro is be a vague material object distinct from both Kilimanjaro(+) and Kilimanjaro(-) has either metaphysical or logical costs. To prove this, I derive some rather unpleasant metaphysical conclusions from the assumption that Kilimanjaro is vague. The proofs will use some contentious principles of classical logic, but rejecting those, and hence rejecting classical logic, would be a substantial logical cost. The most contentious such principle used will be an instance of excluded middle: Sparky is or is not a part of Kilimanjaro. I also assume that if for all x other than Sparky that x is a part of y iff it is a part of z, then if Sparky is part of both y and z, or part of neither y nor z, then y and z coincide. If someone can contrive a mereological theory that rejects this principle, it will be immune to these arguments.\nIt is very plausible that material objects are individuated by the materials from which they are composed, so any coincident material objects are identical. Properly understood, that is a good account of what it is to be material. The problem is getting a proper understanding. Sider (1996) interprets it as saying that no two non-identical material objects coincide right now. His project ends up running aground over concerns about sentences involving counting, but his project, of finding a strong interpretation of the principle is intuitively compelling. David (Lewis 1986 Ch. 4) defends a slight weaker version: no two non-identical material objects coincide at all times. Call this the strong composition principle (scp). The scp is (classically) inconsistent with the hypothesis that Kilimanjaro is vague. If Sparky is part of Kilimanjaro, then Kilimanjaro and Kilimanjaro(+) always coincide. If Sparky is not part of Kilimanjaro then Kilimanjaro and Kilimanjaro(-) always coincide. Either way, two non-identical objects always coincide, which the scp does not allow.\nSome think the scp is refuted by Gibbard’s example of Lumpl and Goliath (Gibbard 1975). The most natural response to Gibbard’s example is to weaken our individuation principle again, this time to: no two non-identical material objects coincide in all worlds at all times. Call this the weak compositional principle (wcp). Since there are worlds in which Goliath is composed of bronze, but Lumpl is still a lump of clay in those worlds, Lumpl and Goliath do not refute the wcp. Some may think that even the wcp is too strong7, but most would agree that if vague objects violated the wcp, that would be a reason to believe they don’t exist.\n7 Kit Fine (1994) does exactly this.Given a plausible metaphysical principle, which I call Crossover, vague objects will violate the wcp. As shown above, Kilimanjaro actually (always) coincides with Kilimanjaro(+) or Kilimanjaro(-), but is not identical with either. Crossover is the following principle:\n\nCrossover\n\nFor any actual material objects x and y there is an object z that coincides with x in the actual world and y in all other worlds.\n\n\nGiven that arbitrary fusions exist, Crossover is entailed by, but does not entail, the doctrine of arbitrary modal parts: that for any object o and world w, if o exists in w then o has a part that only exists in w. But Crossover does not have the most surprising consequence of the doctrine of arbitrary modal parts: that for any object o there is an object that has essentially all the properties o actually has.\nLet K1 be the object that coincides with Kilimanjaro in this world and Kilimanjaro(+) in all other worlds. Let K2 be the object that coincides with Kilimanjaro in this world and Kilimanjaro(-) in all other worlds. If Sparky is part of Kilimanjaro then K1 and Kilimanjaro(+) coincide in all worlds, but they are not identical, since it is determinate that Sparky is actually part of Kilimanjaro(+) and not determinate that it is part of K1. If Sparky is not part of Kilimanjaro then K2 and Kilimanjaro(-) coincide in all worlds, but they are not identical, since it is determinate that Sparky is not actually part of Kilimanjaro(-) and not determinate that it is not part of K2. Either way, we have a violation of the wcp. So the following three claims are (classically) inconsistent.\n\nCrossover.\nThe wcp.\nKilimanjaro is a vague object that indeterminately has Sparky as a part.\n\nI think the first two are highly plausible, so accepting (c) is costly. I already noted the plausibility of the wcp, so the focus should be on Crossover. On Lewis’s account of modality, it is clearly true, as is the stronger doctrine of arbitrary modal parts. On a fictionalist theory of modality based on Lewis’s account, it is still true, or at least true in the fiction that we must adopt to make sense of modal talk. So the principle is not without merits. And dialectically, opposing Crossover will be problematic for the believer in vague objects. Either an object’s modal profile is determined by its categorical properties or it isn’t. If it is, then the wcp will entail the scp, so by the above reasoning vague objects will be inconsistent with the wcp. If it is not, then it is hard to see why an object could not have a completely arbitrary modal profile, say the profile of some other ordinary material object. But that means Crossover is true, and again we cannot have both the wcp and vague objects. Probably the best way out for the believer in vague objects will be to short-circuit this reasoning by abandoning classical logic, presumably by declining to endorse the version of excluded middle with which I started. But that is undoubtedly a costly move, particularly for a supervaluationist.\n\n\n0.5 McKinnon on Coins and Precisifications\nMost of our discussions of the Problem of the Many relate to the vagueness in a single singular term, and a single ordinary object. As McKinnon reminds us, however, there is not just one mountain in the world, there are many of them, and supervaluationists are obliged to say plausible things about statements that are about many mountains. Or, to focus on McKinnon’s example, we must not only have a plausible theory of coins, but of coin exhibitions. These do raise distinctive problems. Imagine we have an exhibition with, as we would ordinarily say, 2547 coins, each numbered in the catalogue. So to each number n there correspond millions of coin-like entities, coin*s in Sider’s helpful phrase (Sider 2001), and each precisification assigns a coin* to a number. In general, Sider holds that something is an F* iff it has all the properties necessary and sufficient for being an F except the property of not massively overlapping another F. There are some interesting questions about how independent these assignments can be. If one precisification assigns coin* c1 to n1, and another assigns coin* c2 to n2 (distinct from n1) then is there a guaranteed to be a precisification that assigns both c1 to n1 and c2 to n2? In other words, may the precisifications of each numeral (construed as a coin denotation) be independent of each other? The following example suggests not. Say Cj is the set of coin*s that are possible precisifications of j. This set may be vague because of higher–order vagueness, but set those difficulties aside. If every member of C1728 has a duplicate in C1729, then presumably only precisifications that assigned duplicates to ‘1728’ and ‘1729’ would be admissible. If the exhibition has two Edward I pennies on display to show the obverse and reverse, and miraculously these coins are duplicates, such a situation will arise.\nThis case is fanciful, so we don’t know whether in reality the precisifications of the numerals are independent. We probably can’t answer this question, but this is no major concern. McKinnon has found a question which the supervaluationist should feel a need to answer, but to which neither answer seems appropriate. Say that a precisification is principled iff there is some not-too-disjunctive property F such that for each numeral n, the precisification assigns to n the F-est coin* in Cn. If F does not come in degrees, then the precisification assigns to n the F in Cn. McKinnon’s question to the supervaluationist is: Are all precisifications principled? He aims to show either answering ‘yes’ or ‘no’ gets the supervaluationist in trouble. ‘Yes’ leads to there being too few precisifications; ‘No’ leads to there being too many. Let us look at these in order.\nI have little to say for now on the first horn of this dilemma. McKinnon’s survey of principled precisifications only considers cases where F is intrinsic, and I postpone for now investigation of extrinsic principles. Nevertheless, he does show that if F must be intrinsic, then there are not enough principled precisifications to generate all the indeterminacy our coin exhibit intuitively displays. The other horn is trickier.\nA precisification must not only assign a plausible coin* to each numeral, it must do so in such a way that respects penumbral connections. McKinnon thinks that unprincipled, or arbitrary precisifications, will violate (NAD) and (NAS).\n\nNon-Arbitrary Differences (NAD)\n\nFor any coin and non-coin, there is a principled difference between them which forms the basis for one being a coin and the other being a non-coin.\n\nNon-Arbitrary Similarities (NAS)\n\nFor any pair of coins, there is a principled similarity between them which forms the basis for their both being coins.\n\n\nMcKinnon holds these are true, so they should be true on all precisifications, but they are not true on unprincipled precisifications, so unprincipled precisifications are unacceptable. The motivation for (NAD) and (NAS) is clear. When we list the fundamental properties of the universe, we will not include being a coin. Coinness doesn’t go that deep. So if some things are coins, they must be so in virtue of their other properties. From this (NAD) and (NAS) follow.\nThe last step looks dubious. Consider any coin, for definiteness say the referent of ‘1728’, and a coin* that massively overlaps it. The coin* is not a coin, so (a) one of these is a coin and the other is not, and (b) the minute differences between them cannot form the basis for a distinction between coins and non-coins. Hence (NAD) and (NAS) fail. At best, it seems, we can justify the following claims. If something is a coin* and something else is not, then there is a principled difference between them that makes one of them a coin* and the other not. Something is a coin iff it is a coin* that does not excessively overlap a coin. If this is the best we can do at defining ‘coin’, then the prospects for a reductive physicalism about coins might look a little dim, though this is no threat to a physicalism about coins that stays neutral on the question of reduction. (I trust no reader is an anti-physicalist about coins, but it is worth noting how vexing questions of reduction can get even when questions of physicalism are settled.)\nSo I think this example refutes (NAD) and (NAS). Do I beg some questions here? Well, my counterexample turns crucially on the existence of kinds of objects, massively overlapping coin*s, that some people reject, and indeed that some find the most objectionable aspect of the supervaluationist solution. But this gets the burden of proof the wrong way around. I was not trying to refute (NAD) and (NAS). I just aimed to parry an argument based on those principles. I am allowed to appeal to aspects of my theory in doing so without begging questions. I do not want to rest too much weight on this point, however, for issues to do with who bears the burden of proof are rarely easily resolved, so let us move on.\nMy main response to McKinnon’s dilemma is another dilemma. If the principled similarities and differences in (NAD) and (NAS) must be intrinsic properties, then those principles are false, because there is no principled intrinsic difference between a coin and a token, or a coin and a medal. If the principled similarities and differences in (NAD) and (NAS) may be extrinsic properties, then those principles may be true, but then the argument that there are not enough principled precisifications fail, since now we must consider precisifications based on extrinsic principles. Let’s look at the two halves of that dilemma in detail, in order.\nA subway token is not a coin. Nor is a medal.8 But in their intrinsic respects, subway tokens often resemble certain coins more than some coins resemble other coins. Imagine we had a Boston subway token (which looks a bit like an American penny, but larger), an American penny, a British 20p piece (which is roughly heptagonal) and an early Australian holey dollar (which has a hole in it). There is no non-disjunctive classification of these by intrinsic properties that includes the penny, the 20p piece and the holey dollar in one group, and the subway token in the other. Any group that includes the penny and the other coins will include the token as well. So if we restrict attention to intrinsic similarities and differences, (NAD) and (NAS) are false.\n8 Some people I have asked think tokens are coins, but no one thinks medals are coins, so if you (mistakenly) think tokens are coins, imagine all my subsequent arguments are phrased using medals rather than tokens.9 Note that I say little here about what the intent of the creator must be. I don’t think that the intent must always be to create legal tender. A ceremonial coin that is created, for example, to be tossed before the start of a sporting match is still a coin, although it is not intended to be tender. But intent still matters. If someone had made a duplicate of that ceremonial coin with the intent of awarding it as a medal to the victorious captain, it would be a medal and not a coin.10 Because of the problems raised in the previous footnote, I will not try and say just what this intention amounts to. There are complications when (a) the creator is a corporate entity rather than an individual and (b) the coins are mass–produced rather than produced individually. But since the story is essentially the same, I leave the gruesome details out here.There is a difference between these coins and the subway token. The coins were produced with the intent of being legal tender, the token was not. Perhaps we can find a difference between coins and non-coins based on the intent of their creator.9 This might make (NAD) and (NAS) true. But note that given the theory of precisifications developed in section 3, on every precisification, one and only one of the precisifications of ‘1728’ will be the subject of an intention on the part of its manufacturer. Just which of the objects is the subject of this intent will vary from precisification to precisification, but there is only one on every precisification. So we can say that on every precisification, the coin is the one where the intent of its creator was that it be used in a certain way. Indeed, on any precisification we may have antecedently thought to have existed, we can show that precisification to be principled by taking F to be the property being created with intent of being used in a coin-like way.10 So now we can say that restricting attention to the principled precisifications does not unduly delimit the class of precisifications.\nLet’s sum up. To argue against the possibility of unprincipled precisifications, McKinnon needed to justify (NAD) and (NAS). But these are only true when we allow ‘principled differences’ to include differences in creatorial intent. And if we do that we can see that every prima facie admissible precisification is principled, so we can give an affirmative answer to McKinnon’s question.\nIt might be objected that this move relies heavily on the fact that for many artefacts creative intent is constitutive of being the kind of thing that it is. But a Problem of the Many does not arise only for artefacts, so my solution does not generalise. This is little reason for concern since McKinnon’s problem does not generalise either. (NAD) and (NAS) are clearly false when we substitute ‘mountain’ for ‘coin’. Consider a fairly typical case where it is indeterminate whether we have one mountain or two.11 In this case it might be not clear whether, for example, we have one mountain with a southern and a northern peak, or two mountains, one of them a little north of the other. Whether there is one mountain here or two, clearly the two peaks exist, and their fusion exists too. The real question is which of these three things is a mountain. However this question is resolved, a substitution instance of (NAD) with the two objects being the southern peak and the fusion of the two peaks will be false. So in this case a relatively unprincipled precisification will be acceptable. The point here is that mountain*s that are not mountains exist (either the peaks or their fusion will do as examples), and that suffices to refute McKinnon’s alleged penumbral connections and allow, in this case, a negative answer to his question.\n11 This case is rather important in the history of the problem, because its discussion in Quine (1960) is one of the earliest presentations in print of anything like the problem of the many.\n\n0.6 Sorensen on Direct Reference\nAccording to orthodoxy, we can use descriptions to determine the reference of names without those descriptions becoming part of the meaning of the name. This, apparently, is what happened when Leverrier introduced ‘Neptune’ to name, not merely describe, the planet causing certain perturbations, and when someone introduced ‘Jack the Ripper’ to name, not merely describe, the person performing certain murders. So let us introduce ‘Acme’ as the name for the first tributary of the river Enigma. As Sorensen suggests, this can create certain problems.\n\nWhen [explorers] first travel up the river Enigma they finally reach the first pair of river branches. They name one branch ‘Sumo’ and the other ‘Wilt’. Sumo is shorter but more voluminous than Wilt. This makes Sumo and Wilt borderline cases of ‘tributary’ … ‘Acme’ definitely refers to something, even though it is vague whether it refers to Sumo and vague whether it refers to Wilt. (Sorensen 2000, 180)\n\nIf ‘Acme’, ‘Sumo’ and ‘Wilt’ are all vague names related in this way, Sorensen thinks the supervaluationist has a problem. The sentences ‘Acme is Sumo’ and ‘Acme is Wilt’ both express propositions of the form \\(\\langle x = y \\rangle\\). For exactly one of them, x is y. Since the proposition contains just the objects x and y (and the identity relation) but not their route into the proposition, there is no vagueness in the proposition. Hence there is no way to precisify either proposition. So a supervaluationist cannot explain how these propositions are vague.\nThis is no problem for supervaluationism, since supervaluationism says that sentences, not propositions, are vague. Indeed, most supervaluationists would say that no proposition is ever vague. Thinking they are vague is just another instance of the fallacy Russell identified: attributing properties of the representation to the entity, in this case a proposition, represented.\nBut maybe there is a problem in the area. One natural way of spelling out the idea that names directly refer to objects is to say that the meaning of a name is its referent. And one quite plausible principle about precisifications is that precisifications must not change the meaning of a term, they may merely provide a meaning where none exists. Now the supervaluationist has a problem. For it is true that one of Sorensen’s identity sentences is true in virtue of its meaning, since its meaning determines that it expresses a proposition of the form \\(\\langle x = x \\rangle\\). But each sentence is false on some precisifications, so some precisifications change the meaning of the terms involved.\nThe best way to respond to this objection is simply to bite the bullet. We can accept that some precisifications alter meanings provided we can provide some other criteria for acceptability of precisifications. I offered one such proposal in section 2. An acceptable precisification takes the partial order more natural than, turns it into a complete order without changing any of the relations that already exist, and uses this new relation to generate meanings. If we proceed in this way it is possible, for all we have hitherto said, that on every precisification the proposition expressed by ‘Acme is Sumo’ will be of the form \\(\\langle x = y \\rangle\\), so just the named object, rather than the method of naming, gets into the proposition. The central point is that since precisifications apply to the processes that turn semantic intentions into meanings, rather than to sentences with meanings, there is no guarantee they will preserve meanings. But if we like directly referential theories of names we should think this perfectly natural. If names are directly referential then Sorensen’s argument that there are vague sentences that are true in virtue of their meaning works. But this is consistent with supervaluationism.\nOne challenge remains. If precisifications change meanings, why should we care about them, or about what is true on all of them? This is not a new challenge; it is a central plank in Jerry Fodor and Ernest Lepore’s (1996) attack on supervaluationism. A simple response is just to say that we should care about precisifications because this method delivers the right results in all core cases, and an intuitively plausible set of results in contentious cases. This kind of instrumentalism about the foundations of a theory is not always satisfying.12 But if that’s the biggest problem supervaluationists have, they should be able to sleep a lot easier than the rest of us.\n12 The largest debate in the history of philosophy of economics concerned whether we could, or should, be instrumentalists about the ideally rational agents at the core of mainstream microeconomic theory. See Friedman (1953) for the classic statement of the instrumentalist position, and Hausman (1992) for the most amusing and enlightening of the countably many responses.\n\n0.7 Conclusions and Confessions\nI have spent a fair bit of time arguing that supervaluationism is not vulnerable to a few challenges based on the Problem of the Many. Despite doing all this, I don’t believe supervaluationism to be quite true. So why spend this time? Because the true theory of vagueness will be a classical semantic theory, and everything I say about supervaluationism above applies mutatis mutandis to all classical semantic theories. I focussed on supervaluationism because it is more familiar and more popular, but I need not have.\nWhat is a classical semantic theory? That’s easy - it’s a theory that is both classical and semantic. What is a classical theory? It is one that incorporates vagueness while preserving classical logic. How much of classical logic must we preserve? That’s a hard question, though it is relevant to determining whether supervaluationism is (as it is often advertised) a classical theory. Williamson (1994) notes that supervaluationism does not preserve classical inference rules, and Hyde (1997) notes that it does not preserve some classically valid multiple–conclusion sequents. Keefe (2000) argues that neither of these constitutes an important deviation from classical logic. I’m inclined to disagree with Keefe on both points. Following Read (2000), I take it that the best response to the anti-classical arguments in Dummett (1991) takes the essential features of classical logic to be its inferential rules as formulated in a multiple–conclusion logic. But we need not adjudicate this dispute here. Why should we want a classical theory? The usual arguments for it are based on epistemic conservatism, and I think these arguments are fairly compelling. I also think that no non–classical theory will be able to provide a plausible account of quantification.13\n13 See the last section of Weatherson (2005) for a detailed defence of this claim.What is a semantic theory? It is one that makes vagueness a semantic phenomenon. It is not necessarily one that makes vagueness a linguistic phenomenon. That would be absurd in any case, since clearly some non–linguistic entities, maps, beliefs and pictures for example, are vague. But the more general idea that vagueness is a property only of representations is quite attractive. It links up well with the theory of content Lewis outlines in “Languages and Language” - all Languages (in his technical sense) are precise, vagueness in natural language is a result of indecision about which Language we are speaking.\nTrenton Merricks (2001) argues against this picture, claiming that all semantic vagueness (he says ‘linguistic’, but ignore that) must arise because of metaphysical or epistemic vagueness. He claims that if (17) is vague, then so is (18), and (18)’s vagueness must be either metaphysical or semantic.\n\nHarry is bald.\n‘Bald’ describes Harry.\n\nOne might question the inference from (17)‘s vagueness to (18) - on some supervaluational theories if (17) is vague then (18) is false. But I will let that pass, for there is a simpler problem in the argument. Merricks claims that if (18) is vague, then it is vague whether ’Bald’ has the property describing Harry, and this is a kind of metaphysical vagueness. It is hard to see how this follows. If there is metaphysical vagueness, there is presumably some object o and some property F such that it is vague whether the object has the property. Presumably the object here is the word ‘bald’ and the property is describing Harry. But words alone do not have properties like describing Harry. At best, words in languages do so. So maybe the object can be the ordered pair \\(\\langle \\text{`Bald'}, l \\rangle\\), where l is a language. But which one? Not one of Lewis’s Languages, for then it is determinate whether &lt;‘Bald’, l&gt; has the property describing Harry. So maybe a natural language, perhaps English! But it is doubly unclear that English is an object. First, it is unclear whether we should reify natural languages to such a degree that we accept that ‘English’ refers to anything at all. Secondly, if we say ‘English’ does refer, why not say that it refers to one of Lewis’s Languages, thought it is vague which one? That way we can say that the sentence ‘Bald’ in English describes Harry is vague without there being any object that vaguely instantiates a property. Now on a supervaluational theory this approach may have the unwanted consequence that “English is a precise language” is true, since it is true on all precisifications. It does not seem that this problem for the supervaluationist generalises to be a problem for all semantic theories of vagueness, so Merricks has raised no general problem for semantic theories of vagueness. (The problem for the supervaluationist here is not new. For some discussion see Lewis’s response, in “Many, but Almost One” to the objection, there attributed to Kripke, that the supervaluationist account makes it true that all words are precise.)\nIf we have a classical semantic theory that provides a concept of determinateness, then we can define acceptable precisifications as maximal consistent extensions of the set of determinate truths. Given that, it follows pretty quickly that determinate truth implies truth on all precisifications. And this is sufficient for the major objections canvassed above to get a foothold, and hence be worthy of response, though as we have seen none of them will ultimately succeed. Still, our theory may differ from supervaluationism in many ways. For one thing, it might explain determinateness in ways quite different from those in supervaluationism. For example, the theory in Field (2000) is a classical semantic theory14, but it clearly goes beyond supervaluational theory because it has an interesting, if ultimately flawed, explanation of determinateness in terms of Shafer functions. Other classical semantic theories may differ from supervaluationism by providing distinctive theories of higher order vagueness.\n14 At least, it strikes me as a classical semantic theory. Ryan Wasserman has tried to convince me that properly understood, it is really an epistemic theory. Space prevents a thorough account of why I think Field’s theory is flawed. Briefly, I think the point in Leeds (2000) that Field’s concept of a numerical degree of belief needs substantially more explanation than Field gives it can be developed into a conclusive refutation.The most promising research programs in vagueness are within the classical semantic framework. Like all research programs, these programs need a defensive component, to fend off potential refutations and crisis. This avoids unwanted crises in the program, and as we have seen here we can learn a bit from seeing how to defend against certain attacks. There will undoubtedly be more challenges in the time ahead, but for now the moves in this paper brings the defensive side of the program up to date.\n\n\n\n\n\n\nReferences\n\nDummett, Michael. 1991. The Logical Basis of Metaphysics.Cambridge, MA: Harvard.\n\n\nEvans, Gareth. 1978. “Can There Be Vague Objects?” Analysis 38 (4): 208. https://doi.org/10.1093/analys/38.4.208.\n\n\nField, Hartry. 2000. “Indeterminacy, Degree of Belief, and Excluded Middle.” Noûs 34 (1): 1–30. https://doi.org/10.1111/0029-4624.00200.\n\n\nFine, Kit. 1994. “Compounds and Aggregates.” Noûs 28 (2): 137–58. https://doi.org/10.2307/2216046.\n\n\nFodor, Jerry A., and Ernest Lepore. 1996. “What Cannot Be Valuated Cannot Be Valuated, and It Cannot Be Supervaluated Either.” Journal of Philosophy 93 (10): 516–35. https://doi.org/10.5840/jphil1996931013.\n\n\nFriedman, Milton. 1953. “The Methodology of Positive Economics.” In Essays in Positive Economics, 3–43. Chicago: University of Chicago Press.\n\n\nGibbard, Allan. 1975. “Contingent Identity.” Journal of Philosophical Logic 4 (2): 187–221. https://doi.org/10.1007/bf00693273.\n\n\nHausman, Daniel. 1992. “Why Look Under the Hood?” In Essays in Philosophy and Economic Methodology, 70–73. Cambridge: Cambridge University Press.\n\n\nHeller, Mark. 1996. “Against Metaphysical Vagueness.” Philosophical Perspectives 10: 177–85. https://doi.org/10.2307/2216242.\n\n\nHyde, Dominic. 1997. “From Heaps and Gaps to Heaps of Gluts.” Mind 106 (424): 641–60. https://doi.org/10.1093/mind/106.424.641.\n\n\nJackson, Frank. 2001. “Responses.” Philosophy and Phenomenological Research 62 (3): 653–64. https://doi.org/10.2307/2653545.\n\n\nJeshion, Robin. 2002. “Acquiantanceless de Re Belief’.” In Meaning and Truth: Investigations in Philosophical Semantics, edited by Joseph Keim Campbell, Michael O’Rourke, and David Shier, 53–74. New York: Seven Bridges Press.\n\n\nKeefe, Rosanna. 2000. Theories of Vagueness. Cambridge: Cambridge University Press.\n\n\nKripke, Saul. 1980. Naming and Necessity. Cambridge: Harvard University Press.\n\n\n———. 1982. Wittgenstein on Rules and Private Language. Oxford: Basil Blackwell.\n\n\nLeeds, Stephen. 2000. “A Disquotationalist Looks at Vagueness.” Philosophical Topics 28 (1): 107–28. https://doi.org/10.5840/philtopics200028119.\n\n\nLewis, David. 1983. “New Work for a Theory of Universals.” Australasian Journal of Philosophy 61 (4): 343–77. https://doi.org/10.1080/00048408312341131.\n\n\n———. 1984. “Devil’s Bargains and the Real World.” In The Security Gamble: Deterrence in the Nuclear Age, edited by Douglas Maclean, 141–54. Totowa, NJ: Rowman; Allenheld.\n\n\n———. 1986. On the Plurality of Worlds. Oxford: Blackwell Publishers.\n\n\n———. 1988. “Vague Identity: Evans Misunderstood.” Analysis 48 (3): 128–30. https://doi.org/10.1093/analys/48.3.128.\n\n\nMcGee, Vann, and Brian McLaughlin. 2000. “The Lessons of the Many.” Philosophical Topics 28 (1): 129–51. https://doi.org/10.5840/philtopics200028120.\n\n\nMerricks, Trenton. 2001. “Varieties of Vagueness.” Philosophy and Phenomenological Research 62 (1): 145–57. https://doi.org/10.2307/2653593.\n\n\nPriest, Graham. 1998. “What Is so Bad about Contradictions?” Journal of Philosophy 95 (8): 410–26. https://doi.org/10.2307/2564636.\n\n\nPutnam, Hilary. 1973. “Meaning and Reference.” Journal of Philosophy 70 (19): 699–711. https://doi.org/10.2307/2025079.\n\n\n———. 1980. “Models and Reality.” Journal of Symbolic Logic 45 (3): 464–82. https://doi.org/10.2307/2273415.\n\n\nQuine, W. V. O. 1960. Word and Object. Cambridge, MA.: MIT Press.\n\n\nRussell, Bertrand. 1923. “Vagueness.” Australasian Journal of Philosophy and Psychology 1 (2): 84–92. https://doi.org/10.1080/00048402308540623.\n\n\nSalmon, Nathan. 1981. Reference and Essence. Princeton: Princeton University Press.\n\n\nSchiffer, Stephen. 2000. “Replies.” Philosophical Issues 10 (1): 320–43. https://doi.org/10.1111/j.1758-2237.2000.tb00029.x.\n\n\nSider, Theodore. 1996. “All the World’s a Stage.” Australasian Journal of Philosophy 74 (3): 433–53. https://doi.org/10.1080/00048409612347421.\n\n\n———. 2001. “Maximality and Intrinsic Properties.” Philosophy and Phenomenological Research 63 (2): 357–64. https://doi.org/10.1111/j.1933-1592.2001.tb00109.x.\n\n\nSorensen, Roy. 2000. “Direct Reference and Vague Identity.” Philosophical Topics 28 (1): 177–94. https://doi.org/10.5840/philtopics200028123.\n\n\nSzabó, Zoltan Gendler. 2000. “Descriptions and Uniqueness.” Philosophical Studies 101 (1): 29–57. https://doi.org/10.1023/A:1026437211756.\n\n\nWeatherson, Brian. 2005. “True, Truer, Truest.” Philosophical Studies 123 (1-2): 47–70. https://doi.org/10.1007/s11098-004-5218-x.\n\n\nWilliamson, Timothy. 1994. Vagueness. Routledge."
  },
  {
    "objectID": "posts/deliberation/deliberation-costs.html",
    "href": "posts/deliberation/deliberation-costs.html",
    "title": "Deliberation Costs",
    "section": "",
    "text": "Humans making decisions face two big limitations. First, we are informationally limited. We don’t know everything and sometimes we don’t know what we need to know in order to make the optimal decision. Second, we are computationally limited. We can’t process all of the information that we have available to us before a decision needs to be made. Or at least, we can’t do this in a costless manner.\n\nUnpublished draft. Thanks to audiences at Michigan, Toronto, and the Arizona Philosophy Workshop for valuable feedback, not all of which I’ve yet incorporated.\n\nOrthodox decision theory treats these two limitations very differently. To a first approximation, the whole point of orthodox decision theory is to handle the question of how to make decisions without full information. But on the other hand, orthodox decision theory simply assumes away the computational limitations. Orthodox decision theory is a theory of rational choice, and rationality is here understood to involve not being subject to these pesky computational limitations.\n\nPicture by Andy Warhol via Creative Commons.\n\nI think this is a serious mistake. In particular, I think there are several cases where our theory of rational choice can only give us the correct verdict if we allow it to be sensitive to both kinds of limitation. In this paper, I will discuss three such kinds of cases, and describe how rational choice theory might be revised so as to handle them.\nI’m far from the first to notice this asymmetry in how orthodox decision theory handles the two limitations. For approximately as long as decision theory has existed, there have been people who have noted the oddity of ignoring computational limitations. But there has always been a powerful argument against taking computational limitations seriously. It is long been thought that attempt to do this would lead to a nasty kind of regress. It isn’t entirely clear how the regress argument here is supposed to run; the argument is more often alluded to than carefully stated. But it is a major challenge and I will have something to say about it.\nThe short version of what I’m going to say is that while we should take both kinds of limitations seriously, we should treat them differently in our final theory. We should, as orthodox decision theory says, take a broadly evidentialist approach to informational limitations. That is, good decision makers should have credence distributions over the possibilities left open by their evidence, those credences should be sensitive to the evidence they have, and the choices they make should maximize expected value given those credences. On the other hand, we should take a broadly reliabilist approach to computational limitations. Good decision makers will adopt procedures for managing their own limitations that reliably produce good outcomes. There is no requirement that they adopt the procedures that are best supported by their evidence. The reason there is no requirement they do that is that figuring out what those reliable procedures might be is even more computationally taxing then the problem of deciding what to do. And if we’re going to respect the fact that people can’t always complete difficult computational tasks, we shouldn’t expect them to perform the incredibly difficult task of figuring out how to adjust their decision procedures in light of the evidence about their own limitations.\nYou might think that the reason orthodox theory treats computational limitations this way is that it is simply trying to provide a theory of ideal decision making. There is a separate question, to be sure, of how non-ideal agents should make decisions. But the thought, or at least the hope, is that clearly stating what the ideal looks like will help the non-ideal agents in this task. I think there is a little reason to believe that this hope will be realized. In general, knowing what the ideal looks like provides us with very little guidance as to how to get better. Knowing that any ideal outcome has a certain attribute does not provide a reason, even a defeasible reason, for trying to to acquire that attribute (Lipsey and Lancaster 1956).\nWe can see this by simply thinking about the one limitation that orthodox theory does take seriously. A good decision maker without full information will in general behave nothing like a good decision maker with full information. For example, if you put the informationally limited agent in a casino they will do the exact opposite of what an informationally unlimited agent will do. The informationally unlimited agent will play every game and do quite well at them. The informationally limited agent, on the other hand, will play none of the games because they all have negative expected returns. I think is the general case. It’s a bad idea to emulate the ideal agent, because us non ideal agents often have to act so as to minimize the damage that have other limitations can do. Everyone agrees that is true in the case of informational limitations, and I am going to try and argue that it’s also true for computational limitations.\nSo here’s the plan for the paper. First, in sections 1-2, I will introduce the three kinds of cases but I think motivate taking computational limitations seriously. Then, in sections 3-4, I will introduce the regress argument that is alleged to show that any attempt to do this will end badly. In sections 5-6, I will show how the broadly reliabilist approach to handling computational limitations that I favor can be motivated, and can avoid the regress. Sections 7 and 8 are contingent speculations about how non-ideal agents might choose reliably, and observations on how these debates connect to other philosophical debates\nBefore I start on this, it’s helpful to get clear on exactly what I am taking my orthodox opponent to be committed to. I take them to endorse the following three constraints on a theory of rational choice.\n\nRational agents have credences, and these credences are responsive to evidence.\nThese credences also respect the probability calculus.\nRational agents take actions that maximize their expected utility given these credences.\n\nThere are a lot of questions that I do not take my orthodox opponent to have a settled view on, though of course many orthodox theorists will have one view or another on one or other of these questions. These questions include\n\nWhether rationality puts any constraints on what can be valued;\nWhether our theory of rationality divides up failures to make rational choices into epistemic failures, axiological failures, and practical failures, and if it does make such a division, exactly how it should be made;\nWhether rationality requires that agent be self-aware, i.e., whether they know what their own credences and utilities are; and\nExactly what evidence is, or what it means for credences to be responsive to evidence.\n\nMy hope is that I can provide an objection to orthodoxy that is insensitive to how orthodox theorists answered these questions. That’s a rather ambitious project, since the answers one gives to these questions will help provide responses to some of the objections I shall offer. But I’m not going to try to anticipate every possible response the orthodox theorist could make. Indeed, I don’t think that I’ve got anything like a knock down watertight argument against all possible versions of orthodoxy. What I think I do have is a set of reasons to consider an alternative, and an outline of what that alternative may look like.\n\n1 Three Puzzles\n\n1.0.1 Puzzle One - Close Calls\nLet’s start with an example from a great thinker. It will require a little exegesis, but that’s not unusual when using classic texts.\n\nWell Frankie Lee and Judas Priest\nThey were the best of friends\nSo when Frankie Lee needed money one day\nJudas quickly pulled out a roll of tens\nAnd placed them on the footstool\nJust above the potted plain\nSaying “Take your pick, Frankie boy,\nMy loss will be your gain.”\n          (“The Ballad of Frankie Lee and Judas Priest”, 1968.\n           Lyrics from Bob Dylan (2016) 225)\n\nOn a common reading of this, Judas Priest isn’t just asking Frankie Lee how much money he wants to take, but which invididual notes. Let’s simplify, and say that it is common ground that Frankie should only take $10, so the choice Frankie Lee has is which of the individual notes he will take. This will be enough to set up the puzzle.\nAssume something else that isn’t in the text, but which isn’t an implausible addition to the story. The world Frankie Lee and Judas Priest live in is not completely free of counterfeit notes. And it would be bad for Frankie Lee to take a counterfeit note. It won’t matter just how common these notes are, or how bad it would be. But our puzzle will be most vivid if each of these are relatively small quantities. So there aren’t that many counterfeit notes in circulation, and the (expected) disutility to Frankie Lee of having one of them is not great. There is some chance that he will get in trouble, but the chance isn’t high, and the trouble isn’t any worse than he’s suffered before. Still, other things exactly equal, Frankie Lee would prefer a genuine note to a counterfeit one.\nNow for some terminology to help us state the problem Frankie Lee is in. Assume there are \\(k\\) notes on the footstool. Call them \\(n_1, \\dots, n_k\\). Let \\(c_i\\) be the proposition that note \\(n_i\\) is counterfeit, and its negation \\(g_i\\) be that it is genuine. And let \\(t_i\\) be the act of taking note \\(n_i\\). Let \\(U\\) be Frankie Lee’s utility function, and \\(Cr\\) his credence function.\nIn our first version of the example, we’ll make two more assumptions. Apart from the issue of whether the note is real or counterfeit, Frankie Lee is indifferent between the notes, so for some \\(h, l\\), \\(U(t_i | g_i) = h\\) and \\(U(t_i | c_i) = l\\) for all \\(i\\), with of course \\(h &gt; l\\). If we add an extra assumption that Frankie Lee thinks the probability that each of the notes is genuine is the same, we get the intuitive result back that he is indifferent between the banknotes.\nBut is that really a plausible move? Here is one way to start worrying about it. Change the example so that the country Frankie Lee and Judas Priest live in is very slowly modernising its currency. It is getting rid of old fashioned, and somewhat easy to counterfeit, paper money, and joining the civilised countries that use plastic money. Moreover, plastic bank notes are, for all intents and purposes, impossible to counterfeit. (At least, no one has yet figured out how to do it, and Frankie Lee knows this.)\nSome of the notes Judas Priest offers are the new plastic notes, and some are the old paper notes. Now it seems clear that Frankie Lee should take one of the new notes, and not merely on aesthetic grounds. Rather, the fact that the plastic notes are less likely to be counterfeit is a reason to prefer to take them. And this is true no matter how unlikely it is that the paper notes are counterfeit, as long as this likelihood is non-zero.\nBut now go back to the base case, where all the money is paper. A small change in probability of being counterfeit seems to be enough to give Frankie Lee a reason to prefer some of them to the others. Indeed, the only way for him to be indifferent between the notes is if the probability of any one being counterfeit is exactly the same as the probability of any other being counterfeit. But that two of the notes have exactly the same probability of being counterfeit is a measure zero event. It isn’t happening. So Frankie Lee shouldn’t be indifferent between the notes.\nOf course, if the notes look exactly the same, then the probability that each is counterfeit is exactly the same. But that’s only because that probability is one. In that case Frankie Lee should run away as fast as possible. That’s not the realistic case.\nThe realistic case is that the notes look a little different to each other in ever so many respects. (Including, one hopes, their serial numbers.) Some will be a little more faded, or a little more torn, or a little more smudged or crumpled, than the others. It is overwhelmingly likely that these fades, tears, smudges, spills etc are the result of the normal wear and tear on the currency - wear and tear that paper notes tend to wear on their face. But every imperfection in every note is some evidence, very very marginal evidence but still evidence, that the note is counterfeit. And since Frankie Lee’s evidence, on any extant theory of evidence, includes visible things like the tears, smudges etc on the notes, they are pieces of evidence that affect the evidential expected utility of taking each note. So if Frankie Lee wants to maximize evidential expected utility, there is precisely one note he should take. Though it probably won’t be obvious to him which one it is, so rationality requires Frankie Lee to spend some time thinking about which note is best.\nThis is intuitively the wrong result. (Though it is what happens in the song.) Frankie Lee should just make a choice more or less arbitrarily. Since expected utility theory does not say this, expected utility theory is wrong.\nThe Frankie Lee and Judas Priest case is weird. Who offers someone money, then asks them to pick which note to take? And intuitions about such weird cases cases are sometimes deprecated. Perhaps the contrivance doesn’t reveal deep problems with a philosophical theory, but merely a quirk of our intuitions. I am not going to take a stand on any big questions about the epistemology of intuitions here. Rather, I’m going to note that cases with the same structure as the story of Frankie Lee and Judas Priest are incredibly common in the real world. Thinking about the real world examples can both show us how pressing the problems are, and eventually show us a way out of those problems.\nSo let’s leave Frankie Lee for now, just above the potted plain, and think about a new character. We will call this one David, and he is buying a few groceries on the way home from work. In particular, he has to buy a can of chickpeas, a bottle of milk, and a carton of eggs. To make life easy, we’ll assume each of these cost the same amount: five dollars.1 None of these purchases is entirely risk free. Canned goods are pretty safe, but sometimes they go bad. Milk is normally removed from sale when it goes sour, but not always. And eggs can crack, either in transit or just on the shelf. In David’s world, just like ours, each of these risks is greater than the one that came before.\n1 If that sounds implausible to you, make the can/bottle/carton a different size, or change the currency to some other dollars than the one you’re instinctively using. But I think this examples works tolerably well when understand as involving, for example, East Carribean dollars.David has a favorite brand of chickpeas, of milk, and of eggs. And he knows where in the store they are located. So his shopping is pretty easy. But it isn’t completely straightforward. First he gets the chickpeas. And that’s simple; he grabs the nearest can, and unless it is badly dented, or leaking, he puts in in his basket. Next he goes onto the milk. The milk bottles have sell-by dates printed in big letters on the front. And David checks that he isn’t picking up one that is about to expire. His store has been known to have adjacent bottles of milk with sell-by dates 10 days apart, so it’s worth checking. But as long as the date is far enough in the future, he takes it and moves on. Finally, he comes to the eggs. (Nothing so alike as eggs, he always thinks to himself.) Here he has to do a little more work. He takes the first carton, opens it to see there are no cracks on the top of the eggs, and, finding none, puts that in his basket too. He knows some of his friends do more than this; flipping the carton over to check for cracks underneath. But the one time he tried that, the eggs ended up on the floor. And he knows some of his friends do less; just picking up the carton by the underside, and only checking for cracks if the underside is sticky where the eggs have leaked. He thinks that makes sense too, but he is a little paranoid, and likes visual confirmation of what he’s getting. All done, he heads to the checkout, pays his $15, and goes home.\nThe choice David faces when getting the chickpeas is like the choice Frankie Lee faces. He has to choose from among a bunch of very similar seeming options. In at least the chickpeas example, he should just pick arbitrarily. But for very similar reasons to Frankie Lee, expected utility theory won’t say that.\nThe standard model of practical rationality that we use in philosophy is that of expected utility maximization. But there are both theoretical and experimental reasons to think that this is not the right model for choices such as that faced by Frankie or David. maximizing expected utility is resource intensive, especially in contexts like a modern supermarket, and the returns on this resource expenditure are unimpressive. What people mostly do, and what they should do, is choose in a way that is sensitive to the costs of adopting one or other way.\nThere are two annoying terminological issues around here that I mostly want to set aside, but need to briefly address in order to forestall confusion.\nI’m going to assume maximizing expected utility means taking the option with the highest expected utility given facts that are readily available. So if one simply doesn’t process a relevant but observationally obvious fact, that can lead to an irrational choice. I might alternatively have said that the choice was rational (given the facts the chooser was aware of), but the observational process was irrational. But I suspect that terminology would just add needless complication.\nI’m going to spend more time on another point that is partially terminological, but primarily substantive. That’s whether we should identify the choice consequentialists recommend in virtue of the fact that it maximizes expected utility with one of the options (in the ordinary sense of option), or something antecedent. I’m going to stipulate (more or less) that it is consistent with consequentialism that the choice can be something antecedent - it can be something like a choice procedure. And I’m going to argue that this is what the rational consequentialist should choose.\nI’m going to call any search procedure that is sensitive to resource considerations a satisficing procedure. This isn’t an uncommon usage. Charles Manski (2017) uses the term this way, and notes that it has rarely been defined more precisely than that. But it isn’t the only way that it is used. Mauro Papi (2013) uses the term to exclusively mean that the chooser has a ‘reservation level’, and they choose the first option that crosses it. This kind of meaning will be something that becomes important again in a bit. And Chris Tucker (2016), following a long tradition in philosophy of religion, uses it to mean any choice procedure that does not optimize. Elena Reutskaja et al -Reutskaja et al. (2011) contrast a ‘hybrid’ model that is sensitive to resource constraints with a ‘satisficing’ model that has a fixed reservation level. They end up offering reasons to think ordinary people do (and perhaps should) adopt this hybrid model. So though they don’t call this a satisficing approach, it just is a version of what Manski calls satisficing. Andrew Caplin et al -Caplin, Dean, and Martin (2011), on the other hand, describe a very similar model to Reutskaja et al’s hybrid model - one where agents try to find something above a reservation level but the reservation level is sensitive to search costs - as a form of satisficing. So the terminology around here is a mess. I propose to use Manski’s terminology: agents satisfice if they choose in a way that is sensitive to resource constraints.\nIdeally they would maximize, subject to constraints, but saying anything more precise than this brings back the regress problem that we started with. Let’s set it aside just a little longer, and go back to David and the chickpeas.\nWhen David is facing the shelf of chickpeas, he can rationally take any one of them - apart perhaps from ones that are seriously damaged. How can expected utility theory capture that fact? I think if it identifies David’s choices with the cans on the shelf, and not with a procedure for choosing cans, then it cannot.\nIt says that more than one choice is permissible only if the choices are equal in expected utility. So the different cans are equal in expected utility. But on reflection, this is an implausible claim. Some of the cans are ever so slightly easier to reach. Some of the cans will have ever so slight damage - a tiny dint here, a small tear in the label there - that just might indicate a more serious flaw. Of course, these small damages are almost always irrelevant, but as long as the probability that they indicate damage is positive, it breaks the equality of the expected utility of the cans. Even if there is no visible damage, some of the labels will be ever so slightly more faded, which indicates that the cans are older, which ever so slightly increases the probability that the goods will go bad before David gets to use them. Of course in reality this won’t matter more than one time in a million, but one in a million chances matter if you are asking whether two expected utilities are strictly equal.\nThe common thread to the last paragraph is that these objects on the shelves are almost duplicates, but the most careful quality control doesn’t produce consumer goods that are actual duplicates. There are always some differences. It is unlikely that these differences make precisely zero difference to the expected utility of each choice. And even if they do, discovering that is hard work.\nSo it seems likely that, according to the expected utility model, it isn’t true that David could permissibly take any can of chickpeas that is easily reachable and not obviously flawed. Even if that is true, it is extremely unlikely that David could know it to be true. But one thing we know about situations like David’s is that any one of the (easily reached, not clearly flawed) cans can be permissibly chosen, and David can easily know that. So the expected utility model, as I’ve so far described it, is false.\n\n\n1.0.2 Puzzle Two - Psychic Costs of Bias\nIn all but a vanishingly small class of cases, the different cans will not have the same expected utility. But figuring out which can has the highest expected utility is going to be work. It’s possible in principle, I suppose, that someone could be skilled at it, in the sense that they could instinctively pick out the can whose shape, label fading, etc., reveal it to have the highest expected utility. Such a skill seems likely to be rare - though I’ll come back to this point below when considering some other skills that are probably less rare. For most people, maximizing expected utility will not be something that can be done through skill alone; it will take effort. And this effort will be costly, and almost certainly not worth it. Although one of the cans will be ever so fractionally higher in expected utility than the others, the cost of finding out which can this is will be greater than the difference in expected utility of the cans. So aiming to maximize expected utility will have the perverse effect of reducing one’s overall utility, in a predictable way.\nThe costs of trying to maximize expected utility go beyond the costs of engaging in search and computation. There is evidence that people who employ maximizing strategies in consumer search end up worse off than those who don’t. Schwartz et al. (2002) reported that consumers could be divided in ‘satisficers’ and ‘maximizers’. And once this division is made, it turns out that the maximizers are less happy with individual choices, and with their life in general. This finding has been extended to work on career choice (Iyengar, Wells, and Schwartz 2006), where the maximizers end up with higher salaries but less job satisfaction, and to friend choice (Newman et al. 2018), where again the maximizers seem to end up less satisfied.\nThere are two things that can go wrong when you try to maximize. Maximising requires considering the strengths and weaknesses of each of the choices. That means, it requires giving at least some consideration to the negative attributes of what you end up choosing. And these can cause you to be less happy with the actual choice when those negative attributes are realized. And it also means giving consideration to the positive attributes of the choices not made. And this could lead to regret when you have to adopt a choice that lacks those positive attributes. So there are two very natural paths by which the attempt to maximize could backfire, any incurs costs that wouldn’t have been incurred by the person who simply makes an arbitrary choice.\nThere is evidence here that both these paths are realised, and that maximisers do indeed end up psychically worse off than satisficers. Now to be sure, there are both empirical and theoretical reasons to be cautious about accepting these results at face value. Whether the second path, from consideration of positive attributes of the non-chosen option to felt regret, is psychologically significant seems to be tied up with the ‘paradox of choice’ (Schwartz 2004), the idea that sometimes giving people even more choices makes them less happy with their outcome, because they are more prone to regret. But it is unclear whether such a paradox exists. One meta-analysis (Scheibehenne, Greifeneder, and Todd 2010) did not show the effect existing at all, though a later meta-analysis finds a significant mediated effect (Chernev, Böckenholt, and Goodman 2015). But it could also be that the result is a feature of an idiosyncratic way of carving up the maximizers from the satisficers. Another way of dividing them up produces no effect at all (Diab, Gillespie, and Highhouse 2008).\nThe theoretical reasons relate to Newcomb’s problem. Even if we knew that maximizers were less satisfied with how things are going than satisficers, it isn’t obvious that any one person would be better off switching to satisficing. They might be like a two-boxer who would get nothing if they took one-box. There is a little evidence in Iyengar, Wells, and Schwartz (2006) that this isn’t quite what is happening, but the overall situation is unclear.\nBut the philosophical questions here are a bit simpler than the psychological questions. Whether maximisers in general are subject to these two kinds of costs is a tricky empirical question. Whether there could be one maximiser who is subject to them, and who knows that they are, is a much easier question. Of course someone could be like that. Indeed, it seems beyond dispute that many real people are subject to these costs. The only empirical question is whether these people are a significant minority or a significant majority.\nAnd all it takes for the philosophical question to be pressing is that some choosers are, and know that they are, disposed to incur these psychological costs if they consciously try to maximise expected value. Our theory of choice should have something to say to them, and orthodox theory is silent. Especially for choices that are intended to produce happiness, the happiness effects of the choice procedure itself should be taken into account. But orthodox theory ignores it.\n\n\n1.0.3 Puzzle Three - Mathematical Challenges\nFor a final case, let’s consider Kyla, a student taking a mathematics exam. It’s getting towards the end of the exam and she’s facing quite a bit a time pressure. She comes to a true false question, and she knows that she knows how to solve questions like it. But she also knows that there are other kinds of questions that she is better at solving under time pressure. And while this is just a true false question, the exam is set up so that she gets a large negative score if she gets the question wrong. The expected return of simply guessing is strongly negative.\nThe rational thing for Kyla to do is to go on to other questions and come back to this one if she has time. But orthodox theory doesn’t allow for this. The probability of any mathematical truth is one. And it’s part of orthodoxy that credences are supposed to be probability functions. So whatever the correct answer is, offering it will have positive expected utility given Kyla’s credences, assuming those credences are rational.\nSo orthodoxy gets this choice, and all other choices that turn on mathematical ignorance, badly wrong. The case where Kyla simply has to decide whether to answer the question now or come back to it later is in some ways a relatively easy case. The really hard decisions are about how much time to allocate to solving various mathematical problems, when there are both costs to spending time, and rewards to solving as many problems as possible. These can often be important decisions, and ones that our theory should have something to say about. But orthodoxy does not have anything to say. It’s time to look for something else.\n\n\n\n2 Dialectical Interludes\n\n2.0.1 Interlude One - The Obvious Answer\nBy this time you might be expecting a relatively simple answer to this question. The problem is that the orthodox theorist was focussing on the wrong choice. We shouldn’t focus on the choice to take this can of chickpeas or that one, or to answer true or false to this question. Rather, we should focus on the choice to choose one procedure or another. And the rational chooser will choose the procedure that is on average best.\nThat solves our cases quite well. The best procedure for Frankie Lee or David to adopt is to choose arbitrarily. Any other procedure will take time, and it’s not going to be time well spent. The best procedure for the person wracked by regret at choices they didn’t make is also to choose somewhat arbitrarily, before the regrets have time to embed. Conversely, the best procedure for Kyla is to skip any questions that she can’t do quickly, and come back to them if it turns out she has time.\nGiven some very weak assumptions, Maximise expected utility will not be an optimal procedure in this sense. Actually it’s ambiguous what it means to say someone should adopt the procedure Maximise expected utility, but however you disambiguate that, it’s wrong. The procedure Calculate what maximises expected utility then choose it is not optimal, because the calculations may not be worth the effort. The procedure Instinctively choose what maximises expected utility is a very efficient procedure if it is available, but for most agents it isn’t available. We should no more criticise agents who don’t adopt it than we criticise agents who don’t get to work by apparating.\nI’m going to adopt a version of the view that the rational choice is the outcome of an optimal procedure. But I’m not going to adopt the most obvious version of this obvious answer. In particular, I’m not going to say that agents should adopt the procedure such that adopting that procedure maximises expected value. Rather, I think, they should adopt the procedure that maximises something like average value. We’ll return to this in a bit, but first I want to clear up some other dialectical points.\n\n\n2.0.2 Dialectical Point Two - Possible Orthodox Solutions\nThere are ways of tinkering with orthodoxy to avoid some of the problems that I raised in the previous section. For example, dropping the constraint that credences are probabilities would avoid giving the wrong answer in Kyla’s case. And maybe, just maybe, there is a theory of evidence, or of evidential support, such that the evidential expected utility of each of Frankie Lee’s choices are not distinct. I’m certainly not going to try to go through every possible theory of evidence, or of evidential support, to show that this isn’t the case.\nBut I do want to note three constraints on an orthodox solution to the problems that I have raised.\nFirst, the solution must handle all the cases. This is not a completely trivial point. The reason orthodoxy fails in the three cases is a little different in each case. There is not, at least as far as I can tell, a simple way to handle all of them simultaneously while staying roughly within orthodoxy.\nSecond, the solution must not introduce any more complications of its own. For example, you could try to solve some of the problems by saying that the decision maker’s evidence includes just those facts that are immediately available to her. Perhaps there is some sense of ‘immediacy’ in which this provides the start of a solution to the first two puzzles. (I think the third puzzle won’t be solved this way, but the first two might.) But this solution introduces problems of its own. For example, a decision can be irrational in virtue of the fact that a moment’s thought would’ve revealed to the decision maker that it will lead to disaster. If we restrict evidence to what is available at less than a moment’s thought, then we get this case wrong. If we don’t put such a restriction in place, then we’re back to having problems with the first two puzzles I mentioned above. I don’t want to clean there is nothing for the orthodox theorist to do here, but I do think it will be tricky to handle the puzzles without licencing irrational thoughtlessness.\nThird, any orthodox solution should be just as simple and as well motivated as the obvious answer I just discussed. Saying that we should focus on procedures and not on the choices they lead to on an occasion resolves all of these puzzles in a simple and natural way. Even if an orthodox solution can be found to all three puzzles, if it requires three different changes to the orthodox view, it’s hard to believe that it will be preferable to a simple solution in terms of procedures.\n\n\n2.0.3 Dialectical Point Three - Terminology\nAt this point, some people might want to simply stipulate that the word “rational” picks out the choice that a computationally ideal actor would take. Even if it’s good in some sense for David to choose arbitrarily, there is still an ideal can to choose, and he only deserves the honorific rational if he chooses it.\nI am not going to get into a fight over terminology here. If people want to continue inquiring into what David would ideally do, then I’m not going to get in their way. But I found this inquiry unmotivated for three reasons. First, if we’re going to consider what David would ideally do, then I’m more interested in what he’d do if he were really ideal, and knew everything. I don’t see the appeal of investigating what he would do given one, but only one, kind of idealisation. Second, I don’t think the ideal is a particularly good guide. Knowing what the gods do doesn’t help the mortals, for mortals just get burned if they try to be like gods.\nBut the biggest reason concerns a purpose that I think is a central function of the concept of rationality. We have a need to make the people around us intelligible and predictable. And the best way we have to do this is to understand the constraints and the motivations of people around us, and feed those into a theory of rational choice that outputs a decision given constraints and motivations. It doesn’t always work, especially if you are trying to make predictions. But it beats most of the alternatives by a comfortable margin.\nIf that’s the reason for having a theory of rational choice, then the orthodox theory is not fit for purpose. The person who stands in the grocery store aisle deliberating over which can to get is neither intelligible nor predictable. The theory that says rational agents adopt procedures that do well on average, given their constraints and motivations, does make the ordinary behavior of supermarket shoppers intelligible and predictable.\nWhen I say ‘we’ need to make folks around us intelligible and predictable, I mean this to work at two different levels. From a very early age, we do this kind of reasoning about particular individuals to learn about the world (Scott and Baillargeon 2013). If a child sees a competent seeming adult use a particular method to solve a problem, and the adult does not seem to have any constraints that the child is free of, the child will copy what the adult does (Levy and Alfano 2020). This makes perfect sense; the adult is rational (and better informed than the child), so probably the adult’s procedure is optimal for the child. If we know that children do this, we can exploit it to trick them. For example, we can demonstrate sub-optimal procedures, and children will mimic them for a surprisingly long time. But this isn’t because the child is a fool; it’s because they have a clever way of learning about the world that can misfire when people set out to confound it.\nBut I also mean this to work at the level of social analysis. The whole point of game theoretic explanations of social phenomena is that we can make a pattern of behavior intelligible by simply presenting the constraints and motivations of the choosers, and then showing how rational behavior on everyone’s part produces the outcome. The research program this paper is a part of is motivated by the hope, and it is a hope more than a theory, that the same theory of rationality can serve both the child who is selectively imitating those around them, and the social scientist with their game theoretic models. Whether that’s true in general or not, I think both the child and the theorist are better served by a theory of rational choice that is sensitive to computational limitations and deliberation costs. And it’s their perspectives that I’m most interested in when theorising about rationality.\nThere is one other terminological dispute that I have no interest in entering into, but I need to make explicit in order to set aside. Some philosophers use ‘decision theory’ to refer to the study of purely procedural aspects of rationality. On this picture, there are three parts to rational choice: epistemology, axiology and decision theory. A rational agent will comply with all three. Compliance with the first is manifest in rational credences. Compliance with the second is manifest in rational values. And compliance with the third is manifest in choices that are rational given the first two. I don’t much care for this highly factorised model of rational choice theory. Imagine we see someone punching themselves in the head, and ask why they are doing this. If they say, “I want to bring about world peace, and I believe this is the best way to do it”, we don’t reply, “Well, I guess two out of three isn’t bad”. We just think they are irrational. But for current purposes I don’t want to debate this. This paper is about the theory of rational choice. If you think that encompasses more than decision theory, that it also includes epistemology and axiology, then this isn’t a paper in decision theory strictly speaking. But even someone who thinks the theory of rational choice can be factorised in this way still thinks there is a theory of rational choice. And my plan here is to offer a rival theory. Whether what I offer is a rival theory of decision turns on terminological questions about ‘decision theory’ that I’m hereby setting aside.\n\n\n\n3 History and Regresses\nThe idea that rational people are sensitive to their own computational limitations has a long history. It is often traced back to a footnote of Frank Knight’s. Here is the text that provides the context for the note.\n\nLet us take Marshall’s example of a boy gathering and eating berries … We can hardly suppose that the boy goes through such mental operations as drawing curves or making estimates of utility and disutility scales. What he does, in so far as he deliberates between the alternatives at all*, is to consider together with reference to successive amounts of his “commodity,” the utility of each increment against its “cost in effort,” and evaluate the net result as either positive or negative (Knight 1921, 66–67)\n\nAnd the footnote attached to ‘at all’ says this\n\nWhich, to be sure, is not very far. Nor is this any criticism of the boy. Quite the contrary! It is evident that the rational thing to do is to be irrational, where deliberation and estimation cost more than they are worth. That this is very often true, and that men still oftener (perhaps) behave as if it were, does not vitiate economic reasoning to the extent that might be supposed. For these irrationalities (whether rational or irrational!) tend to offset each other. (Knight 1921, 67fn1)\n\nKnight doesn’t really give an argument for the claim that these effects will offset. And as John Conlisk (1996) shows in his fantastic survey of the late 20th century literature on bounded rationality, it very often isn’t true. Especially in game theoretic contexts, the thought that other players might think that “deliberation and estimation cost more than they are worth” can have striking consequences. But our aim here is not to think about economic theorising, but about the nature of rationality.\nThere is something paradoxical, almost incoherent, about Knight’s formulation. If it is “rational to be irrational”, then being “irrational” can’t really be irrational. There are two natural ways to get out of this paradox. One, loosely following David Christensen (2007), would be to say that “Murphy’s Law” applies here. Whatever one does will be irrational in some sense. But still some actions are less irrational than others, and the least irrational will be to decline to engage in deliberation that costs more than it is worth. I suspect what Knight had in mind though was something different (if not obviously better). He is using ‘rational’ as more or less a rigid designator of the the property of choosing as a Marshallian maximizer does. And what he means here is that the disposition to not choose in that way will be, in the long run, the disposition with maximal returns.\nThis latter idea is what motivates the thought that rational agents will take what John Conlisk calls “deliberation costs” into account. And Conlisk thinks that this is what rational agents will do. But he also raises a problem for this view, and indeed offers one of the clearest (and most widely cited) statements of this problem.\n\nHowever, we quickly collide with a perplexing obstacle. Suppose that we first formulate a decision problem as a conventional optimization based on the assumption of unbounded rationality and thus on the assumption of zero deliberation cost. Suppose we then recognize that deliberation cost is positive; so we fold this further cost into the original problem. The difficulty is that the augmented optimization problem will itself be costly to analyze; and this new deliberation cost will be neglected. We can then formulate a third problem which includes the cost of solving the second, and then a fourth problem, and so on. We quickly find ourselves in an infinite and seemingly intractable regress. In rough notation, let \\(P\\) denote the initial problem, and let \\(F(.)\\) denote the operation of folding deliberation cost into a problem. Then the regress of problems is \\(P, F(P), F^2(P), \\ldots\\) (Conlisk 1996, 687)\n\nConlisk’s own solution to this problem is not particularly satisfying. He notes that once we get to \\(F^3\\) and \\(F^4\\), the problems are ‘overly convoluted’ and seem to be safely ignored. This isn’t enough for two reasons. First, even a problem that is convoluted to state can have serious consequences when we think about solving it. (What would Econometrica publish if this weren’t true?) Second, as is often noted, \\(F^2(P)\\) might be a harder problem to solve than \\(P\\), so simply stopping the regress there and treating the rational agent as solving this problem seems to be an unmotivated choice.\nAs Conlisk notes, this problem has a long history, and is often used to dismiss the idea that folding deliberation costs into our model of the optimising agent is a good idea. I use ‘dismiss’ advisedly here. As he also notes, there is very little discussion of this infinite regress problem in the literature before 1996. The same remains true after 1996. What is done is that instead people appeal to the regress in a sentence or two to set aside approaches that incorporate deliberation cost in the way that Conlisk suggests.\nUp to around the time of Conlisk’s article, the infinite regress problem was often appealed to by people arguing that we should, in effect, ignore deliberation costs. After his article, the appeals to the regress comes from a different direction. It is usually from theorists arguing that deliberation costs are real, but the regress means it will be impossible to consistently incorporate them into a model of an optimizing agent. So we should instead rely on experimental techniques to see how people actually handle deliberation costs; the theory of optimization has reached its limit. This kind of move is found in writers as diverse as Gigerenzer and Selten (2001), Odell (2002), Pingle (2006), Mangan, Hughes, and Slack (2010), Ogaki and Tanaka (2017) and Chakravarti (2017). And proponents of taking deliberation costs seriously within broadly optimizing approaches, like Miles Kimball (2015), say that solving the regress problem is the biggest barrier to having such an approach taken seriously by economists. So let’s turn to how we might solve it.\n\n\n4 Four Non-Solutions\nMy solution, as I’ve mentioned a couple of times, is a form of reliabilism. The rational choice is the one that would be produced by using the procedure that does best on average. That procedure will just be maximising expected utility when computational costs are zero, and will involve appeal to expected utility maximisation in many other cases. But it won’t, in general, simply be expected utility maximisation.\nTo get clearer on what the reliabilist solution is, and how it is motivated, I want to first go through three other solutions that I don’t think work.\nFirst, we could just say that the rational choice is simply the choice that produces the best actual result. This gets some cases intutively wrong; it says that it is never rational to leave a casino without gambling. And it eliminates a type of choice that we think is real: the lucky guess. We want lucky guesses to be cases that produce good outcomes, but are not rational. If the rational choice just is the best choice, this is impossible. Since lucky guesses are not impossible, this theory can’t be right.\nSecond, we could say that the rational choice is the choice that maximises expected value. But I’ve already gone over why that is wrong. There are really two things we could mean by saying the rational choice is the one that maximises expected value, and both of them are wrong. We could say that the rational choice is to compute what has the highest expected value, and then choose it. But this gives the wrong result in all the cases that I discussed at the beginning. Or we could say that the rational choice is to insinctively pick the one with the highest expected value. But there is no more reason to think this is something that choosers can do than there is to think that choosers can instinctively pick the choice with the highest actual value. So this is unrealistic.\nThird, we could say the choice is the output of the procedure such that adopting that procedure maximises expected value, given one’s evidence about the world and about the nature of procedures. Here, I think, the regress has bite because the same arguments from the previous paragraph still apply. We really need to distinguish two possible things we might mean by saying that one should adopt the procedure such that adopting it maximises expected value. First, we could mean that choosers should compute which procedure will maximise expected value, and then adopt it. But this will get the wrong result in Frankie Lee’s case, and in David’s. They shouldn’t be doing any computation at all. So perhaps instead we could say that the rational chooser will instinctively choose the procedure with the highest expected value. But there is no more reason to think that choosers could always do that there is to think that they can simply choose the first-order option with the highest actual or expected value. So this idea fails, and it fails for just the same reasons as the suggestion of the previous paragraph. That doesn’t prove a regress is looming, but it doesn’t look good.\nThe fourth option I’ll discuss is designed to avoid this problem, and it is going to look somewhat more promising2. Maybe we can’t all at once choose the best procedure. But we can do it piecemeal.\n2 Indeed, in early drafts of this paper, I didn’t distinguish this proposal from the one I’ll endorse in the next section. And those ‘early drafts’ were circulated in late 2019. So they included the first draft of the paper that I sent to Ted. I’m sorry for doing something between clarifying and changing my view so late.In general, here’s a way to adopt a complicated procedure. When faced with a certain class of problems, adopt the simplest procedure that agree with the complicated procedure over the range of choices you face. Then, as the problems expand, start either complicating the procedure, or adopt a meta-procedure for choosing which simple procedure to adopt on an occasion. Over time, if all goes well, you’ll eventually adopt something like the complicated procedure, and do it without having to solve impossibly hard calculations about procedural effectiveness, or having miraculously good instincts.\nOne appeal of this approach is that it blocks the regress. If one selects a procedure piecemeal in this way, there is a good sense in which \\(F(P) = F^2(P) = F^3(P) = \\dots\\). After all, there won’t be a difference between adopting a procedure, and adopting a procedure for adopting that procedure. Both of them will just involve making the choices you have to make on a given day, and looking for the opportunity to integrate those choices into a larger and more systematic theory. By adopting a first-order procedure piecemeal, you also adopt a second-order procedure piecemeal. And if \\(F(P) = F^2(P) = F^3(P) = \\dots\\), then the regress doesn’t get going.\nThe problem is that this is too demanding. We want choosers to maximise. We don’t expect them to be able to maximise over every possible choice situation, just over the one in front of them. If I’m buying chickpeas, and I arbitrarily choose one of the cans, that’s all to the good. It’s a rational choice. And, crucially, it stays being a rational choice even if I have dispositions to choose badly in other choice situations. But on the ‘piecemeal’ model being considered here, those dispositions to choose badly are partially constitutive of my choice procedure. And rational choice is a matter of choosing in virtue of adopting the correct choice procedure. So someone who is irrational somewhere is, it turns out, irrational everywhere. This is a bad result. There is something right about the idea that the rational chooser will just choose what’s in front of them, and do so in a sensible way. But we shouldn’t go on to say that rational choice requires that the global procedure one thereby implicitly adopts is the right one; that’s too high a bar.\n\n\n5 Skilled Choice\nThe way to see what’s right about the last proposal, and to see our way to the correct solution, is to somewhat reconceptualise rational choice. We shoudl conceive of the rational chooser as a skilled chooser. And we should think skills are a matter of reliably doing well across realistic situations.\nThe justification for conceiving of rational choice as skilled choice is largely pragmatic. Thinking of rationality that ways results in a plausible theory of rationality, and other ways of thinking about rationality resulted in implausible theories. So rather than argue for the conception of rationality as skill, I’m going to more or less assume it, and hope to justify this assumption by its fruitfulness. What I will argue for is the idea that skill involves reliably succeeding across realistic situations.3\n3 This is very similar to the modal understanding of skill in Beddor and Pavese (2020).Think for a bit about skilled atheletes, or skilled players of chess or other games. Part of being skilled is succeeding. But it isn’t just about success. Some people win due to luck. The skilled player won’t always win, but they will reliably win across a range of situations.\nWhich situations are those? They are the situations that are normal enough for the kind of activity being engaged in. These might be dependent on highly contingent features of the activity. A chess player who wins international tournaments must be very skilled. We wouldn’t retract that assessment if it turned out they only played well in quiet enviornments, and frequently lost chess games in noisy pubs. High level chess is played in quiet environments, so that’s what matters.\nA football player whose instincts only go right when there is no wind around is not particuarly skilled. Someone who doesn’t know how to adjust their passes when the wind changes is not skilled; it is lucky that they get ever connect on a pass. Conversely, a football player whose instincts are finely calibrated to the actual gravitational field strength around here could be highly skilled. It’s not part of footballing skill that one is able to adjust to changes in gravitational field strength. Some kinds of flexibility, such as ability to adjust to wind conditions, matter, while others, such as ability to adjust to a different gravitational field, do not. There are intermediate cases where the importance of the ability to adjust is dependent on contingent attributes of the activity. Top level Australian Rules Football is almost always played at sea level. An Australian Rules Footballer whose instincts are calibrated for play at sea level, and who has no ability to adjust to changes in altitude, might still be highly skilled. But in a sporting competition where top flight games are frequently played in Mexico City or Quito, an inability to adjust to changing altitudes is a substantial limitation on one’s skill. It is luck, not skill, that causes one to succeed in contests at one’s favored altitude. But it isn’t luck that the Australian Rules Footballer is playing at sea level; that’s a stable generalisation about the sport.\nThe same kind of story holds true for the skilled chooser. They have to do well, and not by chance. But that can involve having instincts that are calibrated to the enviornment one is actually in, and which would misfire in other environments. A skilled supermarket shopper need not be applying procedures that would do well in a medieval market. But they must be applying procedures that will keep working if the shelving of various items is changed.\nThat’s to say, the skilled chooser will adopt a procedure that will, on average, produce the best results in circumstances like the ones they are in.There is an implicit notion of probability in that definition. But it isn’t the notion of credence, or even of rational credence. Rather, it is the notion of how likely it is, or how frequent it is, that different circumstances obtain. That’s the sense in which the theory is reliabilist.\nWhen I say ‘produce the best results’, I mean the best results of the available procedures. Just like we don’t require rational commuters to apparate, we don’t require rational choosers to instinctively maximise utility, or expected utility. They (just) have to do the best they can.\nSkilled action frequently involves doing things where one has no evidence for the utility of such performances. It can even involve doing things where one has evidence against the utility of what one is doing. To see this, imagine a junior athelete who is thriving against competitors their own age with an unusual technique. They are told, by seemingly trustworthy coaches, that to thrive at higher levels, they have to adopt a more orthodox technique. But though they have reason to believe these coaches, they keep instinctively lapsing back into their unusual techniques. And, amazingly, the coaches are wrong, and what looked like a technique for winning against kids in parks ends up working at international level competition. (This isn’t entirely unlike the story of Australian cricketer Steve Smith.) Such an athelet may be highly skilled. And their skill consists in, among other things, their instincts to do things that they have (misleading) evidence will not work. Their skill, that is, involves deploying a procedure that is actually reliable, even after they get evidence it is unreliable. I think the same is true of skilled choice. Sometimes, the skilled chooser will deploy a technique that they think is defective, and even one that they think is defective on reasonable grounds. As long as it works, it can still be the basis for skilled, and hence rational, choosing.\n\n\n6 Regress Blocking\nWith all that in place, let’s return to the regress problem, and in particular to Conlisk’s statement of it. Why should we think the rational agent solves \\(F(P)\\), and not \\(F^n(P)\\) for some \\(n &gt; 1\\)? I want to say that’s just what rational choice is; it’s skillfully managing one’s own computational and informational limitations. And skill in this sense involves getting it right, and doing so reliably, not necessarily thinking through the problem. This suggests two questions.\n\nWhy should we allow this kind of unreflective rule-following in our solution to the regress?\nWhy should we think that \\(F(P)\\) is the point where this consideration kicks in, as opposed to \\(P\\), or anything else?\n\nThere are a few ways to answer 1. One motivation traces back to the work by the artificial intelligence researcher Stuart Russell (1997). (Although really it starts with the philosophers Russell cites as inspiration, such as Cherniak (1986) and Harman (1973).) He stresses that we should think about the problem from the outside, as it were, not from inside the agent’s perspective. How would we program a machine that we knew would have to face the world with various limitations? We will give it rules to follow, but we won’t necessarily give it the desire (or even the capacity) to follow those rules self-consciously. That might be useful some of the time - though really what’s more useful is knowing the limitations of the rules. And that can be done without following the rules as such. It just requires good dispositions to complicate the rules one is following in cases where such complication will be justified.\nAnother motivation is right there in the quote from Knight that set this literature going. Most writers quote the footnote, where Knight suggests it might be rational to be irrational. But look back at what he’s saying in the text. The point is that it can be perfectly rational to use considerations other than drawing curves and making utility scales. What one has to do is follow internal rules that (non-accidentally) track what one would do if one was a self-consciously perfect Marshallian agent. That’s what I’m saying too, though I’m saying it one level up.\nFinally, there is the simple point that on pain of regress any set of rules whatsoever must say that there are some rules that are simply followed. This is one of the less controversial conclusions of the debates about rule-following that were started by Wittgenstein (1953). That we must at some stage simply follow rules, not follow them in virtue of following another rule, say the rule to compute how to follow the first rule and act accordingly, is an inevitable consequence of thinking that finite creatures can be rule followers.\nSo question 1 is not really a big problem. But question 2 is more serious. Why \\(F(P)\\), and why not something else? The short answer will be that any reason to think that rational actors maximize expected utility, as opposed to actual utility, will also be a reason to think that they solve \\(F(P)\\) and not \\(P\\).\nStart by stepping back and thinking about why we cared about expected utility instead of actual utility in the first place. Why not just say that the best thing to do is to produce the best outcome, and be done with it? Well, we don’t say that because we take it as a fixed point of our inquiry that agents are informationally limited, and that the best thing to do is what is best given that limitation. Given some plausible assumptions, the best thing for the informationally limited agent to do would be to maximize expected utility. This is a second-best option, but the best is unavailable given the limitations that we are treating as unavoidable.\nBut agents are not just informationally limited, they are computationally limited too. And we could have instead treated that as the core limitation to be modelled. As Conlisk says, it is “entertaining to imagine” theorists who worked in just this way, taking the agents in their models to have computational but not informational limitations (Conlisk 1996, 691). Let’s imagine that when we meet the Martian economists, that’s how they reason. Conlisk notes a few things that the Martian economists might do. They might disparage their colleagues who take informational limitations seriously as introducing ad hoc stipulations into their theory. They might argue that informational limitations are bound to cancel out, or be eliminated by competition. They might argue that apparent informational limitations are really just computational ones, or at least can be modelled as computational ones. And so on.\nWhat he doesn’t add is that they might suggest that there is a regress worry for any attempt to add informational constraints. Let \\(Q\\) be the initial problem as the Martians see it. That is, \\(Q\\) is the problem of finding the best outcome given full knowledge of the situation, but the actual computational limitations of the agent. Then we suggest that we should also account for the informational limitations. Let’s see if this will work, they say. Let \\(I()\\) be the function that transforms a problem into one that is sensitive to the informational limitations of the agent. But if we’re really sensitive to informational limitations, we should note that \\(I(Q)\\) is also a problem the agent has to solve under conditions of less than full information.4 So the informationally challenged agent will have to solve not just \\(I(Q)\\), but \\(I^2(Q)\\), and \\(I^3(Q)\\) and so on.5\n4 At this point the Martians might note that while they are grateful that Williamson (2000) has highlighted problems with the KK principle, and these problems show some of the reasons for wanting to idealise away from informational limitations, they aren’t in fact relying on Williamson’s work. All they need is that agents do not exactly what they know. And that will be true as long as the correct epistemic logic is weaker than S5. And that will be true as long as someone somewhere has a false belief. And it would just be weird, they think, to care about informational limitations but want to idealise away from the existence of false beliefs.5 At this point, some of the Martians note that the existence of Elster (1979) restored their faith in humanity.Orthodox defenders of (human versions of) rational choice theory have to think this is a bad argument. And I think most of them will agree with roughly the solution I’m adopting. The right problem to solve is \\(I(Q)\\), on a model where \\(Q\\) is in fact the problem of choosing the objectively best option. If one doesn’t know precisely what one’s knowledge is, then one has to maximize expected utility somewhat speculatively. But that doesn’t mean that one shouldn’t maximize expected utility.\nBut the bigger thing to say is that neither we nor the Martians really started with the right original problem. The original problem, \\(O\\), is the problem of choosing the objectively best option. The humans start by considering the problem \\(I(O)\\), i.e., \\(P\\), and then debate whether we should stick with that problem, or move to \\(F(I(O))\\). The Martians start by considering the problem \\(F(O)\\), i.e., \\(Q\\), then debate whether we should stick with that or move to \\(I(F(O))\\). And the answer in both cases is that we should move.\nGiven the plausible commutativity principle, that introducing two limitations to theorising has the same effect whichever order we introduce them, \\(I(F(O)) = F(I(O))\\). That is, \\(F(P) = I(Q)\\). And that’s the problem that we should think the rational agent is solving.\nBut why solve that, rather than something more or less close to \\(O\\)? Well, think about what we say about an agent in a Jackson case who tries to solve \\(O\\) not \\(I(O)\\). (A Jackson case, in this sense, is a case where the choice with highest expected value is known to not have the highest objective value. So trying to get the highest objective value will mean definitely not maximizing expected value.) We think it will be sheer luck if they succeed. We think in the long run they will almost certainly do worse than if they tried to solve \\(I(O)\\). And in the rare case where they do better, we think it isn’t a credit to them, but to their luck. In cases where the well-being of others is involved, we think aiming for the solution to \\(O\\) involves needless, and often immoral, risk-taking.\nThe Martians can quite rightly say the same things about why \\(F(O)\\) is a more theoretically interesting problem than \\(O\\). Assume we are in a situation where \\(F(O)\\) is known to differ from \\(O\\), such as the case Kyla was in. Or, for a different example, imagine the decision maker will get a reward if they announce the correct answer to whether a particular sentence is a truth-functional tautology, and they are allowed to pay a small fee to use a computer that can decide whether any given sentence is a tautology. The solution to \\(O\\) is to announce the correct answer, whatever it is. The solution to \\(F(O)\\) is to pay to use the computer. And the Martians might point out that in the long run, solving \\(F(O)\\) will yield better results. That if the agent does solve problems like \\(O\\) correctly, even in the long run, this will just mean they were lucky not rational. That if the reward is that a third party does not suffer, then it is immorally reckless to not solve \\(F(O)\\), i.e., to not consult the computer. And in general, whatever we can say that motivated “Rational Choice Theory”, as opposed to “Choose the Best Choice Theory”, they can say too.\nBoth the human and the Martian arguments look good to me. We should add in both computational and informational limitations into our model of the ideal agent. And that’s the solution to the regress. It is legitimate to think that there is a rule that rational creatures follow immediately, on pain of thinking that all theories of rationality imply regresses. And thinking about the contingency of how Rational Choice Theory got to be the way it is suggests that the solution to what Conlisk calls \\(F(P)\\), or what I’ve called \\(F(I(O))\\), will be that point.\n\n\n7 The Nature of Good Procedures\nSince this is meant to be a theory of rational choice for real people, it would be helpful to say a few words about what these reliable procedures that stop the regress might be. In principle they could be anything, but in practice I think three kinds of procedures are particularly important: instincts, planning, and modelling. I’ll say a bit about each of these in turn.\nHumans are surprisingly good at instinctively allocating reasonable amounts of cognitive resources to computational tasks. In artificial intelligence research, one of the big challenges is trying to make machines be as good as humans at figuring out which problems to allocate cognitive resources to. This is sometimes known as the frame problem. Here’s a typical description of this from a recent survey article.\n\nAnd, more generally, how do we account for our apparent ability to make decisions on the basis only of what is relevant to an ongoing situation without having explicitly to consider all that is not relevant? (Shanahan 2016)\n\nNote that this assumes is that humans are actually very good at this rather hard task - setting aside the irrelevant without first thinking that it is irrelevant. This has to be instinctive. We don’t go around thinking about how much time to spend thinking on various subjects. That would be self-defeating. Obviously we are far from perfect at this, but it is striking how good we are at it.\nRecent work on ‘vigilance’ has illustrated how good we are at one aspect of this problem (Sperber et al. 2010). Somehow, and I don’t think it is clear how, we manage to keep track of our environment in a comprehensive enough away that it allows us to focus on those things that need focusing on. For example, when walking down a busy street, we don’t make a model of the expected movements of each of the individuals around us. That would be too computationally taxing. But we do pay enough attention to each of those individuals for us to be able to focus on any one of them if they seem to pose a particular challenge or threat. If one of them is weaving in a drunken manner, or carrying a sword, we are able to focus on them very quickly. To do this we must be paying at least background attention to every one of them. I think this turns out to be a common phenomenon. There are many situations where we don’t have the ability to carefully consider everything that’s going on, but we do manage to pick out the things around us that need close attention. And that requires monitoring of the entire environment, and doing some very quick and dirty processing of the resulting inputs. As I said, it’s a bit of a mystery how we do this. But whatever we do, it’s an amazing feat of insinctively solving a cognitive resource allocation problem.\nWhen I say we do some of these things instinctively, I don’t mean that our ability to do them is innate. We might pick them up by learning from those around us. This learning need not be conscious. It might happen by imitation. It is sometimes thought that humans’ disposition to over imitate those around them is a kind of irrationality (Levy and Alfano 2020). But my guess is that it is part of what grounds our skill in solving these hard cognitive resource allocation problems.\nBut rather than speculate further about what future research will show about the range and limits of human instinct, let’s turn to two ways of consciously adopting reliable procedures. In his discussion of the regress, Miles Kimball (2015) suggests a few options that might work. I want to focus on two of them: planning and modelling.\n\nLeast transgressive are models in which an agent sits down once in a long while to think very carefully about how carefully to think about decisions of a frequently encountered type. For example, it is not impossible that someone might spend one afternoon considering how much time to spend on each of many grocery-shopping trips in comparison shopping. In this type of modelling, the infrequent computations of how carefully to think about repeated types of decisions could be approximated as if there were no computational cost, even though the context of the problem implies that those computational costs are strictly positive. (Kimball 2015, 174)\n\nAnd that’s obviously relevant to David in the supermarket. He could, in principle, spend one Saturday afternoon thinking about how carefully to check each of the items in the supermarket before putting it in his shopping cart. And then in future trips, he could just carry out this plan. In general, planning as a device for incurring computational costs at a time when those costs are less costly.\nThis isn’t a terrible strategy, but I suspect it’s rarely optimal. For one thing, there are much better things to do with Saturday afternoons. For another, it suggests we are back in the business of equating solving \\(F(P)\\) with approximately solving \\(P\\). And that’s a mistake. Better to just say that David is rational if he just does the things that he would do were he to waste a Saturday afternoon this way, and then plan it out. And that thought leads to Kimball’s more radical suggestion for how to avoid the regress,\n\n[M]odelling economic actors as doing constrained optimization in relation to a simpler economic model than the model treated as true in the analysis. This simpler economic model treated as true by the agent can be called a “folk theory” (Kimball 2015, 175)\n\nIt’s this last idea I plan to explore in more detail. (It has some similarities to the discussion of small worlds in Joyce (1999) 70-77.) The short version is that David can, and should, have a little toy model of the supermarket in his head, and should optimize relative to that model. The model will be false, and David will know it is false. And that won’t matter, as long as David treats the model the right way.\nThere are a lot of things that could have gone wrong with a can of chickpeas. They could have gone bad inside the can. They could have been contaminated, either deliberately or through carelessness. They could have been sitting around so long they have expired. All these things are, at least logically, possible.\nBut these possibilities, while serious, have two quite distinctive features. One is that they are very rare. In some cases they may have never happened. (I’ve never heard of someone deliberately contaminating canned chickpeas, though other grocery products like strawberries have been contamination targets.) The other is that there are few easy ways to tell whether they are actualised. You can scan each of the cans for an expiry date, but it is really uncommon that this is relevant, and it takes work since the expiry dates are normally written in such small type. If a can is really badly dented, I guess that weakens the metal and raises ever so slightly the prospect of unintentional contamination. But it’s common to have shelves full of cans that have no dents, or at most very minor ones.\nGiven these two facts - the rarity of the problems and the difficulty in getting evidence that significantly shifts the probability that this is one of the (rare) problems - the rational thing to do is choose in a way that is insensitive to whether those problems are actualised. Or, perhaps more cautiously, one should be vigilant, in the sense of Sperber et al. (2010), to some of these problems, and ignore the rest. But being vigilant about a problem means, I take it, being willing to consider it if and only if you get evidence that it is worth considering. In the short run, you still ignore the potential problem.\nAnd to ignore a potential problem is to choose in a way that is insensitive to evidence for the problem. That makes sense for both the banknotes and the chickpeas, because engaging in a choice procedure that is sensitive to the probability of the problem will, in the long run, make you worse off.\nIn Kimball’s terms, the rational shopper will have a toy model of the supermarket in which all cans of chickpeas that aren’t obviously damaged are safe to eat. This will be a defeasible model, but on a typical grocery trip, it won’t be defeated. In Joyce’s terms, the small worlds the shopper uses in setting up the decision problem they face will all be ones in which the chickpeas are safe.\nSo the suggestion is that very often, the way to be rational is to have right model in your head, and apply it correctly. A choice is the rational choice in your situation iff it is the recommendation of the right model. And the right model includes just as much information, and just as many complications, as the situation demands. The regress is blocked, on this picture, because you don’t have to have computed, or even be in a position to compute, that the right model is the right model. Here I am following Knight. Rational agents don’t have to have worked through Marshall’s Principles; they just have to think and act as if they had. But crucially, they don’t have to even act as if they are applying the Principles to the world. They could apply them to a good model of the world, and that’s good enough.\n\n\n8 Three Philosophical Postscripts\n\n8.0.1 Idealisation\nThe story I’m telling here about how rational agents use models is very similar, and indeed draws heavily on, the story that Michael Strevens (2008) tells about how scientists use idealisations. On that story, to use an idealisation is to set some messy value to a computationally more simple value (often 0 or 1), and to (implicitly) assert that the difference between the actual value and the computationally simpler value is irrelevant for current purposes.\nOne benefit Strevens gets from this is that he is spared saying that scientists use falsehoods in their reasoning. After all, it is often true that the difference between the messy value and the simple value is irrelevant for current purposes - and that’s all that the scientist is committing to.\nThe same is true in this picture. Frankie Lee can’t know that the banknotes are all equally likely to be genuine; because that’s not strictly true. But he can know that the right model to use in his current situation is one that sets the probability of any note’s genuineness to 1. That’s both true - assuming that our picture of what makes a model right is one that takes deliberation costs seriously - and well supported by his evidence.\n\n\n8.0.2 Epistemic Luck\nOn the story I’m telling, whether decision makers are rational or irrational will often be a matter of luck. This is as you should expect if rationality is a matter of successfully applying a skill. Most skills are not infallible. Being skilled at an activity means one usually succeeds, or at least one succeeds at a higher rate than is normal, but on any given day one could fail. The epistemic failures I call irrationality, even though the person in some sense does the same thing as they do in cases where they act rationally.\nHere is one version of that. Recall the version of the Frankie Lee example where the country has just started modernising its financial system by introducing plastic banknotes. Frankie Lee knows that plastic banknotes are genuine - no one has figured out how to forge them yet. So if some of them are on offer, he should take one. But, let’s imagine, he’s temporarily forgotten this fact. So he takes one of the paper notes. This is irrational.\nBut it’s also bad luck. It’s not normally required that we scour our memories for any relevant information before making a decision like this. Normally, Frankie Lee could have put in this much cognitive effort, and ended up rational. But the world did not cooperate, and he ended up irrational.\nI think any story that connects rationality to succeeding via skill will have the consequence that sometimes whether one is rational is in part a matter of luck. But the possibility of epistemic luck shouldn’t surprise us. Assume that what one should, rationally, do and believe is a function of what one knows. And assume that the right epistemic logic is weaker than S5. Then one won’t always know what one knows. So one won’t always know what one should do or believe. So if one believes what one should, or does what one should, this will be in some sense a matter of luck. And surely the right epistemic logic is weaker than S5. Even if you think the anti-luminosity arguments are bad, and the right epistemic logic is stronger than S4, you shouldn’t think that people know what it is they don’t know. (False beliefs, for example, are typically pieces of non-knowledge that are not known to be not knowledge.) So we shouldn’t be surprised that there is epistemic luck.\n\n\n8.0.3 Knowledge and Rational Choice\nSo my preferred picture of rational action in cases where there are deliberation costs is that the chooser has a model of the decision problem in their head, and they know it is a good model. That’s a constraint on rationality, but it’s also a constraint on knowledge. If the chooser knows that \\(p\\), they can’t be using a model where it might be that \\(\\neg p\\). That, I think, is the core way that practical factors encroach on knowledge - sometimes one is in a practical situation where the best model allows for the possibility of \\(\\neg p\\), and being in such a situation defeats any putative knowledge that \\(p\\).\nBut I used to say something different about how practical factors affected knowledge. I used to say something like the following.\n\nOne knows \\(p\\) only if the rational choice (or choices) conditional on \\(p\\) are the rational choice (or choices) unconditionally for any choice one is considering.\nThe rational choice, either conditional or unconditional, is the one with the highest expected utility, or if there are ties, then all of them are rational choices.\n\nAnd it turns out that combination of views is untenable. This was shown independently twice over, once by Alex Zweber (2016) and then, separately, by Charity Anderson and John Hawthorne -Anderson and Hawthorne (2019). They considered situations like the original Frankie Lee example, and noted that my view had the implausible consequence that Frankie Lee did not know, of each note, that it was genuine. After all, as it stands Frankie Lee should be indifferent between the notes, but conditional on one of the notes being genuine, he should prefer that one. And that’s implausible. Both papers go on to note other implausibilities that purportedly follow, but already we should acknowledge this is a problem. (Whether my view was really committed to the other implausibilities is something I could argue about, but it doesn’t matter because this is already a perfectly good counterexample.)\nThe solution, I now think, is to qualify the second bullet point above. What I should have said instead is\n\nThe rational choice is the one with the highest expected utility on the model that the chooser is rationally using, or if there are ties, then all of them are rational choices.\n\nAnd now the problem goes away. It is rational for Frankie Lee to use the model where all the notes are genuine - it isn’t worth the cost of using a more complicated model. And on that model, conditionalising on the hypothesis that one of the notes is genuine doesn’t change anything. So if Frankie Lee is using that model, he knows the notes are genuine. If he isn’t using that model then he doesn’t know the notes are genuine. But this isn’t because of any pragmatic theory of knowledge - it’s simply that to know \\(p\\) requires one actually take \\(p\\) as given, and Frankie Lee fails that criteria.\nSo cases like Frankie Lee, or David and the chickpeas, are perfectly good counterexamples to the version of epistemic pragmatic encroachment I used to endorse. But they don’t show that pragmatic theories are false in general; they just show I got an important detail wrong. To get these details right we need a better theory of when people (rationally) ignore the details.\n\n\n\n\n\n\n\nReferences\n\nAnderson, Charity, and John Hawthorne. 2019. “Knowledge, Practical Adequacy, and Stakes.” Oxford Studies in Epistemology 6: 234–57.\n\n\nBeddor, Bob, and Carlotta Pavese. 2020. “Modal Virtue Epistemology.” Philosophy and Phenomenological Research 101 (1): 61–79. https://doi.org/10.1111/phpr.12562.\n\n\nCaplin, Andrew, Mark Dean, and Daniel Martin. 2011. “Search and Satisficing.” American Economic Review 101 (7): 2899–2922. https://doi.org/10.1257/aer.101.7.2899.\n\n\nChakravarti, Ashok. 2017. “Imperfect Information and Opportunism.” Journal of Economic Issues 51 (4): 1114–36. https://doi.org/10.1080/00213624.2017.1391594.\n\n\nChernev, Alexander, Ulf Böckenholt, and Joseph Goodman. 2015. “Choice Overload: A Conceptual Review and Meta-Analysis.” Journal of Consumer Psychology 25 (2): 333–58. https://doi.org/10.1016/j.jcps.2014.08.002.\n\n\nCherniak, Christopher. 1986. Minimal Rationality. Cambridge, MA: MIT Press.\n\n\nChristensen, David. 2007. “Does Murphy’s Law Apply in Epistemology? Self-Doubt and Rational Ideals.” Oxford Studies in Epistemology 2: 3–31.\n\n\nConlisk, John. 1996. “Why Bounded Rationality?” Journal of Economic Literature 34 (2): 669–700.\n\n\nDiab, Dalia L., Michael A. Gillespie, and Scott Highhouse. 2008. “Are Maximizers Really Unhappy? The Measurement of Maximizing Tendency.” Judgment and Decision Making 3 (5): 364–70.\n\n\nDylan, Bob. 2016. The Lyrics: 1961-2012. New York: Simon & Schuster.\n\n\nElster, Jon. 1979. Ulysses and the Sirens: Studies in Rationality and Irrationality. Cambridge: Cambridge University Press.\n\n\nGigerenzer, Gerd, and Reinhard Selten. 2001. Bounded Rationality: The Adaptive Toolbox. Cambridge, MA: MIT Press.\n\n\nHarman, Gilbert. 1973. Thought. Princeton: Princeton University Press.\n\n\nIyengar, Sheena S., Rachael E. Wells, and Barry Schwartz. 2006. “Doing Better but Feeling Worse: Looking for the ‘Best’ Job Undermines Satisfaction.” Psychological Science 17 (2): 143–50. https://doi.org/10.1111/j.1467-9280.2006.01677.x.\n\n\nJoyce, James M. 1999. The Foundations of Causal Decision Theory. Cambridge: Cambridge University Press.\n\n\nKimball, Miles. 2015. “Cognitive Economics.” The Japanese Economic Review 66 (2): 167–81. https://doi.org/10.1111/jere.12070.\n\n\nKnight, Frank. 1921. Risk, Uncertainty and Profit. Chicago: University of Chicago Press.\n\n\nLevy, Neil, and Mark Alfano. 2020. “Knowledge from Vice: Deeply Social Epistemology.” Mind 129 (515): 887–915. https://doi.org/10.1093/mind/fzz017.\n\n\nLipsey, R. G., and Kelvin Lancaster. 1956. “The General Theory of Second Best.” Review of Economic Studies 24 (1): 11–32. https://doi.org/10.2307/2296233.\n\n\nMangan, Jean, Amanda Hughes, and Kim Slack. 2010. “Student Finance, Information and Decision Making.” Higher Education 60 (5): 459–72. https://doi.org/10.1007/s10734-010-9309-7.\n\n\nManski, Charles F. 2017. “Optimize, Satisfice, or Choose Without Deliberation? A Simple Minimax-Regret Assessment.” Theory and Decision 83 (2): 155–73. https://doi.org/10.1007/s11238-017-9592-1.\n\n\nNewman, David B., Joanna Schug, Masaki Yuki, Junko Yamada, and John B. Nezlek. 2018. “The Negative Consequences of Maximizing in Friendship Selection.” Journal of Personality and Social Psychology 114 (5): 804–24. https://doi.org/10.1037/pspp0000141.\n\n\nOdell, John S. 2002. “Bounded Rationality and World Political Economy.” In Governing the World’s Money, edited by David M. Andrews, C. Randall Henning, and Louis W. Pauly, 168–93. Ithaca: Cornell University Press.\n\n\nOgaki, Masao, and Saori C. Tanaka. 2017. Behavioral Economics: Toward a New Economics by Integration with Traditional Economics. Singapore: Springer.\n\n\nPapi, Mario. 2013. “Satisficing and Maximizing Consumers in a Monopolistic Screening Model.” Mathematical Social Sciences 66 (3): 385–89. https://doi.org/10.1016/j.mathsocsci.2013.08.005.\n\n\nPingle, Mark. 2006. “Deliberation Cost as a Foundation for Behavioral Economics.” In In Handbook of Contemporary Behavioral Economics: Foundations and Developments, edited by Morris Altman, 340–55. New York: Routledge.\n\n\nReutskaja, Elena, Rosemarie Nagel, Colin F. Camerer, and Antonio Rangel. 2011. “Search Dynamics in Consumer Choice Under Time Pressure: An Eye-Tracking Study.” American Economic Review 101 (2): 900–926. https://doi.org/10.1257/aer.101.2.900.\n\n\nRussell, Stuart J. 1997. “Rationality and Intelligence.” Artificial Intelligence 94 (1-2): 57–77. https://doi.org/10.1016/S0004-3702(97)00026-X.\n\n\nScheibehenne, Benjamin, Rainer Greifeneder, and Peter M. Todd. 2010. “Can There Ever Be Too Many Options? A Meta-Analytic Review of Choice Overload.” Journal of Consumer Research 37 (3): 409–25. https://doi.org/10.1086/651235.\n\n\nSchwartz, Barry. 2004. The Paradox of Choice: Why More Is Less. New York: Harper Collins.\n\n\nSchwartz, Barry, Andrew Ward, John Monterosso, Sonja Lyubomirsky, Katherine White, and Darrin R. Lehman. 2002. “Maximizing Versus Satisficing: Happiness Is a Matter of Choice.” Journal of Personality and Social Psychology 83 (5): 1178–97. https://doi.org/10.1037/0022-3514.83.5.1178.\n\n\nScott, Rose M., and Renée Baillargeon. 2013. “Do Infants Really Expect Agents to Act Efficiently? A Critical Test of the Rationality Principle.” Pscyhological Science 24 (4): 466–74. https://doi.org/10.1177/0956797612457395.\n\n\nShanahan, Murray. 2016. “The Frame Problem.” In The Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta, Spring 2016. Metaphysics Research Lab, Stanford University.\n\n\nSperber, Dan, Fabrice Clément, Christophe Heintz, Olivier Mascaro, Hugo Mercier, Gloria Origgi, and Deirdre Wilson. 2010. “Epistemic Vigilance.” Mind and Language 25 (4): 359–93. https://doi.org/10.1111/j.1468-0017.2010.01394.x.\n\n\nStrevens, Michael. 2008. Depth: An Account of Scientific Explanations. Cambridge, MA: Harvard University Press.\n\n\nTucker, Chris. 2016. “Satisficing and Motivated Submaximization (in the Philosophy of Religion).” Philosophy and Phenomenological Research 93 (1): 127–43. https://doi.org/10.1111/phpr.12191.\n\n\nWilliamson, Timothy. 2000. Knowledge and its Limits. Oxford University Press.\n\n\nWittgenstein, Ludwig. 1953. Philosophical Investigations. London: Macmillan.\n\n\nZweber, Adam. 2016. “Fallibilism, Closure, and Pragmatic Encroachment.” Philosophical Studies 173 (10): 2745–57. https://doi.org/10.1007/s11098-016-0631-5."
  },
  {
    "objectID": "posts/review-gauker/review-of-words-without-meaning.html",
    "href": "posts/review-gauker/review-of-words-without-meaning.html",
    "title": "Review of “Words Without Meaning”",
    "section": "",
    "text": "In philosophy it’s hard to find a view that hasn’t had an ism associated with it, but there are some. Some theories are too obscure or too fantastic to be named. And occasionally a theory is too deeply entrenched to even be conceptualised as a theory. For example, many of us hold without thinking about it the theory that “the central function of language is to enable a speaker to reveal his or her thoughts to a hearer,” (3) that in the case of declarative utterances the thoughts in question are beliefs whose content is some proposition or other, and that hearers figure out what the content of that belief is by virtue of an inference that turns on their beliefs about the meanings of the words we use. These claims might seem too trivial to even be called a theory. They have seemed too trivial to draw an ism. Christopher Gauker calls them ‘the received view’, and the purpose of his book Words Without Meanings (all page references to this book) is to argue against this received view and propose an alternative theory in its place. In Gauker’s theory the primary function of language is social coordination. If language ever functions as a conduit to the mind, this is a secondary effect.\n\nPublished in Notre Dame Philosophical Reviews.\n\nIt is useful to have an ism for everything, so let’s call ‘the received view’ Lockism, since Locke believed something similar. Of course, Locke probably didn’t have any detailed opinions about where the semantics/pragmatics distinction lies or what the role and importance Horn scales might be or how to build a compositional semantics for quantification, or indeed about many of the issues on which various contemporary Lockists have their most distinctive views, but there’s an intellectual legacy worth noting. Still, if Locke was a Lockist without having views on these matters, this starts to suggest how broad, and how divided, the Lockist church may be. Lockists need not agree on the semantic analyses of indicative conditionals or attitude reports. They need not even agree on whether there are such things as conventional implicatures or deep structures. An argument against Lockism will have to either focus on the few rather platitudinous points where Lockists agree, or try to respond to all the ways Lockists might develop their position. Gauker takes both options throughout his book. The central theses of the Lockist position that are attacked concern the nature and contents of beliefs, the nature of logical implication and the status of truth. Gauker’s attacks on Lockist theories of quantifier domain restriction and of presupposition rely more heavily on attacking all the variants of Lockism.\nBut the arguments against Lockism are not necessarily the most important parts of the book. Alongside the criticisms of Lockism, Gauker develops in great detail his own positive theory about the nature and role of linguistic communication. Gauker suggests “the primary function of assertions ... is to shape the manner in which interlocutors attempt to achieve their goals.” (52) Conversations do not take place in a vacuum. Conversants frequently talk because they want something. The world does not always make it easy for us to get what we want, but sometimes at least other people can tell us which ways work best.\nIt becomes crucial to Gauker’s theory here that certain actions are or are not in accord with certain sets of sentences. Given this idea the primary norm of conversation becomes: Say things such that others who act in accord with what you say, and with what else has been said, will achieve their goals. The concept of actions according with (sets of) sentences seems intuitive at first. If my goal is to download the new Matrix movie, then going to stealthatmovie.com is in accord with {‘The new Matrix movie is available at stealthatmovie.com’} while going to moviebootlegger.com, or anywhere else, is not. (These are, by the way, fake site names.) Given this idea of actions according with sets of sentences, we can then define the context, or set of relevant sentences, as the smallest set such that “all courses of action in accordance with it relative to the goal of the conversation are good ways of achieving the goal”. (56) We can then restate the primary norm as: Say things that are in the context. Those sentences will be useful to say, and their negations will be useful to deny. This idea of useful assertability becomes crucial to Gauker’s theory, often playing much the role that a Lockist has truth play. For example, validity gets defined in terms of assertability preservation in all contexts.\nClearly the concept of actions according with contexts given goals is quite crucial, but there’s less explication of it than we might hope. I have some idea what it might mean to say that my going to stealthatmovie.com accords with the proposition that the new Matrix movie is available at stealthatmovie.com, and I have some idea which facts in the world may make this true. But I don’t have as clear an idea about what it means to say this action accords with any sentence. Sentences are just marks on paper, or sound waves. We can be pretty sure that this accord between actions and marks on paper is not a primitive fact about the world. Lockists think that actions accord with sentences because sentences express propositions and some actions accord with propositions. But this isn’t Gauker’s account, and it isn’t clear what is. At one stage Gauker notes that the distinction between actions that accord with a context and those that do not will be primitive relative to the ‘fundamental norms of discourse’, which are the primary focus of Words Without Meanings. That sounds right, and I hope it’s a sign that we’ll see more details about the concept of accord in future work.\nThis issue though is important because there are a few reasons to worry about how the concept of accord will be explicated. First, whatever problems face Lockist theories of meaning, including some of the problems Gauker raises, may recur here. Second, some theories of accord will introduce entities that are functionally just like meanings, so if meaning is a functional concept, as seems plausible, those theories will not end up being theories of words without meaning. Third, as Gauker notes, there are serious epistemological questions about how we could ever learn which actions accord with which contexts relative to which goals. Those who are impressed by Fodor’s arguments for the systematicity of human linguistic competence will probably think these questions raise insuperable difficulty for anything like Gauker’s program. On the other hand, those that are impressed by Gauker’s program will probably find these Fodorian claims overstated.\nWords Without Meaning concludes with three chapters setting out a rather distinctive view of belief. Gauker argues that a complete account of the role of belief ascriptions should be sufficient for a theory of belief. This is not because of a general policy that explaining the talk about something is sufficient to explain the thing in general. Such a policy is not entirely antithetical to Gauker’s overall picture, but it would be hard to defend in all cases. Rather, Gauker argues, in practice we have little use for beliefs and desires other than in our ascriptions of them, so an account of their ascription is all the account we need. Many philosophers will baulk here, because they think folk psychology provides a crucial role for beliefs and desires. Since folk psychology is a crucial part of how we predict the actions of other people, and of how we explain their actions, there is an important aspect of the nature of beliefs and desires that a mere account of their ascriptions will not capture. These philosophers will not agree with Gauker that an “account of the attribution of beliefs and desires is already an account of [their] nature.” (271‑2)\nGauker’s response to these philosophers is to question the explanatory and predictive capacity of folk psychology. He argues first that the explanatory, and especially the predictive, power of folk psychology is much over-rather. And more importantly, he argues that when there do appear to be good folk psychological explanations or predictions, there are equally good explanations that do not appeal to beliefs and desires. The argument for this involves running through several cases with some care, but very roughly the common theme is that beliefs and desires (if they exist) are themselves capable of explanation, so at least most of the time we can replace an explanation in terms of beliefs and desires with one that appeals to the explanations of those very beliefs and desires. This gives us a fairly general strategy for dispensing with folk psychological concepts in explanation and prediction.\nThis does not mean that we adopt an error theory of belief or desire ascriptions. Gauker thinks these have a use, so they are properly assertable. Their role, in general, is to let us speak on behalf of other people. “The primary function of attributions of belief and desire is to extend the range of participation in conversation.” (226) When I say that Harry believes that tech stocks are good investments, I say on Harry’s behalf that tech stocks are good investments. Unfortunately, we never get a complete positive characterisation of when it is permissible to say something on Harry’s behalf. We are told that such assertions, like all assertions, must be relevant to the conversation, but beyond that not a lot. We are told that it can’t just be permissible to say this just in case Harry would be disposed to say it, were he here. Harry might have a habit of keeping his investment ideas to himself, but still believe that tech stocks are good investments. And we’re told that this can be permissible to say even if Harry has never made an ‘inner assertion’ that tech stocks are good investments. But this doesn’t amount to a positive characterisation. Further, it’s not clear how to extend this account to all attitude reports, especially reports of desire-like attitudes. One could truly say Brian wants to play for the Red Sox, but in doing so one is not making a command, or even a request, on my behalf.\nAs well as these intriguing positive proposals, there are several arguments against Lockism. Chapter 2, on mental representation, is an attack on the Lockist position that there are beliefs with propositional content. Gauker first notes that any attempt to provide an atomistic theory of mental content seems to run into insuperable counterexamples. The main focus is Fodor’s asymmetric dependence theory, but a few other atomist theories are raised and dismissed. Gauker suggests that holistic theories are a little more promising, but when we look at the details we see that these all fall to a version of Putnam’s model-theoretic argument. Gauker’s argument here differs from Putnam’s in two key respects. First, it concerns primarily mental content, rather than linguistic content. Second, it has fewer theoretical overheads. Gauker shows that the argument never really needed any complicated mathematics; the formalism in the standard semantics for first-order logic is quite sufficient. Despite those two differences, the argument is fairly familiar, and the moves that could be made in response are also, by now, fairly familiar. Gauker quickly surveys these moves, and notes why he thinks none of them work, but the survey will probably be too brief to convince many who are happy with their preferred reply to Putnam. Those who are not happy with any of the replies to Putnam, or who would be more impressed by a version of Putnam’s argument that did not drift into needless technicality, should enjoy Gauker’s argument.\nThe middle half of Words Without Meanings consists of six case studies designed to show that Gauker’s approach can solve problems that are intractable for Lockism. Three of these are described as being in pragmatics, the other three in semantics. Here Gauker more often has to revert to arguing against each of the different versions of Lockism in the literature, for there are few points of agreement among Lockists once we get to the details on how language works. This is particularly clear when we look at pragmatics. I guess most Lockists agree that there is a pragmatics/semantics distinction, and most of those who do agree think that there is such a thing as scalar implicature. Beyond that there are disagreements everywhere. So Gauker is more often required to argue against all the versions of Lockism in existence. Even if he succeeds against all of them, Lockism is a growing doctrine, and a smart Lockist could often take Gauker’s positive ideas and incorporate them into Lockism. So it’s not clear we’ll see any knock-down argument against Lockism here. But maybe there will be an interesting abductive argument develop, and in any case it is always worthwhile to see Gauker’s positive account. Space prevents a full discussion of many of the issues raised here, but I’ll provide a quick summary of the salient issues, and why Gauker thinks he has an advantage over his Lockist rivals.\nThe first case study concerns domains of discourse, which mostly means domains of quantification. To use Gauker’s example, imagine Tommy runs into Suzy’s room, where Suzy is playing with her marbles, and says “All the red ones are mine.” What determines the domain of Tommy’s quantifier? If it is what Tommy intends, then we might end up saying that his sentence is, surprisingly, true. For Tommy, it turns out, intends only to speak of the marbles in his room, which are as it turns out all his. But if we don’t take it to be what Tommy intends, and instead let the domain be set by what Suzy thinks the domain is, or what a reasonable hearer would think the domain is, then we undermine the Lockist picture that the role of language is for the speaker’s thoughts to be communicated. In these cases it is the thoughts of the hearer, or of a reasonable hearer, seem to determine the meaning of what is said. Gauker suggests it is better to say that the domain is the class of things that are relevant to the goal of the conversation that Tommy and Suzy are having.\nThe second case concerns presupposition. Allegedly, some sentences are such that they cannot be properly asserted or denied unless some condition, the presupposition, is met. Sentences containing factive attitude verbs are sometimes held to fall into this category. So I cannot affirm or deny I regret that you failed the test unless you failed the test. There are several Lockist theories of presupposition, but Gauker argues that none of them can satisfactorily explain how asserting such sentences can inform the hearer of the truth of the presupposition, in this case that the test was in fact failed. Gauker’s theory, which does not have a special category of truth conditions apart from assertability conditions, does not have this difficulty. For a similar reason, however, the Lockist theory that rejects the concept of presupposition also avoids any problem of informative presupposition.\nThe third case concerns Gricean implicature. Gauker notes, correctly, that we can well explain the effects of Gricean implicature without presuming that the hearer even contemplates what the speaker had in mind in speaking. But this kind of contemplation is essential to Grice’s official story. Gauker’s alternative suggestion is that we can explain non-literal communication by assuming the hearer draws inferences about the context from the assertability of what is actually said.\nThe next three case studies are classified as ‘Semantics’, so we might hope that here Lockists will present a more unified target. But two of the studies seem, from a Lockist perspective, to concern the semantics/pragmatics boundary, so again there will be several varieties of Lockism that need to be addressed.\nThe first semantics study concerns quantifiers. Gauker argues that in practice (1) is a bad argument form, (1a) for instance is invalid, while (2) is a good argument form.\n\nEverything is F. Therefore, a is F. 1a. Everything is made of wood. Therefore, Socrates is made of wood.\na is F. Therefore, something is F.\n\nGauker argues in some detail that various Lockist theories of quantifier domain restriction cannot explain the asymmetry here. On his theory, the asymmetry falls out quite naturally, since quantification is always over named objects, and once named an object is relevant. So (1) need not be valid, since a need not have been named, but (2) must be valid.\nThe last two case studies are the most interesting, and the most intricate. I can’t do justice in a small space to the details of Gauker’s theory, but I’ll say a little about the issues raised. Chapter 8 concerns conditionals. Gauker thinks he has a telling argument against a central Lockist claim. The primary intuition is that (3) and (4) are logically equivalent, i.e. each entails the other, (at least when p and q are not themselves conditionals), but they are not equivalent when embedded in longer sentences. In particular, (5) and (6) need not be equivalent.\n\nEither not p or q\nIf p then q\nEither not p or q, or r\nIf p then q, or r\n\nIf this is right, then what Gauker calls ‘the Equivalence Principle’, that substitution of logical equivalent constituents preserves truth-conditional content, is false. Gauker suggests this is a serious problem for Lockism. There are, however, a few Lockist theories in which Equivalence fails. For example, in classical supervaluationism, p or not p is a logical truth, and p is equivalent to p is true, but p is true or not p is not a logical truth. So some Lockists have learned to live without Equivalence. More importantly, the data that suggests that (3) and (4) are logically equivalent isn’t unequivocal. Some Lockists have provided arguments as to why (3) and (4) will usually have the same assertion conditions even though they have different truth conditions. (Gauker notes Robert Stalnaker’s 1975 paper ‘Indicative Conditionals’ that argues for this line.) If those arguments can be made to succeed, then we can keep Equivalence by denying that (3) really entails (4).\nMore interesting than the possible Lockist replies is Gauker’s own theory. He manages, quite impressively I think, to provide a recursive definition of truth conditions for the connectives without keeping Equivalence. The rough idea is that If p then q is true iff p strictly implies q relative to the context. Strict implication theories usually block the inference from (5) to (6), as Gauker’s does, but they also normally block the inference from (3) to (4). In Gauker’s theory, however, because entailment is defined in terms of assertability-preservation, and disjunctions can only be asserted if one or other disjunct is assertable in every possibility left open by the context, the inference from (3) to (4) is valid. Roughly, any contextually salient possibility either contains not p or q, so all the possibilities that contain p contain q, in which case If p then q is assertable. This theory still has some counter-intuitive features, since the paradoxes of material implication are still with us, but it’s a fascinating addition to the literature on conditionals.\nThe final case study concerns truth, and in particular the semantic paradoxes. Gauker argues that extant Lockist responses to the paradoxes are not capable of handling metalinguistic versions of the paradox. In particular, Lockist theories struggle with sentences like (7).\n\n\ndoes not express a true sentence in this context.\n\n\nGauker’s argument that his theory does better than the Lockist here has two parts. First, he has a detailed demonstration that it is impossible to infer a contradiction directly from (7) in his theory. Second, he argues that a Lockist explanation of what’s going on with (7) has to posit that uttering, or writing, ‘this context’ changes the context. This might be true, indeed Gauker endorses a similar claim in his response to the paradoxes. But on most Lockist accounts of what contexts are, we could replace the demonstrative with some other phrase that more directly picks out the context. For example if a context is just an ordered n-tuple, we could just replace ‘this context’ with a description of the n-tuple that is, actually, the context. Here it does look as if Gauker’s theory has more resources than the traditional Lockism. It remains to be seen whether Gauker’s theory is completely free from the paradoxes - it’s quite a bit harder to come up with a consistent theory of truth than it is to block the liar paradox - but again Gauker provides an interesting alternative to existing approaches, and one that experts in the area should pay close attention.\nOverall, what should we make of Words Without Meanings? I think the book has three major aims, and it succeeds in two of them. The first aim is to extend Gauker’s preferred theory of linguistic communication to show how it handles presupposition, quantification, conditionals, attitude reports and truth ascriptions. In this it succeeds quite well, especially in showing how the project holds together technically. The second aim is to raise a host of problems for the Lockist theory, problems that are deserving of serious consideration and response. And again, there is no doubt it succeeds. Even if one thinks that all the problems Gauker raises can be solved, having them set forth so sharply certainly advances the debate. The third aim, the big one, is to convince Lockists that their research program is moribund, and Gauker’s contextualist alternative is the way of the future. That aim, in short, is for a revolution in semantics. (And in any fields that presuppose Lockist semantics. Many of our best syntactic theories have to be revised if Gauker is correct.) Here I think the book is less successful, if only because the aim is so high. It’s not clear how any short book, and the MIT series Words Without Meaning is in is clearly a series for short books, could trigger such a revolution. Lockism may have its weaknesses, and Gauker shines a spotlight on a few, but it’s been a relatively productive program the last fifty years, so overthrowing it will not be easy. Such a revolution would need a longer book, or books, answering among other questions the metaphysical and epistemological questions about Gauker’s concept of actions according with sentences we noted above. Gauker’s work always leaves the impression that he has worked through the relevant material in much more detail than is apparent from a superficial reading of the text, so such books and papers may well be in the pipeline. If one is already on Gauker’s side in these disputes, one should heartily welcome the wealth of detail Words Without Meaning adds to his program. If one is more conservative, more orthodox, one should perhaps be worried about the anomalies rising, but not panicked. At least, not panicked yet."
  },
  {
    "objectID": "posts/tamp/the-asymmetric-magnets-problem.html",
    "href": "posts/tamp/the-asymmetric-magnets-problem.html",
    "title": "The Asymmetric Magnets Problem",
    "section": "",
    "text": "There are many controversial theses about intrinsicness and duplication. The first aim of this paper is to introduce a puzzle that shows that two of the uncontroversial sounding ones can’t both be true. The second aim is to suggest that the best way out of the puzzle requires sharpening some distinctions that are too frequently blurred, and adopting a fairly radical reconception of the ways things are.\n\nPublished in Philosophical Perspectives 20: 479-92.\nImage by oskay via Creative Commons.\n\n\n0.1 Two Theses about Duplication\nIn all of David Lewis’s discussions of intrinsicness and duplication, he held that the two concepts are connected by a tight circle of interdefinition. Duplicates share all of their intrinsic features, and objects that share all of their intrinsic features are duplicates. (Lewis 1983b, 1983a; Langton and Lewis 1998). Both of these claims are a little controversial. One might hold that some impure properties that aren’t shared by all duplicates, like having George Clooney as a part, are nevertheless intrinsic since gaining or losing them seems to amount to a non-Cambridge change (Weatherson 2006). And one might hold that some properties which don’t differ between duplicates by definition, such as being a duplicate of the Louvre as it actually is, are nevertheless extrinsic (Dunn 1990). So maybe Lewis’s tight circle of interdefinition is not beyond question. But the following principle seems utterly uncontroversial to me.\n\nThanks to the Philosophy Program at the RSSS, ANU, where this was first drafted, to audiences at University of Manitoba and Stanford University, and to the attendees at my seminar on David Lewis at Cornell University. I am especially grateful to Ben Caplan, John Hawthorne, Ishani Maitra, Raul Saucedo and Wolfgang Schwarz.\n\nIntrinsicness Principle\n\nIf a and b differ in their pure intrinsic features, they are not duplicates;\nIf a and b have the same pure intrinsic features, then they are duplicates\n\nThat conjunction is the first of our (hitherto) uncontroversial theses. The second needs a bit more work to state formally.\nIt is fairly intuitive that whether two objects are duplicates is not an emergent feature of reality. In some sense, whether two complex are duplicates just depends on the properties of their parts and the relations between their parts. But this claim does turn out to be controversial; David Lewis (1983b) has controverted it. To a first approximation, his theory says that whether two objects are duplicates depends on whether they share the same perfectly natural properties. If there are any perfectly natural properties that are emergent, i.e. which are properties that complex objects have but not in virtue of the properties of or relations between their parts, then whether two objects are duplicates will also be emergent. Now Lewis doesn’t think there are any emergent perfectly natural properties, since the existence of such properties would be incompatible with the thesis of Humean Supervenience. But Lewis doesn’t think that Humean Supervenience is a necessary truth, let alone a conceptual truth, but at best a contingent truth. So the principle that duplication is not emergent is not something that is true in virtue of the concept of duplication.\nStill, nothing in Lewis’s views suggest that the following principle is false. If all the fundamental properties are not emergent, i.e. they are properties that complex things have in virtue of the fundamental properties of and relations between their parts, then duplication is not emergent. We might try and formalise this as follows. If all the fundamental properties are not emergent, then if the parts of x and y are duplicates, then x and y are duplicates. This principle is, however, too strong. It doesn’t account for the possibility that the parts of x and y are arranged differently. For instance, in the following example, the fusion of a and b is not a duplicate of the fusion of c and d, even though a is a duplicate of c and b is a duplicate of d.\n\nThe problem is that the arrangement of the two objects is different. So what we need is a principle that says that if all the perfectly natural properties are not emergent properties, and if the parts of x and y are duplicates, and those parts are arranged the same way, then x and y are duplicates. Saying this formally is not exactly trivial. The following version uses the idea of an isometry1.\n1 An isometry is “a transformation that does not change the distance between points” (Yaglom 1962, 11). That is, it is a function from points to points that doesn’t change distances. Although the isometry is initially defined as a function on points, it can obviously be extended to a function from regions to regions. If r is a region, i.e. a set of points, then f(r) is {f(x): x \\({\\in}\\) r}.Parts Principle\n\nThis principle holds in all worlds in which no fundamental properties or quantities are emergent. If X and Y are sets of material objects, a is the fusion of the members of X and b is the fusion of the members of Y, f is a function X \\({\\rightarrow}\\) Y, and i is an isometry defined on the space that X and Y are in, and the following conditions hold:\n\nFor all x in X, f(x) is a duplicate of x; and\nFor all x in X, if r exactly occupied by x, then i(r)\n\nis the region exactly occupied by f(x), then a and b are duplicates.\n\nThe Parts Principle is not as easy to state as the Intrinsicness Principle, but I think the idea it is expressing is fairly intuitive. Nevertheless, I think the two principles cannot both be true.\n\n\n0.2 Three Distinctions\nThe problem I’ll be focussing on looks rather simple, but it brings out several points that seem to have metaphysical interest. In particular, it highlights the importance of three distinctions that are easy to blur when doing metaphysics. It will make the exposition of the puzzle easier to place these distinctions up front.\nThe first distinction is between features and properties. Most metaphysicians accept that to fully characterise the world, we need to do more than say what exists. As well as saying what there is, we need to say how the things that exist are. It is easy to assume that to do that, we need to say what properties things have. But this need not be correct, or at least it need not be correct if we are looking to characterise the world in the most fundamental way. It might be that the fundamental features of reality are quantities, i.e. features that objects have to different degrees or in different amounts. Properties, like being green are features, but quantities, like mass or velocity are also features, just features that can be instantiated to different degrees or magnitudes. So feature is a more general category than property, and so as to not beg any questions, I’ll talk about intrinsic features and fundamental features rather than intrinsic properties and fundamental properties throughout. My solution to the problem will involve assuming that at least some of the fundamental features of reality are indeed quantities not properties.\nThe second distinction is between fundamental features and perfectly natural features. Fundamental features are features that do not obtain in virtue of other features obtaining. The fundamental features are part of a minimal basis we need for characterising reality. Generally fundamental features are related to other fundamental features by exceptionless laws, though this is not part of their definition. What is definitional is that they are basic and that they provide a basis for characterising the world without redundancy. (As a Humean, I’d also say that there are no necessary connections between distinct fundamental features, but that is a controversial metaphysical thesis, not a defining characteristic.) Perfectly natural features are features that make for primitive objective resemblance between things that instantiate them. By a primitive objective resemblance, I mean an objective resemblance that does not obtain in virtue of sharing more basic (in the limit, fundamental) properties. David Lewis (1983b) assumes, without much by way of argument as far as I can see, that the fundamental features are the perfectly natural features. My solution to the problem will involve rejecting that identity.\nThe final distinction is between the thesis that all the fundamental non-spatiotemporal features of reality are intrinsic properties of points, and the thesis that these features are local features. Jeremy Butterfield (2006) has stressed the importance of this distinction for metaphysics. A feature is local to a point iff it is intrinsic to arbitrarily small regions around that point. For example, the slope of a curve at a point is local to that point, even though it isn’t intrinsic to the point. So locality and intrinsicness can come apart. (This raises interesting questions about, for example, whether it is best to state the thesis of Humean Supervenience in terms of local properties or in terms of intrinsic properties of points.) I’ll say more about the importance of this distinction in section 5.\nI’ve already made use of these distinctions in setting out the principles about intrinsicness in section one. (In particular, it is crucial that the Parts Principle is stated in terms of fundamental rather than perfectly natural features.) Using them we can get to our central puzzle, the Asymmetric Magnets Problem.\n\n\n0.3 The Asymmetric Magnets Problem\nOur puzzle is similar to the spinning sphere, often thought to raise a problem for Humean Supervenience (Armstrong 1980). The similarity is not in respect of its target; the puzzle is meant to be a puzzle for everyone who accepts those two principles, not just the Humean. Rather, the similarity is in that the puzzle is set in a world where there are homogeneous physical objects. Such a world is in many ways quite distant from actuality. But I think such worlds are useful fictions for elucidating the conceptual connections between central concepts in metaphysics. The puzzle is also set in a world with Euclidean spatial geometry. Again this is a fiction, but a useful one for working out conceptual connections.\nIn this world, some of the fundamental features are what we’ll call vector features. (This is a much smaller deviation from actuality.) Vector features are either quantities like velocity the value of which is a vector, or properties like having velocity v, where v is some vector. In particular, the strength and direction of the magnetic field throughout the world is a fundamental feature of the world. I’ll assume that both space-time regions and physical objects can have these vector features, although I’m only going to focus on the field strength and direction at a point in a physical object. Finally, I’ll assume that all of the fundamental physical quantities in the world are local. So there are no fundamental emergent quantities in the world. It might be worried that the last two assumptions are inconsistent, and that vector quantities could not be local. I’ll come back to this worry in section 5.\nSome of the things in this world are magnets. These are homogeneous objects with a uniform non-zero magnetic field throughout. I’m going to represent the magnetic field strength and direction of such a magnet with an arrow pointing towards the north pole of the magnet. The length of the arrow is proportional to the strength of the field.\nThe simplest kind of magnet is a bar magnet, just like the kind I used to play with in primary school. (Apart from being homogeneous of course!) These are cuboids with equal heights and depths, and a long length in the direction of their magnetic field. Suzy is playing with some magnets and, tiring of using her magnets to grab the other childrens’, decides to sharpen one end of each of her magnets for use as a weapon. The teacher notices this, confiscates the weaponised magnets, and lays them out on her desk. Here is what they look like from the teacher’s point of view.\n\nI’ve added the labels.\nEach magnet has one sharp end and one flat end. Each also has one north pole and one south pole. And, of course, each has one end to the right (from the teachers’ point of view) and one end to the left. The distribution of these properties of ends is different in the three cases.\n\nA’s north pole is sharp and to the right.\nB’s north pole is sharp and to the left.\nC’s north pole is flat and to the left.\n\nQuestion: Which of the magnets are duplicates?\nAnswer: A and B, but not C.\nI hope you agree with the answer! If not, let me provide a small argument.\nA and B are intrinsic duplicates because we could ‘line up’ A and B by picking A up, spinning it around, and moving it across a bit. And that’s only possible if the two objects are duplicates. This idea, that objects that can be transformed into one another by simple geometric transformations such as rotation and translation is a very deep part of our conceptual scheme. Consider, for example, Euclid’s proof of proposition 4.\n\nLet ABC, DEF be two triangles having the two sides AB, AC equal to the two sides DE, DF respectively, namely AB to DE and AC to DF, and the angle BAC equal to the angle EDF. I say that the base BC is also equal to the base EF, the triangle ABC will be equal to the triangle DEF … For, if the triangle ABC be applied to the triangle DEF, and if the point A be placed on the point D and the straight line AB on E, then the point B will also coincide with E, because AB is equal to DE. Again, AB coinciding with DE, the straight line AC will also coincide with DF, because the angle BAC is equal to the angle EDF; hence the point C will also coincide with the point F, because AC is again equal to DF. But B also coincided with E; hence the base BC will coincide with the base EF … and will be equal to it. Thus the whole triangle ABC will coincide with the whole triangle DEF, and will be equal to it. (Euclid 1956, 247–48)\n\nAs many mathematicians have pointed out over the centuries, this is not Euclid’s finest moment as a geometer. The idea he’s pushing is clear enough. If ABC and DEF satisfy the assumptions, then you can pick up ABC and place it on DEF, so that the sides and vertices all coincide. Does this prove that the sides and angles in the original triangle are equal? Not really, or at least not without the assumption that picking up ABC and moving it around doesn’t change its side lengths or angle magnitudes. And Euclid hadn’t said anything at that stage of the Elements to justify this assumption.\nSo qua axiomatic geometer Euclid has blundered here. But there is more to life than axiomatic geometry. There is, for instance, metaphysics. And the assumption Euclid is using here is, I think, a sound metaphysical intuition. (If it weren’t, the complaints about this fundamental proof in Euclid would have been earlier, and more frequent, than they actually were.) That intuition is, I think, that intrinsic properties are not, ceteris paribus, changed merely by moving objects around. Of course other things are not always equal; the intrinsic properties of a car are not preserved if you drive it into a wall. But the kind of abstract motion that Euclid is contemplating when he moves ABC onto DEF, or that I’m contemplating when I think about moving B around so it lines up with A, does not destroy intrinsic properties. So that’s an argument that A and B are intrinsically alike.\nOn the other hand, A and B each have a property that C lacks. Their magnetic field points towards their sharp end. This is in some sense a relational property, it is defined in part in terms of two things pointing in the same direction, but it doesn’t seem like a relation between the magnet and anything else. In general, properties that things have in virtue of relations between their parts are intrinsic properties. (It is intrinsic to the earth, for example, that more of its surface is wet than dry, even though this property is defined in terms of a relation.) So this is an intrinsic property of A. And, given the plausibility of the Intrinsicness Principle, that’s a reason to think that A and C are not intrinsic.\n\n\n0.4 The Principles and the Problem\nHere then is our problem. Try to answer the following question given the two principles: Is the direction of a vector feature an intrinsic feature of its bearer or not? If yes, then A and B are not duplicates. If no, then A and C are duplicates. (In fact all three are duplicates, though I won’t prove this.) Neither way does it turns out that A and B are duplicates, but C is not, as we need. The aim of this section is to spell out that little argument in more detail, so we can see how the principles relate to the problem.\nFirst, we’ll assume that the direction of a vector feature is an intrinsic feature of its bearer. We need a way to rigidly denote directions, so we’ll call the direction that the vector in A points d1, and the direction that the vector in B points d2. Since d1 \\({\\neq}\\) d2, A and B differ in their intrinsic properties. By the second clause of the Intrinsicness Principle, it follows that A and B are not duplicates.\nSecond, we’ll assume that the direction of a vector feature is not an intrinsic feature of its bearer. Now we want to show that B and C are duplicates. To do this we’ll use the Parts Principle. All of the fundamental quantities are local, so the Parts Principle applies. Now let the members of X and Y be the point-sized parts of A and C. Let l be the distance from the tip of the pointed end of A to the tip of the pointed end of C. The isometry i is a translation with length l and direction d1, i.e. a function that maps any point to the point that is distance l away from it in direction d1. This isometry maps A onto C. By the first clause of the Intrinsicness Principle, and the assumption that direction is not intrinsic, every point in A is a duplicate of any point in C. So by the Parts Principle, A and C are required.\nThe conclusion is that if we want to say that A and B are duplicates, but A and C are not duplicates, then we can’t hold on to both the Intrinsicness Principle and the Parts Principle.\nI think we should give up the Parts Principle. In particular, we should say that the Parts Principle holds only if all the perfectly natural features of reality are local, and this might fail to hold even if all the fundamental features of reality are local. The need for the distinction between these possibilities is, I think, the main lesson of the problem. But before we get to that conclusion, I want to address an objection to the argument so far.\n\n\n0.5 Two Worries About Locality\nI can an imagine an objection to this argument along the following lines. In the setup of the problem, I said that some of the fundamental features of reality are vector-valued quantities. I also said that all of the fundamental features of reality are local. But these assumptions are inconsistent. Vector properties are not intrinsic properties of points. (Since we’re trying to hold on to the Intrinsicness Principle, we have to accept this.) Hence they are not, in the salient sense, local features of reality.\nI think this objection is sound all the way to the last step. As noted above, we need to distinguish between local properties and intrinsic properties of points. The distinction is common in mathematics, but has not been paid sufficient attention in metaphysics. Jeremy Butterfield’s (2006) is an important exception, one that was very influential on this paper.\nSo it is fair to say that all fundamental features of reality are local if all the facts about the world supervene on facts about the distribution of fundamental features in arbitrarily small regions, plus facts about the spatiotemporal arrangement of those regions. And there is no reason to think that positing vector features as fundamental is inconsistent with the fundamental features being local in this sense. Butterfield argues, persuasively, that velocity properties in Newtonian mechanics are not intrinsic properties of points, but he stresses that this doesn’t mean they are not local in this sense. He is focussing on velocity, and what he says doesn’t immediately translate to all vector properties. (It matters to his argument, for example, that velocities are conceptually connected to the positions of objects at different times, in a way that, for example, magnetic fields are not.) But I think his conclusions are independently plausible. Indeed, the argument from isometry above is an argument for the very same conclusion. So the short version of my reply is to concede that once we’ve allowed vector properties as fundamental, we can’t say that all the fundamental features of reality are intrinsic properties of points and spatiotemporal relations between them, but this is consistent with saying that all the fundamental features of reality are local.\nOnce we’ve said that, however, a different kind of objection becomes salient. It might be thought that if the fundamental features are intrinsic properties of regions not of points, the natural version of the Parts Principle is slightly weaker than as stated. In particular, we should focus our attention to cases where the sets X and Y consist of objects with positive size. Because this weakening flows naturally from the definition of locality, it doesn’t look like an ad hoc weakening. However this weakening does not at the end of the day help to save the Parts Principle. That’s because we can find a different way to divide up A and C into parts of positive size so that the Parts Principle still applies. A sketch of how we’ll (start to) divide up A is here.\n\nThe idea is that we make one large square part, and then divide the rest of A up into infinitely many diamonds. We do this recursively. Note that we start with a triangle whose base is to the left and vertex to the right. We create from this a diamond whose four vertices are the vertex of the triangle, and the midpoints of each of the three sides of the triangle. If we imagine cutting this diamond out of the magnet, we’d be left with two small triangles, each with a base on the left and a vertex on the right. We can do the same trick to create diamonds and (in imagination) cut them out, leaving us with four triangles. Repeat this until we have an infinity of diamonds. The fusion of all these diamonds with the large square will be our original magnet. Moreover, since every part is symmetric around the axis perpendicular to d1, each part will be a duplicate of the corresponding part in C. So the Parts Principle still tells us, falsely, that A and C are duplicates. We have to look somewhere else to avoid the problem.\n\n\n0.6 The solution and its problems\nThe Asymmetric Magnets Problem looks easy. It is easy to say intuitively why A and B are duplicates, but C is not. The reason was given at the end of section three. In both A and B, the magnetic field ‘points’ in the same direction that the physical object does, while in C this is not the case. The difficulty arises when we try and shoehorn this intuition into a formal theory. We need to say that it is intrinsic to the magnet that its magnetic field points the same way it does. And we need to say this without saying that the direction of the magnetic field is itself intrinsic. I know of one way to do this, but it involves some overheads. I’m not going to argue for this at any length here, but I think the difficulty of providing a general solution to the Asymmetric Magnets Problem is one of many reasons to think that we should learn to live with these overheads.\nMy solution starts with Lewis’s definition of duplication. I gave a rough statement of this above; we now need a more precise statement. For Lewis, two objects are duplicates iff there is a mapping m from parts of one to parts of the other that (a) is an isomorphism and (b) for all n-place perfectly natural properties P, and all parts x1, …, xn of the first object, Px1…xn iff Pm(x1)…m(xn). So the objects are duplicates if their parts have the same natural properties, and stand in the same perfectly natural relations. That’s how Lewis’s theory goes; now we have to start adding variations. The first variation is quite radical, but one we have independent reason to make.\nAs John Hawthorne (2006) and David Denby (2001) have argued, Lewis’s theory of properties has difficulties accounting for quantities. Hawthorne notes that if we just take individual mass properties, e.g. having mass 17kg, having mass 42ng etc as perfectly natural, there is no way to state physical laws involving mass, such as the law of gravitation, as simple statements where all predicates denote perfectly natural properties. But the theory of laws in Lewis (1983b) says that all physical laws are simple statements where all predicates denote perfectly natural properties. This is something of a problem. For different reasons, Denby suggests that we take determinables as being perfectly natural. The individual mass properties are perfectly natural, he suggests, but not fundamental. What is fundamental is the determinable, mass, of which they are determinate.\nI think we should make a more radical move in the interests of simplicity. What reason do we have for thinking that the fundamental ways things are are properties rather than quantities or magntitudes? Very little reason, I’d say. Modern physics seems much more concerned with quantities than properties. What properties it is concerned with, such as being positively charged, seem to be derived from more fundamental quantities, such as charge. It would perhaps be convenient for formal semantics if the world had an object-property structure to match the subject-predicate structure of simple sentences. But we have no reason to believe the world will be so accommodating. It might turn out that there are a few fundamental quantities in the world. A quantity is a feature that objects have to different degrees. We can identify each value a quantity takes with a property. (Examples are properties like having mass 17kg.) But that shouldn’t make us think that the properties are metaphysically primary. They might be derived from the quantities. Hawthorne’s and Denby’s arguments push us towards that conclusion, and I’ll show here that assuming quantities are primary helps us state a solution to the Asymmetric Magnets Problem.\nSome quantities take simple values. The values of the mass quantity, for instance, are sufficiently simple that they can be represented by real numbers. But not all quantities are like that. In some cases the values are structured entities, which are composed of a magnitude and some other some other part or parts. Vector quantities are like this. We can naturally think of vectors as structured entities composed of a direction and a magnitude. I’m going to assume, at least for the sake of solving this problem, that any perfectly natural quantity takes values that either are magnitudes (as mass does) or takes values that are structured entities composed, among other things, of a magnitude. (This is an empirical assumption, and it may well not be true. If it is not true, the analysis of duplication below will need to be made more complicated.) For ease of exposition, I’ll say that a function \\(f\\) is perfectly natural iff it maps objects onto values, such that there is some perfectly natural quantity such that for any \\(x, f(x)\\) is the value that quantity takes with respect to \\(x\\). So if the quantity is mass, \\(f(x)\\) is \\(x\\)’s mass. And I’ll say that \\(|f(x)|\\) is the magnitude of this value, in the sense described above. (The notation here is slightly non-standard, since I allow that magnitudes may be negative numbers. For example, if \\(f\\) represents charge and \\(x\\) is negatively charged, then \\(|f(x)|\\) may be a negative number.)\nNow for the definition of duplication. Two objects are duplicates iff there is a mapping \\(m\\) from parts of one to parts of the other that (a) is an isomorphism and (b) for all \\(n\\)-place natural functions \\(f\\), and all parts \\(x_1, ..., x_n\\) of the first object, \\(|f(x_1,\\dots, x_n)| = |f(m(x_1),\\dots,f(m(x_n))|\\). So the objects are duplicates if the magnitudes of each of the natural quantities of each of their parts are the same. This allows that the quantities can vary without loss of intrinsic character, provided there is no variation in magnitude.\nThe Asymmetric Magnets Problem suggests a view on which the directions of vector features are indirectly relevant to the intrinsic nature of objects. ‘Indirectly’ because changing the direction doesn’t change the intrinsic properties of objects. But ‘relevant’ because the direction can matter, as we see when comparing A and C. The definition of duplication in terms of quantities that take structured values allows us to capture this indirect relevance. We’ll do so by defining a feature whose magnitude varies depending on how the object’s shape and the direction of its vector features are coordinated.\nLet \\(f\\) be a function representing some perfectly natural quantity such that \\(f(x)\\) is a vector. That is, \\(f\\) represents some perfectly natural vector quantity. This quantity may or may not be fundamental, though it will be fundamental in the cases under consideration here. Let \\(c\\) be a function that takes an object as input and returns its geometric centre as output. (By the geometric centre of \\(x\\) I mean the centre of mass of an object with the same shape as \\(x\\) and uniform mass density throughout.) Now suppose that the following function is perfectly natural. \\[g(x, y, z) =_{df} \\text{the cosine of the angle between }f(x)\\text{ and the ray from }g(y)\\text{ to }g(z)\\]\nThe motivation for taking this to be perfectly natural (but obviously not fundamental) is that it delivers the right results about the Asymmetric Magnets Problem, and it seems to deliver those results for the right reasons. To see it delivers the right results, just apply the above definition of duplication. Two objects are duplicates iff there is an isomorphism \\(m\\) from the parts of one to the parts of the other such that for all \\(n\\)-place natural functions \\(f\\), and all parts \\(x_1, ..., x_n\\) of the first object, \\(|f(x_1,\\dots, x_n)| = |f(m(x_1),\\dots,f(m(x_n))|\\). To make the discussion easier, we’ll redraw the magnets with some salient parts labelled.\n\nAny isomorphism from A to B that satisfy this constraint has to map A1 to B1, and A2 to B2. And any isomorphism from A to C that satisfy this constraint has to map A1 to C1, and A2 to C2. Now let f be the function whose value is represented by the arrow, and let g be the function defined as above. So if A and B are duplicates, it must be the case that g(A, A1, A2) = g(B, B1, B2). It is easy to verify that since f(A) points in the same direction as the ray from the centre of A1 to the centre of A2, \\(g(\\text{A}, \\text{A}_1, \\text{A}_2) = 1\\), and similarly the ray from the centre of B1 to the centre of B2 points in the same direction as f(B), g(B, B1, B2) = 1. So there is no reason here to doubt that A and B are duplicates. On the other hand, since the ray from the centre of C1 to the centre of C2 is in the opposite direction to f(C), g(C, C1, C2) = -1. So there is no isomorphism from parts of A to parts of C that preserves the value of perfectly natural properties, so A and C are not duplicates, as required.\nI don’t doubt that there are other ways to solve this problem, so I certainly won’t try arguing that this is the only solution. But I think it works, and the reason it works is because the values of natural quantities are structured entities, in this case vectors. Because they have structure, we can use one part of the structure (i.e. the magnitude) in determining what is directly relevant to intrinsicness, and another part of the structure (in this case the direction) in determining what is indirectly relevant. So it’s an important advantage of using quantities rather than properties as the centrepiece of our metaphysics that the values of natural quantities can be structured entities, and having something like structured quantities seems crucial to solving this problem.\nAlthough g is represents a perfectly natural quantity, it does not represent a fundamental quantity. Instead, it represents a quantity whose value supervenes on the distribution of other perfectly natural quantities. So we have to allow that there is a distinction between the fundamental quantities and the perfectly natural quantities. I don’t think this is a cost of the theory; there is no way to capture the idea that directions are indirectly relevant without distinguishing between the perfectly natural and the fundamental, so the Asymmetric Magnets Problem is a reason to make such a distinction. (I’m indebted here to Ben Caplan.)\nWe can reduce the apparent cost of this distinction by noting that one reason we might have for blocking redundant natural quantities does not apply here. (By a redundant quantity, I just mean one that supervenes on the fundamental quantities.) We don’t want to say that disjunctive properties like being grue, that supervene on other natural properties, are perfectly natural. But that’s not primarily because of the supervenience, but because of the fact that grueness doesn’t make for resemblance amongst the things that instantiate it. So at least that reason for caring about redundancy doesn’t apply here. (I’m indebted here to Raul Saucedo.)\nFinally, it is crucial to my solution that A, B and C have these parts. If A, B and C are extended simples, I can’t run the argument I make here. Indeed, if they are extended simples, it looks like they are duplicates by my definition. That seems bad. I think this is a problem that we don’t need to worry about, because this isn’t a real possibility. I’ll concede for the sake of argument that there are such things as extended simples. What I don’t see any need to concede the possibility of are asymmetric extended simples. In general, the way that we deduce that an object has parts is by noting it has different properties at different places. (This point is made in Sider (2003).) I think this is just the right strategy to use, as a matter of necessity. If an object has different properties in different locations, it has different parts in those different locations. So there could not be extended simples that are asymmetric magnets. The case where my theory produces the wrong result is an impossible case.\n\n\n0.7 Wrapping Up\nThis paper has had several ambitions, some loftier than others. The most basic aim has been to introduce the Asymmetric Magnets Problem, and argue that it is going to be hard work for a systematic theory of intrinsicness to account for the facts about the problem. The more profound aims involve tearing apart concepts that metaphysicians often take for granted are interchangeable. My solution to the problem involves distinguishing local features from intrinsic features of points, fundamental features from perfectly natural features, and, most importantly, features from properties. The last of these is I think the biggest point. If we come to believe that quantities, not qualities, are the fundamental ways things are, then quite a bit of metaphysical orthodoxy needs rewriting. Some of that rewriting may be simple; just a matter of crossing out ‘li’ and writing in ‘nt’ in the middle of some words. But changes in fundamental metaphysics tend not to be isolated, and the rewriting project may lead to more wide-ranging changes. (Egan (2004) makes this point well, with an important illustration.) Now I certainly haven’t given anything like a conclusive argument in this paper that we should set about that project immediately. I have, however, provided one reason to think the project will eventually be necessary, and I suspect that more reasons will be provided in the future.\n\n\n\n\n\n\nReferences\n\nArmstrong, David. 1980. “Identity Through Time.” In Time and Cause: Essays Presented to Richard Taylor, edited by Peter van Inwagen, 67–78. Dordrecht: Reidel.\n\n\nButterfield, Jeremy. 2006. “Against Pointillisme about Mechanics.” British Journal for the Philosophy of Science 57 (4): 709–53. https://doi.org/10.1093/bjps/axl026.\n\n\nDenby, David. 2001. “Determinable Nominalism.” Philosophical Studies 102 (3): 297–327. https://doi.org/0.1023/A:1010314926955.\n\n\nDunn, J. Michael. 1990. “Relevant Predication 2: Intrinsic Properties and Internal Relations.” Philosophical Studies 60 (3): 177–206. https://doi.org/10.1007/bf00367469.\n\n\nEgan, Andy. 2004. “Second-Order Predication and the Metaphysics of Properties.” Australasian Journal of Philosophy 82 (1): 48–66. https://doi.org/10.1080/713659803.\n\n\nEuclid. 1956. The Thirteen Books of the Elements, Tr. Thomas l. Heath. New York: Dover.\n\n\nHawthorne, John. 2006. “Quantity in Lewisian Metaphysics.” In Metaphysical Essays, 229–37. Oxford: Oxford University Press.\n\n\nLangton, Rae, and David Lewis. 1998. “Defining ‘Intrinsic’.” Philosophy and Phenomenological Research 58 (2): 333–45. https://doi.org/10.2307/2653512.\n\n\nLewis, David. 1983a. “Extrinsic Properties.” Philosophical Studies 44 (2): 197–200. https://doi.org/10.1007/bf00354100.\n\n\n———. 1983b. “New Work for a Theory of Universals.” Australasian Journal of Philosophy 61 (4): 343–77. https://doi.org/10.1080/00048408312341131.\n\n\nSider, Theodore. 2003. “Maximality and Microphysical Supervenience.” Philosophy and Phenomenological Research 66 (1): 139–49. https://doi.org/10.1111/j.1933-1592.2003.tb00247.x.\n\n\nWeatherson, Brian. 2006. “Intrinsic Vs. Extrinsic Properties.” In The Stanford Encyclopedia of Philosophy (Fall 2006 Edition), edited by Edward N. Zalta. Metaphysics Research Lab, Stanford University.\n\n\nYaglom, I. M. 1962. Geometric Transformations i. Random House: New York."
  },
  {
    "objectID": "posts/mbt/memory-belief-and-time.html",
    "href": "posts/mbt/memory-belief-and-time.html",
    "title": "Memory, Belief and Time",
    "section": "",
    "text": "I know a lot about the past. I know, for instance, that the Chicago White Sox won the 2005 baseball World Series. I remember that’s true. I don’t remember the event. I was in Australia, and it wasn’t on television. I don’t even remember the event of learning that the White Sox won. But I remember that they won. And to remember something is to, inter alia, know it is true. And to know something is to, inter alia, have a rational belief that it is true.\nSo I have a rational belief that the White Sox won the 2005 baseball World Series. In virtue of what is this belief of mine rational? That’s too big a question to answer here, so let’s start narrowing it down. Is this belief rational in virtue of facts about how I now am, or historical facts about me? Call the former view a temporally local theory of rationality, and the latter a temporally extended view. Which of those is correct?\nI’m going to defend the temporally extended view. In this respect I’m following recent work by David James Barnett (2015), though being a philosopher I’ll quibble about his argument, put forward alternate reasons, and so on. But I’m agreeing with his big conclusion.\nAt least, I’m going to agree with a version of that conclusion. I’m an evidentialist about rationality, in a sense that I’ll try to make clearer as we progress through the paper. So it’s natural to convert the core question into a question about evidence, and about evidence acquisition. What is my evidence that the White Sox won the 2005 World Series, and in virtue of what do I have that evidence? Is it the currect fact that it mnemonically seems to me that the White Sox won, perhaps supplemented with some knowledge I have about the reliabiity of my mnemonic seemings? Or is it something more temporally extended? I’m going to argue that it is the latter.\nMy positive view, inspired to some extent by the evidence is knowledge view defended by Timothy Williamson (2000), is that the fact the White Sox won became part of my evidence some time in 2005, and has stayed in my evidence ever since. At the time this belief, and this knowledge, was grounded in further evidence, presumably perceptual evidence of what some computer screen looked like. But I came to know the White Sox won, and this became part of my evidence. An alternative view is that the visual seemings from 2005 are part of my evidence still. That’s what the view of David Lewis (1996) implies. And yet another view is that the content of those perceptions, perhaps that ESPN is telling me the White Sox won, is still in my evidence. I don’t like either of these latter views, but I’m not going to argue about them here. Rather, the focus is on whether evidence is contemporary or historical, and I want to argue for the class of historical theories over the class of contemporary theories."
  },
  {
    "objectID": "posts/mbt/memory-belief-and-time.html#evidentialism",
    "href": "posts/mbt/memory-belief-and-time.html#evidentialism",
    "title": "Memory, Belief and Time",
    "section": "1 Evidentialism",
    "text": "1 Evidentialism\nI’m interested in memory because it raises challenges for the evidentialist theory I’d like to defend. Evidentialism, as we’ll start construing it, says that the doxastic attitudes it is rational to have depend entirely on the evidence one has. This is a version of evidentialism. I’m taking this to be a thesis both about partial beliefs, what are commonly called credences in the philosophical literature, and full beliefs. I have a lot to say elsewhere about the relationship between full and partial belief  (Weatherson 2012), but I won’t be relying on those views here.\nI am construing the ‘dependence’ in the statement of evidentialism rather weakly. It is just a claim that the evidence one has, and the attitudes it may be rational to hold, co-vary. Put another way, the rationality of doxastic attitudes supervenes on one’s evidence, at least throughout worlds similar enough to this one. I am not defending the stronger claim that facts about what evidence one has are always explanatorily prior to facts about what doxastic attitudes it is rational to hold.\nIt is easy enough to imagine epistemologies that aim for this more ambitious, priority, thesis. David Lewis (1996), for instance, suggests we should understand evidence in terms of phenomenal states; two agents with the same phenomenology over time have the same evidence. It’s arguable that facts about phenomenology are metaphysically prior to facts about rationality. So, if one was an evidentialist with Lewis’s theory of evidence, it would be natural to think that facts about evidence didn’t just subvene facts about rationality; the former provided full and perhaps reductive explanations for the latter.\nI hold out no such hope for reductive explanations. Indeed, I’m closer in spirit to the kind of view you might read into Timothy Williamson (2000). As noted above, Williamson holds that one’s evidence is all and only what one knows. This thesis has become known as E=K. The notation here is instructive. It is commonplace to introduce new terms by definition by putting the new term on the left-hand side of an equality sign. \\(A =_{df} B\\) means that \\(A\\) is defined to be identical to \\(B\\), not the other way around. The E=K thesis suggests a form of evidentialism where evidence is in fact explanatorily posterior to rationality. Something is part of one’s evidence in virtue of the fact that one knows it, and arguably one only knows what one rationally believes.\nI’ve been a bit coy in the previous paragraph about what I’m attributing to Williamson, and what I’m just saying can be read into him. That’s because the view Williamson defends is not that rationality has explanatory priority, but that knowledge does. As he says in the first line of his book, his view is “knowledge first”  (Williamson 2000 v). And it’s consistent with ‘knowledge first’ to say that the explanatory relationship between evidence and rationality is complicated and multi-directional. Although I don’t endorse the knowledge first program, I agree with that last conclusion. The explanatory relationship between evidence and rationality is complicated and multi-directional. Evidentialism should not be construed as denying this claim.\nThe other way in which my version of evidentialism is weaker than it may be is that it really is restricted to being a claim about rationality. It isn’t a claim about justification. For all I say here, maybe something other than evidence determines whether a doxastic attitude is justified. For example, it may be that only true beliefs are justified. I don’t think that’s true, but if it is it would be consistent with evidentialism as I’m construing it.\nMore importantly for what follows, evidentialism also isn’t a claim about wisdom. It is very important to keep evaluations of agents apart from evaluations of acts or states. It is attitudes or states that are in the first instance rational or irrational. We can talk about rational or irrational agents, but such notions are derivative. Rational agents are those generally disposed to have rational attitudes, or be in rational states. Wisdom, on the other hand, is in the first instance a property of agents. Again, we can generalise the term to attitudes or states. A wise decision, for instance, is one that a wise person would make. But the wisdom of agents is explanatorily and analytically prior to the wisdom of their acts, judgments, decisions and attitudes. (I think that everything I’ve said in this paragraph is true of ordinary English. But I’m not committed to that, and it doesn’t matter if I’m wrong. You can read this paragraph as stipulating that ‘rational’ is to be used as a term that in the first instance applies to states, and ‘wise’ is to be used as a term that in the first instance applies to agents, and little will be lost.)\nEvidentialism is not a claim about the nature of wise agents. Perhaps a wise agent is one who always has rational attitudes. If so, then evidentialism will have quite strong implications for what wise agents are like. But that connection between wisdom and rationality is far from an obvious conceptual truth. For all I’ve said, it may well be wise to have doxastic attitudes that do not track one’s evidence. That is consistent with evidentialism, provided we understand the relevant situations as being ones where it is unwise to have rational attitudes.\nThe most important recent work on the connection between rationality and wisdom is by Maria Lasonen-Aarnio (2010, 2014a). And I agree with almost everything she says about the connection. The biggest difference between us is terminological. She uses ‘reasonable’ and ‘reasonableness’ where I use ‘wise’ and ‘wisdom’. In my idiolect, I find it too easy to confuse ‘rational’ and ‘reasonable’. So I’m using a different term, and one that, to me at least, more strongly suggests a focus on agents, not states. But this is a small point, and everything I say about the distinction draws heavily on Lasonen-Aarnio’s work.\nFinally, I’m not taking evidentialism to be committed to any kind of uniqueness thesis. It may be that different agents with the same evidence can have different views about p, and both be rational. That’s fine, as long as any agent with just that evidence could have either view about p and be rational. The view is that there’s a function from evidence and attitude to rational evaluation, not that there’s a function from evidence to rational attitude."
  },
  {
    "objectID": "posts/mbt/memory-belief-and-time.html#memoryandtestimony",
    "href": "posts/mbt/memory-belief-and-time.html#memoryandtestimony",
    "title": "Memory, Belief and Time",
    "section": "2 Memory and Testimony",
    "text": "2 Memory and Testimony\nIt’s natural to think about theories of memory by analogy to theories of testimony. Indeed, we see this strategy used in otherwise very different work by Sarah Moss (2012) and David James Barnett (2015). Moss and Barnett have very different views on memory, and very different views on the relationship between memory and testimony, but they both find it worthwhile to situate views about memory in relation to views about testimony. And I will follow this lead.\nFor an evidentialist, there are three interesting classes of theories of testimony. These almost, but not quite, track onto familiar categories of theories in the literature on testimony. I’ll use slightly idiosyncratic names for them, just to indicate that the categories aren’t exactly the same. In all cases, speaker S says that p on the basis of evidence E, and hearer H hears (and understands) the speaker. (And I’ll assume S is a she, and H a he.) I’m going to start with the case where S knows that p, and H has no reason to doubt S’s testimony; we’ll look at the complications that ensue when those assumptions are dropped presently.\nThe classes I’m interested in are divided by their answers to two questions:\n\nIs the evidence that H gets, in the first instance, that p, or that S said that p?\nIf the evidence is only that S said that p, is the fact that S said that p a ‘self sufficient’ reason to believe that p, or does it need to be supplemented?\n\nThe term ‘self sufficient’ is borrowed from Anna-Sara Malmgren (2006), who uses it in describing work by Crispin Wright (2002, 2004), James Pryor (2004) and Roger White (2005). Wright, Pryor and White are primarily concerned with whether perceptual appearances are self sufficient reasons to believe their contents, or they need to be supplemented. That isn’t the focus here; like Malmgren I’m focussing on testimony and memory.\nHere are the three classes of views that you get from the natural answers to those questions.\n\nIndirect Theories of Testimony.\n\nThe evidence is that S said that p, and this is not a self-sufficient reason to believe that p. This class closely corresponds to the class of so-called reductionist theories of testimony. Jennifer Lackey (2008) provides an important recent indirect theory.\n\nDirect Theories of Testimony.\n\nThe evidence is that S said that p, and this is a self-sufficient (though defeasible) reason to believe that p. Many theorists who reject reductionism about testimony endorse what I’m calling a direct theory. C. A. J. Coady (1995) provides an important recent direct theory.\n\nTransmission Theories of Testimony.\n\nThe evidence is that p, so it doesn’t matter how we answer the second question. Frederick Schmitt (2006) provides an important recent transmission theory.\n\n\nTransmission theories need not deny that H also gets the evidence that S said that p. And they need not take a stand on how good that evidence is as evidence that p. And direct theories need not deny that H may have independent evidence that if S says that p, then p is true. But in the other direction, I’m taking it as characteristic of the theories that they deny the core claims of the ones that come after them. So indirect theories deny that H immediately gets evidence that p, or that S says that p is a self sufficient reason to believe p. And direct theories deny that H immediately gets evidence that p.\nThe direct and transmission theories just say that a certain thing is possible. I haven’t said yet what they have to say about when it possible. To make matters a little less abstract, I’ll focus for now on theories that abide by the following constraints.\n\nS saying that p is only reason to believe that p in the absence of evidence against p, and in the absence of evidence against S’s reliability.\nH only gets to add p to their stock of evidence if it was in S’s stock of evidence to start with; testimony doesn’t generate evidence, except for evidence about what is said.\n\nA direct theory that didn’t comply with the first constraint really would be a charter for gullibility. Even with this constraint, direct theories possibly are too gullible, as Elizabeth Fricker (1994) has argued, but without this constraint they certainly are. And a transmission theory that didn’t comply with the second constraint would not deserve the name transmission; it would be a generative theory.\nWe can use these categories to draw three similar categories of memory. Here the case is that M forms a belief that p at \\(t_1\\), and has an apparent memory of p at \\(t_2\\). As we might put it, her memory reports that p at this time. As above, start with the simple case where M knows p at \\(t_1\\), and there is no counterevidence, or reason to doubt her own reliability, at later times. We’ll come back, in great detail, to cases where those assumptions are relaxed. What evidence does M get, in these simple cases, when her memory reports that p, and how good is this evidence?\n\nIndirect Theories of Memory\n\nThe evidence is that M’s memory reports that p, and this is not a self sufficient reason to believe that p.\n\nDirect Theories of Memory\n\nThe evidence is that M’s memory reports that p, and this is a self sufficient reason to believe that p.\n\nTransmission Theories of Memory\n\nThe evidence is that p.\n\n\nThe first two theories are temporally local, in the sense I started with, and the last is temporally extended. Again, we’ll put some restrictions in place.\n\nMemory’s reporting that p is only a self sufficient reason to believe that p in the absence of either evidence against p, or evidence that memory is unreliable.\nMemory only transmits evidence that p if p was genuinely among M’s pieces of evidence at an earlier time. And that requires, I’m assuming, that M knew that p at the earlier time.1\n\n1 As with the transmissive view on testimony, I don’t take it to be essential to the transmissive view that all mnemonic knowledge is transmitted. Perhaps, as Lackey (2005) argues, memory can sometimes generate new knowledge. Even so, as long as it sometimes plays a purely preservative role, the transmissive theory is true.2 Michael Dummett (1994) also defends a transmissive account of memory, though the analogy between testimony and memory is important in his argument. Jérôme Dokic (2001) endorses Dummett’s position on memory.Since I want to defend a temporally extended theory, that means I’m defending the transmission theory. And like Barnett, I do so while rejecting the corresponding theory of testimony.2 But once we set things out this way, we see that there are two distinct temporally local theories, and they fail for slightly different reasons. Before we get to why they fail, we’ll look at a reason for thinking one or other of them must work."
  },
  {
    "objectID": "posts/mbt/memory-belief-and-time.html#shangrila",
    "href": "posts/mbt/memory-belief-and-time.html#shangrila",
    "title": "Memory, Belief and Time",
    "section": "3 Shangri La",
    "text": "3 Shangri La\nThe Shangri La case introduced by Frank Arntzenius (2003) can be used to generate an argument that evidentialists are committed to the temporally local approach to evidence. This isn’t exactly how Arntzenius introduced it; he introduced it as a puzzle for conditionalisation. But the argument I’m interested in is related to the puzzle Arntzenius introduced. Here is how Michael Titelbaum describes the example.\n\nYou have reached a fork in the road to Shangri La. The guardians of the tower will flip a fair coin to determine your path. If it comes up heads, you will travel the Path by the Mountains; if it comes up tails, you will travel the Path by the Sea. Once you reach Shangri La, if you have traveled the Path by the Sea the guardians will alter your memory so you remember having traveled the Path by the Mountains. If you travel the Path by the Mountains they will leave your memory intact. Either way, once in Shangri La you will remember having traveled the Path by the Mountains. The guardians explain this entire arrangement to you, you believe their words with certainty, they flip the coin, and you follow your path. What does ideal rationality require of your degree of belief in heads once you reach Shangri La.  (Titelbaum 2014, 120)\n\nThe name of the person Titelbaum’s narrator is addressing isn’t given, so we’ll call him Hugh. And we’ll focus on the case where Hugh actually travels by the Mountains.\n\n\n\nOriginal Shangri La game; Hugh takes the right-hand path\n\n\nThere is something very puzzling about Hugh’s case. On the one hand many philosophers (including Arntzenius and Titelbaum) report a strong intuition that once in Shangri La, Hugh should have equal confidence that he came by the mountains as that he came by the sea. On the other hand, it’s hard to tell a dynamic story that makes sense of that. When he is on the Path by the Mountans, Hugh clearly knows that he is on that path. It isn’t part of the story that the paths are so confusingly marked that it is hard to tell which one one is on. Then Hugh gets to Shangri La and, well, nothing happens. The most straightforward dynamic story about Hugh’s credences would suggest that, unless something happens, he should simply retain his certainty that he was on the Path by the Mountains.\nAnd you might think evidentialism is committed to the same thing as that dynamic story. To see why, imagine that Hugh is being terrifically sneaky, and wearing a small camera in his glasses. The camera is tracking what he sees, and Laurie is watching it on a distant TV monitor. The guardians can’t do anything to Laurie’s memory, so they don’t, just like they don’t do anything to Hugh. That night, it might seem Hugh and Laurie have the same evidence. Yet, according to some intuitions, it is rational for Laurie to believe that Hugh took the Path by the Mountains, and not rational for Hugh to believe this.\nHere’s a natural way out of that bind. Say that the evidence Hugh and Laurie have does not consist of what they saw as Hugh was ascending, but their current mnemonic seemings. Now their evidence is different. Hugh has the evidence that it seems to Hugh that Hugh ascended via the mountains, and Laurie has the evidence that it seems to Laurie that Hugh ascended via the mountains. And it is common knowledge that in either this world or a nearby one, Hugh’s mnemonic seemings are unreliable, while Laurie’s are reliable in all nearby worlds. So the temporally local theories can handle the problem, while one might think temporally extended theories cannot.\nThe most straightforward way to explain the common intuition about Shangri La is via the indirect theory of memory. On that theory, Hugh won’t know that he came to Shangri La via the mountains. That’s because the report of his memory, “We got here via the mountains, Hugh!”, would be the same however he came up, and Hugh knows it. There is no basic entitlement, on this theory, to move from My memory says that p to p, and since Hugh does not even believe that a correlation obtains in practice between what he believes about his method of ascent and how he actually ascended, there is no earned entitlement.\nIt is a little tempting to read some of the published arguments that Hugh can’t know he came via the mountains as reasoning in just this way. Here is Arntzenius’s central argument. (Assume Arntzenius is talking to Hugh here, so ‘you’ picks out Hugh.)\n\nFor you will know that he would have had the memories that you have either way, and hence you know that the only relevant information that you have is that the coin was fair.  (Arntzenius 2003, 356)\n\nSarah Moss (2012) makes a similar claim about the case. (Again, her narration is addressed to Hugh.)\n\nIntuitively, even if you travel on the mountain path, you should have .5 credence when you gets to Shangri La that the coin landed heads. This is a case of abnormal updating: once you arrive in Shangri La, you can no longer be sure that you traveled on the mountain path, because you can no longer trust your apparent memory.  (Moss 2012, 241–42)\n\nNow it isn’t immediately clear why the fact that Hugh would have the same apparent memories in the two cases should matter. As far as I can see, the only way it could matter is if the following two things were true. First, we are using a temporally local theory, so the evidence is what Hugh’s memory reports when he is in Shangri La, not the evidence he acquired on the trip up the mountain. And second, what those appearances support is solely a function of things internal to the agent, and not, say, their connection to the truth. As an evidentialist, I’m committed to a version of that second assumption - at least, I’m committed to saying that things that over-ride evidence must themselves be evidence.\nLet’s focus for now on the assumption of temporal localism behind the arguments here. I’m going to offer a series of arguments against it, starting with a variant on the Shangri La case."
  },
  {
    "objectID": "posts/mbt/memory-belief-and-time.html#iteratedshangrila",
    "href": "posts/mbt/memory-belief-and-time.html#iteratedshangrila",
    "title": "Memory, Belief and Time",
    "section": "4 Iterated Shangri La",
    "text": "4 Iterated Shangri La\nHere’s a slightly more complicated variant of the Shangri La example.\n\nSati walks up to the base of the paths to Shangri La. “Have some toast and yeast extract,” says one of the attendants, somewhat stiltedly.\n“Yeast extract?” says Sati.\n“Yes, yeast extract. Vegemite or Marmite, your choice.”.\n“Must I?” says Sati.\n“You must.”\n“Well, Vegemite then,” says Sati, recalling fond memories of having Vegemite in Australia, and dire memories of that trip to the English countryside.\n“Good choice,” says the attendant. Sati has her Vegemite on toast, and heads up the mountain path to Shangri La, as directed. On the way, she notices a worried looking person standing in front of a priest about to flip a coin. When she gets to Shangri La, she asks the attendant about that.\n“Oh,” says the attendant, “he chose Marmite.” Sati looks confused as to why this is relevant, so the attendant continues. “The priests don’t like people who choose Marmite, but they still must let them through. So they flip a coin to decide whether they will go by the sea or the mountains. Then, if they went by the sea, they will wipe the memory of that trip, and replace it with a memory of going through the mountains.”\n“I’m glad that didn’t happen to me. Lucky I chose Vegemite.”\n“Recently,” continued the attendant, “the priests decided to make things more complicated. They decided they would also wipe the memory of having eaten the Marmite, and hence facing the coin flip. Instead they would implant a false memory of having chosen Vegemite, indeed false memories of having preferred Vegemite to Marmite in the past, plus a false memory of seeing some other poor sap facing the coin flip. They really really don’t like Marmite eaters.”\n“So all the Marmite eaters get memories wiped?” asked Sati.\n“No, only if the coin lands the wrong way. So some people get to the top thinking they liked Marmite. But we only tell that memories of going by the sea will be wiped. In fact, knowing they chose Marmite is evidence they went by the Mountains, but they don’t know that.”\n“It all sounds horrible,” says Sati. “I’m so glad I remembered I liked Vegemite more than Marmite.”\n“Have a good day!” said the attendant, grinning.\n\nI think that Sati’s last statement is correct; she does remember that she likes Vegemite more than Marmite. Indeed, she knows this in virtue of her memory. But it’s not clear how a temporally local theory, either direct or indirect, can get that answer.\nImagine someone, call him Joe, who starts off in the same situation as Sati at the base of the mountain. Sadly, due to an unfortunate unbringing, he prefers Marmite to Vegemite, so he takes that. And then the coin lands the wrong way, and he is sent by the sea. Then his memories are wiped and replaced with fake memories when he gets to Shangri La.\n\n\n\nRevised Shangri La game; Sati takes the right-hand path, Joe the left- hand path\n\n\nIf a temporally local theory is correct, then presumably Sati and Joe have the same evidence. And that means if evidentialism is true, then it is rational for them to believe the same things. Yet that is implausible; Joe should not be very confident that he had the Vegemite, came by the mountains, and so on.\nOn the other hand, it is overdetermined that Sati can know she came by the Mountains. The crucial difference between Sati and Hugh comes from the defeasibility conditions on the transmission theory. Past memories that p transform into current evidence that p unless they are forgotten, or the agent gets some good reason to suspect that her memory is unreliable. Hugh has such a reason; he is a coin flip away from having faulty memories. Sati does not have such a reason. She knows that had she had a very different kind of upbringing, and had she been on the bad end of a coin flip, she would have had faulty memories. But a reason to think that had things been different she would have reason to distrust her memories is not, itself, a reason to distrust her memories.\nSati’s case is not meant to be a close call. There are lots of relevant ways in which her case is different to cases in which the defeasibility clause is triggered. The fact that two different kinds of things need to have gone wrong here is relevant. And the fact that the first requires things going wrong for a long long time into the past is relevant. And the fact that the first is only a problem in very different possible worlds to actuality is relevant. In short, any plausible kind of defeasibility condition whatsoever on the transmission theory will mean that Joe’s memories of going by the sea are not transmitted, but only an implausibly strong defeasibility condition will prevent Sati’s memories from being transmitted.\nNote that I have not said that Sati can trust her memories because the probability of them being unreliable is so low. That is not the way to formulate defeasibility conditions. The sense of probability that is relevant here is evidential probability. And evidential probability is, as the name suggests, explanatorily posterior to evidence possession. We should not use evidential probability in our theory of what evidence the agent has. Sati knows she grew up liking Vegemite, despite the Shangri La shenanigans. But that’s not because it is so improbable that she had her memories wiped. Rather, it is improbable she had her memories wiped because she knows she does not meet the conditions under which memories are wiped.\nSo temporally extended theories can distinguish Sati’s case from Joe’s, as intuition requires that they be distinguished. But temporally local theories seem to have a problem here. Perhaps the problem here is not with the theory of mnemonic evidence that the the temporally local theories hold, but with evidentialism. Perhaps, that is, this is a case where we should say that Sati and Joe have the same evidence, but that this evidence supports different beliefs given the different reliability of their memories.\nBut there is little to be said to motivate such a theory. If we aren’t going to be evidentialists, it isn’t clear what the relevance of a theory of evidence is. And if we are going to say that historical events, like the fact that Joe’s memories were wiped and Sati’s weren’t, are relevant to contemporary rationality, it isn’t clear what we gain by having a temporally local theory of evidence. Either way, we have said that the existence of past events is relevant to the rationality of current beliefs. At this point we aren’t engaged in much more than a terminological dispute with the temporally extended theories."
  },
  {
    "objectID": "posts/mbt/memory-belief-and-time.html#againstindirecttheory",
    "href": "posts/mbt/memory-belief-and-time.html#againstindirecttheory",
    "title": "Memory, Belief and Time",
    "section": "5 Against Indirect Theory",
    "text": "5 Against Indirect Theory\nAs Matthias Steup (2013) argues, the indirect theory of memory is implausible. It says that when one remembers that, say, the Chicago White Sox won the 2005 World Series, there are two things that are needed in order to ground the rational belief. The first is the apparent memory, and the second is some kind of reason to think that the memories are reliable. But the only reasons we could have for believing the second comes from what we have learned about the track record of memory, or perhaps of the role of memory in human functioning. And we couldn’t be rational in believing those things unless we could rationally rely on memory in forming beliefs. So we can never rationally form any belief on the basis of memory unless we antecedently have reason to trust memory. And that, plus the indirect theory of memory, leads to a vicious regress, and hence to an implausible scepticism.\nThe argument here is similar in form to an argument that has often been levelled against the indirect theory of testimony. This argument traces back at least to Coady (1995). The argument is that children can rely on testimony to get knowledge, and hence rational belief, but they don’t have the information or the cognitive capacity to rationally judge who is and isn’t reliable. So it can’t be, contra the indirect theorist, that such judgments of reliability are required in order to get rational belief and knowledge from testimony.\nOne problem with such an argument in the case of testimony is that it has relied, historically, on a very impoverished view of the cognitive capacities of young children. It is true that the capacity shown for explicit reasoning by children is often very weak. But they have rather amazing capacities for implicit reasoning, and there isn’t any reason to think they could not judge and track reliability of informants.3\n3 On children’s capacities to learn, see Saffran, Aslin, and Newport (1996; Saffran, Newport, and Aslin 1996) and Gopnik et al. (2001). For applications of this directly to the judgments of credibility, see among many others, Koenig, Clément, and Harris (2004) and Harris and Corriveau (2011). Jaswal, McKercher, and VanderBorght (2008) show that children don’t just track credibility of informants, they trade off credibility of informant against credibility of what is currently being said. In general, the lesson from the last 10 to 20 years of research is that children have more than enough capacity to perform the cognitive tasks that indirect theorists require of them.The issue here is not capacity, it is information. No matter how much capacity you have, you can’t make rational judgments about the reliability of memory without information about memory. And you can’t have that information without being able to use memory. That’s the key problem.\nWe can use this idea to strengthen the arguments in the previous section about Sati. If the indirect theory of memory is wrong, we have to be a bit careful about why Hugh can’t know he came by the mountain path. It can’t just be that he lacks a reason to think his memories are reliable. Rather, it must be that what he was told at the bottom of the mountain is a reason to think his memories are not reliable. It must be the presence of reasons to doubt memory, not the absence of reasons to trust, that is doing the work.\nAnd, as noted, this is a big difference between Hugh’s case and Sati’s. Sati does not have any positive reason to doubt her memory. She is several steps removed from the situation where her memories would be in doubt. It’s true that her mnemonic beliefs are insensitive to the truth in a certain way. Arguably, the nearest world in which she came to Shangri La by the sea is one where she still believes she came by the mountains. But any kind of defeasible, direct theory of memory will allow for some rational but insensitive belief.\nAssume that our theory says that S can rationally use her memory to believe that p unless defeaters D are triggered. And S uses her memory to (accurately) remember \\(\\neg D\\). That is, she remembers that she is not in a situation where those defeaters are triggered. Presumably if D were true, her memory would be unreliable; that’s what makes D a defeater. So there isn’t any reason to think that this mnemonic belief in \\(\\neg D\\) is sensitive; she may well still have had it were D true. But the direct theory implies this doesn’t matter, and the direct theory is the only theory on the table given that the indirect theory leads to implausible scepticism.\nCould it be that Sati should not trust her memory because she is, and she knows she is, in a class of people whose memories are unreliable? Well, the mere fact that she is in such a class is not interesting. She knows, after all she is a member of the class consisting of her and all people with unreliable memories, and the memories of that class are as a group unreliable. But that’s not a reason to distrust her memory. Or, at least, it can’t be on pain of scepticism. What must matter is that she is in such a class, and it is epistemologically significant. But the significant class around here seems to be the class of people whose memories have been erased, or who have reason to suspect their memories have been erased. And that doesn’t include Sati. She knows she likes Vegemite, and has for a long time, and she knows that only Marmite-likers in Shangri La had their memories erased.\nHere’s what is true of Sati. She is, right now, phenomenally indistinguishable from a possible person whose memories are unreliable. But why should that matter? We all know brain in vat cases are possible, and each of us is phenomenally indistinguishable from such an unreliable ‘person’. But that isn’t on its own grounds for doubt about memory. All that she learns from the attendant is that another kind of brain in vat case is possible. But she knew they were possible all along. The case isn’t actual and, unless we come up with a trigger for the defeater in the theory of memory, she has no reason to think it is actual."
  },
  {
    "objectID": "posts/mbt/memory-belief-and-time.html#argumentfromapriority",
    "href": "posts/mbt/memory-belief-and-time.html#argumentfromapriority",
    "title": "Memory, Belief and Time",
    "section": "6 Argument from A Priority",
    "text": "6 Argument from A Priority\nThere is another argument against the temporally local theories, and against both the direct and indirect theories, that we can derive from the work of Tyler Burge (1993, 1997). (I should note that there is considerable dispute about how best to interpret Burge. I’m not claiming that what follows is the best interpretation, or the only interpretation, just that it is an interesting argument inspired by, and quite arguably contained in, his work.)\nTamati is doing a proof. At one stage in the proof he appeals to Fermat’s Little Theorem, which says for any natural number \\(n\\), and any prime \\(p\\), \\(n^p \\equiv n \\text{ (mod } p)\\). Using this theorem, Tamati completes his proof, and derives a nice result \\(M\\). Intuitively, Tamati has not just come to know \\(M\\), but he has come to know \\(M\\) a priori.\nBut assume, now, that either kind of temporally local theory is true. At one stage of the proof, Tamati had to, at least implicitly, reason as follows. It seems to me that I remember that \\(n^p \\equiv n \\text{ (mod } p)\\), so (perhaps with an extra premise), \\(n^p \\equiv n \\text{ (mod } p)\\). And that can’t be a priori reasoning, since the premise about how things seem to Tamati is contingent and a posteriori. If the indirect theory of memory is right, the extra premise needed about the reliability of Tamati’s memory will also be contingent and a posteriori.\nIt would be a very strange and revisionary theory of the a priori to say that any proof is not a priori if it relies on remembered theorems without, perhaps, memory of the proof of that theorem. The proof of Fermat’s Little Theorem isn’t difficult, but it does go through several steps. It is hard to keep the whole proof in mind at once. Even proving it, that is, requires a little memory. On the temporally local theory, it isn’t clear that it could ever be a priori knowable for any normal person. And any theorem that required using it would similarly be a posteriori.\nPerhaps it could be said that Tamati’s reasoning is a priori because it doesn’t rely on sense perception, only on perception of how things seem to Tamati. But some such perception of how things seem yields a posteriori knowledge. If Tamati has a headache, and notices this at the same time he remembers Fermat’s Little Theorem, he gets a posteriori knowledge of the contingent truth that he has a headache, and a priori knowledge of the necessary truth of the theorem.\nIn short, a transmissive theory of memory is required to get the result that Tamati gets a priori knowledge of the mathematical theorem. As Burge argues, a transmissive theory of testimony gets the exciting result that when Tamati goes on to tell his friend about \\(M\\), the friend gets a priori knowledge of \\(M\\) as well. If one thinks it is intuitive that the friend’s knowledge is a priori, that’s a good reason to favour a transmissive view of testimony. But that the friend’s knowledge is a priori is not as intuitively obvious as that Tamati’s knowledge is a priori, so it isn’t obvious we must treat memory and testimony the same way here.\nI’ll end this section with a note about the dialectic. What would the argument of the paper lose if the arguments of this section didn’t work? This is an important question because of arguments, such as those by Daniele Sgaravatti (2012, Ch. 3), that the a priori/a posteriori distinction can’t do the epistemological work that it is traditionally taken to do. The answer is that we’d lose one of the best arguments against the direct version of the temporally local theory, while the argument against the indirect version would not be significantly affected.\nAssume for now that one is happy with Tamati’s knowledge, and indeed all non-trivial mathematical knowledge, being a posteriori in this way, because it relies on mnemonic knowledge about one’s earlier self. There is still the question of how one gets from this knowledge about one’s earlier self to knowledge of mathematics. On this indirect theory, this goes via reasoning about the reliability of one’s earlier self. But that reasoning will have to use some non-trivial mathematics, and we’ll be back in the kind of circle we warned about in the previous section. On the direct theory, this won’t be a problem, since there isn’t any challenge in getting from I have an apparent memory that p to p. That inference is perfectly sound, as long as one lacks reasons to distrust it. It is still, I think, puzzling that we have to analyse mathematicians as reasoning this way, and generating a posteriori knowledge. But they key dialectical point is that sense of puzzlement is only relevant to thinking about the direct version of the temporally local theory; the indirect version is beset by a host of further and more serious problems."
  },
  {
    "objectID": "posts/mbt/memory-belief-and-time.html#argumentfromlaundering",
    "href": "posts/mbt/memory-belief-and-time.html#argumentfromlaundering",
    "title": "Memory, Belief and Time",
    "section": "7 Argument from Laundering",
    "text": "7 Argument from Laundering\nThe arguments involving Sati and Tamati were designed to show that not all rational mnemonic belief relies on inference from the existence of a current mnemonic seeming. But neither argument suggested that there was anything wrong with such inferences. It is fully compatible with what I said about both Sati and Tamati that they could also try to infer from how things seem to them to facts about how they got to Shangri La, or about modular arithmetic.\nBarnett’s argument for a temporally extended view takes the opposite tack. He thinks there is something problematic about these inferences, or at least a special class of them. And because of this, he infers that the inference from present seeming can’t be explanatorily important. And that gets him to a version of a temporally extended theory.\nSo what’s the problem? Here’s the schematic case that he focusses on.\n\n\nTwo Beliefs\n\nOn Monday you came to believe that \\(p\\) for good reasons that justified your belief, and on Tuesday you came to believe that \\(q\\) for bad reasons that failed to justify it (where \\(p\\) and \\(q\\) are independent). It is now Wednesday, and you have forgotten nothing, reconsidered nothing, and learned no new relevant evidence. You recall each conclusion without occurrently recalling your original reasons for those conclusions.  (Barnett 2015, 15)\n\n\n\nAgain, it’s a bit of an annoyance to use ‘you’, especially since you, dear reader, would not do anything so foolhardy as come to believe \\(q\\). So let’s assume Barnett’s narration is directed at Kim. And the question is, is Kim’s belief that \\(q\\), on Wednesday, rational? Assume, to make the case most interesting, that this mistaken inference to \\(q\\) is completely out of character. Kim is, and knows he is, a very reliable processor of information, who rarely makes this kind of mistake.\nThe worry is that any temporally local theory will say that Kim’s belief on Wednesday is rational. After all, Kim has an apparent belief that \\(q\\), and not only lacks evidence of his unreliability, but knows he is reliable. Great! But, intuitively, his belief doesn’t go from being irrational to being rational just by the passage of time. It can’t get its irrationality laundered out in this way.\nBut it isn’t clear how big a problem this really should be. Note that Kim is supposed to have forgotten nothing. So the evidence on which \\(q\\) was based is still there. Now allow the temporally local theory a principle that they should want on independent grounds. That principle is that evidence screens judgment; the evidential force of the fact that an agent made a judgment is completely screened, for that agent, by the evidence the judgment was based on.4 I just stated that principle sychronically, so it doesn’t immediately have implications for Kim’s case. But it is plausible to say that as long as the judgment remains, its evidential force is screened off by the evidence it was based on.\n4 I haven’t actually defended this in print yet, but it is correctly attributed to me by Sophie Horowitz (2014, 25).Now whether one has a direct or indirect theory, Kim is not obviously compelled to hold on to her belief that \\(q\\). And whether or not one believes the screening principle, the fact that Kim has forgotten nothing means that there is no symmetry between the cases of \\(p\\) and \\(q\\). The relevant evidence is different in the two cases. The only theorist who has a challenge here is one who thinks that only occurrent states are evidence, and that is a particularly implausible addition to the indirect theory.\nBarnett’s case is different in a couple of respects than an example Gilbert Harman (1986, Ch. 4) uses to draw rather different conclusions. Working through the differences between them allows us to see something interesting about rational dilemmas, even if it isn’t immediately relevant to the debates about memory.\nIn Harman’s example, Karen first draws a conclusion \\(q\\). This is actually rational for her to draw given her evidence, but her evidence was extremely misleading. She then forgets why she came to believe \\(q\\), and gets new evidence that would show her the old evidence was misleading. But since she doesn’t remember why she believed \\(q\\), she doesn’t know that this new evidence affects her grounds for belief in \\(q\\), and retains the belief.\nHarman says that this is rational. Karen isn’t required to keep track of her evidence for each thing she believes. That seems right. It is hardly a rational failing of mine to not remember precisely why I think that the White Sox won the 2005 World Series; I don’t need to keep that level of detail in mind. And if Karen does not do that, she can’t be expected to adjust her beliefs when the evidence that, unbeknownst to her, they are based on is undermined.\nHarman thinks that our original intuition about Karen’s case is that her belief in \\(q\\) is irrational once it has been undermined. But he also thinks reflection on real life cases like Karen’s shows this intuition to be mistaken. The lesson he draws from this is that something like the direct theory is right; Karen can trust her memories unless she has a special reason to doubt them, even if in fact she couldn’t put together a positive argument for their reliability.\nBarnett’s case of Kim is different than Harman’s case of Karen in two respects. Kim retains his evidence; Karen loses hers. And Kim makes an irrational mistake; Karen is rationally misled by misleading evidence. Are those differences enough to think we should treat the cases differently? Or should we be worried that Karen’s case, like perhaps Kim’s, is one where intuition is not a reliable guide?\nI don’t actually have a firm view on this. The differences are significant. Harman himself thinks that the intuition in Karen’s case is driven by the mistaken assumption that Karen will track and retain her evidence. That’s not true in normal cases like Karen’s. But it is true, by stipulation, in Kim’s. So that is one big reason for treating the cases differently. Still, I do worry a little that we’re drifting into areas where intuition is unreliable.\nTo make that worry a little more concrete, consider this argument for the conclusion that Kim’s belief in \\(q\\) is actually rational.\n\nIt would be irrational for Kim to re-open inquiry into whether \\(q\\), given that it was settled, and no new evidence has come in.\nIt would be irrational or impossible for Kim to intentionally forget \\(q\\).\nKim cannot change his attitude to \\(q\\) without either re-opening inquiry into whether \\(q\\), or by forgetting \\(q\\).\nThere is some rational attitude towards \\(q\\) that Kim can take.\nSo, Kim is rational to retain belief in \\(q\\), since any other possible path would involve irrationality of some kind.\n\nPremises 2 and 3 aren’t, I think, particularly controversial, especially if ‘inquiry’ is read so broadly that any re-evaluation of \\(q\\) counts as re-opening inquiry. The issues are premises 1 and 4. Premise 4 is a no dilemmas principle. We’ll return to it later, though in this context it is notable that Barnett himself endorses it, as do many other epistemologists.  (Barnett 2015, 10)\nThe big issue is premise 1. I think it is true. It is a mistake to go around constantly reconsidering things that one has settled. Once a decision has been reached, it should be held, unless a reason comes along to reconsider it. That reason may be evidence that the decision was faulty, or reason to think the decision was badly made. But the mere passage of time is not a reason to reconsider, and nor is the fact that if inquiry were (properly) conducted, it would yield a different conclusion.\nThe picture I’m putting forward here owes a lot to Richard Holton (1999, 2009, 2014), as well as to a related idea due to Crispin Wright (2004). Holton argues that if one has an intention, rationality requires one to maintain that unless a good reason comes along to reconsider it. The fact that one would not form the intention again were one to reconsider it is not, he thinks, itself a good reason. Strikingly, he says that even in Kavka’s toxin puzzle  (Kavka 1983), the agent who intends to drink the toxin should not reconsider, because they have no reason to do so.  (Holton 2009, 162–65). And he suggests that we should think of belief along similar lines  (Holton 2014). To believe something is to commit to its truth, and we need a positive reason to give up our commitments. Wright argues that the sceptic tries to lure us into opening inquiries we can tell will not be completed. We should resist the lure. We have no reason to open the broad ranging inquiry into our own competencies that the sceptic wants us to hold, and good reason to avoid it.5\n5 Sue Hamilton (2001, 78) says that this idea, that it is wrong to open an inquiry you know you can’t complete, plays a central role in the epistemology of the important Nyāya philosopher Gotama. The discussion of forecasting in Tetlock and Gardner (2015) might cast doubt on whether the kind of conservatism I’m endorsing here is empirically sound. There is a suggestion there that people who tinker with their credal states more frequently end up with more accurate credences. This is a topic that deserves revisiting as more data comes in.We can perhaps motivate the application of these ideas to cases like Kim’s by thinking of a similar case involving action.\n\nNed has been thinking about buying a new bed. He is deciding between a wood bed and a metal bed. And he just decided to get the wood bed. This is a bad mistake. He will like the metal bed much better, and this is in fact clear from the evidence available to Ned. But he’s made up his mind. The wood bed store is five miles east, the metal bed store is five miles west. And there’s Ned in his car, driving eastward. What does rationality require of Ned now?\n\nI think Ned’s in a rational dilemma. It is irrational to drive to the wood bed store and buy a wood bed. He won’t like it, and it is predictable that he won’t. What a mistake. But it is irrational to reopen inquiry. He’s made up his mind, and now he should focus on the road. He hasn’t received any new evidence about the qualities of the bed, or any reason to think he mis-evaluated the old evidence. And we can’t go around second guessing our past decisions all the time. That includes those of us (presumably all of us) who make mistakes. It is irrational to be fickle.\nSo what can Ned rationally do? The arguments of the previous paragraph suggest he’s in a rational dilemma. If you want to act rationally, you shouldn’t start where Ned is. If he keeps driving to the wood bed store, he’ll irrationally buy a sub-optimal bed. If he thinks again about the issue, he’ll be irrationally fickle. Rationality requires something that is practically impossible; changing his mind about what to buy without re-opening the issue of what to buy.\nThis is a dilemma for Ned, but it is one he could have avoided. He could have not made the mistaken decision in the first place. It may or may not be unfair if rationality makes incompatible demands on an agent without any chance to avoid them. But it isn’t unfair to think that agents who make mistakes at \\(t_1\\) are, in virtue of those mistakes, left without any good options at \\(t_2\\). Mistakes have consequences.\nIs this inconsistent with evidentialism? I said above that evidentialism says the rational status of a belief supervenes on the evidence that the agent has. Yet now I’m saying Ned is irrational to change his mind. But if he had, with the very same evidence, believed that he should get the metal bed, that would have been rational. This looks like a counterexample to evidentialism.\nHere’s why it isn’t a counterexample. What is irrational for Ned is re-opening inquiry into what bed to get. It is the activity of engaging in further consideration of the question that it is irrational. Moreover, this is irrational because the evidence that is available to make this decision does not support it. Should Ned irrationally engage in this activity, there is a uniquely rational way to finish it, which is to change his mind. But that’s not the same as saying that he should, rationally, change his mind.\nI am making a big assumption here, but one I think is true. Careful consideration involves thinking through a large amount of evidence. Decisions to engage in careful consideration must be made on the basis of flimsier amounts of evidence. After all, to bring all the evidence one has to bear on a question is to engage in careful consideration. So a decision to engage in such consideration must not use all that evidence. So evidentialism must say that the rationality of a belief, credence, decision etc must depend on, i.e., supervene on, the evidence available to the agent when they make that decision. And when deciding whether to carefully consider or reflect on the evidence, very little is available.\nThat’s why I think Ned isn’t a counterexample to evidentialism. And nor is Kim a counterexample to evidentialism, even if there is no way she can rationally lose her belief in q. For Kim too faces a dilemma, of just the same kind. So the argument I gave for the rationality of Kim’s continuing to believe q goes wrong at step 4. Kim has gotten herself into a mess, and there are no rational ways out.\nBut note that last conclusion cuts across the theories of memory we’ve considered here. The temporally extended theory has, as its distinctive claim, that some agents have a kind of evidence that the temporally local theory says no agent has. But Kim is not one of those agents. The evidence in question is evidence one gets when one acquires a piece of knowledge, and keeps that token mental state across time. And the relevant fact about Kim is that he has a belief in \\(q\\) that is well and truly not a piece of knowledge. So it doesn’t look like the case should tell the local and extended theories apart.\nWhat it does so is show that there is a new kind of argument for the possibility of rational dilemmas. People make mistakes. When they do, there might be no good way to undo the effect of the mistake. And then they’re in a dilemma. We don’t avoid that conclusion by giving people who don’t make mistakes more evidence."
  },
  {
    "objectID": "posts/mbt/memory-belief-and-time.html#conclusionandfutureresearch",
    "href": "posts/mbt/memory-belief-and-time.html#conclusionandfutureresearch",
    "title": "Memory, Belief and Time",
    "section": "8 Conclusion and Future Research",
    "text": "8 Conclusion and Future Research\nI’ve argued for a transmissive, temporally extended, view of memory and the evidence it provides. When I remember that the White Sox won in 2005, it is the fact that they won which is my evidence, not my apparent memory. The role of memory is to preserve this fact in evidence, not to give me new evidence for it. Saying this invites any number of questions. I’ll end with a list of several ones that I find fascinating, but which I’m a long way from having answers to, divided up loosely into questions about metaphysics, and questions about epistemology.\n\n8.1 Preservation\nWhat is it for memory to preserve a belief? Sven Bernecker (2008) has written on this at length, and the issue turns out to be much more complicated than we might first suspect. I’m particularly unsure about cases like this one,\n\n\nAnkati.\n\nI haven’t had to change planes at O’Hare for over five years. That makes me happy.\n\nBojan.\n\nAre you sure? What about the trip to Vancouver? Or the one to Hong Kong?\n\nAnkati.\n\nVancouver was a direct flight. And I went to Hong Kong via New York. But, oh, you’re right, I came back via O’Hare. Sad face.\n\n\n\nAt the end Ankati remembers that she flew home from Hong Kong via O’Hare. Is this a belief that was stored in memory ever since it happened? If so, we have to say that Ankati had inconsistent beliefs at the start of the conversation. If not, then I think it is hard to say that the relevant evidence for the belief that saddens her is the fact that she transferred at O’Hare. In such a case, it seems to me that the temporally local theory is more plausible than in more usual cases.\n\n\n8.2 Initial Evidence and Over-Riding\nThe following two questions are related:\n\nWhat past states can constitute present evidence?\nWhat present states can over-ride, or defeat, past evidence?\n\nMy instinct is to defend an extremely restricted answer to this pair of questions. In particular, \\(S\\)’s attitude towards \\(p\\) at \\(t_1\\) can only be evidence for her at \\(t_2\\) if the following conditions obtain.\n\n\\(S\\) knows that \\(p\\) at \\(t_1\\).\n\\(S\\) does not receive a significant amount of evidence against \\(p\\) between \\(t_1\\) and \\(t_2\\).\n\\(S\\) does not receive (undefeated) reasons to distrust her ability to preserve information between \\(t_1\\) and \\(t_2\\).\n\nBut every one of these points is problematic.\nThe first point might imply some counterintuitive things about people who trust misleading evidence, such as ‘Karen’ in the earlier cited example by Gilbert Harman (1986, Ch. 4). Let’s focus on an even simpler case than Harman’s. Unlike me, my doppleganger Nairb believes that the Astros beat the White Sox in the 2005 World Series. That’s because his web browser had been hacked on that crucial October morning, and it reported the wrong results. He hasn’t seen any relevant evidence since. He has forgotten why he thinks the Astros won in 2005, but has held on to the belief. Is this belief rational, and what’s his evidence for it?\nThe evidence can’t be that the Astros won in 2005; they didn’t. And it can’t be that his computer reported that; he’s forgotten that fact. Let’s say that it is his apparent memory that they won, which seems to be the only remaining option. That would mean that the rationality of his forming the belief in the first place is independent of whether his current belief that the Astros won is rational. That’s better than the alternative options, but it isn’t particularly happy either.\nThe second point leads us into the version of the dogmatism puzzle that Maria Lasonen-Aarnio (2014b) has developed. Assume that significant evidence can factor into insignificant parts. Pazu knows that \\(p\\), then gets three pieces of evidence \\(e_1, e_2\\) and \\(e_3\\) that tell against \\(p\\). The conjunction is significant evidence, the individual parts are not. But the parts come in sequentially. When \\(e_1\\) comes in, Pazu still knows \\(p\\); after all, it is insignificant evidence. So Pazu can conclude, i.e., know, that it is misleading evidence. And, intuitively, we can ignore evidence we know to be misleading. So he ignores \\(e_1\\). And for similar reasons he ignores \\(e_2\\). Then \\(e_3\\) comes in. Should he still ignore it? Presumably; it is on its own insignificant, and the only other evidence was known to be misleading, and so ignored. But it is odd that Pazu can hold onto his knowledge in \\(p\\) in the face of these three pieces of evidence, while he would have lost knowledge had they come in at once.\nFinally, we need to explain why evidence of unreliability of mnemonic processes can block mnemonic knowledge. If memory was a source of evidence, rather than a preserver of evidence, that would be an easy problem. In general, a source does not provide evidence to an agent if the agent has reason to believe that it is unreliable. The problem is how to motivate an extension of that principle to memory, which is in general not a source of evidence, but a preserver of it.\nWe could simply insist that the Shangri La case shows that the preservative role of memory can be defeated given sufficient grounds to doubt its accuracy. I think that’s right, we can insist that. But there is a puzzle still about why this should be so. And that puzzle remains work for another day, as do the other puzzles in this section.\n\n\n8.3 Externalism\nFinally, there are some tantalising possibilities for new angles into familiar epistemological debates between internalists and externalists. It is hardly news that this is possible; Goldman’s ‘problem of forgotten evidence’ is a familiar challenge to (certain) internalists  (Goldman 1999). But there might be other ways to make memory relevant to familiar debates.\nIf the temporally extended theory is true, then what is rational depends on something that is, well, extended. And if what is rational depends on something that is extended in time, we might think it is less surprising that is also depends on something that is extended in space. And that suggests the way to a kind of externalism.\nWe can do a bit better than that hand-waving metaphor though. There are versions of the New Evil Demon problem for transmissivism. If transmissivism is true anyway, that means those problems have solutions. Then we just have to find what those solutions are, and see if they generalise to solutions to the spatial version of the New Evil Demon problem. And if they do, we might have new ways to defend externalist theories of rationality, or at least new motivations for familiar ways to defend those theories."
  },
  {
    "objectID": "posts/review-sameness/review-of-sameness-and-substance-renewed.html",
    "href": "posts/review-sameness/review-of-sameness-and-substance-renewed.html",
    "title": "Review of “Sameness and Substance Renewed”",
    "section": "",
    "text": "Sameness and Substance Renewed (hereafter, 2001) is, in effect, a second edition of Wiggins’s 1980 book Sameness and Substance (hereafter, 1980), which in turn expanded and corrected some ideas in his 1967 Identity and Spatio-Temporal Continuity (hereafter, 1967). All three books have similar aims. The first is to argue, primarily against Geach, that identity is absolute not relative. The second is to argue that, despite this, whenever an identity claim a = b is true, there is a sortal f such that a is the same f as b. The biggest difference between 1967 and the two later books is that the later books contain much more detail on what a sortal must be if this claim, called D, is to be both correct and philosophically interesting. The third aim is to apply the first two conclusions to the topic of personal identity.\n\nThis review first published in Notre Dame Philosophical Reviews.\n\nFor the bulk of 2001, most of the changes to 1980 are confined to footnotes, the bulk of these consisting of a citation of, and occasionally a brief comment upon, a post 1980 publication that bears on Wiggins’s approach to the topic. This changes in the last two chapters. The penultimate chapter is a mostly new discussion of the determinacy of identity. In the final chapter, on personal identity, Wiggins retracts many of the claims made in the matching chapter of 1980, and raises some interesting objections to Parfit’s account of personal identity. Apart from those, the major changes to 1980 are stylistic. No longer is the material considered more peripheral printed in smaller type, though to make up for this there are frequent exhortations to skip these sections. And the longer notes of the 1980 edition are now mostly incorporated into the text, several prefixed with advice that they not be read.\nIn the preface Wiggins says that it is a matter of no concern whether 1980 and 2001 are the same book. But it is of concern to me, twice over. First, it makes a large difference to what kind of review should be written whether this is an old book reissued or a new book. Secondly, the difficulty in answering this question draws out some problems Wiggins’s theory faces when we try to apply it outside the realms of physics and biology. On the first problem, the reader who hopes here to find a comprehensive discussion of the literature on identity post-1980 as it strikes David Wiggins will be disappointed. Three examples should help to illustrate this.\nIn 1967 Wiggins held, quite sensibly, that a statue is not identical to the bronze that it is made of, but rather is constituted by that bronze. This was an important move in his response to Geach. If identity is absolute, and the statue is identical with the bronze, then we can’t say that when the statue is remoulded into a vase, we have the same lump of bronze but a different artwork. In 2001 he says much the same thing. This still seems like good common sense, but the problem is that in the intervening 34 years there has been a mass of work on constitution, most of it concluding that the constitution relation is much more problematic than we had originally thought. In a genuinely new work, or even perhaps in a revised old work, this material should have been addressed.\nIn 1980 Wiggins makes it quite clear he dislikes perdurantist theories of persistence that hold that an object persists from t­1 to t2 by having instantaneous temporal parts at every time in [t1, t2]. Just why he dislikes perdurantism is unclear, since all his arguments are directed against the conjunction of this view with the striking, and not especially popular, view that our ordinary names refer to these instantaneous objects. In 2001 it is still clear he dislikes perdurantism. But we find little on the barrage of arguments perdurantists have offered in the last 21 years in support of their position. All we find is a footnote expressing agreement with Mark Johnston’s response to Lewis’s ‘problem of temporary intrinsics’ argument, and a citation of a paper expanding upon said agreement. Given that this book largely reprints previously available material, including more detail here would not have been absurd, and saying something about other arguments quite appropriate.\nThe third example is a little more serious. In the book’s new chapter, he outlines approvingly Evans’s proof that identity is always determinate identity, and cites (without outlining) a proof by Williamson that distinctness is always determinate. From these proofs he quite naturally concludes that the prospects for indeterminate identities are pretty grim. But he doesn’t engage with those who maintain that, despite all this, there really are indeterminate identities. It would have been worthwhile, for instance, to see a more direct engagement between his views and those of, say, Terrence Parsons, who over the last 15 years has developed a rather detailed theory on which indeterminate identity is possible. It will probably turn out that Wiggins’s position is entirely correct, and Parsons’s position basically mistaken, but that’s no reason to not take Parsons more seriously.\nApart from this oversight, there is one rather odd feature in the discussion of determinacy. Wiggins says that “it can be perfectly determinate which mountain x is without x’s extent being determinate.” (166) The idea is that it can be determinate that x is, say, this mountain, while it is indeterminate whether, say, that foothill is part of x. Such a position always feels strained to me, but it is certainly not unfamiliar. But it is very hard to see how it is meant to fit in with Wiggins’s picture of the role of sortal concepts, such as mountain. On page 70 he says a sortal concept is such that grasp of it determines “what changes x tolerates without there ceasing to exist such a thing as x.” (He actually says ‘substance-concept’, not ‘sortal concept’ there, but these phrases seem to be used synonymously.) The trouble should be apparent. For it to be determinate what x is, presumably just is for it to be determinate that x is this mountain. That is, it is determinate that x falls under the sortal mountain, and that sortal must determine persistence conditions, else it fails to be a sortal. But that means x’s persistence conditions are determined. So there is a determinate fact, perhaps unknown and perhaps even unknowable, about how far in the future one can go without leaving x behind. (I assume here that if x’s temporal extent is determined by which sortal it falls under, then x’s temporal extent is determinate. I imagine some will deny this claim, but it looks like a platitude to me.) On the other hand, it seems that it can be determinate what x is even though the conditions of x’s spatial persistence, conditions that determine how far westward one can go without leaving x behind, are not determinate. Just how this asymmetry is to be tolerated is not explained.\nMuch of the interest in this edition will focus on the new material on personal identity, and I shall say more about this below. But it is worth going over the central claims of the earlier part of the book. The crucial principle is called D(ii). The derivation of it appeals crucially to D(i). (Both definitions, and the commentary, from page 64.)\nD(i) (x)(t) [(x exists at t) → (∃g) (g(x) at t)].\nD(ii) (x)(∃g)(t) [(x exists at t) → (g(x) at t)].\n‘x’ ranges over three-dimensional continuants, ‘t’ over times and ‘g’ over sortals. The argument for D(i) is that for any object at any time there is an answer to the Aristotelian question What is it? This answer is a sortal so, as just noted, it must determine principles of persistence. It must also determine “a prnciple of activity, a principle of functioning or a principle of operation”. (72) If the last claim looks disjunctive, that’s because it is. Sortals for living objects determine principles of activity, sortals for artifacts determine principles of functioning. Just what philosophically interesting features these principles share is never satisfactorily explained. So there’s a suspicion that there is no decent concept of sortal that covers the kinds of things living creatures are and the kinds of things artifacts are. In slogan form sortal isn’t a sortal. Two other considerations reinforce that suspicion.\nFirst, there are objects that don’t naturally fall under any known sortal. Just looking at the computer I’m now using, there is the latch that holds the lid down when it’s closed, the button that opens the CD tray, the brightness control, and the stick that plays some (but not all) the functional roles of a mouse. It’s far from obvious that any of these falls under a sortal, at least if a sortal must determine persistence conditions and a principle of functioning.\nSecondly, there’s a tension between the kinds of sortals Wiggins thinks appropriate for artifacts and what he says about persistence. Artifact sortals are, he says, functional kinds. These sortals are meant to determine persistence conditions. Whether an object has persisted is not meant to depend on extrinsic, or external, factors. This is the upshot of his Only a and b rule (96), which is important in ruling out ‘best deserver’ theories of persistence. That rule says that we don’t need to consider objects other than a or b to determine whether a is b. So whether a, the boy genius is b, the Nobel Prize winning author, cannot depend on the existence or otherwise of a person more closely continuous with a than b happens to be. Hence Nozick’s theory of personal identity, which rejects this, cannot be true. But to determine whether a´, the brightness control on my computer at t1 is b´, the volume control on Jack’s computer at t2, we need to see which sortals a´ and b´ fall under, to see whether a´ has persisted. That will depend, in part, on whether a´ still falls under that sortal, whatever it is. Such a sortal will sort by functional role, and whether that functional role is fulfilled at all times between t1 and t2 will be determined by things other than a´ and b´. The point generalises: in most cases whether an object continues to fill a functional role often turns on the existence, and behaviour, of other objects. The natural conclusion to be drawn here is that D(i) might be false for artifacts.\nClearly D(i) doesn’t entail D(ii). But, bracketing our concerns about its truth, it might still be usable in an abductive argument for D(ii). Wiggins does just this. The argument, and this is I think the only argument for D(ii), is that it best explains our widespread agreement over whether an object has survived. Wiggins says that, “Our capacity for massive agreement about this is much more remarkable than our occasional disagreement,” (66) and given D(i), D(ii) is the best explanation of this. Two replies. First, the agreement is not all that widespread, even in actual cases. Think, for example, about the range of disagreement over whether a corpse is a thing that once lived, and hence the disagreement over whether Auntie is buried behind the back shed, or Auntie no longer exists. Secondly, there is a better explanation – the perdurantist explanation given by Lewis. This not only explains why there is agreement just where there is agreement, but why there is disagreement where there is disagreement. The story is familiar. All sorts of continuants (fusions of temporal parts) exist, but we choose which ones to refer to and quantify over because of our particular interests, and those choices are codified in our linguistic practices. When dealing with historically familiar situations, membership of linguistic, and more broadly cultural, communities commits us to common answers. Since most situations are historically familiar, we have agreement in most cases. When we deal with new cases, either generated by new technology or new imaginativeness, and our interests do not pick out a clearly preferable continuant, we do not have agreement. If this is right, we will agree about the familiar and disagree about the unfamiliar. Happily, this is exactly what we find – we all know what the persistence conditions for cows, pigs and chicken are, we do not know the persistence conditions for corporate entities or pieces of software or even relocated football teams in perfectly everyday cases.\nIn 1980, the chapter on personal identity had two main aims. The first was to argue that Lockean considerations about continuity of memory could be used in an account of personal identity, even if they would have to be used as reference fixers rather than as constituents of a reductive analysis. The opponents here were those followers of Bishop Butler, most prominently Anthony Flew, who held that any such consideration would be hopelessly circular. The second aim was to argue that it is a conceptual truth that persons are animals. The targets here were (unnamed) philosophers who wanted to provide a complete functional analysis of a person. The objections were mainly political but since it is unclear whether the philosophy of personal identity should be part of metaphysics or ethics, that’s perfectly acceptable.\nIn 2001, the aims have changed. Wiggins retracts everything he said against Butler and Flew, and then spends most of the chapter in a lengthy discussion of Parfit’s theory of personal identity. Butler’s original complaint against Locke was that the concept of memory needs a pre-existing concept of personal identity to be applied so it cannot be used in a non-circular account of identity. In the bluntest version of this complaint, it is held that ‘A remembers X-ing’ is properly represented as ‘A remembers A X-ing’, which requires an identity between the referents of the two occurences of ‘A’. Wiggins’s complaint, in 1980, was that this position costs us some vital distinctions. We want to distinguish, for example, ‘A imagines being an elephant’ from ‘A imagines A being an elephant’. In the first case only, A imagines something possible. And what holds for imagining, he thought, holds for remembering. Wiggins now rejects the last step here. Remembering, unlike imagining, has a tie to the truth. A can only remember X-ing if A in fact X-ed. This last claim might not be part of the logical form of ‘A remembers X-ing’, but there is a close relation between the two. Wiggins calls the relationship presupposition, but the name here doesn’t matter much. So Butler, and Flew, were right – appeals to memory in a theory of personal identity are hopelessly circular, because they presuppose that debates about identity through time are resolved.\nThe rest of the chapter outlines concerns with Parfit’s theory of personal identity, based on his concept of quasi-memory, and with the intuitions behind some cases that support Parfit’s theory. Quasi-memory, unlike memory, need not be factive, but what is quasi-remembered must have happened somewhere, to someone. Wiggins launches a barrage of attacks on this idea, of which the following three seem most telling. First, quasi-memory could not be defined (and is not defined) as memory minus factiveness, because conceptual subtraction is undefined in the absence of conceptual analysis, and we don’t have a conceptual analysis here. Secondly, the concept of quasi-memory may seem to make sense for quite general, de dicto memories, but it runs into trouble with de re, or even with more specific memories. If I am to quasi-remember climbing Big Ben on my sixteenth birthday, must someone have climbed Big Ben on my sixteenth birthday? Or perhaps on their sixteenth birthday? Thirdly, even if Parfit can define the concept of accurate quasi-memory, that won’t get us the general concept of quasi-memory, because again conceptual subtraction doesn’t make sense.\nThere are some good points here for followers of Parfit to consider. They are followed by some interesting considerations about why we might rethink our intuitions about personal identity in cases involving brain swaps. Those interested in personal identity debates, and particularly Wiggins’s and Parfit’s contributions, should pay close attention here. These will not be the only people to whom this new volume has interest. Sameness and Substance was an important statement of a rather commonsensical solution to some of the hardest questions in metaphysics, a solution with which everyone working in the field should be well acquainted. And those who have not previously read it closely will find that the stylistic changes (having a uniform font size, incorporating the longer notes into the text) make the renewed version of Sameness and Substance much more accessible than the original."
  },
  {
    "objectID": "posts/review-rethinking-intuition/index.html",
    "href": "posts/review-rethinking-intuition/index.html",
    "title": "Review of “Rethinking Intuition”",
    "section": "",
    "text": "This collection arose out of a conference on intuitions at the University of Notre Dame in April 1996. The papers in it mainly address two related questions: (a) How much evidential weight should be assigned to intuitions? and (b) Are concepts governed by necessary and sufficient conditions, or are they governed by ‘family resemblance’ conditions, as Wittgenstein suggested? The book includes four papers by psychologists relating and analyzing some empirical findings concerning intuitions and eleven papers by philosophers endorsing various answers to these questions.\n\nPublished in Ethics 112: 361-364.\n\nThe first section consists of the papers by psychologists. In these papers, the main target is the traditional philosopher who holds, inter alia, that the answer to a is “quite a lot” and the answer to b is the former, that there are necessary and sufficient conditions for most philosophically interesting concepts. If you like these answers, then you might spend your time Chisholming away at concepts like ‘justice,’ ‘knowledge,’ and ‘causation’—proposing snappy analyses and testing them against intuitions about possible cases. But if you don’t like these answers, you might prefer to make pointed criticisms of the presuppositions of such a methodology and suggest some more empirically defensible ways of coming to understand concepts. Indeed, this is just what the psychologists writing here do.\nThe papers by the philosophers are, very roughly, divided up according to their answers to these questions. The second section, titled “Rethinking Intuition and Philosophical Method,” consists of papers disagreeing with traditional philosophy about a or b. (This section includes papers by Stephen Stich, Robert Cummins, Hilary Kornblith, Tamara Horowitz, William Ramsey, and Alvin Goldman and Joel Pust.) The really radical position, expressed most clearly by Stich, is that traditional philosophy is wrong on both counts. We need to bring much more empirical research to bear on explicating crucial concepts in ethics, epis- temology, and so forth, and the explications we will end up with will not be short lists of necessary and sufficient conditions. The third section, titled “Defending the Philosophical Tradition,” contains, mostly, defenses of one of the traditional views. (This section includes papers by George Bealer, Richard Foley, Ernest Sosa, George Graham and Terry Horgan, and Michael DePaul.) The main aim here is to defend the value of intuitions as evidence; there is no explicit defense of the traditional view of concepts. Despite this neat rationale, the editors’ classification breaks down in a few cases. For example, in Kornblith’s paper he indicates substantial agreement with the paper by Graham and Horgan. So it is a little unclear why these papers are in these opposing sections. There is one other philosophical paper: Gary Gutting’s historical introduction is printed in a special ‘Introduction’ section.\nThree of the papers have the phrase “Reflective Equilibrium” in their title, so it might be expected that there would be some cutting-edge discussions about how to balance competing desiderata in achieving equilibrium. We don’t get such a discussion, and perhaps with good reason. With a nod in the direction of Goodman, Rawls, and Daniels, the writers mostly agree that if the aim of ethical or epistemological theory is, primarily, to systematize our intuitions, then reflective equilibrium (RE) is the way to do it. The papers here are, quite self- consciously, interested in the more basic question of whether that is what we want ethics or epistemology to do. I’ll conclude by saying a bit more about the papers which most clearly address this question. For the radicals, Cummins argues that “philosophical intuition is epistemologically useless” (p. 125). For the traditionals, on the other hand, Michael DePaul argues that RE provides “close to a correct answer” to the question, “How should we conduct philo- sophical inquiry?” (p. 294).\nCummins compares evidence from intuitions to evidence from other sources, like telescopes. He notes two related features of telescopes which, he thinks, makes them more trustworthy sources of evidence than intuitions. First, telescopes can be calibrated. We can apply telescopes to cases about which we have reliable independent evidence and see whether they deliver appropriate answers. For example, we can point a telescope at a distant mountain and see whether it looks the same through the telescope as it does up close and personal. If so, we can trust what it shows about places we have never before seen, such as heavenly bodies. If not, we not only learn that the telescope is untrustworthy but also may learn a little about the way in which it fails. Unlike telescopes, intuitions cannot be independently checked. They can only be checked against other intuitions. Hence, argues Cummins, they are untrustworthy. As Sosa notes, the comparison here may be unfair. Even though we can calibrate telescopes, we cannot calibrate observation as a whole. We can only calibrate particular kinds of observations against other kinds of observations and particular kinds of intuitions against other kinds of intuitions. Intuition, in this respect, is just like observation, and since we trust observations, we should trust intuitions.\nCummins’s other critique is that what evidence we do have about intuitions suggests that they are artifacts of the process by which they are produced rather than reliable guides to their subject matters. The idea is that the presence of a certain intuition concerning fairness tells us more about the source of the intuition (usually the person who has the intuition) than about fairness. If this is right, then intuitions are obviously not evidential. Cummins’s argument is that there are only five possible sources of intuitions, and examination of each suggests that intuitions are artifacts of the process by which they are produced. To prove this, Cummins works through each of the five possible sources and argues for each that an intuition derived from that source has no evidential value. Argument by cases in this way, when there are five possible cases to cover, is never going to be satisfactory. For example, one of the cases Cummins considers is that intuitions are evidential because they arise from possession of concepts. Something like this view is endorsed in the papers by Bealer and by Goldman and Pust. Cummins thinks this does not work because our concepts are just sets of beliefs. One’s concept of an elevator is just everything one believes about elevators. If anything like this is right, then the fact that we intuit that p just means that we believe p and that could not be evidence that p. But the theory of concepts he has in mind cannot be right. As Fodor has pointed out, it seems people can share concepts while having different beliefs involving those concepts. Indeed, something like this must be right if genuine disagreement is possible. If possessing a concept just meant having certain beliefs, then it would be impossible for people with radically different beliefs about a subject to share concepts relating to that subject. Since such sharing is possible, concept possession does not reduce to having certain beliefs. The main point is not that there is an insurmountable problem for Cummins here—maybe a more detailed discussion could show that his account of concepts is right and Fodor’s is wrong—but rather that with such a wide terrain to cover, a short argument is not going to win many converts.\nMichael DePaul is much more content with intuitions playing a central role in philosophy. Indeed, he seems happy to let them do all the work. His paper imagines a dialogue between himself and a friendly barfly who wants to be told all about how philosophy works. At some point in the conversation, DePaul’s character decides to present the new friend with an extended summary of how RE works. The friend is bemused that philosophers seem to only sit around and compare intuitive judgments. It does seem, notes the friend, a trifle self-indulgent. DePaul’s response attempts to defend RE by an argument that any alternative method would be irrational. Any alternative, argues DePaul, would have to (a) abandon reflection, (b) reflect incompletely, by leaving out certain beliefs, principles, or whatever enters into reflection, or (c) not allow results of reflection to influence final theory. As DePaul notes, it would be irrational to accept any of these options. DePaul acknowledges two possible criticisms here, criticisms which he admits he is not sure how to answer. The first is that it is not clear what is wrong with being irrational, at least in the sense DePaul has in mind. The second is that even if we have a reason not to be irrational, it is not clear how strong a reason this is and, hence, whether irrationality might be justifiable on occasion because it fulfills some greater purpose.\nThere is a third criticism that more closely reflects the problem raised by DePaul’s interlocutor. When someone says that philosophy should be about more than systematizing intuitions, they are not advocating alternatives to RE but, rather, supplements to it. The point of the criticism was that there must be other sources of evidence for moral or conceptual claims, other than just intuition. (This, apparently, is intuitively obvious!) DePaul provides a good response to someone who wants to say that intuitions have no evidential value at all. But he does not answer the critic who denies that intuitions provide the only evidence that might bear on philosophical problems.\nThis is a very useful collection to have published. A study of the role of intuition should be at the heart of any investigation into philosophical methodology. And such an investigation will have to take into account both the empirical findings about how intuition works and the philosophical considerations about how much importance should be attached to intuitions. The papers here do not look like the last word on any of these questions, but they are a helpful, and perhaps overdue, first word."
  },
  {
    "objectID": "posts/cwpwpe/can-we-do-without-pragmatic-encroachment.html",
    "href": "posts/cwpwpe/can-we-do-without-pragmatic-encroachment.html",
    "title": "Can We Do Without Pragmatic Encroachment?",
    "section": "",
    "text": "0.1 Introduction\nRecently several authors have defended claims suggesting that there is a closer connection between practical interests and epistemic justification than has traditionally been countenanced. Jeremy Fantl and Matthew McGrath (2002) argue that there is a “pragmatic necessary condition on epistemic justification” (77), namely the following.\n\nPublished in Philosophical Perspectives 19: 417-43.\n\n\n(PC)\n\nS is justified in believing that p only if S is rational to prefer as if p. (77)\n\n\nAnd John Hawthorne (2004) and Jason Stanley (2005) have argued that what it takes to turn true belief into knowledge is sensitive to the practical environment the subject is in. These authors seem to be suggesting there is, to use Jonathan Kvanvig’s phrase “pragmatic encroachment” in epistemology. In this paper I’ll argue that their arguments do not quite show this is true, and that concepts of epistemological justification need not be pragmatically sensitive. The aim here isn’t to show that (PC) is false, but rather that it shouldn’t be described as a pragmatic condition on justification. Rather, it is best thought of as a pragmatic condition on belief. There are two ways to spell out the view I’m taking here. These are both massive simplifications, but they are close enough to the truth to show the kind of picture I’m aiming for.\n\nThanks to Michael Almeida, Tamar Szabó Gendler, Peter Gerdes, Jon Kvanvig, Barry Lam, Ishani Maitra, Robert Stalnaker, Jason Stanley, Matthew Weiner for helpful discussions, and especially to Matthew McGrath for correcting many mistakes in an earlier draft of this paper.\n\nFirst, imagine a philosopher who holds a very simplified version of functionalism about belief, call it (B).\n\n(B)\n\nS believes that p iff S prefers as if p\n\n\nOur philosopher one day starts thinking about justification, and decides that we can get a principle out of (B) by adding normative operators to both sides, inferring (JB).\n\n(JB)\n\nS is justified in believing that p only if S is justified to prefer as if p\n\n\nNow it would be a mistake to treat (JB) as a pragmatic condition on justification (rather than belief) if it was derived from (B) by this simple means. And if our philosopher goes on to infer (PC) from (JB), by replacing ‘justified’ with ‘rational’, and inferring the conditional from the biconditional, we still don’t get a pragmatic condition on justification.\nSecond, Fantl and McGrath focus their efforts on attacking the following principle.\n\nEvidentialism\n\nFor any two subjects S and S\\(^\\prime\\), necessarily, if S and S\\(^\\prime\\) have the same evidence for/against p, then S is justified in believing that p iff S\\(^\\prime\\) is, too.\n\n\nI agree, evidentialism is false. And I agree that there are counterexamples to evidentialism from subjects who are in different practical situations. What I don’t agree is that we learn much about the role of pragmatic factors in epistemology properly defined from these counterexamples to evidentialism. Evidentialism follows from the following three principles.\n\nProbabilistic Evidentialism\n\nFor any two subjects S and S\\(^\\prime\\), and any degree of belief \\(\\alpha\\) necessarily, if S and S\\(^\\prime\\) have the same evidence for/against p, then S is justified in believing that p to degree \\(\\alpha\\) iff S\\(^\\prime\\) is, too.\n\nThreshold View\n\nFor any two subjects S and S\\(^\\prime\\), and any degree of belief \\(\\alpha\\), if S and S\\(^\\prime\\) both believe p to degree \\(\\alpha\\), then S believes that p iff S\\(^\\prime\\) does too.\n\nProbabilistic Justification\n\nFor any \\(S, S\\) is justified in believing p iff there is some degree of belief \\(\\alpha\\) such that S is justified in believing p to degree \\(\\alpha\\), and in S’s situation, believing p to degree \\(\\alpha\\) suffices for believing p.\n\n\n(Degrees of belief here are meant to be the subjective correlates of Keynesian probabilities. See Keynes (1921) for more details. They need not, and usually will not, be numerical values. The Threshold View is so-called because given some other plausible premises it implies that \\(S\\) believes that p iff S’s degree of belief in p is above a threshold.)\nI endorse Probabilistic Justification, and for present purposes at least I endorse Probabilistic Evidentialism. The reason I think Evidentialism fails is because the Threshold View is false. It is plausible that Probabilistic Justification and Probabilistic Evidentialism are epistemological principles, while the Threshold View is a principle from philosophy of mind. So this matches up with the earlier contention that the failure of Evidentialism tells us something interesting about the role of pragmatics in philosophy of mind, rather than something about the role of pragmatics in epistemology.\nAs noted, Hawthorne and Stanley are both more interested in knowledge than justification. So my discussion of their views will inevitably be somewhat distorting. I think what I say about justification here should carry over to a theory of knowledge, but space prevents a serious examination of that question. The primary bit of ‘translation’ I have to do to make their works relevant to a discussion of justification is to interpret their defences of the principle (KP) below as implying some support for (JP), which is obviously similar to (PC).\n\n(KP)\n\nIf S knows that p, then S is justified in using p as a premise in practical reasoning.\n\n(JP)\n\nIf S justifiably believes that p, then S is justified in using p as a premise in practical reasoning.\n\n\nI think (JP) is just as plausible as (KP). In any case it is independently plausible whether or not Hawthorne and Stanley are committed to it. So I’ll credit recognition of (JP)’s importance to a theory of justification to them, and hope that in doing so I’m not irrepairably damaging the public record.\nThe overall plan here is to use some philosophy of mind, specifically functionalist analyses of belief to respond to some arguments in epistemology. But, as you can see from the role the Threshold View plays in the above argument, our starting point will be the question what is the relation between the credences decision theory deals with, and our traditional notion of a belief? I’ll offer an analysis of this relation that supports my above claim that we should work with a pragmatic notion of belief rather than a pragmatic notion of justification. The analysis I offer has a hole in it concerning propositions that are not relevant to our current plans, and I’ll fix the hold in section 3. Sections 4 and 5 concern the role that closure principles play in my theory, in particular the relationship between having probabilistically coherent degrees of belief and logically coherent beliefs. In this context, a closure principle is a principle that says probabilistic coherence implies logical coherence, at least in a certain domain. (It’s called a closure principle because we usually discuss it by working out properties of probabilistically coherent agents, and show that their beliefs are closed under entailment in the relevant domain.) In section 4 I’ll defend the theory against the objection, most commonly heard from those wielding the preface paradox, that we need not endorse as strong a closure principle as I do. In section 5 I’ll defend the theory against those who would endorse an even stronger closure principle than is defended here. Once we’ve got a handle on the relationship between degrees of belief and belief tout court, we’ll use that to examine the arguments for pragmatic encroachment. In section 6 I’ll argue that we can explain the intuitions behind the cases that seem to support pragmatic encroachment, while actually keeping all of the pragmatic factors in our theory of belief. In section 7 I’ll discuss how to endorse principles like (PC) and (JP) (as far as they can be endorsed) while keeping a non-pragmatic theory of probabilistic justification. The interesting cases here are ones where agents have mistaken and/or irrational beliefs about their practical environment, and intuitions in those cases are cloudy. But it seems the most natural path in these cases is to keep a pragmatically sensitive notion of belief, and a pragmatically insensitive notion of justification.\n\n\n0.2 Belief and Degree of Belief\nTraditional epistemology deals with beliefs and their justification. Bayesian epistemology deals with degrees of belief and their justification. In some sense they are both talking about the same thing, namely epistemic justification. Two questions naturally arise. Do we really have two subject matters here (degrees of belief and belief tout court) or two descriptions of the one subject matter? If just one subject matter, what relationship is there between the two modes of description of this subject matter?\nThe answer to the first question is I think rather easy. There is no evidence to believe that the mind contains two representational systems, one to represent things as being probable or improbable and the other to represent things as being true or false. The mind probably does contain a vast plurality of representational systems, but they don’t divide up the doxastic duties this way. If there are distinct visual and auditory representational systems, they don’t divide up duties between degrees of belief and belief tout court, for example. If there were two distinct systems, then we should imagine that they could vary independently, at least as much as is allowed by constitutive rationality. But such variation is hard to fathom. So I’ll infer that the one representational system accounts for our credences and our categorical beliefs. (It follows from this that the question Bovens and Hawthorne (1999) ask, namely what beliefs should an agent have given her degrees of belief, doesn’t have a non-trivial answer. If fixing the degrees of belief in an environment fixes all her doxastic attitudes, as I think it does, then there is no further question of what she should believe given these are her degrees of belief.)\nThe second question is much harder. It is tempting to say that \\(S\\) believes that p iff S’s credence in p is greater than some salient number \\(r\\), where \\(r\\) is made salient either by the context of belief ascription, or the context that S is in. I’m following Mark Kaplan (1996) in calling this the threshold view. There are two well-known problems with the threshold view, both of which seem fatal to me.\nAs Robert Stalnaker (1984, 91) emphasised, any number \\(r\\) is bound to seem arbitrary. Unless these numbers are made salient by the environment, there is no special difference between believing p to degree 0.9786 and believing it to degree 0.9875. But if \\(r\\) is 0.98755, this will be the difference between believing p and not believing it, which is an important difference. The usual response to this, as found in (Foley 1993 Ch. 4) and Hunter (1996) is to say that the boundary is vague. But it’s not clear how this helps. On an epistemic theory of vagueness, there is still a number such that degrees of belief above that count, and degrees below that do not, and any such number is bound to seem unimportant. On supervaluational theories, the same is true. There won’t be a determinate number, to be sure, but there will a number, and that seems false. My preferred degree of belief theory of vagueness, as set out in Weatherson (2005) has the same consequence. Hunter defends a version of the threshold view combined with a theory of vagueness based around fuzzy logic, which seems to be the only theory that could avoid the arbitrariness objection. But as Williamson (1994) showed, there are deep and probably insurmountable difficulties with that position. So I think the vagueness response to the arbitrariness objection is (a) the only prima facie plausible response and (b) unsuccessful.\nThe second problem concerns conjunction. It is also set out clearly by Stalnaker.\n\nReasoning in this way from accepted premises to their deductive consequences (\\(P\\), also \\(Q\\), therefore \\(R\\)) does seem perfectly straightforward. Someone may object to one of the premises, or to the validity of the argument, but one could not intelligibly agree that the premises are each acceptable and the argument valid, while objecting to the acceptability of the conclusion. (Stalnaker 1984, 92)\n\nIf categorical belief is having a credence above the threshold, then one can coherently do exactly this. Let \\(x\\) be a number between \\(r\\) and than \\(r\\) \\(\\nicefrac{1}{2}\\), such that for an atom of type U has probability \\(x\\) of decaying within a time \\(t\\), for some \\(t\\) and U. Assume our agent knows this fact, and is faced with two (isolated) atoms of U. Let p be that the first decays within \\(t\\), and \\(q\\) be that the second decays within \\(t\\). She should, given her evidence, believe p to degree \\(x, q\\) to degree \\(x\\), and \\(p \\wedge q\\) to degree \\(x ^2\\). If she believed \\(p \\wedge q\\) to a degree greater than \\(r\\), she’d have to either have credences that were not supported by her evidence, or credences that were incoherent. (Or, most likely, both.) So this theory violates the platitude. This is a well-known argument, so there are many responses to it, most of them involving something like appeal to the preface paradox. I’ll argue in section 4 that the preface paradox doesn’t in fact offer the threshold view proponent much support here. But even before we get to there, we should note that the arbitrariness objection gives us sufficient reason to reject the threshold view.\nA better move is to start with the functionalist idea that to believe that p is to treat p as true for the purposes of practical reasoning. To believe p is to have preferences that make sense, by your own lights, in a world where p is true. So, if you prefer A to B and believe that p, you prefer A to B given p. For reasons that will become apparent below, we’ll work in this paper with a notion of preference where conditional preferences are primary.1 So the core insight we’ll work with is the following:\n1 To say the agent prefers A to B given \\(q\\) is not to say that if the agent were to learn \\(q\\), she would prefer A to B. It’s rather to say that she prefers the state of the world where she does A and \\(q\\) is true to the state of the world where she does B and \\(q\\) is true. These two will come apart in cases where learning \\(q\\) changes the agent’s preferences. We’ll return to this issue below.\nIf you prefer A to B given \\(q\\), and you believe that p, then you prefer A to B given \\(p \\wedge q\\)\n\nThe bold suggestion here is that if that is true for all the A, B and q that matter, then you believe p. Put formally, where Bel(p) means that the agent believes that p, and A \\(\\geq _q\\) B means that the agent thinks A is at least as good as B given \\(q\\), we have the following\n\nBel(p) \\(\\leftrightarrow \\forall\\)A\\(\\forall\\)B\\(\\forall q\\) (A \\(\\geq _q\\) B \\(\\leftrightarrow\\) A \\(\\geq _{p \\wedge q}\\) B)\n\nIn words, an agent believes that p iff conditionalising on p doesn’t change any conditional preferences over things that matter.2 The left-to-right direction of this seems trivial, and the right-to-left direction seems to be a plausible way to operationalise the functionalist insight that belief is a functional state. There is some work to be done if (1) is to be interpreted as a truth though.\n2 This might seem much too simple, especially when compared to all the bells and whistles that functionalists usually put in their theories to (further) distinguish themselves from crude versions of behaviourism. The reason we don’t need to include those complications here is that they will all be included in the analysis of preference. Indeed, the theory here is compatible with a thoroughly anti-functionalist treatment of preference. The claim is not that we can offer a functional analysis of belief in terms of non-mental concepts, just that we can offer a functionalist reduction of belief to other mental concepts. The threshold view is also such a reduction, but it is such a crude reduction that it doesn’t obviously fall into any category.If we interpret the quantifiers in (1) as unrestricted, then we get the (false) conclusion that just about no one believes no contingent propositions. To prove this, consider a bet that wins iff the statue in front of me waves back at me due to random quantum effects when I wave at it. If I take the bet and win, I get to live forever in paradise. If I take the bet and lose, I lose a penny. Letting A be that I take the bet, B be that I decline the bet, \\(q\\) be a known tautology (so my preferences given \\(q\\) are my preferences tout court) and p be that the statue does not wave back, we have that I prefer A to B, but not A to B given p. So by this standard I don’t believe that p. This is false – right now I believe that statues won’t wave back at me when I wave at them.\nThis seems like a problem. But the solution to it is not to give up on functionalism, but to insist on its pragmatic foundations. The quantifiers in (1) should be restricted, with the restrictions motivated pragmatically. What is crucial to the theory is to say what the restrictions on A and B are, and what the restrictions on \\(q\\) are. We’ll deal with these in order.\nFor better or worse, I don’t right now have the option taking that bet and hence spending eternity in paradise if the statue waves back at me. Taking or declining such unavailable bets are not open choices. For any option that is open to me, assuming that statues do not in fact wave does not change its utility. That’s to say, I’ve already factored in the non-waving behaviour of statues into my decision-making calculus. That’s to say, I believe statues don’t wave.\nAn action A is a live option for the agent if it is really possible for the agent to perform A. An action A is a salient option if it is an option the agent takes seriously in deliberation. Most of the time gambling large sums of money on internet gambling sites over my phone is a live option, but not a salient option. I know this option is suboptimal, and I don’t have to recompute every time whether I should do it. Whenever I’m making a decision, I don’t have to add in to the list of choices bet thousands of dollars on internet gambling sites, and then rerule that out every time. I just don’t consider that option, and properly so. If I have a propensity to daydream, then becoming the centrefielder for the Boston Red Sox might be a salient option to me, but it certainly isn’t a live option. We’ll say the two initial quantifiers range over the options that are live and salient options for the agent.\nNote that we don’t say that the quantifiers range over the options that are live and salient for the person making the belief ascription. That would lead us to a form of contextualism for which we have little evidence. We also don’t say that an option becomes salient for the agent iff they should be considering it. At this stage we are just saying what the agent does believe, not what they should believe, so we don’t have any clauses involving normative concepts.\nNow we’ll look at the restrictions on the quantifier over propositions. Say a proposition is relevant if the agent is disposed to take seriously the question of whether it is true (whether or not she is currently considering that question) and conditionalising on that proposition or its negation changes some of the agents unconditional preferences over live, salient options.3 The first clause is designed to rule out wild hypotheses that the agent does not take at all seriously. If \\(q\\) is not such a proposition, if the agent is disposed to take it seriously, then it is relevant if there are live, salient A and B such that A \\(\\geq _q\\) B \\(\\leftrightarrow\\) A \\(\\geq\\) B is false. Say a proposition is salient if the agent is currently considering whether it is true. Finally, say a proposition is active relative to p iff it is a (possibly degenerate) conjunction of propositions such that each conjunct is either relevant or salient, and such that the conjunction is consistent with p. (By a degenerate conjunction I mean a conjunction with just one conjunct. The consistency requirement is there because it might be hard in some cases to make sense of preferences given inconsistencies.) Then the propositional quantifier in (1) ranges over active propositions.\n3 Conditionalising on the proposition There are space aliens about to come down and kill all the people writing epistemology papers will make me prefer to stop writing this paper, and perhaps grab some old metaphysics papers I could be working on. So that proposition satisfies the second clause of the definition of relevance. But it clearly doesn’t satisfy the first clause. This part of the definition of relevance won’t do much work until the discussion of agents with mistaken environmental beliefs in section 7.We will expand and clarify this in the next section, but our current solution to the relationship between beliefs and degrees of belief is that degrees of belief determine an agent’s preferences, and she believes that p iff the claim (1) about her preferences is true when the quantifiers over options are restricted to live, salient actions, and the quantifier over propositions is restricted to salient propositions. The simple view would be to say that the agent believes that p iff conditioning on p changes none of her preferences. The more complicated view here is that the agent believes that p iff conditioning on p changes none of her conditional preferences over live, salient options, where the conditions are also active relative to p.\n\n\n0.3 Impractical Propositions\nThe theory sketched in the previous paragraph seems to me right in the vast majority of cases. It fits in well with a broadly functionalist view of the mind, and as we’ll see it handles some otherwise difficult cases with aplomb. But it needs to be supplemented a little to handle beliefs about propositions that are practically irrelevant. I’ll illustrate the problem, then note how I prefer to solve it.\nI don’t know what Julius Caeser had for breakfast the morning he crossed the Rubicon. But I think he would have had some breakfast. It is hard to be a good general without a good morning meal after all. Let p be the proposition that he had breakfast that morning. I believe p. But this makes remarkably little difference to my practical choices in most situations. True, I wouldn’t have written this paragraph as I did without this belief, but it is rare that I have to write about Caeser’s dietary habits. In general whether p is true makes no practical difference to me. This makes it hard to give a pragmatic account of whether I believe that p. Let’s apply (1) to see whether I really believe that p.\n\nBel(p) \\(\\leftrightarrow \\forall\\)A\\(\\forall\\)B\\(\\forall q\\) (A \\(\\geq _q\\) B \\(\\leftrightarrow\\) A \\(\\geq _{p \\wedge q}\\) B)\n\nSince p makes no practical difference to any choice I have to make, the right hand side is true. So the left hand side is true, as desired. The problem is that the right hand side of (2) is also true here.\n\nBel(\\(\\neg p\\)) \\(\\leftrightarrow \\forall\\)A\\(\\forall\\)B\\(\\forall q\\) (A \\(\\geq _q\\) B \\(\\leftrightarrow\\) A \\(\\geq _{\\neg p \\wedge q}\\) B)\n\nAdding the assumption that Caeser had no breakfast that morning doesn’t change any of my practical choices either. So I now seem to inconsistently believe both p and \\(\\neg p\\). I have some inconsistent beliefs, I’m sure, but those aren’t among them. We need to clarify what (1) claims.\nTo do so, I supplement the theory sketched in section 2 with the following principles.\n\nA proposition p is eligible for belief if it satisfies \\(\\forall\\)A\\(\\forall\\)B\\(\\forall q\\) (A \\(\\geq _q\\) B \\(\\leftrightarrow\\) A \\(\\geq _{p \\wedge q}\\) B), where the first two quantifiers range over the open, salient actions in the sense described in section 2.\nFor any proposition p, and any proposition \\(q\\) that is relevant or salient, among the actions that are (by stipulation!) open and salient with respect to p are believing that p, believing that q, not believing that p and not believing that q\nFor any proposition, the subject prefers believing it to not believing it iff (a) it is eligible for belief and (b) the agents degree of belief in the proposition is greater than \\(\\nicefrac{1}{2}\\).\nThe previous stipulation holds both unconditionally and conditional on p, for any p.\nThe agent believes that p iff \\(\\forall\\)A\\(\\forall\\)B\\(\\forall q\\) (A \\(\\geq _q\\) B \\(\\leftrightarrow\\) A \\(\\geq _{p \\wedge q}\\) B), where the first two quantifiers range over all actions that are either open and salient tout court (i.e. in the sense of section 2) or open and salient with respect to p (as described above).\n\nThis all looks moderately complicated, but I’ll explain how it works in some detail as we go along. One simple consequence is that an agent only believes that p iff their degree of belief in p is greater than \\(\\nicefrac{1}{2}\\). Since my degree of belief in Caeser’s foodless morning is not greater than \\(\\nicefrac{1}{2}\\), in fact it is considerably less, I don’t believe \\(\\neg p\\). On the other hand, since my degree of belief in p is considerably greater than \\(\\nicefrac{1}{2}\\), I prefer to believe it than disbelieve it, so I believe it.\nThere are many possible objections to this position, which I’ll address sequentially.\nObjection: Even if I have a high degree of belief in p, I might prefer to not believe p because I think that belief in p is bad for some other reason. Perhaps, if p is a proposition about my brilliance, it might be immodest to believe that p.\nReply: Any of these kinds of considerations should be put into the credences. If it is immodest to believe that you are a great philosopher, it is equally immodest to believe to a high degree that you are a great philosopher.\nObjection: Belief that p is not an action in the ordinary sense of the term.\nReply: True, which is why this is described as a supplement to the original theory, rather than just cashing out its consequences.\nObjection: It is impossible to choose to believe or not believe something, so we shouldn’t be applying these kinds of criteria.\nReply: I’m not as convinced of the impossibility of belief by choice as others are, but I won’t push that for present purposes. Let’s grant that beliefs are always involuntary. So these ‘actions’ aren’t open actions in any interesting sense, and the theory is section 2 was really incomplete. As I said, this is a supplement to the theory in section 2.\nThis doesn’t prevent us using principles of constitutive rationality, such as we prefer to believe p iff our credence in p is over \\(\\nicefrac{1}{2}\\). Indeed, on most occasions where we use constitutive rationality to infer that a person has some mental state, the mental state we attribute to them is one they could not fail to have. But functionalists are committed to constitutive rationality (Lewis 1994). So my approach here is consistent with a broadly functionalist outlook.\nObjection: This just looks like a roundabout way of stipulating that to believe that p, your degree of belief in p has to be greater than \\(\\nicefrac{1}{2}\\). Why not just add that as an extra clause than going through these little understood detours about preferences about beliefs?\nReply: There are three reasons for doing things this way rather than adding such a clause.\nFirst, it’s nice to have a systematic theory rather than a theory with an ad hoc clause like that.\nSecond, the effect of this constraint is much more than to restrict belief to propositions whose credence is greater than \\(\\nicefrac{1}{2}\\). Consider a case where p and \\(q\\) and their conjunction are all salient, p and \\(q\\) are probabilistically independent, and the agent’s credence in each is 0.7. Assume also that \\(p, q\\) and \\(p \\wedge q\\) are completely irrelevant to any practical deliberation the agent must make. Then the criteria above imply that the agent does not believe that p or that \\(q\\). The reason is that the agent’s credence in \\(p \\wedge q\\) is 0.49, so she prefers to not believe \\(p \\wedge q\\). But conditional on p, her credence in \\(p \\wedge q\\) is 0.7, so she prefers to believe it. So conditionalising on p does change her preferences with respect to believing \\(p \\wedge q\\), so she doesn’t believe p. So the effect of these stipulations rules out much more than just belief in propositions whose credence is below \\(\\nicefrac{1}{2}\\).\nThis suggests the third, and most important point. The problem with the threshold view was that it led to violations of closure. Given the theory as stated, we can prove the following theorem. Whenever p and \\(q\\) and their conjunction are all open or salient, and both are believed, and the agent is probabilistically coherent, the agent also believes \\(p \\wedge q\\). This is a quite restricted closure principle, but this is no reason to deny that it is true, as it fails to be true on the threshold view.\nThe proof of this theorem is a little complicated, but worth working through. First we’ll prove that if the agent believes p, believes \\(q\\), and p and \\(q\\) are both salient, then the agent prefers believing \\(p \\wedge q\\) to not believing it, if \\(p \\wedge q\\) is eligible for belief. In what follows Pr(\\(x | y\\)) is the agent’s conditional degree of belief in \\(x\\) given \\(y\\). Since the agent is coherent, we’ll assume this is a probability function (hence the name).\n\nSince the agent believes that \\(q\\), they prefer believing that \\(q\\) to not believing that \\(q\\) (by the criteria for belief)\nSo the agent prefers believing that \\(q\\) to not believing that \\(q\\) given p (From 1 and the fact that they believe that p, and that \\(q\\) is salient)\nSo Pr(\\(q | p\\)) \\(&gt; \\nicefrac{1}{2}\\) (from 2)\nPr(\\(q | p\\)) = Pr(\\(p \\wedge q | p\\)) (by probability calculus)\nSo Pr(\\(p \\wedge q | p\\)) \\(&gt; \\nicefrac{1}{2}\\) (from 3, 4)\nSo, if \\(p \\wedge q\\) is eligible for belief, then the agent prefers believing that \\(p \\wedge q\\) to not believing it, given p (from 5)\nSo, if \\(p \\wedge q\\) is eligible for belief, the agent prefers believing that \\(p \\wedge q\\) to not believing it (from 6, and the fact that they believe that p, and \\(p \\wedge q\\) is salient)\n\nSo whenever, \\(p, q\\) and \\(p \\wedge q\\) are salient, and the agent believes each conjunct, the agent prefers believing the conjunction \\(p \\wedge q\\) to not believing it, if \\(p \\wedge q\\) is eligible. Now we have to prove that \\(p \\wedge q\\) is eligible for belief, to prove that it is actually believed. That is, we have to prove that (5) follows from (4) and (3), where the initial quantifiers range over actions that are open and salient tout court.\n\n\\(\\forall\\)A\\(\\forall\\)B\\(\\forall r\\) (A \\(\\geq_r\\) B \\(\\leftrightarrow\\) A \\(\\geq _p \\wedge r\\) B)\n\\(\\forall\\)A\\(\\forall\\)B\\(\\forall r\\) (A \\(\\geq_r\\) B \\(\\leftrightarrow\\) A \\(\\geq _q \\wedge r\\) B)\n\\(\\forall\\)A\\(\\forall\\)B\\(\\forall r\\) (A \\(\\geq_r\\) B \\(\\leftrightarrow\\) A \\(\\geq _{p \\wedge q \\wedge r}\\) B)\n\nAssume that (5) isn’t true. That is, there are A, B and S such that \\(\\neg\\)(A \\(\\geq_s\\) B \\(\\leftrightarrow\\) A \\(\\geq _{p \\wedge q \\wedge s}\\)B). By hypothesis S is active, and consistent with \\(p \\wedge q\\). So it is the conjunction of relevant, salient propositions. Since \\(q\\) is salient, this means \\(q \\wedge s\\) is also active. Since S is consistent with \\(p \\wedge q\\), it follows that \\(q \\wedge s\\) is consistent with p. So \\(q \\wedge s\\) is a possible substitution instance for \\(r\\) in (3). Since (3) is true, it follows that A \\(\\geq _{q \\wedge s}\\) B \\(\\leftrightarrow\\) A \\(\\geq _{p \\wedge q \\wedge s}\\) B. By similar reasoning, it follows that \\(s\\) is a permissible substitution instance in (4), giving us A \\(\\geq_s\\) B \\(\\leftrightarrow\\) A \\(\\geq _{q \\wedge s}\\) B. Putting the last two biconditionals together we get A \\(\\geq_s\\) B \\(\\leftrightarrow\\) A \\(\\geq _{p \\wedge q \\wedge s}\\)B, contradicting our hypothesis that there is a counterexample to (5). So whenever (3) and (4) are true, (5) is true as well, assuming \\(p, q\\) and \\(p \\wedge q\\) are all salient.\n\n\n0.4 Defending Closure\nSo on my account of the connection between degrees of belief and belief tout court, probabilistic coherence implies logical coherence amongst salient propositions. The last qualification is necessary. It is possible for a probabilistically coherent agent to not believe the non-salient consequences of things they believe, and even for a probabilistically coherent agent to have inconsistent beliefs as long as not all the members of the inconsistent set are active. Some people argue that even this weak a closure principle is implausible. David Christensen (2005), for example, argues that the preface paradox provides a reason for doubting that beliefs must be closed under entailment, or even must be consistent. Here is his description of the case.\n\nWe are to suppose that an apparently rational person has written a long non-fiction book—say, on history. The body of the book, as is typical, contains a large number of assertions. The author is highly confident in each of these assertions; moreover, she has no hesitation in making them unqualifiedly, and would describe herself (and be described by others) as believing each of the book’s many claims. But she knows enough about the difficulties of historical scholarship to realize that it is almost inevitable that at least a few of the claims she makes in the book are mistaken. She modestly acknowledges this in her preface, by saying that she believes the book will be found to contain some errors, and she graciously invites those who discover the errors to set her straight. (Christensen 2005, 33–34)\n\nChristensen thinks such an author might be rational in every one of her beliefs, even though these are all inconsistent. Although he does not say this, nothing in his discussion suggests that he is using the irrelevance of some of the propositions in the author’s defence. So here is an argument that we should abandon closure amongst relevant beliefs.\nChristensen’s discussion, like other discussions of the preface paradox, makes frequent use of the fact that examples like these are quite common. We don’t have to go to fake barn country to find a counterexample to closure. But it seems to me that we need two quite strong idealisations in order to get a real counterexample here.\nThe first of these is discussed in forthcoming work by Ishani Maitra (Maitra 2010), and is briefly mentioned by Christensen in setting out the problem. We only have a counterexample to closure if the author believes every thing she writes in her book. (Indeed, we only have a counterexample if she reasonably believes every one of them. But we’ll assume a rational author who only believes what she ought to believe.) This seems unlikely to be true to me. An author of a historical book is like a detective who, when asked to put forward her best guess about what explains the evidence, says “If I had to guess, I’d say …” and then launches into spelling out her hypothesis. It seems clear that she need not believe the truth of her hypothesis. If she did that, she could not later learn it was true, because you can’t learn the truth of something you already believe. And she wouldn’t put any effort into investigating alternative suspects. But she can come to learn her hypothesis was true, and it would be rational to investigate other suspects. It seems to me (following here Maitra’s discussion) that we should understand scholarly assertions as being governed by the same kind of rules that govern detectives making the kind of speech being contemplated here. And those rules don’t require that the speaker believe the things they say without qualification. The picture is that the little prelude the detective explicitly says is implicit in all scholarly work.\nThere are three objections I know to this picture, none of them particularly conclusive. First, Christensen says that the author doesn’t qualify their assertions. But neither does our detective qualify most individual sentences. Second, Christensen says that most people would describe our author as believing her assertions. But it is also natural to describe our detective as believing the things she says in her speech. It’s natural to say things like “She thinks it was the butler, with the lead pipe,” in reporting her hypothesis. Third, Timothy Williamson (2000) has argued that if speakers don’t believe what they say, we won’t have an explanation of why Moore’s paradoxical sentences, like “The butler did it, but I don’t believe the butler did it,” are always defective. Whatever the explanation of the paradoxicality of these sentences might be, the alleged requirement that speakers believe what they say can’t be it. For our detective cannot properly say “The butler did it, but I don’t believe the butler did it” in setting out her hypothesis, even though believing the butler did it is not necessary for her to say “The butler did it” in setting out just that hypothesis.\nIt is plausible that for some kinds of books, the author should only say things they believe. This is probably true for travel guides, for example. Interestingly, casual observation suggests that authors of such books are much less likely to write modest prefaces. This makes some sense if those books can only include statements their authors believe, and the authors believe the conjunctions of what they believe.\nThe second idealisation is stressed by Simon Evnine (1999) in his paper “Believing Conjunctions”. The following situation does not involve me believing anything inconsistent.\n\nI believe that what Manny just said, whatever it was, is false.\nManny just said that the stands at Fenway Park are green.\nI believe that the stands at Fenway Park are green.\n\nIf we read the first claim de dicto, that I believe that Manny just said something false, then there is no inconsistency. (Unless I also believe that what Manny just said was that the stands in Fenway Park are green.) But if we read it de re, that the thing Manny just said is one of the things I believe to be false, then the situation does involve me being inconsistent. The same is true when the author believes that one of the things she says in her book is mistaken. If we understand what she says de dicto, there is no contradiction in her beliefs. It has to be understood de re before we get a logical problem. And the fact is that most authors do not have de re attitudes towards the claims made in their book. Most authors don’t even remember everything that’s in their books. (I’m not sure I remember how this section started, let alone this paper.) Some may argue that authors don’t even have the capacity to consider a proposition as long and complicated as the conjunction of all the claims in their book. Christensen considers this objection, but says it isn’t a serious problem.\n\nIt is undoubtedly true that ordinary humans cannot entertain book-length conjunctions. But surely, agents who do not share this fairly superficial limitation are easily conceived. And it seems just as wrong to say of such agents that they are rationally required to believe in the inerrancy of the books they write. (38: my emphasis)\n\nI’m not sure this is undoubtedly true; it isn’t clear that propositions (as opposed to their representations) have lengths. And humans can believe propositions that can be represented by sentences as long as books. But even without that point, Christensen is right that there is an idealisation here, since ordinary humans do not know exactly what is in a given book, and hence don’t have de re attitudes towards the propositions expressed in the book.\nI’m actually rather suspicious of the intuition that Christensen is pushing here, that idealising in this way doesn’t change intuitions about the case. The preface paradox gets a lot of its (apparent) force from intuitions about what attitude we should have towards real books. Once we make it clear that the real life cases are not relevant to the paradox, I find the intuitions become rather murky. But I won’t press this point.\nA more important point is that we believers in closure don’t think that authors should think their books are inerrant. Rather, following Stalnaker (1984), we think that authors shouldn’t unqualifiedly believe the individual statements in their book if they don’t believe the conjunction of those statements. Rather, their attitude towards those propositions (or at least some of them) should be that they are probably true. (As Stalnaker puts it, they accept the story without believing it.) Proponents of the preface paradox know that this is a possible response, and tend to argue that it is impractical. Here is Christensen on this point.\n\nIt is clear that our everyday binary way of talking about beliefs has immense practical advantages over a system which insisted on some more fine-grained reporting of degrees of confidence … At a minimum, talking about people as believing, disbelieving, or withholding belief has at least as much point as do many of the imprecise ways we have of talking about things that can be described more precisely. (96)\n\nRichard Foley makes a similar point.\n\nThere are deep reasons for wanting an epistemology of beliefs, reasons that epistemologies of degrees of belief by their very nature cannot possibly accommodate. (Foley 1993, 170, my emphasis)\n\nIt’s easy to make too much of this point. It’s a lot easier to triage propositions into TRUE, FALSE and NOT SURE and work with those categories than it is to work assign precise numerical probabilities to each proposition. But these are not the only options. Foley’s discussion subsequent to the above quote sometimes suggests they are, especially when he contrasts the triage with “indicat[ing] as accurately as I can my degree of confidence in each assertion that I defend.” (171) But really it isn’t much harder to add two more categories, PROBABLY TRUE and PROBABLY FALSE to those three, and work with that five-way division rather than a three-way division. It’s not clear that humans as they are actually constructed have a strong preference for the three-way over the five-way division, and even if they do, I’m not sure in what sense this is a ‘deep’ fact about them.\nOnce we have the five-way division, it is clear what authors should do if they want to respect closure. For any conjunction that they don’t believe (i.e. classify as true), they should not believe one of the conjuncts. But of course they can classify every conjunct as probably true, even if they think the conjunction is false, or even certainly false. Still, might it not be considered something of an idealisation to say rational authors must make this five-way distinction amongst propositions they consider? Yes, but it’s no more of an idealisation than we need to set up the preface paradox in the first place. To use the preface paradox to find an example of someone who reasonably violates closure, we need to insist on the following three constraints.\n\nThey are part of a research community where only asserting propositions you believe is compatible with active scholarship;\nThey know exactly what is in their book, so they are able to believe that one of the propositions in the book is mistaken, where this is understood de re; but\nThey are unable to effectively function if they have to effect a five-way, rather than a three-way, division amongst the propositions they consider.\n\nPut more graphically, to motivate the preface paradox we have to think that our inability to have de re thoughts about the contents of books is a “superficial constraint”, but our preference for working with a three-way rather than a five-way division is a “deep” fact about our cognitive system. Maybe each of these attitudes could be plausible taken on its own (though I’m sceptical of that) but the conjunction seems just absurd.\nI’m not entirely sure an agent subject to exactly these constraints is even fully conceivable. (Such an agent is negatively conceivable, in David Chalmers’s terminology, but I rather doubt they are positively conceivable.) But even if they are a genuine possibility, why the norms applicable to an agent satisfying that very gerrymandered set of constraints should be considered relevant norms for our state is far from clear. I’d go so far as to say it’s clear that the applicability (or otherwise) of a given norm to such an odd agent is no reason whatsoever to say it applies to us. But since the preface paradox only provides a reason for just these kinds of agents to violate closure, we have no reason for ordinary humans to violate closure. So I see no reason here to say that we can have probabilistic coherence without logical coherence, as proponents of the threshold view insist we can have, but which I say we can’t have at least when the propositions involved are salient. The more pressing question, given the failure of the preface paradox argument, is why I don’t endorse a much stronger closure principle, one that drops the restriction to salient propositions. The next section will discuss that point.\nI’ve used Christensen’s book as a stalking horse in this section, because it is the clearest and best statement of the preface paradox. Since Christensen is a paradox-mongerer and I’m a paradox-denier, it might be thought we have a deep disagreement about the relevant epistemological issues. But actually I think our overall views are fairly close despite this. I favour an epistemological outlook I call “Probability First”, the view that getting the epistemology of partial belief right is of the first importance, and everything else should flow from that. Christensen’s view, reduced to a slogan, is “Probability First and Last”. This section has been basically about the difference between those two slogans. It’s an important dispute, but it’s worth bearing in mind that it’s a factional squabble within the Probability Party, not an outbreak of partisan warfare.\n\n\n0.5 Too Little Closure?\nIn the previous section I defended the view that a coherent agent has beliefs that are deductively cogent with respect to salient propositions. Here I want to defend the importance of the qualification. Let’s start with what I take to be the most important argument for closure, the passage from Stalnaker’s Inquiry that I quoted above.\n\nReasoning in this way from accepted premises to their deductive consequences (\\(P\\), also \\(Q\\), therefore \\(R\\)) does seem perfectly straightforward. Someone may object to one of the premises, or to the validity of the argument, but one could not intelligibly agree that the premises are each acceptable and the argument valid, while objecting to the acceptability of the conclusion. (Stalnaker 1984, 92)\n\nStalnaker’s wording here is typically careful. The relevant question isn’t whether we can accept p, accept \\(q\\), accept p and \\(q\\) entail \\(r\\), and reject \\(r\\). As Christensen (2005 Ch. 4) notes, this is impossible even on the threshold view, as long as the threshold is above 2/3. The real question is whether we can accept p, accept \\(q\\), accept p and \\(q\\) entail \\(r\\), and fail to accept \\(r\\). And this is always a live possibility on any threshold view, though it seems absurd at first that this could be coherent.\nBut it’s important to note how active the verbs in Stalnaker’s description are. When faced with a valid argument we have to object to one of the premises, or the validity of the argument. What we can’t do is agree to the premises and the validity of the argument, while objecting to the conclusion. I agree. If we are really agreeing to some propositions, and objecting to others, then all those propositions are salient. And in that case closure, deductive coherence, is mandatory. This doesn’t tell us what we have to do if we haven’t previously made the propositions salient in the first place.\nThe position I endorse here is very similar in its conclusions to that endorsed by Gilbert Harman in Change in View. There Harman endorses the following principle. (At least he endorses it as true – he doesn’t seem to think it is particularly explanatory because it is a special case of a more general interesting principle.)\n\nRecognized Logical Implication Principle\n\nOne has reason to believe p if one recognizes that p is logically implied by one’s view. (Harman 1986, 17)\n\n\nThis seems right to me, both what it says and its implicature that the reason in question is not a conclusive reason. My main objection to those who use the preface paradox to argue against closure is that they give us a mistaken picture of what we have to do epistemically. When I have inconsistent beliefs, or I don’t believe some consequence of my beliefs, that is something I have a reason to deal with at some stage, something I have to do. When we say that we have things to do, we don’t mean that we have to do them right now, or instead of everything else. My current list of things to do includes cleaning my bathroom, yet here I am writing this paper, and (given the relevant deadlines) rightly so. We can have the job of cleaning up our epistemic house as something to do while recognising that we can quite rightly do other things first. But it’s a serious mistake to infer from the permissibility of doing other things that cleaning up our epistemic house (or our bathroom) isn’t something to be done. The bathroom won’t clean itself after all, and eventually this becomes a problem.\nThere is a possible complication when it comes to tasks that are very low priority. My attic is to be cleaned, or at least it could be cleaner, but there are no imaginable circumstances under which something else wouldn’t be higher priority. Given that, should we really leave clean the attic on the list of things to be done? Similarly, there might be implications I haven’t followed through that it couldn’t possibly be worth my time to sort out. Are they things to be done? I think it’s worthwhile recording them as such, because otherwise we might miss opportunities to deal with them in the process of doing something else. I don’t need to put off anything else in order to clean the attic, but if I’m up there for independent reasons I should bring down some of the garbage. Similarly, I don’t need to follow through implications mostly irrelevant to my interests, but if those propositions come up for independent reasons, I should deal with the fact that some things I believe imply something I don’t believe. Having it be the case that all implications from things we believe to things we don’t believe constitute jobs to do (possibly in the loose sense that cleaning my attic is something to do) has the right implications for what epistemic duties we do and don’t have.\nWhile waxing metaphorical, it seems time to pull out a rather helpful metaphor that Gilbert Ryle (1949) develops in The Concept of Mind at a point where he’s covering what we’d now call the inference/implication distinction. (This is a large theme of chapter 9, see particularly pages 292-309.) Ryle’s point in these passages, as it frequently is throughout the book, is to stress that minds are fundamentally active, and the activity of a mind cannot be easily recovered from its end state. Although Ryle doesn’t use this language, his point is that we shouldn’t confuse the difficult activity of drawing inferences with the smoothness and precision of a logical implication. The language Ryle does use is more picturesque. He compares the easy work a farmer does when sauntering down a path from the hard work he did when building the path. A good argument, in philosophy or mathematics or elsewhere, is like a well made path that permits sauntering from the start to finish without undue strain. But from that it doesn’t follow that the task of coming up with that argument, of building that path in Ryle’s metaphor, was easy work. The easiest paths to walk are often the hardest to build. Path-building, smoothing out our beliefs so they are consistent and closed under implication, is hard work, even when the finished results look clean and straightforward. Its work that we shouldn’t do unless we need to. But making sure our beliefs are closed under entailment even with respect to irrelevant propositions is suspiciously like the activity of buildings paths between points without first checking you need to walk between them.\nFor a less metaphorical reason for doubting the wisdom of this unchecked commitment to closure, we might notice the difficulties theorists tend to get into all sorts of difficulties. Consider, for example, the view put forward by Mark Kaplan in Decision Theory as Philosophy. Here is his definition of belief.\n\nYou count as believing P just if, were your sole aim to assert the truth (as it pertains to P), and you only options were to assert that P, assert that \\(\\neg\\)P or make neither assertion, you would prefer to assert that P. (109)\n\nKaplan notes that conditional definitions like this are prone to Shope’s conditional fallacy. If my sole aim were to assert the truth, I might have different beliefs to what I now have. He addresses one version of this objection (namely that it appears to imply that everyone believes their sole desire is to assert the truth) but as we’ll see presently he can’t avoid all versions of it.\nThese arguments are making me thirsty. I’d like a beer. Or at least I think I would. But wait! On Kaplan’s theory I can’t think that I’d like a beer, for if my sole aim were to assert the truth as it pertains to my beer-desires, I wouldn’t have beer desires. And then I’d prefer to assert that I wouldn’t like a beer, I’d merely like to assert the truth as it pertains to my beer desires.\nEven bracketing this concern, Kaplan ends up being committed to the view that I can (coherently!) believe that p even while regarding p as highly improbable. This looks like a refutation of the view to me, but Kaplan accepts it with some equanimity. He has two primary reasons for saying we should live with this. First, he says that it only looks like an absurd consequence if we are committed to the Threshold View. To this all I can say is that I don’t believe the Threshold View, but it still seems absurd to me. Second, he says that any view is going to have to be revisionary to some extent, because our ordinary concept of belief is not “coherent” (142). His view is that, “Our ordinary notion of belief both construes belief as a state of confidence short of certainty and takes consistency of belief to be something that is at least possible and, perhaps, even desirable” and this is impossible. I think the view here interprets belief as a state less than confidence and allows for as much consistency as the folk view does (i.e. consistency amongst salient propositions), so this defence is unsuccessful as well.\nNone of the arguments here in favour of our restrictions on closure are completely conclusive. In part the argument at this stage rests on the lack of a plausible rival theory that doesn’t interpret belief as certainty but implements a stronger closure principle. It’s possible that tomorrow someone will come up with a theory that does just this. Until then, we’ll stick with the account here, and see what its epistemological implications might be.\n\n\n0.6 Examples of Pragmatic Encroachment\nFantl and McGrath’s case for pragmatic encroachment starts with cases like the following. (The following case is not quite theirs, but is similar enough to suit their plan, and easier to explain in my framework.)\n\nLocal and Express\nThere are two kinds of trains that run from the city to the suburbs: the local, which stops at all stations, and the express, which skips the first eight stations. Harry and Louise want to go to the fifth station, so they shouldn’t catch the Express. Though if they do it isn’t too hard to catch a local back the other way, so it isn’t usually a large cost. Unfortunately, the trains are not always clearly labelled. They see a particular train about to leave. If it’s a local they are better off catching it, if it is an express they should wait for the next local, which they can see is already boarding passengers and will leave in a few minutes. While running towards the train, they hear a fellow passenger say “It’s a local.” This gives them good, but far from overwhelming, reason to believe that the train is a local. Passengers get this kind of thing wrong fairly frequently, but they don’t have time to get more information. So each of them face a gamble, which they can take by getting on the train. If the train is a local, they will get home a few minutes early. If it is an express they will get home a few minutes later. For Louise, this is a low stakes gamble, as nothing much turns on whether she is a few minutes early or late, but she does have a weak preference for arriving earlier rather than later. But for Harry it is a high stakes gamble, because if he is late he won’t make the start of his daughter’s soccer game, which will highly upset her. There is no large payoff for Harry arriving early.\n\nWhat should each of them do? What should each of them believe?\nThe first question is relatively easy. Louise should catch the train, and Harry should wait for the next. For each of them that’s the utility maximising thing to do. The second one is harder. Fantl and McGrath suggest that, despite being in the same epistemic position with respect to everything except their interests, Louise is justified in believing the train is a local and Harry is not. I agree. (If you don’t think the particular case fits this pattern, feel free to modify it so the difference in interests grounds a difference in what they are justified in believing.) Does this show that our notion of epistemic justification has to be pragmatically sensitive? I’ll argue that it does not.\nThe fundamental assumption I’m making is that what is primarily subject to epistemic evaluation are degrees of belief, or what are more commonly called states of confidence in ordinary language. When we think about things this way, we see that Louise and Harry are justified in adopting the very same degrees of belief. Both of them should be confident, but not absolutely certain, that the train is a local. We don’t have even the appearance of a counterxample to Probabilistic Evidentialism here. If we like putting this in numerical terms, we could say that each of them is justified in assigning a probability of around 0.9 to the proposition That train is a local.4 So as long as we adopt a Probability First epistemology, where we in the first instance evaluate the probabilities that agents assign to propositions, Harry and Louise are evaluated alike iff they do the same thing.\n4 I think putting things numerically is misleading because it suggests that the kind of bets we usually use to measure degrees of belief are open, salient options for Louise and Harry. But if those bets were open and salient, they wouldn’t believe the train is a local. Using qualitative rather than quantitative language to describe them is just as accurate, and doesn’t have misleading implications about their practical environment.How then can we say that Louise alone is justified in believing that the train is a local? Because that state of confidence they are justified in adopting, the state of being fairly confident but not absolutely certain that the train is a local, counts as believing that the train is a local given Louise’s context but not Harry’s context. Once Louise hears the other passenger’s comment, conditionalising on That’s a local doesn’t change any of her preferences over open, salient actions, including such ‘actions’ as believing or disbelieving propositions. But conditional on the train being a local, Harry prefers catching the train, which he actually does not prefer.\nIn cases like this, interests matter not because they affect the degree of confidence that an agent can reasonably have in a proposition’s truth. (That is, not because they matter to epistemology.) Rather, interests matter because they affect whether those reasonable degrees of confidence amount to belief. (That is, because they matter to philosophy of mind.) There is no reason here to let pragmatic concerns into epistemology.\n\n\n0.7 Justification and Practical Reasoning\nThe discussion in the last section obviously didn’t show that there is no encroachment of pragmatics into epistemology. There are, in particular, two kinds of concerns one might have about the prospects for extending my style of argument to block all attempts at pragmatic encroachment. The biggest concern is that it might turn out to be impossible to defend a Probability First epistemology, particularly if we do not allow ourselves pragmatic concerns. For instance, it is crucial to this project that we have a notion of evidence that is not defined in terms of traditional epistemic concepts (e.g. as knowledge), or in terms of interests. This is an enormous project, and I’m not going to attempt to tackle it here. The second concern is that we won’t be able to generalise the discussion of that example to explain the plausibility of (JP) without conceding something to the defenders of pragmatic encroachment.\n\n(JP)\n\nIf S justifiably believes that p, then S is justified in using p as a premise in practical reasoning.\n\n\nAnd that’s what we will look at in this section. To start, we need to clarify exactly what (JP) means. Much of this discussion will be indebted to Fantl and McGrath’s discussion of various ways of making (JP) more precise. To see some of the complications at issue, consider a simple case of a bet on a reasonably well established historical proposition. The agent has a lot of evidence that supports p, and is offered a bet that returns $1 if p is true, and loses $500 if p is false. Since her evidence doesn’t support that much confidence in p, she properly declines the bet. One might try to reason intuitively as follows. Assume that she justifiably believed that p. Then she’d be in a position to make the following argument.\n\np\nIf p, then I should take the bet\nSo, I should take the bet\n\nSince she isn’t in a position to draw the conclusion, she must not be in a position to endorse both of the premises. Hence (arguably) she isn’t justified in believing that p. But we have to be careful here. If we assume also that p is true (as Fantl and McGrath do, because they are mostly concerned with knowledge rather than justified belief), then the second premise is clearly false, since it is a conditional with a true antecedent and a false consequent. So the fact that she can’t draw the conclusion of this argument only shows that she can’t endorse both of the premises, and that’s not surprising since one of the premises is most likely false. (I’m not assuming here that the conditional is true iff it has a true antecendent or a false consequent, just that it is only true if it has a false antecedent or a true consequent.)\nIn order to get around this problem, Fantl and McGrath suggest a few other ways that our agent might reason to the bet. They suggest each of the following principles.\n\nS knows that p only if, for any act A, if S knows that if p, then A is the best thing she can do, then S is rational to do A. (72)\nS knows that p only if, for any states of affairs A and B, if \\(S\\) knows that if p, then A is better for her than B, then S is rational to prefer A to B. (74)\n(PC) S is justified in believing that p only if S is rational to prefer as if p. (77)\n\nHawthorne (2004, 174–81) appears to endorse the second of these principles. He considers an agent who endorses the following implication concerning a proposed sell of a lottery ticket for a cent, which is well below its actuarially fair value.\n\nI will lose the lottery.\nIf I keep the ticket, I will get nothing.\nIf I sell the ticket, I will get a cent.\nSo I ought to sell the ticket. (174)\n\n(To make this fully explicit, it helps to add the tacit premise that a cent is better than nothing.) Hawthorne says that this is intuitively a bad argument, and concludes that the agent who attempts to use it is not in a position to know its first premise. But that conclusion only follows if we assume that the argument form is acceptable. So it is plausible to conclude that he endorses Fantl and McGrath’s second principle.\nThe interesting question here is whether the theory endorsed in this paper can validate the true principles that Fantl and McGrath articulate. (Or, more precisely, we can validate the equivalent true principles concerning justified belief, since knowledge is outside the scope of the paper.) I’ll argue that it can in the following way. First, I’ll just note that given the fact that the theory here implies the closure principles we outlined in section 5, we can easily enough endorse Fantl and McGrath’s first two principles. This is good, since they seem true. The longer part of the argument involves arguing that their principle (PC), which doesn’t hold on the theory endorsed here, is in fact incorrect.\nOne might worry that the qualification on the closure principles in section 5 mean that we can’t fully endorse the principles Fantl and McGrath endorse. In particular, it might be worried that there could be an agent who believes that p, believes that if p, then A is better than B, but doesn’t put these two beliefs together to infer that A is better than B. This is certainly a possibility given the qualifications listed above. But note that in this position, if those two beliefs were justified, the agent would certainly be rational to conclude that A is better than B, and hence rational to prefer A to B. So the constraints on the closure principles don’t affect our ability to endorse these two principles.\nThe real issue is (PC). Fantl and McGrath offer a lot of cases where (PC) holds, as well as arguing that it is plausibly true given the role of implications in practical reasoning. What’s at issue is that (PC) is stronger than a deductive closure principle. It is, in effect, equivalent to endorsing the following schema as a valid principle of implication.\n\np\nGiven p, A is preferable to B\nSo, A is preferable to B\n\nI call this Practical Modus Ponens, or PMP. The middle premise in PMP is not a conditional. It is not to be read as If p, then A is preferable to B. Conditional valuations are not conditionals. To see this, again consider the proposed bet on (true) p at exorbitant odds, where A is the act of taking the bet, and B the act of declining the bet. It’s true that given p, A is preferable to B. But it’s not true that if p, then A is preferable to B. Even if we restrict our attention to cases where the preferences in question are perfectly valid, this is a case where PMP is invalid. Both premises are true, and the conclusion is false. It might nevertheless be true that whenever an agent is justified in believing both of the premises, she is justified in believing the conclusion. To argue against this, we need a very complicated case, involving embedded bets and three separate agents, Quentin, Robby and Thom. All of them have received the same evidence, and all of them are faced with the same complex bet, with the following properties.\n\np is an historical proposition that is well (but not conclusively) supported by their evidence, and happens to be true. All the agents have a high credence in p, which is exactly what the evidence supports.\nThe bet A, which they are offered, wins if p is true, and loses if p is false.\nIf they win the bet, the prize is the bet B.\nS is also an historical proposition, but the evidence tells equally for and against it. All the agents regard S as being about as likely as not. Moreover, S turns out to be false.\nThe bet B is worth $2 if S is true, and worth -$1 if S is false. Although it is actually a losing bet, the agents all rationally value it at around 50 cents.\nHow much A costs is determined by which proposition from the partition {\\(q, r, s\\)} is true.\nIf \\(q\\) is true, A costs $2\nIf \\(r\\) is true, A costs $500\nIf \\(t\\) is true, A costs $1\nThe evidence the agents has strongly supports \\(r\\), though \\(t\\) is in fact true\nQuentin believes \\(q\\)\nRobby believes \\(r\\)\nThom believes \\(t\\)\n\nAll of the agents make the utility calculations that their beliefs support, so Quentin and Thom take the bet and lose a dollar, while Robby declines it. Although Robby has a lot of evidence in favour of p, he correctly decides that it would be unwise to bet on p at effective odds of 1000 to 1 against. I’ll now argue that both Quentin and Thom are potential counterexamples to (PC). There are three possibilities for what we can say about those two.\nFirst, we could say that they are justified in believing p, and rational to take the bet. The problem with this position is that if they had rational beliefs about the partition {\\(q, r, t\\)} they would realise that taking the bet does not maximise expected utility. If we take rational decisions to be those that maximise expected utility given a rational response to the evidence, then the decisions are clearly not rational.\nSecond, we could say that although Quentin and Thom are not rational in accepting the bet, nor are they justified in believing that p. This doesn’t seem particularly plausible for several reasons. The irrationality in their belief systems concerns whether \\(q, r\\) or \\(t\\) is true, not whether p is true. If Thom suddenly got a lot of evidence that \\(t\\) is true, then all of his (salient) beliefs would be well supported by the evidence. But it is bizarre to think that whether his belief in p is rational turns on how much evidence he has for \\(t\\). Finally, even if we accept that agents in higher stakes situations need more evidence to have justified beliefs, the fact is that the agents are in a low-risk situation, since \\(t\\) is actually true, so the most they could lose is $1.\nSo it seems like the natural thing to say is that Quentin and Thom are justified in believing that p, and are justified in believing that given p, it maximises expected utility to take the bet, but they are not rational to take the bet. (At least, in the version of the story where they are thinking about which of \\(q, r\\) and \\(t\\) are correct given their evidence when thinking about whether to take the bet they are counterexamples to (PC).) Against this, one might respond that if belief in p is justified, there are arguments one might make to the conclusion that the bet should be taken. So it is inconsistent to say that the belief is justified, but the decision to take the bet is not rational. The problem is finding a premise that goes along with p to get the conclusion that taking the bet is rational. Let’s look at some of the premises the agent might use.\n\nIf p, then the best thing to do is to take the bet.\n\nThis isn’t true (p is true, but the best thing to do isn’t to take the bet). More importantly, the agents think this is only true if S is true, and they think S is a 50/50 proposition. So they don’t believe this premise, and it would not be rational to believe it.\n\nIf p, then probably the best thing to do is to take the bet.\n\nAgain this isn’t true, and it isn’t well supported, and it doesn’t even support the conclusion, for it doesn’t follow from the fact that \\(x\\) is probably the best thing to do that \\(x\\) should be done.\n\nIf p, then taking the bet maximises rational expected utility.\n\nThis isn’t true – it is a conditional with a true antecedent and a false consequent. Moreover, if Quentin and Thom were rational, like Robby, they would recognise this.\n\nIf p, then taking the bet maximises expected utility relative to their beliefs.\n\nThis is true, and even reasonable to believe, but it doesn’t imply that they should take the bet. It doesn’t follow from the fact that doing something maximises expected utility relative to my crazy beliefs that I should do that thing.\n\nGiven p, taking the bet maximises rational expected utility.\n\nThis is true, and even reasonable to believe, but it isn’t clear that it supports the conclusion that the agents should take the bet. The implication appealed to here is PMP, and in this context that’s close enough to equivalent to (PC). If we think that this case is a prima facie problem for (PC), as I think is intuitively plausible, then we can’t use (PC) to show that it doesn’t post a problem. We could obviously continue for a while, but it should be clear it will be very hard to find a way to justify taking the bet even spotting the agents p as a premise they can use in rational deliberation. So it seems to me that (PC) is not in general true, which is good because as we’ll see in cases like this one the theory outlined here does not support it.\nThe theory we have been working with says that belief that p is justified iff the agent’s degree of belief in p is sufficient to amount to belief in their context, and they are justified in believing p to that degree. Since by hypothesis Quentin and Thom are justified in believing p to the degree that they do, the only question left is whether this amounts to belief. This turns out not to be settled by the details of the case as yet specified. At first glance, assuming there are no other relevant decisions, we might think they believe that p because (a) they prefer (in the relevant sense) believing p to not believing p, and (b) conditionalising on p doesn’t change their attitude towards the bet. (They prefer taking the bet to declining it, both unconditionally and conditional on p.)\nBut that isn’t all there is to the definition of belief tout court. We must also ask whether conditionalising on p changes any preferences conditional on any active proposition. And that may well be true. Conditional on \\(r\\), Quentin and Thom prefer not taking the bet to taking it. But conditional on \\(r\\) and p, they prefer taking the bet to not taking it. So if \\(r\\) is an active proposition, they don’t believe that p. If \\(r\\) is not active, they do believe it. In more colloquial terms, if they are concerned about the possible truth of \\(r\\) (if it is salient, or at least not taken for granted to be false) then p becomes a potentially high-stakes proposition, so they don’t believe it without extraordinary evidence (which they don’t have). Hence they are only a counterexample to (PC) if \\(r\\) is not active. But if \\(r\\) is not active, our theory predicts that they are a counterexample to (PC), which is what we argued above is intuitively correct.\nStill, the importance of \\(r\\) suggests a way of saving (PC). Above I relied on the position that if Quentin and Thom are not maximising rational expected utility, then they are being irrational. This is perhaps too harsh. There is a position we could take, derived from some suggestions made by Gilbert Harman in Change in View, that an agent can rationally rely on their beliefs, even if those beliefs were not rationally formed, if they cannot be expected to have kept track of the evidence they used to form that belief. If we adopt this view, then we might be able to say that (PC) is compatible with the correct normative judgments about this case.\nTo make this compatibility explicit, let’s adjust the case so Quentin takes \\(q\\) for granted, and cannot be reasonably expected to have remembered the evidence for \\(q\\). Thom, on the other hand, forms the belief that \\(t\\) rather than \\(r\\) is true in the course of thinking through his evidence that bears on the rationality of taking or declining the bet. (In more familiar terms, \\(t\\) is part of the inference Thom uses in coming to conclude that he should take the bet, though it is not part of the final implication he endorses whose conclusion is that he should take the bet.) Neither Quentin nor Thom is a counterexample to (PC) thus understood. (That is, with the notion of rationality in (PC) understood as Harman suggests that it should be.) Quentin is not a counterexample, because he is rational in taking the bet. And Thom is not a counterexample, because in his context, where \\(r\\) is active, his credence in p does not amount to belief in p, so he is not justified in believing p.\nWe have now two readings of (PC). On the strict reading, where a rational choice is one that maximises rational expected utility, the principle is subject to counterexample, and seems generally to be implausible. On the loose reading, where we allow agents to rely on beliefs formed irrationally in the past in rational decision making, (PC) is plausible. Happily, the theory sketched here agrees with (PC) on the plausible loose reading, but not on the implausible strict reading. In the previous section I argued that the theory also accounts for intuitions about particular cases like Local and Express. And now we’ve seen that the theory accounts for our considered opinions about which principles connecting justified belief to rational decision making we should endorse. So it seems at this stage that we can account for the intuitions behind the pragmatic encroachment view while keeping a concept of probabilistic epistemic justification that is free of pragmatic considerations.\n\n\n0.8 Conclusions\nGiven a pragmatic account of belief, we don’t need to have a pragmatic account of justification in order to explain the intuitions that whether \\(S\\) justifiably believes that p might depend on pragmatic factors. My focus here has been on sketching a theory of belief on which it is the belief part of the concept of a justified belief which is pragmatically sensitive. I haven’t said much about why we should prefer to take that option than say that the notion of epistemic justification is a pragmatic notion. I’ve mainly been aiming to show that a particular position is an open possibility, namely that we can accept that whether a particular agent is justified in believing p can be sensitive to their practical environment without thinking that the primary epistemic concepts are themselves pragmatically sensitive.\n\n\n\n\n\n\nReferences\n\nBovens, Luc, and James Hawthorne. 1999. “The Preface, the Lottery, and the Logic of Belief.” Mind 108 (430): 241–64. https://doi.org/10.1093/mind/108.430.241.\n\n\nChristensen, David. 2005. Putting Logic in Its Place. Oxford: Oxford University Press.\n\n\nEvnine, Simon. 1999. “Believing Conjunctions.” Synthese 118: 201–27. https://doi.org/10.1023/A:1005114419965.\n\n\nFantl, Jeremy, and Matthew McGrath. 2002. “Evidence, Pragmatics, and Justification.” Philosophical Review 111: 67–94. https://doi.org/10.2307/3182570.\n\n\nFoley, Richard. 1993. Working Without a Net. Oxford: Oxford University Press.\n\n\nHarman, Gilbert. 1986. Change in View. Cambridge, MA: Bradford.\n\n\nHawthorne, John. 2004. Knowledge and Lotteries. Oxford: Oxford University Press.\n\n\nHunter, Daniel. 1996. “On the Relation Between Categorical and Probabilistic Belief.” Noûs 30: 75–98. https://doi.org/10.2307/2216304.\n\n\nKaplan, Mark. 1996. Decision Theory as Philosophy. Cambridge: Cambridge University Press.\n\n\nKeynes, John Maynard. 1921. Treatise on Probability. London: Macmillan.\n\n\nLewis, David. 1994. “Reduction of Mind.” In A Companion to the Philosophy of Mind, edited by Samuel Guttenplan, 412–31. Oxford: Blackwell. https://doi.org/10.1017/CBO9780511625343.019.\n\n\nMaitra, Ishani. 2010. “Assertion, Norms and Games.” In Assertion: New Philosophical Essays, edited by Jessica Brown and Herman Cappelen, 277–96. Oxford: Oxford University Press.\n\n\nRyle, Gilbert. 1949. The Concept of Mind. New York: Barnes; Noble.\n\n\nStalnaker, Robert. 1984. Inquiry. Cambridge, MA: MIT Press.\n\n\nStanley, Jason. 2005. Knowledge and Practical Interests. Oxford University Press.\n\n\nWeatherson, Brian. 2005. “True, Truer, Truest.” Philosophical Studies 123 (1-2): 47–70. https://doi.org/10.1007/s11098-004-5218-x.\n\n\nWilliamson, Timothy. 1994. Vagueness. Routledge.\n\n\n———. 2000. Knowledge and its Limits. Oxford University Press."
  },
  {
    "objectID": "posts/dpww/doing-philosophy-with-words.html",
    "href": "posts/dpww/doing-philosophy-with-words.html",
    "title": "Doing Philosophy With Words",
    "section": "",
    "text": "Scott Soames (2003) has written two wonderfully useful books that will be valuable introductions to twentieth century philosophy. The books arose out of his well-received classes on the history of twentieth century history at Princeton, and will be valuable to anyone teaching similar courses. I shall be relying on them as I teach such a course at Cornell.\n\nPublished in Philosophical Studies 135 (2007): 429-37.\n\nThe books consist of detailed case studies of important twentieth-century works. They are best read alongside those original texts. Anyone who works through the canon in this way will have an excellent introduction to what twentieth century philosophers were trying to do. The selections are judicious, and while some are obvious classics some are rather clever choices of papers that are representative of the type of work being done at the time. And Soames doesn’t just point to the most important works to study, but the most important sections of those works.\n\nThanks to David Chalmers, Michael Fara, John Fischer, Tamar Szabó Gendler, James Klagge, Michael Kremer, Ishani Maitra, Aidan McGlynn, Alva Noë, Jonathan Weinberg and Larry Wright.\n\nSoames’s discussion of these pieces is always built around an analysis of their strengths and weaknesses. He praises the praiseworthy, but the focus, at least in the sections I’m discussing (ordinary language philosophy from Wittgenstein to Grice), is on where these philosophers go wrong. This is particularly so when the mistakes are representative of a theme. There are three main mistakes Soames finds in philosophers of this period. First, they rely logical positivism long after it had been shown to be unviable. Second, they disregard the principle that semantics should be systematic. Third, they ignore the distinction between necessity and a priority. All three constitute major themes of Soames’s book, and indeed of twentieth century philosophy as Soames sees it.\nThese books concentrate, almost to a fault, on discussion of philosophers’ published works, as opposed to the context in which they are written. Apart from occasionally noting that some books were released posthumously, we aren’t told whether the philosophers who wrote them are alive, and only in one case are we told when a philosopher was born. This kind of external information does not seem important to Soames. He is the kind of historian who would prefer a fourth reading of Austin’s published works to a first reading of his wartime diaries. And he’d prefer to spend the evening working on refutations, or charitable reformulations, of Austin’s arguments to either. I’m mostly sympathetic to this approach; this is history of philosophy after all. We can leave discussions of the sociology of 1950s Oxford to those better qualified. But this choice about what to write about has consequences.\nMost of Soames’s chapters focus almost exclusively on a particular book or paper. The exceptions are like the chapter on Sense and Sensibilia, where Soames contrasts Austin’s discussion with Ayer’s response. We learn a lot about the most important works that way, but less about their intellectual environment. So the book doesn’t have much by way of broad discussion about overall trends or movements. There’s very little, for example, about who were the influencers and who the influenced. There’s nothing about how anyone not called ‘Wittgenstein’ changed their positions in response to criticism. One assumes from the chronology that Ryle’s influence on Austin was greater than Austin’s influence on Ryle, for example, but Soames is silent on whether this is true.\nSoames says at one point that, “[Ryle] was, along with Wittgenstein, J. L. Austin, and Paul Grice, one of the prime movers in postwar philosophy in England.” (68). But we aren’t really told why this is so, apart from the discussion of some prominent works of these four philosophers. (Perhaps Soames has taken the maxim Show it, don’t say it rather completely to heart.) Nor are why told why the list includes those four, and not, say, Strawson or Geach or Anscombe. Actually Anscombe’s absence reminds us that there is almost no discussion of women in philosophy in the book. That’s not Soames fault, it’s a reflection of a long-running systematic problem in philosophy that the discipline has a hard time recruiting and retaining women. Could some of that be traced back to what was going on in the ordinary language period? That kind of questions can’t be addressed by the kind of history book that Soames has written, where the focus is on the best philosophical writing, and not on the broader philosophical community.\nOne of the other consequences of the format is that, by necessity, many important figures are left out, on pain of writing a fifteen-volume book. In the period under discussion here there was historically important work by (among many others) Nelson Goodman, Wilfrid Sellars and Roderick Chisholm, some of which connects up closely to the themes and interests of the ordinary language philosophers, but none of which is as much as mentioned. (Goodman is mentioned in the epilogue as someone Soames regrets not covering.)\nNow this can’t be a complaint about the book Soames has written, because it would have been impossible to cover any more figures than he did in the style and depth that he did. And it would have been impossible to tell in detail the story of how Ryle’s impact on the philosophical world differed from Austin’s, or of the painfully slow integration of women into the top echelons of philosophy, without making the book be even more monumental than it is. All we’re left with is a half-hearted expression of regret that he didn’t write a different kind of book, one that told us more about the forest, even as we value what he says about the tallest of the trees.\n\n0.1 Grice and The End of Ordinary Language\nThere is one place where Soames stops to survey the field, namely his discussion of the impact of Grice’s work on the ordinary language tradition. Soames argues that with Grice’s William James lectures, the idea of ordinary language philosophy had “run their course”. The position seems to be that Grice overthrew a paradigm that had been vibrant for two decades, but was running out of steam by the time of Grice’s James lectures. How plausible is this?\nThe first step is to work out just what it was that Grice (1989) refuted. When summarising the ordinary language paradigm that he takes Grice to have overthrown, Soames is uncharacteristically harsh. In Soames’s summary one of the characteristic activities of an ordinary language philosopher is “opportunistically assembling reminders about how philosophically significant words are used in ordinary settings” (216). That may be a fair enough description of some mid-century work, but it isn’t a fair summary of the best of the work that Soames has spent the previous two hundred odd pages discussing. It all suggests that Grice didn’t so much overthrow ordinary language philosophy as much as badly done ordinary language philosophy, and this category might not include Strawson, Ryle, Austin and so on.\nMore importantly, it isn’t entirely clear just what it was Grice did that caused this paradigm shift. In Soames’s telling it seems the development of the speaker meaning/semantic meaning distinction was crucial, but Austin (1962) at least already recognised this distinction, indeed appealed to it twice in Sense and Sensibilia. Soames mentions the discussion on pages 89 to 91 of Sense and Sensibilia of phrases like “I see two pieces of paper”, and there is also the intriguing discussion on pages 128-9 of the relation between accurate and true where Austin goes close to stating Grice’s submaxim of concision.\nThe other suggestion is that Grice restored the legitimacy and centrality of systematic semantic theorising. It’s true Grice did that, but this doesn’t show we have to give up ordinary language philosophy unless it was impossible to be an ordinary language philosopher and a systematic semanticist. And it isn’t clear that this really is impossible. It hardly seems inconsistent with the kind of philosophy Austin did (especially in his theory of perception) that one endorse a systematic semantic theory. (Though Austin himself rarely put forward systematic analyses.) Notably, there are plenty of very systematic formal semanticists who take Strawson’s work on descriptions seriously, and try and integrate it into formal models. So we might wonder why Grice’s work shouldn’t have led to a kind of ordinary language philosophy where we paid more careful attention to system-building.\nMore broadly, we might wonder whether the ordinary language period really did end. The analysis of knowledge industry (strangely undiscussed in a work on analysis in the twentieth century) seemed to putter along much the same before and after the official demise of ordinary language philosophy. And there are affinities between the ordinary language philosophers and important contemporary research programs, e.g. the ‘Canberra Plan’ as described by Frank Jackson (1998). So perhaps before we asked who killed ordinary language philosophy (It was Professor Grice! In Emerson Hall!! With the semantics/pragmatics distinction!!!) we should have made sure there was a corpse. More on this point presently.\n\n\n0.2 A Whig History?\nOne of the major themes of Soames’s discussion is that there are some systematic problems in twentieth century philosophy that are righted by the heroes at the end of the story. I already mentioned the heroic role assigned to Grice. But the real star of the show is Kripke (1980), who comes in as a deus ex machina at the end showing how different necessity and a priority are, and thereby righting all manner of grievous wrongs. That Kripke is an important figure in twentieth century philosophy is hardly a matter of dispute, but Soames does stretch a little to find errors for our hero to correct.\nSome of the complaints about philosophers collapsing the necessary/a priori distinction do hit the target, but don’t leave deep wounds in their victims. For instance, Soames quotes Ryle (1954) arguing (in Dilemmas) that perception cannot be a physiological process because if it were we couldn’t know whether we saw a tree until we found out the result of complicated brain scans. Soames points out, perfectly correctly, that the seeing might be necessarily identical to the brain process even if we don’t know, and even can’t know without complicated measurements, whether they are identical. Soames is right that Ryle has made an epistemological argument here when a metaphysical argument was needed. But rewriting Ryle so he makes that metaphysical argument isn’t hard. If my seeing the tree is necessarily identical to the brain process, and the brain process is (as Ryle and Soames seem to agree it is) individuated by the brain components that implement it, then I couldn’t have seen the tree had one of the salient neurons in my brain been silently replaced with a functionally equivalent silicon chip. Since it is possible that I could have seen a tree even if a salient neuron was replaced with a functionally equivalent silicon chip, the seeing and the brain process are not necessarily identical. So while Ryle might have slipped here, and Kripke’s work does help us correct the slip, the consequences of this are basically verbal.\nA more important charge of ignoring the necessary/a priori distinction comes in Soames’s discussion of Wittgenstein’s deflationism about philosophy. Here is the salient passage.\n\nHis deflationary conception of philosophy is also consistent with, and even derivative from, his new ideas about meaning plus a set of unquestioned philosophical presuppositions he brings to the enterprise. The philosophical presuppositions include the then current and widespread assumptions that (i) that philosophical theses are not empirical, and hence must be necessary and a priori, and (ii) that the necessary, the a priori and the analytic are one and the same. Because he takes these assumptions for granted, he takes it for granted that if there are any philosophical truths, they must be analytic (29).\n\nThis seems to me to be mistaken twice over.\nFirst, it isn’t clear to me that there is any appeal to concepts of necessity in the passages in Wittgenstein Soames is summarising here, and metaphysical necessity simply doesn’t seem to have been a major interest of Wittgenstein’s. Wittgenstein does appear to reason that if a proposition is not empirical it is a priori, but that inference doesn’t go via claims about necessity, and isn’t shown to be fallacious by any of Kripke’s examples.\nSecond, it simply isn’t true that philosophers in Wittgenstein’s time took for granted that the analytic and the a priori were one and the same. To be sure, many philosophers in the early twentieth century (including many argue the younger Wittgenstein) argued against Kant’s claim that they are distinct, but this isn’t quite the same as taking for granted they are identical. And there are a few places where Wittgenstein appears to accept that some propositions are synthetic a priori. For example in Remarks on the Foundations of Mathematics he says it is synthetic a priori that there is no reddish green, (Part III, para 39) and goes on to say this about primes.\n\nThe distribution of primes would be an ideal example of what could be called synthetic a priori, for one can say that it is at any rate not discoverable by an analysis of the concept of a prime number. (Wittgenstein 1956, pt. III, para 42)\n\nNow it is far from obvious what the connection is between remarks such as these and the remarks about the impossibility of philosophical theses in the Investigations. Indeed it is not obvious whether Wittgenstein really believed in the synthetic a priori at any stage of his career. But given his lack of interest in metaphysical necessity, and openness to the possibility of synthetic a priori claims, it seems unlikely that he was, tacitly or otherwise, using the argument Soames gives him to get the deflationary conclusions.1\n1 I’m grateful to many correspondants for discussions about Wittgenstein. They convinced me, inter alia, that it would be foolish of me to commit to strong views of any kind about the role of the synthetic a priori in Wittgenstein’s later thought, and that the evidence is particularly messy because Wittgenstein wasn’t as centrally concerned with these concepts as we are.\n\n0.3 Getting the Question Right\nAs I mentioned above, Soames’s is the kind of history that focuses on the works of prominent philosophers, rather than their historical context. There’s much to be gained from this approach, in particular about what the greats can tell us about pressing philosophical questions. But one of the costs is that in focussing on what they say about our questions, we might overlook their questions. In most cases this is a trap Soames avoids, but in the cases of Austin and Ryle the trap may have been sprung.\nSoames sees Austin in Sense and Sensibilia as trying to offer us a new argument against radical scepticism.\n\nAustin’s ultimate goal is to undermine the coherence of skepticism. His aim is not just to show that skepticism is unjustified, or implausible, or that it is a position no one has reason to accept. Rather, his goal is to prevent skepticism from getting off the ground by denying skeptics their starting point. (173-4)\n\nBut we don’t get much of an interpretative argument that this is really Austin’s goal. Indeed, Soames concedes that Austin “doesn’t always approach these questions directly” (172). I’d say he does very little to approach them at all. To be sure, many contemporary defenders of direct realism are interested in its anti-sceptical powers, but there’s little to show Austin was so moved. Scepticism is not a topic that even arises in Sense and Sensibilia until the chapter on Warnock, after Austin has finished with the criticism of Ayer that takes up a large part of the book. And Soames doesn’t address the question of how to square the somewhat dismissive tone Austin takes towards scepticism in “Other Minds” with the view here propounded that Austin put forward a fairly radical theory of perception as a way of providing a new answer to the sceptic.\nIf Austin wasn’t trying to refute the sceptic, what was he trying to do? The simplest explanation is that he thought direct realism was true, sense-data theories were false, and that “there is noting so plain boring a the constant repetition of assertions that are not true, and sometimes no even faintly sensible; if we can reduce this a bit, it will all be to the good.” (Austin 1962, 5) I’m inclined to think that in this case the simplest explanation is the best, that Austin wrote a series of lectures on perception because he was interested in the philosophy of perception. Warnock says that “Austin was genuinely shocked by what appeared to his eye to be recklessness, hurry, unrealism, and inadequate attention to truth” (Warnock 1989, 154) and suggests this explained not only why Austin wrote the lectures but their harsh edge.\nThere is one larger point one might have wanted to make out of a discussion of direct realism, or that one might have learned from a discussion of direct realism, that seems relevant to what comes later in Soames’s book. If we really see objects, not sense-data, then objects are constituents of intentional states. That suggests that public objects might be constituents of other states, such as beliefs, and hence constituents of assertions. Soames doesn’t give us a discussion of these possible historical links between direct realism and direct reference, and that’s too bad because there could be some fertile ground to work over here. (I’m no expert on the history of the 1960s, so I’m simply guessing as to whether there is a historical link between direct realism and direct reference to go along with the strong philosophical link between the two. But it would be nice if Soames has provided an indication as to whether those guesses were likely to be productive or futile.)\nSoames gives us no inkling of where theories of direct reference came from, save from the brilliant mind of Kripke. Apart from the absence of discussion of any connection between direct realism and direct reference, there’s no discussion of the possible connections between Wittgenstein’s later theories and direct reference, as Howard Wettstein (2004) has claimed exist. And there’s no discussion of the (possibly related) fact that Kripke was developing the work that went into Naming and Necessity at the same time as he was lecturing and writing on Wittgenstein, producing the material that eventually became Wittgenstein on Rules and Private Language. Kripke is presented here as the first of the moderns2, and in many ways he is, but the ways in which he is the last (or the latest) of the ordinary language philosophers could be a very valuable part of a history of philosophy.3\n2 The first of what David Armstrong (2000) has aptly called “The Age of Conferences”.3 Just in case this gets misinterpreted, what I’m suggesting here is that Kripke (and his audiences) might have been influenced in interesting ways by philosophy of the 1950s and 1960s, not that Kripke took his ideas from those philosophers. The latter claim has been occasionally made, but on that ‘debate’ (Soames 1998b, 1998a) I’m 100% on Soames’s side.Matters are somewhat more difficult when it comes to Ryle’s The Concept of Mind. Ryle predicted that he would “be stigmatised as ‘behaviourist’” (Ryle 1949, 327) and Soames obliges, and calls him a verificationist to boot.\n\nIf beliefs and desires were private mental states [says Ryle], then we could never observe the beliefs and desires of others. But if we couldn’t observe them, then we couldn’t know that they exist, [which we can.] … This argument is no stronger than verificationism in general, which by 1949 when The Concept of Mind was published, had been abandoned by its main proponents, the logical positivists, for the simple reason that every precise formulation of it had been decisively refuted (97-8).\n\nBut Ryle’s position here isn’t verificationism at all, it’s abductophobia, or fear of inference to underlying causes. Ryle doesn’t think the claim of ghosts in the machine is meaningless, he thinks it is false. The kind of inference to underlying causes he disparages here is exactly the kind of inference to unobservables that paradigm verificationists, especially Ayer, go out of their way to allow, and in doing so buy all end of trouble.4 And abductophobia is prevalent among many contemporary anti-verificationists, particularly direct realists such as McDowell (1996), Brewer (1999) and Smith (2003) who think that if we don’t directly observe beer mugs we can never be sure that beer mugs exist. I basically agree with Soames that Ryle’s argument here (and the same style of argument recurs repeatedly in The Concept of Mind) is very weak, but it’s wrong to call it verificationist.\n4 It would be particularly poor form of me to use a paradigm case argument without discussing Soames’s very good dissection of Malcolm’s paradigm case argument in chapter 7 of his book. So let me note my gratitude as a Cornellian for all the interesting lines of inquiry Soames finds suggested in Malcolm’s paper – his is a paradigm of charitable interpretation, a masterful discovery of wheat where I’d only ever seen chaff.The issue of behaviourism is trickier. At one level Ryle surely is a behaviourist, because whatever behaviourism means in philosophy, it includes what Ryle says in The Concept of Mind. Ryle is the reference-fixer for at least one disambiguation of behaviourist. However we label Ryle’s views though, it’s hard to square what he says his aims are with the aims Soames attributes to him. In particular, consider Soames’s criticism of Ryle’s attempt to show that we don’t need to posit a ghost in the machine to account for talk of intelligence. (Soames is discussing a long quote from page 47 of The Concept of Mind.)\n\nThe description Ryle gives here is judicious, and more or less accurate. But it is filled with words and phrases that seem to refer to causally efficacious internal mental states—inferring, thinking, interpreting, responding to objections, being on the lookout for this, making sure not to rely on that, and so on. Unless all of these can be shown to be nothing more than behavioral dispositions, Ryle will not have succeeded in establishing that to argue intelligently is simply to manifest a variety of purely behavioral dispositions. (106)\n\nAnd Soames immediately asks\n\nSo what are the prospects of reducing all this talk simply to talk about what behavior would take place in various conditions? (106)\n\nThe answer, unsurprisingly, is that the prospects aren’t good. But why this should bother Ryle is never made clear. For Ryle only says that when we talk of mental properties we talk about people’s dispositions, not that we talk about their purely behavioural dispositions. The latter is Soames’s addition. It is rejected more or less explicitly by Ryle in his discussion of knowing how. “Knowing how, then, is a disposition, but not a single-track disposition like a reflex or a habit … its exercises can be overt or covert, deeds performed or deeds imagined, words spoken aloud or words heard in one’s head, pictures painted on canvas or pictures in the mind’s eye.” (1949, 46–47). Nor should Ryle feel compelled to say that these dispositions are behavioural, given his other theoretical commitments.\nRyle is opposed in general to talk of ‘reduction’ as the discussion of mechanism on pages 76ff shows. To be sure there he is talking about reduction of laws, but he repeatedly makes clear that he regards laws and dispositions as tightly connected (1949, 43, 123ff) and suggests that we use mental concepts to signal that psychological rather than physical laws are applicable to the scenario we’re discussing (167). Moreover, he repeatedly talks about mental events for which it is unclear there is any kind of correlated behavioural disposition, e.g. the discussion of Johnson’s stream of consciousness on page 58 and the extended discussion of imagination in chapter 8. Ryle’s claim that “Silent soliloquy is a form of pregnant non-sayings” (269) hardly looks like the claim of someone who wanted to reduce all mental talk to behavioural dispositions, unless one leans rather hard on ‘pregnant’. But we aren’t told whether Soames leans hard on this word, for he never quite tells us why he thinks all the dispositions that Ryle considers must be behavioural dispositions, rather than (for example) dispositions to produce other dispositions.\nTo be sure, from a modern perspective it is hard to see where the space is that Ryle aims to occupy. He wants to eliminate the ghosts, so what is left for mind to be but physical stuff, and what does physical stuff do but behave? He’s not an eliminativist, so he’s ontologically committed to minds, and he hasn’t left anything for them to be but behavioural dispositions. So we might see it (not unfairly) but that’s not how Ryle sees it.5 Soames sees Ryle as an ancestor of a reductive materialist like David Lewis, and a not very successful one at that. But the Ryle of The Concept of Mind has as much in common with non-reductive materialists, especially when he says that “not all questions are physical questions” (1949, 77), insists that “men are not machines, not even ghost-ridden machines” (1949, 81) and describes Cartesians rather than mechanists as “the better soldiers” (1949, 330) in the war against ignorance. Perhaps a modern anti-dualist should aim for a reduction of the mental to the physical, but Ryle thought no such reduction was needed to give up the ghost, and the historian should record this.\n5 Of course he couldn’t have seen it that way since in 1949 he wouldn’t have had the concept of ontological commitment.\n\n0.4 Conclusion\nAs I said at the top, Soames has written two really valuable books. For anyone who wants to really understand the most important philosophical work written between 1900 and 1970, reading through the classics while constantly referring back to Soames’s books to have the complexities of the philosophy explained will be immensely rewarding. Those who do that might feel that the people who skip reading the classics and just read Soames’s books get an unreasonably large percentage of the benefits they’ve accrued. As noted once or twice above I have some quibbles with some points in Soames’s story, but that shouldn’t let us ignore what a great service Soames has provided by providing these surveys of great philosophical work.\n\n\n\n\n\n\nReferences\n\nArmstrong, D. M. 2000. “Black Swans: The Formative Influences in Australian Philosophy.” In Rationality and Irrationality, edited by Berit Brogaard and Barry Smith, 11–17. Kirchberg: Austrian Ludwig Wittgenstein Society.\n\n\nAustin, J. L. 1962. Sense and Sensibilia. Oxford: Oxford University Press.\n\n\nBrewer, Bill. 1999. Perception and Reason. Oxford: Oxford University Press.\n\n\nGrice, H. Paul. 1989. Studies in the Way of Words. Cambridge, MA.: Harvard University Press.\n\n\nJackson, Frank. 1998. From Metaphysics to Ethics: A Defence of Conceptual Analysis. Clarendon Press: Oxford.\n\n\nKripke, Saul. 1980. Naming and Necessity. Cambridge: Harvard University Press.\n\n\nMcDowell, John. 1996. Mind and World. Cambridge, MA: Harvard University Press.\n\n\nRyle, Gilbert. 1949. The Concept of Mind. New York: Barnes; Noble.\n\n\n———. 1954. Dilemmas. Cambridge: Cambridge University Press.\n\n\nSmith, Michael. 2003. “Rational Capacities.” In Weakness of Will and Varities of Practical Irrationality, edited by Sarah Stroud and Christine Tappolet, 17–38. Oxford: Oxford University Press.\n\n\nSoames, Scott. 1998a. “More Revisionism about Reference.” In The New Theory of Reference, edited by Paul Humphreys and James Fetzer, 65–87. Dordrecht: Kluwer.\n\n\n———. 1998b. “Revisionism about Reference: A Reply to Smith.” In The New Theory of Reference, edited by Paul Humphreys and James Fetzer, 13–35. Dordrecht: Kluwer.\n\n\n———. 2003. Philosophical Analysis in the Twentieth Century. Princeton: Princeton University Press.\n\n\nWarnock, G. J. 1989. J. L. Austin. London: Routledge.\n\n\nWettstein, Howard. 2004. The Magic Prism. Oxford: Oxford University Press.\n\n\nWittgenstein, Ludwig. 1956. Remarks on the Foundations of Mathematics. New York: Macmillan."
  },
  {
    "objectID": "posts/ddd/deontology-and-descartess-demon.html",
    "href": "posts/ddd/deontology-and-descartess-demon.html",
    "title": "Deontology and Descartes’s Demon",
    "section": "",
    "text": "0.1 Digesting Evidence\nIn his Principles of Philosophy, Descartes says,\n\nFinally, it is so manifest that we possess a free will, capable of giving or withholding its assent, that this truth must be reckoned among the first and most common notions which are born with us. (Descartes 1644/2003, para. xxxix)\n\nIn this paper, I am going to defend a broadly Cartesian position about doxastic freedom. At least some of our beliefs are freely formed, so we are responsible for them. Moreover, this has consequences for epistemology. But the some here is crucial. Some of our beliefs are not freely formed, and we are not responsible for those. And that has epistemological consequences too. Out of these considerations a concept of doxastic responsibility arises that is useful to the externalist in responding to several challenges. I will say at some length how it supports a familiar style of externalism response to the New Evil Demon problem, and I will note some difficulties in reconciling internalism with the idea that justification is a kind of blamelessness. The internalist, I will argue, has to say that justification is a kind of praiseworthiness, and this idea that praise is more relevant to epistemic concepts than blame will be a recurring theme of the paper.\nWhile the kind of position I am adopting has been gaining supporters in recent years, it is still largely unpopular. The arguments of William Alston (1988) have convinced many that it is a mistake to talk of doxastic freedom, or doxastic responsibility. The short version of this argument is that our beliefs are involuntary, and freedom and responsibility require voluntariness. The longer, and more careful, argument involves drawing some distinctions between ways in which we might come to be in a state. It helps to start with an example where the normative facts are relatively uncontroversial, namely digestion.\nImagine that Emma eats a meat pie, and due to a malfunction in her stomach the pie is not properly digested, leading to some medical complications. Is Emma responsible for her ill-health? Well, that depends on the back-story. If Emma knew that she could not properly digest meat pies, but ate one anyway, she is responsible for the illness via her responsibility for eating the pie. Even if Emma did not know this, she might be responsible for the state of her stomach. If her stomach could not digest the pie because it had been damaged by Emma’s dietary habits, and say Emma knew that her diet could damage her stomach, then Emma is responsible for the state of her stomach and hence for the misdigestion of the pie and hence for her ill-health. But if neither of these conditions obtain, if it just happens that her stomach misdigests the pie, then Emma is not responsible for her ill-health. Even though the cause of her ill-health is something that her stomach does, he is not responsible for that since her stomach is not under her voluntary control. Put another way, her responsibility for maintaining her own health means that she is responsible for the type of digester she is, but he is not responsible for this token digestion.\nSimplifying a little, Alston thinks that the case of belief is similar. Say that Emma has a false belief that p. Is she responsible for this piece of doxastic ill-health? Again, that depends on the back story. If Emma believes that p because she was careless in gathering evidence, and the evidence would have pointed to ~p, then she is responsible for being a bad gatherer of evidence. If Emma has been negligent in maintaining her doxastic health, or worse if she has been doing things she knows endangers doxastic health, then she is responsible for being the type of believer she is. But she is never responsible merely for the token belief that is formed. Her mind simply digests the evidence she has, and Emma’s responsibility only extends to her duty to gather evidence for it, and her duty to keep her mind in good working order. She is not responsible for particular acts of evidential digestion.\nBut these particular acts of evidential digestion are the primary subject matters of epistemology. When we say Emma’s belief is justified or unjustified, we frequently mean that it is a good or bad response to the evidence in the circumstances. (I am obviously here glossing over enormous disputes about what makes for a good response, what is evidence, and what relevance the circumstances have. But most theories of justification can be fit into this broad schema, provided we are liberal enough in interpreting the terms ‘good’, ‘evidence’ and ‘circumstances’.) If Emma is not responsible for her response to the evidence, then either we have to divorce justification from responsibility, or we have to say that the concept of justification being used in these discussions is defective.\nWe can summarise these considerations as a short argument. The following formulation is from Sharon (Ryan 2003, 49).\n\nIf we have any epistemic obligations, then doxastic attitudes must sometimes be under our voluntary control.\nDoxastic attitudes are never under our voluntarily control.\nWe do not have any epistemic obligations.\n\nRyan goes on to reject both premises. (And she does so while interpreting “voluntary control” to mean “direct voluntary control”; the response is not meant to sidestep Alston’s argument.) Matthias Steup (2000, 2008) also rejects both premises of this argument. I am more sympathetic to premise 1, but I (tentatively) agree with them, against what sometimes seems to be orthodoxy, that premise 2 fails. That is, I endorse a kind of doxastic voluntarism. (Just what kind will become clearer as we go along.) There are four questions that anyone who endorses voluntarism, and wants to argue that this matters epistemologically, should I think answer. These are:\n\nWhat is wrong with current arguments against voluntarism?\nWhat does the voluntariness of (some) beliefs consist in?\nWhich kinds of beliefs are voluntary?\nWhat difference does the distinction between these classes make for epistemology?\n\nMy answer to (A) will be similar to Ryan’s, and to Steup’s, but with I think enough differences in emphasis to be worth working through. My answer to (B), however, will be a little more different. I am going to draw on some work on self-control to argue that some beliefs are voluntary because they are the result of exercises of, or failures to exercise, self-control. My answer to (C) is that what I will call inferential beliefs are voluntary, while perceptual beliefs are not. Ryan and Steup sometimes seem to suggest that even perceptual beliefs are voluntary, and I do not think this is true. The consequence for this, I will argue in answering (D), is that inferential beliefs should be judged by how well they respond to the evidence, while perceptual beliefs should be judged by how well they reflect reality. When an agent has misleading evidence, their inferential beliefs might be fully justified, but their perceptual beliefs, being misleading, are not.\nI will detail my answers to those four questions in sections 2, 4, 6 and 7. In between I will discuss recent work on self-control (section 3) and the contrast between my answer to (B) and other voluntarist answers (section 5). In section 8 I will say how my partially voluntarist position gives the externalist a way to avoid the New Evil Demon problem. And in section 9 I will make a direct argument for the idea that justification is a kind of praiseworthiness, not a kind of blamelessness.\nBefore we start, I want to note two ways, other than Ryan’s, of formulating an argument against doxastic responsibility. These are going to seem quite similar to Ryan’s formulation, but I think they hide important differences. The first version uses the idea that some doings (or states) are volitional. That is, we do them (or are in them) because we formed a volition to do so, and this volition causes the doing (or state) in the right kind of way.\n\nIf we have any epistemic obligations, then either the formation or maintenance of doxastic attitudes must sometimes be volitional.\nThe formation or maintenance of doxastic attitudes is never volitional.\nWe do not have any epistemic obligations.\n\nI will not argue against premise 2 of this argument, though Carl Ginet (1985, 2001) (1985, 2001) has done so. But I think there’s little to be said for premise 1. The principle behind it is that we are only responsible for volitional doings. And that principle is very dubious. We could run the kind of regress arguments against it that Gilbert Ryle (1949) offers. But it is simpler to note some everyday counterexamples. Borrowing an example from Angela M A. M. Smith (2005), if I forget a friend’s birthday, that is something I am responsible and blameworthy for, but forgetting a birthday is not volitional. (Below I will offer a Rylean argument that we are sometimes praiseworthy for doings that are not volitional.) So this argument fails. Alternatively, we could run the argument by appeal to freedom.\n\nIf we have any epistemic obligations, then doxastic attitudes must sometimes be free.\nDoxastic attitudes are never free.\nWe do not have any epistemic obligations.\n\nPremise 1 of this argument is more plausible. But, as we’ll see presently, premise 2 is not very plausible. Whether Descartes was right that premise 2 is obviously false, it does seem on reflection very hard to defend. So this argument fails. Ryan’s formulation is interesting because it is not clear just which of the premises fails. As I said, I am going to suggest that premise 2 fails, and that doxastic attitudes are voluntary. But this will turn on some fine judgments about the voluntary/involuntary boundary. If I am wrong about those judgments, then the arguments below will suggest that premise 1, not premise 2, in Ryan’s formulation fails. Either way though, the argument is unsuccessful.\n\n\n0.2 Responding to the Involuntarists\nThere are two kinds of argument against the idea that belief is voluntary. One kind, tracing back to Bernard Williams (1976), holds that the possibility of voluntary belief can be shown to be incoherent by reflection on the concept of belief. This argument is no longer widely endorsed. Nishi Shah (2002) provides an excellent discussion of the problems with Williams’ argument, and I have nothing to add to his work. I will focus on the other kind, that claims we can see that belief is involuntary by observing differences between beliefs and paradigm cases of voluntary actions. I will make three objections to these arguments. First, the argument looks much less plausible once we distinguish between having a belief and forming a belief. Second, the argument seems to rely on inferring from the fact that we do not do something (in particular, believe something that we have excellent evidence is false) to the conclusion that we can not do it. As Sharon Ryan (2003) points out, this little argument overlooks the possibility that we will not do it. Third, the argument relies on too narrow a conception of what is voluntary, and when we get a more accurate grasp on that concept, we’ll give up the argument. Here is a representative version of the argument from William Alston.\n\nCan you, at this moment, start to believe that the United States is still a colony of Great Britain, just by deciding to do so? … [S]uppose that someone offers you $500,000,000 to believe it, and you are much more interested in the money than in believing the truth. Could you do what it takes to get that reward? . . . Can you switch propositional attitudes toward that proposition just by deciding to do so? It seems clear to me that I have no such power. Volitions, decisions, or choosings don’t hook up with anything in the way of propositional attitude inauguration, just as they don’t hook up with the secretion of gastric juices or cell metabolism. (Alston 1988, 122)\n\nNow Alston does note, just one page earlier, that what is really relevant is whether our being in a state of belief is voluntary, not whether the activity of belief formation is voluntary. But he thinks nevertheless that issues about whether we can form beliefs, any old beliefs it seems, voluntarily matters to the question about the voluntariness of belief states.\nIf we think about what it is to be in a state voluntarily, this all seems beside the point. We can see this by considering what it is to be in a political state voluntarily. Consider Shane, who was born into Victoria. His coming to be in Victoria was hence not, in any way, voluntary. Shane is now a grown man, and he has heard many travellers’ tales of far away lands. But the apparent attractions of Sydney and other places have no pull on Shane; he has decided to stay in Victoria. If he has the capacity to leave Victoria, then Shane’s continued presence in Victoria is voluntary. Similarly, we are voluntarily in a belief state if we have the capacity to leave it, but choose not to exercise this capacity. Whether the belief was formed voluntarily is beside the point.\nIf Shane leaves a state, the natural place to leave is for another state, perhaps New South Wales or South Australia. It might be thought that if we leave a belief state, we have to move into another belief state. So to have this capacity to leave, we need the ability to form beliefs voluntarily. Not at all. The capacity to become uncertain, i.e. to not be in any relevant belief state, is capacity enough. (If Shane has a boat, and the capacity to flourish at sea, then perhaps he too can have the capacity to leave Victoria without the capacity to go into another state.)\nBut do we have the capacity to become uncertain? Descartes appeared to think so; arguably the point of the First Meditation is to show us how to exercise this capacity. Moreover, this capacity need not be one that we exercise in any particularly nearby possible worlds. We might exercise our freedom by always doing the right thing. As Descartes goes on to say in the Fourth Meditation.\n\nFor in order to be free, there is no need for me to be capable of going in each of two directions; on the contrary, the more I incline in one direction – either because I clearly understand that reasons of truth and goodness point that way, or because of a divinely produced disposition of my inmost thoughts – the freer is my choice. (Descartes 1641/1996, 40)\n\nThis seems like an important truth. Someone who is so sure of their own interests and values, and so strong-willed as to always aim to promote them, cannot in a certain sense act against their own self-interest and values. But this does not make their actions in defence of those interests and values unfree. If it did, we might well wonder what the value of freedom was. And note that even if there’s a sense that our character could not have done otherwise, this in no way suggests their actions are outside their control. Indeed, a person who systematically promotes the interests and values they have seems an exemplar of an agent in control. The character I am imagining here is in important respects unlike normal humans. We know we can, and do, act against our interests and values. But we can become more or less like them, and it is important to remember, as Descartes does, that in doing so we do not sacrifice freedom for values or interests.\nJohn Cottingham (2002) interprets Descartes here as suggesting that there is a gap between free action and voluntary action, contrasting his “strongly compatibilist notion of human freedom” (350) with the “doxastic involuntarism” (355) suggested by the following lines of the Third Meditation.\n\nYet when I turn to the things themselves which I think I perceive very clearly, I am so convinced by them that I spontaneously declare: let whoever can do so deceive me, he will never bring it about that I am nothing, so long as I continue to think that I am something … (Descartes 1641/1996, 25)\n\nNow there are two questions here. The first is whether Descartes intended to draw this distinction. That is, whether Descartes thought that the kind of free actions that he discusses in the Fourth Meditations, the free action where we are incapable of going in the other directions, are nevertheless involuntary. I do not have any informed opinions about this question. The second is whether this kind of consideration supports the distinction between the free and the voluntary. And it seems to me that it does not. Just as Descartes says the free person will be moved by reasons in the right way, it seems natural to say that a person who acts voluntarily will be responsive to reasons. Voluntary action does require freedom from certain kinds of coercion, but the world does not coerce us when it gives us reason to believe one thing rather than another. If we have voluntary control over our beliefs, then we should be compelled by the sight of rain to believe it is raining.\nIn her discussion of the puzzle of imaginative resistance, Tamar Szabó Gendler (2000) notes that philosophers have a tendency to read too much into intuitions about certain cases. What we can tell from various thought experiments is that in certain circumstances we will not do a certain thing. But getting from what we will not do to what we can not do is a tricky matter, and it is a bad mistake to infer from will not to can not too quickly. Matthias Steup (2000) points out that if you or I try to stick a knife into our hand, we similarly will not do it. (I assume a somewhat restricted readership here.) But this is no evidence that we cannot do it. And Sharon Ryan (2003) notes that we will not bring ourselves to run over pedestrians for no reason. For most of us, our moral sense prevents acting quite this destructively. Yet our continued avoiding of pedestrians is a series of free, even voluntary, actions. We could run over the pedestrians, but we will not. Since forming false beliefs is a form of self-harm, it is not surprising that it has a similar phenomenology, even if it is genuinely possible.\nIt might be argued that we will engage in small forms of self-harm that we can do when the financial rewards are great enough. So we should be able to form this belief about the United States for a large amount sum of money. But I suspect that the only way to exercise the capacity to believe the United States is still a colony is by first suspending my belief that it is no longer a colony. And the only way I can do that is by generally becoming more sceptical of what I have been told over the years. Once I get into such a sceptical mood, I will be sceptical of claims that I will get half a billion dollars should I have this wild political belief. So I will not form the belief in part because the ‘promisor’ lacks the capacity to sufficiently convince me that I will be richly rewarded for doing so. This looks like a lack of capacity on their part, not my part.\nThe final point to make about this argument, and those like it, is that if we are to conclude that belief formation is never voluntary, then we need to compare it to all kinds of voluntary action. And Alston really only ever compares belief formation to volitional action. If this does not exhaust the range of voluntary action, then belief formation might be properly analogous to some other voluntary action. Indeed, this turns out to be the case. To see so, we need to make a small detour through modern work on self-control.\n\n\n0.3 How to Control Your Temper\nTo start, let’s consider three examples of a person failing to keep a commitment they have made about what the good life is. The three ways will be familiar from Gary Watson’s discussion of recklessness, weakness and compulsion Watson (1977), and the discussion of these cases by Jeanette Kennett and Michael Smith Kennett and Smith (1996b, 1996a). My characterisation of the cases will turn out to differ a little from theirs, but the cases are similar. Each of the examples concerns a character Murray, who has decided that he should not swear around his young son Red. He resolves to do this, and has been working on curbing his tendency to swear whenever anything bad happens. But three times over the course of the day he breaks his commitment.1\n1 The cases, especially the second, were inspired by Richard Holton’s discussion of resolutions to prevent ‘automatic’ actions like smoking or sleeping in. See Holton (2003, 2004).The first time comes when Murray puts his hand down on a hot plate that he did not realise was on. The searing pain undermines his self-control, and he is unable to stop himself from swearing loudly through the pain.\nThe second time comes when Murray drops and breaks a wine glass. Murray does not lose his self-control, but he does not exercise the self-control he has. He temporarily forgets his commitment and so, quite literally, curses his misfortune. On doing so he immediately remembers that Red is around, and the commitment he has made, and regrets what he did.\nThe third time comes on the tram home, when Murray gets into a disagreement with a political opponent. Murray can not find the words to express what he feels about the opponent without breaking his commitment. So he decides, without much reason, that his need to express what he feels outweighs his commitment, and starts describing his opponent using language he would, all things considered, not have used around young Red.\nThe first and third cases are close to textbook cases of compulsion and recklessness. Note in the first case that when Murray reflects back on what happened, he might be irritated that his work on reducing his tendency to swear has not been more successful. But he will not be upset that he did not exercise more self-control on that occasion. He did not have, no normal person would have, the amount of self-control he would have needed to stop swearing then. All that would help is having the disposition to say different things when his self-control is defeated. And that is not a disposition he can acquire on the spot.\nI have described the first case as one where Murray’s self-control is undermined. This is a term taken from recent work by Richard Holton and Stephen Shute (2007), who carefully distinguish between self-control being undermined by a provocation, and it being overwhelmed by a provocation. Undermining occurs when the provocation causes the agent to have less self-control than they usually have; overwhelming occurs when the provocation is too much for the agent’s control. The difference is relevant to them, because they are interested in what it is for an agent to lose control. That seems to be what happens here. After all, the things one would naturally do afterwards (jumping around, screaming, swearing if one’s so disposed) do not seem particularly controlled by any measure.\nSimilarly I have accepted Watson’s description of cases like the third as instances of recklessness, but we should not think this necessarily contrasts with weakness. It might be that in this case Murray is both weak and reckless. He is not akratic, if we stipulatively define akrasia as acting against one’s better judgment. But if we accept Richard Holton’s view that weakness of will consists in being “too ready to reconsider their intentions” (Holton 1999, 241), then in this case Murray is weak-willed.2This seems to be the right way to talk about the case to me. With these details in place, we can talk about what’s crucial to this essay, the contrast with the second case.\n2 Whether Murray is akratic is a slightly more complicated question than I have suggested in the text. If akrasia is acting against one’s judgment, then he is not; if akrasia is acting against one’s considered judgment, then he is. ‘Akrasia’ is a technical term, so I do not think a huge amount turns on what we say about this question.\nThere is an interesting historical precedent for Holton’s theory of weakness of will. Ryle hints at a similar position to Holton’s when he says “Strength of will is a propensity the exercise of which consist in sticking to tasks’ that is, in not being deterred or diverted. Weakness of will is having too little of this propensity.” (1949, 73) But the idea is not well developed in Ryle. We’ll return below to the differences between Ryle’s and Holton’s theories.In the second case Murray fails to exercise self-control. He could have prevented himself from swearing in front of his son. Breaking a wine glass is irritating, but it neither undermines nor, necessarily, overwhelms self-control. Murray had the capacity to think about his resolution to not swear in front of Red. And if he had exercised this capacity, he would not have sworn when he did.\nIn the first case, Murray will only regret his lack of prior work at changing his dispositions in cases where his control fails. In the second case he will regret that, but he will also regret what he did on that occasion, for he could have kept his resolution, had only he thought of it. This regret seems appropriate, for in the second case he did something wrong at the time he swore, as well perhaps as having done something wrong earlier. (Namely, not having worked hard enough on his dispositions.) This difference in regret does not constitute the difference between compulsion and a case where self-control fails, but it is pretty good evidence that this is a failure of self-control.\nSo the second case is not one where Murray was compelled. He had the capacity to keep his commitment, and nothing was stopping him exercising this control, but he failed to do so. His failure was a failure of self-control. Murray’s self-control is, in this case, overwhelmed by the provocation. But it need not have been. Within some fairly broad limits, how much self-control we exercise is up to us.3 Murray’s failure of self-control is culpable because anyone with the capacity for self-control Murray has could have avoided breaking his commitment. I am not going to try to offer an analysis of what it is to have a capacity, but I suspect something like the complicated counterfactual analysis Kennett and Smith offer, and that Smith offers elsewhere (M. Smith 1997, 2003), is broadly correct.4\n3 Holton (2003) compares self-control to a muscle that we can exercise. We can make a similar point to the one in the text about physical muscles. If I try to lift a box of books and fail, that does not show I lack the muscular capacity to lift the box; I might not have been trying hard enough.4 (Ryle 1949, 71ff) also offers a counterfactual account of capacities that seems largely accurate.Kennett and Smith stress two things about this capacity that are worth noting here. First, having this kind of capacity is part of what it is to be rational. That is, being rational requires thinking of the right thing at the right time. As Ryle says, “Intelligently reflecting how to act is, among other things, considering what is pertinent and disregarding what is inappropriate.”(Ryle 1949, 31) Second, Kennett and Smith note that exercises of this capacity cannot be volitional. Following Davidson (1963), they say they cannot be actions. I find this terminology somewhat strained. Catching a fast moving ball is an action, I would say, but it does not seem to be volitional. So I will use ‘volitional action’ for this Davidsonian sense of action.\nMany recent philosophers have endorsed the idea that some of the mental states for which we hold people responsible are not voluntary, or at least are not volitional. Adams (1985; Heller 2000; Owens 2000) and Hieronymi (2008) note ways in which we appropriately blame people for being in certain states, where being in that state is not volitional. Something like this idea seems to be behind Ryle’s several regress arguments against the intellectualist legend. It just is not true that what we do divides cleanly into outcomes of conscious thought on the one hand, and mere bodily movements (a la digestion) on the other.5 Rather there is a spectrum of cases from pure ratiocination at one end to pure bodily movement at the other. And some of the things in the middle of this spectrum are proper subjects of reactive attitudes. The focus in this literature has been on blame, but some states in the middle of this spectrum are also praiseworthy.\n5 As I read him, Ryle takes this fact to reveal an important weakness in Descartes’ theory of mind.Consider some action that is strikingly imaginative, e.g. a writer’s apt metaphor or, say, a cricket captain’s imaginative field placements. It seems that, assuming the field settings are successful, the captain deserves praise for being so imaginative. But of course the captain did not, really could not, first intend to imagine such field settings, then carry out that intention. So something for which the captain deserves praise, his act of imagination, is not volitional. So not all praiseworthy things we do are volitional.\nThere are two responses to this argument that I can imagine, neither of them particularly plausible. First, we might think that the captain’s imagination is simply a remarkable feature of nature, as the Great Barrier Reef is. It is God, or Mother Nature, who should be praised, not the captain. Now it seems fair to react to some attributes of a person this way. A person does not deserve praise for having great eyesight, for example. But such a reaction seems grossly inappropriate, almost dehumanising, in this case. To be sure, we might also praise God or Mother Nature for yielding such an imaginative person, but we’ll do that as well as rather than instead of, praising the person. Second, we might praise the captain for his work in studying the game, and thinking about possible ways to dismiss batsmen, rather than this particular action. But if that is what we praise the captain for, we should equally praise the captain’s opponent, a hard working dullard. And that does not seem right. The hard-working dullard deserves praise for his hard work in the lead up, but the hard-working imaginative skipper deserves praise for what he does in the game too. So reactive attitudes, particularly praise, are appropriately directed at things people do even if these things are not volitional.\nThe key point of this section then is that responsibility outruns volition. Some actions are blameworthy because they are failures of self-control. Some actions are praiseworthy because they are wonderful feats of imagination. But neither failing to exercise self-control, nor exercising imagination, needs be volitional is order to be a locus of responsibility. I will argue in the next section that these considerations support the idea of responsibility for beliefs.\n\n\n0.4 Voluntariness about Belief\nHere is a situation that will seem familiar to anyone who has spent time in a student household. Mark is writing out the shopping list for the weekly grocery shop. He goes to the fridge and sees that there is a carton of orange juice in the fridge. He forms the belief that there is orange juice in the fridge, and hence that he does not need to buy orange juice. As it turns out both of these beliefs are false. One of his housemates finishes off the orange juice, but stupidly put the empty carton back in the fridge. When Mark finds this out, he is irritated at his housemate, but he is also irritated at himself. He did not have to draw the conclusion that there was orange juice in the fridge. He was, after all, living in a student house where people do all sorts of dumb things. That his housemate might have returned an empty container to the fridge was well within the range of live possibilities. Indeed had he even considered the possibility he would have thought it was a live possibility, and checked whether the container was empty before forming beliefs about what was needed for the shopping.\nExamples like this can be easily multiplied. There are all sorts of beliefs that we form in haste, where we could have stopped to consider the various realistic hypotheses consistent with the evidence, and doing so would have stopped us forming the belief. Indeed, unless one is a real master of belief formation, it should not be too hard to remember such episodes frequently from one’s everyday life. These conclusions that we leap to are voluntary beliefs; we could have avoided forming them. And not only could we have avoided these formations, but we would have if we had followed the methods for belief formation that we approve of. That seems enough, to me, to say the formation is voluntary. This is not the only way that voluntary doings, like calling a relevant possibility to mind, can matter to belief. The next example will be a little more controversial, but it points at the importance of dismissing irrelevant possibilities.\nLater that evening, Mark is watching his team, Geelong, lose another football game. Geelong are down by eight goals with fifteen minutes to go. His housemates are leaving to go see a movie, and want to know if Mark wants to come along. He says that he is watching the end of the game because Geelong might come back. One of his housemates replies, “I guess it is possible they’ll win. Like it is possible they’ll call you up next week to see if you want a game with them.” Mark replies, “Yeah, you are right. This one’s over. So, which movie?” Mark does nott just give in to his housemates, he forms the belief that Geelong will lose. Later that night, when asked what the result of the game was, he says that he did nott see the final score, but that Geelong lost by a fair bit. (In a recent paper (Weatherson 2005) I go into a lot more detail on the relation between not taking possibilities seriously, and having beliefs. The upshot is that what Mark does can count as belief formation, even if his credence that Geelong will lose does not rise.)\nNow it is tempting, or perhaps I should say that I am tempted, to view the housemate as offering Mark a reason to believe that Geelong will lose. We could view the housemate’s comments as shorthand for the argument that Geelong’s winning is as likely as Mark’s playing for Geelong, and since the latter will not happen, neither will the former. And maybe that is part of what the housemate is doing. But the larger part is that she is mocking Mark for his misplaced confidence. And the point of mocking someone, at least the point of constructive mockery like this, is to get them to change their attitudes. Mark does so, by ceasing to take seriously the possibility that Geelong will come back. In doing so, he exercises a capacity he had for a while, the capacity to cease taking this unserious possibility seriously, but needed to be prompted to use.\nIn both cases I say Mark’s belief formation is voluntary. In the first case he forms the belief because he does not exercise his doxastic self-control. He should have hesitated and not formed a belief until he checked the orange juice. And he would have done so if only he’d thought of the possibility that the container was empty. But he did not. And just as things we do because we do not bring the right thing to mind, like Murray’s swearing in the second case, are voluntary and blameworthy, Mark’s belief is voluntary and blameworthy. In the second case, he forms the belief by ceasing to take an unserious possibility seriously. In most cases of non-perceptual, non-testimonial belief formation, there is a counter-possibility that we could have taken seriously. Skill at being a believer involves not taking extreme possibilities, from Cartesian sceptical scenarios to unlikely footballing heroics, seriously. Exercises of such skill are rarely, if ever, volitional. But just like other mental activities that are not volitional can be voluntary and praiseworthy, not taking an extreme possibility seriously can be voluntary and praiseworthy.6\n6 (Ryle 1949, 29ff) stresses the importance of calling the right things to mind to rational thought and action. I am using a case here where Mark deliberately casts an option from his mind, but the more general point is that what possibilities we call to mind is a crucial part of rational action, and can be praiseworthy or blameworthy, whether or not it is volitional.7 Ryle seems to have taken an intermediate position. He holds, I think, the view that voluntary acts are culpable acts where we had the capacity to do otherwise (71). So Mark’s belief about the orange juice is voluntary because he had the capacity to retain doubt, and nothing prevented him exercising it. But the belief about the football is not voluntary because we should not talk about praiseworthy acts being voluntary or involuntary. The last point is the kind of error that (Grice 1989, Ch.1) showed us how to avoid.I have made two claims for Mark’s beliefs in the above two cases. First, they are instances of voluntary belief formation. In each case he could have done otherwise, either by exercising or failing to exercise his capacity to take various hypotheses seriously. Second, they are appropriate subjects of praise and blame. I imagine some people will agree with the second point but not the first. They will say that only volitional actions are voluntary, even though things we do like bringing relevant considerations to mind are praiseworthy or blameworthy. Such people will agree with most of what I say in this paper. In particularly they’ll agree that the examples involving Mark undermine Alston’s argument against the applicability of deontological concepts in epistemology. So I am not going to die in a ditch over just what we call voluntary. That is, I won’t fuss too much over whether we want to say premise 2 in Ryan’s formulation of the argument is shown to be false by these examples (as I say) or premise 1 is shown to be false (as such an objector will say.) I will just note that it is hard for such people to say intuitive things about the second instance of Murray’s swearing, and this seems like a strong reason to not adopt their position.7\n\n\n0.5 Ryan and Steup\nSharon Ryan has a slightly different view. She thinks that the truth of voluntarism consists in the fact that we hold certain beliefs intentionally. She does not offer an analysis of what it is to do something intentionally, except to say that consciously deciding to do something is not necessary for doing it intentionally, but doing it purposefully is (Ryan 2003, 70–71) In a similar vein, she says “When there’s a car zooming toward me and I believe that there is, I’m believing freely because I’m believing what I mean to believe.” (Ryan 2003, 74) This is said to be an intentional, and I take it a voluntary, belief.\nIt seems to me that there’s a large difference between things we voluntarily do, and things we mean to do, or do purposefully. There are several things we do voluntarily without meaning to do them. Murray’s swearing in the second example above is one instance. When we misspeak, or (as I frequently do) mistype, we do things voluntarily without meaning to do them. I do not mean by mistype cases where we simply hit the wrong key, but such cases as where I write in one more negation than I meant to, or, as I did earlier this evening, write “S is justified in believing that p” when I meant to write “S is justified in believing that she is justified in believing that p.” These are voluntary actions because I had the capacity to get it right, but did not exercise the capacity. But they are not things I meant to do. (I suspect there are also cases where we do things because we mean to do them, but they are not voluntary. These include cases where we train ourselves to produce a reflexive response. But I will not stress such cases here.)\nMatthias Steup (2008) argues that if compatibilism is true about free action, then our beliefs are free. His argument consists in running through the most plausible candidates to be compatibilist notions of freedom, and for each candidate that is plausible, showing that at least some of our beliefs satisfy the purported conditions on free actions. I agree with a lot of what Steup says, indeed this paper has been heavily influenced by what he says. But one crucial analogy fails I think. Steup is concerned to reject the premise that if \\(\\Phi\\)-ing is free, one \\(\\Phi\\)s because one has formed the intention to \\(\\Phi\\). His response centres around ‘automatic’ actions, such as the things we do when starting our drive to work: inserting the key, shifting into reverse, etc.\n\nThe question is whether they are caused by any antecedently formed intentions. I don’t think they are. … I didn’t form an intention to … shift into reverse…. I do things like that automatically, without thinking about them, and I assume you do too. But one can’t form an intention to \\(\\Phi\\) without thinking about \\(\\Phi\\)ing … Just one more example: I’d like to see the person who, just before brushing her teeth, forms the intention to unscrew the cap of the toothpaste tube. (Steup 2008, 383)\n\nI suspect that Steup simply has to look in the mirror. It is true that we do not usually form conscious intentions to shift into reverse, or unscrew the cap, but not all intentions are conscious. If we were asked later, perhaps by someone who thought we’d acted wrongly, whether we intended to do these things, the natural answer is yes. The best explanation of this is that we really did have an intention to do them, albeit an unconscious one. (I am indebted here to Ishani Maitra.)\nSteup is right that free actions do not require a prior intention, but his examples do not quite work. The examples I have used above are the Rylean regress stoppers, such as acts of imagination, and actions that we do because we did not think, like Murray’s swearing. If asked later whether he intended to say what he said, Murray would say yes in the third example, but (I think) no in the first and second. Intuitively, I think, he did not have such an intention.8\n8 If so, Murray is not weak-willed according to Holton’s theory of will, but, since he does not keep his resolution, he is weak-willed according to Ryle’s otherwise similar theory. This seems to be an advantage of Holton’s theory over Ryle’s. Murray’s problem is not that his will was weak, it is that it was not called on. More generally, Ryle’s identification of weakness of will with irresoluteness seems to fail for people who frequently forget their resolutions. These people are surely irresolute, but (in agreement with Holton’s theory) I think they are not weak-willed.\n\n0.6 Involuntarism about Perceptual Beliefs\nIn some early 1990s papers, Daniel Gilbert and colleagues defended a rather startling thesis concerning the relation of comprehension and belief (Gilbert, Krull, and Malone 1990; Gilbert 1991; Gilbert, Tafarodi, and Malone 1993) Casual introspection suggests that when one reads or hears something, one first comprehends it and then, if it is backed by sufficient reasons, believes it. Gilbert (1991) argues against this seeming separation of comprehension and belief, and in favour of a view said to derive from Spinoza. When we comprehend a sentence, we add it to our stock of beliefs. If the new belief is implausible given our old beliefs, then we “unbelieve” it.9\n9 The evidence for this view is set out in Gilbert, Krull, and Malone (1990; Gilbert, Tafarodi, and Malone 1993).We may picturesquely compare the two models of belief and comprehension to two models for security. The way security works at a nightclub is that anyone can turn up at the door, but only those cleared by the guards are allowed in. On the other hand, the way security works at a shopping mall is that anyone is allowed in, but security might remove those it regards as undesirable. Intuitively, our minds work on the nightclub model. A hypothesis can turn up and ask for admission, but it has to be approved by our cognitive security before we adopt it as a belief. Gilbert’s position is that we work on the shopping mall model. Any hypothesis put in front of us is allowed in, as a belief, and the role of security is to remove troublemakers once they have been brought inside.\nNow I do not want to insist Gilbert’s theory is correct. The experimental evidence for it is challenged in a recent paper (Hasson, Simmons, and Todorov 2005). But I do want to argue that if it is correct, then there is a kind of belief that is clearly involuntary. We do not have much control over what claims pass in front of our eyes, or to our ears. (We have some indirect control over this – we could wear eye shades and ear plugs – but no direct control, which is what’s relevant.) If all such claims are believed, these are involuntary beliefs. To be sure, nothing Gilbert says implies that we can not quickly regain voluntary control over our beliefs as we unbelieve the unwanted inputs. But in the time it takes to do this, our beliefs are out of our control.\nGilbert’s theory is rather contentious, but there are other kinds of mental representations that it seems clear we can not help forming. In The Modularity of Mind, Jerry Fodor (1983) has a long discussion of how the various input modules that he believes to exist are not under our voluntary control.10 If I am sitting on a train opposite some people who are chatting away, I can not help but hear what they say. (Unless, perhaps, I put my fingers in my ear.) This is true not just in the sense that I can not help receive the sound waves generated by their vocalisations. I also can not help interpreting and comprehending what they are saying. Much as I might like to not be bothered with the details of their lives, I can not help but hear what they say as a string of English sentences. Not just hearing, but hearing as happens automatically.\n10 As he says, they have a mandatory operation. See pages 52-55 in particular, but the theme is central to the book.This automatic ‘hearing as’ is not under my voluntary control. I do not do it because I want to do it, or as part of a general plan that I endorse or have chosen to undertake. It does not reflect any deep features of my character. (Frankly I would much rather that I just heard most of these conversations as meaningless noise, like the train’s sound.) But I do it, involuntarily, nonetheless. This involuntariness is reflected in some of our practices. A friend tells me not to listen to X, because X is so often wrong about everything. Next I see the friend I say that I now believe that p, and when the friend asks why, I say it is because X said that p. The friend might admonish me. They will not admonish me for being within hearing range of X; that might have been unavoidable. And, crucially, they will not admonish me for interpreting X’s utterances. Taken literally, that might be what they were asking me not to do. But they’ll know it was unavoidable. What they were really asking me not to do was the one relevant thing that I had control over, namely believe what X said.\nAs Fodor points out at length, both seeing as and hearing as are generally outside voluntary control. Our perceptual systems, and by this I am including verbal processing systems, quickly produce representations that are outside voluntary control in any sense. If any of these representations amount to beliefs, then there are some involuntary beliefs that we have. So we might think that in the case above, although it was up to me to believe that p, it was not up to me to believe that, say, X said that p, because this belief was produced by a modular system over which I have no control.\nThis is not the position that Fodor takes. He thinks that beliefs are not produced by input modules. Rather, the non-modular part of the mind, the central processor, is solely responsible for forming and fixing beliefs. And the operation of this central processor is generally not mandatory, at least not in the sense that the operation of the modules is mandatory. Whether this is right seems to turn (in part) on a hard question to do with the analysis of belief.\nLet us quickly review Fodor’s views on the behaviour of input modules. The purpose of each module is to, within a specified domain, quickly and automatically produce representations of the world. These are, as on the nightclub model, then presented to cognition to be allowed in as beliefs or not. Here is how Fodor puts it.\n\nI am supposing that input systems offer central processes hypotheses about the world, such hypotheses being responsive to the current, local distribution of proximal stimulations. The evaluation of these hypotheses in light of the rest of what one knows is one of the things that central processes are for; indeed, it is the fixation of perceptual belief.(Fodor 1983, 136)\n\nBut these representations do not just offer hypotheses. They can also guide action prior to being ‘approved’ by the central processes. That, at least, seems to be the point of Fodor’s discussion of the evolutionary advantages of having fast modules (Fodor 1983, 70–71). The core idea is that when one is at risk of being eaten by a panther, there is much to be said for a quick, automatic, panther recognition device. But there is just as much to be said for acting immediately on one’s panther recognition capacities rather than, say, searching for possible reasons why this panther appearance might be deceptive. And browsing reason space for such evidence of deceptions is just what central processes, in Fodor’s sense, do. So it seems the natural reaction to seeing a panther should be, and is, guided more-or-less directly by the input modules not central processes.\nSo these ‘hypotheses’ are representations with belief-like direction of fit, i.e. they are responsive to the world, that guide action in the way that beliefs do. These are starting to sound a lot like beliefs. Perhaps we should take a Gilbert-style line and say that we automatically believe what we perceive, and the role of Fodorian central processes is not to accept or reject mere hypotheses, but to unbelieve undesirable inputs.11 There are a number of considerations that can be raised for and against this idea, and perhaps our concept of belief is not fine enough to settle the matter. But let’s first look at three reasons for thinking these inputs are not beliefs.\n11 To be clear, the position being considered here is not that we automatically believe p when someone says p to us, but that we automatically believe that they said that p.First, if they are beliefs then we are often led into inconsistency. If we are looking at a scene we know to be illusory, then we might see something as an F when we know it is not an F. If the outputs of visual modules are beliefs, then we inconsistently believe both that it is and is not F. Perhaps this inconsistency is not troubling, however. After all, one of the two inconsistent beliefs is involuntary, so we are not responsible for it. So this inconsistency is not a sign of irrationality, just a sign of defective perception. And that is not something we should be surprised by; the case by definition is one where perception misfires.\nSecond, the inputs do not, qua inputs, interact with other beliefs in the right kind of way. Even if we believe that if p then q, and perceive that p, we will not even be disposed to infer that q unless and until p gets processed centrally. On this point, see Stich (1978) and (Fodor 1983, 83–86). The above considerations in favour of treating inputs as beliefs turned heavily on the idea that they have the same functional characteristics as paradigm beliefs. But as David Braddon-Mitchell and Frank Jackson (2007, 114–23) stress, functionalism can only be saved from counterexamples if we include these inferential connections between belief states in the functional charactisation of belief. So from a functionalist point of view, the encapsulation of input states counts heavily against their being beliefs.\nFinally, if Fodor is right, then the belief-like representation of the central processes form something like a natural kind. On the other hand, the class consisting of these representations plus the representations of the input modules looks much more like a disjunctive kind. Even if all members of the class play the characteristic role of beliefs, we might think it is central to our concept of belief that belief is a natural kind. So these inputs should not count as beliefs.\nOn the other hand, we should not overestimate the role of central processes, even if Fodor is right that central processes are quite different to input systems. There are two related features of the way we process inputs that point towards counting some inputs as beliefs, and hence as involuntary beliefs. The first feature is that we do not have to put any effort into believing what we see. On the contrary, as both Descartes and Hume were well aware, we believe what we see by default, and have to put effort into being sceptical. The second feature is that, dramatic efforts aside, we can only be so sceptical. Perhaps sustained reflection on the possibility of an evil demon can make us doubt all of our perceptions at once. But in all probability, at least most of the time, we can not doubt everything we see and hear.12 We can perhaps doubt any perceptual input we receive, but we can not doubt them all.\n12 As noted in the last footnote, when I talk here about what we hear, I mean to include propositions of the form S said that p, not necessarily the p that S says.In the picturesque terms from above, we might think our security system is less like a nightclub and more like the way customs appears to work at many airports. (Heathrow Airport is especially like this, but I think it is not that unusual.) Everyone gets a cursory glance from the customs officials, but most people walk through the customs hall without even being held up for an instant, and there are not enough officials to stop everyone even if they wanted to. Our central processes, faced with the overwhelming stream of perceptual inputs, are less the all-powerful nightclub bouncer and more the overworked customs official, looking for the occasional smuggler who should not be getting through.\nThe fact that inputs turn into fully fledged beliefs by default is some reason to say that they are beliefs as they stand. It is noteworthy that what Gilbert et al’s experiments primarily tested was whether sentences presented to subjects under cognitive load ended up as beliefs of the subjects. Now this could be because comprehending a sentence implies, at least temporarily, believing it. But perhaps a more natural reading in the first instance is that inputted sentences turn into beliefs unless we do something about it. Gilbert et al are happy inferring that in this case, the inputs are beliefs until and unless we do that something. This seems to be evidence that the concept of belief philosophers and psychologists use include states that need to be actively rejected if they are not to acquire all the paradigm features of belief. And that includes the inputs from Fodorian modules.\nThat argument is fairly speculative, but we can make more of the fact that subjects can not stop everything coming through. This implies that there will be some long disjunctions of perceptual inputs that they will end up believing no matter how hard they try. Any given input can be rejected, but subjects only have so much capacity to block the flow of perceptual inputs. So some long disjunctions will turn up in their beliefs no matter how hard they try to keep them out. I think these are involuntary beliefs.\nSo I conclude tentatively that perceptual inputs are involuntary beliefs, at least for the time it would take the central processes to evaluate them were it disposed to do so. And I conclude less tentatively that subjects involuntarily believe long disjunctions of perceptual inputs. So some beliefs are involuntary.\nSpace considerations prevent a full investigation of this, but there is an interesting connection here to some late medieval ideas about evidence. In a discussion of how Descartes differed from his medieval influences, Matthew L. Jones writes “For Descartes, the realignment of one’s life came about by training oneself to assent only to the evident; for the scholastics, assenting to the evident required no exercise, as it was automatic.” [Jones (2006) 84]13 There is much contemporary interest in the analysis of evidence, with Timothy Williamson’s proposal that our evidence is all of our knowledge being a central focus (Williamson 2000 Ch. 9). I think there’s much to be said for using Fodor’s work on automatic input systems to revive the medieval idea that the evident is that which we believe automatically, or perhaps it is those pieces of knowledge that we came to believe automatically. As I said though, space prevents a full investigation of these interesting issues.\n13 Jones attributes this view to Scotus and Ockham, and quotes Pedro Fonseca as saying almost explicitly this in his commentary on Aristotle’s Metaphysics.\n\n0.7 Epistemological Consequences\nSo some of our beliefs, loosely speaking the perceptual beliefs, are spontaneous and involuntary, while other beliefs, the inferential beliefs, are voluntary in that we have the capacity to check them by paying greater heed to counter-possibilities. (In what follows it will not matter much whether we take the spontaneous beliefs to include all the perceptual inputs, or just the long disjunctions of perceptual inputs that are beyond our capacity to reject. I will note the few points where it matters significantly.) This has some epistemological consequences, for the appropriate standards for spontaneous, involuntary beliefs are different to the appropriate standards for considered, reflective beliefs. I include in the latter category beliefs that were formed when considered reflection was possible, but was not undertaken.\nTo think about the standards for spontaneous beliefs, start by considering the criteria we could use to say that one kind of animal has a better visual system than another. One dimension along which we could compare the two animals concerns discriminatory capacity – can one animal distinguish between two things that the other cannot distinguish? But we would also distinguish between two animals with equally fine-grained visual representations, and the way we would distinguish is in terms of the accuracy of those representations. Some broadly externalist, indeed broadly reliabilist, approach has to be right when it comes to evaluating the visual systems of different animals.\nThings are a little more complicated when it comes to evaluating individual visual beliefs of different animals, but it is still clear that we will use externalist considerations. So imagine we are looking for standards for evaluating particular visual beliefs of again fairly basic animals. One very crude externalist standard we might use is that a belief is good iff it is true. Alternatively, we might say that the belief is good iff the process that produces it satisfied some externalist standard, e.g. it is generally reliable. Or we might, in a way, combine these and say that the belief is good iff it amounts to knowledge, incorporating both the truth and reliability standards. It is not clear which of these is best. Nor is it even clear which, if any, animals without sophisticated cognitive systems can be properly said to have perceptual beliefs. (I will not pretend to be able to evaluate the conceptual and empirical considerations that have been brought to bear on this question.) But what is implausible is to say that these animals have beliefs, and the relevant epistemic standards for evaluating these beliefs are broadly internal.\nThis matters to debates about the justificatory standards for our beliefs because we too have perceptual beliefs. And the way we form perceptual beliefs is not that different from the way simple animals do. (If the representations of input processes are beliefs, then it does not differ in any significant way.) When we form beliefs in ways that resemble those simple believers, most notably when we form perceptual beliefs, we too are best evaluated using externalist standards. The quality of our visual beliefs, that is, seems to directly track the quality of our visual systems. And the quality of our visual system is sensitive to external matters. So the quality of our visual beliefs is sensitive to external matters.\nOn the other hand, when we reason, we are doing something quite different to what a simple animal can do. A belief that is the product of considered reflection should be assessed, inter alia, by assessing the standards of the reflection that produced it. To a first approximation, such a belief seems to be justified if it is well supported by reasons. Some reasoners will be in reasonable worlds, and their beliefs will be mostly true. Some reasoners will be in deceptive worlds, and many of their beliefs will be false. But this does not seem to change what we say about the quality of their reasoning. This, I take it, is the core intuition behind the New Evil Demon problem, that we’ll address much more below.\nSo we’re naturally led to a view where epistemic justification has a bifurcated structure. A belief that is the product of perception is justified iff the perception is reliable; a belief that is (or could have been) the product of reflection is justified iff it is well-supported by reasons.14 This position will remind many of Ernest Sosa’s view that there is animal knowledge, and higher knowledge, or scientia (Sosa 1991, 1997). And the position is intentionally similar to Sosa’s. But there is one crucial difference. On my view, there is just one kind of knowledge, and the two types of justification kick in depending on the kind of knower, or the kind of knowing, that is in question. If we simply form perceptual beliefs, without the possibility of reconsidering them (in a timely manner), then if all goes well, our beliefs are knowledge. Not some lesser grade of animal knowledge, but simply knowledge. To put it more bluntly, if you’re an animal, knowledge just is animal knowledge. On the other hand, someone who has the capacity (and time) to reflect on their perceptions, and fails to do so even though they had good evidence that their perceptions were unreliable, does not have knowledge. Their indolence defeats their knowledge. Put more prosaically, the more you are capable of doing, the more that is expected of you.\n14 There is a delicate matter here about individuating beliefs. If I look up, see, and hence believe it is raining outside, that is a perceptual belief. I could have recalled that it was raining hard a couple of minutes ago, and around here that kind of rain does not stop quickly, and formed an inferential belief that it was raining outside. I want to say that that would have been a different belief, although it has the same content. If I do not say that, it is hard to defend the position suggested here when it comes to the justificatory status of perceptual beliefs whose contents I could have otherwise inferred.\n\n0.8 The New Evil Demon Problem\nThe primary virtue of the above account, apart from its intuitive plausibility, is that it offers a satisfactory response to the New Evil Demon argument. The response in question is not new; it follows fairly closely the recent response due to Clayton Littlejohn (2009), who in turn builds on responses due to Kent Bach (1985) and Mylan Engel (1992). But I think it is an attractive feature of the view defended in this paper that it coheres so nicely with a familiar and attractive response to the argument.\nThe New Evil Demon argument concerns victims of deception who satisfy all the internal standards we can imagine for being a good epistemic agent. So they are always careful to avoid making fallacious inferences, they respect the canons of good inductive and statistical practice, they do not engage in wishful thinking, and so on. The core intuition of the New Evil Demon argument is that although these victims do not have knowledge (because their beliefs are false), they do have justified beliefs. Since the beliefs do not satisfy any plausible externalist criteria of justification, we conclude that no externalist criteria can be correct. The argument is set out by Stewart Cohen (1984).\nA fairly common response is to note that even according to externalist epistemology there will be some favourable epistemic property that the victim’s beliefs have, and this can explain our intuition that there is something epistemically praiseworthy about the victim’s beliefs. My approach is a version of this, one that is invulnerable to recent criticisms of the move. For both this response and the criticism to it, see James Pryor (2001). I am going to call my approach the agency approach, because the core idea is that the victim of the demon is in some sense a good doxastic agent, in that all their exercises of doxastic agency are appropriate, although their perception is quite poor and this undermines their beliefs.\nAs was noted above, the quality of our visual beliefs is sensitive to external matters. This is true even for the clear-thinking victim of massive deception. Denying that the victim’s visual beliefs are as good as ours is not at all implausible; indeed intuition strongly supports the idea that they are not as good. What they are as good at as we are is exercising their epistemic agency. That is to say, they are excellent epistemic agents. But since there is more to being a good believer than being a good epistemic agent, there is also for example the matter of being a good perceiver, they are not as good at believing as we are.\nSo the short version of my response to the New Evil Demon problem is this. There are two things we assess when evaluating someone’s beliefs. We evaluate how good an epistemic agent they are. And we evaluate how good they are at getting evidence from the world. Even shorter, we evaluate both their collection and processing of evidence. Externalist standards for evidence collection are very plausible, as is made clear when we consider creatures that do little more than collect evidence. The intuitions that the New Evil Demon argument draws on come from considering how we process evidence. When we consider beliefs that are the products of agency, such as beliefs that can only be arrived at by extensive reflection, we naturally consider the quality of the agency that led to those beliefs. In that respect a victim might do as well as we do, or even better. But that is no threat to the externalist conclusion that they are not, all things considered, as good at believing as we are.\nAs I mentioned earlier, this is similar to a familiar response to the argument that James Pryor considers and rejects. He considers someone who says that what is in common to us and the clear-thinking victim is that we are both epistemically blameless. The objection he considers says that the intuitions behind the argument come from confusing this notion of being blameless with the more general notion of being justified. This is similar to my idea that the victim might be a good epistemic agent while still arriving at unjustified beliefs because they are so bad at evidence collection. But Pryor argues that this kind of deontological approach cannot capture all of the intuitions around the problem.\nPryor considers three victims of massive deception. Victim A uses all sorts of faulty reasoning practices to form beliefs, practices that A could, if they were more careful, could see were faulty. Victim B was badly ‘brought up’, so although they use methods that are subtly fallacious, there is no way we could expect B to notice these mistakes. Victim C is our paradigm of good reasoning, though of course C still has mostly false beliefs because all of their apparent perceptions are misleading. Pryor says that both B and C are epistemically blameless; C because they are a perfect reasoner and B because they cannot be blamed for their epistemic flaws. But we intuit that C is better, in some epistemic respects, than B. So there is some internalist friendly kind of evaluation that is stronger than being blameless. Pryor suggests that it might be being justified, which he takes to be an internalist but non-deontological concept.\nThe agency approach has several resources that might be brought to bear on this case. For one thing, even sticking to deontological concepts we can make some distinctions between B and C. We can, in particular, say that C is epistemically praiseworthy in ways that B is not. Even if B cannot be blamed for their flaws, C can be praised for not exemplifying those flaws. It is consistent with the agency approach to say that C can be praised for many of their epistemic practices while saying that, sadly, most of C’s beliefs are unjustified because they are based on faulty evidence, or on merely apparent evidence.\nThe merits of this kind of approach can be brought out by considering how we judge agents who are misled about the nature of the good. Many philosophers think that it is far from obvious which character traits are virtues and which are vices. Any particular example is bound to be controversial, but I think it should be uncontroversial that there are some such examples. So I will assume that, as Simon Keller (2005) suggests, it is true but unobvious that patriotism is not a virtue but a vice.\nNow consider three agents D, E and F. D takes patriotism to extremes, developing a quite hostile strand of nationalism, which leads to unprovoked attacks on non-compatriots. E is brought up to be patriotic, and lives this way without acting with any particular hostility to foreigners. F is brought up the same way, but comes to realise that patriotism is not at all virtuous, and comes to live according to purely cosmopolitan norms. Now it is natural to say that D is blameworthy in a way that E and F are not. As long as it seems implausible to blame E for not working through the careful philosophical arguments that tell against following patriotic norms, we should not blame E for being somewhat patriotic. But it is also natural to say that F is a better agent than either D or E. That is because F exemplifies a virtue, cosmopolitanism, that D and E do not, and does not exemplify a vice, patriotism, that D and E do exemplify. F is in this way praiseworthy, while D and E are not.\nThis rather strongly suggests that when agents are misled about norms, a gap will open up between blamelessness and praiseworthiness. We can say that Pryor’s victim C is a better epistemic agent than A or B, because they are praiseworthy in a way that A and B are not. And we can say this even though we do not say that B is blameworthy and we do not say that being a good epistemic agent is all there is to being a good believer.\nAt this point the internalist might respond with a new form of the argument. A victim of deception is, they might intuit, just as praiseworthy as a regular person, if they perform the same inferential moves. I think at this point the externalist can simply deny the intuitions. In general, praiseworthiness is subject to a degree of luck. (Arguably blameworthiness is as well, but saying so sounds somewhat more counterintuitive than saying praiseworthiness is a matter of luck.) For example, imagine two people dive into ponds in which they believe there are drowning children. The first saves two children. The second was mistaken; there are no children to be rescued in the pond they dive into. Both are praiseworthy for their efforts, but they are not equally praiseworthy. The first, in particular, is praiseworthy for rescuing two children. As we saw in the examples of the writer and the good cricket captain above, praiseworthiness depends on outputs as well as inputs, and if the victim of deception produces beliefs that are defective, i.e. false, then through no fault of their own they are less praiseworthy.\n\n\n0.9 Praise and Blame\nAs Pryor notes, many philosophers have thought that a deontological conception of justification supports an internalist theory of justification. I rather think that is mistaken, and that at least one common deontological understanding of what justification is entails a very strong kind of externalism. This is probably a reason to not adopt that deontological understanding.\nAssume, for reductio, that S’s belief that p is justified iff S is blameless in believing that p. I will call this principle J=B to note the close connection it posits between justification and blamelessness. Alston (1988) seems to identify the deontological conception of justification with J=B, or at least to slide between the two when offering critiques. But one of Alston’s own examples, the ‘culturally isolated tribesman’, suggests a principle that can be used to pull these two ideas apart. The example, along with Pryor’s three brains case, suggests that A1 is true.\n\nA1\n\nIt is possible for S to have a justified but false belief that her belief in p is justified.\n\n\nA1 is a special instance of the principle that justification does not entail truth. Some externalists about justification will want to reject the general principle, but all internalists (and indeed most externalists) will accept it. Now some may think that the general principle is right, but that beliefs about what we are justified in believing are special, and if they are justified they are true. But such an exception seems intolerably ad hoc. If we can have false but justified beliefs about some things, then presumably we can have false but justified beliefs about our evidence, since in principle our evidence could be practically anything. So the following situation seems possible; indeed it seems likely that something of this form happens frequently in real life. S has a false but justified belief that e is part of her evidence. S knows both that anyone with evidence e is justified in believing p in the absence of defeaters, and that there are no defeaters present. So S comes to believe, quite reasonably, that she is justified in believing that p. But S does not have this evidence, and in fact all of her evidence points towards ~p.15 So it is false that she is justified in believing p.\n15 I am assuming here that evidence of evidence need not be evidence. This seems likely to be true. In Bayesian terms, something can raise the probability of e, while lowering the probability of p, even though the probability of p given e is greater than the probability of p. Bayesian models are not fully general, but usually things that are possible in Bayesian models are possible in real life.The following principle seems to be a reasonable principle concerning blameless inference.\n\nA2\n\nIf S blamelessly believes that she is justified in believing that p, and on the basis of that belief comes to believe that p, then she is blameless in believing that p.\n\n\nThis is just a principle of transfer of blameworthiness. The quite natural thought is that you do not become blameworthy by inferring from I am justified in believing p to p. This inference is clearly not necessarily truth-preserving, but that is not a constraint on inferences that transfer blameworthiness, since not all ampliative inferences are blameworthy. (Indeed, many are praiseworthy.) And it is hard to imagine a less blameworthy ampliative inference schema than this one.\nWe can see this more clearly with an example of A2. Suzy sees a lot of Fs and observes they are all Gs. She infers that it is justified for her to conclude that all Fs are Gs. Now it turns out this is a bad inference. In fact, G is a gruesome predicate in her world, so that is not a justified inference. But Suzy, like many people, does not have the concept of gruesomeness, and without it had no reason to suspect that this would be a bad inference. So she is blameless. If all that is correct, it is hard to imagine that she becomes blameworthy by actually inferring from what she has so far that all Fs are in fact Gs. Perhaps you might think her original inference, that it is justified to believe all Fs are Gs, was blameworthy, but blame can not kick in for the first time when she moves to the first order belief.\nI am now going to derive a contradiction from A1, A2 and J=B, and a clearly consistent set of assumptions about a possible case of belief.\n\nS justifiedly, but falsely, believes that she is justified in believing p. (Assumption - A1)\nOn the basis of this belief, S comes to believe that p. (Assumption)\nS blamelessly believes that she is justified in believing that p. (1, J=B)\nS blamelessly believes that p. (2, 3, A2)\nS is justified in believing that p. (4, J=B)\nIt is false that S is justified in believing that p. (1)\n\nOne of A1, A2 and J=B has to go. If you accept J=B, I think it has got to be A1, since A2 is extremely plausible. But A1 only fails if we accept quite a strong externalist principle of justification, namely that justification entails truth. More precisely, we’re led to the view that justification entails truth when it comes to propositions about our own justification. But as we saw above, that pretty directly implies that justification entails truth when it comes to propositions about our own evidence. And, on the plausible assumption that evidence can be practically anything, that leads to there being a very wide range of cases where justification entails truth. So J=B entails this strong form of externalism.\nThis does not mean that internalists cannot accept a deontological conception of justification. But the kind of deontological conception of justification that is left standing by this argument is quite different to J=B, and I think to existing deontological conceptions of justification. Here’s what it would look like. First, we say that a belief’s being justified is not a matter of it being blameless, but a matter of it being in a certain way praiseworthy. Second, we say that the inference from I am justified in believing that p to p is not praiseworthy if the premise is false. So if we tried to run the above argument against J=P (the premise that justified beliefs are praiseworthy) it would fail at step 4. So anyone who wants to hold that justification is (even in large part) deontological, and wants to accept that justification can come apart from truth, should hold that justification is a kind of praiseworthiness, not a kind of blamelessness.\n\n\n\n\n\n\nReferences\n\nAdams, Robert Merrihew. 1985. “Involuntary Sins.” Philosophical Review 94 (1): 3–31. https://doi.org/10.2307/2184713.\n\n\nAlston, William. 1988. “The Deontological Conception of Epistemic Justification.” Philosophical Perspectives 2: 257–99. https://doi.org/10.2307/2214077.\n\n\nBach, Kent. 1985. “A Rationale for Reliabilism.” Monist 68 (2): 246–63. https://doi.org/10.5840/monist198568224.\n\n\nBraddon-Mitchell, David, and Frank Jackson. 2007. The Philosophy of Mind and Cognition, Second Edition. Malden, MA: Blackwell.\n\n\nCohen, Stewart. 1984. “Justification and Truth.” Philosophical Studies 46 (3): 279–95. https://doi.org/10.1007/bf00372907.\n\n\nCottingham, John. 2002. “Descartes and the Voluntariness of Belief.” Monist 85 (3): 343–60. https://doi.org/10.5840/monist200285323.\n\n\nDavidson, Donald. 1963. “Actions, Reasons and Causes.” Journal of Philosophy 60 (23): 685–700. https://doi.org/10.2307/2023177.\n\n\nDescartes, René. 1641/1996. Meditations on First Philosophy, Tr. John Cottingham. Cambridge: Cambridge University Press.\n\n\n———. 1644/2003. The Principles of Philosophy, Tr. John Veitch. Champaign, IL: Project Gutenberg.\n\n\nEngel, Mylan. 1992. “Personal and Doxastic Justification in Epistemology.” Philosophical Studies 67 (2): 133–50. https://doi.org/10.1007/bf00373694.\n\n\nFodor, Jerry A. 1983. The Modularity of Mind. Cambridge, MA: MIT Press.\n\n\nGendler, Tamar Szabó. 2000. “The Puzzle of Imaginative Resistance.” Journal of Philosophy 97 (2): 55–81. https://doi.org/10.2307/2678446.\n\n\nGilbert, Daniel T. 1991. “How Mental Systems Believe.” American Psychologist 46 (2): 107–19. https://doi.org/10.1037//0003-066x.46.2.107.\n\n\nGilbert, Daniel T., Douglas S. Krull, and Patrick S. Malone. 1990. “Unbelieving the Unbelievable: Some Problems in the Rejection of False Information.” Journal of Personality and Social Psychology 59 (4): 601–13. https://doi.org/10.1037//0022-3514.59.4.601.\n\n\nGilbert, Daniel T., Romin W. Tafarodi, and Patrick S. Malone. 1993. “You Can’t Not Believe Everything You Read.” Journal of Personality and Social Psychology 65 (2): 221–33. https://doi.org/10.1037//0022-3514.65.2.221.\n\n\nGinet, Carl. 1985. “Contra Reliabilism.” Monist 68 (2): 175–87. https://doi.org/10.5840/monist198568218.\n\n\n———. 2001. “Deciding to Believe.” In Knowledge, Truth and Duty, edited by Matthias Steup, 63–76. Oxford: Oxford University Press.\n\n\nGrice, H. Paul. 1989. Studies in the Way of Words. Cambridge, MA.: Harvard University Press.\n\n\nHasson, Uri, Joseph P. Simmons, and Alexander Todorov. 2005. “Believe It or Not: On the Possibility of Suspending Belief.” Psychological Science 16 (7): 566–71. https://doi.org/10.1111/j.0956-7976.2005.01576.x.\n\n\nHeller, Mark. 2000. “Hobartian Voluntarism: Grounding a Deontological Conception of Epistemological Justification.” Pacific Philosophical Quarterly 81 (2): 130–41. https://doi.org/10.1111/1468-0114.00099.\n\n\nHieronymi, Pamela. 2008. “Responsibility for Believing.” Synthese 161 (3): 357–73. https://doi.org/10.1007/s11229-006-9089-x.\n\n\nHolton, Richard. 1999. “Intention and Weakness of Will.” The Journal of Philosophy 96 (5): 241–62. https://doi.org/10.2307/2564667.\n\n\n———. 2003. “How Is Strength of Will Possible?” In Weakness of Will and Varities of Practical Irrationality, edited by Sarah Stroud and Christine Tappolet, 39–67. Oxford: Oxford University Press.\n\n\n———. 2004. “Rational Resolve.” Philosophical Review 113 (4): 507–35. https://doi.org/10.1215/00318108-113-4-507.\n\n\nHolton, Richard, and Stephen Shute. 2007. “Self-Control in the Modern Provocation Defence.” Oxford Journal of Legal Studies 27 (1): 49–73. https://doi.org/10.1093/ojls/gql034.\n\n\nJones, Matthew L. 2006. The Good Life in the Scientific Revolution: Descartes, Pascal, Leibniz and the Cultivation of Virtue. Chicago: University of Chicago Press.\n\n\nKeller, Simon. 2005. “Patriotism as Bad Faith.” Ethics 115 (3): 563–92. https://doi.org/10.1086/428458.\n\n\nKennett, Jeanette, and Michael Smith. 1996a. “Frog and Toad Lose Control.” Analysis 56 (2): 63–73. https://doi.org/10.1111/j.0003-2638.1996.00063.x.\n\n\n———. 1996b. “Philosophy and Commonsense: The Case of Weakness of Will.” In The Place of Philosophy in the Study of Mind, edited by Michaelis Michael and John O’Leary-Hawthorne, 141–57. Norwell, MA: Kluwer. https://doi.org/10.1017/CBO9780511606977.005.\n\n\nLittlejohn, Clayton. 2009. “The Externalist’s Demon.” Canadian Journal of Philosophy 39 (3): 399–434. https://doi.org/10.1353/cjp.0.0054.\n\n\nOwens, David. 2000. Reason Without Freedom: The Problem of Epistemic Responsibility. New York: Routledge.\n\n\nPryor, James. 2001. “Highlights of Recent Epistemology.” British Journal for the Philosophy of Science 52 (1): 95–124. https://doi.org/10.1093/bjps/52.1.95.\n\n\nRyan, Sharon. 2003. “Doxastic Compatibilism and the Ethics of Belief.” Philosophical Studies 114 (1-2): 47–79. https://doi.org/10.1023/A:1024409201289.\n\n\nRyle, Gilbert. 1949. The Concept of Mind. New York: Barnes; Noble.\n\n\nShah, Nishi. 2002. “Clearing Space for Doxastic Voluntarism.” The Monist 85 (3): 436–45. https://doi.org/10.5840/monist200285326.\n\n\nSmith, Angela M. 2005. “Responsibility for Attitudes: Activity and Passivity in Mental Life.” Ethics 115 (2): 236–71. https://doi.org/10.1086/426957.\n\n\nSmith, Michael. 1997. “A Theory of Freedom and Responsibility.” In Ethics and Practical Reason, edited by Garrett Cullity and Berys Gaut, 293–317. Oxford: Oxford University Press.\n\n\n———. 2003. “Rational Capacities.” In Weakness of Will and Varities of Practical Irrationality, edited by Sarah Stroud and Christine Tappolet, 17–38. Oxford: Oxford University Press.\n\n\nSosa, Ernest. 1991. Knowledge in Perspective. New York: Cambridge University Press.\n\n\n———. 1997. “Reflective Knowledge in the Best Circles.” Journal of Philosophy 94 (8): 410–30. https://doi.org/10.2307/2564607.\n\n\nSteup, Matthias. 2000. “Doxastic Voluntarism and Epistemic Deontology.” Acta Analytica 15 (1): 25–56.\n\n\n———. 2008. “Doxastic Freedom.” Synthese 161 (3): 375–92. https://doi.org/10.1007/s11229-006-9090-4.\n\n\nStich, Stephen. 1978. “Beliefs and Subdoxastic States.” Philosophy of Science 45 (4): 499–518. https://doi.org/10.1086/288832.\n\n\nWatson, Gary. 1977. “Skepticism about Weakness of Will.” Philosophical Review 86 (3): 316–39. https://doi.org/10.2307/2183785.\n\n\nWeatherson, Brian. 2005. “Can We Do Without Pragmatic Encroachment?” Philosophical Perspectives 19 (1): 417–43. https://doi.org/10.1111/j.1520-8583.2005.00068.x.\n\n\nWilliams, Bernard. 1976. “Deciding to Believe.” In Problems of the Self, 136–51. Cambridge: Cambridge University Press.\n\n\nWilliamson, Timothy. 2000. Knowledge and its Limits. Oxford University Press."
  },
  {
    "objectID": "posts/lummarg/luminous-margins.html",
    "href": "posts/lummarg/luminous-margins.html",
    "title": "Luminous Margins",
    "section": "",
    "text": "0.1 Luminosity\nIn Knowledge and Its Limits Timothy Williamson argues that few conditions are luminous. 1 A condition is luminous iff we know we are in it whenever we are. Slightly more formally, Williamson defines\n1 Williamson (2000) Ch. 4; all references to this book unless otherwise specified.\nPublished in 83: 373-383.\nThanks to Tamar Szabó Gendler, John Hawthorne, Chris Hill, Ernest Sosa and the ’s referees.\n\n\nA condition C is defined to be luminous if and only if (L) holds:\n\n(L)\n\nFor every case \\({\\alpha}\\), if in \\({\\alpha}\\) C obtains, then in \\({\\alpha}\\) one is in a position to know that C obtains (95).\n\n\n\nIntuitively, the argument against this is as follows. The following three conditions are incompatible.\n\nGradual Change\n\nThere is a series of cases, each very similar to adjacent cases, that starts with a case where C clearly obtains, and ends with a case where C clearly doesn’t obtain.\n\nLuminosity\n\nWhenever C obtains you can know it does.\n\nSafety\n\nOnly safe beliefs count as knowledge, so whenever you can know that C obtains, C obtains in all very similar cases.\n\n\nLuminosity and Safety entail\n\nTolerance\n\nWhenever C obtains, it obtains in all very similar cases.\n\n\nBut Tolerance is incompatible with Gradual Change, since Tolerance entails that if the first member of the series is a case where C obtains, then every successive member is also a case where C obtains. Williamson argues that for any interesting epistemic condition, Gradual Change is a clear possibility. And he argues that Safety is a general principle about knowledge. So Luminosity must be scrapped. The counterexamples to Luminosity we get from following this proof through are always borderline cases of C obtaining. In these cases Luminosity fails because any belief that C did obtain would be unsafe, and hence not knowledge.\nI will argue, following Sainsbury (1995), that Williamson has misinterpreted the requirement that knowledge be safe. The most plausible safety condition might be compatible with Gradual Change and Luminosity, if we make certain plausible assumptions about the structure of phenomenal beliefs.\nOne consequence of the failure of Luminosity is that a certain historically important kind foundationalist analysis of knowledge fails. This kind of foundationalist takes the foundations to be luminous. Although I think Williamson’s argument against Luminosity does not work, my objections are no help to the foundationalist. As I said, my objection to Williamson rests on certain assumptions about the structure of phenomenal beliefs. It is a wide open empirical and philosophical question whether these assumptions are true. If this kind of foundationalism provided a plausible analysis of knowledge, then it would be a wide open question whether our purported knowledge rested on any foundations, and hence a wide open question whether we really had any knowledge. But this is a closed question. It is a Moorean fact that we know many things. So while I object to Williamson’s claim that we have no luminous mental states, I do not object to the weaker claim that we might not have any luminous mental states, and this claim is enough to do much of the philosophical work to which Williamson puts Luminosity.\n\n\n0.2 Williamson’s Example\nWilliamson suggests that (L), the formal rendition of Luminosity, fails for all interesting conditions even if we restrict the quantifier to those that are ‘physically and psychologically feasible’ [94], and I will assume that is what we are quantifying over. To argue that (L) fails for any interesting C, Williamson first argues that it fails in a special case, when C is the condition feeling cold, and then argues that the conditions that lead to failure here are met for any other interesting C. So I will also focus on the special case.\nMr Davis’s apartment faces southwest, so while it is often cold in the mornings it always warms up as the midday and afternoon sun streams in. This morning Mr Davis felt cold when he awoke, but now at noon he is quite warm, almost hot. But the change from wake-up time to the present is rather gradual. Mr Davis does not take a hot bath that morning, nor cook a hot breakfast, but sits reading by the window until the sun does its daily magic. Assume, for the sake of the argument, that feeling cold is luminous, so whenever Mr Davis feels cold, he knows he feels cold. Williamson argues this leads to a contradiction as follows. (I’ve changed names and pronouns to conform with my example.)\n\nLet t0, t1, …, tn be a series of times at one millisecond intervals from dawn to noon. Let \\({\\alpha}\\)i be the case at ti (0 \\({\\leq}\\) i \\({\\leq}\\) n). Consider a time ti between t0 and tn, and suppose that at tn Mr Davis knows that he feels cold. … Now at ti+1 he is almost equally confident that he feels cold, by the description of the case. So if he does not feel cold at ti+1, then his confidence at ti that he feels cold is not reliably based, for his almost equal confidence on a similar basis one millisecond earlier that he felt cold was misplaced … His confidence at ti was reliably based in the way required for knowledge only if he feels cold at ti+1. In the terminology of cases…:\n(ii) If in \\({\\alpha}\\)i he knows that he feels cold, then in \\({\\alpha}\\)i+1 he feels cold. (97)\n\nGiven (L), all instances of (ii), and the fact that Mr Davis feels cold when he awakes, we get the false conclusion that he now feels cold. So if we accept all instances of (ii), we must conclude that (L) is false when C is feeling cold and ‘one’ denotes Mr Davis. Why, then, accept (ii)? One move Williamson makes here is purely defensive. He notes that (ii) is different from the conditionals that lead to paradox in the Sorites argument. The antecedent of (ii) contains the modal operator knows that absent from its consequent, so we cannot chain together instances of (ii) to produce an implausible conditional claim. If that operator were absent then from all the instances of (ii) it would follow that if Mr Davis feels cold at dawn he feels cold at noon, which is false. But by strengthening the antecedent, Williamson weakens (ii) to avoid that conclusion. But the fact that (ii) is not paradoxical is not sufficient reason to accept it.\n\n\n0.3 Reliability\nIt is useful to separate out two distinct strands in Williamson’s argument for (ii). One strand sees Williamson arguing for (ii) by resting on the principle that beliefs constitute knowledge only if they are reliably based. The idea is that if Mr Davis’s belief that he feels cold is a bit of knowledge, it is reliable, and if it is reliable it is true in all similar situations, and hence it is true in \\({\\alpha}\\)i+1. The other strand sees him appealing to a vague but undoubtedly real requirement that beliefs must be safely true in order to be knowledge. Neither argument is successful, though the second kind of argument is better than the first.\nWilliamson acknowledges Conee and Feldman’s arguments that no reliabilist epistemologist has yet solved the generality problem (100). But he takes this to be reason to abandon not the concept of reliability, but the hope of providing a reductive analysis of it. Williamson thinks we can get a long way by just resting on the intuitive concept of reliability. This seems to be a mistake. There are two ordinary ways of using ‘reliable’ in the context of discussing beliefs, and neither provides support for (ii).\nFirst, and this is clearly not what is needed, sometimes ‘reliable’ just means true. This is the sense of the word in which we can consistently say, “It turned out the information that old Ronnie provided us about where the gov’nor was eating tonight was reliable, which was plenty surprising since Ronnie hadn’t been right about anything since the Nixon administration.” This is the sense in which reliable means just what the etymology suggests it means, something that can be relied upon. And that means, in practice, true. But that won’t help at all, for if ‘reliable’ just means true, then nothing follows from the fact that knowledge is reliable that does not follow from the fact that it is factive.\nSecond, there is a distinctively philosophical sense in which reliable means something more like true in a wide range of circumstances. This is the sense in which a stopped clock is not even reliable twice a day. At first, this might look to help Williamson a little more. But if philosophical usage is to be key, the second look is more discouraging. For in its philosophical usage, reliability does not even entail truth. And if reliability does not entail truth in the actual situation, it surely does not entail truth in nearby situations. But Williamson’s argument for (ii) requires that reliability in \\({\\alpha}\\)i entails truth in \\({\\alpha}\\)i+1. So on neither of its natural readings does the concept of reliability seal the argument here, and since we have no unnatural reading to fall back upon, the argument from reliability for (ii) fails. To be fair, by chapter 5 of Williamson’s book the concept of reliability that seems to be employed is little distinguishable from the concept of safety. So let us turn to those arguments.\n\n\n0.4 Safety\nWilliamson at times suggests that the core argument for (ii) is a straight appeal to intuition. “[E]ven when we can appeal to rigorous rules, they only postpone the moment at which we must apply concepts in particular cases on the basis of good judgement. … The argument for (ii) appeals to such judgement.” (101) The appeal to intuition is the royal road to scepticism, so we would be justified in being a little wary of it. Weinberg, Stich, and Nichols (2001) discovered that undergraduates from the same social class as Williamson, Mr Davis and I would frequently judge that a subject could not know that mule was a mule unless he could tell it apart from a cleverly painted zebra. The judgements of that class are not obviously the basis for a sane epistemology.\nWilliamson undersells his argument by making it an appeal to judgement. For there is a principle here, if not a rigorous rule, that grounds the judgement. The principle is something like Ernest Sosa’s safety principle. The idea is that a belief does not constitute knowledge if it is false in similar situations. “[N]ot easily would S believe that p without it being the case that p.” (Sosa 1999, 142) There is much to be said here about what is a similar situation. (David Lewis (1996) discusses a concept of similarity in the context of saying that worlds can be salient, in his sense, in virtue of being similar to salient worlds.) It might turn out that there is no account of similarity that makes it plausible that this is a constraint on knowledge. But for present purposes I am prepared to grant (a) that only safe beliefs count as knowledge, and (b) that \\({\\alpha}\\)i+1 is a similar situation to \\({\\alpha}\\)i.\nThis might seem like too much of a concession to Williamson, for it already conflicts with some platitudes about knowledge. Consider a case that satisfies the following three conditions. Some light reflects off a leopard some distance away and strikes our eyes. The impact of that light causes, by the normal processes, a belief that a leopard is nearby to appear in our belief box. Beliefs, including leopard-related beliefs, that we form by this kind of process are on the whole very reliable. You might think these conditions are sufficient for our belief to count as knowledge that a tiger is present. The proponent of Safety denies this. She says that if, for example, there are several cheetahs with a particularly rare mutation that make the look much like leopards around, and if we saw them at similar distance we would have mistaken them for leopards. Since we could easily have had the belief that a leopard is nearby while there were no leopards, only cheetahs, nearby, the belief is not safe and so does not count as knowledge.\nThere are two reasons to think that safety is too strong here, neither of which strike me as completely compelling. (I’m still conceding things to Williamson here. If there’s a general objection to Safety then his argument against Luminosity does not get off the ground. That’s not my position. As I’ll soon argue, I think Williamson has misinterpreted Safety.) The first reason is a worry that if we deny knowledge in a case of reliable veridical perception, we are conceding too much to the sceptic. But the proponent of Safety has a very good reason to distinguish this case from my current veridical perception of a table - my perception is safe and the perception of a leopard is not. So there is no slippery slope to scepticism here. The second is that the allegedly similar case is not really that similar, because in that case the belief is caused by a cheetah, not a leopard. But to regard cases where the evidence is different in this way as being dissimilar is to make the safety condition impotent, and Sosa has shown that we need some version of Safety to account for our intuitions about different cases.2\n2 I assume here a relatively conservative epistemological methodology, one that says we should place a high priority on having our theories agree with our intuitive judgments. I’m in favour of a more radical methodology that makes theoretical virtues as important as agreement with particular intuitions Weatherson (2003). On the radical view Safety might well be abandoned. But on that view knowledge might be merely true belief, or merely justified true belief, so the argument for Luminosity will be a non-starter. But the argument of this paper does not rest on these radical methodological principles. The position I’m defending is that, supposing a standard methodological approach, we should accept a Safety principle. But as I’ll argue, the version of Safety Williamson adopts is not appropriate, and the appropriate version does not necessarily support the argument against Luminosity.So I think some version of Safety should be adopted. I don’t think this gives us (ii), for reasons related to some concerns first raised by Mark Sainsbury (1995). The role for Safety condition in a theory of knowledge is to rule out knowledge by lucky guesses. This includes lucky guesses in mathematics. If Mr Davis guesses that 193 plus 245 is 438, he does not thereby know what 193 plus 245 is. Can Safety show why this is so? Yes, but only if we phrase it in a certain way. Assume that we have a certain belief B with content p. (As it might be, Mr Davis’s belief with content 193 + 245 = 438.) Then the following two conditions both have claims to being the correct analysis of ‘safe’ as it appears in Safety.\n\nContent-safety\n\nB is safe iff p is true in all similar worlds.\n\nBelief-safety\n\nB is safe iff B is true in all similar worlds.\n\n\nIf we rest with content-safety, then we cannot explain why Mr Davis’s lucky guess does not count as knowledge. For in all nearby worlds, the content of the belief he actually has is true. If we use belief-safety as our condition though, I think we can show why Mr Davis has not just got some mathematical knowledge. The story requires following Marian David’s good advice for token physicalists and rejecting content essentialism about belief (David (2002); see also Gibbons (1993). The part of Mr Davis’s brain that currently instantiates a belief that 193 plus 245 is 438 could easily have instantiated a belief that 193 plus 245 is 338, for Mr Davis is not very good at carrying hundreds while guessing. If, as good physicalists, we identify his belief with the part of the brain that instantiates it, we get the conclusion that this very belief could have had the false content that 193 plus 245 is 338. So the belief is not safe, and hence it is not knowledge.\nThis lends some credence to the idea that it’s belief-safety, not content-safety, that’s the important safety criteria. When talking about Mr Davis’s mathematical hunches, belief-safety is a stronger condition than content-safety. But when talking about his feelings, things may be reversed.\nLet me tell you a little story about how Mr Davis’s mind is instantiated. Mr Davis’s phenomenal beliefs do not arise from one part of his brain, his belief box or mind’s eye, tracking another part, the part whose states constitute his feeling cold. Rather, when he is in some phenomenal state, the very same brain states constitute both the phenomena and a belief about the phenomena. Mr Davis’s brain is so wired that he could not have any sensation of radiant heat (or lack thereof) without his thereby believing that he is having just that sensation, because he could not have felt cold without that feeling itself being a belief that he felt cold. In that case, belief-safety will not entail (ii). Imagine that at \\({\\alpha}\\)i Mr Davis feels cold, but at \\({\\alpha}\\)i+1 he does not. (I assume here, with Williamson, that there is such an i.) At \\({\\alpha}\\)i he thereby believes that he feels cold. The content of that belief is a de se proposition that is false at \\({\\alpha}\\)i+1, so it violates content-safety. But in \\({\\alpha}\\)t+1 that part of his brain does not constitute his feeling cold (for he does not feel cold), and thereby does not constitute his believing that he feels cold. By hypothesis, by that time no part of his brain constitutes feeling cold. So the belief in \\({\\alpha}\\)i that he feels cold is not false in \\({\\alpha}\\)i+1; it either no longer exists, or now has the true content that Mr Davis does not feel cold. So belief-safety does not prevent this belief of Mr Davis’s from being knowledge. And indeed, it seems rather plausible that it is knowledge, for he could not have had just this belief without it being true. This belief violates content-safety but not belief-safety, and since we have no reason to think that content-safety rather than belief-safety is the right form of the safety constraint, we have no reason to reject the intuition that this belief, this more or less infallible belief, counts as a bit of knowledge.\nThis story about Mr Davis’s psychology might seem unbelievable, so let me clear up some details. Mr Davis has both phenomenal and judgemental beliefs about his phenomenal states. The phenomenal beliefs are present when and only when the phenomenal states are present. The judgemental beliefs are much more flexible, they are nomically independent of the phenomena they describe. The judgemental beliefs are grounded in ‘inner perceptions’ of his phenomenal states. The phenomenal beliefs are not, they just are the phenomenal states. The judgemental beliefs can be complex, as in a belief that I feel cold iff it is Monday, while the phenomenal beliefs are always simple. It is logically possible that Mr Davis be wired so that he feel cold without believing he feels cold, but it is not an accident that he is so wired. Most of his conspecifics are similarly set up. It is possible that at a particular time Mr Davis has both a phenomenal belief and a judgemental belief that he feels cold, with the beliefs being instantiated in different parts of his brain. If he has both of these beliefs in \\({\\alpha}\\)i, then Williamson’s argument may well show that the judgemental belief does not count as knowledge, for it could be false in \\({\\alpha}\\)i+1. If he has the judgemental belief that he is not cold in \\({\\alpha}\\)i, then the phenomenal belief that he is cold may not be knowledge, for it is plausible that the existence of a contrary belief defeats a particular belief’s claim to knowledge. But that does not mean that he is not in a position to know that he is cold in \\({\\alpha}\\)i.\nSome may object that it is conceptually impossible that a brain state that instantiates a phenomenal feel should also instantiate a belief. And it is true that Mr Davis’s phenomenal states do not have some of the features that we typically associate with beliefs. These states are relatively unstructured, for example. Anyone who thinks that it is a conceptual truth that mental representations are structured like linguistic representations will think that Mr Davis could not have the phenomenal beliefs I have ascribed to him. But it is very implausible that this is a conceptual truth. The best arguments for the language of thought hypothesis rest on empirical facts about believers, especially the facts that mental representation is typically productive and systematic. If there are limits to how productive and systematic Mr Davis’s phenomenal representations are, then it is possible that his phenomenal states are beliefs. Certainly those states are correlated with inputs (external states of affairs) and outputs (bodily movements, if not actions) to count as beliefs on some functionalist conceptions of belief.\nA referee noted that we don’t need the strong assumption that phenomenal states can be beliefs to make the argument here, though it probably is the most illumination example. Either of the following stories about Mr Davis’s mind could have done. First, Mr Davis’s phenomenal belief may be of the form “I feel \\({\\phi}\\)”, where “I” and “feel” are words in Mr Davis’s language of thought, and \\({\\phi}\\) is the phenomenal state, functioning as a name for itself. As long as the belief arises whenever Mr Davis is \\({\\phi}\\), and it has the phenomenal state as a constituent, it can satisfy belief-safety even when content-safety fails. The second option involves some more contentious assumptions. The phenomenal belief may be of the form “I feel thus”, where the demonstrative picks out the phenomenal state. As long as it is essential to the belief that it includes a demonstrative reference to that phenomenal state, it will satisfy belief-safety. This is more contentious because it might seem plausible that a particular demonstrative belief could have picked out a different state. What won’t work, of course, is if the phenomenal belief is “I feel F”, where F is an attempted description of the phenomenal state. That certainly violates every kind of safety requirement. I think it is plausible that phenomenal states could be belief states, but if you do not believe that it is worth noting the argument could possibly go through without it, as illustrated in this paragraph.\nMr Davis is an interesting case because he shows just how strong a safety assumption we need to ground (ii). For Mr Davis is a counterexample to (ii), but his coldness beliefs satisfy many plausible safety-like constraints. For example, his beliefs about whether he feels cold are sensitive to whether he feels cold. Williamson (Ch. 7) shows fairly conclusively that knowledge does not entail sensitivity, so one might have thought that in interesting cases sensitivity would be too strong for what is needed, not too weak as it is here. From this it follows that any safety condition that is strictly weaker than sensitivity, such as the condition that the subject could not easily believe p and be wrong, is not sufficient to support (ii). Williamson slides over this point by assuming that the subject will be almost as confident that he feels cold at \\({\\alpha}\\)i+1 as he is at \\({\\alpha}\\)i. This is no part of the description of the case, as Mr Davis shows.\nMy argument above rests on the denial of content essentialism, which might look like a relatively unsafe premise. So to conclude this section, let’s see how far the argument can go without that assumption. Sainsbury responds to his example, the lucky arithmetic guess, by proposing a different version of safety: mechanism-safety.\n\nMechanism-safety\n\nB is safe iff the mechanism that produced B produces true beliefs in all similar worlds.\n\n\nI didn’t want to rest on this too much because I think it’s rather hard to say exactly what the mechanism is that produces Mr Davis’s belief that he feels cold. But if it’s just his sensory system, then I think it is clear that even at \\({\\alpha}\\)i, Mr Davis’s belief that he feels cold satisfies mechanism-safety. The bigger point here is that content-safety is a very distinctive kind of safety claim, but it’s the only kind that justifies (ii).\n\n\n0.5 Retractions\nTo close, let me stress how limited my criticisms of Williamson here are. Very briefly, the argument is that there can be some self-presenting mental states, states that are either token identical with the belief that they exist or are constituents of (the contents of) beliefs that they exist, and these beliefs will satisfy all the safety requirements we should want, even in borderline cases. If some conditions are invariably instantiated by self-presenting states, then those conditions will be luminous. And I think it is a live possibility, relative at least to the assumptions Williamson makes, that there are such self-presenting states. But there aren’t very many of them. There is a reason I picked feels cold as my illustration. It’s not laughable that it is self-presenting.\nOn the other hand, it is quite implausible that, say, knowing where to buy the best Guinness is self-presenting. And for states that are not self-presenting, I think Williamson’s anti-luminosity argument works. That’s because it is very plausible (a) that for a belief to be knowledge it must satisfy either belief-safety or mechanism-safety, (b) a non-self-presenting state satisfies belief-safety or mechanism-safety only if it satisfies content-safety, and (c) as Williamson showed, if beliefs about a state must satisfy content-safety to count as knowledge, then that state is not luminous. So epistemic states, like the state of knowing where to buy the best Guinness, are not luminous. That is to say, one can know where to buy the best Guinness without knowing that one knows this. And saying that (for these reasons) is to just endorse Williamson’s arguments against the KK principle. Those arguments are an important special case of the argument against luminosity, and I don’t see how any of my criticisms of the general argument touch the special case.\nWilliamson describes his attacks on luminosity as an argument for cognitive homelessness. If a state was luminous, that state would be a cognitive home. Williamson thinks we are homeless. I think we may have a small home in our phenomenal states. This home is not a mansion, perhaps just a small apartment with some afternoon sun, but it may be a home.\nDon’t be fooled into thinking this supports any kind of foundationalism about knowledge, however. It is true that if we have the kind of self-presenting states that Mr Davis has (under one of the three descriptions I’ve offered), then we have the self-justifying beliefs that foundationalism needs to get started. But it is at best a wide-open philosophical and scientific question whether we have any such states, while it is not a wide-open question whether we have any knowledge, or any justified beliefs. If these states are the only things that could serve as foundations, it would be at least conceptually possible that we could have knowledge without self-justifying foundations. So the kind of possibility exemplified by Mr Davis cannot, on its own, prop up foundationalism.\n\n\n\n\n\n\nReferences\n\nDavid, Marian. 2002. “Content Essentialism.” Acta Analytica 17: 103–14. https://doi.org/10.1007/bf03177510.\n\n\nGibbons, John. 1993. “Identity Without Supervenience.” Philosophical Studies 70 (1): 59–79. https://doi.org/10.1007/bf00989662.\n\n\nLewis, David. 1996. “Elusive Knowledge.” Australasian Journal of Philosophy 74 (4): 549–67. https://doi.org/10.1080/00048409612347521.\n\n\nSainsbury, Mark. 1995. “Vagueness, Ignorance and Margin for Error.” British Journal for the Philosophy of Science 46: 589–601. https://doi.org/10.1093/bjps/46.4.589.\n\n\nSosa, Ernest. 1999. “How to Defeat Opposition to Moore.” Philosophical Perspectives 13: 141–53. https://doi.org/10.1111/0029-4624.33.s13.7.\n\n\nWeatherson, Brian. 2003. “What Good Are Counterexamples?” Philosophical Studies 115 (1): 1–31. https://doi.org/10.1023/A:1024961917413.\n\n\nWeinberg, Jonathan, Stephen Stich, and Shaun Nichols. 2001. “Normativity and Epistemic Intuitions.” Philosophical Topics 29 (1): 429–60. https://doi.org/10.5840/philtopics2001291/217.\n\n\nWilliamson, Timothy. 2000. Knowledge and its Limits. Oxford University Press."
  },
  {
    "objectID": "posts/nine-obj/nine-objections-to-steiner-and-wolff-on-land-disputes.html",
    "href": "posts/nine-obj/nine-objections-to-steiner-and-wolff-on-land-disputes.html",
    "title": "Nine Objections to Steiner and Wolff on Land Disputes",
    "section": "",
    "text": "In the July 2003 Analysis, Hillel Steiner and Jonathan Wolff (2003) propose a framework for “resolving disputed land claims between competing nations or ethnic groups.” The idea is that we should auction off the land, with the loser of the auction getting the money. While this might mean that the richer party will normally end up with the land, and this is normally not thought to be a good thing, if the auction is conducted as they specify “it will turn out that the other party ends up with something which, in the circumstances, it prefers to the land: lots of money.”\n\nPublished in Analysis 63: 321-327.\nPicture by Mustang Joe via Creative Commons.\n\nActually, it isn’t so clear that this is what will result. Let’s say we have a particular parcel of land that groups A and B want. They each want it quite strongly, but B has deeper pockets than A, so while A would be prepared to pay 8 for the land, B would be prepared to pay 12. For the auction process to function, there must be a minimum bid increment, I’ll say it is \\(\\frac{1}{2}\\). Assume that B has just bid 4, A must now choose whether to bid 4\\(\\frac{1}{2}\\) or accept B’s bid. And assume for now that A is not bidding tactically, it only makes a bid if it would prefer to win the auction with that bid than accept B’s bid. This assumption will be relaxed below.\nSo for now, A must decide whether it prefers to be given 4, or to get the land for 4\\(\\frac{1}{2}\\). Since it values the land at 8, and since it will give up 8\\(\\frac{1}{2}\\) to buy the land (the 4\\(\\frac{1}{2}\\) it will pay, plus the 4 it would have received from B) it may well decide to just accept the bid. But now it has ended up with something it definitely does not prefer to the land, since it just accepted a bid for 4. There are two assumptions at play here. One is that A doesn’t bid tactically, which I shall return to a bit. The other is that how much A will pay for the land is not affected by receiving B’s 4. That is, I assume that the marginal utility of money is relatively constant for A over the ranges of money at play in the auction. This assumption might be false if we’re dealing with a very large or valuable body of land, but it’s not unreasonable in most circumstances. (Space prevents a complete study of what happens if we take the declining marginal utility of money completely into account. Roughly, the effect is that some of my criticisms are slightly vitiated.) Now while these assumptions might be false, Steiner and Wolff give us no reason to be certain they are false. So for all they’ve said we could have a situation just like this one, where the poorer party ends up with something it wants much less than the land. Hence\n\nObjection 1. There is no guarantee that the losing party will end up with something they prefer to the land.\n\nWhile this contradicts an alleged benefit of Steiner and Wolff’s plan, it might not be thought to be a deep problem. After all, A gets half as much as they wanted, and if they are only one of two equal claimants to the land, then this is a fair result. This may be true, but note that the assumption that each party has an equal claim to the land is doing a lot of work here. If A’s claim is stronger, then only getting half of the value of the land is quite unfair. If the two claims are incommensurable, there may be no fact of the matter whether it is fair that A receives 4. If we cannot tell which of the moral claims is stronger, which is very often the case in land disputes, it may be impossible to tell whether A’s receiving 4 is fair or not. Hence\n\nObjection 2. The proposal is only appropriate where each party has a genuinely equal moral claim to the land. This doesn’t happen often, and it is quite rare that we know it happens.\n\nWhile Steiner and Wolff note that they are leaving questions about enforcement and compliance to another place, so it isn’t fair to press them too strongly on these topics, it is worth noting how this feature of their proposal makes compliance harder to enforce. If by participating in the auction both parties are tacitly agreeing that the other party has an equal claim to the land, and I think the above suggests they are doing just this, that will reduce the legitimacy of the auction process in the eyes of members of the losing group. And that will lead to enforcement difficulties down the line.\nThere is an administrative problem lurking around here. Since each party will end up with something from this process once the auction begins, we must have a way of determining whether the competing claims warrant an auction, or whether one party should receive the land, or whether some kind of negotiation is possible. And once we set up a process to do that, it could easily encourage relatively spurious land claims. Unless there is a serious cost to suggesting that one should be party to an auction of some block of land, there is a large incentive to get into these auctions wherever and whenever possible. Perhaps some method could be designed to offset this incentive, and perhaps even the desire groups have to be approved by the court of public opinion will offset it at times, but it seems to be a problem with the proposal as formulated.\nTo be sure, if A accepts B’s bid, then both parties do end up with something from the auction. A gets 4, and B gets some land that it values at 12 for 4, a gain of 8. Note that B does much better out of the auction than A. If the auction stops when the richer party makes a bid at or above half the price the poorer party would pay, then the richer party will always end up with a higher ‘utility surplus’. Hence\n\nObjection 3. If there’s no tactical bidding the utility surplus is given entirely to the richer party.\n\nLet’s relax the assumption that A does not bid tactically. Indeed, let’s make things as good as could be realistically expected for A. It knows that B values the land at 12 and does not bid tactically, so B will make bids up to 6, and accept any bid over 6. Hence the auction proceeds as follows: A bids 4\\(\\frac{1}{2}\\), B bids 5, A bids 5\\(\\frac{1}{2}\\), B bids 6, A accepts. Now things could go better for A, but it would require some luck and courage. A could bid 6\\(\\frac{1}{2}\\) and B could reply with a bid of 7, but since this requires B acting against its own interests (it is better off accepting the bid of 6\\(\\frac{1}{2}\\) after all), and hence also requires A making a risky move that will only yield dividends only if B acts against its own interests in just this way, such an outcome seems unlikely. So in practice the best case scenario for A is that B pays 6 for the land. In this case A ends up with 6, and B ends up paying 6 for land it values at 12, a gain of 6. Hence\n\nObjection 4. Among the realistic outcomes, the best case scenario for the poorer party is that it ends up with as large a utility surplus as the richer party.\n\nBest cases don’t often happen, so in practice we should normally expect a result somewhere between the ‘no tactical bargaining’ option, where B receives a larger share of the surplus, and this ‘best case scenario’ where the two parties get an equal share of the surplus. Hence in almost all cases, the richer party will get a larger surplus than the poorer party. This seems like a flaw in the proposal, but worse is to come. Most of the ways in which B can realistically increase its share of the surplus involve behaviour that we should not want to encourage.\nConsider again A’s decision to reject the bid of 5 and bid 5\\(\\frac{1}{2}\\). Assume, for simplicity, that A plans to accept a bid of 6, but drop the assumption that A knows that B will reject a bid of 5\\(\\frac{1}{2}\\), if it is made. So before A makes its decision, there are three possible outcomes it faces:\nIn this case it receives 5.\nIn this case it gets the land (value 8) for 5\\(\\frac{1}{2}\\), net gain 2\\(\\frac{1}{2}\\).\nIn this case B bids 6, and A accepts, so it gets 6.\nA’s expected utility is higher if it bids 5\\(\\frac{1}{2}\\) rather than accepts B’s bid iff its degree of belief that B will bid 6 is over \\(\\frac{5}{7}\\). If it is less confident than that that B will bid 6, it should accept the bid of 5. As it happens, B is going to reject a bid of 5\\(\\frac{1}{2}\\) and bid 6, so it is better off if A accepts the bid of 5. If A knows B’s plans, this will not happen. But if A is ignorant of B’s intentions, it is possible it will accept the bid of 5. Indeed, since A’s confidence that B will decline must be as high as \\(\\frac{5}{7}\\) before it makes the bid of 5\\(\\frac{1}{2}\\), it might be quite likely in this case that A will just accept the bid.\nNot surprisingly, we get the result that B is better off if its bargaining plans are kept secret than if they are revealed to A. That in itself may not be objectionable. But remember that the agents here are not individuals, they are states. And the decisions about how to bid involve policy questions that will often be the most important issue the state in question faces for many a year. Ideally, decisions about how to approach the auction should be decided as democratically as possible. But democratic decision making requires openness, and it is impossible that all the stakeholders in B, including one imagines the citizens, can participate in the decision about how to approach the auction without B tipping its hand. In the modern world it’s impossible to involve everyone in B without opening the debate to agents of A. And this, as we’ve seen, probably has costs. Since B is better off if it does not make decisions about how to approach the auction in the open, we have\n\nObjection 5. The proposal favours secretive governments over open democratic governments.\n\nAssume that B has been somewhat secretive, but A is still fairly confident that B will not accept a bid of 5\\(\\frac{1}{2}\\). Its degree of belief that such a bid will be rejected is \\(\\frac{3}{4}\\), let’s say, so it is disposed to gamble and make that bid. But now B starts making some noises about what it will do with any money it gets from A. The primary beneficiary of this windfall will be B’s military. And the primary use of this military is to engage in military conflicts with A. While some of these engagements will be defensive, if A gets the land under dispute many will be offensive. (I don’t think these assumptions are particularly fanciful in many of the land disputes we see in the modern world.) A must take this into account when making its decisions. It seems reasonable to say that every 1 that A gives B has a disutility of 1.2 for A, 1 for the cost of the money it gives up, and 0.2 for the extra damage it may suffer when that money is turned into weaponry turned back against A. Now the utility calculations are quite different. If B accepts A’s bid of 5\\(\\frac{1}{2}\\), A’s balance sheet will look like this:\nThe land, value 8.\n5\\(\\frac{1}{2}\\) paid to B, value 5\\(\\frac{1}{2}\\)\nB’s extra military capability, value (a little over) 1.\nRoughly 1\\(\\frac{1}{2}\\).\nSo now the expected utility of bidding 5\\(\\frac{1}{2}\\) is:\n\nProb(Bid Accepted) Utility(Bid Accepted) + Prob(Bid Rejected) Utility(Bid Rejected)\n\\(\\approx \\frac{1}{4} \\times 1\\frac{1}{2} + \\frac{3}{4} \\times 6\\)\n= \\(4\\frac{7}{8}\\)\n\nHence A’s expected utility for accepting B’s bid of 5, i.e. 5, is higher than its expected utility of bidding 5\\(\\frac{1}{2}\\), so it will accept the bid, just as B wanted it to do. So if B indicates that it will use any payments from A to attack A, it may well be able to get the land for less. Hence\n\nObjection 6. The proposal favours belligerent governments over peaceful governments.\n\nOne qualification to this objection is that what matters here is what A thinks B will do, not what B actually does. So the objection is not that the proposal rewards offensive behaviour, but that it rewards belligerence, or indications of offensive behaviour. This isn’t as bad as rewarding military action, but it is still objectionable.\nThroughout I have used a particular example to make the points clearer, none of the arguments turns on the details of this example. What matters is that in any case where one party is able to spend more for the land in question simply because they are richer, the richer party will almost inevitably have a higher utility surplus, and this party can increase their expected utility surplus by being more secretive about their plans, and by being adopting a more belligerent tone towards their rivals before and during the auction. So it seems the proposal systematically rewards behaviour we should be discouraging.\nThe remaining objections concern the implementation of Steiner and Wolff’s proposal. While I don’t have a demonstrative proof that any of these concerns present insurmountable difficulties, they all suggest ways in which the proposal must be qualified if it is to be just.\nThe proposal seems to assume that the parties to the dispute agree over whether the land in question can be divided. As Steiner and Wolff put it, “The auction can thus be viewed as a device for achieving a fair settlement for the disposition of a good when neither division nor joint ownership is acceptable to the parties.” In some conflicts at least part of what is at issue is whether the land can be divided. For instance, if we were applying this proposal as a way of settling the war between Britain and Ireland in 1921, would we say that all of Ireland should be auctioned off, or just that the six counties that became Northern Ireland should be auctioned? Assuming the British had decided that governing southern Ireland had become too much trouble and were only interested in retaining the north, they may not have wanted to pay for the whole country just to protect their interests in the north. But at least some of the Irish would have been unwilling to accept a process that may have led to the division of the country, as would have obtained had the south been granted Home Rule, but the north left subject to an auction. (The historical facts are, obviously, somewhat more complicated than I’ve sketched here, but even when those complications are considered the difficulties that must be overcome before we know how to apply the proposal to a real situation are formidable.) Hence\n\nObjection 7. The proposal assumes a mechanism for determining which land is indivisible, and in some cases developing such a process is no easier than settling the dispute.\n\nSteiner and Wolff assume that the groups, A and B, are easily identifiable. In practice, this may not be so easy. For example, at least some people in Scotland would prefer that Scotland was independent. For now most people prefer devolution to independence (and some would prefer rule from Westminster) but we can easily imagine circumstances in which the nationalist support would rise to a level where it became almost a majority. If a majority in Scotland wants to secede, and the British government is willing to do this, then presumably they will just secede. But what are we to do if a narrow majority in Scotland wants to secede, and the British government (or people) do not want them to go? Presumably Steiner and Wolff’s proposal is that some sort of auction should be held to determine who should be in charge of the land. But who exactly are meant to be the parties? On the Westminster side, is the party Britain as a whole, or Britain except for Scotland? On the Scottish side, is it the Scottish people? The Scottish government, which for now is a creature that exists at the pleasure of the British Parliament? Those people who support Scottish independence? If the last, how shall we determine just who these people are? Perhaps some one or other of these answers can be defended, but the proposal is seriously incomplete, hence\n\nObjection 8. There is no mechanism for determining who shall count as a member of the groups in question.\n\nFinally, the proposal simply assumes that we can agree upon the currency in which the auction shall be conducted, but it is not ever so clear that this can be done. Usually, the two parties to a dispute will use different currencies, so to avoid conflicts it would be best if the auction were conducted in a neutral currency. But finding such a currency may be non-trivial. There are only a handful of currencies in the world whose supply is sufficiently abundant to conduct an auction of this size, and most of the time those currencies will be backed by governments who favour one side in the dispute. If they use this favouritism to provide access to credit denominated in their currency at a discounted rate, that threatens the fairness of the auction. Hence\n\nObjection 9. The proposal assumes a given currency in which to conduct the auction, but in practice any choice of currency may favour one side.\n\nThe last three objections are, as mentioned, somewhat administrative. It is possible that in a particular situation they could be overcome, though I think that it is more likely that they would pose serious difficulties to a would-be auction-wielding pacifier. But that’s not the serious problem with the proposal. The real problem, as the first six objections show, is that it favours rich, secretive, belligerent states that are disposed to make spurious land claims over poor, democratic, pacifist states that only make genuine land claims.\n\n\n\n\nReferences\n\nSteiner, Hillel, and Jonathan Wolff. 2003. “A General Framework for Resolving Disputed Land Claims.” Analysis 63 (3): 188–89. https://doi.org/10.1093/analys/63.3.188."
  },
  {
    "objectID": "posts/review-keefe/review-of-theories-of-vagueness.html",
    "href": "posts/review-keefe/review-of-theories-of-vagueness.html",
    "title": "Review of “Theories of Vagueness”",
    "section": "",
    "text": "Many philosophers, I suspect, are partial to supervaluational theories of vagueness. And with good reason. Its rivals all seem to promise metaphysical mysteries concerning hitherto unnoticed, and perhaps unnoticeable, sharp boundaries around our concepts, or radical revision in our logical practices. And not only have philosophers been so tempted. The texts are a little unclear, but it seems several economists can be read as adopting supervaluational solutions to the difficulties raised by vagueness in economic concepts. Given its popularity, and plausibility, supervaluationism deserves a book-length defence. Yet this is the first such book in the philosophical canon.\n\nPublished in Philosophy and Phenomenological Research 67: 491-4.\n\nAnd it is a fine defence of supervaluationism, though I doubt it is entirely successful. I ended up, a little contrariwise, feeling less convinced in the hegemony of supervaluational approaches than I was when I started. In part this was because Keefe was so clear in setting out where some rival approaches, especially degree-based approaches, failed that I felt she had inadvertently pointed out where her opponents should move next. Keefe’s positive theory is fairly familiar, though she often marshalls new arguments for it, so this review will not dwell on exposition but concentrate on Keefe’s arguments.\nThe book effectively divides into three parts. The first two chapters involve some scene-setting, and a discussion of the various methodological principles adopted. The next four chapters are attacks on non-supervaluational theories. And the final two chapters defend Keefe’s preferred version of supervaluationism. Starting with methodology seemed to be a good idea, but the discussion didn’t break much new ground. It turns out, surprisingly enough, that reflective equilibrium is useful in theorising about vagueness too.\nThe first rival theory to be examined is epistemicism, and Keefe presents two main arguments. One of these is fairly familiar, epistemicists have no theory about how predicates get the particular precise extensions that they do. This is true, but then supervaluationists aren’t exactly flush with theories about how predicates get the particular imprecise extensions that they do either. The other criticism is more interesting. Epistemicism posits a sharp boundary between the tall and not-tall, but we don’t know where this boundary is. It is a mystery why we do not have this knowledge, one that epistemicists try to solve by showing we could not know where the boundary is. But there are other mysteries too. For some reason, we don’t try to find out where the boundary is, and we don’t have beliefs about where it is. That we couldn’t get this kind of knowledge doesn’t explain these omissions. Like Hobbes trying to square the circle, we all try impossible things sometimes. So epistemicism has more explaining to do than it has hitherto done.\nKeefe spends two chapters attacking theories based on degrees of truth. There are several related objections raised to these theories, but fundamentally they all boil down to the problem of false precision. If there is no fact of the matter as to whether Kylie is happy is true or not, then there is no fact of the matter as to whether it is true to degree 0.314. The most natural formulation of degree theories assumes there are facts of this latter form. More complicated formulations are either incoherent or incomplete. Keefe is good at working through the various moves that have been attempted to avoid this problem, and showing that none of them work. But at times she seemed too content to refute theories that had appeared in the literature, rather than anticipating future challengers. One particular challenge seemed particularly worthy of consideration. At one point Keefe introduces a new connective \\(≥_T\\) to mean true to the same or a greater degree. She notes that most extant degree theorists are committed to a connectedness principle for \\(≥_T\\): either \\(p ≥_T q\\) or \\(q ≥_T p\\). But this principle is implausible given their other commitments. At this point it seemed relevant to wonder how well a theory that dropped all talk of degrees of truth and just took this connective \\(≥_T\\) as primitive could avoid Keefe’s objections. Indeed, at the equivalent point in his discussion in Vagueness, Timothy Williamson considers some arguments against just this position, but his discussion is rather brief. One can’t reply to every possible response, but this one seemed so apposite, I would have liked to see Keefe’s response to it.\nKeefe holds that a sentence is true iff it is true on all admissible precisifications, i.e. that truth is supertruth. She says little about what makes a precisification acceptable, except that it must respect penumbral connections, and that admissibility is a vague matter. One consequence of this is that schema (T): S is true iff S is not always true. Keefe suggests that the standard arguments for (T) are circular, because they assume that there are no truth-value gaps. And, following van Fraassen, she notes something similar to (T) is true, and this is good enough.\nShe holds that an argument is valid iff it preserves truth, i.e. supertruth. Hence we have S \\(\\dashv \\vdash\\) S is true.This interderivability might explain why we, mistakenly, think (T) is true. There is a familiar problem with this move, one stressed by Williamson. On all precisifications, all theorems of classical logic are true, so these all end up being true. So to that extent supervaluationism preserves classical logic. But not all admissible inference rules of classical logic preserve supertruth. In particular, the deduction theorem is no longer admissible. We can’t infer (2) from (1):\n\nS \\(\\vdash\\) S is true.\n\\(\\vdash\\) S ⊃ S is true.\n\nKeefe responds by noting that something similar to the deduction theorem is true, and this might explain our mistaken attachment to it. Keefe assumes the language contains an operator D, read ‘definitely’, such that DA means A is supertrue. Then the following rule is admissible:\n\n⊃I*\n\nFrom A,B \\(\\vdash\\) C, infer B \\(\\vdash\\) DA ⊃ C\n\n\nWe think the standard ⊃ introduction rule, the deduction theorem, is acceptable because we mistake it for this one. Keefe notes we can set out similar kinds of rules for argument by cases (∨-elimination) and reductio ad absurdum (¬-introduction). These are intended to be small deviations from classical logic, but they strip the proof theory of much of its power. Keefe’s rules are insufficient to prove p ⊃ r \\(\\vdash\\) (p ∧ q) ⊃ r, or p ⊃ p. One might question the value of inference rules with such little power.\nThere is little on the specific problems associated with the problem of the many for supervaluationism. Stephen Schiffer1 recently proposed a variant on the problem, suggesting that the standard supervaluational solution misclassifies some speech reports. Keefe replies that Schiffer’s argument doesn’t seem to go through if we adopt Davidson’s paratactic theory of speech reports. Well, maybe it doesn’t, but if supervaluationism requires the paratactic theory of speech reports, that seems highly relevant to its ultimate success, but Keefe merely assigns it a footnote.\n1 “Two Issues of Vagueness” Monist 81: 193-214.There is a little more on the most obvious difficulty for supervaluationism, that it verifies some strange existentials. Consider a Sorites series of objects arranged with respect to F-ness, each a little more F than its predecessor, with the extremes being clearly F and not-F respectively. Then the sentence There is a pair of adjacent objects such that one is F and the other is not is supertrue. Keefe notes that we can distinguish here between the truth of the existential and the truth of an instance. And she notes that pragmatic theories due to Fine and Tappenden might explain our unwillingness to assert the existential, even if it is true. Still, it is would have been nice to see some discussion on whether this is a particular problem when F is a phenomenal predicate, or when it is ‘ineradicably vague’, as Dummett and other think predicates like ‘sort of nearby’ are.\nThe major innovation in the book is its treatment of higher-order vagueness. Keefe notes the following argument raises a serious difficulty for supervaluationism here\n\nAccording to the theory, a sentence is true simpliciter iff it is true on all complete and admissible specifications [i.e. on all precisifications]. But for any sentence, either it is true on all complete and admissible specifications (hence true simpliciter) or not (hence borderline or false). So there is no scope for avoiding sharp boundaries to the borderline cases or for accommodating borderline borderline cases. (202)\n\nKeefe’s response is to claim that the argument assumes, falsely, that there is “a precise and unique set of complete and admissible specifications.” (202) Keefe denies this and instead develops a theory of higher-order vagueness based on supervaluating the concept of admissibility. But it is not clear where the argument does assume this. After all, the argument makes no mention of sets. And it is a little unclear just why this assumption should be false. Keefe argues that there is no such set because complete and admissible specification is vague, just as there is no precise and unique set of tall things because tall is vague. But even though complete and admissible specification is vague, on every precisification there is still a unique set of complete and admissible specifications, so it is true that there is such a set, so there is one. (Keefe accepts the S is true therefore S direction of (T).)\nIt is also unclear how the vagueness of the term complete and admissible specification is relevant. The supervaluational idea was that a sentence is true iff it is true on all specifications (precisifications) that are complete and admissible, not iff it is true on all specifications satisfying the term complete and admissible. It is a use/mention confusion to hold the latter view. But if the former is correct, the vagueness of any term, even ‘admissible’, is irrelevant to the above argument. So there still seems to be work to do on higher-order vagueness.\nI’ve focussed on the negatives here, but this shouldn’t overshadow how many good parts this book has. The coverage of the literature is peerless, the writing is always crisp and clear, and in many places Keefe’s arguments move the debate in interesting new directions. It would be a great book to teach from, and indeed I would already be doing so, if only it were available in paperback. I do hope the publishers correct this problem shortly."
  },
  {
    "objectID": "posts/epvn/epistemicism-parasites-and-vague-names.html",
    "href": "posts/epvn/epistemicism-parasites-and-vague-names.html",
    "title": "Epistemicism, Parasites, and Vague Names",
    "section": "",
    "text": "Why is it so implausible that there is a sharp boundary between the rich and the non-rich? Perhaps we find it implausible merely because we (implicitly) believe that if there were such a boundary we would be able to discover where it is. If this is so we should revise our judgements. As Timothy Williamson (1994, 2000) has shown, if there were such a boundary we would not know where it is. Still, this is not the only reason for being sceptical about the existence of such a boundary. In “Vagueness, Epistemicism and Response-Dependence” John Burgess (2001) outlines an impressive objection to the existence of such boundaries, and in particular to epistemicist theories that posit their existence. Burgess’s objection is based not on principles about the epistemology of content, as the bad objection just stated is, but rather on principles about the metaphysics of content.\n\nPublished in Australasian Journal of Philosophy 81: 276-279.\nPicture by Pacific Klaus via Creative Commons.\n\nIf a word t has content c, this must be the case in virtue of some more primitive fact obtaining. Facts about content, such as this, are not among the fundamental constituents of reality. Roughly, facts about linguistic content must obtain in virtue of facts about use. But there are simply not enough facts about use to determine a precise meaning for paradigmatically vague terms like ‘rich’. Any theory that holds that ‘rich’ does have a precise meaning must meet this objection. As Burgess argues, Williamson’s attempts to do this have not been entirely successful. Burgess argues, persuasively, that epistemicists owe us a theory of how terms like ‘rich’ get to have the precise meaning they apparently have given that the facts about use do not seem to generate a precise meaning. He also argues, less persuasively, that Williamson’s ‘parasitic’ strategy for meeting this obligation is unsuccessful. Indeed, the argument here rests at one point on a premiss that is clearly false. I will suggest a way to patch the argument and reinstate the objection to epistemicism.\nThe obligation to provide a theory that generates content in terms of use does not just fall on the epistemicists. We indeterminists about content must also discharge it. Assume that we have done so, and we have a theory of content that divides sentences into (at least) the true, the false and the indeterminate. (Williamson 1994, 207–8) argues that the only reason we believe that any sentences fall into this third category is that we are respecting a mythical symmetry between truth and falsity. We are falling into the trap of thinking that if a sentence is not somehow made false, it is not false. The true story is that if an assertoric sentence has content, and it is not made true, it isfalse. This provides the basis for Williamson’s ‘parasitic’ strategy: wait for the indeterminist to offer a theory of when sentences are true, accept that part of the indeterminist theory, and say all other sentences that express propositions are false. If the strategy works, then there is no way the indeterminist can meet the obligation to provide a theory of content without the epistemicist also being able to do so, so there is no argument for indeterminism here. (There are complications, to put it mildly, with this strategy when the indeterminist allows the border between the true and the indeterminate to be vague. Burgess lets these potential problems slide, and so shall I.)\nThe strategy rests on the purported asymmetry between truth and falsity. Burgess claims that positing such an asymmetry makes epistemicism inconsistent. Consider a colour patch that is around the border between red and orange. Burgess claims, correctly, that an indeterminist theory of content may say that (1) and (2) are indeterminate, and hence Williamson might be committed to the position that (1) and (2) are false, and hence so is (3).\n\nThat patch is red.\nThat patch is orange.\nThat patch is either red or orange.\n\nBut this is hopeless because “on the epistemicist view, there is a sharp boundary in the series between red and orange; every patch is either one or the other.” (Burgess 2001, 519) This last claim is false. According to epistemicism, there is a sharp boundary between red and not red, so the patch is either red or not red. But the epistemicist need not hold that if the patch is not red, then it is orange. It is consistent with epistemicism that there are colours strictly between red and orange, just as it is consistent with epistemicism that there are colours strictly between red and yellow, and just as it is consistent with epistemicism that there are colours strictly between red and blue. Hence it is possible that the colour of this patch is strictly between red and orange, and thus is neither red nor orange. So this line of reasoning does not work. Perhaps the argument can be easily fixed. According to the indeterminist, both (1) and (4) are indeterminate. Hence according to Williamson’s ‘parasitic’ theory of content, both (1) and (4) are false, so (5) is false.\n\nThat patch is red.\nThat patch is not red.\nThat patch is either red or not red.\n\nThis is more like a problem, because Williamson certainly is committed to the truth of (5). However, it is easy to see how Williamson should respond. The theory of content sketched above (or more precisely, the strategy for converting indeterminist theories to determinist ones) was only meant to apply to simple sentences. A simple sentence is true iff the indeterminist says it is true. The truth value of compound sentences, like (4) and (5), is given by a standard Davidsonian theory of truth. Hence (1) is false and (4) is true, as required.\nThe best way to resurrect Burgess’s argument is to shift our attention from vague predicates to vague names. Consider any mountain, say Kilimanjaro. It is vague just where the mountain starts, so it will be vague just which atoms constitute Kilimanjaro. Kilimanjaro is some fusion of atoms or other, but it is indeterminate just which one it is. Some of these fusions have different masses, and some have different shapes, so no sentence of the form of (6) or of (7) will be true according to the indeterminist.\n\nKilimanjaro has shape s.\nKilimanjaro has mass m.\n\nHence according to the Williamson’s asymmetric theory of truth, any sentence of either of these forms is false. Note that this holds even if we restrict the application of his theory to simple sentences. Now let K be a set of fusions of atoms {f1, f2, …, fn} such that it is determinate that Kilimanjaro is one of these fusions. (Because of higher-order vagueness it may be impossible to find such a set that does not contain any fusion that is determinately not Kilimanjaro. That will not matter; all that we require is that Kilimanjaro is one of these fusions.) Let si be the shape of fi and mi its mass. Then for all i, (6.i) and (7.i) are false, as we just argued.\n\n\nKilimanjaro has shape si.\n\n\nKilimanjaro has mass mi.\n\n\nHence both (8) and (9) are false.\n\nKilimanjaro has shape s1 or Kilimanjaro has shape s2 or … or Kilimanjaro has shape sn.\nKilimanjaro has mass m1 or Kilimanjaro has mass m2 or … or Kilimanjaro has mass mn.\n\nAnd the epistemicist is committed to (8) and (9) being true. We may not be able to discover which disjunct is true, but that is no reason to think that the disjunction is not true. Burgess’s argument was that if we adopt Williamson’s advice for constructing a theory of content, we will misclassify sentences that express penumbral connections. He was basically right, but we need to use a different example to prove it.\nI assumed above that Kilimanjaro is a fusion of atoms. Some may object to this on the grounds that Kilimanjaro has different temporal and modal properties to any fusion of atoms. I doubt such objections ultimately work, but for present purposes the important thing to note is that the argument can go through without such an assumption. Even if Kilimanjaro is not identical to any fusion in K, it is clear that Kilimanjaro (actually, now) exactly overlaps some member of K. And since Kilimanjaro has the same (actual, present) shape and mass as any fusion of atoms it exactly overlaps, it still follows that (8) and (9) are true.\nIf we do assume that Kilimanjaro is one of the fusions, then we can generate another case where Williamson’s theory generates false predictions. Since at most one of the fusions is a mountain, it follows that (10.i) is indeterminate for all i on an indeterminist theory of content, and hence false according to Williamson.\n\n\nfi is a mountain.\n\n\nHence his theory mistakenly predicts that (11) is false, when it is by hypothesis true.\n\nf1 is a mountain or f2 is a mountain or … or fn is a mountain.\n\nThis argument does rest on a contentious bit of metaphysics, but it still seems basically sound.\nI did not assume at any point that Kilimanjaro is a vague object. I did assume that ‘Kilimanjaro’ is a vague name, but it is consistent with the argument I have presented that there are no vague objects, and the vagueness in ‘Kilimanjaro’ consists in it being indeterminate which precise object it denotes.\nAs Burgess demonstrates, it is fair to require that the epistemicist provide a theory of how terms get the precise content they do. Williamson attempted to show he was in just as good a position to discharge this obligation as the indeterminist by providing an algorithm for converting any indeterminist theory of content into one acceptable to the epistemicist. Burgess argued that the algorithm produced unacceptable results when we applied it to vague sentences such as (1) and (2). This particular argument is no good; the algorithm does not seem to produce implausible results in that case. We can make this form of argument work, however, especially if we focus on vague names. Applying the algorithm to any plausible indeterminist theory produces the result that every disjunct in (8) and (9) are false, and hence that these disjunctions are false. Since the epistemicist is (correctly) committed to these sentences being true, Burgess was correct to conclude that “this particular attempt to implement the parasite strategy is doomed to failure.”\n\n\n\n\nReferences\n\nBurgess, John. 2001. “Vagueness, Epistemicism and Response-Dependence.” Australasian Journal of Philosophy 79 (4): 507–24. https://doi.org/10.1080/713659306.\n\n\nWilliamson, Timothy. 1994. Vagueness. Routledge.\n\n\n———. 2000. Knowledge and its Limits. Oxford University Press."
  },
  {
    "objectID": "posts/imps/accuracy-and-the-imps.html",
    "href": "posts/imps/accuracy-and-the-imps.html",
    "title": "Accuracy and the Imps",
    "section": "",
    "text": "1 Accuracy, Bribes and Scoring Rules\nBelief aims at the truth. So at least in some sense, an agent is doing better at believing the closer they are to the truth. When applied to individual beliefs, this generates epistemic advice that is literally platitudinous: if you know that a change in your attitude towards p will make your attitude towards p more accurate, make that change! When applied to collective bodies of belief though, the advice turns out to be more contentious. Call epistemic consequentialism the view that if an agent knows that a change in their overall belief state will make their belief state more accurate, they should make that change, if they have the power to do so.\n\nThanks to Alejandro Pérez Carballo, Richard Pettigrew, and the participants in the Arché Epistemology Seminar for helpful comments.\nImage by tanakawho via Creative Commons.\n\nHilary Greaves (2013) has recently argued that epistemic consequentialism is false because it licences certain epistemic ‘bribes’, and these should not be licenced. We’ll argue that the best forms of epistemic consequentialism do not licence some of these bribes after all.1 Here is the key case Greaves uses.2\n1 Though they do licence others; see section 2.4 for more discussion.2 Greaves has four other cases, but the Imps case is the only one that is a problem for all forms of consequentialism she discusses. Similar cases have suggested by Selim (Berker 2013a, 2013b) and C. S. Jenkins (2007), but we’ll focus on Greaves’s discussion since she engages more fully with the literature on scoring rules. We’ll return briefly to Berker’s discussion in section 2.\nEmily is taking a walk through the Garden of Epistemic Imps. A child plays on the grass in front of her. In a nearby summerhouse are \\(n\\) further children, each of whom may or may not come out to play in a minute. They are able to read Emily’s mind, and their algorithm for deciding whether to play outdoors is as follows. If she forms degree of belief 0 that there is now a child before her, they will come out to play. If she forms degree of belief 1 that there is a child before her, they will roll a fair die, and come out to play iff the outcome is an even number. More generally, the summerhouse children will play with chance \\((1-\\frac{q(C_0)}{2})\\), where \\(q(C_0)\\) is the degree of belief Emily adopts in the proposition \\(C_0\\) that there is now a child before her. Emily’s epistemic decision is the choice of credences in the proposition \\(C_0\\) that there is now a child before her, and, for each \\(j = 1, \\ldots, n\\) the proposition \\(C_j\\) that the jth summerhouse child will be outdoors in a few minutes’ time.\n\n\n\\(\\ldots\\) if Emily can just persuade herself to ignore her evidence for \\(C_0\\), and adopt (at the other extreme) credence 0 in \\(C_0\\), then, by adopting degree of belief 1 in each \\(C_{j} (j = 1, ... , 10)\\), she can guarantee a perfect match to the remaining truths. Is it epistemically rational to accept this ‘epistemic bribe’? Greaves (2013, 918)\n\nThe epistemic consequentialist says that it is best to have credences that are as accurate as possible. We will focus on believers who assign probabilistically coherent credences (degrees of belief) to the propositions in some “target set” \\(\\mathscr{X}\\), and we will think of the “degree of fit” between her beliefs and the truth as being measured by a strictly proper scoring rule. This is a function \\(\\mathbf{I}_{\\mathscr{X}}\\) which associates each pair \\(\\langle \\mathbf{cred}, @ \\rangle\\) consisting of a credence function \\(\\mathbf{cred}\\) whose domain includes \\(\\mathscr{X}\\) and a consistent truth-value assignment @ for elements of \\(\\mathscr{X}\\) with a non-negative real number \\(\\mathbf{I}_{\\mathscr{X}}(@, \\mathbf{cred})\\). Intuitively, \\(\\mathbf{I}_{\\mathscr{X}}\\) measures the inaccuracy of the credences that cred assigns to the propositions in \\(\\mathscr{X}\\) when their truth-values are as described by @. Note that higher \\(\\mathbf{I}_{\\mathscr{X}}\\)-values indicate higher levels of epistemic disutility, so that lower is better from a consequentialist perspective. One popular scoring rule is the Brier score, which identifies inaccuracy with the average squared distance between credences and truth-values. (Greaves calls this the ‘quadratic scoring rule’, which is a useful description too.) More formally, we have:\n\\[\\mathbf{Brier}_{\\mathscr{X}}(@, \\mathbf{cred}) = \\frac{1}{|\\mathscr{X}|}\\sum_{X \\in \\mathscr{X}} (\\mathbf{cred}(X) - @(X))^2\\] where \\(|\\mathscr{X}|\\) is the number of propositions in \\(\\mathscr{X}\\) and \\(@(X)\\) is either zero or one depending upon whether X is true or false.\nAnother common score is the logarithmic rule, which defines inaccuracy as:\n\\[\\mathbf{Log}_{\\mathscr{X}}(@, \\mathbf{cred}) = \\frac{1}{|\\mathscr{X}|}\\sum_{X \\in \\mathscr{X}} -\\text{log}(\\mathbf{cred}(X)) \\cdot @(X)\\] For now we will follow Greaves in assuming that our epistemic consequentialist uses the Brier score to measure epistemic disutility, but we will relax that assumption in a little while.\nNow let’s think about the ‘bribe’ that Greaves offers, from the point of view of the epistemic consequentialist. The choices are to have one of two credal states, which we’ll call cred1 and cred2. We’ll say cred1 is the one that best tracks the initial evidence, so \\(\\mathbf{cred1}(C_0) = 1\\), and \\(\\mathbf{cred1}(C_i) = 0.5\\) for \\(i \\in {1, ..., 10}\\). And cred2 is the credence Emily adopts if she accepts the bribe, so \\(\\mathbf{cred2}(C_0) = 0\\), while \\(\\mathbf{cred2}(C_i) = 1\\) for \\(i \\in {1, ..., 10}\\). Which state is better?\nThinking like an epistemic consequentialist, you might ask which state is more accurate? It seems like that would be cred2. While cred1 gets \\(C_0\\) exactly right it does not do very well on the other propositions. In contrast, while cred2 gets \\(C_0\\) exactly wrong, it is perfect on the other ten propositions. So overall, cred2 looks to have better epistemic consequences: when compared to being right about one proposition and off by 0.5 on ten others, being right on ten is surely worth one false belief. The Brier score seems to bear this out. If we let \\(\\mathscr{X}\\), the target set, consist of \\(C_0, C_1, ..., C_{10}\\), then we have \\[\\begin{aligned}\n\\mathbf{Brier}_\\mathscr{X}(\\mathbf{cred1}, @) &= \\frac{1}{11}[(1-\\mathbf{cred1}(C_0))^2 + \\sum_{i = 1}^{10} (@(C_i) - \\frac{1}{2}) ^2] = \\frac{10}{44} \\\\\n\\mathbf{Brier}_\\mathscr{X}(\\mathbf{cred2}, @) &= \\frac{1}{11}[(1-\\mathbf{cred2}(C_0))^2 + \\sum_{i = 1}^{10} (@(C_i) - cred(C_i)) ^2] = \\frac{1}{11} \\end{aligned}\\] So, it seems that a good epistemic consequentialist will take the bribe. But, doesn’t that seem like the height of epistemic irresponsibility? It means choosing to believe that \\(C_0\\) is certainly false when you have conclusive evidence for thinking that it is true. If you see the child on the lawn in front of you, how can you sanction believing she is not there?\nAs Greaves admits, intuitions are divided here. Some consequentialists might think that “epistemic bribes” are at least sometimes worth taking, while those of a more deontological bent will always find such trade-offs “beyond the pale”  (Berker 2013a, 363). We will largely sidestep these contentious issues here, though our argument will offer comfort to epistemic consequentialists who feel queasy about accepting the bribe offered in Imps. We contend that, when inaccuracy is measured properly, the consequences of adopting the cred2 credences are strictly worse than the consequences of adopting cred1.\nThe basic problem is that Imps cherry-picks propositions in a way no consequentialist should condone. Its persuasive force rests on the assumption that, for purposes of epistemic evaluation, nothing matters except the accuracies of the credences assigned to propositions in the target set \\(\\mathscr{X}\\). But \\(\\mathscr{X}\\) is the wrong target! By confining attention to it Greaves ignores the many other credences to which Emily becomes committed as a consequence of adopting cred1 or cred2. Any (coherent) agent who invests credence zero in \\(C_0\\) must also invest credence zero in any proposition \\(C_0 \\wedge Y\\), where \\(Y\\) is any conjunction or disjunction of elements from \\(\\mathscr{X}\\). Likewise, anyone who invests credence one in \\(C_n\\) must invest credence one in any proposition \\(C_n \\vee Y\\), where \\(Y\\) is any conjunction or disjunction from \\(\\mathscr{X}\\). In the current context (where the probabilities of the various \\(C_i\\) are independent), when Emily adopts a credence function over \\(\\mathscr{X}\\) she commits to having a credence for (i) every atomic proposition ±\\(C_0 \\wedge\\)± \\(C_1 \\wedge\\)±\\(C_2 \\wedge \\ldots \\wedge\\)±\\(C_{10}\\), where ‘±’ can be either an affirmation or a negation, and (ii) every disjunction of these atomic propositions. In short, she commits to having credences over the whole Boolean algebra \\(\\mathscr{A}_\\mathscr{X}\\) generated by \\(\\mathscr{X}\\). Since each event of a child coming out is independent, adopting cred1 will commit her to setting cred1(±\\(C_0 \\wedge\\)± \\(C_1 \\wedge\\)±\\(C_2 \\wedge \\ldots \\wedge\\)±\\(C_{10}) = \\frac{1}{1024}\\) when \\(C_0\\) is affirmed, and 0 when it is negated. While adopting cred2 commits her to setting cred2(±\\(C_0 \\wedge\\)± \\(C_1 \\wedge\\)±\\(C_2 \\wedge \\ldots \\wedge\\)±\\(C_{10}\\)) equal to 1 when \\(C_0\\) is negated and the rest of the \\(C_i\\) are affirmed, and to 0 otherwise. In this way, each of these probability assignments over the 2048 atoms determine a definite probability for every one of the \\(2^{2048}\\) propositions in \\(\\mathscr{A}_\\mathscr{X}\\).\nIt is our view that consequentialists should reject any assessment of epistemic utility that fails to take the accuracies of all these credences into account. All are consequences of adopting cred1 or cred2, and so all should be part of any consequentialist evaluation of the quality of those credal states. The right “target set” to use when computing epistemic disutility is not \\(\\mathscr{X}\\) but \\(\\mathscr{A}_\\mathscr{X}\\). If we don’t do that, we ignore most of the ways in which cred1 and cred2 differ in accuracy. If Emily takes the bribe, she goes from having credence 0.5 in \\(C_0 \\leftrightarrow C_1\\) to having credence 0 in it. And that’s unfortunate, because the chance of \\(C_0 \\leftrightarrow C_1\\) goes from 0.5 to 1. This is another proposition, as well as \\(C_0\\), that Emily acquires a false belief in by taking the bribe. Of course, there are other propositions not counted that go the other way. Originally, Emily has a credence of 0.25 in \\(C_1 \\wedge C_2\\), and its chance is also 0.25. After taking the bribe, this has a chance of 1, and her credence in it is 1. That’s an improvement in accuracy. So there are a host of both improvements and deteriorations that are as yet unaccounted for. We should account for them, and making the target set be \\(\\mathscr{A}_\\mathscr{X}\\) does that.\nWhen seen from this broader perspective, it turns out the seeming superiority of cred2 over cred1 evaporates. The rest of this section (and the appendix) is dedicated to demonstrating this. We’ll make the calculations a little easier on ourselves by relying on a theorem concerning Brier scores for coherent agents. Assume, as is the case here, that Emily’s credences are defined over an atomic Boolean alegbra of propositions. The atoms are the ‘worlds’, or states that are maximially specific with respect to the puzzle at hand. In this case there are 2048 states, which we’ll label \\(s_0\\) through \\(s_{2047}\\). In \\(s_k\\), the first child is on the lawn iff \\(k \\leq 1023\\), and summerhouse child \\(i\\) comes out iff the (\\(i\\) + 1)th digit in the binary expansion of \\(k\\) is 1. Let \\(\\mathscr{S}_\\mathscr{X}\\) be the set of all these states. That’s not a terrible target set; as long as Emily is probabilistically coherent it is comprehensive. The theorem in question says that for any credence function cred defined over a partition of states \\(\\mathscr{S}\\), and over the algebra \\(\\mathscr{A}\\) generated by those states,\n\nTheorem-1 \\[\\mathbf{Brier}_{\\mathscr{A}}(\\mathbf{cred}, @) = \\frac{|\\mathscr{S}|}{4}\\mathbf{Brier}_{\\mathscr{S}}(\\mathbf{cred}, @)\\]\n\n(The proof of this is in the appendix.) So whichever credence function is more accurate with respect to \\(\\mathscr{S}_{\\mathscr{X}}\\) will be more accurate with respect to \\(\\mathscr{A}_{\\mathscr{X}}\\). So let’s just work out \\(\\mathbf{Brier}_{\\mathscr{S}_{\\mathscr{X}}}\\) for cred1 and cred2 at the actual world.\nFirst, cred1 will appropriately assign credence 0 to each \\(s_k (k \\in {0, ..., 1023})\\). Then it assigns credence \\(\\frac{1}{1024}\\) to every other \\(s_k\\). For 1023 of these, that is off by \\(\\frac{1}{1024}\\), contributing \\(\\frac{1}{2^{20}}\\) to the Brier score. And for 1 of them, namely @, it is off by \\(\\frac{1023}{1024}\\), contributing \\(\\frac{1023^2}{2^{20}}\\). So we get: \\[\\begin{aligned}\n\\mathbf{Brier}_{\\mathscr{S}_{\\mathscr{X}}}(\\mathbf{cred1}, @) &= \\frac{1}{2048} [1024 \\cdot 0 + 1023 \\cdot \\frac{1}{2^{20}} + \\frac{1023^2}{2^{20}}] \\\\\n&= \\frac{1}{2048} \\cdot \\frac{1023 + 1023 ^2}{2^{20}} \\\\\n&= \\frac{1}{2048} \\cdot \\frac{1023 \\cdot 1024}{2^{20}} \\\\\n&= \\frac{1}{2048} \\cdot \\frac{1023}{1024} \\\\\n&= \\frac{2^{10}-1}{2^{21}}\\end{aligned}\\] It’s a bit easier to work out \\(\\mathbf{Brier}_{\\mathscr{S}_{\\mathscr{X}}}(\\mathbf{cred2}, s_{2047})\\). (We only need to work out the Brier score for that state, because by the setup of the problem, Emily knows that’s the state she’ll be in if she adopts cred2). There are 2048 elements in \\(\\mathscr{S}_{\\mathscr{X}}\\). And cred2 assigns the perfectly accurate credence to 2046 of them, and is perfectly inaccurate on 2, namely \\(s_{1023}\\), which it assigns credence 1, and \\(s_{2047}\\) which it assigns credence 0. So we have \\[\\begin{aligned}\n\\mathbf{Brier}_{\\mathscr{S}_{\\mathscr{X}}}(\\mathbf{cred2}, s_{2047}) &= \\frac{1}{2048} (2046 \\cdot 0 + 1 + 1) \\\\\n&= \\frac{1}{1024} \\\\\n&= \\frac{2^{11}}{2^{21}}\\end{aligned}\\] In fact, it isn’t even close. If Emily adopts cred2 she becomes a little more than twice as inaccurate.\nIt is tedious to calculate \\(\\mathbf{Brier}_{\\mathscr{A}_{\\mathscr{X}}}(\\mathbf{cred1}, @)\\) directly, but it is enlightening to work through the calculation of \\(\\mathbf{Brier}_{\\mathscr{A}_{\\mathscr{X}}}(\\mathbf{cred2}, s_{2047})\\). Note that there are two crucial states out of the 2048: \\(s_{2047}\\), the actual state where all children come out, and state \\(s_{1023}\\) where child 0 does not come out, but the other 10 children all do. There are \\(2^{2^{11}-2}\\) propositions in each of the following four sets:\n\n\\(\\{p: s_{2047} \\vDash p\\) and \\(s_{1023} \\vDash p\\}\\)\n\\(\\{p: s_{2047} \\vDash p\\) and \\(s_{1023} \\nvDash p\\}\\)\n\\(\\{p: s_{2047} \\nvDash p\\) and \\(s_{1023} \\vDash p\\}\\)\n\\(\\{p: s_{2047} \\nvDash p\\) and \\(s_{1023} \\nvDash p\\}\\)\n\nIf Emily takes the bribe, she will have perfect accuracy with respect to all the propositions in class 1 (which are correctly believed to be true), and all the propositions in class 4 (which are correctly believed to be false). But she will be perfectly inaccurate with respect to all the propositions in class 2 (which are incorrectly believed to be false), and all the propositions in class 3 (which are incorrectly believed to be true). So she is perfectly accurate on half the propositions, and perfectly inaccurate on half of them, so one’s average inaccuracy is \\(0.5 \\cdot 0 + 0.5 \\cdot 1 = 0.5\\). And that’s an enormous inaccuracy. It is, in fact, as inaccurate as one can possibly be while maintaining probabilistic coherence.\n\nTheorem-2: When inaccuracy over \\(\\mathscr{A}\\) is measured using the Brier score, the least accurate credal states are those which assign credence 1 to some false atom of \\(\\mathscr{A}\\).\n\n(The proof is in the appendix.) So taking the bribe is not a good deal, even by consequentialist lights. And that isn’t too surprising; taking the bribe makes Emily have maximally inaccurate credences on half of the possible propositions about the children.\nSo far we have followed Greaves in assuming that inaccuracy is measured by the quadratic, or Brier, rule. It turns out that we can drop that assumption. We actually only need some very weak conditions on accuracy rules to get the result that Greaves style bribes are bad deals, though the proof of this becomes a trifle more complicated.\nLet \\(\\mathscr{A}\\) be an algebra of propositions generated by a partition of \\(2N\\) atoms \\(a_1, ..., a_{2N}\\). Suppose \\(a_1\\) is the truth, and consider two probability functions, \\(P\\) and \\(Q\\) defined in \\(\\mathscr{A}\\). \\(P\\) assigns all its mass to the first \\(N\\) atoms, so that \\(P(a_k) = 0\\) for all \\(k &gt; N\\). We also assume that \\(P\\) assigns some positive probability to the true atom \\(a_1\\). \\(Q\\) assigns all its mass to the false atom \\(a_{2N}\\). Note that this will be a good model of any case where an agent is offered a bribe of the form: drop the positive confidence you have in proposition \\(p_0\\), instead assign it credence 0, and you’ll be guaranteed a maximally accurate credence in \\(j\\) other logically independent propositions \\(p_1, ..., p_j\\). The only other assumptions needed to get the model to work are that \\(p_0\\) is actually true, and \\(N = 2^j\\).\nImagine that the accuracy of a probability function \\(\\pi\\) over \\(\\mathscr{A}\\) is measured by a proper scoring rule of the form\n\\[\\mathbf{I}(a_n, \\pi) = 2^{-2N}\\sum_{X \\in \\mathscr{A}} \\mathbf{i}(v_n(X), \\pi(X))\\] where \\(v_n(X)\\) is \\(X\\)s truth value when \\(a_n\\) is the true atom, and i is a score that gives the accuracy of \\(\\pi(X)\\) in the event that \\(X\\)s truth value is \\(v_n(X)\\). We shall assume that this score has the following properties.\n\nTruth Directedness\n\nThe value of \\(\\mathbf{i}(1, p)\\) decreases monotonically as \\(p\\) increases. The value of \\(\\mathbf{i}(0, p)\\) increases monotonically as \\(p\\) decreases.\n\nExtensionality\n\n\\(\\mathbf{i}(v_n(X), \\pi(X))\\) is a function only of the truth-value and the probability; the identity of the proposition does not matter.\n\nNegation Symmetry\n\n\\(\\mathbf{i}(v_n(\\neg X), \\pi(\\neg X)) = \\mathbf{i}(v_n(X), \\pi(X))\\) for all \\(x, n, \\pi\\).\n\n\n\nTheorem-3: Given these assumptions, \\(P\\)’s accuracy strictly exceeds \\(Q\\)’s.\n\nAgain, the proof is in the appendix.\nTheorem-3 ensures that taking the deal that Greaves offers in Imps will reduce Emily’s accuracy relative to any proper scoring rule satisfying Truth Directedness, Extensionality and Negation Symmetry. To see why, think of Emily’s credences as being defined over an algebra generated by the atoms ±\\(C_0 \\wedge\\)± \\(C_1 \\wedge\\)±\\(C_2 \\wedge \\ldots \\wedge\\)±\\(C_{10}\\), where it is understood that some \\(C_0\\) atom is true and all the \\(\\neg C_0\\) atoms are false. Since Emily is convinced of \\(C_0\\) and believes that every other \\(C_n\\) has some chance of occurring, and since the various \\(C_n\\) are independent of one another, her credence function cred1 will assigns a positive probability to each \\(C_0\\) atom, including the true atom (whichever that might be). Now, let \\(Q\\) be a credence function that places all its weight on some false atom \\(\\neg C_0 \\wedge\\)± \\(C_1 \\wedge\\)±\\(C_2 \\wedge \\ldots \\wedge\\)±\\(C_{10}\\). Theorem-3 tells us that Emily’s cred1 is more accurate than \\(Q\\), and that this is true no matter which \\(C_0\\) atom is true or which \\(\\neg C_0\\) atom \\(Q\\) regards as certain. By taking the bribe Emily will guarantee the truth of \\(C_0 \\wedge C_1 \\wedge \\dots \\wedge C_{10}\\), but the cost will be that she must adopt the cred2 credences, which assign probability one to the false atom \\(\\neg C_0 \\wedge C_1 \\wedge \\dots \\wedge C_{10}\\). Extensionality ensures that any two credence functions that assign probability one to a false atom will have the same inaccuracy score, and that this score will not depend on which atom happens to be the true one. The upshot is that cred2 will have the same inaccuracy when Emily accepts the bribe as \\(Q\\) does when she rejects it. Thus, since cred1 is more accurate than \\(Q\\), it is also more accurate than cred2, which means that Emily should reject the bribe in order to promote credal accuracy.\nWe do not want to oversell this conclusion. Strictly speaking, we have only shown that consequentialists should reject epistemic bribes when doing so requires them to go from being confident in a truth to being certain of some maximally specific falsehood. This is a rather special situation, and there are nearby cases to which our results do not apply, and in which consequentialists may sanction bribe-taking. For example, if Emily only has to cut her credence for \\(C_0\\) in half, say from \\(\\frac{1}{2}\\) to \\(\\frac{1}{4}\\), to secure knowledge of \\(C_1 \\wedge \\dots \\wedge C_{10}\\), then Theorem-3 offers us no useful advice. Indeed, depending on the scoring rule and the nature of the bribe, we suspect that believers will often be able to improve accuracy by changing their credences in ways not supported by their evidence, especially when these changes affect the truth-values of believed propositions. The only thing we insist upon is that, in all such cases, credal accuracy should be measured over all relevant propositions, not just over a select salient few. But that’s something that is independently plausible. Perhaps it might be pragmatically justified to become more accurate on salient propositions at the expense of becoming very inaccurate over hard to state compounds of those propositions, but it is never epistemically justified.\n\n\n2 Four Caveats\n\n2.0.1 Greaves’s Imps Argument May Work Against Some Forms of Consequentialism\nWe said above that no consequentialist should accept Greaves’s setup of the Imps puzzle, since they should not accept an inaccuracy measure that ignores some kind of introduced inaccuracy. That means that, for all we have said, Greaves’s argument works against those consequentialists who do not agree with us over the suitability of target sets that are neither algebras or partitions. And, at least outside philosophy, some theorists do seem to disagree with us.\nFor instance, it is common in meteorology to find theorists who measure the accuracy of rain forecasts over an \\(n\\) day period by just looking at the square of the distance between the probability of rain and the truth about rain on each day. To pick an example almost literally at random, Mark Roulston (2007) defends the use of the Brier score, calculated just this way, as a measure of forecast accuracy. So Greaves’s target, while not including all consequentialists, does include many real theorists.\nThat said, it seems there are more mundane reasons to not like this approach to measuring the accuracy of weather forecasts. Consider this simple case. Ankita and Bojan are issuing forecasts for the week that include probabilities of rain. They each think that there is a 0% chance of rain most days. But Ankita thinks there will be one short storm come through during the week, while Bojan issues a 0% chance of rain forecast for each day. Ankita thinks the storm is 75% likely to come on Wednesday, so there’s a 75% chance of rain that day, and 25% likely to come Thursday, so there’s a 25% chance of rain that day.\nAs it happens, the storm comes on Thursday. So over the course of the week, Bojan’s forecast is more accurate than Ankita’s. Bojan is perfectly accurate on 6 days, and off by 1 on Thursday. Ankita is perfectly accurate on 5 days, and gets an inaccuracy score of \\(0.75^2 = 0.5625\\) on Wednesday and Thursday, which adds up to more than Bojan’s inaccuracy. But this feels wrong. There is a crucial question that Ankita was right about and Bojan was wrong about, namely will there be a storm in the middle of the week. Ankita’s forecast only looks less accurate because we aren’t measuring accuracy with respect to this question. So even when we aren’t concerned with magical cases like Greaves’s, there is a good reason to measure accuracy comprehensively, i.e., with respect to an algebra or a partition.\n\n\n2.0.2 Separateness of Propositions\nThere is a stronger version of the intuition behind the Imps case that we simply reject. The intuition is well expressed by Selim Berker (2013a, 365, emphasis in original)\n\nThe more general point is this: when determining the epistemic status of a belief in a given proposition, it is epistemically irrelevant whether or not that belief conduces (either directly or indirectly) toward the promotion of true belief and the avoidance of false belief in other propositions beyond the one in question.\n\nLet’s put that to the test by developing the Ankita and Bojan story a little further. They have decided to include, in the next week’s forecast, a judgment on the credibility of rain. Bojan thinks the evidence is rather patchy. And he has been reading Glenn Shafer (1976), and thinks that when the evidence is patchy, credences in propositions and their negations need not add to 1. So if \\(p\\) is the proposition It will rain next week, Bojan has a credence of 0.4 in both \\(p\\) and \\(\\neg p\\).\nAnkita thinks that’s crazy, and suggests that there must be something deeply wrong with the Shafer-based theory that Bojan is using. But Bojan is able to easily show that the common arguments against Shafer’s theory are blatantly question begging  (Maher 1997; Weatherson 1999). So Ankita tries a new tack. She has been reading Joyce (1998), from which she got the following idea. She argues that Bojan will be better off from the point of view of accuracy in having credence 0.5 in each of \\(p\\) and \\(\\neg p\\) than in having credence 0.4 in each. As it stands, one of Bojan’s credences will be off by 0.4, and the other by 0.6, for a Brier score of \\((0.4^2 + 0.6^2)/2 = 0.26\\), whereas switching would give him a Brier score of \\((0.5^2 + 0.5^2)/2 = 0.25\\).\nBut Bojan resists. He offers two arguments in reply.\nFirst, he says, for all Ankita knows, one of his credences might be best responsive to the evidence. And it is wrong, always and everywhere, to change a credence away from one that is best supported by the evidence in order to facilitate an improvement in global accuracy. That, says Bojan, is a violation of the “separateness of propositions”  (Berker 2013a).\nSecond, he says, even by Ankita’s accuracy-based lights, this is a bad idea. After all, he will be making one of his credences less accurate in order to make an improvement in global accuracy. And that’s again a violation of the separateness of propositions. It’s true that he won’t be making himself more inaccurate in one respect so as to secure accuracy in another, as in the bribes case. But he will be following advice that is motivated by the aim of becoming, in total, more accurate, at the expense of accuracy for some beliefs.\nWe want to make two points in response. First, if the general point that Berker offers is correct, then these are perfectly sound replies by Bojan. Although Bojan is not literally in a bribe case, like Emily, he is being advised to change some credences because the change will make his overall credal state better, even if it makes it locally worse in one place. It does not seem to matter whether he can identify which credence gets made worse. Berker argues that the trade offs that epistemic consequentialism makes the same mistake ethical consequentialism makes; it authorises inappropriate trade-offs. But in the ethical case, it doesn’t matter whether the agent can identify who is harmed by the trade-off. If it is wrong to harm an identifiable person for the greater good, it is wrong to harm whoever satisfies some description in order to produce the greater good.\nSo if the analogy with anti-consequentialism in ethics goes through, Bojan is justified in rejecting Ankita’s advice. After all there is, according to Berker, a rule against making oneself doxastically worse in one spot for the gain of an overall improvement. And that’s what Bojan would do if he took Ankita’s advice. But, we say, Bojan is not justified in rejecting Ankita’s advice. In fact, Ankita’s advice is sound advice, and Bojan would do well to take it. So Berker’s general point is wrong.\nOur second point is a little more contentious. We suspect that if Bojan has a good reason to resist this move of Ankita’s, he has good reason to resist all attacks on his Shafer-based position. So if Berker’s general point is right, it means there is nothing wrong with Bojan’s anti-probabilist position. Now we haven’t argued for this; to do so would require going through all the arguments for probabilism and seeing whether they can be made consistent with Berker’s general point. But our suspicion is that none of them can be, since they are all arguments that turn on undesirable properties of global features of non-probabilistic credal states. So if Berker is right, probabilism is wrong, and we think it is not wrong.\n\n\n2.0.3 Is this Consequentialism?\nSo far we’ve acquiesed with the general idea that Greaves’s and Berker’s target should be called consequentialism. But there are reasons to be unhappy with this label. In general, a consequentialist theory allows agents to make things worse in the here and now, in return for future gains. A consequentialist about prudential decision making, in the sense of Hammond (1988), will recommend exercise and medicine taking. And they won’t be moved by the fact that the exercise hurts and the medicine is foul-tasting. It is worth sacrificing the welfare of the present self for the greater welfare of later selves.\nNothing like that is endorsed, as far as we can tell, by any of the existing ‘epistemic consequentialists’. Certainly the argument that Ankita offers Bojan does not rely on this kind of reasoning. In particular, epistemic consequentialists do not say that it is better to make oneself doxastically worse off now in exchange for greater goods later. Something like that deal is offered to the reader of Descartes (1641/1996), but it isn’t as popular nowadays.\nRather, the rule that is endorsed is Right now, have the credences that best track the truth! This isn’t clearly a form of consequentialism, since it really doesn’t care about the consequences of one’s beliefs. It does say that it is fine to make parts of one’s doxastic state worse in order to make the whole better. That’s what would happen if Bojan accepted Ankita’s advice. But that’s very different from doing painful exercise, or drinking unpleasant medicine. (Or, for that matter, to withdrawing belief in any number of truths.)\nWhen Greaves tries to flesh out epistemic consequentialism, she compares it to evidential and causal versions of prudential decision theory. But it seems like the right comparison might be to something we could call constitutive decision theory. The core rule, remember, is that agents should form credences that constitute being maximally accurate, not that cause them to be maximally accurate.\nThe key point here is not the terminological one about who should be called consequentialist. Rather, it is that the distinction between causation and constitution is very significant here, and comparing epistemic utility theory to prudential utility theory can easily cause it to be lost. Put another way, we have no interest in defending someone who wants to defend a causal version of epistemic utility theory, and hence thinks it could be epistemically rational to be deliberately inaccurate now in order to be much more accurate tomorrow. We do want to defend the view that overall accuracy right now is a prime epistemic goal.\n\n\n2.0.4 Other Bribes\nAs already noted, we have not offered a general purpose response to bribery based objections to epistemic consequentialism. All we’ve shown is that some popular examples of this form of objection misfire, because they offer bribes that are bad by the consequentialists’ own lights. But there could be bribes that are immune to our objection.\nFor example, imagine that Ankita has, right now, with credence 0.9 in \\(D_0\\), and 0.5 in \\(D_1\\). These are good credences to have, since she knows those are the chances of \\(D_0\\) and \\(D_1\\). She’s then offered an epistemic bribe. If she changes her credence in \\(D_0\\) to 0.91, the chance of \\(D_1\\) will become 1, and she can have credence 1 in \\(D_1\\). Taking this bribe will increase her accuracy.\nWe could imagine the anti-consequentialist arguing as follows.\n\nIf epistemic consequentialism is true, Ankita is epistemically justified in accepting this bribe.\nAnkita is not epistemically justified in accepting this bribe.\nSo, epistemic consequentialism is not true.\n\nWe’re not going to offer a reply to this argument here; that is a task for a much longer paper. There are some reasons to resist premise one. It isn’t clear that it is conceptually possible to accept the bribe. (It really isn’t clear that it is practically possible, but we’re not sure whether that’s a good reply on the part of the consequentialist.) And it isn’t clear that the argument for premise one properly respects the distinction between causation and constitution we described in the last section.\nEven if those arguments fail, the intuitive force of premise two is not as strong as the intuition behind Greaves’s, or Berker’s, anti-bribery intuitions. And that’s one of the main upshots of this paper. It’s commonly thought that for the consequentialist, in any field, everything has its price. The result we proved at the end of section one shows this isn’t true. It turns out that no good epistemic consequentialist should accept a bribe that leads them to believing an atomic proposition they have conclusive evidence is false, no matter how strong the inducements. Maybe one day there will be a convincing bribery based case that epistemic consequentialism is unacceptably corrupting of the epistemic soul. But that case hasn’t been made yet, because we’ve shown a limit on how corrupt the consequentialist can be.\n\n\n\nAppendix: Proofs of Theorems 1, 2, 3\n\nTheorem-1: Brier\\(_{\\mathscr{A}}(\\mathbf{c},@) = \\frac{N}{4}\\text{Brier}_{\\mathscr{S}}(\\mathbf{c},@)\\) where \\[\\begin{aligned}\n\\text{Brier}_{\\mathscr{S}}(\\mathbf{c},@) &= \\frac{\\sum_{s \\in \\mathscr{S}} (@(s) - c(s))^2}{N}\\end{aligned}\\]\n\nTo prove this we rely on a series of lemmas.\n\nAlejandro Pérez Carballo gives a more direct and elegant proof of this result in a recent manuscript. We have kept our inefficient proof since its structure provides a guide for the proof of Theorem-3.\n\nLet \\(\\mathscr{A}\\) be the algebra generated by a finite partition of states \\(\\mathscr{S}= \\{s_1, s_2, \\dots, s_N\\}\\). @ is a truth-value assignment for propositions in \\(\\mathscr{A}\\). For simplicity, assume \\(s_1\\) is the true state, so that @(\\(s_1\\)) = 1 and @(\\(s_n\\)) = 0 for \\(n &gt; 1\\). The credence function c assigns values of \\(c_1, c_2, \\dots, c_{N-1}, c_N\\) to the elements of \\(\\mathscr{S}\\), where \\(\\sum^{N}_{n=1} c_n = 1\\) in virtue of coherence.\nIt will be convenient to start by partitioning \\(\\mathscr{A}\\) into four “quadrants”. Let \\(B\\) range over all disjunctions with disjunctions drawn from \\(\\mathscr{B}= \\{s_2, s_3, \\dots, s_{N-1}\\}\\) (including the empty disjunction, i.e., the logical contradition \\(\\bot\\)). Then, \\(\\mathscr{A}\\) can be split into four disjoint parts:\n\\(\\mathscr{A}_1 = \\{B \\vee s_1 \\vee s_N: B\\) a disjunction of the elements of \\(\\mathscr{B}\\}\\)\n\\(\\mathscr{A}_2 = \\{B \\vee s_1: B\\) a disjunction of the elements of \\(\\mathscr{B}\\}\\)\n\\(\\mathscr{A}_3 = \\{B \\vee s_N: B\\) a disjunction of the elements of \\(\\mathscr{B}\\}\\)\n\\(\\mathscr{A}_4 = \\{B: B\\) a disjunction of the elements of \\(\\mathscr{B}\\}\\)\nNotice that:\n\\(\\mathscr{A}_1 \\cup \\mathscr{A}_2\\) contains all and only the true propositions in \\(\\mathscr{A}\\).\n\\(\\mathscr{A}_3 \\cup \\mathscr{A}_4\\) contains all and only the false propositions in \\(\\mathscr{A}\\).\n\\(\\mathscr{A}_1\\) and \\(\\mathscr{A}_4\\) are complementary sets, i.e., all elements of \\(\\mathscr{A}_4\\) are negations of elements of \\(\\mathscr{A}_1\\), and conversely.\n\\(\\mathscr{A}_2\\) and \\(\\mathscr{A}_3\\) are also complementary.\n\\(\\mathscr{A}_1 \\cup \\mathscr{A}_4\\) is the subalgebra of \\(\\mathscr{A}\\) generated by \\(\\{s_1 \\vee s_N, s_2, s_3, \\dots, s_{N-1}\\}\\).\nAll four quadrants have the same cardinality of \\(2^{N-2}\\).\nFor an additive scoring rule \\(\\mathbf{I}(\\mathbf{c}, @) = \\sum_{A \\in \\mathscr{A}}\\mathbf{i}(\\mathbf{c}(A), @(A))\\) and \\(j = 1, 2, 3, 4\\), define \\(\\mathbf{I}_j = \\sum_{A \\in \\mathscr{A}_j}\\mathbf{i}(\\mathbf{c}(A), @(A))\\), and note that \\(\\mathbf{I}(\\mathbf{c}, @) = 2^{-N}(\\mathbf{I}_1 + \\mathbf{I}_2 + \\mathbf{I}_3 + \\mathbf{I}_4)\\).\n\nLemma-1.1: If \\(\\textbf{I}\\) is negation symmetric, i.e., if \\(\\mathbf{i}(\\mathbf{c}(\\neg A), @(\\neg A)) = \\mathbf{i}(\\mathbf{c}(A), @(A))\\) for all \\(A\\), then \\(\\mathbf{I}_1 = \\mathbf{I}_4\\) and \\(\\mathbf{I}_2 = \\mathbf{I}_3\\), and \\(\\mathbf{I}(\\mathbf{c},@) = 2^{1-N}(\\mathbf{I}_2 + \\mathbf{I}_4)\\).\n\nProof: This is a direct consequence of the fact that \\(\\mathscr{A}_1\\) is complementary to \\(\\mathscr{A}_4\\) and that \\(\\mathscr{A}_2\\) is complementary to \\(\\mathscr{A}_3\\) since this allows us to write\n\\[\\begin{aligned}\n\\mathbf{I}_1(\\mathbf{c},@) &= \\sum_{A \\in \\mathscr{A}_1} \\mathbf{i}(\\mathbf{c}(A), @(A)) = \\sum_{A \\in \\mathscr{A}_1} \\mathbf{i}(\\mathbf{c}(\\neg A), @(\\neg A)) = \\mathbf{I}_4(\\mathbf{c},@). \\\\\n\\mathbf{I}_3(\\mathbf{c},@) &= \\sum_{A \\in \\mathscr{A}_3} \\mathbf{i}(\\mathbf{c}(A), @(A)) = \\sum_{A \\in \\mathscr{A}_3} \\mathbf{i}(\\mathbf{c}(\\neg A), @(\\neg A)) = \\mathbf{I}_2(\\mathbf{c},@). \\text{ QED}\\\\\\end{aligned}\\] Applying Lemma 1.1 with I = Brier we get\n\\[\\begin{aligned}\n(\\#)\\quad \\mathbf{Brier}_{\\mathscr{A}}(\\mathbf{c}, @) &= 2^{1-N} \\sum_{A \\in \\mathscr{A}} (@(A) - c(A))^2 \\\\\n&= 2^{1-N} \\sum_B [(1-c_1)^2 - 2(1-c_1)\\mathbf{c}(B) + \\mathbf{c}(B)^2]\\end{aligned}\\] since\n\\[\\begin{aligned}\n\\mathbf{Brier}_2 &= \\sum_B[1 - \\mathbf{c}(B \\vee s_1)]^2 &&= \\sum_B[(1 - c_1) - \\mathbf{c}(B)]^2 \\\\\n& &&= \\sum_B [(1-c_1)^2 - 2(1-c_1)\\mathbf{c}(B) + \\mathbf{c}(B)^2] \\\\\n\\mathbf{Brier}_4 &= \\sum_B \\mathbf{c}(B)^2 && \\quad\\end{aligned}\\]\n\nLemma-1.2 \\[\\begin{aligned}\n(\\sum_{n=2}^{N-1} c_n)^2 &= \\sum_{n=2}^{N-1} c{_n}^2 + 2 \\sum_{n=2}^{N-2} \\sum_{j&gt;n}^{N-1}c_nc_j\\end{aligned}\\]\n\nProof by induction. Easy.\n\nLemma-1.3 \\[\\begin{aligned}\n\\mathbf{Brier}_{\\mathscr{S}}(\\mathbf{c},@) &= \\frac{2}{N}[(1-c_1)^2 + \\sum_{n=2}^{N-1} c{_n}^2  - (1-c_1)(\\sum_{n=2}^{N-1}c_n) + \\sum_{n=2}^{N-2} \\sum_{j&gt;n}^{N-1}c_nc_j]\\end{aligned}\\]\n\nProof: Using the definition of the Brier score and the fact that \\(s_1\\) is true, we have\n\\[\\begin{aligned}\n\\mathbf{Brier}_{\\mathscr{S}}(\\mathbf{c},@) &= \\frac{1}{N}[(1 - c_1)^2 + \\sum_{n=2}^{N-1} c{_n}^2 + (1 - \\sum_{n=1}^{N-1}c_n)^2] \\\\\n&= \\frac{1}{N}[(1 - c_1)^2 + \\sum_{n=2}^{N-1} c{_n}^2 + ((1 -c_1) - \\sum_{n=2}^{N-1}c_n)^2] \\\\\n&= \\frac{1}{N}[(1 - c_1)^2 + \\sum_{n=2}^{N-1} c{_n}^2 + (1 -c_1)^2 - 2(1 - c_1) \\sum_{n=2}^{N-1}c_n + (\\sum_{n=2}^{N-1}c_n)^2] \\\\\n&= \\frac{1}{N}[(1 - c_1)^2 + \\sum_{n=2}^{N-1} c{_n}^2 + (1 -c_1)^2 - 2(1 - c_1) \\sum_{n=2}^{N-1}c_n  \\\\\n&\\quad \\quad +\\sum_{n=2}^{N-1} c{_n}^2 + 2 \\sum_{n=2}^{N-2} \\sum_{j&gt;n}^{N-1}c_nc_j] \\quad \\text{(Lemma-1.2)}\\end{aligned}\\] Then grouping like terms and factoring out 2 yields the desired result. QED\n\nLemma-1.4 \\[\\begin{aligned}\n\\sum_{n=2}^{N-1}c_n &= 2^{3-N}\\sum_{B \\in \\mathscr{B}}\\mathbf{c}(B)\\end{aligned}\\]\n\nProof: For each \\(n = 2, 3, \\dots, N-1\\), each \\(s_n\\) appears in half of the \\(2^{N-2}\\) disjunctions with disjuncts drawn from \\(\\mathscr{B}\\). As a result, each \\(c_n\\) appears as a summand \\(2^{N-3}\\) times among the sums that express the various \\(\\mathbf{c}(B)\\). So \\(\\sum_{B \\in \\mathscr{B}}\\mathbf{c}(B) = 2^{N-3}\\sum_{n=2}^{N-1}c_n\\). QED\n\nLemma-1.5 \\[\\begin{aligned}\n\\sum_{B \\in \\mathscr{B}}\\mathbf{c}(B)^2 &= 2^{N-3}[\\sum_{n=2}^{N-1} c{_n}^2 + \\sum_{n=2}^{N-2} \\sum_{j&gt;n}^{N-1}c_nc_j]\\end{aligned}\\]\n\nProof: We proceed by induction starting with the first meaningful case of \\(N=4\\), where calculation shows \\(\\sum_B\\mathbf{c}(B)^2 = (c_2 + c_3)^2 + c{_2}^2 + c{_3}^2 = 2[c{_2}^2 + c{_3}^2 + c_2c_3]\\). Now, assume the identity holds for disjunctions \\(B\\) of elements of \\(\\mathscr{B}\\) and show that it holds for disjunctions \\(A\\) of elements of \\(\\mathscr{B}\\cup \\{s_N\\}\\).\n\\[\\begin{aligned}\n\\sum_A\\mathbf{c}(A)^2 &= \\sum_B\\mathbf{c}(B)^2 + \\sum_B\\mathbf{c}(B \\vee s_N)^2 \\\\\n&= \\sum_B\\mathbf{c}(B)^2 + \\sum_B(\\mathbf{c}(B)^2 + 2c_N\\mathbf{c}(B) + c{_N}^2)\\\\\n&= 2\\sum_B\\mathbf{c}(B)^2 + 2c_N\\sum_B\\mathbf{c}(B) + \\sum_Bc{_N}^2 \\\\\n&= 2 \\cdot 2^{N-3}[\\sum_{n=2}^{N-1} c{_n}^2 + \\sum_{n=2}^{N-2} \\sum_{j&gt;n}^{N-1}c_nc_j] + 2c_N\\sum_B\\mathbf{c}(B) + \\sum_Bc{_N}^2 &&\\text{(Induction Hypothesis)}\\\\\n&= 2^{N-2}[\\sum_{n=2}^{N-1} c{_n}^2 + \\sum_{n=2}^{N-2} \\sum_{j&gt;n}^{N-1}c_nc_j] + 2^{N-2}c_N\\sum_{n=2}^{N-1}c_n + \\sum_Bc{_N}^2 &&\\text{(Lemma-1.4)} \\\\\n&= 2^{N-2}[\\sum_{n=2}^{N-1} c{_n}^2 + \\sum_{n=2}^{N-2} \\sum_{j&gt;n}^{N-1}c_nc_j] + 2^{N-2}c_N\\sum_{n=2}^{N-1}c_n + 2^{N-2}c{_N}^2 &&\\text{Since $|\\mathscr{B}| = 2^{N-2}$} \\\\\n&= 2^{N-2}[\\sum_{n=2}^{N} c{_n}^2 + \\sum_{n=2}^{N-1} \\sum_{j&gt;n}^{N}c_nc_j] && \\text{ QED}\\end{aligned}\\] Plugging the results of the last two lemmas into Lemma-1.3 produces a result of\n\\[\\begin{aligned}\n\\mathbf{Brier}_{\\mathscr{S}}(\\textbf{c},@) &= \\frac{2}{N}[(1-c_1)^2 + 2^{3-N}\\sum_{B \\in \\mathscr{B}}\\mathbf{c}(B)^2 - 2^{3-N}(1-c_1)\\sum_{B \\in \\mathscr{B}}\\mathbf{c}(B)] \\\\\n&= \\frac{2}{N}\\sum_{B \\in \\mathscr{B}}[2^{2-N}(1-c_1)^2 + 2^{3-N}\\mathbf{c}(B)^2 - 2^{3-N}(1-c_1)\\mathbf{c}(B)] \\\\\n&= \\frac{2^{3-N}}{N}\\sum_{B \\in \\mathscr{B}}[(1 - c_1)^2 + 2\\mathbf{c}(B)^2 - 2(1-c_1)\\mathbf{c}(B)]\\end{aligned}\\] Comparing this to (#) we see that it is just \\(\\frac{N}{4}\\) times Brier\\(_\\mathscr{S}(\\mathbf{c},@)\\), as we aimed to prove. QED.\n\nTheorem-2. When inaccuracy over \\(\\mathscr{A}\\) is measured using the Brier score, the least accurate credal states are those which assign credence 1 to some false atom of \\(\\mathscr{A}\\).\n\nProof: As before, suppose that \\(@(s_1) = 1\\), and let c be a credence function that assigns credence 1 to some false atom \\(s_2, s_3,..., s_N\\) of \\(\\mathscr{A}\\). In light of Theorem-1 it suffices to show that \\(\\mathbf{Brier}_\\mathscr{S}(\\mathbf{c}, @) &gt; \\mathbf{Brier}_\\mathscr{S}(\\mathbf{b}, @)\\) where b does not assign credence 1 to any false atom. Start by noting that for any credence function \\(\\pi\\) defined on the atoms of \\(\\mathscr{A}\\) one has\n\\[\\begin{aligned}\n\\mathbf{Brier}_\\mathscr{S}(\\pi,@) &= \\frac{1}{N}[(1-\\pi_1)^2 + \\sum_{n=2}^{N-1}\\pi{_n}^2+ (1-\\sum_{n=1}^{N-1}\\pi{_n})^2] \\\\\n&= \\frac{1}{N}[1 - 2\\pi_1 + \\sum_{n=1}^{N-1}\\pi{_n}^2+ (1-\\sum_{n=1}^{N-1}\\pi{_n})^2]\\end{aligned}\\]\nBut, since each \\(\\pi_n \\in [0, 1]\\) is non-negative, it follows that \\(\\pi_1 \\geq \\pi{_1}^2, \\pi_2 \\geq \\pi{_2}^2, \\dots, \\pi_N \\geq \\pi{_N}^2\\) with the inequality strict in each case unless \\(\\pi_n\\) is either 1 or 0.\nThis means that the sum \\(\\sum_{n=1}^{N-1}\\pi{_n}^2+ (1-\\sum_{n=1}^{N-1}\\pi{_n})^2\\) is less than or equal to 1, with equality if and only if exactly one of the atoms \\(s_n\\) is assigned probability 1 (and the rest have probability zero). As a result, Brier\\(_\\mathscr{S}(\\pi, @) \\leq \\frac{2}{N}(1 - \\pi_1)\\) with equality if and only if exactly one of the atoms \\(s_n\\) is assigned probability 1. So, there are three relevant cases:\nIf \\(\\pi\\) assigns some false atom probability 1, Brier\\(_\\mathscr{S}(\\pi, @) = \\frac{2}{N}\\cdot(1 - 0) = \\frac{2}{N}\\).\nIf \\(\\pi\\) assigns the true atom probability 1, Brier\\(_\\mathscr{S}(\\pi, @) = \\frac{2}{N}\\cdot(1 - 1) = 0\\).\nIf \\(\\pi\\) does not assign any atom probability 1, Brier\\(_\\mathscr{S}(\\pi, @) &lt; \\frac{2}{N}\\cdot(1 - c_1) \\leq \\frac{2}{N}\\).\nSo, since c fits case (i) and b fits case (ii) or (iii) we have the desired result. QED\n\nTheorem-3: Let \\(\\mathscr{A}\\) be an algebra of propositions generated by atoms \\(a_1, ..., a_{2N}\\), where \\(a_1\\) is the truth. Let \\(P\\) and \\(Q\\) be probability functions defined on \\(\\mathscr{A}\\). \\(P\\) assigns all its mass to the first \\(N\\) atoms, so that \\(P(a_1 \\vee \\dots \\vee a_N) = 1\\), and it also assigns some positive probability to \\(a_1\\). \\(Q\\) assigns all its mass to the false atom \\(a_{2N}\\), so that \\(Q(a_{2N}) = 1\\). Then, for any proper score I satisfying Truth-directedness, Extensionality and Negation Symmetry we have \\(\\mathbf{I}(v_1, P) &lt; \\mathbf{I}(v_1, Q)\\) where \\(v_1\\) is the truth-value assignment associated with \\(a_1\\) (i.e., where \\(v_1(X) = 1\\) if and only if \\(a_1\\) entails \\(X\\)).\n\nProof: We can divide the algebra \\(\\mathscr{A}\\) into four quadrants \\[\\begin{aligned}\n\\mathscr{A}^1 &= \\{X \\in \\mathscr{A}: a_1 \\vDash X \\text{ and } a_{2N} \\vDash X\\} \\\\\n\\mathscr{A}^2 &= \\{X \\in \\mathscr{A}: a_1 \\vDash X \\text{ and } a_{2N} \\nvDash X\\} \\\\\n\\mathscr{A}^3 &= \\{X \\in \\mathscr{A}: a_1 \\nvDash X \\text{ and } a_{2N} \\vDash X\\} \\\\\n\\mathscr{A}^4 &= \\{X \\in \\mathscr{A}: a_1 \\nvDash X \\text{ and } a_{2N} \\nvDash X\\}\\end{aligned}\\] We know the following:\n\n\\(Q\\) is maximally accurate on \\(\\mathscr{A}^1 \\cup \\mathscr{A}^4\\). Every proposition in \\(\\mathscr{A}^1\\) is true, and \\(Q\\) assigns it a probability of 1. Every proposition in \\(\\mathscr{A}^4\\) is false, and \\(Q\\) assigns it a probability of 0.\n\\(Q\\) is maximally inaccurate on \\(\\mathscr{A}^2 \\cup \\mathscr{A}^3\\). Every proposition in \\(\\mathscr{A}^2\\) is true, and \\(Q\\) assigns it a probability of 0. Every proposition in \\(\\mathscr{A}^3\\) is false, and \\(Q\\) assigns it a probability of 1.\n\\(P\\) is maximally accurate on \\(\\mathscr{A}^3 \\cup \\mathscr{A}^4\\). Every proposition in \\(\\mathscr{A}^3 \\cup \\mathscr{A}^4\\) is false, and \\(P\\) assigns it a probability of 0.\nEach quadrant has \\(2^{2N-2}\\) elements.\n\n\nLemma-3.1: When \\(a_1\\) is true, the accuracy score of \\(P\\) over the propositions in \\(\\mathscr{A}^1\\) is identical to the accuracy score of \\(P\\) over the propositions in \\(\\mathscr{A}^2\\).\n\nProof: Note first that the function \\(F: \\mathscr{A}^1 \\rightarrow \\mathscr{A}^2\\) that takes \\(X\\) to \\(X \\wedge \\neg a_{2N}\\) is a bijection of \\(\\mathscr{A}^1\\) onto \\(\\mathscr{A}^2\\). Since every proposition in \\(\\mathscr{A}^1 \\cup \\mathscr{A}^2\\) is true, we can then write the respective accuracy scores of \\(\\mathscr{A}^1\\) and \\(\\mathscr{A}^2\\) as \\[\\begin{aligned}\n\\mathbf{I}_{\\mathscr{A}^1}(a_1, P) &= 2^{2-2N} \\cdot \\sum_{X \\in \\mathscr{A}^1} \\mathbf{I}(1, P(X)) \\\\\n\\mathbf{I}_{\\mathscr{A}^2}(a_1, P) &= 2^{2-2N} \\cdot \\sum_{X \\in \\mathscr{A}^1} \\mathbf{I}(1, P(X \\wedge \\neg a_{2N}))\\end{aligned}\\] Note: \\(X\\) ranges over \\(\\mathscr{A}^1\\) in both summations. But since \\(P(a_{2N}) = 0\\) we have \\(P(X) = P(X \\wedge a_{2N})\\) for each \\(X\\) in \\(\\mathscr{A}^1\\). Since I is extensional, this means that \\(\\mathbf{I}(1, P(X)) = \\mathbf{I}(1, P(X \\wedge a_{2N}))\\) for each \\(X\\) in \\(\\mathscr{A}^1\\). And, it follows that \\(\\mathbf{I}_{\\mathscr{A}^1}(a_1, P)\\) and \\(\\mathbf{I}_{\\mathscr{A}^2}(a_1, P)\\) are identical. (Note that even if \\(P(a_{2N}) &gt; 0\\), Truth-directedness entails that \\(\\mathbf{I}_{\\mathscr{A}^1}(a_1, P) &lt; \\mathbf{I}_{\\mathscr{A}^2}(a_1, P)\\).)\n\nLemma-3.2: When \\(a_1\\) is true, the accuracy score of \\(Q\\) over \\(\\mathscr{A}^2\\) is identical to the accuracy score of \\(Q\\) over \\(\\mathscr{A}^3\\).\n\nProof: To see this, note first that the function \\(G: \\mathscr{A}^2 \\rightarrow \\mathscr{A}^3\\) that takes \\(X\\) to \\(G(X) = \\neg X\\) is a bijection (i.e., the negation of everything in \\(\\mathscr{A}^2\\) is in \\(\\mathscr{A}^3\\) and vice-versa). This, together with the fact that \\(\\mathscr{A}^2\\) contains only truths and \\(\\mathscr{A}^3\\) contains only falsehoods, lets us write \\[\\begin{aligned}\n\\mathbf{I}_{\\mathscr{A}^2}(a_1, Q) &= 2^{2-2N} \\cdot \\sum_{X \\in \\mathscr{A}^2} \\mathbf{I}(1, Q(X)) \\\\\n\\mathbf{I}_{\\mathscr{A}^3}(a_1, Q) &= 2^{2-2N} \\cdot \\sum_{X \\in \\mathscr{A}^2} \\mathbf{I}(0, Q(\\neg X))\\end{aligned}\\] But since I is negation symmetric, \\(\\mathbf{I}(1, Q(X)) = \\mathbf{I}(0, Q(\\neg X))\\) for every \\(X\\), which means that \\(\\mathbf{I}_{\\mathscr{A}^2}(a_1, Q) = \\mathbf{I}_{\\mathscr{A}^3}(a_1, Q)\\). (Note that this proof made no assumptions about \\(Q\\) except that it was a probability.)\n\nLemma-3.3: If \\(P(a_1) &gt; 0\\), the accuracy score of \\(P\\) over \\(\\mathscr{A}^2\\) is strictly less than the accuracy score of \\(Q\\) over \\(\\mathscr{A}^2\\).\n\nProof: Since \\(Q(X) = 0\\) everywhere on \\(\\mathscr{A}^2\\) we have \\[\\begin{aligned}\n\\mathbf{I}_{\\mathscr{A}^2}(a_1, P) &= 2^{2-2N} \\cdot \\sum_{X \\in \\mathscr{A}^2} \\mathbf{I}(1, P(X)) \\\\\n\\mathbf{I}_{\\mathscr{A}^2}(a_1, Q) &= 2^{2-2N} \\cdot \\sum_{X \\in \\mathscr{A}^2} \\mathbf{I}(1, 0) \\end{aligned}\\] But, by Truth Directedness \\(\\mathbf{I}(1, 0) &gt; \\mathbf{I}(1, P(X))\\) since \\(P(a_1) &gt; 0\\) implies that \\(P(X) &gt; 0\\) for all \\(X \\in \\mathscr{A}^2\\). Thus \\(\\mathbf{I}_{\\mathscr{A}^2}(a_1, Q) &gt; \\mathbf{I}_{\\mathscr{A}^2}(a_1, P)\\).\nTo complete the proof of the theorem we need only note that \\[\\begin{aligned}\n\\mathbf{I}_{\\mathscr{A}}(a_1, P) &= \\frac{\\mathbf{I}_{\\mathscr{A}^1}(a_1, P)}{4} + \\frac{\\mathbf{I}_{\\mathscr{A}^2}(a_1, P)}{4} &\\text{(since }P\\text{ is perfect on }\\mathscr{A}^3 \\cup \\mathscr{A}^4) \\\\\n&= \\frac{\\mathbf{I}_{\\mathscr{A}^2}(a_1, P)}{2} &\\text{Lemma-3.1} \\\\\n&&lt; \\frac{\\mathbf{I}_{\\mathscr{A}^2}(a_1, Q)}{2} &\\text{Lemma-3.3} \\\\\n&= \\frac{\\mathbf{I}_{\\mathscr{A}^2}(a_1, Q)}{4} + \\frac{\\mathbf{I}_{\\mathscr{A}^3}(a_1, Q)}{4} &\\text{Lemma-3.2} \\\\\n&= \\mathbf{I}_{\\mathscr{A}}(a_1, Q) &\\text{(since }Q\\text{ is perfect on }\\mathscr{A}^1 \\cup \\mathscr{A}^4)\\end{aligned}\\]\n\n\n\n\n\n\nReferences\n\nBerker, Selim. 2013a. “Epistemic Teleology and the Separateness of Propositions.” Philosophical Review 122 (3): 337–93. https://doi.org/10.1215/00318108-2087645.\n\n\n———. 2013b. “The Rejection of Epistemic Consequentialism.” Philosophical Issues 23 (1): 363–87. https://doi.org/10.1111/phis.12019.\n\n\nDescartes, René. 1641/1996. Meditations on First Philosophy, Tr. John Cottingham. Cambridge: Cambridge University Press.\n\n\nGreaves, Hilary. 2013. “Epistemic Decision Theory.” Mind 122 (488): 915–52. https://doi.org/10.1093/mind/fzt090.\n\n\nHammond, Peter J. 1988. “Consequentialist Foundations for Expected Utility.” Theory and Decision 25 (1): 25–78. https://doi.org/10.1007/BF00129168.\n\n\nJenkins, C. S. 2007. “Entitlement and Rationality.” Synthese 157 (1): 25–45. https://doi.org/10.1007/s11229-006-0012-2.\n\n\nJoyce, James M. 1998. “A Non-Pragmatic Vindication of Probabilism.” Philosophy of Science 65 (4): 575–603. https://doi.org/10.1086/392661.\n\n\nMaher, Patrick. 1997. “Depragmatised Dutch Book Arguments.” Philosophy of Science 64 (2): 291–305. https://doi.org/10.1086/392552.\n\n\nRoulston, Mark S. 2007. “Performance Targets and the Brier Score.” Meterological Applications 14: 185–94. https://doi.org/10.1002/met.21.\n\n\nShafer, Glenn. 1976. A Mathematical Theory of Evidence. Princeton: Princeton University Press.\n\n\nWeatherson, Brian. 1999. “Begging the Question and Bayesians.” Studies in the History and Philosophy of Science Part A 30: 687–97."
  },
  {
    "objectID": "posts/indsub/indicative-and-subjunctive-conditionals.html",
    "href": "posts/indsub/indicative-and-subjunctive-conditionals.html",
    "title": "Indicative and Subjunctive Conditionals",
    "section": "",
    "text": "This paper presents a new theory of the truth conditions for indicative conditionals. The theory allows us to give a fairly unified account of the semantics for indicative and subjunctive conditionals, though there remains a distinction between the two classes. Put simply, the idea behind the theory is that the distinction between the indicative and the subjunctive parallels the distinction between the necessary and the a priori. Since that distinction is best understood formally using the resources of two-dimensional modal logic, those resources will be brought to bear on the logic of conditionals."
  },
  {
    "objectID": "posts/indsub/indicative-and-subjunctive-conditionals.html#a-grand-unified-theory",
    "href": "posts/indsub/indicative-and-subjunctive-conditionals.html#a-grand-unified-theory",
    "title": "Indicative and Subjunctive Conditionals",
    "section": "1 A Grand Unified Theory?",
    "text": "1 A Grand Unified Theory?\nOur primary focus is the indicative conditional ‘If \\(A\\), \\(B\\)’, written as \\(A \\rightarrow B\\). Most theorists fail to distinguish between this conditional and ‘If \\(A\\), then \\(B\\)’, and for the most part I will follow this tradition. The most notable philosophical exception is Grice, who suggested that only the latter says that \\(B\\) follows from \\(A\\) in some relevant way (1989: 63). Theorists do distinguish between this conditional and the subjunctive ‘If it were the case that \\(A\\), it would be the case that \\(B\\)’, written as \\(A \\,\\square\\!\\mathord\\to B\\). There is some debate about precisely where to draw the line between these two classes, which I’ll discuss in section three, but for now I’ll focus on cases far from the borderline. One important tradition in work on conditionals holds that the semantics of indicatives differs radically from the semantics of subjunctives. According to David Lewis (1973, 1976) and Frank Jackson (1987) for example, indicatives are truth-functional, but subjunctives are not. This makes a mystery of some of the data. For example, as Jackson himself writes:\n\nBefore the last presidential election commentators said ‘If Reagan loses, the opinion polls will be totally discredited’, afterwards they said ‘If Reagan had lost, the opinion polls would have been totally discredited’, and this switch from indicative to subjunctive counterfactual did not count as a change of mind (Jackson 1987, 66).\n\nThe point can be pushed further. To communicate the commentators’ pre-election opinions using indirect speech we would say something like (1).\n\nCommentators have said that if Reagan were to lose the opinion polls would be totally discredited.\n\nYet it is possible on Jackson’s view that what the commentators said was true, since Reagan won, yet the words after ‘that’ in (1) form a false sentence. So we can accurately report someone speaking truly by using a false sentence. Jackson’s response plays on the connections between \\(A \\rightarrow B\\) and the disjunction ‘Not-\\(A\\) or \\(B\\)’. That disjunction has undeniably different truth conditions to \\(A \\,\\square\\!\\mathord\\to\\) B. Pushing the truth conditions of \\(A \\rightarrow B\\) closer to those of \\(A \\,\\square\\!\\mathord\\to\\) B will move them away from ‘Not- \\(A\\) or \\(B\\)’. One gain in similarity and theoretical simplicity is bought at the cost of another. Jackson’s account, by making \\(A \\rightarrow B\\) have similar truth conditions to ‘Not - \\(A\\) or \\(B\\)’ but similar assertibility conditions to \\(A \\,\\square\\!\\mathord\\to B\\), tries to have the best of both worlds. How great the similarity between indicative conditionals and disjunctions really is, and hence how great the cost of linking indicatives and subjunctives, might well be questioned. After all, we don’t report an utterance of an indicative using a disjunction.\nTwo types of cases seem to threaten the success of a unified theory. First, rigidifying expressions like ‘actually’ behave differently in indicatives and subjunctives. Secondly, some conditionals differ in intuitive truth value when we transpose them from the indicative to the subjunctive. The most famous examples of this phenomenon involve various presidential assassinations. The effects of rigidity on conditionals are less explored, so we will first look at that. Consider the following example, from page 55 of Naming and Necessity.\n\nIf heat had been applied to this stick \\(S\\) at \\(t_0\\), then at \\(t_0\\) stick \\(S\\) would not have been one meter long.\n\nThe background is that we have stipulated that a metre is the length of stick \\(S\\) at time \\(t_0\\). (2) contrasts with (3), which seems false.\n\nIf heat was applied to this stick \\(S\\) at \\(t_0\\), then at \\(t_0\\) stick \\(S\\) was not one meter long.\n\nIf we have stipulated that to be a meter long is to be the length of \\(S\\) at \\(t_0\\), then whatever conditions \\(S\\) was under at \\(t_0\\), it was one meter long. As Jackson points out, we can get the same effect with explicit rigidifiers like ‘actually’. We could, somewhat wistfully, say (4). It may even be true. But (5) seems barely coherent, and certainly not something we could ever say.\n\nIf Hillary Clinton were to become the next U.S. President, things would be different from the way they actually will be.\nIf Hillary Clinton becomes the next U.S. President, things will be different from the way they actually will be.\n\nIt looks like any theory of conditionals will have to account for a difference between the behaviour of rigid designators in indicatives and subjunctives. We may avoid the conclusion by showing that the difference only appears in certain types of conditionals, and we already have an explanation for those cases. For example, it is well known that usually one cannot say \\(A \\rightarrow B\\) if it is known that not-\\(A\\). As Dudman (1994) points out, (6) is clearly infelicitous on its most obvious reading.\n\n*Granny won, but if she lost she was furious.\n\nTo complete the diagnosis, note that the most striking examples of the different behaviour of rigid designators in different types of conditionals comes up in cases where the antecedent is almost certainly false. The effect is that the subjunctive can be asserted, but not the indicative. So this phenomenon may be explainable by some other part of the theory of conditionals.1 These are the most striking exemplars of the difference I am highlighting, but not the only examples. Hence, this point cannot explain all the data, though it may explain why pairs like (2)/(3) and (4)/(5) are striking. For instance, in the following pairs, the indicative seems appropriate and intuitively true, and the subjunctive seems inappropriate and intuitively false.\n1 An anonymous reviewer for Philosophical Quarterly suggested this point.\nIf C-fibres firing is what causes pain sensations, then C-fibres firing is what actually causes pain sensations.\nIf C-fibres firing were what caused pain sensations, then C-fibres firing would be what actually causes pain sensations.\nIf the stuff that plays the gold role has atomic number 42, then gold has atomic number 42.\nIf the stuff that played the gold role had atomic number 42, gold would have atomic number 42.\n\nIn (9) and (10) I assume that to play the gold role one must play it throughout a large part of the world, and not just on a small stage. Something may play the gold role in a small part of the world without being gold. Since there are pairs of conditionals like these where the indicative is appropriate, but the subjunctive is not, the explanation of the behaviour of rigid terms cannot rely on the fact that the antecedents of indicatives must be not known to be false. We will also need a more traditional example of the differences between indicatives and subjunctives, as in (11) and (12).\n\nIf Hinckley didn’t shoot Reagan, someone else did.\nIf Hinckley hadn’t shot Reagan, someone else would have.\n\nI have concentrated on the examples involving rigidity because they seem to pose a deeper problem for unifying the theory of conditionals than the presidential examples. As Jackson (1987, 75) points out, one can presumably explain (11) and (12) on a possible worlds account by varying the similarity metric between indicatives and subjunctives, or on a probabilistic account by varying the background evidence. It is unclear, however, how this will help with the rigidity examples. Assume, for example, that C-fibres firing is not what causes pain sensations. Still, (7) seems true, but its consequent is false in all possible worlds. Therefore, the nearest world in which its antecedent is true is a world in which its consequent is false, and on a simple possible worlds theory it should turn out false. On a simple probabilistic account, the probability that C-fibres firing actually cause pain sensations given that they do is 1, whatever the background evidence, so (8) should turn out true, contrary to our intuitions. So while the details deal with the presidential examples, the structure of the theory must deal with the rigidity examples.\nI will follow that strategy here. In section two I set out the framework of a unified possible worlds account of indicatives and subjunctives. In section three I present my preferred way of filling out the details of that framework. The framework deals with the differing behaviour of rigid designators in indicatives and subjunctives; the details deal with examples like (11) and (12). One reason for dividing the presentation in this way is to highlight the option of accepting the framework and filling in the details in different ways."
  },
  {
    "objectID": "posts/indsub/indicative-and-subjunctive-conditionals.html#the-new-theory",
    "href": "posts/indsub/indicative-and-subjunctive-conditionals.html#the-new-theory",
    "title": "Indicative and Subjunctive Conditionals",
    "section": "2 The New Theory",
    "text": "2 The New Theory\n\n2.1 Actually\nAs Kripke (1980) showed, the reference for some terms is fixed by what plays a particular role in the actual world. Even if it were the case that XYZ fills the ocean, falls from the sky, is drinkable and transparent and so on, for short is watery, it would still be the case that water is H2O, not XYZ. For it would still be that H2O actually is watery. Whatever were the case, this world would be actual.\nYet, we want to have a way to talk about what would have happened had some other world been actual. In particular, had the actual world been one in which XYZ is watery, it would be true, indeed necessarily true, that water is XYZ. Throughout the 1970s a number of methods for doing this were produced. The following presentation is indebted to Davies and Humberstone (1980), but other approaches might have been used. The notation \\(\\vDash_y^x A\\) is interpreted as ‘\\(A\\) is true in world \\(y\\) from the perspective of world \\(x\\) as actual’. So, letting @ be the actual world and \\(w\\) be a world in which only XYZ is watery, we can represent what was said informally above as follows.\n\n\\(\\vDash_@^@\\) H2O is watery and H2O is water.\n\\(\\vDash_w^@\\) XYZ is watery and H2O is water.\n\\(\\vDash_@^w\\) H2O is watery and XYZ is water.\n\\(\\vDash_w^w\\)XYZ is watery and XYZ is water.\n\nNow as Kripke noted, it is necessary but a posteriori that water is H2O. Conversely, it is a priori but contingent that water is watery. This is a priori because we knew before we determined what water really is that it would be whatever plays the watery role in this world, the actual world. In general \\(A\\) is necessary iff, given this is the actual world, it is true in all worlds. And \\(A\\) is a priori iff, whatever the actual world turns out to be like, it makes \\(A\\) true. So we get the following definitions.\n\n\\(A\\) is a priori iff for all worlds \\(w\\), \\(\\vDash_w^w\\) \\(A\\).\n\\(A\\) is necessary iff for all worlds \\(w\\), \\(\\vDash_w^@\\) \\(A\\).\n\nThe connection between actuality and the a priori is important. It is a priori that we are in the actual world. Something is a priori iff it is true whenever the two indices are the same. If we regard possible worlds as sets of sentences, we can think of the sets {\\(A\\): \\(\\vDash_x^x\\) \\(A\\)} for each possible world \\(x\\) as the epistemically possible worlds. Note that I don’t make the set of epistemically possible worlds relative to an evidence set, as others commonly do. Rather they are just the sets of sentences consistent with what we know a priori. More accurately, identify a world pair \\(\\langle x\\), \\(y \\rangle\\) with the set of {\\(A\\): \\(\\vDash_y^x\\) \\(A\\)}. Then \\(\\langle x\\), \\(y \\rangle\\) is an epistemically possible world pair iff \\(x\\) = \\(y\\).\nTo finish this formal excursion, we note the definition of ‘Actually \\(A\\)’. Given what has been said so far, this needs no explanation.\n\n\\(\\vDash_y^x\\)Actually \\(A\\) iff \\(\\vDash_x^x\\) \\(A\\).\n\n\n\n2.2 The Analysis of Indicatives\nNow we have the resources for my theory of the truth conditions for indicatives. I also give the parallel truth condition for subjunctives to show the similarities.\n\n\\(\\vDash_@^@\\)\\(A \\rightarrow B\\) iff the nearest possible world \\(x\\) that \\(\\vDash_x^x\\) \\(A\\) is such that \\(\\vDash_x^x\\) \\(B\\).\n\\(\\vDash_@^@\\) \\(A \\,\\square\\!\\mathord\\to B\\) iff the nearest possible world \\(x\\) that \\(\\vDash_x^@\\) \\(A\\) is such that \\(\\vDash_x^@\\)\\(B\\).\n\nThese only cover the special case of what is true here from the perspective of this world as actual. We can partially generalise the analysis of indicatives in one dimension as follows.\n\n\\(\\vDash_w^w\\) \\(A \\rightarrow B\\) iff the nearest possible world \\(x\\) to \\(w\\) such that \\(\\vDash_x^x\\) \\(A\\) is such that \\(\\vDash_x^x\\) \\(B\\).\n\nI will make some comments below about how we might fully generalise the analysis, but for now, I want to focus on these simpler cases. Note that straight away this makes \\(A \\rightarrow\\) Actually \\(A\\) come out true, by the definition of ‘Actually’. If we allow ourselves quantification over propositions, we can give an analysis of ‘things are different from the way they actually are’, as follows:\n\n(\\(\\vDash_y^x\\) Things are different from the way they actually are) iff\n(\\(\\exists\\)\\(p\\): \\(\\vDash_y^x\\) \\(p\\) and not \\(\\vDash_x^x\\) \\(p\\))\n\nSince nothing both is and is not the case in \\(x\\) from the perspective of \\(x\\) as actual, this can never be true when \\(y\\) is \\(x\\). This explains why it can never serve as the consequent of an indicative conditional.\n\n\n2.3 Motivations\nThe theory outlined here is reasonably unified, and accounts for the rigidity phenomena, but without any further justification, the resort to two-dimensional modal logic is ad hoc. This subsection responds to that problem with some independent motivations for the theory. In particular I argue that this theory best captures the well-known epistemic feel of the indicative conditional.\nEver since Ramsey (1929/1990) most theorists have held that there is an epistemic element to indicatives. Here is Ramsey’s sketch of an analysis of indicatives.\n\nIf two people are arguing ‘If \\(p\\) will q?’ and are both in doubt as to \\(p\\), they are adding \\(p\\) hypothetically to their stock of knowledge and arguing on that basis about q; so that in a sense ‘If \\(p\\), q’ and ‘If \\(p\\), \\(\\neg\\)q’ are contradictories (Ramsey 1929/1990, 247n).\n\nNothing of the sort could be true about subjunctives. What is in our ‘stock of knowledge’, or the contextually relevant knowledge, makes at most an indirect contribution to the truth- value of a subjunctive. It makes an indirect contribution because the common knowledge might affect the context, which in turn determines the similarity measure. But given a context, a subjunctive makes a broadly metaphysical claim, an indicative a broadly epistemic claim. Hence, the relationship between the indicative and subjunctive should parallel the relationship between the necessary and the a priori. As should be clear, this is exactly what happens on this theory.\nThe close similarity between the indicative/subjunctive distinction and the a priori/necessary distinction can be demonstrated in other ways. For example, corresponding to the contingent a priori (13) the indicative (14) is true, but the subjunctive (15) is false. And corresponding to the necessary a posteriori (16) the subjunctive (17) is true but the indicative (18) is false. (I am assuming that it is part of the definitions of the water role and the fire role that nothing can play both roles.)\n\nWater is what plays the water role.\nIf XYZ plays the water role, XYZ is water.\nIf XYZ played the water role, it would be water.\nWater is H2O.\nIf all H2O played the fire role, all water would be fire.\nIf all H2O plays the fire role, all water is fire.\n\nThis suggests the analysis sketched here is not ad hoc at all, but follows naturally from considerations about the necessary and a priori. These sketchy considerations might not provide much positive support for my theory. The main evidence for the theory, however, is the way it manages the hard cases, particularly cases involving rigid designation. What these considerations show is that the correct theory of indicatives may invoke the resources of two-dimensional modal logic without automatically renouncing any claim to systematicity."
  },
  {
    "objectID": "posts/indsub/indicative-and-subjunctive-conditionals.html#the-details",
    "href": "posts/indsub/indicative-and-subjunctive-conditionals.html#the-details",
    "title": "Indicative and Subjunctive Conditionals",
    "section": "3 The Details",
    "text": "3 The Details\nIn this section, I want to look at four questions. First, what can we say about the similarity measure at the core of this account? Secondly, how should we generalise the theory to cover cases where the definite description in the analysis appears to denote nothing? Thirdly, how should we generalise the theory to cover cases where the two indices differ? Finally, how should we draw the line between indicatives and subjunctives? If what I said in the previous section is correct, there should be something to say about each of these questions, and what is said should be motivated. While it is not important that what I say here is precisely true, I do hope that it is.\n\n3.1 Nearness\nIdeally, we could use exactly the same similarity metric for both indicatives and subjunctives. The existence of pairs like (11) and (12) suggests this is impossible. So we must come up with a pair of measures on the worlds satisfying three constraints. First, the measure for subjunctives must deliver plausible verdicts for most subjunctive conditionals. Secondly, the measure for indicatives must deliver plausible verdicts for most indicative conditionals. Thirdly, the measures must be similar enough that we can explain the close relationship between indicatives and subjunctives set out in section one. The theory of section two requires that these objectives be jointly satisfiable. I will attempt to demonstrate that they are by outlining a pair of measures satisfying all three.\nLewis (1979a) provides the measure for subjunctives. He suggests the following four rules for locating the nearest possible world in which A is true.\n\nIt is of the first importance to avoid big, widespread, diverse violations of law.\nIt is of the second importance to maximise the spatio-temporal region throughout which perfect match of particular fact prevails.\nIt is of the third importance to avoid even small, localized, simple violations of law.\nIt is of little or no importance to secure approximate similarity of particular fact, even in matters that concern us greatly. (Lewis 1979a, 47–48)\n\nThe right measure for indicatives is somewhat simpler. Notice that whenever we know that \\(A \\supset B\\) and don’t know whether \\(A\\), \\(A \\rightarrow B\\) seems true. More generally, if I know some sentence \\(S\\) such that \\(A\\) and \\(S\\) together entail \\(B\\), and I would continue to know \\(S\\) even were I to come to doubt \\(B\\), then \\(A \\rightarrow B\\) will seem true to me. No matter how good a card cheat I know Sly Pete to be, if I know that he has the worse hand, and that whenever someone with the worse hand calls they lose, it will seem true to me that If Sly Pete calls, he will lose. Further, if someone else knows these background facts and tells me that If Sly Pete calls, he will lose, she speaks truthfully.\nThis data suggests that whenever there is a true \\(S\\) such that \\(A\\) and \\(S\\) entail \\(B\\), \\(A \\rightarrow B\\) is true. But this would mean \\(A \\rightarrow B\\) is true whenever \\(A \\supset B\\) is true, which seems incredible. On this theory it is true that If there is a nuclear war tomorrow, life will go on as normal. There are some very subtle attempts to make this palatable. The ‘Supplemented Equivalence Theory’ in Jackson (1987) may even be successful. But two problems remain for all theories saying \\(A \\rightarrow B\\) has the truth value of \\(A \\supset B\\). First, they make some apparently true negated conditionals turn out false, such as It is not true that if there is a nuclear war tomorrow, life will go on as normal. It is hard to see how an appeal to Gricean pragmatics will avoid this problem. Secondly, such theories fail the third task we set ourselves at the start of the section: explaining the close connections between indicatives and subjunctives.\nSo we might be tempted to try a different path. Let’s take the data at face value and say that \\(A \\rightarrow B\\) is true in a context if there is some \\(S\\) such that some person in that context knows \\(S\\), and \\(A\\) and \\(S\\) together entail \\(B\\). We can formalise this claim as follows. Let \\(d\\)(\\(x\\), \\(y\\)) be the ‘distance’ from \\(x\\) to \\(y\\). This function will satisfy few of the formal properties of a distance relationship, so remember this is just an analogy. Let K be the set of all propositions \\(S\\) known by someone in the context, \\(W\\) the set of all possible worlds, and \\(i\\) the impossible world, where everything is true. Then \\(d\\): \\(W \\times W \\cup \\{i\\} \\rightarrow \\Re\\) is as follows:\n\nIf \\(y = x\\) then \\(d\\)(\\(x\\), \\(y\\)) = 0\nIf \\(y \\in W, y \\neq x\\) and \\(\\forall S\\): \\(S \\in\\) K \\(\\supset \\vDash_y^y\\) \\(S\\), then \\(d\\)(\\(x\\), \\(y\\)) = 1\nIf \\(y\\) = \\(i\\) then \\(d\\)(\\(x\\), \\(y\\)) = 2\nOtherwise, \\(d\\)(\\(x\\), \\(y\\)) = 3\n\nLess formally, the nearest world to a world is itself. The next closest worlds are any compatible with everything known in the context, then the impossible world, then the possible worlds incompatible with something known in the context. It may seem odd to have the impossible world closer than some possible worlds, but there are two reasons for doing this. First, in the impossible world everything known to any conversational participant is true. Secondly, putting the impossible world at this position accounts for some examples. This is a variant on a well known case; see for example Gibbard (1981) and Barker (1997).\nJack and Jill are trying to find out how their local representative Kim, a Democrat from Texas, voted on a resolution at a particular committee meeting. So far, they have not even found out whether Kim was at the meeting. Jack finds out that all Democrats at the meeting voted against the resolution; Jill finds out that all Texans at the meeting voted for it. When they return to compare notes, Jack can truly say If Kim was at the meeting, she voted against the resolution, and Jill can truly say If Kim was at the meeting, she voted for the resolution. If \\(i\\) is further from the actual world than some possible world where Kim attended the meeting, these statements cannot both be true.\nIt may be thought the distance function needs to be more fine-grained to account for the following phenomena2. It seems possible that in each of the following pairs, the first sentence is true and the second false.\n2 Lewis (1973) makes this objection to a similar proposal for subjunctives; the objection has just as much force here as it does in the original case.\n\nIf Anne goes to the party, so will Billy.\nIf Anne goes to the party, Billy will not go.\n\n\nIf Anne and Carly go to the party, Billy will not go.\nIf Anne and Carly go to the party, so will Billy.\n\n\nIf Anne, Carly and Donna go to the party, so will Billy.\nIf Anne, Carly and Donna go to the party, Billy will not.\n\n\nAssume, as seems plausible, it is necessary and sufficient for \\(A \\rightarrow B\\) to be true that the nearest \\(A \\wedge B\\) world is closer than the nearest \\(A\\wedge \\neg B\\) world. (This does not immediately follow from the analysis in section 2, but is obviously compatible with it.) Given this, there is no context in which the first conditional in each pair is true, and the second false. McCawley (1996) points out a way to accommodate these intuitions. Every time a conditional is uttered, or considered in a private context, the context shifts so as to accommodate the possibility that its antecedent is true. So at first we don’t consider worlds where Carly or Donna turn up, and agree that (19a) is true and (19b) false because in those worlds Billy loyally follows Anne to the party. When (20a) or (20b) is uttered, or considered, we have to allow some worlds where Carly goes to the party into the context set. In some of these worlds Anne goes to the party and Billy doesn’t, the worlds where Carly goes to party. A similar story explains how (21a) can be true despite (20b) being false.3\n3 There is an obvious similarity between this argument and some of the uses of contextual dependence in Lewis’s theory of knowledge (Lewis 1996). Indeed, McCawley credits Lewis (1979b) as an inspiration for his ideas.This move does seem to save the theory from potentially troubling data, but without further support it may seems rather desperate. There are two independent motivations for it. First, it explains the inappropriateness of (6).\n\n*Grannie won, but if she lost she was furious.\n\nIf assertion narrows the contextually relevant worlds to those where the assertion is true, as Stalnaker (1978) suggests, and uttering a conditional requires expanding the context to include worlds where the antecedent is true, it follows that utterances like (6) will be defective. The speech acts performed by uttering each clause give the hearer opposite instructions regarding how to amend the context set. Secondly, McCawley’s assumption explains why we generally have little use for indicative conditionals whose antecedents we know are false. To interpret an indicative we first have to expand the context set to include a world where the antecedent is true, but if we know the antecedent is false we usually have little reason to want to do that. If there is a dispute over the size of the context set, we may want to expand it so as to avoid miscommunication, which explains why we will sometimes assert conditionals with antecedents we know to be false when trying to convince someone else that the antecedent really is false.\nSo we have a pair of measures that give plausible answers on a wide range of cases. Such a pair should also validate the close connection between indicatives and subjunctives we saw earlier. The data set out in section one suggests that this connection may be close to synonymy, as in (1), but in some cases, as in (11) and (12), the connection is much looser. The differing behaviour of rigid designators in indicatives and subjunctives reveals a further difference, but the two-dimensional nature of the analysis, not the particulars of the similarity metric, accounts for that. I propose to explain the data by looking at which facts we hold fixed when trying to determine the nearest possible world. The facts we hold fixed in evaluating indicatives and subjunctives, according to the two metrics outlined above, are the same in just the cases we feel that the indicatives and subjunctives say the same thing.\nWhen evaluating an indicative we hold fixed all the facts known by any member of the conversation. When evaluating a subjunctive we hold fixed (a) all facts about the world up to some salient time t and (b) the holding of the laws of nature at all times after t. The time t is the latest time such that some worlds fitting this description make \\(A\\) true and contain no large miracles. The two sets of facts held fixed match when we know all the salient facts about times before t, and know no particular facts about what happens after t.\nIn the opinion poll case, when evaluating the original indicative our knowledge at the earlier time was held fixed. We knew that the polls predicted a Reagan landslide, that when one makes spectacularly false predictions one is discredited, and so on. When we turn to evaluating the subjunctive, we hold fixed the facts about the world before the election (presumably the relevant time t) and some laws. Therefore, we hold fixed the polls predictions, and the law that when one makes spectacularly false predictions one is discredited. So the same facts are held fixed. And in general, this will happen whenever all we know is all the specific facts up to the relevant time, and some laws that allow us to extrapolate from those facts.\nIn the case where indicatives and subjunctives come apart, as in (11) and (12), the relevant knowledge differs from the first case. By hypothesis, we do not know who pulled the trigger, but we do know that a trigger was pulled. Our knowledge of the relevant facts does not consist in knowledge of all the details up to a salient time, and knowledge that the world will continue in a law-governed way after this. Therefore, we would predict that the indicatives and subjunctives would come apart, because what is held fixed when evaluating the two conditionals differs. We find exactly that. So the pair of measures can explain the close connection between indicatives and subjunctives when it exists, and explain why the two come apart when they do come apart.\n\n\n3.2 No Nearest Possible World\nGenerally, there are three kinds of problems under this heading. First, there may be no \\(A\\)-worlds, and so no nearest \\(A\\)-world. Secondly, there may be an infinite sequence of ever-nearer \\(A\\)-worlds without a nearest \\(A\\)-world. Thirdly, there may be several worlds in a tie for nearest \\(A\\)-world. If the measure suggested in the previous section is correct, the first two problems do not arise here. The third problem, however, arises almost all the time, so we need to say something about it.\nThe approach I favour is set out in Stalnaker (1981). The comparative similarity measure is a partial order on the possible worlds. Stalnaker recommends we assess conditionals using supervaluations, taking the precisifications to be the complete extensions of this partial order. In particular, if several possible worlds tie for being the closest \\(A\\)-worlds4, then \\(A \\rightarrow B\\) will be true if they are all \\(B\\)-worlds, false if they are all \\(\\neg B\\)-worlds, and not truth-valued otherwise. For consistent \\(A\\), this makes \\(\\neg\\)(\\(A \\rightarrow B\\)) equivalent to \\(A \\rightarrow \\neg B\\). Since we generally deny \\(A \\rightarrow B\\) just when we would be prepared to assert \\(A \\rightarrow \\neg B\\), this seems like a good outcome.5 Further, this account makes \\(A \\rightarrow B\\) generally come out gappy when A is false. Many theorists hold that indicative conditionals, especially those with false antecedents, lack truth values.6 This can’t be right in general, since it is a platitude that \\(A \\rightarrow A\\) is true for every \\(A\\), but the position has some attraction. Happily, our theory respects the motivations behind such positions without violating the platitude.\n4 Of course in this context \\(x\\) is an \\(A\\)- world iff \\(\\vDash_x^x\\) \\(A\\).5 Edgington (1996) furnishes some nice examples against the view that \\(A \\,\\square\\!\\mathord\\to B\\) should be false when there are several equally close \\(A\\)-worlds in a tie for closest and some are \\(B\\)-worlds but some are \\(\\neg B\\)-worlds.6 See Edgington (1995) for an endorsement of this position and discussion of others who have held it.In any case, these details are not important to the overall analysis. If someone favours a resolution of ties along the lines Lewis suggested this could easily be appended onto the basic theory.\n\n\n3.3 The General Theory\nSo far, I have just defined what it is for \\(A \\rightarrow B\\) to be true in this world from the perspective of this world as actual. To have a fully general theory I need to say when \\(A \\rightarrow B\\) is true in an arbitrary world from the perspective of another (possibly different) world as actual. And that general theory must yield the theory above as a special case when applied to our world. As with the special theory above, the general theory will mostly be derived from Twin Earth considerations.\nIn general, \\(\\vDash_y^x\\) \\(A \\rightarrow B\\) iff the nearest world pair \\(\\langle z, v \\rangle\\) such that \\(\\vDash_v^z\\) \\(A\\) is such that \\(\\vDash_v^z\\) \\(B\\). Nearness is again defined epistemically, but what we know about \\(x\\) and \\(y\\) matters. In particular if \\(\\vDash_v^z\\) \\(C\\) for all sentences \\(C\\) such that someone in the context knows that \\(\\vDash_y^x\\)\\(C\\) , but not \\(\\vDash_w^u\\) \\(C\\) for some such \\(C\\) , then \\(\\langle z, v \\rangle\\) is closer to \\(\\langle x, y \\rangle\\) than is \\(\\langle u, w \\rangle\\). As should be clear from this, nearness is context-dependent, and the context it depends on is the actual speaker’s context. For conditionals as for quantified sentences, the same words will express different propositions in different contexts.\nLet’s draw out some consequences of this definition. First, for any \\(x\\) we know that \\(\\vDash_x^x\\) \\(C\\) for all a priori propositions \\(C\\). In particular, we know that \\(\\vDash_x^x\\)\\(D \\equiv\\) (Actually \\(D\\)) for any proposition \\(D\\), where ‘\\(\\equiv\\)’ represents the material biconditional. So the nearest world pair \\(\\langle z, v \\rangle\\) to \\(\\langle x, x \\rangle\\) must be one in which \\(z = v\\), even if that means \\(z\\) is the impossible world \\(i\\). Hence the general theory of indicatives reduces to the special theory set out above when applied to epistemically possible worlds: when assessing the truth value of an indicative in an epistemically possible world pair we need only look at other epistemically possible world pairs.\nSecondly, when evaluating conditionals with respect to epistemically impossible world pairs \\(\\langle x, y \\rangle\\), we need to use other epistemically impossible world pairs. For example, imagine some explorers are wandering around Twin Australia, a dry continent to the south of Twin Earth. As explorers of such lands are wont to do, they are dying of thirst, so they are seeking some watery stuff to save themselves. Without knowing whether they succeed, we know (22) is false.\n\nIf the explorers find some watery stuff, they will find some water.\n\nThis theory can explain the falsity of (22). We know, from the way Twin Earth is stipulated, that all the watery stuff of the explorers’ acquaintance is not water. So we know any watery stuff they find will not be water. And we know that water is scarce on Twin Earth, even scarcer than watery stuff in Twin Australia, so it is unlikely they will find some watery stuff and simultaneously stumble across some water.\nThis theory also explains occurrences of indicatives embedded in subjunctives. These are very odd, as should be expected if indicatives are about epistemic connections and subjunctives about metaphysical connections, but we can just make sense of them some of the time. For example, it seems possible to make sense of (23) and that it is true.\n\nIf the bullet that actually killed JFK had instead killed Jackie Kennedy, then it would be true that if Oswald didn’t kill Jackie Kennedy, someone else did.\n\nOn our theory, to evaluate this we first find the nearest world pair \\(\\langle @, w \\rangle\\) such that \\(\\vDash_w^@\\) The bullet that actually killed JFK instead killed Jackie Kennedy, and then evaluate the indicative relative to it. Now one thing we know about this world pair is that in it, someone killed Jackie Kennedy. So this must hold in all nearby world pairs. Hence in any such world pair that Oswald did not kill Jackie Kennedy, someone else did, so (23) turns out true.\nIt might be thought that such embeddings do not make particularly good sense. I have some sympathy for such a view. If one adopts the ‘special theory’ developed in the previous section, and rejects the general theory developed in this subsection, one may have an explanation for the impossibility of such embeddings. However, even if we cannot make sense of such embeddings, we still need to account for the truth conditions of indicatives relative to epistemically impossible world pairs to make sense of claims such as Necessarily (\\(A \\rightarrow A\\)).7\n7 I am indebted to Lloyd Humberstone for pointing this out to me.\n\n3.4 Classifying Conditionals\nIn recent years, there has been extensive debate over where the line between indicatives and subjunctives falls. This debate focuses on whether ‘future indicatives’ like (24) are properly classified with indicatives or subjunctives.\n\nIf Booth doesn’t shoot Lincoln, someone else will.\n\nJackson (1990) and Bennett (1995) argue that this should go with ordinary indicatives. Dudman (1994) and Bennett (1988) argue that it should go with ordinary subjunctives, though this is not how Dudman would put it. This theory of indicatives appears to favour Jackson and (the later) Bennett, because of the apparent triviality of conditionals like (25).\n\nIf it will rain then it will actually rain."
  },
  {
    "objectID": "posts/indsub/indicative-and-subjunctive-conditionals.html#conclusion",
    "href": "posts/indsub/indicative-and-subjunctive-conditionals.html#conclusion",
    "title": "Indicative and Subjunctive Conditionals",
    "section": "4 Conclusion",
    "text": "4 Conclusion\nDespite its lack of attention in the literature, data about the role of rigid designators in indicatives deserve close attention. Any plausible theory of indicatives must be able to deal with it, and it isn’t clear how existing possible worlds theories could do so. The easiest way to build a semantics for indicatives is to say that “If \\(A\\) then \\(C\\)” is true just in case the nearest world in which \\(A\\) is true is a world where \\(C\\) is true. Even before the hard questions about the meaning of ‘nearest’ here start to be asked, we know a theory of this form is wrong because it makes mistaken predictions about the role of rigid designators. A conditional like “If the stuff in the rivers, lakes and oceans really is XYZ, then water is XYZ” is true, even though the consequent is true in no possible worlds. The simplest way to solve this difficulty is to revisit the idea of ‘true in a world’. Rather than looking for a nearby world in which \\(A\\) is true, and asking whether \\(C\\) is true in it, we look for a nearby world \\(w\\) such that \\(A\\) is true under the supposition that \\(w\\) is actual, and ask whether \\(C\\) is true under the supposition that \\(w\\) is actual. In the terminology of Jackson (1998), we look at worlds considered as actual, rather than worlds considered as counterfactual. This simple change makes an important difference to the way rigid designators behave. There is no world in which water is XYZ. However, under the supposition that the stuff in the rivers, lakes and oceans really is XYZ, and the H2O theory is just a giant mistake, that is, under the supposition that we are in the world known as Twin Earth, water is XYZ. In short, “water is XYZ” is true in Twin Earth considered as actual, even though it is false in Twin Earth considered as counterfactual. So the data about behaviour of rigid designators in indicatives, data like the truth of “If the stuff in the rivers, lakes and oceans really is XYZ, then water is XYZ”, does not refute the hypothesis that “If \\(A\\) then \\(C\\)” is true iff the nearest world such that \\(A\\) is true in that world considered as actual is a world where \\(C\\) is true in that world considered as actual.\nIn section two we looked at how the formal structure of a theory built around that hypothesis might look. In section three we looked at how some of the details may be filled in. The most pressing task is to provide a similarity metric so we can have some idea about which worlds will count as being nearby. The theory I defended has three important features. First, it is epistemic. Which worlds are nearby depends on what is known by conversational participants. Secondly, it is contextualist in two respects. The first respect is that it is the knowledge of the audience that matters, not just the knowledge of the speaker and the intended audience. The second respect is that it allows that what is known by the audience may be affected by the utterance of the conditional. In particular, if the utterance of “If \\(A\\), \\(B\\)” causes the audience to consider \\(A\\) to be possible, and hence cease to know that \\(\\neg A\\), then \\(A\\) is not part of what is known for purposes of determining which worlds are nearby. (I assume here a broadly contextualist account of knowledge, as in Lewis (1996), but this is inessential. If you do not like Lewis’s theory, replace all references to knowledge here, and in section 3.1, with references to epistemic certainty. I presume that what is epistemically certain really is contextually variable in the way Lewis suggests.) Thirdly, it is coarse- grained: whether a world is nearby depends only on whether it is consistent with what is known, not ‘how much’ it agrees with what is known. The resultant theory seems to capture all the data, to explain the generally close connection between indicatives and subjunctives, and to explain the few differences which do arise between indicatives and subjunctives.\nThe other detail to be filled in concerns embeddings of indicatives inside subjunctives. The formalism here requires that we use the full resources of two- dimensional modal logic, but the basic idea is very simple. Consider a sentence of the form “If it were the case that \\(A\\), it would be the case that if \\(B\\), \\(C\\) .” Roughly, this will be true iff the metaphysically nearest world in which \\(A\\) is true, call it \\(w_A\\), is a world where \\(B \\rightarrow C\\) is true. And that will be true iff the epistemically nearest world to \\(w_A\\) is which \\(B\\) is true is a world where \\(C\\) is true. Less roughly, we have to quantify not over worlds, but over pairs of worlds, where the first element of the pair determines the reference for rigid designators, and the second element determines the truth of sentences given those references. But this only adds to the formal complexity; the underlying idea is still the same. The important philosophical point to note is that when we are trying to find the epistemically nearest world to \\(w_A\\) (or, more strictly, the nearest world pair to \\(\\langle @, w_A \\rangle\\)) the facts that have to be held fixed are the facts that we know about \\(w_A\\), not what our counterparts in \\(w_A\\), or indeed what any inhabitant of \\(w_A\\) knows about their world. These embeddings may be rare in everyday speech, but since they are our best guide to the truth values of indicatives in other possible worlds, they are theoretically very important."
  },
  {
    "objectID": "posts/bqb/begging-the-question-and-bayesians.html",
    "href": "posts/bqb/begging-the-question-and-bayesians.html",
    "title": "Begging the Question and Bayesians",
    "section": "",
    "text": "The arguments for Bayesianism in the literature fall into three broad categories. There are Dutch Book arguments, both of the traditional pragmatic variety and the modern ‘depragmatised’ form. And there are arguments from the so-called ‘representation theorems’. The arguments have many similarities, for example they have a common conclusion, and they all derive epistemic constraints from considerations about coherent preferences, but they have enough differences to produce hostilities between their proponents. In a recent paper, Maher (1997) has argued that the pragmatised Dutch Book arguments are unsound and the depragmatised Dutch Book arguments question begging. He urges we instead use the representation theorem argument as in Maher (1993). In this paper I argue that Maher’s own argument is question-begging, though in a more subtle and interesting way than his Dutch Book wielding opponents.\n\nPublished in Studies in History and Philosophy of Science Part A 30: 687-697.\nPicture by ankakay via Creative Commons.\n\n\n0.1 Bayesianism\nWhat’s a Bayesian? The term these days covers so many different positions that the only safe course is to strictly define what one means by the term. The alternative, as the discussion in Walley (1996) shows, is to have one of the least interesting semantic debates ever held. I define a Bayesian to be one who is committed to two theses, which I’ll call (B1) and (B2).\n\n(B1)\n\nBelief comes by degrees.\n\n(B2)\n\nIt is a requirement of consistency that these degrees of belief, or credences, be consistent with the probability calculus.\n\n\nI should explain (B2) a little. Historically, Bayesians held that credences were, or at least ought be, reals in [0, 1], and the function Bel which takes any proposition into the agent’s credence in that proposition should be a probability function. Modern Bayesians, following Levi (1980) and Jeffrey (1983), allow that credences can be imprecise. In this case the consistency requirement is that there be some precisification of their credences which is a probability function. (B2) is deliberately ambiguous between the traditional and modern Bayesian positions, largely because nothing in this debate turns on this question1.\n1 Historically the impetus for allowing imprecise credences was the economic distinction between insurable and uninsurable risks, as discussed in Knight (1921), Keynes (1937), Tintner (1941) and Hart (1942).There are many other properties that could have been used to define Bayesians. For example, it could be suggested that it is requirement of being a Bayesian that one think rules like (B2) are derived by analysing credences as dispositions to bet. This is suggested by Kaplan (1993, 320) to be the “fundamental Bayesian insight”. Or it could be argued that being a Bayesian requires some an extra rule to the effect that credences are updated by conditionalisation. I haven’t included that for two reasons. First, I’m mostly interested in static constraints on credences, and secondly, some paradigm Bayesians like Levi (1980) and Fraassen (1989) reject this rule in its fully general form. Finally it might be suggested that Bayesians aren’t those that believe certain principles like (B1) and (B2), but only those who think these principles provide the foundation for all philosophy of science. So perhaps my definition is a bit liberal.\nNow it is well known that not everyone’s a Bayesian. One group of non-Bayesians who have received too little attention from their Bayesian rivals are those who accept (B1) but not (B2). That is, theorists who agree there are such things as credences, and even that credences are important for philosophy of science, but not that they ought be constrained by the probability calculus. The most interesting example is the theory of evidence developed by Dempster (1967, 1968) and Shafer (1976)\nDempster and Shafer, like many other theorists, think that when we have no evidence either for or against p, we should have low credences in both p and \\({\\lnot}\\)p. In the limit case it is acceptable to have our credence in both p and in \\({\\lnot}\\)p set at zero. Now this is in conflict with (B2), for it is a theorem of the probability calculus that Pr(p) + Pr(\\({\\lnot}\\)p) = 1, and so by (B2) it is a requirement of rationality that Bel(p) + Bel(\\({\\lnot}\\)p) = 0.\nThis intuition about cases where the evidence is low is formalised in a rather neat theory. For simplicity I’ll say how the theory works when we are interested in finitely many propositions; Shafer shows the infinite case can be dealt with but it doesn’t raise any philosophically interesting differences. We are interested in n propositions, so the possibility space contains 2n ‘worlds’. A proposition A can be identified in the usual ways with the set of worlds at which it is true. The Bayesian has us place a normalised measure on this possibility space, with our credence in A being the measure of the set A. In Dempster and Shafer’s theory we place a normalised measure, which they call a ‘mass function’ on the power set of the worlds, excluding the null set. Our credence in A is calculated as the measure of the set of sets which are subsets of A. So in the simplest case, where we are just interested in one proposition p, the mass function is defined on {{p}, {\\({\\lnot}\\)p}, {p, \\({\\lnot}\\)p}}. Complete ignorance is represented by giving {p, \\({\\lnot}\\)p} mass one, and the other sets mass zero. Hence both Bel(p) and Bel(\\({\\lnot}\\)p) are zero. On the other hand, Bel(p \\({\\vee}\\) \\({\\lnot}\\)p) will be one, as is Bel(C) for any classical tautology C. As a consequence of this we will not have the addition rule.\n\nAddition:\n\nFor disjoint A, B, Bel(A \\({\\vee}\\) B) = Bel(A) + Bel(B)\n\n\nSince Bayesians believe in Addition and some opponents do not, arguments for Bayesianism should be inter alia arguments for Addition. I don’t want to argue that Dempster and Shafer’s theory is right. It has some internal problems, particularly with updating, which make it look not too promising as a general theory of evidence. The recent collection edited by Yager, Fedrizzi, and Kacprzyk (1994) has papers dealing with many of these issues for the interested reader. My interest in this theory is merely to show the kind of theorist the Bayesian must argue against. This is particularly important when the alleged problem with arguments for Bayesianism is that they are question-begging.\nAs a last point about the Dempster-Shafer theory it might be noted that not only does Addition fail for credences, the equivalent rule for valuing bets also fails. Put formally, let an A-bet be a bet which pays £1 if A and nothing otherwise. It is consistent with the Dempster-Shafer theory to say the value of an A-bet is always £Bel(A). So on this theory it is not the case that for disjoint A, B it is true that the value of an (A \\({\\vee}\\) B)-bet always equals the value of an A-bet plus the value of a B-bet.\nSince it is sometimes thought there is an argument showing this to be incoherent, it is worthwhile giving a partial defence of its consistency. An argument like the following appears, as we’ll see, to be endorsed by Maher. There exists a voucher which is an (A \\({\\vee}\\) B)-bet, a ticket which is an A-bet and a coupon which is a B-bet. Now anyone holding the ticket and the coupon will receive exactly the same payout in all circumstances as anyone holding the voucher, hence they must have the same value. Hence the value of the voucher is the value of the ticket plus the value of the coupon. The problem with this argument is that it assumes the ticket and the coupon are not what economists call complementary goods. Some goods, like say compact discs, have more value to a consumer if they hold certain other goods, like compact disc players. On the Dempster-Shafer theory, the ticket and the coupon may well be complementary goods. To anyone holding the ticket, the value of the coupon is the difference between value of the voucher and the value of the ticket, that is, Bel(A \\({\\vee}\\) B) - Bel(A). This will in general be greater than its ‘intrinsic’ value Bel(B). But this goes no way to showing that its value to someone without the ticket must be greater than Bel(B). This, in rough outline, is the objection Schick (1986) makes to Dutch Book arguments. So arguments for Addition which assume that A-bets and B-bets are not complements will beg the question against proponents of the Dempster-Shafer theory, who have a principled reason to reject that assumption.\n\n\n0.2 Dutch Book Arguments\nAs I mentioned above, there are three broad categories of arguments for Bayesianism, two breeds of Dutch Book arguments and ‘representation theorem’ style arguments. In this section I’ll briefly deal with the Dutch Book arguments before looking at Maher’s version of the representation theorem argument in section 3.\nThe classic, pragmatic, Dutch Book argument, assumes that appropriate circumstances exist whereby the amount an agent would be prepared to pay for any A-bet is £Bel(A). Indeed, they assume this not only is true, but that it would remain true while the agent starts trading in bets. Given these assumptions, if the agent’s credences are not a probability function, a clever bookie who knows just their credences can sell them a ‘Dutch Book’ which is guaranteed to lose in all circumstances.\nEveryone’s got their favourite objection to this argument, so I won’t spend much time on it here. Maher (1993, 98) argues that the declining marginal utility of money means that this won’t work for pounds, and since there is no currency with a constant marginal utility this flaw can’t be resolved. This is a rather odd objection since Savage (1954) argued long ago that we could get around this problem by using bets denominated in lottery tickets. As mentioned above, Schick (1986) takes the possibility of complementary bets to be a crushing blow to the argument. My favourite objection turns on the distinction that Adam Smith famously drew attention to between the usefulness of a good and its market value. Bel(A) can determine, at most, the usefulness of an A-bet, so at disequilibrium a coherent agent should probably not trade A-bets for £Bel(A). And since there’s Dutch Books to be sold we must be at disequilibrium, so the initial assumption about ‘appropriate circumstances’ must be false. In any case, there are enough different objections to this argument that we can safely move on.\nThe depragmatised Dutch Book arguments, as in Howson and Urbach (1989), Christensen (1996) and Hellman (1997), do away with the prospect of a bookie actually milking the poor incoherent agent. Rather they use similar reasoning to show that there is something wrong with an agent whose credences are not probability functions. I will concentrate on Christensen’s argument, but similar comments apply to the other two arguments.\nChristensen does not believe that an agent who’s credence in A is x should be prepared to buy a A-bet for £A. However he does say that the agent should “evaluate such [trades] as fair” (Christensen 1996, 456). So credences may ‘sanction’ (his term) certain odds even if the agent does not desire to accept these sanctioned bets. This may come about because of the declining marginal utility of the currency in which the bets are denominated, or because of a dislike of gambling, or possibly because of the discrepancy I mentioned between use-value and exchange-value. Now making the safe enough assumption that credences that sanction trades which lead to sure loss are defective he concludes that credences which do not satisfy the probability calculus are defective.\nHowever, Maher (1997, 301–3) points out, the argument so far doesn’t get the conclusion Christensen wants. Indeed for some simple Shafer functions which are not probability functions no sure-loss trades will be sanctioned. To get Christensen’s conclusion, we need the extra premise that if two trades are sanctioned their sum is sanctioned. Equivalently, we need the premise that what bets are sanctioned is independent of what bets are already held. But given the definition of ‘sanction’ this just is the premise that credences must satisfy Addition. So the argument is question-begging against the writer who denies Addition. Maher shows that similar problems beset the arguments in Howson and Urbach (1989) and Hellman (1997).\n\n\n0.3 Representation Theorems\nThe alternative Maher supports is based around ‘representation theorems’. A similar approach is taken by Kaplan (1996), but I’ll focus on Maher. In any case, the issues that arise are exactly the same. The basic idea is that it is a requirement on the coherence of an agent’s preferences that there exist a probability function and a set of utility functions equivalent up to affine transformation such that the agent prefers gamble f to g iff the expected utility of f given the probability function and any of the utility functions is greater than that of g. The probability function will give us the agent’s credences in all propositions. Preferences are decreed to be coherent if they satisfy a number of axioms that Maher defends. For example, it is required that preferences be transitive, that an agent not prefer f to g and prefer g to f, and so on. The claim here is that the defence of these axioms begs the question against a supported of the Dempster-Shafer approach.\nStrictly Maher does not quite believe that all coherent credence functions are probability functions. The argument to that conclusion requires that preferences be complete, and Maher does not think this is plausible. If we drop that assumption we get the conclusion that the agent’s credences should be represented by sets of probability functions as in Levi and Jeffrey, not a single probability function. However for convenience he assumes first that completeness holds, and I’ll follow this lead. Nothing pertaining to the success or otherwise of the argument turns on this point.\nThere are a few immediate problems with this approach. Maher needs to assume that if an agent has a higher credence in p than in q they will prefer a p-bet to a q-bet. The problem is that when it is unlikely that we will ever see p or \\({\\lnot}\\)p confirmed we may well prefer a q-bet to a p-bet even if we have a higher degree of belief in p. I would prefer a bet on the Yankees winning the next World Series to a bet on Oswald being Kennedy’s assassin, even though I have a higher degree of belief in Oswald’s guilt than the Yankees’s success, because betting on the Yankees gives me some chance of getting a payout.\nMaher is aware of this point, but his attempt to dispose of it is disastrous. His example is comparing a bet on the truth of the theory of evolution, construed as the claim that all life on earth is descended from a few species, with betting on its negation Maher (1993, 89). Taking scientists as his expert function he asks some biologists which of these bets they would prefer, on the assumption that there are extraterrestrials who have been observing earth from its formation and will adjudicate on the bet. He is rather happy that they all plump for betting on Darwin. But this is a perfectly useless result. The objection was that we can have degrees of belief on unverifiable propositions, but our attitudes to bets on these propositions will be quite different to our attitude towards bets on verifiable propositions. He has attempted to counter this by simply making the problematic proposition verifiable. When we drop the assumption that there are extraterrestrials, so the theory of evolution would become unverifiable, presumably most people would (strictly) prefer a bet on a fair coin landing heads to either a bet on the theory of evolution or its negation. Preferences in a situation when the theory is verifiable are completely irrelevant to the problem unverifiable theories pose for Bayesian philosophies of science. So we have a problem, although I’d be prepared to accept for the sake of the argument it can be finessed.\nThe major problem for Maher is that his argument is just as question-begging as the Dutch Book arguments he criticises, though in a more subtle and interesting way. For Maher’s argument to work we have to accept some constraints on preferences, such as transitivity. His argument is only as strong as the argument for these constraints. He has nine axioms which must be justified in some way2. The most interesting is Independence, which he construes as follows. D is a set of gambles and X a set of propositions, f \\({\\leq}\\) g means the agent either prefers g to f or is indifferent between them, f \\({\\equiv}\\) g means that f and g are exactly the same gamble, they have the same payouts in all possible worlds, and f \\({\\equiv}\\) g on A means that on all possible worlds in which A, f and g have the same payouts.\n2 There is a further axiom designed to guarantee countable additivity, but that raises independent problems and won’t be discussed here.\nIndependence\n\nFor all f, f\\(^\\prime\\), g, g\\(^\\prime\\) \\({\\in}\\) D and A \\({\\in}\\) X, if f \\({\\equiv}\\) f \\(^\\prime\\) on A, g \\({\\equiv}\\) g\\(^\\prime\\) on A, f \\({\\equiv}\\) g on \\({\\lnot}\\)A, f \\(^\\prime\\) \\({\\equiv}\\) g\\(^\\prime\\) on \\({\\lnot}\\)A and f \\({\\leq}\\) g then f \\(^\\prime\\) \\({\\leq}\\) g\\(^\\prime\\) (Maher 1993, 190)\n\n\nThe idea is that if f and g have the same payouts given some proposition, say A, our preference between f and g should be independent of its value. All that matters, according to this idea, is the comparative fact that if A turns out true f and g have identical payouts, so whichever of the bets is preferred given \\({\\lnot}\\)A should be preferred overall. The most famous examples where intuition says this may be violated are the Allais and Ellsburg ‘paradoxes’. Since uncertainty plays a larger role in it, I’ll briefly sketch the Ellsburg paradox. An urn contains 90 balls. Thirty of these are yellow, and remainder are either black or red in unknown proportion. The payouts for the four gambles in question are given in this table.\n\n\n\n\n \nRed\nBlack\nYellow\n\n\nf\n£1\n0\n0\n\n\ng\n0\n0\n£1\n\n\nf\\(^\\prime\\)\n£1\n£1\n0\n\n\ng\\(^\\prime\\)\n0\n£1\n£1\n\n\n\n\nMany subjects prefer g to f, since they know the chance of a yellow ball being drawn but not that of a red ball, but prefer f\\(^\\prime\\) to g\\(^\\prime\\) since they know the chance of a red or black ball being drawn but not that of a black or yellow ball. This is easily justifiable under the Dempster-Shafer approach. Let B, R and Y be the propositions that a black, red and yellow ball respectively is drawn. Given the evidence about the composition of the urn, it seems plausible to set Bel(B) = Bel(R)=0, Bel(Y)=Bel(Y\\({\\vee}\\)B) = Bel(Y\\({\\vee}\\)R) = \\(\\frac{1}{3}\\) and Bel(B\\({\\vee}\\)R) = \\(\\frac{2}{3}\\). Bayesians say this is coherent, but it is perfectly acceptable under a Dempster-Shafer theory. Given these credences, the value of f is £0, and the value of g is £\\(\\frac{1}{3}\\). However the value of f\\(^\\prime\\) is £\\(\\frac{2}{3}\\) while the value of g\\(^\\prime\\) is just £\\(\\frac{1}{3}\\). Hence it is not only acceptable, but arguably a requirement of rationality that an agent prefer g to f but f\\(^\\prime\\) to g\\(^\\prime\\).\nWith these preferences, and setting A to ‘A black ball is not drawn’ we can see this violates Maher’s independence axiom. No objection yet, many people are just irrational. The real problem arises with Maher’s argument that people who choose in this way are irrational. The following two choice trees set out two ‘tree form’ versions of the choices facing these subjects.\n\nThe left-hand tree represents the choice between f and g. The subject is told that if a black ball is drawn they will receive nothing, but if it is not drawn they will have a choice between betting on red and betting on yellow. So far we have a standard enough dynamic choice problem. Maher proposes to make it synchronic by requiring that subjects specify in advance what they would do if they reached the square, that is if a black ball is not drawn. This, he claims, makes the situation exactly as if the agent was choosing between f and g. Now the right-hand tree is the same as the left-hand tree in all respects but one. If a black ball is drawn the agent receives £1, not nothing. But the only choice the agent has to make is exactly the same as in the left-hand tree, so they ought make the same choice. We can concede to Maher here that it would be irrational to specify, in advance, a preference for g over f in the left-hand tree and for f\\(^\\prime\\) over g in the right-hand tree. This is, however, insufficient for his conclusion.\nThe problem lies in his assumption that “it seems uncontroversial that the consequences a person values are not changed by representing the options in a tabular or tree form” Maher (1993, 71). As Seidenfeld (1994) makes clear, this is exactly what is controversial in these circumstances. Indeed this premise, call it Reduction, is expressly denied by a number of heterodox decision theorists, and by writers who deny Addition on the occasions they talk about decision theory. There is a good reason for this. As noted above, on the Dempster-Shafer theory, Bel(B\\({\\vee}\\)R)may be greater than Bel(B)+Bel(R). When evaluating the worth of choosing f\\(^\\prime\\) in the original, tabular, it seems plausible that it is Bel(B\\({\\vee}\\)R) that matters, not Bel(B)+Bel(R). However in the tree form problem all that matters to f\\(^\\prime\\) is Bel(B), for the possibility that we won’t need to choose, and Bel(R), for the possibility that we do.\nThe point is that Maher has to either assume agents only consider Bel(B) and Bel(R) when assessing f\\(^\\prime\\), not Bel(B\\({\\vee}\\)R), or that Bel(B\\({\\vee}\\)R) is some function of Bel(B) and Bel(R) so that we can ignore that complication, in his ‘uncontroversial’ assumption. The first option is implausible, surely when comparing f\\(^\\prime\\) and g\\(^\\prime\\) we just compare Bel(B\\({\\vee}\\)R) with Bel(B\\({\\vee}\\)Y). More interestingly, I claim that the second is question-begging. Given that virtually everyone agrees that in some cases, for example lotteries, degrees of belief should be probability functions, in some cases the function which gives us Bel(B\\({\\vee}\\)R) from Bel(B) and Bel(R) must be addition. Hence he must assume that Bel(B\\({\\vee}\\)R) = Bel(B)+Bel(R) for the move from tabular to tree form to be plausible. But this is just what he was trying to prove, so the argument is question-begging.\n\n\n0.4 Conclusion\nMaher rightly objects to depragmatised Dutch Book arguments on the ground that they are question-begging. That is, they use their conclusion as an implicit premise. It is argued here that the same objection applies to Maher’s argument for Bayesianism. He relies on the reducibility of tree form decisions to table form decisions, but the only justification for this could be a reliance on Addition. But Addition was what he was trying to prove all along, so he isn’t allowed to take Reduction as a premise.\nThere are three moves that Maher could make here. First, he could say that Reduction is so obvious that it should be acceptable as a premise without justification. The resulting argument may be effective at convincing some agnostics about Bayesianism that their implicit assumptions all along were Bayesian, but it would be completely ineffective against the sceptics about Bayesianism I have been discussing. Secondly, he could come up with a new argument for Reduction that I haven’t considered here and isn’t vulnerable to this objection. Given the conclusions of the last section I doubt this is possible, but the ingenuity of philosophers shouldn’t be underestimated. Thirdly, and most interestingly, he could look for justifications of Bayesianism that do not rely on construing credences as dispositions to bet. Since the arguments from considerations about preferences to constraints on credences have so far all failed, the time might be right to look at the problem from a different direction.\n\n\n\n\n\n\nReferences\n\nChristensen, David. 1996. “Dutch-Book Arguments De-Pragmatized: Epistemic Consistency for Partial Believers.” Journal of Philosophy 93 (9): 450–79. https://doi.org/10.2307/2940893.\n\n\nDempster, Arthur. 1967. “Upper and Lower Probabilities Induced by a Multi-Valued Mapping.” Annals of Mathematical Statistics 38: 325–39. https://doi.org/10.1214/aoms/1177698950.\n\n\n———. 1968. “A Generalisation of Bayesian Inference.” Journal of the Royal Statistical Society Series B 30: 205–47.\n\n\nFraassen, Bas van. 1989. Laws and Symmetry. Oxford: Clarendon Press.\n\n\nHart, A. G. 1942. “Risk, Uncertainty and the Unprofitability of Compounding Probabilities.” In Studies in Mathematical Economics and Econometrics, edited by F. McIntyre O. Lange and T. O. Yntema., 110–18. Chicago: University of Chicago Press.\n\n\nHellman, Geoffery. 1997. “Bayes and Beyond.” Philosophy of Science 64 (2): 191–221. https://doi.org/10.1086/392548.\n\n\nHowson, Colin, and Peter Urbach. 1989. Scientific Reasoning. La Salle: Open Court.\n\n\nJeffrey, Richard. 1983. “Bayesianism with a Human Face.” In Testing Scientific Theories, edited by J. Earman (ed.). Minneapolis: University of Minnesota Press.\n\n\nKaplan, Mark. 1993. “Confessions of a Modest Bayesian.” Canadian Journal of Philosophy 23 (sup1): 315–37. https://doi.org/10.1080/00455091.1993.10717353.\n\n\n———. 1996. Decision Theory as Philosophy. Cambridge: Cambridge University Press.\n\n\nKeynes, John Maynard. 1937. “The General Theory of Employment.” Quarterly Journal of Economics 51 (2): 209–23. https://doi.org/10.2307/1882087.\n\n\nKnight, Frank. 1921. Risk, Uncertainty and Profit. Chicago: University of Chicago Press.\n\n\nLevi, Isaac. 1980. The Enterprise of Knowledge. Cambridge, MA.: MIT Press.\n\n\nMaher, Patrick. 1993. Betting on Theories. Cambridge: Cambridge University Press.\n\n\n———. 1997. “Depragmatised Dutch Book Arguments.” Philosophy of Science 64 (2): 291–305. https://doi.org/10.1086/392552.\n\n\nSavage, Leonard. 1954. The Foundations of Statistics. New York: John Wiley.\n\n\nSchick, Frederick. 1986. “Dutch Bookies and Money Pumps.” Journal of Philosophy 83 (2): 112–19. https://doi.org/10.2307/2026054.\n\n\nSeidenfeld, Teddy. 1994. “When Normal and Extensive Form Decisions Differ.” In Logic, Methodology and Philosophy of Science, edited by Brian Skyrms Dag Prawitz and Dag Westerståhl, 451–63. Amsterdam: Elsevier.\n\n\nShafer, Glenn. 1976. A Mathematical Theory of Evidence. Princeton: Princeton University Press.\n\n\nTintner, Gerhard. 1941. “The Theory of Choice Under Subjective Risk and Uncertainty.” Econometrica 9 (3/4): 298–304. https://doi.org/10.2307/1907198.\n\n\nWalley, Peter. 1996. “Inferences from Multinomal Data: Learning about a Bag of Marbles (with Discussion).” Journal of the Royal Statistical Society Series B 58: 3–57.\n\n\nYager, R., M. Fedrizzi, and J. Kacprzyk, eds. 1994. Advances in the Dempster- Shafer Theory of Evidence. New York: John Wiley."
  },
  {
    "objectID": "posts/borge/the-sporting-attitude.html",
    "href": "posts/borge/the-sporting-attitude.html",
    "title": "The Sporting Attitude",
    "section": "",
    "text": "Steffen Borge’s The Philosophy of Football (Borge 2019) is a really great contribution to philosophy of sport. More than that, it shows how questions in metaphysics, aesthetics, and philosophy of mind can be illuminated by looking at them through the perspective of sport. I’m going to focus on one particular question he raises, primarily in chapter 3. What attitude towards a game should players take? What is, to use Suits’s terminology (Suits 1978), the lusory attitude that goes along with playing a sport.\n\nPublished in Sport, Ethics and Philosophy 16(3): 353-361.\nImage by IQRemix via Creative Commons.\n\nThere are actually three distinct questions here that are worth separating. I’m going to start with the first, but as we’ll see, I’m going to end up having more to say about the second and the third.\n\nWhat attitude to the game must players have if they are to play the game?\nWhat attitude to the game should players have if they are playing the game?\nWhat attitude must players generally have if the game is to be the game that it is?\n\nBorge argues that Suits’s answer to question 1 is much too strong, and I’m mostly inclined to agree. But I think the answers he gives to 1 and 3 are too weak. And thinking about question 2 will help us see why.\nTo start, let’s think about why we might be interested in question one in the first place. Imagine someone, call him George, who stands on a football field, but doesn’t act like a footballer. When the ball comes to him, he catches it, or picks it up, and runs towards the opposite goal line. If he makes it there, he places the ball over the goal line in celebration. George isn’t playing football - he’s playing rugby. (Or, perhaps, he’s trying to play rugby and not really succeeding at playing anything, since there clearly isn’t a rugby game going on.) Now imagine someone else, call him Webb, who tries to be like George, but fails. He really wants to pick the ball up and run with it. And he tries to do this repeatedly. But he fails every time. He never lays a hand on the ball in fact. Is Webb playing football?\nI think he’s not, or at least that there is an important sense in which he is not. And this is a hard thing to capture. Webb isn’t playing football well, since he isn’t ever involved with the play. But actually kicking the ball, or even doing any kind of football like move, isn’t essential to playing football. (See, for example, some of the less impressive performances of Mesut Özil’s Arsenal career.) The problem with Webb is that he’s trying to play a completely distinct game. It was easy to say why George was not playing football; he was gratuitously breaking the rules. But Webb is not breaking the rules. What’s wrong with Webb, what makes him a non-footballer, is something mental.\nNow at this stage you might be tempted to say that the problem with Webb is that he isn’t trying to follow the rules. But, as Borge points out, this can’t be the story1. A defender who grabs an opponent’s jersey - just hard enough to not get penalised - is still playing football. A winger who drags an opponent back to prevent a counterattack - and knows that a yellow card will follow - is still playing football. To use an example we’ll come back to a bit, Luis Suárez was playing football when he pulled off that impressive, but totally illegal, save in the 2010 World Cup. You can play football while deliberately, knowingly, breaking the rules of football. So if the problem with Webb is that he has the wrong attitude, what attitude that he lacks must you have to count as a football player?\n1 See the ‘Fistful of Fouls’ example on page 139.I’m going to argue that playing a sport requires taking the rules of that sport as providing reasons against certain actions. To play football is, among other things, to regard oneself as having a reason to not handle the ball. (Except as a goalkeeper, or during a throw-in, etc.) This reason can be outweighed, but never defeated. Even if handling the ball is the right thing to do all things considered, one has an outweighed but undefeated reason to not do it. That’s the attitude that’s essential to playing football. Or, more precisely, playing football requires being part of a game where almost all the players have that attitude almost all the time.\nTo get to this conclusion, I’m going to start by looking at Suits’s view that being a player requires treating the rules as binding; that one is not playing the game is the rules are broken. This requires reconsidering what the rules are, and I’m going to broadly agree with Borge’s critique of this reconsideration. Then I’m going to go over my positive view, that being a player requires treating rules as providing reasons. Then I’ll compare this view to Borge’s view; the views might not be that far apart. And finally I’ll talk about the view of rules as reasons can be strengthened by incorporating D’Agastino’s view that games have an ethos, and playing the game requires upholding that ethos.\nA simple way to relate rules to player attitudes is to say that playing the game requires treating the rules as binding. On the face of it this is absurd; players commit fouls, even intentional fouls, in every game. A way to make it plausible is to reinterpret the rules so that they are more or less never broken. Now this might seem absurd - a defender grabbing an attacker who is running by is breaking the rules. But as Borge discusses2, you don’t have to think about rules this way. You cold say the rule is not Don’t grab other players. Instead, the rule is If you grab another player then (ceteris paribus), the other team gets a free kick. The defender isn’t breaking that rule. It’s true that they do something that leads to the other team being awarded something by the referee. But a defender who kicks the ball into touch to stop an attack also does something that leads to the other team being awarded something by the referee, and they aren’t breaking any rules. On this way of thinking, all rules are like the rules about what happens when the ball goes out of play, and players do not deliberately break those rules.\n2 See the ideas for how to flesh out a Suitsian view on pages 154ff.We can put the same point in Kantian terms. We ordinarily think of rules as being categorical imperatives, like Don’t grab other players, that players break. The view I’m interested in here is that rules are hypothetical imperatives, like If you grab another player then (ceteris paribus), the other team gets a free kick. And while these might be broken too, some fouls are never called, players do not intend to break them. Indeed, it’s not clear that a player could intend to break them. The few categorical imperatives there are, like Don’t use a sword while playing football, are clearly followed by the players.\nThis is a plausible model for some sports. In particular, it seems like a not absurd model for cricket. At first it might look like cricket has a number of rules for proper bowling, like that you must not overstep the crease when bowling, and you must not straighen your arm when bowling. But on closer look, it is plausible that some of these are hypothetical imperatives. The overstepping rule is really a conditional - if you overstep then the batting team is awarded a run (and some other things). The bowler isn’t breaking a rule when they overstep, they are just doing something that results by rule in good results for the other team. In that respect, they are just like a fielder whose overthrow goes to the boundary. On the other hand, the rule about straightening your arm is a categorical imperative: you must not do that. And we can see that from the fact that the match officials’ duty is not to penalise this kind of bowling, but to prevent it. So it’s plausible that in cricket, most rules should be understood as conditionals, and players intend to conform to them.\nBut this is not a particularly plausible model for football. We can see this by considering a pair of cases. In each case, an attacker has the ball at the corner flag, and is about to cross to an unmarked teammate near the penalty box. In the first case, defender Ellie prevents the cross by sliding in and cleanly kicking the ball over the goal line. In the second case, attacker Sam, who isn’t as good at this, prevents the cross by sliding in and bundling the ball, the attacker, the corner flag and the watching sideline official over the goal line. In both cases, the immediate thing the officials should do is award an unobstructed kick to the attacking team by the corner flag. If rules are hypothetical imperatives, then in an important sense Sam and Ellie did the same thing. They triggered a hypothetical that leads to the other team getting a reward of an unobstructed kick by the corner flag. But surely that leaves something out. What Ellie did was great defending, and what Sam did was foul play. This suggests that we want some notion of rules in which Sam was breaking the rules, and Ellie was not. If the Suitsian model says otherwise, it is wrong. But the Suitsian can’t go on to say that what Sam did was against the rules, because then it would imply that being a player means intending to not do what Sam did, and that is clearly wrong.\nBorge discusses some examples like this one, and gives two further arguments as to why the view I’m discussing gets the case wrong. I’m sympathetic to Borge’s conclusions, but both the arguments seem to need further refinement. And working through is interesting because it reveals how hard it is to put one’s finger on what distinguishes the cases.\nBorge’s first argument3 is that we need to say Sam broke the rules to explain why we added extra penalties in the 1980s and 1990s against this kind of foul play. But I suspect this is easier to explain than Borge thinks. Sports, especially football codes, change rules all the time to discourage behaviour they want to see less of. In Australian football, if a defender carries a ball into their own goal, the other team gets one point, and traditionally the defending team got a goal kick. Since the alternative might be giving up a goal, worth six points, this was often a sensible play. It was so sensible, and became so prevalent, that the rules were changed to discourage it, replacing the goal kick with a jump ball near the goal. The fact that administrators of the game changed the penalties for certain tackles doesn’t show that those tackles were against the rules, it might just show they wanted less of those kinds of things. (Compare too the change to the rules of football to ban handling back passes.) And the fact that Sam might get a red card for this tackle doesn’t even show it is against the rules. Dangerous play can get a red card even if it isn’t a rule violation. There isn’t a rule against kicking the ball hard and straight at an annoying fan pitchside, but it could be a red card if the kick was too hard and straight.\n3 Again, I’m focussing on the discussion on pages 143ff.Borge’s second argument is that the I’m imagining is too revisionist. We talk as if there are laws of the game, rules, that Sam broke and Ellie did not. And while this is true, I don’t think we should be too concerned about this. That’s in part because there are sports like cricket where this kind of revisionism seems on reflection plausible. But it is in part because of things internal to football. We talk about tackles like Sam’s being against the Laws of the game. But we also talk about being offside as against the Laws. It certainly triggers the exception clause (unless there has been a violation of the Laws) in the clause about a definition of a goal. And the story I’m telling seems fine, and perhaps quite plausible, for off side. You can’t get carded for repeatedly being offside, even if like Inzaghi you were born in an offside position. If there is a distinction between Sam’s case and Ellie’s case, it doesn’t just feel like we talk as if Sam’s action was against the rules (or the Laws), and Ellie’s was not.\nStill, I think is a key difference between the cases. And I suspect it does cause a problem for this view. Here is one way to see the difference between the cases. Imagine Sam gets away with just a yellow card for her tackle, so both versions of the story continue with the defending team gathering in the penalty box to defend a set piece. In a normal football game, the reactions of the defending team would be different in the two cases. Ellie would be getting fist bumps or other signs of appreciation at a job well done. But it would be very poor form for Sam’s teammates to react in the same way. That’s true even though doing what Sam did,triggering the condition of a hypothetical imperative, improved her team’s position just as much as what Ellie did. Being a football player involves taking a certain attitude towards actions, and that attitude requires distinguishing Sam and Ellie’s attitude.\nThere is a famous real life example of this: Luis Suárez’s handball on the goal line against Ghana in the 2010 World Cup. On the rules as hypothetical imperatives model, the rules played out to perfection in this case. A penalty was awarded against Suárez’s team, and he was given a red card and a suspension. But this benefited his team, since the penalty was missed, and his team went on to win a game they surely would have lost otherwise. On the view that rules are hypothetical imperatives, then what Suárez did was great football, just like Ellie in the fictional example. But that all seems wrong. A lot of people in the game thought that it was unseemly of Suárez to be so proud of what he did. Yet why shouldn’t he have been proud?\nBoth of these cases can be explained if we understand rules as categorical imperatives, and the players’ attitude towards them not as binding constraints, but as providing reasons. Football includes a rule against handling the ball, and a rule against kicking other players. It also provides penalties for breaching these rules. But the force of the rules is not exhausted by penalties. The rules provide reasons that can be outweighed by other considerations, but never defeated. That’s why we don’t celebrate tackles like Sam’s, or saves like Suárez’s. They have done something that may have increased the team’s win probability, but which they had reason not to do. And their teammates share those reasons. Celebrating the action is a kind of complicity in wrongdoing.\nBorge’s view about the lusory attitude is similar to this, but I think a little different. He says that football players have to “endure, obey or accept the arbitration of the rules of football” (150). Or, as he’d put it previously, the players have to “defer to the referee and … respect his decisions”4. (I’m simplifying a bit here, not least by blurring the participant/practitioner distinction.)\n4 Borge (2010, 164), as cited on page 150Now there is an obvious objection to this view. Players clearly do not respect the authority of the referee. It is a commonplace to see them surrounding the referee after an adverse decision complaining about it, and trying to cajole the referee to change their mind. If a defendant in a criminal trial reacted to a judge’s verdict this way, they’d be held in contempt of court. And it is hard to square respect with contempt.\nBorge should, I think, say that respecting the authority of the referee is better understood not in its ordinary usage, but just in the sense that the players do what the referee says. Maybe they complain about the mistaken award of a corner, but they don’t just take a goal kick if the referee is unmoved. That’s to say, the term ‘endure’ in the first quote above is important; it’s what players most often do.\nBut even this would be too strong a claim. Let me give just one amusing example. In 2002, I was watching the Germany-Ireland World Cup game in a bar in London. It ended with a stoppage time equaliser by Robbie Keane which brought the house down. But before that the most striking moment was an otherwise routine Ireland free kick. Germany lined up a wall, and the referee clearly said where they were supposed to stand. The camera operator, in a moment of genius, focused on the feet of the German players as the referee walked away. And as soon as his back was turned, four pairs of feet started shuffling forward in unison. The bar erupted in laughter. The lesson for us is that the players don’t have to respect the referee in the sense of doing what he says, or even endure his decisions; if they can get away with it they will just do something else.\nA better idea, not far from Borge’s I think, is to say that the players don’t have to respect the referee, but they do have to respect the rules of the game. Now this might seem absurd, in light of the examples of gratuitous rule breaking that we’ve used. But I think we can see why something like it is right if we step away from Germans and Uruguayans at World Cups, and imagine a park game. Thinking about games that are low stakes, and so the incentive to win at all costs is reduced, will help us get a better sense of what’s permissible.\nImagine Lisa is playing a game where there is a wall running down one sideline not far from the field of play. At one stage, Lisa is trapped with the ball near that sideline. She realises that a clever little bounce pass to herself off the wall will let her get out of the trap, and she executes it with aplomb. Now this might be a fun thing to do in practice, but it’s really not compatible with playing. When she does this, she has to some extent ceased to be a football player, and instead become someone who likes to show off football skills.\nOf course, Lisa won’t get any advantage from this, because the referee will simply award a throw in to the opposition. At least, the referee will probably do that. But maybe the referee will be unsighted, or incompetent, and will not award the throw. Still, it was wrong for Lisa to do that. It’s part of football that walls are not in play, and being a player requires acting as if that’s true.\nIf we imagine an incompetent referee, then we can push intuitions about cases like this even further. Imagine that Lisa goes on to notice that the referee either can’t or won’t penalise players for using their arms to control passes that come in at chest height. So every time she receives a pass to her chest, she uses her arm to help cushion the ball. The opposition are infuriated, she isn’t being subtle about it, but the referee doesn’t stop her, so she keeps on doing it. And eventually she gets a goal.\nI think she’s doing something wrong here. And I suspect, though perhaps cultural norms will vary a bit on this point, that if it is too blatant and the stakes are low enough, her teammates won’t be impressed either. They came to play a football game, and she’s making a mockery of it. Maybe they won’t celebrate the goal she gets by cheating this way, or maybe they will join in the opposition’s remonstration. Why don’t they just applaud her contribution to winning? The picture of rules as reasons explains this nicely I think. The rule against handball provides a reason for every player to not handle the ball. Maybe in a game with a huge amount at stake, the stakes override that reason. But in a park game, where the benefit of rule breaking is merely that Lisa gets a bit better control over the ball, that reason should be decisive. To the extent that she doesn’t treat it as decisive, she is undermining the sense in which they are playing football. And this can be true even if the referee won’t call this kind of foul.\nI think, and again I could be wrong, that the players would react very differently to Lisa than they’d react to the kind of ordinary shirt pulling and soft fouling that goes on at most corners. There is something particularly disrespectful about what Lisa is doing that doesn’t extend to fouls that everyone does all the time. And this is true even if Lisa would, were the referee to call her for a foul, be willing to shrug and hand the ball to the opposition for a free kick. (And then stand a foot closer than the referee said was allowed.) This is a puzzle, and I am not convinced Borge’s theory of what it is to play football can account for it.\nThe right thing to say here draws on a view of Fred D’Agostino’s that Borge discusses5. A sport has an ethos. This can’t be derived from the written rules of the game, but is something like the collective spirit in which it is played. In D’Agostino’s version, this provides the unbreakable rules of the game. The ethos says that if you do this or this, you’re no longer playing the game. This is too strong, as Borge points out. But something like it is right. My preferred version is that the ethos of the game provides the strength of reasons that go along with each rule. Currently the ethos says that shirt tugging at corners is something one has little reason to avoid, handball is something one has strong reason to avoid, and tackles from behind one has stronger reason still to avoid. But these aren’t essential to playing football; it was the same game when the strength of reasons were different.\n5 See D’Agostino (1981) for the original, and pages 144-148 of Borge’s book for the discussion.In most cases in football, the strength of reasons is just what you might expect from a minimal familiarity with the game, combined with the fact that player safety is in everyone’s interests. But in other sports you need something like an ethos to explain a lot of what we see. In both cricket and baseball, a player on the batting side is out if they hit the ball and it is caught by a fielder before touching the ground. And in both sports there are hard cases where the ball, the fielder, and the ground come together almost simultaneously. But the sports treat these cases very differently. In cricket it is very poor form to appeal for a catch unless you are confident you caught the ball, and if you believe you did not catch it, you should say so to the officials. In baseball, you appeal for everything and leave it up to the officials to make the decisions. These principles are followed from the lowest levels of the game to the highest. You couldn’t derive them from the rules of the game, or from the idea that players should respect the rules and the officials. You need to appeal to something like D’Agostino’s idea of ethos to explain the difference between the sports.\nBut if an ethos is so essential to a sport, does that mean that players in communities with a different ethos are literally playing different games? As Borge points out, this would be an absurd result6. His example involves a World Cup team not used to the stricter refereeing in international games. But you don’t need to go that far afield. I’ve heard that in England it can be a debacle when a Premier League referee takes charge of a Championship game, because the players just one level down are used to getting away with much heavier tackles than a referee who has to look after superstars in the top flight will allow. Now here’s the objection. If the ethos is essential to the game, and the ethos is different in the Premiership and the Championship, then it follows they are playing a different sport in the Premiership and the Championship. And that’s a reductio of the position.\n6 I’m drawing here on his discussion of Ghafoor Jahani at the 1978 World Cup, on page 148.This criticism relies on reading too much into the notion of an ethos. It’s true that in a colloquial sense, the game has a different ethos in a place where a certain tackle is commonplace to what it has in a place where that tackle is routinely penalised. But this isn’t what D’Agastino meant by “ethos”, and it isn’t what I mean. In D’Agastino’s version, it concerned what was simply not to be done. The teams who are used to lighter refereeing typically won’t do things that teams used to stricter refereeing simply won’t do. The things they get penalised for all the time are part of the repetoire of the more mannered teams; it’s just that those teams don’t do them as often. So I’m not sure these are examples of difference in ethos in D’Agastino’s sense. And they need not be differences in my sense either. As I’m using the term, the ethos of a game tells you what reasons you have to not do certain actions beyond what penalties will be applied to those actions. Changing the penalties doesn’t even look like something that changes the non-penalty reasons.\nBut the bigger point to make in reply turns on the fact, much stressed by Borge, that football is social. Indeed, it is social twice over. Whether one is playing football at a given moment is a social fact. Whether I am reading a book at a moment is largely up to me. But there is literally nothing I could do right now, sitting at my computer with no one around, that would make it the case that I was playing a game of football. For that I would need teammates, and opponents (and for that matter a field) and none of them are to hand. But that doesn’t exhaust how social football is. As Borge argues in chapter two, what makes it the case that various token games are tokens of the kind football consists largely of social facts as well. Once we take these things into account, we can see that appeal to something like an ethos of football won’t make it the case that people with different attitudes are playing different games.\nThere is an objection to the whole project of this paper that you might have been considering, and which it is finally time to address. I’ve been asking what attitude is required to play football. And at some level the answer is that literally anything goes. If there is a field of the right kind, and 22 other people on it - 10 of them your teammates, 11 of them opponents, and a referee - and they are doing paradigmatically football type things, then as long as you’re in uniform you’re playing football. Short of pulling out a weapon and assaulting people with the weapon, there is little you could do that would count as not playing football, as opposed to playing badly. So how can we talk about the attitude that is necessary for playing football?\nWell, we can still talk generically about what the players in general must think and feel in order for there to be a game. Exceptions can be tolerated. It is easy to come up with extreme cases. Imagine an East German player playing in France in the 1960s, and spending the whole game looking for the safest moment to defect. Or imagine a girl from an area where scouts never venture, finally getting a chance to play in front of a scout, and for this game only caring about how impressive her play is. It will be hard to come up with any plausible story about the attitude of football players that covers their attitudes, yet they are still playing football. But those exceptions can be tolerated, as long as they are exceptions. If everyone is looking for a chance to defect, it isn’t really a game, it’s an escape attempt. If everyone is just looking to impress the scouts, it’s an exhibition or a scrimmage, not a game. What we’re after here is what must be true in general.\nBecause to a pretty close approximation, all it takes to be playing football is to be part of a football game. And being part of it might literally just mean wearing the right kit, and being on the right field. And it being a football game is a matter of this game standing in the right social relations to games of football across space and time. Neither requires any player have attitudes of any kind. But we can ask what attitudes, if any, are necessary to be generic across the players in this game for it to stand in the right relations to the class of all football games. And we can ask what attitudes, if any, are necessary to be generic across the players in all games if those games are to be, collectively, football.\nAnd like as above, I think an account in terms of reasons is basically right. What makes the players across all the football games the world over players of the same game? I think it’s because they are, generally, taking the rules to provide reasons to act, and not act, in certain ways. There is massive variation within these. At a junior enough level, they are barely cognisant of the rules, and so cannot take them as reasons. At a high enough level, they might be so focused on winning that they care little for the rules beyond the fact that rule violations might lead to penalties. But it would have to be a very jaded team that celebrates Sam just as much as they celebrate Ellie; even at the highest level, players’ reactive attitudes tend to generally acknowledge the reason-giving force of the rules.\nI’ll close by considering two related problems. If the games are associated with the way players take the rules to be reasons, that suggests that games are individuated much too finely. If here we regard the rule against handball as having just this strength as a reason, and over there they regard it as having a little less strength, then are we not both playing football? That would be absurd. And if little kids don’t understand the rules as having reason-giving force, because perhaps they don’t understand the rules at all, are they playing a different game? This seems wrong, since we can talk about someone having played football since they were four.\nThere are two points to note about ‘football’ that are relevant to both of these objections. The term is vague. Whether these five year olds kicking a ball around a small field, with no throw ins, goal keepers, headers, or offside rules, are playing football is a bit vague. There is a sense in which they are, and a sense in which they are not. And even given a precisification, the question of whether two people are playing the same sport, or the same game, doesn’t always correspond to the meaning of the name of the game, or games, they play. The same thing happens with language. How widely is English spoken? Do folks speak the same language in Glasgow, Pittsburgh and Sydney? There is a sense in which they are speaking different languages - they certain have a very different lexicon. But there is a perhaps more important sense in which they are speaking the same language, and that language is English. Is 50-over cricket the same sport, or the same game, as 20-over cricket? There is a sense in which the answer is yes, and a sense in which the answer is no. (I’m actually kind of surprised at how much the infrastructure around cricket supposes the no answer - the games are more similar to each other than either is to junior cricket.) The same happens here. It’s true on my view that there is a sense in which players who differ in what strength they give to the rules of football are playing different games, just like 50-over and 20-over cricket might be different games. But just like those are both games of cricket, and like the folks in Glasgow, Pittsburgh and Sydney are all speaking English, the players might all be playing football.\nWhile I’ve disagreed, at least on points of emphasis, with Borge, I want to close by expressing again my appreciation for his book. Philosophy is richer when it engages with real life, especially with those aspects of real life that make less sense the more you think about them. And his book is a great example of this kind of engagement, and is rewarding reading for anyone who cares about either football or philosophy, and especially for those of us who care about both.\n\n\n\n\n\nReferences\n\nBorge, Steffen. 2010. “In Defence of Maradona’s Hand of God.” In Philosophy of Sport: International Perspectives, edited by A. Hardman and C. Jones, 154–79. Cambridge Scholars Publishing.\n\n\n———. 2019. The Philosophy of Football. London: Routledge.\n\n\nD’Agostino, Fred. 1981. “The Ethos of Games.” Journal of the Philosophy of Sport, 7–18.\n\n\nSuits, Bernard. 1978. The Grasshopper: Games, Life and Utopia. Toronto: University of Toronto Press."
  },
  {
    "objectID": "posts/epic/epistemic-modals-in-context.html",
    "href": "posts/epic/epistemic-modals-in-context.html",
    "title": "Epistemic Modals in Context",
    "section": "",
    "text": "In the 1970s David Lewis argued for a contextualist treatment of modals (Lewis 1976, 1979). Although Lewis was primarily interested in modals connected with freedom and metaphysical possibility, his arguments for contextualism could easily be taken to support contextualism about epistemic modals. In the 1990s Keith DeRose argued for just that position (DeRose 1991, 1998).\n\nPublished in Contextualism in Philosophy, edited by Gerhard Preyer and Georg Peter, 131-169.\n\nIn all contextualist treatments, the method by which the contextual variables get their values is not completely specified. For contextualist treatments of metaphysical modality, the important value is the class of salient worlds. For contextualist treatments of epistemic modality, the important value is which epistemic agents are salient. In this paper, we start by investigating how these values might be generated, and conclude that it is hard to come up with a plausible story about how they are generated. There are too many puzzle cases for a simple contextualist theory to be true, and a complicated contextualist story is apt to be implausibly ad hoc.\nWe then look at what happens if we replace contextualism with relativism. On contextualist theories the truth of an utterance type is relative to the context in which it is tokened. On relativist theories, the truth of an utterance token is relative to the context in which it is evaluated. Many of the puzzles for contextualism turn out to have natural, even elegant, solutions given relativism. We conclude by comparing two versions of relativism.\nWe begin with a puzzle about the role of epistemic modals in speech reports.\n\n0.1 A Puzzle\nThe celebrity reporter looked discomforted, perhaps because there were so few celebrities in Cleveland.\n“Myles”, asked the anchor, “where are all the celebrities? Where is Professor Granger?”\n“We don’t know,” replied Myles. “She might be in Prague. She was planning to travel there, and no one here knows whether she ended up there or whether she changed her plans at the last minute.”\nThis amused Professor Granger, who always enjoyed seeing how badly wrong CNN reporters could be about her location. She wasn’t sure exactly where in the South Pacific she was, but she was certain it wasn’t Prague. On the other hand, it wasn’t clear what Myles had gotten wrong. His first and third sentences surely seemed true: after all, he and the others certainly didn’t know where Professor Granger was, and she had been planning to travel to Prague before quietly changing her destination to Bora Bora.\nThe sentence causing all the trouble seemed to be the second: “She might be in Prague.” As she wiggled her toes in the warm sand and listened to the gentle rustling of the palm fronds in the salty breeze, at least one thing seemed clear: she definitely wasn’t in Prague – so how could it be true that she might be? But the more she thought about it, the less certain she became. She mused as follows: when I say something like x might be F, I normally regard myself to be speaking truly if neither I nor any of my mates know that x is not F. And it’s hard to believe that what goes for me does not go for this CNN reporter. I might be special in many ways, but I’m not semantically special. So it looks like Myles can truly say that I might be in Prague just in case neither he nor any of his mates knows that I am not. And I’m sure none of them knows that, because I’ve taken great pains to make them think that I am, in fact, in Prague – and reporters always fall for such deceptions.\nBut something about this reasoning rather confused Professor Granger, for she was sure Myles had gotten something wrong. No matter how nice that theoretical reasoning looked, the fact was that she definitely wasn’t in Prague, and he said that she might be. Trying to put her finger on just where the mistake was, she ran through the following little argument.\n\nWhen he says, “She might be in Prague” Myles says that I might be in Prague.1\nWhen he says, “She might be in Prague” Myles speaks truly iff neither he nor any of his mates know that I’m not in Prague.\nNeither Myles nor any of his mates know that I’m not in Prague.\nIf Myles speaks truly when he says that I might be in Prague, then I might be in Prague.\nI know I’m not in Prague.\nIt’s not the case that I know I’m not in Prague if I might be in Prague.\n\n1 Some of Professor Granger’s thoughts sound a little odd being in the present tense, but as we shall see, there are complications concerning the interaction of tense with epistemic modals, so for now it is easier for us to avoid those interactions.There must be a problem here somewhere, she thought – for (1) – (6) are jointly inconsistent. (Quick proof: (2) and (3) entail that Myles speaks truly when he says, “She might be in Prague”. From that and (1) it follows he speaks truly when he says Professor Granger might be in Prague. From that and (4) it follows that Professor Granger might be in Prague. And that combined with (5) is obviously inconsistent with (6).) But wherein lies the fault? Unless some fairly radical kind of scepticism is true, Professor Granger can know by observing her South Pacific idyll that she’s not in Prague – so (5) looks secure. And it seems pretty clear that neither Myles nor any of his mates know that she’s not in Prague, since they all have very good reason to think that she is – so it looks like (3) is also OK. But the other four premises are all up for grabs.\nWhich exactly is the culprit is a difficult matter to settle. While the semantic theory underlying the reasoning in (1)-(6) is mistaken in its details, something like it is very plausible. The modal ‘might’ here is, most theorists agree, an epistemic modal. So its truth-value should depend on what someone knows. But who is this someone? If it is Myles, or the people around him, then the statement “she might be in Prague” is true, and it is unclear where to block the paradox. If it is Professor Granger, or the people around her, then the statement is false, but now it is unclear why a competent speaker would ever use this kind of epistemic modal. Assuming the someone is Professor Granger, and assuming Professor Granger knows where she is, then “Granger might be in Prague” will be true iff “Granger is in Prague” is true. But this seems to be a mistake. Saying “Granger might be in Prague” is a way to weaken one’s commitments, which it could not be if the two sentences have the same truth conditions under plausible assumptions. So neither option looks particularly promising.\nTo make the problem even more pressing, consider what happens if a friend of Professor Granger’s who knows she is in the South Pacific overhears Myles’s comment. Call this third party Charles. It is prima facie very implausible that when Myles says that Professor Granger might be in Prague he means to rule out that Charles knows that she is not. After all, Charles is not part of the conversation, and Myles need not even know that he exists. So if Myles knows what he is saying, what he is saying could be true even if Charles knows Professor Granger is not in Prague. But if Charles knows this, Charles cannot regard Myles’s statement as true, else he will conclude that Professor Granger might be in Prague, and he knows she is not. So things are very complicated indeed.\nIn reasoning as we have been, we have been assuming that the following inferences are valid.\n\nA competent English speaker says It might be that S; and\nS, on that occasion of use, means that p; entail\nThat speaker says that it might be that p\n\nFurther, (9) plus\n\nThat speaker speaks truly; entail\nIt might be that p\n\nIf Charles accepts the validity of both of these inferences, then he is under considerable pressure to deny that Myles speaks truly. And it would be quite natural for him to do so – for instance, by interrupting Myles to say that “That’s wrong. Granger couldn’t be in Prague, since he left on the midnight flight to Tahiti.” But it’s very hard to find a plausible semantic theory that backs up this intervention, although such reactions are extremely common. (To solidify intuitions, here is another example: I overhear you say that a certain horse might have won a particular race. I happen to know that the horse is lame. I think: you are wrong to think that it might have won.)2\n2 Note that it also seems implausible to say that this is an instance of metalinguistic negation, as discussed in Horn (1989). When Charles interrupts Myles to object, the objection isn’t that the particular form of words that Myles has chosen is inappropriate. The form of words is fine, and Myles’ utterance would be completely unobjectionable if Charles’s epistemic state were slightly different. What’s wrong is that Myles has used a perfectly acceptable form of words to say something that’s false (at least by Charles’ lights—more on this later). We also think it’s implausible to understand the ‘might’ claims in question here as claims of objective chance or objective danger.Our solutions to this puzzle consist in proposed semantic theories for epistemic modals. We start with contextualist solutions, look briefly at invariantist solutions, and conclude with relativist solutions. Although we will look primarily at the costs and benefits of these theories with respect to intuitions about epistemic modals, it is worth remembering that they differ radically in their presuppositions about what kind of theory a semantic theory should be. Solving the puzzles to do with epistemic modals may require settling some of the deepest issues in philosophy of language\n\n\n0.2 Contextualist Solutions\nIn his (1991), Keith DeRose offers the following proposal:\n\nS’s assertion “It is possible that P” is true if and only if (1) no member of the relevant community knows that P is false, and (2) there is no relevant way by which members of the relevant community can come to know that P is false. (593-4)\n\nDeRose intends ‘possible’ here to be an epistemic modal, and the proposal is meant to cover all epistemic modals, including those using ‘might’.3 We will not discuss here the issues that arise under clause (2) of DeRose’s account, since we’ll have quite enough to consider just looking at whether clause (1) or anything like it is correct.4\n3 We take the puzzle to be a puzzle about sentences containing epistemic modal operators, however they are identified. We are sympathetic with DeRose’s (1998) position that many sentences containing ‘might’ and ‘possible’ are unambiguously epistemic, but do not wish to argue for that here. Rather, we simply take for granted that a class of sentences containing epistemic modal operators has been antecedently identified.\nThere are two differences between ‘possible’ and ‘might’. The first seems fairly superficial. Sentences where might explicitly takes a sentence, rather than a predicate, as its argument are awkward at best, and may be ungrammatical. It is possible that Professor Granger is in Prague is much more natural than It might be the case that Professor Granger is in Prague, but there is no felt asymmetry between Professor Granger is possibly in Prague and Professor Granger might be in Prague. We will mostly ignore these issues here, and follow philosophical orthodoxy in treating epistemic modals as being primarily sentence modifiers rather than predicate modifiers. The syntactic features of epistemic modals are obviously important, but we’re fairly confident that the assumption that epistemic modals primarily operate on sentences does not bear any theoretical load here, and could be replaced if necessary.\nThe other difference will be relevant to some arguments that follow. ‘Might’ can interact with tense operators in a way that ‘possible’ does not. It might have rained could either mean MIGHT (WAS it rains) or WAS (MIGHT it rains), while It possibly rained unambiguously means POSSIBLY (WAS it rains). It is often hard in English to tell just which meaning is meant when a sentence contains both tense operators and epistemic modals, but in Spanish these are expressed differently: Puede haber llovido; Podría haber llovido.4 There are three kinds of cases where something like DeRose’s clause (2) could be relevant.\nFirst, Jack and Jill are in a conversation, and Jack knows p while Jill knows p \\({\\rightarrow \\neg}\\) Fa. In this case intuitively neither could truly say a might be F even though neither knows a is not F.\nSecond, there are infinitely many mathematicians discussing Fermat’s Last Theorem. The first knows just that it has no solutions for n=3, the second just that it has no solutions for n=4, and so on. Intuitions are (unsurprisingly) weaker here, but we think none of them could say Fermat’s Last Theorem might have solutions, because the group’s knowledge rules this out.\nThird, if S was very recently told that a is not F, but simply forgot this, then intuitively she speaks falsely if she says a might be F.\nFourth, if S has the materials for easily coming to know P from her current knowledge, but has not performed the relevant inference, then we might be inclined (depending on how easy the inferential steps were to see and so on) to say that she is wrong to utter ‘It might be that not P’.\nRather than try and resolve the issues these cases raise, we will stick to cases where the only thing that could make a might be F false is that someone knows that a is not F.5 She would also have violated some pragmatic principles by knowingly using a third-person pronoun to refer to herself, but we take it those principles are defeasible, and violation of them does not threaten the truth-aptness of her utterance.In our discussion below, we consider three promising versions of contextualist theory. What makes the theories contextualist is that they all say that Myles spoke truly when he said “She might be in Prague”, but hold that if Professor Granger had repeated his words she would have said something false.5 And the reason for the variation in truth-value is just that Myles and Professor Granger are in different contexts, which supply different relevant communities. Where the three theories differ is in which constraints they place on how context can supply the community in question.\nThe first is the kind of theory that DeRose originally proposed. On this theory, there is a side constraint that the relevant community always includes the speaker: whenever S truly utters a might be F, S does not know that a is not F. We’ll call this the speaker-inclusion constraint, or sometimes just speaker-inclusion. There is some quite compelling evidence for speaker-inclusion. Consider, for example, the following sort of case: Whenever Jack eats pepperoni pizza, he forgets that he has ten fingers, and thinks “I might only have eight fingers.” Jill (who knows full well that Jack has ten fingers) spots Jack sitting all alone finishing off a pepperoni pizza, and says, “He might have eight fingers.” Jill has said something false. And what she’s said is false because it’s not compatible with what she knows that Jack has eight fingers. But if the relevant community could ever exclude the speaker, one would think it could do so here. After all, Jack is clearly contextually salient: he’s the referent of ‘he,’ the fingers in question are on his hand, and no one else is around.6 Now, a single case does not prove a universal7 – but the case does seem to provide good prima facie vidence for DeRose’s constraint.\n6 Notice that intuitions do not change if we alter the case in such a way that Jack has a strange disorder that makes it very hard for him to come to know how many fingers he has. Thus clause (2) of Derose’s analysis cannot do the work of the relevant side constraint.7 And see the case of Tom and Sally in the maze below for some countervailing evidence.One implication of DeRose’s theory is that (1) is false, at least when Professor Granger says it. For when Professor Granger reports that Myles says “She might be in Prague,” she is reporting a claim he makes about his epistemic community – that her being in Prague is compatible with the things that they know. But when she says (in the second clause) that this means he is saying that she might be in Prague, she speaks falsely. For in her mouth the phrase “that I might be in Prague” denotes the proposition that it’s compatible with the knowledge of an epistemic community that includes Professor Granger (as the speaker) that Professor Granger is in Prague. And that is not a proposition that Myles assented to. So DeRose’s theory implies that the very intuitive (1) is false when uttered by Granger.\n\nWhen he says, “She might be in Prague” Myles says that I might be in Prague.\n\nIt is worth emphasizing how counterintuitive this consequence of speaker-inclusion is. If the speaker-inclusion constraint holds universally then in general speech involving epistemic modals cannot be reported disquotationally. But notice how natural it is, when telling the story of Jack and Jill, to describe the situation (as we ourselves did in an earlier draft of this paper) as being one where “Whenever Jack eats pepperoni pizza, he forgets that he has ten fingers, and thinks he might only have eight.” Indeed, it is an important generalization about how we use language that speakers usually do not hesitate to disquote in reporting speeches using epistemic modals. So much so that exceptions to this general principle are striking – as when the tenses of the original speech and the report do not match up, and the tense difference matters to the plausibility of the attribution.\nOne might try to explain away the data just presented by maintaining a laxity for ‘says that’ reports. A chemist might say ‘The bottle is empty’ meaning it is empty of air, while milkman might utter the same sentence, meaning in my context that it is empty of milk. Nevertheless, the milkman might be slightly ambivalent about denying:\n\nWhen the chemist says ‘The bottle is empty’, she says that the bottle is empty.\n\nAnd this is no doubt because the overt ‘says that’ construction frequently deploys adjectives and verbs in a rather quotational way. After all, the chemist could get away with the following speech in ordinary discourse: “I know the milkman said that the bottle is empty. But he didn’t mean what I meant when I said that the bottle is empty. When he said that the bottle was empty he meant that it was empty of milk.”8 Thus the conventions of philosophers for using ‘say that’ involve regimenting ordinary use in a certain direction.9 But the disquotational facts that we are interested in cannot be explained away simply by invoking these peculiarities of ‘says that’ constructions, for the same disquotational ease surrounds the relevant belief reports. In the case just considered, while we might argue about whether it was acceptable for the chemist to say, in her conversational context, “The milkman said that the bottle was empty”, it is manifestly unacceptable for her to say “The milkman believes that the bottle is empty”. This contrasts with the case of ‘might’: If someone asked Professor Granger where Myles thought she was, she could quite properly have replied with (12).\n8 Notice that this use prohibits the inference from: The speaker said that the bottle was empty, to, The speaker expressed the proposition/said something that meant that the bottle was empty.9 We are grateful for correspondence with John MacFarlane here.\nHe thinks that/believes that I might be in Prague.\n\nIndeed, we in general tend find the following inference pattern – a belief-theoretic version of (7) to (9) above – compelling:\n\nA competent English speaker sincerely asserts It might be that S\nS, in that context of use, means that p.; therefore,\nThat speaker believes that it might be that p\n\nOur puzzle cannot, then, be traced simply to a laxity in the ‘says that’ construction.10 Whatever the puzzle comes to, it certainly runs deeper than that.\n10 For what its worth, we also note that ‘S claimed that P’ has less laxity (of the sort being discussed) than ‘S said that P’.Notice that (12) does not suggest that Myles thinks that for all Professor Granger knows, she is in Prague; it expresses the thought that Myles thinks that for all he knows, that is where she is. Moreover, this is hardly a case where Granger’s utterance is of doubtful appropriateness: (12) is one of the ways canonically available for Granger to express that thought. But if we assume that what is reported in a belief report of this kind is belief in the proposition the reporter expresses by I might be in Prague, and we assume a broad-reaching speaker-inclusion constraint, we must concede that the proposition Granger expresses by uttering (12) is that Myles believes that for all Professor Granger knows, Professor Granger is in Prague.\nIf the speaker-inclusion constraint holds universally, then anyone making such a report is wrong. There are two ways for this to happen—either they know what the sentences they’re using to make the attributions mean, and they have radically false views about what other people believe, or they have non-crazy views about what people believe, but they’re wrong about the meanings of the sentences they’re using. The first option is incredibly implausible. So our first contextualist theory needs to postulate a widespread semantic blindness; in general speakers making reports are mistaken about the semantics of their own language. In particular, it requires that such speakers are often blind to semantic differences between sentence tokens involving epistemic modals. It is possible that some theories that require semantic blindness are true, but other things being equal we would prefer theories that do not assume this.11 In general the burden of proof is on those who think that the folk don’t know the meaning of their own words. More carefully: the burden of proof is on those who think that the folk are severely handicapped in their ability to discriminate semantic sameness and difference in their home language.\n11 Note that the negation of semantic blindness concerning some fragment of the language is not the theory that speakers know all the semantic equivalences that hold between terms in that fragment. All we mean by the denial of semantic blindness is that speakers not have false beliefs about the semantics of their terms.So the plausibility of (1) counts as evidence against the first contextualist theory, and provides a suggestion for our second contextualist theory. The cases that provide the best intuitive support for the speaker-inclusion constraint and the case we used above, involved unembedded epistemic modals. Perhaps this constraint is true for epistemic modals in simple sentences, but not for epistemic modals in ‘that’ clauses. Perhaps, that is, when S sincerely asserts X Vs that a might be F, she believes that X Vs that for all X (and her community) knows, a is F. (This is not meant as an account of the logical form of X Vs that a might be F, just an account of its truth conditions. We defer consideration of what hypothesis, if any, about the underlying syntax could generate those truth conditions.) To motivate this hypothesis, note how we introduced poor Jack, above. We said that he thinks he might have eight fingers. We certainly didn’t mean by that that Jack thinks something about our epistemic state.\nThe other problem with the speaker-inclusion constraint is that it does not seem to hold when epistemic modals are bound by temporal modifiers, as in the following example. A military instructor is telling his troops about how to prepare for jungle warfare. He says, “Before you walk into an area where there are lots of high trees, if there might be snipers hiding in the branches, clear away the foliage with flamethrowers.” Whatever the military and environmental merits of this tactic, the suggestion is clear. The military instructor is giving generic conditional advice: in any situation of type S, if C then do A. The situation S is easy to understand, it is when the troops are advancing into areas where there are high trees. And A, too, is clear: blaze ’em. But what about C? What does it mean to say that there might be snipers in the high branches? Surely not that it’s compatible with the military instructor’s knowledge that there are snipers in the high branches – he’s sitting happily in West Point, watching boats sail lazily along the Hudson. What he thinks about where the snipers are is neither here nor there. Intuitively, what he meant was that the troops should use flamethrowers if they don’t know whether there are snipers in the high branches. (Or if they know that there are.) So as well as leading to implausible claims about speech reports, the speaker-inclusion constraint seems clearly false when we consider temporal modifiers.\nHere is a way to deal with both problems at once. There are constraints on the application of the speaker-inclusion constraint. It does not apply when the epistemic modal is in the scope of a temporal modifier (as the flamethrower example shows) and it does not apply when the epistemic modal is in a ‘that’ clause.12 Our second contextualist theory then accepts the speaker-inclusion constraint, but puts constraints on its application.\n12  This theory looks like one in which propositional attitude operators become monsters, since the content of Jack thinks that Jill might be happy is naturally generated by applying the operator Jack thinks to the proposition that that Jill might be happy denotes when it is expressed in Jack’s context. But this is not the easiest, or obviously the best, way to look at the theory. For one thing, that way of looking at things threatens to assign the wrong content to Jack thinks that Jill might have stolen my car. The content of Jill might have stolen my car in Jack’s context is that for all Jack knows, Jill stole Jack’s car, which is not what is intended. That is to say, thinking of propositional attitude operators as monsters here ignores the special status of epistemic modals in the semantics. It is better, we think, to hold that on this theory epistemic modals are impure indexicals whose value is fixed, inter alia, by their location in the sentence as well as their location in the world. But even if this theory does not officially have monsters, the similarity to monstrous theories is worth bearing in mind as one considers the pros and cons of the theory.\nThanks to Ernest Lepore for helpful discussions here.This kind of theory, with a speaker-inclusion constraint only applying to relatively simple epistemic modals, allows us to accept (1). The problematic claim on this theory turns out to be (4):\n\nIf Myles speaks truly when he says that I might be in Prague, then I might be in Prague.\n\nWhen Myles said that Professor Granger might be in Prague, he was speaking truly. That utterance expressed a true proposition. So the antecedent of (4) is true. But the consequent is false: the “might” that appears there is not in a that-clause or in the scope of a temporal modifier; so the speaker-inclusion constraint requires that Professor Granger be included in the relevant community; and since she knows that she is not in Prague, it’s not true that she might be. We would similarly have to reject:\n\nIf Myles has a true belief that I might be in Prague, then I might be in Prague.\n\nBut there are reasons to be worried about this version of contextualism, beyond the uneasiness that attaches to denying (4), and, worse still, (4\\(^\\prime\\)). For one, this particular version of the speaker-inclusion constraint seems a bit ad hoc: why should there be just these restrictions on the relevant community? More importantly, the theory indicts certain inferential patterns that are intuitively valid. Suppose a bystander in our original example reasoned13:\n13 What follows is a belief theoretic version of Charles’ reasoning.\nMyles believes that it might be that Professor Granger is in Prague.\nMyles’s belief is true; therefore,\nIt might be that Professor Granger is in Prague.\n\nBut this version of contextualism tells us that while (13) and (14) are true, (15) is false. In general, there are going to be counter-intuitive results whenever we reason from cases where the speaker-inclusion constraint does not apply to cases where it does.\nFinally, the theory is unable to deal with certain sorts of puzzle cases. The first kind of case directly challenges the speaker-inclusion constraint for simple sentences, although we are a little sceptical about how much such a case shows.14 Tom is stuck in a maze. Sally knows the way out, and knows she knows this, but doesn’t want to tell Tom. Tom asks whether the exit is to the left. Sally says, “It might be. It might not be.” Sally might be being unhelpful here, but it isn’t clear that she is lying. Yet if the speaker-inclusion constraint applies to unembedded epistemic modals, then Sally is clearly saying something that she knows to be false, for she knows that she knows which way is out.\n14  A similar case to the following appears in (Hawthorne 2004, 27).This case is not altogether convincing, for there is something slightly awkward about Sally’s speech here. For example, if Sally knows the exit is not to the left, then even if she is prepared to utter, “It might be [to the left],” she will not normally self-ascribe knowledge that it might be to the left. And normally speakers don’t sincerely assert things they don’t take themselves to know. So it is natural to suppose that a kind of pretense or projection is going on in Sally’s speech that may well place it beyond the purview of the core semantic theory.\nThe following case makes more trouble for our second contextualist theory, though it too has complications. Ann is planning a surprise party for Bill. Unfortunately, Chris has discovered the surprise and told Bill all about it. Now Bill and Chris are having fun watching Ann try to set up the party without being discovered. Currently Ann is walking past Chris’s apartment carrying a large supply of party hats. She sees a bus on which Bill frequently rides home, so she jumps into some nearby bushes to avoid being spotted. Bill, watching from Chris’s window, is quite amused, but Chris is puzzled and asks Bill why Ann is hiding in the bushes. Bill says\n\nI might be on that bus.\n\nIt seems Bill has, somehow, conveyed the correct explanation for Ann’s dive—he’s said something that’s both true and explanatory. But in his mouth, according to either contextualist theory we have considered, it is not true (and so it can’t be explanatory) that he might have been on the bus. He knows that he is in Chris’s apartment, which is not inside the bus.\nChris’s question, like most questions asking for an explanation of an action, was ambiguous. Chris might have been asking what motivated Ann to hide in the bushes, or he might have been asking what justified her hiding in the bushes. This ambiguity is often harmless, because the same answer can be given for each. This looks to be just such a case. Bill seems to provide both a motivation and a justification for Ann’s leap by uttering (16). That point somewhat undercuts a natural explanation of what’s going on in (16). One might think that what he said was elliptical for She believed that I might be on the bus. And on our second contextualist theory, that will be true. If Bill took himself to be answering a question about motivation, that might be a natural analysis. (Though there’s the underlying problem that Ann presumably wasn’t thinking about her mental states when she made the leap. She was thinking about the bus, and whether Bill would be on it.) But that analysis is less natural if we think that Bill was providing a justification of Ann’s actions.15 And it seems plausible that he could utter (16) in the course of providing such a justification. This suggests that (16) simply means that for all Ann knew, Bill was on that bus. Alternatively, we could say that (16) is elliptical for Because I might be on that bus, and that the speaker-inclusion constraint does not apply to an epistemic modal connected to another sentence by ‘because’. This may be right, but by this stage we imagine some will be thinking that the project of trying to find all the restrictions on the speaker-inclusion constraint is a degenerating research program, and a paradigm shift may be in order.\n15 Though the theory will allow for the truth of, “I might have been on that bus” (since the epistemic modal clause doesn’t occur on its own, but in the scope of a temporal operator). So if we think that (i) that’s enough to do the justificatory and explanatory work, and (b) Bill’s utterance of “I might be on that bus” is best understood as a clumsy stab at “I might have been on that bus”, then perhaps we can account for this kind of case using our second contextualist theory. Two worries: First, it is a cost of the theory that we have to reinterpret Bill’s utterance in this way, as a clumsy attempt to say something that the theory can accommodate. Second, there might be cases where the interpretation is less plausible: As a response to, “Why is Ann getting ready to jump over the hedge?”, “I might have been on that bus” sounds worse to us than “I might be on that bus”.So our final contextualist theory is that DeRose’s original semantic theory, before the addition of any sort of speaker-inclusion constraint, was correct and complete. So ‘might’ behaves like ‘local’ and ‘nearby’. If Susie says “There are snipers nearby,” the truth condition for that might be that there are snipers near Susie, or that there are snipers near us, or that there are snipers near some other contextually salient individual or group. Similarly, if she utters “Professor Granger might be in Prague” the truth condition for that might be that for all she knows Professor Granger is in Prague, or that for all we know Professor Granger is in Prague, or that for all some other community knows, Professor Granger is in Prague. There are no universal rules requiring or preventing the speaker from being included in the class of salient epistemic agents.\nAccording to the third version of contextualism, if Professor Granger does not equivocate when working through her paradox, then the problem lies with (6):\n\nIt’s not the case that I can know I’m not in Prague if I might be in Prague.\n\nAt the start of her reasoning process, Professor Granger’s use of ‘might’ means (roughly) ‘is compatible with what Myles and his friends know’. And if it keeps that meaning to the end, then the antecedent of (6) is true, because Professor Granger might (in that sense) be in Prague, even though she knows she is not. Any attempt to show that (1) through (6) form an inconsistent set will commit a fallacy of equivocation.16\n16 The same kind of equivocation can be seen in other arguments involving contextually variable terms. Assume that Nomar lives in Boston, Derek lives in New York, and Nomar, while talking about Fenway Park in Boston says, “I live nearby.” Derek, at home in New York, hears this on television and runs through the following argument.\n\nIn saying “I live nearby” Nomar says that he lives nearby. (Plausible disquotational premise about ‘nearby’)\nNomar speaks truly when he says “I live nearby” (Follows from the setup)\nIf Nomar speaks truly when he says “I live nearby” and in saying “I live nearby” he says that he lives nearby, then he lives nearby. (I.e. if he speaks truly then what he says is true.)\nIf Nomar lives nearby, then he lives in New York (Since everywhere that’s nearby to Derek’s home is in New York.); therefore\nNomar lives in New York\n\nThe right thing to say about this argument is that it equivocates. Every premise has a true reading. Perhaps every premise is true on its most natural reading, but the denotation of ‘nearby’ has to change throughout the argument for every premise to be true. The current view is that ‘might’ behaves like ‘nearby’, and that Professor Granger’s argument equivocates, like Derek’s.17 There also seems to be a past/future asymmetry about epistemic modals which the third contextualist theory will have trouble explaining. Consider this case involving past tense epistemic modals. Romeo sees Juliet carrying an umbrella home on a sunny afternoon. When he asks her why she is carrying an umbrella, she replies “It might have rained today.” There’s a scope ambiguity in Juliet’s utterance. If the epistemic modal takes wide scope with respect to the tense operator, Juliet would be claiming that she doesn’t know whether it has rained today (implicating, oddly, that this is why she now has an umbrella.) Or, as Juliet presumably intends, the temporal operator could take wide scope with respect to the epistemic modal. In that case Juliet says that it was the case at some earlier time (presumably when she left for work this morning) that it was compatible with her knowledge that it would rain today. And that seems both true and a good explanation of her umbrella-carrying.\nIt is much harder, if it is even possible, to find cases involving future tense operators where the temporal operator takes wide scope with respect to the pistemic modal. If S says, “It might rain tomorrow”, that seems to unambiguously mean that it’s compatible with S’s current knowledge (and her community’s) that it rains tomorrow. For a more dramatic case, consider a case where two people, Othello and Desdemona, have discovered that a giant earthquake next week will destroy humanity. No one else knows this yet, but there’s nothing that can be done about it. This rather depresses them, so they decide to take memory-wiping drugs so that when they wake up tomorrow, they won’t know about the earthquake. Othello can’t say, “Tomorrow, humanity might survive,” even though it is true that tomorrow, for all anyone will know, humanity will survive. If the temporal modifier could take wide scope with respect to the epistemic modal, Othello’s utterance could have a true reading. But it does not. It’s possible at this point that our policy, announced in footnote 2, of ignoring issues relating to DeRose’s second clause will come back to haunt us. One possibility here is that tomorrow it will still be false that humanity might survive because it’s not compatible with what people tomorrow know and knew that humanity survives. We don’t think that’s what is going on, but it’s possible. Here’s two quick reasons to think that the problem is not so simple. First, if Othello and Desdemona commit suicide rather than take the memory-wiping drugs, it will be compatible tomorrow with all anyone ever knew that humanity survives. But still Othello’s speech seems false. Second, it’s not obviously right that what people ever knew matters for what is epistemically possible now. Presumably at one stage Bill Clinton knew what he had for lunch on April 20, 1973. (For example, when he was eating lunch on April 20, 1973.) But unless he keeps meticulous gastronomical records, this bit of knowledge is lost to humanity forever. So there will be true sentences of the form Bill Clinton might have eaten x for lunch on April 20, 1973 even though someone once knew he did not. Now change the earthquake case so that it will happen in thirty years not a week, and no one will then know about it (because Othello and Desdemona took the memory-wiping drugs and destroyed the machines that could detect it). Still it won’t be true if Othello says, “In thirty years, humanity might survive.” This suggests to us that some kind of constraints on epistemic modals will be required. The existence of these constraints seems to refute the ‘no constraints’ version of contextualism. It also undermines the argument that the second version of contextualism is too ad hoc. Once some constraints are in place, others may be appropriate.But (6) as uttered by Professor Granger sounds extremely plausible. And there are other, more general problems as well. It is difficult on such a theory to explain why it is so hard to get the relevant community to exclude the speaker in present tense cases: Why, for instance, can’t Jill’s statement about Jack, “He might have eight fingers,” be a statement about Jack’s epistemic state rather than her own? The third theory offers us no guidance.17\nWe’ll close this section with a discussion of the interaction between syntax and semantics in these contextualist theories. As is well known, in the last decade many different contextualist theories have been proposed for various philosophically interesting terms. Jason Stanley (2000) has argued that the following two constraints should put limits on when we posit contextualist semantic theories.\n\nVariable\n\nAny contextual effect on truth-conditions that is not traceable to an indexical, pronoun, or demonstrative in the narrow sense must be traceable to a structural position occupied by a variable. [Stanley (2000) 401]18\n18 We assume here, following Stanley, a ‘traditional syntax involving variables’ [fn. 13]Stanley2000-STACAL. At least one of us would prefer a variable-free semantics along the lines of Jacobson (1999) Adopting such a semantics would involve, as Stanley says, major revisions to the presentation of this argument, but would not clearly involve serious changes to the argument. Most contextualists happily accept the existence of variables so we do not beg any questions against them, but see Pagin (2005) for an important exception.\nSyntactic Evidence\n\nThe only good evidence for the existence of a variable in the semantic structure corresponding to a linguistic string is that the string, or another that we have reason to believe is syntactically like it, has interpretations that could only be accounted for by the presence of such a variable.\n\n\nIf any contextualist theory of epistemic modals is to be justifiably believed, then Variable and Syntactic Evidence together entail the existence of sentences where the ‘relevant community’ is bound by some higher operator. So ideally we would have sentences like (17) with interpretations like (18).\n\nEveryone might be at the party tonight.\nFor all x, it is consistent with all x knows that x will be at the party tonight.\n\nNow (17) cannot have this interpretation, which might look like bad news for the contextualist theory. It’s natural to think that if ‘might’ includes a variable whose value is the relevant community, that variable could be bound by a quantifier ranging over it. But if such a binding were possible, it’s natural to think that it would be manifested in (17). So Variable and Syntactic Evidence together entail that we ought not to endorse contextualism about epistemic modals.\nThis argument against contextualism fails in an interesting way, one that bears on the general question of what should count as evidence for or against a contextualist theory. The reason that any variable associated with ‘might’ in (17) cannot be bound by ‘everyone’ is that ‘might’ takes wider scope than ‘everyone’. Note that (17) does not mean (19), but rather means (20).\n\nFor all x, it is consistent with what we know that x will be at the party tonight.\nIt is consistent with what we know that for all x, x will be at the party tonight.\n\nAs Kai von Fintel and Sabine Iatridou (2003) have shown, in any sentence of the form Every F might be G, the epistemic modal takes wide scope. For instance, (21) has no true reading if there is at most one winner of the election, even if there is no candidate that we know is going to lose.\n\nEvery candidate might win.\n\nMore generally, epistemic modals take wide scope with respect to a wide class of quantifiers.19 This fact is called the Epistemic Containment Principle by von Fintel and Iatridou. Even if there is a variable position for the relevant community in the lexical entry for ‘might’, this might be unbindable because the epistemic modal always scopes over a quantifier that could bind it. If that’s true then the requirement imposed by Syntactic Evidence is too strong. If the evidence from binding is genuinely neutral between the hypothesis that this variable place exists and the hypothesis that it does not, because there are no instances of epistemic modals that take narrow scope with respect to quantifiers, it seems reasonable to conclude that there are these variable places on the basis of other evidence.\n19 It is not entirely clear what the relevant class of quantifiers is, although von Fintel and Iatridou have some intriguing suggestions about what it might be.Having said all that, there still may be direct evidence for the existence of a variable position for relevant communities. Consider again our example of the military instructor, reprinted here as (22).\n\nBefore you walk into an area where there are lots of high trees, if there might be snipers hiding in the branches use your flamethrowers to clear away the foliage.\n\nAs von Fintel and Iatridou note, it is possible for epistemic modals to take narrow scope with respect to generic quantifiers. That’s exactly what happens in (22). And it seems that the best interpretation of (22) requires a variable attached to ‘might’. Intuitively, (22) means something like (23).\n\nGenerally in situations where you are walking into an area where there are lots of high trees, if it’s consistent with your party’s knowledge that there are snipers hiding in the branches use your flamethrowers to clear away the foliage.\n\nThe italicised your party seems to be the semantic contribution of the unenunciated variable. We are not saying that the existence of sentences like (23) shows that there are such variables in the logical form of sentences involving epistemic modals.20 We just want to make two points here. First, if you are a partisan of Syntactic Evidence, then (22) should convince you not to object to semantic accounts of epistemic modals that appeal to variables, as our contextualist theories do. Second, we note a general concern that principles like Syntactic Evidence presupposes that a certain kind of construction, where the contextually variable term is bound at a level like LF, is always possible. Since there are rinciples like the Epistemic Containment Principle, we note a mild concern that this presupposition will not always be satisfied.\n20 As previously noted, we are not all convinced that semantics ever needs to appeal to such variables, let alone that it does to account for the behaviour of epistemic modals.\n\n0.3 Invariantist Solutions\nThe most plausible form of invariantism about epistemic modals is that DeRose’s semantics is broadly correct, but the relevant community is not set by context - it is invariably the world. We will call this position universalism. Of course when we say a might be F we don’t normally communicate the proposition that no one in the world knows whether a is F. The analogy here is to pragmatic theories of quantifier domain restriction, according to which when we say Everyone is F, we don’t communicate the proposition that everyone in the world is F, even though that is the truth condition for our utterance.\nThe universalist position denies (2) in Professor Granger’s argument. Myles did not speak truly when he said “Professor Granger might be in Prague” because someone, namely Professor Granger, knew she was not in Prague. Although (2) is fairly plausible, it probably has weaker intuitive support than the other claims, so this is a virtue of the universalist theory.\nThe big advantage (besides its simplicity) of the universalist theory is that it explains some puzzle cases involving eavesdropping. Consider the following kind of case. Holmes and Watson are using a primitive bug to listen in on Moriarty’s discussions with his underlings as he struggles to avoid Holmes’s plan to trap him. Moriarty says to his assistant,\n\nHolmes might have gone to Paris to search for me.\n\nHolmes and Watson are sitting in Baker Street listening to this. Watson, rather inexplicably, says “That’s right” on hearing Moriarty uttering (24). Holmes is quite perplexed. Surely Watson knows that he is sitting right here, in Baker Street, which is definitely not in Paris. But Watson’s ignorance is semantic, not geographic. He was reasoning as follows. For all Moriarty (and his friends) know, Holmes is in Paris searching for him. If some kind of contextualism is true, then it seems that (24) is true in Moriarty’s mouth. And, thought Watson, if someone says something true, it’s OK to say “That’s right.”\nWatson’s conclusion is clearly wrong. It’s not OK for him to say “That’s right,” in response to Moriarty saying (24). So his reasoning must fail somewhere. The universalist says that where the reasoning fails is in saying the relevant community only contains Moriarty’s gang members. If we include Holmes and Watson, as the universalist requires, then Moriarty speaks falsely when he says (24).\nThere are a number of serious (and fairly obvious) problems with the universalist account. According to universalism, the following three claims are inconsistent.\n\nx might be F.\nx might not be F.\nSomeone knows whether x is F.\n\nSince these don’t look inconsistent, universalism looks to be false.\nThe universalist’s move here has to be to appeal to the pragmatics. If (27) is true then one of (25) and (26) is false, although both might be appropriate to express in some contexts. But if we can appropriately utter sentences expressing false propositions in some contexts, then presumably we can inappropriately utter true sentences in other contexts. (Indeed, the latter possibility seems much more common.) So one could respond to the universalist’s main argument, their analysis of eavesdropping cases like Watson’s, by accepting that Watson can’t appropriately say “That’s right” but he can truly say this. The universalist will have a hard time explaining why such a theory cannot work, assuming, of course, that she can explain how her own pragmatic theory can explain all the data.\nThe major problem here is one common to all appeals to radical pragmatics in order to defend semantic theories. If universalism is true then speakers regularly, and properly, express propositions they know to be false.21 (We assume here that radical scepticism is not true, so sometimes people know some things.) Myles knows full well than someone knows whether Professor Granger is in Prague, namely Professor Granger. But if he’s a normal English speaker, this will not seem like a reason for him to not say, “Professor Granger might be in Prague.” Some might not think this is a deep problem for the universalist theory, for speakers can be mistaken in their semantic views in ever so many ways. But many ill regard it as a serious cost of the universalist claim.\n21 By “express” we will always mean “semantically express”. We’re not concerned with, and hope not to commit ourselves to any views about, for example, what’s conveyed via various pragmatic processes.This problem becomes more pressing when we look at what universalism says about beliefs involving epistemic modals. Myles does not just say that Professor Granger might be in Prague, he believes it. And he believes Professor Granger might not be in Prague. If he also believes that Professor Granger knows where she is, these beliefs are inconsistent given universalism. Perhaps the universalist can once again invoke pragmatics. It is not literally true in the story that Myles believes that Granger might be in Prague. But in escribing the situation we use “Myles believes that Granger might be in Prague,” to pragmatically communicate truths by a literal falsehood. This appeal to a pragmatic escape route seems even more strained than the previous universalist claims.\nIn general, the universalism under discussion here seems to run up against a constraint on semantic theorising imposed by Kripke’s Weak Disquotation Principle. The principle says that if a speaker sincerely accepts a sentence, then she believes its semantic value.22 If we have some independent information about what a speaker believes, then we can draw certain conclusions about the content of the sentences she accepts, in particular that she only accepts sentences whose content she believes. The universalist now has two options.23 First, she can say that Myles here does accept inconsistent propositions. Second, she can deny the Weak Disquotation Principle, and say that although Myles sincerely asserts, and accepts, “Professor Granger might be in Prague” he doesn’t really believe that Professor Granger might be in Prague. Generally, it’s good to have options. But it’s bad to have options as unappealing as these.24\n22 Note that something like this had better be true if what it is to believe p is to have a sentence that means p in one’s ‘belief box’.23 We assume that it is not a serious option to deny that we ever accept unnegated epistemic modal sentences.24 There also a technical problem with universalism that mirrors one of the problems Stanley and Szabó (2000) raise for pragmatic theories of quantifier domain restriction. Normally (28) would be used to express a proposition like (29).\n\nEvery professor enjoys every class.\nEvery salient professor enjoys every class that s/he teaches.\n\nIntuitively, by uttering (28) we express a proposition that contains two restricted quantifiers. Let’s accept, for the sake of the argument, that a pragmatic theory of quantifier domain restriction can sometimes explain why the quantifiers in the propositions we express are more restricted than the quantifiers in the truth conditions for the sentences we use. Stanley and Szabó argue that such an explanation will not generalise to cover embedded quantifiers where the quantifier domain in the proposition expressed is bound to the outer quantifier. One such quantifier is the quantifier over classes in (28). We will not repeat their arguments here, but simply note that if they are correct, the universalist faces a problem in explaining how we use sentences with embedded epistemic modals that are (intuitively) defined with respect to a community that is bound by a higher level quantifier. As we saw, (22) provides an example of this kind of epistemic modal.\n\n0.4 Reporting Epistemic Modals\nOur third class of solutions will be relatively radical, so it’s worth pausing to look at the evidence for it. Consider again the dialogue between Moriarty, Holmes and Watson. Moriarty, recall, utters (24)\n\nHolmes might have gone to Paris to search for me.\n\nWatson knows that Holmes is in Baker Street, as of course does Holmes. In the above case we imagined that both Watson and Holmes heard Moriarty say this. Change the story a little so Holmes does not hear Moriarty speak, instead when he comes back into the room he asks Watson what Moriarty thinks. Watson, quite properly, replies with (30).\n\nHe thinks that you might have gone to Paris to search for him.\n\nThis is clearly not direct quotation because Watson changes the pronouns in Moriarty’s statement. It is not as if Watson said “He sincerely said, ‘Holmes might have gone to Paris to search for me.’” This might have been appropriate if Holmes suspected Moriarty was speaking in code so the proposition he expressed was very sensitive to the words he used.\nNor was Watson’s quote a ‘mixed’ quote, in the sense of what happens in (31).25 The background is that Arnold always uses the phrase ‘my little friend’ to denote his Hummer H2, despite that vehicle being neither little nor friendly. No one else, however, approves of this terminology.\n25 Earlier we used speech reports to illustrate the oddities of epistemic modals inside propositional attitude ascriptions. There are well-known difficulties with connecting appropriate speech reports to the semantic content of what is said, as opposed to merely communicated. (For some discussion of these, see Soames (2002) and Capellen and Lepore (1997).) We don’t think those difficulties affect the above arguments, where the evidence is fairly clear, and fairly overwhelming. But matters get a little more delicate in what follows, so we move to belief reports because they are more closely tied to the content of what is believed.\nArnold: My little friend could drive up Mt Everest.\nChaz: Arnold believes his little friend could drive up Mt Everest.26\n\n26 In this case, as with all the belief reports discussed below, the only evidence the reporter has for the report is given by the speech immediately preceding it. We assume there is good reason from the context to assume that the speakers are sincere.27  There are somewhat delicate questions about what a direct belief report means, but we assume the notion is well enough understood, even if we could not formally explicate what is going on in all such reports.We’ve left off the punctuation here so as to not beg any questions, but there is a way this could be an acceptable report if the fourth and fifth word, and those two words only, are part of a quotation. This is clearly not ordinary direct quotation, for Arnold did not think, in English or Mentalese, “His little friend could drive up Mt Everest.” Nevertheless, this is not ordinary indirect quotation. In ordinary spoken English Chaz’s report will be unacceptable unless ‘little friend’ is stressed. The stress here seems to be just the same stress as is used in metalinguistic negation, as described in Horn (1989). Note the length of the pause between ‘his’ and ‘little’. With an ordinary pause it sounds as if Chaz is using, not mentioning, ‘little friend’. So it is possible in principle to have belief reports, like this one, that are neither strictly direct nor strictly indirect.27 Nevertheless, it does not seem like (30) need such a case. In particular, there need be no distinctive metalinguistic stress on ‘might’ in Watson’s utterance of (30), and such stress seems to be mandatory for this mixed report.\nAssuming Moriarty was speaking ordinary English, Watson’s report seems perfectly accurate. This is despite the fact that the relevant community one would naturally associate with Watson’s use of ‘might’ is quite different to the community we would associate with Moriarty’s use. When reporting speeches involving epistemic modals – and the beliefs express by sincere instances of such speeches, speakers can simply disquote the modal terms.\nAs is reasonably well known, there are many terms for which this kind of disquoting report is impermissible. In every case, Guildenstern’s report of Ophelia’s utterance is inappropriate.\n\nOphelia: I love Hamlet.\n…\nGuildenstern: *Ophelia thinks that I love Hamlet.\n\nGuildenstern: What think you of Lord Hamlet?\nOphelia: He is a jerk.\n…\nRosencrantz: What does Ophelia think of the King?\nGuildenstern: *She thinks that he is a jerk.\n\nGuildenstern: Are you ready to teach the class on contextualism?\nOphelia: I’m ready.\n…\nRosencrantz: Does Ophelia think she is ready to defend her dissertation?\nGuildenstern: *She thinks she is ready.\n\n(Guildenstern and Ophelia are on the telephone, Guildenstern is in Miami, and Ophelia is in San Francisco)\nGuildenstern: What do you like best about San Francisco?\nOphelia:There are lots of wineries nearby.\n…\nRosencrantz: Is it possible to grow wine in south Florida?\nGuildenstern: *Ophelia thinks that there are lots of wineries nearby.28\n\n28 We do not say that ‘nearby’ in a speech report could never refer to the area near the location of the original speaker. Had Rosencrantz asked a question about San Francisco, and Guildenstern given the same response, that is presumably what it would have done. We just say that it does not automatically refer back to that area, and in some cases, like (35), it can refer to a quite different area. ‘Nearby’ behaves quite differently in this respect to ‘near here’, which always refers to the area near the reporter.Even when the contextualist claim is not obviously true, as with ‘local’ and ‘enemy’, disquotational reports are unacceptable after context shifts.\n\n(Brian is calling from Providence, Hud and Andy are in Bellingham)\nBrian: When I get all this work done, I’ll head off to a local bar for some drinks.\nAndy: How much work is there?\nBrian: Not much. I should get to the bar in a couple of hours.\nHud: Hey, is Brian in town? Where’s he going tonight?\nAndy: *He thinks he’ll be at a local bar in a couple of hours.\n\nThe Enemy, speaking of us: The enemy have the advantage.\nOne of us: How are we doing?\nAnother of us: Someone just informed me that the enemy have the advantage.\n\n(Terrell is an NFL player, and Dennis is his coach.)\nTerrell: Why are you cutting me coach?\nDennis: Because you are old and slow.\n(After this Terrell returns to academia. Kate and Leopold are students in his department.)\nKate: Do you think Terrell would do well on our department ultimate frisbee team?\nLeopold: ??I’m not sure. Someone thinks he’s old and slow.\n\nThis data provides us with the penultimate argument against the contextualist theory of epistemic modals. We have already seen several such arguments.\nFirst, as seen through the difficulties with each of the options discussed in section 2, any version of contextualism faces serious problems, though by altering the version of contextualism we are using, we can alter what problems we have to face.\nSecond, there is nothing like the speaker-inclusion constraint for terms like ‘local’ and ‘enemy’ for which contextualism is quite plausible. This disanalogy tells against the contextualist theory of ‘might’. With the right stage setting (and it doesn’t usually take very much), we can get ‘local’ and ‘enemy’ to mean local to x and enemy of x for pretty much any x we happen to be interested in talking about. At least for ‘bare’ (unembedded) epistemic modals, the situation is markedly different. We can’t, just by making Jack salient, make our own knowledge irrelevant to the truth of our utterance of, for example, “Jack might have eight fingers.” The only way we can make our knowledge irrelevant is if we are using this sentence in an explanation or justification of Jack’s actions.29\n29 And then it would probably be more natural to say “He might have eight fingers,” but that’s possibly for unrelated reasons.Third, there is a difference in behaviour between embedded and unembedded occurrences of epistemic modals. When epistemic modals are embedded in belief contexts, conditionals, etc., they behave differently—the speaker inclusion constraint seems to be lifted. (Think about belief reports and that military instructor case.) ‘Local’ and ‘enemy’ don’t seem to show any analogous difference in their behaviour between their bare and embedded occurrences.\nFourth, ‘local’ and ‘enemy’ don’t generate any of the peculiar phenomena about willingness to agree. If Myles (still in Cleveland), says\n\nMany local bars are full of Browns fans.\n\nProfessor Granger (still in the South Pacific), will not hesitate to say “that’s right” (as long as she knows that many bars in Cleveland really are, as usual, full of Browns fans). The fact that the relevant bars aren’t local to her doesn’t interfere with her willingness to agree with (39) in the way that the fact that she knew that she wasn’t in Prague interfered with her willingness to agree with Myles’ claim that she might be in Prague, or in the way that Watson’s knowledge that Holmes was in London (should have) interfered with his willingness to assent to Moriarty’s claim that Holmes might be in Paris.\nFifth, when there is a context shift, we are generally hesitant to produce belief reports by disquoting sincerely asserted sentences involving contextually variable terms. This is what the examples (32) through (36) show. For a wide range of contextually variable terms, speakers will quite naturally hesitate to make disquotational reports unless they are in the same context as the original speaker. Such hesitation is not shown by speakers reporting epistemic modals.\nThe sixth argument, that there is an alternative theory that does not have these flaws, will have to wait until the next section. For now, let’s note that there are other words that seem at first to be contextually variable, but for which disquotational reports seem acceptable.\n\nVinny the Vulture: Rotting flesh tastes great.\nJohn: Vinny thinks that rotting flesh tastes great.\n\nAnt Z: He’s huge (said of 5 foot 3 141 lb NBA player Muggsy Bogues)\nAndy: Ant Z thinks that Muggsy’s huge.\n\nMarvin the Martian: These are the same colour (said of two colour swatches that look alike to Martians but not to humans.)\nBrian: Marvin thinks that these are the same colour.\n\nIn all three cases the report is accurate, or at least extremely natural. And in all three cases it would have been inappropriate for the reporter to continue “and he’s right”. But crucially, in none of the three cases is it clear that the original speaker made a mistake. In his context, it seems Vinny utters a truth by uttering, “Rotting flesh tastes great”, for rotting flesh does taste great to vultures. From Ant Z’s perspective, Muggsy Bogues is huge. We assume here, a little controversially, that there is a use of comparative adjectives that is not relativised to a comparison class, but rather to a perspective. Ant Z does not say that Muggsy is huge for a human, or for an NBA player, but just relative to him. And he’s right. Even Muggsy is huge relative to an ant. Note the contrast with (36) here. There’s something quite odd about Leopold’s statement, which intuitively means that someone said Terrell is old and slow for a graduate student, when all that was said was that he is old and slow for an NFL player.30 And, relative to the Martian’s classification of objects into colours, the two swatches are the same colour. So there’s something very odd going on here.\n30 Or perhaps something more specific than that, such as that he is old and slow for a player at his position.The following very plausible principle looks like it is being violated.\n\nTruth in Reporting\n\nIf X has a true belief, then Y’s report X believes that S accurately reports that belief only if in the context Y is in, S expresses a true proposition.31\n31 One might also consider a ‘says that’ version of Truth in Reporting: If X speaks true, then Y’s report X says that S is accurate only if in the context Y is in, S expresses a true proposition. This is more questionable, since it is questionable whether ‘says that’ constructions must report what is semantically expressed by a speech, as opposed to what is merely communicated. See again the papers mentioned in footnote 25.\n\nNot only do our three reports here seem to constitute counterexamples to Truth in Reporting, Watson’s report in (30) is also such a counterexample, if Moriarty speaks truly (and sincerely). One response here would be to give up Truth in Reporting, but that seems like a desperate measure. And we would still have the puzzle of why we can’t say “and he’s right” at the end of an accurate report.\nAnother response to these peculiar phenomena would be to follow the universalist and conclude that Moriarty, Vinny, Ant Z and Marvin all believe something false. It should be clear how to formulate this kind of position: something tastes great iff every creature thinks it tastes great; something is huge iff it is huge relative to all observers; and two things are the same colour iff they look alike (in a colour kind of way) to every observer (in conditions that are normal for them). As we saw, there are problems for the universalist move for epistemic modals. And the attractiveness of the other universal seems to dissipate when we consider the cases from a different perspective.\n\nBrian: Cognac tastes great.\nVinny: Brian believes that cognac tastes great.\n\nAndy:He’s huge (said of Buggsy Mogues, the shortest ever player in the Dinosaur Basketball Association).\nTyrone the T-Rex: Andy believes that Buggsy’s huge.\n\nJohn: These are the same colour (said of two colour swatches that look alike to humans but not to pigeons).\nPete the Pigeon: John believes that these are the same colour.\n\nAgain, every report seems acceptable, and in every case it would seem strange for the reporter to continue “and he’s right.” The universalist explanation in every case is that the original utterance is false. That certainly explains the data about reports, but look at the cost! All of our utterances about colours and tastes will turn out false, as will many of our utterances about sizes. It seems we have to find a way to avoid both contextualism and universalism. Our final suggestions for how to think about epistemic modals attempt to explain all this data.\n\n\n0.5 Relativism and Centred Worlds\nJohn MacFarlane (2003) has argued that believers in a metaphysically open future should accept that the truth of an utterance is relative to a context of evaluation.32 For example, if on Thursday Emily says, “There will be a sea battle tomorrow”, the believer in the open future wants to say that at the time her utterance is neither determinate true nor determinately false. One quick objection to this kind of theory is that if we look back at Emily’s statement while the sea battle is raging on Friday, we are inclined to say that she got it right. From Friday’s perspective, it looks like what Emily said is true. The orthodox way to reconcile these intuitions is that the only sense in which Emily’s statement is indeterminate on Thursday is an epistemic sense – we simply don’t know whether there will be a sea battle. MacFarlane argues instead that we should simply accept the intuitions as they stand. From Friday’s perspective, Emily’s statement is determinately true, from Thursday’s it is not. Hence the truth of statements is relative to a context of evaluation.\n32 We are very grateful in this section to extensive conversations with John MacFarlane. His (2003) was one of the main inspirations for the relativist theory discussed here. His (ms), which he was kind enough to show us a copy of while we were drafting this paper, develops the argument for a relativist approach to epistemic modals in greater detail than we do here. Mark Richard also has work in progress that develops a relativist view on related matters, which he has been kind enough to show us, and which has also influenced our thinking.There is a natural extension of this theory to the cases described above. Moriarty’s statement is true relative to a context C iff it is compatible with what the people in C know that Holmes is in Paris. So in the context he uttered it, the statement is true, because it is consistent with what everyone in his context knows that Holmes is in Paris. But in the context of Watson’s report, it is false, because Watson and Holmes know that Holmes is not in Paris.\nWe will call any such theory of epistemic modals a relativist theory, because it says that the truth of an utterance containing an epistemic modal is relative to a context of evaluation. As we will see, relativist theories do a much better job than contextualist theories of handling the data that troubled contextualist theories. Relativist theories are also plausible for the predicates we discussed at the end of the last section: ‘huge’, ‘color’ and ‘tastes’. On such a theory, any utterance that x tastes F is true iff x tastes F to us. Similarly, an utterance x is huge that doesn’t have a comparison class, as in (41) or (44), is true iff x is huge relative to us. And Those swatches are the same color is true iff they look the same colour to us. The reference to us in the truth conditions of these sentences isn’t because there’s a special reference to us in the lexical entry for any of these worlds. Rather, the truth of any utterance involving these terms is relative to a context of evaluation, and when that is our context of evaluation, we get to determine what is true and what is false. If the sentences were being evaluated in a different context, it would be the standards of that context that mattered to their truth.\nSo far we have not talked about the pragmatics of epistemic modals, assuming that their assertability conditions are given by their truth conditions plus some familiar Gricean norms. But it is not obvious how to apply some of those norms if utterance truth is contextually relative, because one of the norms is that one should say only what is true.\nOne option is to say that utterance appropriateness is, like utterance truth, relative to a context of evaluation. This is consistent, but it does not seem to respect the data. Watson might think that Moriarty’s utterance is false, at least relative to his context of evaluation33, but if he is aware of Moriarty’s epistemic state he should think it is appropriate. So if something like truth is a norm of assertion, it must be truth relative to one or other context. But which one?\n33 We do not assume here that ordinary speakers, like Watson, explicitly make judgments about the truth of utterances relative to a context of evaluation, as such. They do make judgments about the truth of utterances, and those judgments are made in contexts, but they don’t explicitly makes judgments of truth relative to context of evaluation. One of the nice features, however, of the relativist account is that it is possible to do an attractive rational reconstruction of most of their views in terms of contexts.We could say that one should only say things that are true relative to all contexts. But that would mean John’s statement about the two swatches being the same colour would be inappropriate, and that seems wrong.\nWe could say that one should only say things that are true relative to some contexts. But then Brian could have said, “Rotting carcases taste great” and he would have said something appropriate, because that’s true when evaluated by vultures.\nThe correct norm is that one should only say something that’s true when evaluated in the context you are in. We assume here that contexts can include more than just the speaker. If Vinny the Vulture is speaking to a group of humans he arguably cannot say Rotting flesh tastes great. The reason is that rotting flesh does not taste great to the group of speakers in the conversation, most of whom are humans. This norm gives us the nice result that Myles’s statement is appropriate, as is Moriarty’s, even though in each case their most prominent audience member knows they speak falsely.34\n34 Can we even say that someone speaks falsely here now that truth and falsity is always relative to a context of evaluation? It turns out we can, indeed we must, although the matter is a little delicate. We return to this point below.This helps explain, we think, the somewhat ambivalent attitude we have towards speakers who express epistemic modals that are false relative to our context, but true relative to their own. What the speaker said wasn’t true, so we don’t want to endorse what they said. Still, there’s still a distinction between such a speaker and someone who says that the sky is green or that grass is blue. That speaker would violate the properly relativised version of the only say true things rule, and Myles and Moriarty do not violate that rule.\nAs MacFarlane notes, relativist theories deny Absoluteness of Utterance Truth, the claim that if an utterance is true relative to one context of evaluation it is true relative to all of them. It is uncontroversial of course that the truth value of an utterance type can be contextually variable, the interesting claim that relativists make is that the truth value of utterance tokens can also be different relative to different contexts. So they must deny one or more premises in any argument for Absoluteness of Utterance Truth, such as this one.\n\nAbsoluteness of Propositional Content: If an utterance expresses the proposition p relative to some context of evaluation, then it expresses that proposition relative to all contexts of evaluation.\nAbsoluteness of Propositional Truth Value: If a proposition p is true relative to one context in a world it is true relative to all contexts in that world; therefore,\nAbsoluteness of Utterance Truth\n\nThis argument provides a nice way of classifying relativist theories. One relativist approach is to say that Moriarty (or anyone else who utters an epistemic modal) says something different relative to each context of evaluation. Call this approach content relativism. Another approach is to say that there is a single proposition that he expresses with respect to every context, but the truth value of that proposition is contextually variable. Call this approach truth relativism. (So that the meaning of ‘proposition’ is sufficiently understood here, let us stipulate that we understand propositions to be the things that are believed and asserted and thus, relatedly, the semantic values of ‘that’-clauses.)\nIt might look like some of our behaviour is directly inconsistent with any sort of relativism. Consider the following dialogue.\n\nVinny: Rotting flesh tastes great\nVinny’s brother: That’s true.\nJohn: That (i.e. what Vinny’s brother said) is not true.\n\nIf what Vinny’s brother is saying is that Vinny’s utterance Rotting flesh tastes great is true in his context, then John is wrong in saying that what Vinny’s brother said isn’t true. For it is true, we claim, that Rotting flesh tastes great is true in Vinny’s context.35 But this prediction seems unfortunate, because John’s utterance seems perfectly appropriate in his context.\n35 We assume here the vultures are talking mainly to other vultures, and John is talking mainly to other humans.36 We are grateful to John Macfarlane for helpful correspondence that influenced what follows.The solution here is to recognise a disquotational concept of truth, to go alongside the binary concept of truth that is at the heart of the relativist solution.36 The binary concept is a relation between an tterance and a context of evaluation. Call this trueB. So Vinny’s utterance is trueB relative to his context, and to his brother’s context, and falseB relative to John’s context. One crucial feature of the binary concept is that it is not a relativist concept. If it is true relative to one context that an utterance is trueB relative to context C, it is true relative to all contexts that the utterance is trueB relative to context C. The disquotational concept is unary. Call this trueT. As far as is permitted by the semantic paradoxes, it claims that sentences of the form S is trueT iff S will be trueB relative to any context (note here the primacy of truthB for semantic explanation) TrueT is a relative concept. An utterance can be trueT relative to C and not trueT relative to C\\(^\\prime\\). When an utterance is given the honorific true in ordinary discourse, it is the unary relative concept trueT that is being applied. That explains what is going on in (46). Vinny’s brother says that Vinny’s utterance is trueT. Relative to his context, that’s right, since Vinny’s utterance is true in his context. But relative to John’s context, that’s false, because an utterance is trueT relative to John’s context iff it is true relative to John’s context. So John spoke truly relative to his own context, so he spoke correctly. The important point is that assignments of truthT are relative rather than contextually rigid, so they might be judged true relative to some contexts and false relative to others.\nAlthough both truth relativism and content relativism can explain (46) if they help themselves to the distinction between truthB and truthT, there are four major problems for content relativism that seem to show it is not the correct theory.\nThe first problem concerns embeddings of “might” clauses in belief contexts. Suppose Watson says,\n\nMoriarty believes that Holmes might be in Paris.\n\nOn the content relativist view, (47) will say, relative to Watson, that Moriarty believes that, as far as Watson knows, Holmes is in Paris. That would be a crazy thing for Watson to assert. Suppose Watson is talking to Holmes. Then, relative to Holmes, Watson will have claimed that Moriarty believes that, as far as Holmes knows, Holmes is in Paris. That would also be a crazy thing for Watson to assert. But, given what he’s just overheard, it would be perfectly natural—and pretty clearly correct, so long as nothing funny is going on behind the scenes—for Watson to assert (47). A view that tells us that Watson’s saying something crazy relative to everybody who’s likely to be a member of his audience is in pretty serious conflict with our pretheoretical judgements about the case. (Enlarging the context to include both Holmes and Watson obviously doesn’t help, either.)\nThe second problem concerns the social function of assertion. In particular, it causes difficulties for an attractive part of the Stalnakerian story about assertion, that the central role of an assertion is to add the proposition asserted to the stock of conversational presuppositions (Stalnaker 1978). On the content relativist view, it can’t be that the essential effect of assertion is to add the proposition asserted to the stock of common presuppositions, because there’s no such thing as the proposition asserted. There will be a different proposition asserted relative to each audience member. That’s not part of an attractive theory. And it’s not terribly clear what the replacement story about the essential effect of assertion—about the fundamental role of assertion in communication—is going to be. It may be that there’s a story to be told about assertability—about when Moriarty is entitled to assert, for example, “it might be that Holmes is in Paris”—but there’s no obvious story about what he’s up to when he’s making that assertion—about what the assertion is supposed to accomplish. (And if you think that appropriateness of assertion’s got to be tied up with what your assertion’s supposed to accomplish, then you’ll be sceptical about even the first part.)\nThe third problem concerns epistemic modals in the scope of temporal modifiers. The content relativist has difficulties explaining what’s going on with sentences like (48).\n\nThe Trojans were hesitant in attacking because Achilles might have been with the Greek army.\n\nOn the content relativist view, (48) will be false relative to pretty much everybody—certainly relative to everybody alive today. It’s certainly false that the Trojans were hesitant because, as far as we know, Achilles was with the Greek army. (Or worse, because, as far as we knew then, Achilles was with the Greek army.) But, depending on how the Trojan war went, (48) could be true relative to everybody.37\n37 We don’t take any stand here on just how the war went, if it happened at all. The important point is that whether (48) is true when said of a particular battle is a wide-open empirical question, not one that can be settled by appeal to the semantics of might. The content relativist says, falsely, that it can be thus settled.Finally, content relativism has a problem with commands. Keith’s Mom says:\n\nFor all days d, you should carry an umbrella on d if and only if it might rain on d.\n\nSuppose on Monday Keith checks the forecast and it says there’s a 50% chance of rain. So he takes an umbrella. It doesn’t rain, and on Tuesday he wonders whether what he did on Monday was what his Mom said he should. On the content relativist view, we get the following strange result: on Monday, it would have been true to say that he was doing what his Mom said he should, since at the time, the embedded clause expressed a proposition that was true relative to him. Looking back on Tuesday, though, it looks like he did what his Mom said he shouldn’t, because now the embedded clause expresses a proposition that’s false relative to him. But that’s not right. He just plain did what his Mom told him to do.\nThe same thing happens with the soldiers trying to follow the imperative issued as (22). Assume one of them attempts to follow the command by burning down some trees that seem to contain snipers. Relative to the time she is doing the burning, she will be complying with the command. But later, when it turns out the trees were sniper-free, she will not have been following the command. If we assume there’s an overarching command to not use flamethrowers unless explicitly instructed to do so, then it will turn out that, as of now, she violated her orders then. But that’s not right. She just plain followed her orders.\nThere’s a similar problem with the other terms about which relativism seems plausible. Consider the following commands:\n\nDon’t pick fights with huge opponents.\nStack all of the things that are the same color together.\nIf it tastes lousy, spit it out.\n\nIt’s possible to sensibly issue these commands, even in relevantly mixed company. And if we’re going to get the right compliance conditions, we don’t want content relativism about great-tastingness, hugeness, and same-coloredness here. When we hear a command like (52), we take (a) the same command to have been issued to everybody, and (b) everybody to be following it if we all spit out the things that taste lousy to us. On the content relativist view, we’ve each gotten different commands, and the philosopher who spits out the chunk of week-old antelope hasn’t complied with the command that Vinny was given. This seems wrong.\nSo the content relativist theory has several problems. The truth relativist theory does much better. Let us begin with the familiar notion of a function from worlds to truth values. Call any such function a Modal Profile. On the standard way of looking at things, propositions – the objects of belief and assertion, the semantic values of ‘that’-clauses – are, or at least determine a Modal Profile. The truth relativist denies this. According to the truth-relativist, the relevant propositions are true or false not relative to worlds, but relative to positions within worlds—that is, they’re true or false relative to centered worlds. (A centered world is a triple of a possible world, an individual, and a time.) There’s a few ways to formally spell out this idea. One is to replace talk of Modal Profiles with Centring Profiles, i.e. functions from centred worlds to truth values. Another is to say that a centred world and proposition combine to determine a Modal Profile, so propositions determine functions from centred worlds to Modal Profiles. Each of these proposals has some costs and benefits, and we postpone discussion of their comparative virtues to an appendix. For now we are interested in the idea, common to these proposals, that propositions only determine truth values relative to something much more fine-grained than a world. (We take no stand here on whether propositions should be identified with either Modal Profiles or Centering Profiles or functions from Centred Worlds to Modal Profiles).\nTruth relativism is not threatened by the four problems that undermine content relativism.\nAccording to truth relativism, Watson and Moriarty express the very same proposition by the words Holmes might be in Paris, so it is no surprise that Watson can report Moriarty’s assertive utterance by using the very same words. Similarly, it is no surprise that if Moriarty has a belief that he would express by saying Holmes might be in Paris, Watson can report that by (53).\n\nMoriarty believes that Holmes might be in Paris.\n\nAbove we noted that it’s unlikely that Watson could use this to express the proposition that for all Watson knows Holmes is in Paris. We used that fact to argue that DeRose’s constraint did not apply when an epistemic modal is inside a propositional attitude report. The truth relativist theory predicts not only that DeRose’s constraint should not apply, but that a different constraint should apply. When one says that a believes that b might be F, one says that a believes the proposition b might be F. And a believes that proposition iff a believes it is consistent with what they know that b is F. And that prediction seems to be entirely correct. It is impossible for Watson to use (53) to mean that Moriarty believes that for all Holmes knows he is in Paris, or that for all Watson knows Holmes is in Paris. This seems to be an interesting generalisation, and while it falls out nicely from the truth relativist theory, it needs to be imposed as a special constraint on contextualist theories.\nSince there is a proposition that is common to speakers and hearers when an epistemic modal is uttered, we can keep Stalnaker’s nice idea that the role of assertion is to add propositions to the conversational context. Since propositions are no longer identified with sets of possible worlds we will have to modify other parts of Stalnaker’s theory, but those parts are considerably more controversial.\nThe truth relativist can also explain how (48) can be true, though the explanation requires a small detour through the nature of psychological explanations involving relativist expressions go.\n\nThe Trojans were hesitant in attacking because Achilles might have been with the Greek army.\n\nAll of the following could be true, and not because the things in question are rude, huge or great tasting for us.\n\nMarvin the Martian dropped his pants as the Queen passed by because it would have been rude not to.\nChildren are scared of adults because they are huge.\nVultures eat rotting flesh because it tastes great.\n\nIn general it seems that the truth of an explanatory claim of the form, X \\(\\varphi\\)ed because p depends only on whether p is true in X’s context (plus whether the truth of p in X’s context bears the right relation to X’s \\(\\varphi\\)ing).. Whether or not p is true in our context is neither here nor there. Adults are not huge, rotting flesh does not taste great, and it is rude to drop one’s pants as the Queen passes by, but (54)-(56) could still be true, and could all count as good explanations. Similarly, (48) can be true because Achilles might have been with the Greek army could be true relative to the Trojans.\nSimilarly, what it is to comply with a command is to act in a way that makes the command true in the context of action. This is not a particular feature of epistemic modals, but just a general property of how commands involving propositions with centered-worlds truth conditions behave. If Don picks a fight with Pedro after Don has shrunk so much that Pedro is now relatively huge, he violates (50), even if Pedro was not huge when the command was issued. And he still violates it from a later perspective when Pedro and Don are the same size. The general point is that whether the command is violated depends on the applicability of the salient terms from the perspective of the person to whom the command applies. Similarly, Keith does not violate his Mom’s command if he takes an umbrella where It might rain is true in the context the action is performed. And this, of course, matches up perfectly with intuitions about the case.\nIt’s a little tricky to say just which statement in Professor Granger’s original hexalemma gets denied by the truth relativist. It all depends what we mean by spoke truly. If Myles spoke truly means that Myles said something trueT, then (2) is false (relative to Granger’s context), for its right-hand-side is true but its left-hand-side is false. If, on the other hand, it means he said something trueB relative to his own context, then (4) is false, for he did speak trulyB relative to his context, but it’s not the case that Professor Granger might be in Prague. This is awkward, but we might expect that any good solution to the paradox will be awkward.\n\n\n0.6 Objections to Truth Relativism\nIt might be thought that the truth relativist has to deny Truth in Reporting, but in fact this can be retained in its entirety provided we understand it the right way. The following situation is possible on the truth relativist theory. X has a belief that is true in her context, and Y properly reports this by saying X believes that S, where S in Y’s mouth expresses a proposition that is false in Y’s mouth in her context. But this is no violation of Truth in Reporting. What would be a violation is if X’s belief was true in Y’s context, and still Y could report it as described here. But there’s no case where, intuitively, we properly report an epistemic modal but violate that constraint. And the same holds for reports of uses of huge, color or tastes. Even if Vinny (truly) believes that rotting flesh tastes great, and the words “Rotting flesh tastes great” in John’s mouth express a false proposition, John’s report, “Vinny believes that rotting flesh tastes great” would only violate Truth in Reporting if Vinny’s belief is still true in John’s context. And it is not.\nGiven that the relativist has the concept of truthT, or as we might put it truth simpliciter, what should be done with it? The answer seems to be not much. We certainly shouldn’t restate the norms of assertion in terms of it, because that will lead to the appropriateness of assertion being oddly relativised. Whether it was appropriate for Vinny to say “Rotting flesh tastes great,” is independent of the context of evaluation, even if the truth of what he uttered is context-relative. (It would not at all be appropriate for him to have said “Rotting flesh tastes terrible” even though we should think he would have said something true by that remark, and something false by what he actually said.) And the same thing seems to hold for generalisations about truth as the end of belief. It is entirely appropriate for Myles to believe that Granger might be in Prague, because it’s trueB relative to his context. Relatedly, if knowledge is tied to truthT rather than truthB, knowledge can’t be the norm of assertion or end of belief.38 On the other hand, using truthT we can say that Truth in Reporting is true in the truth relativist theory without reinterpreting it in terms of relative truth concepts. Moreover, we can invoke truthT to explain why we got confused when thinking about the original puzzle: It is arguable that, even if we should distinguish truthT from truthB in our semantic theorizing, we aren’t unreflectively as clear about that distinction as we might be. No wonder then that we get a little confused as we think about the Granger case. We want to say Myles doesn’t make a mistake. And we also want to say “That’s wrong” speaking of the object of his assertion and belief, and what’s more, when we say that, we don’t seem to be making a binary claim about the relation between ourselves and what is believes. Once we clearly distinguish truthT from truthB things become clearly. Using the disquotational notion, we can say ‘That is falseT’, which is a monadic claim, and not a binary one. The binary truthB explains why that claim is assertable (it is assertable because ‘That is falseT’ is truthB at my context), but doesn’t figure in the proposition believed. Meanwhile, the relevant notion of mistake – that of an agent believing a proposition that is not trueB at her context, can only be properly articulated once the distinction between the more explanatory truthT is carefully distinguished from the (arguably) conceptually more basic truthB.\n38  Arguably, then, one will have to distinguish (and posit an ordinary conflation between) knowledgeT from knowledgeB, the latter being needed to make good on the normative importance of knowledge, the former being need to make sense of the validity of the inference from knowing that p to p. Is trouble lurking here for the truth relativist, especially given link between the truthB of ‘might’ claims and facts about knowledge? We shall not pursue the matter further here.One final expository point. In general, truth relativism makes for irresolvable disputes. Let us say that two conversational partners are in deadlock concerning a claim when the following situation arises: There is a pair of conversational participants, x and y, and a sentence S, under dispute, such that each express the same proposition (in the sense explained) by S but that S is trueB at each of the contexts x is in during the conversation, and falseB at each of the contexts y is in during the conversation. Neither speaks past one another in alternately asserting and denying the same sentence, since each expresses the same proposition by it. And each asserts what they should be asserting when each says: What I say is truthT and what the other says is falseT., since each makes a speech that is trueT at the respective contexts. In general, truth relativism about a term will lead one to predict deadlock for certain conversations, traceable to the truth relativity of the term. But in the case of ‘might’, it is arguable that conversation tends to force a situation where, even if at the outset, a ‘might’ sentence was true relative to x and not to y (on account of the truth-relativity of the ‘might’ sentence), x and y will, in the course of engagement and dispute, be quickly put into a pair of contexts which do not differ with respect to truthB (unless the ‘might’ sentence contained other terms that themselves made for deadlock). This is not merely because the conversational participants will, through testimony, pool knowledge about the sentence embedded in the ‘might’ claim. It is in any case arguable that the relevant community whose body of knowledge determines whether a ‘might’ claim is trueB at a context always includes not just that of the person at that context but also that of his conversational partners. In the special case of ‘might’, then, Truth Relativism may well generate far less by way of deadlock than in other cases.\nThere are two primary objections to the truth relativist theory: it doesn’t quite handle all the cases and that it is too radical.\nThere are some cases that seem to tell directly against the truth relativist position. Consider the case again of Tom and Sally stuck in a maze. Sally knows the way out, but doesn’t want to tell Tom. She says, inter alia, (57), and does not seem to violate any semantic norms in doing so, even though she knows the exit is some other way.\n\nThe exit might be that way.\n\nThis seems to directly contradict the relativist claim that the norm for assertion is speaking truly in one’s own context. We suspect that what’s going on here is that Sally is projecting herself into Tom’s context. She is, we think, merely trying to verbalise thoughts that are, or should be, going through Tom’s head, rather than making a simple assertion. As some evidence for this, note (as was mentioned above) that it would be wrong to take (57) as evidence that Sally believes the exit might be that way, whereas when a speaker asserts that p that is usually strong evidence that she believes that p. It is unfortunate for the relativist to have to appeal to something like projection, but we think it is the simplest explanation of these cases that any theorist can provide.\nThe idea that utterances have their truth value absolutely is well-entrenched in contemporary semantics, so it should only be overturned with caution. And it might be worried that once we add another degree of relativisation, it will be open to relativise in all sorts of directions. We are sensitive to these concerns, but we think the virtues of the relativist theory, and the vices of the contextualist and invariantist theories, provides a decent response to them. Invariantist theories are simply implausible, and any contextualist theory will have to include so many ad hoc conditions, conditions that seem to be natural consequences of relativism, that there are methodological considerations telling in favour of relativism. (Let us be clear: we are not recommending a general preference for relativism over contextualism in semantic theory. As we have been trying to make clear, for example, the case of ‘might’ is very different from, say, the case of ‘ready’.) It is (as always) hard to tell which way the balance tips when all these methodological considerations are weighed together, but we think the relativist has a good case.\n\n\nAppendix on Types of Content\nRobert Stalnaker has long promoted the idea that the content of an assertoric utterance is a set of possible worlds, or a function from worlds to truth values. This idea has been enormously influential in formal semantics, although it has come in for detailed criticism by various philosophers. (See especially Soames (1987) and King (1994, 1995, 1998).) But even philosophers who think that there is more to content than a set of possible worlds would agree that propositions determine a function from worlds to truth values. Some would agree that such a function exhausts the ‘discriminatory role’ of a proposition, although this depends on the (highly contestable) assumption that the role of propositions is to discriminate amongst metaphysical possibilities. Still, even philosophers who disagree with what Stalnaker says about the nature of propositions could agree that if all we wanted from a proposition was to divide up some metaphysical possibilities, propositions could be functions from worlds to truth values, but they think some propositions that divide up the metaphysical possibilities the same way should be distinguished.\nWe don’t want to take sides in that debate, because our truth relativism means we are in conflict with even the idea that a proposition determines a function from worlds to truth values. To see this, consider a sentence whose truth value is relative to a context of evaluation, such as Vegemite tastes great. The truth relativist says that this sentence should be evaluated as true from a context where people like the taste of Vegemite (call this the Australian context) and should be evaluated as false from a context where people dislike this taste (call that the American context) and both evaluations are correct (from their own perspective) even though the Australians and Americans agree about what the content of Vegemite tastes great is, and they are in the same world. So there’s just no such thing as the truth value of Vegemite tastes great in the actual world, so it does not determine a function from worlds to truth values. What kind of function does it determine then?\nOne option, inspired by Lewis’s work on de se belief, is to say that it determines a function from centred worlds to truth values. The idea is that we can identify a context of evaluation with a centred world, and then Vegemite tastes great will be true relative to a centred world iff it is properly evaluated as true within that context. Alternatively, the content of Vegemite tastes great will determine a set of centred worlds, the set of contexts from which that sentence would be evaluated as true. Just as propositions were traditionally thought to determine (or be) sets of possible worlds, properties were traditionally thought to determine (or be) functions from worlds to sets of individuals.39 Now if we identify centred worlds with \\(\\langle\\)individual, world\\(\\rangle\\) pairs, a function from worlds to sets of individuals just is a set of centred worlds.40 So the content of Vegemite tastes great could just be a property, very roughly the property of being in a context where most people are disposed to find Vegemite great-tasting.\n39  Lewis preferred the theory on which properties were sets of individuals, potentially from different worlds. This theory has difficulties accounting for individuals that exist in more than one world. And since properties exist in more than one world, and properties have to be treated as individuals in some contexts (e.g. when they are the subjects of predication) this is a serious problem. Treating properties as functions from worlds to sets of individuals removes this problem without introducing any other costs. (See Egan (2004) for more details.)40 Matters are a little more complicated when we introduce times into the story. For purposes of this appendix we ignore all matters to do with tense. As you’ll see, the story is complicated enough as it is, and this omission doesn’t seriously affect the dialectic to follow.41 It might be that propositions just are whatever things are the contents of assertions and beliefs, so we shouldn’t say that the contents of sentences like Vegemite tastes great are not propositions. But they will be very different kinds of propositions to what we are used to. Thanks here to John MacFarlane.This proposal has three nice features. First, even though the content of Vegemite tastes great is not, and does not even determine, a proposition as Stalnaker conceived of propositions, it does determine a property. So the proposal is not as radical as it might at first look. Second, properties are the kind of thing that divide up possibilities. The possibilities they divide are individuals, not worlds, but the basic idea that to represent is to represent yourself as being in one class of possible states rather than another is retained. The only change is that instead of representing yourself as being in one class of worlds rather than another, you represent yourself as being in one class of \\(\\langle\\)individual, world\\(\\rangle\\) pairs rather than another. Third, the proposal links up nicely with David Lewis’s account of de se belief, and offers some prospects for connecting the contents of beliefs with the contents of assertions, even when both of these contents have ceased to be propositions in Stalnaker’s sense.41\nBut there’s a problem for this account. Consider what we want to say about Possibly Vegemite tastes great, where context makes it clear that the ‘possibly’ is a metaphysical modal. There’s a trivial problem and a potentially deep problem for this account. The trivial problem is that we know what the meaning of possibly is. It’s a function that takes propositions as inputs and delivers as output a proposition that is true iff the input proposition is true at an accessible world. If the content of Vegemite tastes great is a property rather than a proposition, then we have a type-mismatch. This is a trivial problem because it’s a fairly routine exercise to convert the meanings of words like possibly so they are the right kind of things to operate on what we now take the meaning of Vegemite tastes great to be.\nThe deep problem is that when we go through that routine exercise, we get the wrong results. We don’t want Possibly Vegemite tastes great to be true in virtue of there being an accessible world where the people there like the taste of Vegemite. We want it to be true in virtue of there being a world where Vegemite’s taste is a taste that in this context we’d properly describe as great. And it’s not clear how to get that on the current story. To see how big a problem this is, consider (58), where the modal is meant to be metaphysical and have wide scope.\n\nPossibly everyone hates Vegemite but it tastes great.\n\nThat’s true, on its most natural reading. But the content of Everyone hates Vegemite but it tastes great will be the empty set of centred worlds, for there is no centred world on which this is true. Now it’s not clear just what the meaning of possibly could be that delivers the correct result that (58) is true.\nSo we are tempted to consider an alternative proposal. Start with a very natural way of thinking about why the relativist has to modify the Stalnakerian story about content. The problem is that (even given a context of utterance) tastes great does not determine a property. Rather, relative to any context of evaluation, i.e. centred world, it determines a property. That is, its content is (or at least determines) a function from centred worlds to properties. So given our actual context, it determines the property of having a taste that people around here think is great. Now properties combine with individuals to form Stalnakerian propositions. So tastes great is a function from centred worlds to functions from individuals to sets of worlds. Hence Vegemite tastes great is a function from centred worlds to sets of worlds, the previous function with the value for the ‘individual’ being fixed as Vegemite.\nOur second option then is that in general that sentences containing ‘relative’ terms like ‘tastes’ or ‘huge’ or ‘might’ determines a function from centred worlds to sets of worlds. This makes it quite easy to understand how (58) could work. Possibly type-shifts so that it is now a function from functions from centred worlds to sets of worlds to functions from centred worlds to sets of worlds. It’s fairly easy to say what this function is. If the content of p is (or determines) f, a function from centred worlds to sets of worlds, then the content of \\(\\lozenge p\\) is (or determines) g, the function such that for any centred world c, w \\({\\in}\\) g(c) iff for some w\\(^\\prime\\) accessible from w, w\\(^\\prime\\) \\({\\in}\\) f(c). The core idea is just that we ignore the role of the centred worlds until the end of our semantic evaluation, and otherwise just treat \\(\\lozenge\\) as we’d treated it in traditional semantics. This is a rather nice position in many ways, but there are two issues to be addressed.\nFirst, it is not clear that functions from centred worlds to sets of worlds are really kinds of content. They are not things that divide up intuitive possibilities, in the way that sets of individuals, and sets of \\(\\langle\\)individual, world\\(\\rangle\\) pairs do. It’s no good to say that relative to a centred world a content is determined. That would be fine if we were content relativists, and we said the content was meant to be determined relative to a centred world. But as argued in the text the content of Vegemite tastes great should be the same across various contexts of evaluation. A better response is to say functions from centred worlds to sets of worlds do determine a kind of content. For any such function f, we can determine the set of centred worlds \\(\\langle\\)i, w\\(\\rangle\\) such that w \\({\\in}\\) f(\\(\\langle\\)i, w\\(\\rangle\\)). These will be the centred worlds that the proposition is true at. It’s not necessarily a problem that the proposition does more than determine this set. (It’s not an objection to King’s account of propositions that on his theory propositions do more than determine a set of possibilities.)\nSecond, it isn’t exactly clear how to fill out these functions when we get back to our core case: epistemic modals. It’s easy to say what it is for Vegemite tastes great to be true in a world relative to our context of evaluation; indeed we did so above. It’s a lot harder to say what it is for Granger might be in Prague to be true in an arbitrary world w relative to an arbitrary context of evaluation c. As a first pass, we might say this is true in w iff for all the people in c know, it is true in w that Granger is in Prague. But the problem is that whenever c is not a centre in w, it’s very hard to say just what the people in c know about w. Under different descriptions of w they will know different things about it. If w is described as a nearby world in which Granger is in Cleveland, they will know Granger is not in Prague in w. If it is described as a nearby world in which Myles knows where Granger is they may not know anything about whether Granger is in Prague is in w, even if those descriptions pick out the same worlds. Ideally we would cut through this by talking about their de re knowledge about w, but most folks have very little de re knowledge about other possible worlds. It’s not clear this is a huge problem though. Remember that a sentence containing an epistemic modal is meant to determine a function from centred worlds to functions from worlds to truth values. Provided we have a semantics that allows for semantic indeterminacy, we can just say that the functions from worlds to truth values are partial functions, and they simply aren’t determined when it’s unclear what the people in c know about w. Or we can say there’s a default semantic rule such that w is not in f(c) (where f is the function determined by the sentence) whenever this is unclear. Since the sentences whose meanings are determined by these values of the function, like Possibly Granger might be in Prague are similarly vague, it is no harm if the function is a little vague.\nSo we have two options on the table for what kind of functions sentences might determine if they don’t determine functions from world to truth values. One option is that they determine functions from centred worlds to truth values, another that they determine functions from centred worlds to functions from worlds to truth values. Neither is free from criticism, and the authors aren’t in agreement about which is the best approach, so it isn’t entirely clear what the best way to formally implement truth relativism is. But it does not look like there are no possible moves here. Moving to truth relativism does not mean that we will have to totally abandon the fruitful approaches to formal semantics that are built on ideas like Stalnaker’s, although it does mean that those semantic theories will need to be modified in places.\n\n\n\n\n\n\nReferences\n\nCapellen, Herman, and Ernest Lepore. 1997. “On an Alleged Connection Between Indirect Quotation and Semantic Theory.” Mind and Language 12 (3-4): 278–96. https://doi.org/10.1111/j.1468-0017.1997.tb00075.x.\n\n\nDeRose, Keith. 1991. “Epistemic Possibilities.” Philosophical Review 100 (4): 581–605. https://doi.org/10.2307/2185175.\n\n\n———. 1998. “Simple Might’s, Indicative Possibilities, and the Open Future.” The Philosophical Quarterly 48 (190): 67–82. https://doi.org/10.1111/1467-9213.00082.\n\n\nEgan, Andy. 2004. “Second-Order Predication and the Metaphysics of Properties.” Australasian Journal of Philosophy 82 (1): 48–66. https://doi.org/10.1080/713659803.\n\n\nFintel, Kai von, and Sabine Iatridou. 2003. “Epistemic Containment.” Linguistic Inquiry 34 (2): 173–98. https://doi.org/10.1162/002438903321663370.\n\n\nHawthorne, John. 2004. Knowledge and Lotteries. Oxford: Oxford University Press.\n\n\nHorn, Laurence. 1989. A Natural History of Negation. Chicago: University of Chicago Press.\n\n\nJacobson, Pauline. 1999. “Towards a Variable Free Semantics.” Linguistics and Philosophy 22 (2): 117–84. https://doi.org/10.1023/A:1005464228727.\n\n\nKing, Jeffrey. 1994. “Can Propositions Be Naturalistically Acceptable?” Midwest Studies in Philosophy 19 (1): 53–75. https://doi.org/10.1111/j.1475-4975.1994.tb00279.x.\n\n\n———. 1995. “Structured Propositions and Complex Predicates.” Noûs 29 (4): 516–35. https://doi.org/10.2307/2216285.\n\n\n———. 1998. “What Is a Philosophical Analysis?” Philosophical Studies 90 (2): 155–79. https://doi.org/10.1023/A:1004254128428.\n\n\nLewis, David. 1976. “The Paradoxes of Time Travel.” American Philosophical Quarterly 13 (2): 145–52.\n\n\n———. 1979. “Scorekeeping in a Language Game.” Journal of Philosophical Logic 8 (1): 339–59. https://doi.org/10.1007/bf00258436.\n\n\nMacFarlane, John. 2003. “Future Contingents and Relative Truth.” The Philosophical Quarterly 53 (212): 321–36. https://doi.org/10.1111/1467-9213.00315.\n\n\nPagin, Peter. 2005. “Compositionality and Context.” In Contextualism in Philosophy: Knowledge, Meaning, and Truth, edited by Gerhard Preyer and Georg Peter, 303–48. Oxford: Oxford University Press.\n\n\nSoames, Scott. 1987. “Direct Reference, Propositional Attitudes and Semantic Content.” Philosophial Topics 15 (1): 47–87. https://doi.org/10.5840/philtopics198715112.\n\n\n———. 2002. Beyond Rigidity. Oxford: Oxford University Press.\n\n\nStalnaker, Robert. 1978. “Assertion.” Syntax and Semantics 9: 315–32.\n\n\nStanley, Jason. 2000. “Context and Logical Form.” Linguistics and Philosophy 23 (4): 391–434. https://doi.org/10.1023/A:1005599312747.\n\n\nStanley, Jason, and Zoltán Gendler Szabó. 2000. “On Quantifier Domain Restriction.” Mind and Language 15 (2&3): 219–61. https://doi.org/10.1111/1468-0017.00130."
  },
  {
    "objectID": "posts/kuir/keynes-uncertainty-and-interest-rates.html",
    "href": "posts/kuir/keynes-uncertainty-and-interest-rates.html",
    "title": "Keynes, Uncertainty and Interest Rates",
    "section": "",
    "text": "Keynes (1936) clearly saw an important role for uncertainty in his General Theory. However, few contemporaries agreed with him, and subsequent ‘Keynesians’ generally obliterated the distinction between risk and uncertainty. In part this was caused by Keynes’s informal presentation of his views on uncertainty in The General Theory. This paper has two aims. The first is to sketch a formal theory of uncertainty which captures Keynes’s insights about the risk/uncertainty distinction. I argue that the theory of imprecise probabilities developed in recent years best captures Keynes’s intuitions about uncertainty. In particular this theory provides a formal distinction between risk and uncertainty, and allows for an analysis of Keynes’s ‘weight’ of arguments. However, the second aim is to show that if this is right then Keynes was wrong to draw the economic consequences of uncertainty that he did. In broad terms, I argue that uncertainty is economically impotent. It only has effects in conjunction with some other feature of models or the world, such as missing markets or agent irrationality. But these features plus the existence of risk are sufficient to get the conclusions Keynes wants. These conclusions of Keynes might be right, but if so they can be justified without reference to Keynesian uncertainty. At the end of the day, uncertainty is not as economically interesting as it appears.\n\nPublished in Cambridge Journal of Economics 26: 47-62.\nPicture by Extra Medium via Creative Commons.\n\n\n0.1 Imprecise Probabilities\nIn the classical, or Bayesian1, model of rationality all rational agents have precise degrees of belief, or credences, in each proposition. There is a probability function \\(Bel\\) such that for any proposition \\(A\\), there is a number \\(Bel(A)\\). So if an agent believes \\(p\\) to degree \\(x\\) she believes \\(p\\) to degree \\(1-x\\). This is appropriate for some propositions. For example, if \\(p\\) is a proposition about the decay of an atom with known half-life, or about any event with a known objective chance and hence subject to risk and not uncertainty, the agent’s credences should reflect the chances. Since chances are precise and form a probability function, the credences will also have these properties. The Bayesian theory assumes that all situations can be treated by analogy with these.\n1 For this paper I follow Walley (1991) in describing those theorists who require that all agents have precise degrees of belief and these degrees form a probability function as Bayesians. There is some dispute as to the accuracy of this labelling, particularly as some paradigm case Bayesians, such as Jeffrey (1983) and Fraassen (1990), accept that degrees of belief can be vague. However, there is probably no other name as convenient or as recognisable.As Keynes pointed out in the famous QJE article (Keynes 1937b), this analogy is clearly mistaken. When \\(p\\) is about the price of copper in thirty years, we do not know the chance that \\(p\\) will be true. And we do not have enough information to form a precise credence. As Keynes had argued in his Treatise on Probability sixteen years earlier, attempts to avoid this problem by appeal to a Principle of Indifference lead to contradiction. In The General Theory he noted that he still approved of this little argument (Keynes 1936, 152). Hence Bayesians have no way of representing our ignorance in uncertain situations. They say that all rational agents have a precise epistemic attitude towards each proposition, believing it to some precise degree, whereas ignorance consists in not having such a precise attitude.\nThe theory of imprecise probabilities avoids all of these difficulties. The theory is quite old, dating back to work by Gerhard Tintner (1941) and A. G. Hart (1942), but has only received extensive consideration recently. The best modern summaries are by the philosopher Isaac Levi (1980) and the statistician Peter Walley (1991). There are minor differences, but the theory I shall give captures all the common ingredients. According to Bayesians, states of rational agents are represented by a single probability function \\(Pr\\); in the imprecise theory they are represented by a set of probability functions \\(S\\). The agent’s credence in \\(p\\) is vague over the set of values that \\(Pr(p)\\) takes for \\(Pr \\in S\\). In the extreme case, for every \\(x \\in [0, 1]\\) there will be a \\(Pr \\in S\\) such that \\(Pr(p) = x\\). This represents almost total ignorance about \\(p\\). The set \\(S\\) is called the ‘representor’ of the agent whose credences it represents.\nIt is important to stress what \\(S\\) represents, because there has been some confusion over this2. The \\(Pr\\) do not represent the agent’s hypotheses about the correct distribution of objective chances. I use the phrase ‘objective chance’, or just ‘chance’, to refer to a property that plays a certain role in fundamental physics, the property which makes it the case that the whirrings of atoms in the void is indeterminate. Modern physics, or at least the most popular versions of it, teaches that chance infects all fundamental physical events. These chances fulfill all the properties that anyone has ever wanted in probabilities. They reflect long-run frequencies of repeated events, they put restrictions on reasonable degrees of belief, they can be properly applied to single cases, and so on. If all fundamental physical events are chance events, then arbitrary Boolean combinations of fundamental physical events should also, presumably, be chance events. But any event whatsoever is some combination of fundamental physical events, though for many it may not be clear which combination. So baseball games, romantic affairs and stock market movements are all chance events in this sense, even though they are not, for instance, repeatable events. Of course, trying to predict these using the laws of physics will be even less productive than trying to predict them using the methods we currently have available. Saying where all the atoms, or quarks, currently are is humanly impossible, and perhaps theoretically impossible as well. Even allowing for this, computing where they will move before they get there is beyond the capacity of any possible machine.\n2 See, for example, Gärdenfors and Sahlin (1982), Levi (1982).I distinguish between a situation where the agent does not know the objective chance of some proposition, and a situation where the agent has no precise credence in that proposition. An agent can have a precise credence in \\(p\\) without knowing its objective chance. If the agent believes that a certain number of chance distributions are possible, and gives each of them a precise credence, this entails she has a precise credence in each event. (Imagine we see a fair coin be tossed, and land, but do not see how it falls. The objective chance that it shows heads is either one, if it does, or zero, otherwise. But the appropriate credence in the proposition, the coin has landed heads, is one half.) Rather the \\(Pr\\) represent the precise credence distributions that are consistent with real imprecise distribution. For example, for some rational agent, and some proposition \\(p\\), the agent’s epistemic state will determine that she believes \\(p\\) to a greater degree than 0.2, and a lesser degree than 0.4, but there will be no more facts about the matter. (In this case \\(S\\) will include a function \\(Pr\\) such that \\(Pr(p) = x\\) for each \\(x \\in [0.2,~0.4]\\).) If we ask her whether she thinks \\(p\\) is more likely than some proposition, call it \\(q\\), which she believes to degree 0.3, she will not be able to say one way or the other. And this is not just because she lacks rationality or powers of introspective observation. It is no requirement of rationality that she believe \\(p\\) is more likely, less likely or equally likely than \\(q\\) As Levi and Walley have pointed out, the Bayesian arguments purporting to show this is a constraint on rationality have been hopelessly circular.\nThe reasons for wanting to be able to represent uncertainty were stressed by Keynes, and are generally well known. Before showing why this theory captures Keynes’s intuitions about uncertainty, I will briefly mention two nice formal features of the theory of imprecise probabilities. On many theories of uncertainty, particularly those that represent uncertain agents as having interval valued degrees of belief, it is hard to explain comparative statements, like “\\(p\\) seems more likely to me than \\(q\\)”. These comparatives are crucial to our everyday practices of probabilistic reasoning. We say \\(p\\) is more probable than \\(q\\) according to \\(S\\) iff for all \\(Pr \\in S, Pr(p) &gt; Pr(q)\\). This lets us say, as seems right, that \\(A\\) is more probable than \\(A \\wedge B\\) for almost all propositions \\(A, B\\).\nThe second formal advantage is that we now have a simple way to update epistemic states on receiving new evidence. Let \\(S\\) be the agent’s current representor, and the new evidence be \\(e\\). Then the updated representor, \\(S_e\\) is given as follows: \\[S_e = \\{Pr(\\bullet | e): Pr \\in S\\}\\]\nThat is, we just conditionalise every probability function in \\(S\\). Again, updating has proven problematic for some approaches to uncertainty. The theory of evidence functions, developed by Dempster (1967) and Shafer (1976) allows that an agent can know that if either \\(e\\) or \\(\\neg e\\) comes in as evidence, their credence in \\(p\\) will rise. This seems absurd; we can know before an experiment that whatever happens we’ll be more confident in \\(p\\) than we are now.\nTo take a famous example, three prisoners \\(X\\), \\(Y\\) and \\(Z\\) are about to be exiled to Elba. The governor decides on a whim that he will pardon one, and casts a fair die to choose which. He tells the guards who is pardoned, but instructs them not to tell the prisoners yet. \\(X\\) pleads futilely with his guard, and finally asks, “Can you tell me the name of one of the others who won’t be pardoned.” The guard, realising this will not reveal \\(X\\)’s fate, agrees to answer. \\(X\\) thinks that if \\(Y\\) is pardoned, the guard will say \\(Z\\), so there is at least a one-third probability of that. And if \\(Z\\) is pardoned, the guard will say \\(Y\\), so there is also at least a one-third probability of that. But if he is pardoned, what the guard will have to decide what to say, and we can’t make probability judgements about free human decisions. On the Dempster-Shafer theory, the probability of \\(X\\) being freed is one-third, but the probability of \\(X\\) being freed and the guard saying \\(Y\\) goes to Elba is zero, and the probability of \\(X\\) being freed and the guard saying \\(Z\\) goes to Elba is zero. This is just a standard failure of additivity, and not at all objectionable. The problem is that when the guard says that \\(Y\\) will go to Elba, or that \\(Z\\) will go to Elba, the probability of \\(X\\) being freed rises to one-half. (I will not go through the mathematics here, because it can be found in any book on the Dempster-Shafer theory. See, for example, Walley (1991) or Yager, Fedrizzi, and Kacprzyk (1994).) Since \\(X\\) did not learn about his chances of freedom, this seems like a rather odd result. The theory of imprecise probabilities avoids this problem. It can be easily shown that on this theory for any evidence \\(e\\) if the probability of \\(p\\) given \\(e\\) is greater than the probability of \\(p\\), then the probability of \\(p\\) given \\(\\neg e\\) is less than the probability of \\(p\\). (Again Walley (1991) contains the proof.)\n\n\n0.2 Keynes and Imprecise Probabilities\nObviously enough, this is not the theory that Keynes formally endorses, either in his Treatise on Probability (Keynes 1921) or his economic writings. Nevertheless, I think it is an important theory for understanding Keynes’s use of uncertainty. This is because it, and it alone, captures all of the underlying motivations of Keynes’s theory of uncertainty. Hence any economic consequences of uncertainty Keynes wants to draw will have to be derivable from this theory.\nI have so far spoken blithely of ‘Keynes’s theory of uncertainty’, implicitly assuming there is such a unique theory. In recent years a number of authors (e.g. Runde (1994a; Davis 1994; Coates 1996; Bateman 1996) have questioned this assumption, saying that Keynes changed his theory between the writing of the Treatise on Probability and The General Theory. I will not deal directly with such criticisms here for a number of reasons. First, the main dispute is over whether probabilities are given by logic or are ‘merely subjective’, and that debate is independent of the debate about the effects of allowing imprecise probabilities. Secondly, there are obvious space constraints. Many of these alternative interpretations were put forward in book length arguments, and a fair response to them would not be short. Thirdly, and perhaps most importantly, I take it that the methodological game here is inference to the best explanation. Whatever criticisms I make of others’ interpretations would be rather weak unless I showed that some other overall story was more persuasive. And if I come up with a more persuasive story here criticisms of their accounts will be slightly redundant. So I hope the reader at least permits the indulgence of setting out a theory of Keynes’s ideas predicated on this rather controversial assumption.\nIn the Treatise on Probability (Keynes (1921), hereafter TP) Keynes says that probability is essentially a property of ordered pairs of propositions, or what he calls arguments. He writes \\(p / q = \\alpha\\), for the probability of hypothesis \\(p\\) on evidence \\(q\\) is \\(\\alpha\\). Now this value \\(\\alpha\\) is rather unusual. It sometimes is a number, but sometimes not; it sometimes can be compared to all numbers, but sometimes not; it sometimes can be compared to other probability values such as \\(\\beta\\), but sometimes not and it can enter into arithmetic operations. As a consequence probabilities are subject to all the usual rules of the classical probability calculus. For example, whenever \\(p\\) and \\(r\\) are inconsistent, then \\((p \\vee r) / q = p / q + r / q\\) always holds, even when none of these values is numerical.\nThese five properties are rather perplexing. Indeed, Keynes’s failure to explain or justify them fully is one of the main criticisms that Ramsey (Ramsey 1926, 161–66) launches at Keynes’s theory. But on this theory they all fall out as consequences of our definitions. If \\(p/q = \\alpha\\) then \\(\\alpha\\) will be numerical iff there is some \\(x\\) such that for all \\(Pr \\in S, Pr(p | q) = x\\). Similarly \\(\\alpha &gt; y\\), for real valued \\(y\\), iff \\(Pr(p | q) &gt; y\\) for all \\(Pr \\in S\\). A similar definition holds for \\(\\alpha &lt; y\\) and \\(\\alpha = y\\), from which it can be seen that it is possible that \\(\\alpha\\) is neither greater than, less than, nor equal to \\(y\\). If none of these hold we say that \\(\\alpha\\) and \\(y\\) are incomparable. If \\(p / q = \\alpha\\) and \\(r / s = \\beta\\) then \\(\\alpha &gt; \\beta\\) iff for all \\(Pr \\in S, Pr(p | q) &gt; Pr(r | s)\\). Again similar definitions of less than and equal to apply, and the consequence of all these is that sometimes \\(\\alpha\\) and \\(\\beta\\) will be comparable, sometimes not.\nRamsey is right to question the intelligibility of Keynes’s use of addition and multiplication. We know what it means to add and multiply numbers, but we have no idea what it is to add or multiply non-numerical entities. However, on this theory addition and multiplication are perfectly natural. Since we represent \\(\\alpha\\) and \\(\\beta\\) by sets, generally intervals, then \\(\\alpha + \\beta\\) and \\(\\alpha \\dot \\beta\\) will be sets. They are defined as follows. Again let \\(p / q\\ = \\alpha\\) and \\(r / s = \\beta\\).\n\\[\\begin{aligned}\n\\alpha + \\beta &= \\{x: \\exists Pr \\in S (Pr(p | q) + Pr(r | s) = x)\\} \\\\\n\\alpha \\dot \\beta &= \\{x: \\exists Pr \\in S (Pr(p | q) \\dot Pr(r | s) = x)\\} \\end{aligned}\\]\nThese definitions are natural in the sense that we are entitled to say that the ‘+’ in \\(\\alpha + \\beta\\)means the same as the ‘+’ in 2 + 3. And the definitions show why Keynes’s \\(\\alpha\\)’s and \\(\\beta\\)’s will obey the axioms of the probability calculus. Even if \\(p / q\\) and \\(\\neg p / q\\) are non-numerical, \\(p / q + \\neg p / q\\) will equal {1}, or effectively 1. So we have something like the additivity axiom, without its normal counterintuitive baggage. The main problem with additivity is that sometimes we may have very little confidence in either \\(p\\) or \\(\\neg p\\), but we are certain that \\(p \\vee \\neg p\\). If we measure confidence by the lower bound on these probability intervals, this is all possible on our theory. Our technical apparatus removes much of the mystery behind Keynes’s theory, and fends off an important objection of Ramsey’s.\nThe most famous of Keynes’s conceptual innovations in the TP is his introduction of ‘weight’. He does this in the following, relatively opaque, paragraph.\n\nAs the relevant evidence at our disposal increases, the magnitude of the probability of the argument may either decrease or increase, according as the new knowledge strengthens the unfavourable or the favourable evidence; but something seems to have increased in either case, – we have a more substantial basis upon which to rest our conclusion. I express this by saying that an accession of new evidence increases the weight of an argument. New evidence will sometimes decrease the probability of an argument, but it will always increase its ‘weight’ (Keynes 1921, 77, italics in original).\n\nThe idea is that \\(p / q\\) measures how the evidence in \\(q\\) is balanced between supporting \\(p\\) and supporting \\(\\neg p\\). The concept of weight is needed if we want to also know how much evidence there is. Note that weight only increases when relevant evidence comes in, not when any evidence comes in. The weight of the argument from my evidence to “Oswald killed JFK” is not increased when I discover the Red Sox won last night.\nThe simplest definition of relevance is that new evidence \\(e\\) is irrelevant to \\(p\\) given old evidence \\(q\\) iff \\(p / q \\wedge e)= p / q\\), and relevant otherwise. Now there is a problem. Two pieces of evidence \\(e_1\\) and \\(e_2\\) can be irrelevant taken together, but relevant taken separately. For a general example, let \\(e_1\\) be \\(p \\vee r\\) and \\(e_2\\) be \\(\\neg p \\vee r\\), for almost any proposition \\(r\\). If I receive \\(e_1\\) and \\(e_2\\) sequentially, the weight of the argument from my evidence to \\(p\\) will have increased twice as I receive these new pieces of evidence. So it must be higher than it was when I started. But if I just received the two pieces of evidence at once, as one piece of evidence, I would have properly regarded it as irrelevant. Hence the weight in question would be unchanged. So it looks as if weight depends implausibly not on what the evidence is, but on the order in which it was obtained.\nKeynes avoids this implausibility by tightening up the definition of irrelevance. He says that \\(e\\) is irrelevant to \\(p / q\\) iff there are no propositions \\(e_1\\) and \\(e_2\\) such that \\(e\\) is logically equivalent to \\(e_1\\ \\wedge e_2\\) and either \\(e_1\\) or \\(e_2\\) is relevant to \\(p / q\\). Unfortunately, as I noted in the previous paragraph for virtually any such evidence proposition there will be such propositions \\(e_1\\) and \\(e_2\\). This was first noticed by Carnap (1950). Keynes, had he noticed this, would have had three options. He could conceded that everything is relevant to everything, including last night’s baseball results to the identity of Kennedy’s assassin; he could have conceded that the order in which evidence appears does matter, or he could have given up the claim that new relevant evidence always increases the weight of arguments.\nThe last option is plausible. Runde (1990) defends it, but for quite different reasons. He thinks weight measures the ratio of evidence we have to total evidence we believe is available. Since new evidence might lead us to believe there is much more evidence available than we had previously suspected, the weight might go down. I believe it holds for a quite different reason, one borne out by Keynes’s use of uncertainty in his economics. In The General Theory (Keynes (1936), hereafter GT) Keynes stresses the connection between uncertainty and ‘low weight’ (GT: 148n). If we regard \\(p\\) as merely risky the weight of the argument from our evidence to \\(p\\) is high, if we regard \\(p\\) as uncertain the weight is low. In the Quarterly Journal of Economics article he argues that gambling devices are, or can be thought to be, free of uncertainty, whereas human actions are subject to uncertainty. So the intervention of humans can take a situation from being risky to being uncertain, and hence decrease the weight in question.\nFor example, imagine we are playing a rather simple form of poker, where each player is dealt five cards and then bets on who has the best hand. Before the bets start, I can work out the chance that some other player, say Monica, has a straight. So my credence in the proposition Monica has a straight will be precise. But as soon as the betting starts, my credence in this will vary, and will probably become imprecise. Do those facial ticks mean that she is happy with the cards or disappointed? Is she betting high because she has a strong hand or because she is bluffing? Before the betting starts we have risk, but no uncertainty, because the relevant probabilities are all known. After betting starts, uncertainty is rife.\nThe poker example supports my analysis of weight. If weight of argument rises with reduction of uncertainty, then in some rare circumstances weight of arguments decreases with new evidence. Let \\([x_1, x_2]\\) be the set given by \\(\\{x: Pr(p | q) = x\\}\\) for some \\(Pr \\in S\\}\\), where \\(S\\) is the agent’s representor. Then the weight of the argument from \\(p\\) to \\(q\\), for this agent, is \\(1-(x_2 - x_1)\\). That is, the weight is one when the agent has a precise degree of belief in \\(p\\), zero when she is totally uncertain, and increasing the narrower the interval \\([x_1, x_2]\\) gets. Now in most cases new relevant evidence will increase the weight, but in some cases, like when we are watching Monica, this will not happen. I follow Lawson (1985) in saying that \\(p\\) is uncertain for an agent with evidence \\(q\\) iff \\(p / q\\) is non-numerical, i.e. iff the weight of the argument from \\(q\\) to \\(p\\) is less than one. Hence we get the connection between uncertainty and weight Keynes wanted. I also claim that the bigger \\(x_2 - x_1\\) is, the more \\(p / q\\) is unlike a real number, the more uncertain \\(p\\) is. Keynes clearly intended uncertainty to admit of degrees Keynes (1937b), so this move is faithful to his intent.\nKeynes’s theory of probability is based around some non-numerical values whose nature and behaviour is left largely unexplained, and a concept of weight which is subject to a telling and simple objection. Nevertheless, his core ideas, that probabilities can but need not be precise, and that we need a concept like weight as well as just probability, both seem right for more general reasons. Hence the theory here, which captures the Keynesian intuitions while explaining away his mysterious non-numerical values and making the concept of weight more rigorous, looks to be as good as it gets for a Keynesian theory of uncertainty.\nOne particularly attractive feature of the account is how conservative it is at the technical level. We do not need to change our logic, change which things we think are logical truths, or which things follow from which other things, in order to support our account of uncertainty. This is in marked contrast to accounts based on fuzzy logic or on logics of vagueness. Not only are such changes in the logic unmotivated, they appear to lead to mistakes. No matter how uncertain we are about how the stock will move over the day, we know it will either close higher or not close higher; and we know it will not both close higher and not close higher. The classical laws of excluded middle and non-contradiction seem to hold even in cases of massive uncertainty. This seems to pose a serious problem for theories of uncertainty based on alternative logics. The best approach is one, like the theory here, which is innovative in how it accounts for uncertainty, and conservative in the logic it presupposes.\nSo as a theory of uncertainty I think this account has a lot to be said for it. However, it cannot support the economic arguments Keynes rests on it.\n\n\n0.3 The Economic Consequences of Uncertainty\nUncertainty can impact on the demand for an investment in two related ways. First, it can affect the value of that particular investment; secondly, it can affect the value of other things which compete with that investment for capital. The same story is true for investment as a whole. First, uncertainty may reduce demand for investment directly by making a person who would otherwise be tempted to invest more cautious and hence reluctant to invest. Secondly, if this direct impact is widespread enough, it will increase the demand for money, and hence its price. But the price of money is just the market rate of interest. And the return that an investment must be expected to make before anyone, even an investor not encumbered by uncertainty, will make it is the rate of interest.\nWhen uncertainty reduces investment by increasing interest rates, I will say it has an indirect impact on investment. Keynes has an argument for the existence of this indirect impact. First, he takes the amount of consumption as a given (GT: 245). Or more precisely, for any period he takes the amount of available resources that will not be allocated to consumption as a given. There are three possible uses for these resources: they can be invested, they can be saved as bonds or loans, or they can be hoarded as money. There are many different types of investment, but Keynes assumes that any agent will already have made their judgement as to which is the best of these, so we need only consider that one. There will also be many different length bonds which the agent can hold. So as to simplify the discussion, Keynes proposes just treating these two at a time, with the shorter length bond called ‘money’ and the longer length loan called ‘debts’ (GT: 167n). Hence the rate of interest is the difference between the expected return of the shorter bond over the life of the longer bond and the return of the longer bond. So the rate of interest that we are interested in need not be positive, and when the two bond lengths are short will usually be zero. However, it is generally presumed in discussions that the rate is positive. Now, Keynes assumes that an agent will only allocate resources to investment if investment looks to be at least as worthwhile as holding money, and at least as worthwhile as holding debts. In other words, he makes the standard reduction of \\(n\\)-way choice to a set of 2-way choices3. Usually if someone is of a mind to invest they will not favour holding money over holding debts. The only motivation for holding money, given positive interest rates, could be a desire to have accessible command over purchasing power, and investment foregoes that command. So in practice we only need look at two of the three possible pairwise choices here. Hence I will ignore the choice between investing and holding money, and only look at the money-debt choice and the debt-investment trade-off.\n3 Standard, but I bring it up because the modern theorist whose decision theory is closest to the one Keynes seems to adopt, Levi, explicitly rejects it.Holding a debt provides a relatively secure return in terms of money. Relatively secure because there is the possibility of default. In practice, this means that there is not a sharp distinction between debts and investments, rather a continuum with say government bonds at one extreme and long-term derivatives at the other. Some activities that have the formal structure of ‘debts’, like say provision of venture capital, will be closer to the investment end of the continuum. Unlike debts then, investments as a rule do not have a secure return in terms of money. In most cases they do not even have a precise expected return (GT: 149; Keynes (1937b, 113)). Keynes does not presume that this means that people never invest unless the expected return on the investment is greater than the expected (indeed, known) return on debts. He says explicitly that were this true then ‘there might not be much investment’. Instead, he says that investment under uncertainty depends on ‘confidence’ (GT: 150). Therefore, the following looks compatible with his position.\nBayesians say that each gamble has a precise expected value. The expected return on a bet that pays $1 if some fair coin lands heads is 50 cents. On this theory, expected values are imprecise, because probabilities are imprecise. Formally, say \\(E_{Pr}(G) = \\alpha\\) means that the expected return on \\(G\\) according to probability function \\(Pr\\) is \\(\\alpha\\). Roughly, the expected value for an agent of a gamble \\(G\\) will be \\(\\{x: \\exists Pr \\in S: (E_{Pr}(G) = x)\\}\\), the set of expected values of the bet according to each probability function in the agent’s representor. Note that these are different from the possible outcomes of the bet. As we saw in the case of the coin, expected value can differ from any possible value of the bet. So let the expected value of inesting a certain sum be \\([\\alpha, \\beta]\\), and the expected value of buying a debt with that money be \\(\\chi\\). Then the agent will invest iff \\((1 - \\rho)\\alpha + \\rho \\beta \\geq \\chi\\), where \\(\\rho \\in [0, 1]\\) measures the ‘state of confidence’.4 Now when a crisis erupts, \\(\\rho\\) will go to 0, and investment will dry up. In such cases the decision theory is similar to the one advanced by Levi (1980), Strat (1990) and Jaffray (1994). Since we are interested in a theory of unemployment, we are primarily interested in the cases where \\(\\rho\\) is quite low, in which cases we can say uncertainty is reducing investment.\n4 In case the reader fears I am being absurdly formal with an essentially informal idea, Keynes had such a variable, there described as measuring the ‘state of the news’, in early drafts, but it did not survive to the final stage. So my proposal is not a million miles from what Keynes intended merely by virtue of being algebraic.That last statement might seem dubious at face value. In part, what I mean by it is this. When \\(\\rho\\) is low the value of a set of bets will in general be more than the sum of the value of the bets taken separately. Because individual investors are fearful of exposure to uncertainty, which is presumably what \\(\\rho\\) being low means, sets of investments which if undertaken collectively would be profitable (and everyone agrees that they would) will not be undertaken individually. This suggests a reason that theorists have thought government intervention might be appropriate in times of crisis. Alternatively, if \\(\\rho\\) is low then the value of an investment, how much we will be prepared to pay for it, will probably be lower than our best estimate of its expected return, assuming the latter to be near \\((\\alpha + \\beta) /2\\).\nI shall focus more closely on the indirect effects of uncertainty in section 5. The central idea is that the rate of interest, being the price of money, is completely determined in the market for money. However, this market has some rather strange properties. After all, money is barren, and it can generally be traded for something that is not barren. So, as Keynes puts it, why would anyone ‘outside a lunatic asylum’, want it? Why would the demand for money not drop to zero as soon as the rate of interest is positive?\n\nBecause, partly on reasonable and partly on instinctive grounds, our desire to hold money as a store of wealth is a barometer of the degree of our distrust of our own calculations and conventions concerning the future ... The possession of actual money lulls our disquietude; and the premium which we require to make us part with money is the measure of the degree of our disquietude (Keynes 1937b, 116).\n\nTherefore, more uncertainty means more demand for money means higher interest rates. The rest of the story is standard. Even the confident agent will be disinclined to invest once the rate of interest rises. Using the little decision theory outlined above, more uncertainty means the gap between \\(\\alpha\\) and \\(\\beta\\) grows, which if \\(\\rho\\) is low will tend to reduce \\((1-\\rho)\\alpha + \\rho \\beta\\), the ‘certainty equivalent’ of the expectation of the investment’s worth. On the other hand, uncertainty on the part of the community will tend, for similar reasons, to increase \\(\\chi\\). Either way, investment suffers, and hence so does employment.\n\n\n0.4 Uncertainty and Money\nThere is something very odd about all that we have done so far. Agents react to uncertainty by making their returns measured in dollars more stable. However, in doing so they make their returns measured in any other good less stable. If you have no idea what the price of widgets will be in twelve months time, then holding only widgets increases the uncertainty about how many dollars you will be worth then. However, it makes you more certain about how many widgets you will be worth. Why this preference for money? We deserve an explanation as to why one kind of uncertainty is given such a central place and other kinds are completely ignored.\nKeynes has one explanation. He argues, or perhaps assumes, essentialism about money. Indeed the title of chapter 17 of The General Theory is ‘The Essential Properties of Interest and Money’. These essential properties are entirely functional. As Hicks puts it, “Money is defined by its functions ... money is what money does” (Hicks 1967, 1). The explanation is that agents try to minimise uncertainty relative to whatever plays the functional role of money. Therefore, the explanation does not rely on any mystical powers of dollar bills. Rather, the work is done by the functional analysis of money.\nAs a first approximation, the functional role money plays is that it is a medium of exchange. Keynes does not think this is quite the essential property; rather he says that money is essentially ‘liquid’, and perceived to be liquid. This means that if we hold money we are in a position to discharge obligations and make new purchases as they seem appropriate with greatest convenience and least cost. Even this is not what is given as the official essential property of money. To make the proof that demand for money is not demand for labour easier Keynes takes the essential properties of money to be its negligible elasticities of production and substitution. However, he makes clear that these are important because of their close connection to liquidity (GT: 241). Indeed, when he comes to define a non-monetary economy, he simply defines it as one where there is no good such that the benefits it confers via its liquidity, its ‘liquidity premium’ exceeds the carrying costs of the good. So the properties of having a negligible elasticity of production and substitution seem necessary but insufficient for something to be money.\nThe reason that money uncertainty is more problematic than widget uncertainty is just that money is liquid. At the end of the day, the point of holding investments, bonds or money is not to maximise the return in terms of such units; it is to be used somehow for consumption. Hence, we prefer, ceteris paribus, to store wealth in ways that can be easily exchanged for consumption goods as and when required. Further, we may be about to come across more information about productive uses for our wealth, and if we do, we would prefer to have the least inconvenience about changing how we use wealth. Money is going to be the best store of wealth for each of these purposes. The strength of these preferences determines the liquidity premium that attaches to money.\nSo Keynes’s story here is essentially a ‘missing markets’ story. If there were markets for every kind of transaction there would be no liquidity premium attaching to money, and hence no reason to be averse to uncertainty in terms of money returns as opposed to uncertainty in terms of X’s shares returns. There is a methodological difference here between decision theorists and economists. In decision theory it is common to specify what choices an agent does have. These will usually be finite, or at least simply specified. In economics it is more common to specify what choices an agent does not have, which markets are ‘missing’. In a sense the difference is purely cosmetic, but it can change the way problems are looked at. Since Keynes requires here some markets to be missing, it might be worth investigating what happens here from the more restrictive framework ordinarily applied in decision theory.\nIn some decision-theoretic contexts, we can prefer liquidity even when we are completely certain about what our choices are and what their outcomes will be. Say we are in a game where the object is to maximise our money over 2 days. We start with $100. On day 1, we have a choice of buying for $100 a ticket that will pay $200 at the end of day 2, and is non-transferable, or doing nothing. On day 2, if we still have our $100, we can buy with it a voucher which pays $300 at the end of day 2, or do nothing. Obviously, the best strategy is to do nothing on day 1, and buy the voucher on day 2. The point is just that money here has enough of a liquidity premium on day 1 that we are prepared to hold it and earn no interest for that day rather than buy the ticket (or two day bond) which will earn interest. So uncertainty is not a necessary condition for liquidity premia to exist. On the other hand, perhaps it is necessary for liquidity premia to exist in a world something like ours, where agents neither have all the choices they would have in a perfect market, nor as few as in this simple game. If we added a market for tickets and vouchers to our simple game the prices would be fixed so that money would lose its liquidity premium. Keynes suggests something like this is true for the worlds he is considering: “uncertainty as to the future course of the rate of interest is the sole intelligible explanation of the type of liquidity preference [under consideration]” (GT: 201). However here he merely means lack of certainty; there is no proof that if every agent had precise credences liquidity preference ought to disappear. So it looks like uncertainty in the sense discussed here, vague reasonable beliefs, does no theoretical work. Perhaps this is a bit quick, as the little game I considered is so far from a real-life situation. So I will look more closely at the effects uncertainty is supposed to have. Since it has received the bulk of the theoretical attention, I start with the indirect effects of uncertainty.\n\n\n0.5 Uncertainty and Liquidity Preference\nKeynes thinks the question of why money is demanded at all, why we do not all move from holding money into holding debts as soon as the rate of interest goes positive, needs answering. And he thinks the answer here will be particularly relevant to theories about the rate of interest. If the market in general is at equilibrium then the market in trades between any two goods must also be in equilibrium; in particular it cannot be that there are people holding money who would be prepared to buy debts at the current interest rate. So if the equilibrium interest rate is positive, there must be some people who would prefer to hold money than hold debts. This fact Keynes takes to be central to the correct theory of the rate of interest. Hence, to determine what the rate of interest will be, and what will cause it to change, I need to determine what causes a demand for money.\nKeynes distinguishes four motives for holding money (GT: Ch. 13; (Keynes 1937a, 215–23)). Two of these, the transactions motive and the finance motive, need not detain us. They just relate to the need to make payments in money and on time. The third, the speculative motive, is often linked to uncertainty, and indeed Keynes does so (GT: 201). But ‘uncertainty’ here is just used to mean absence of certainty, that is the existence of risk, which as noted above is not how I am using ‘uncertainty’. As Runde (1994b) points out, an agent who is certain as to future movements in interest rates may still hold money for speculative reasons, as long as other agents who are not so certain have made mistaken judgements. The fourth motive will hold most of my attention. Keynes argues that we may hold money for purely precautionary reasons.\n\nTo provide for contingencies requiring sudden expenditure and for unforeseen opportunities of advantageous purchases, and also to hold an asset of which the value is fixed in terms of money to met a subsequent liability fixed in terms of money, are further motives for holding cash (GT: 196).\n\nDavidson (1988, 1991) justifies this as follows. Uncertainty arises whenever agents do not have sufficient knowledge to calculate the numerical probability of an event. This is given a rather frequentist gloss in Davidson, but that is not necessary. His idea is that we know what the probability of \\(p\\) is when we know the frequency of \\(p\\)-type events in the past and we know the future will resemble the past in this respect. The latter is cashed out as saying \\(p\\) is governed by an ‘ergodic process’. We can replace all this by saying that \\(p\\) is subject to uncertainty whenever we do not know its objective chance, whether or not objective chance ought to be analysed by frequentist approaches. Davidson then argues that since for most \\(p\\) we do not have this knowledge, we have to adopt ‘sensible’ approaches like holding money.\nRunde (1994b) objects that Davidson’s story is incoherent. On Davidson’s theoretical story there are only two epistemic states relative to \\(p\\) that are possible. An agent can know the chance of \\(p\\), in which case their credence is set equal to it, or they are completely uncertain about it. In the latter case there can be no reason for taking some action rather than another. Now the reason that it is ‘sensible’ to hold money is that we expect money to be liquid. However, we do not know the chance of money remaining liquid; whether or not money remains liquid is not determined by an ergodic process. Hence, we have no reason for letting that partial belief be a guide to action.\nThis is a fair criticism, but it can be met by amending the theory rather than by giving it up. On my theory, if an agent knows the chance of \\(p\\) they will have a precise degree of belief in \\(p\\). When they do not their degree of belief will, in general, be vague but not totally vague. As with Keynes, I have uncertainty come in degrees. This amendment is enough to rescue Davidson’s theory. An agent might not know the chance that money will become illiquid in the next short period of time, but they might know enough for it to be reasonable to have a credence in that proposition which is vague over some small interval close to zero. It may still be sensible to hold some money even when the expected return on other investments really is vague. But is it sensible to prefer fixed to uncertain returns? In other words, is there a direct effect of uncertainty that makes people prefer bonds to investments?\n\n\n0.6 Uncertainty and Indecision\nAs Keynes repeatedly stressed, investment is not like a game of chance where the expected results are known in advance. And this is part of the explanation for the extreme instability in investment levels compared to other economic variables.\n\nThe state of long-term expectation ... does not solely depend on the most probable forecast we can make. It also depends on the confidence with which we make this forecast (GT: 148).\nHuman decisions affecting the future, whether personal or political or economic, cannot depend on strict mathematical expectation, since the basis for making such calculations does not exist ... it is our innate urge to activity which makes the wheels go round, our rational selves choosing between the alternatives as best we are able, calculating where we can, but often falling back for our motive on whim or sentiment or chance (GT: 162-3).\n\nThe most charitable reading of Keynes here is to say he agreed, in principle, with what is sometimes referred to as a Horwitz-style decision rule. If the expected return of an investment is vague over \\([\\alpha, \\beta]\\) then its ‘value’ is given by \\((1-\\rho)\\alpha + \\rho \\beta\\), where \\(\\rho \\in [0, 1]\\) is a measure of confidence. By the 1937 article, he has become more interested in the special case where confidence has collapsed and \\(\\rho\\) is approaching 0. This interpretation would explain all his references to decision-making under uncertainty in The General Theory and subsequent discussion, provided we make the safe assumption that ‘cold calculation’ would only have us spend \\(x\\) on an investment with expected return \\([\\alpha, \\beta]\\) when \\(\\alpha \\geq x\\). In particular, any interpretation of the underlying decision theory here will have to give some role to ‘whim or sentiment or chance’, and I give it a variable, ‘\\(\\rho\\)’. With this theory, I have the extensions needed to avoid Runde’s objection to Davidson. I have a continuum of degrees of uncertainty, rather than a raw dichotomy, and I have an explanation of why it is ‘sensible’ to prefer gambles with known expected returns, at least when \\(\\rho\\) is relatively low.\nThis theory is meant to serve two related purposes. It is meant to show why we might prefer money to debts, even though our best estimate of the expected return of the debts is positive, and again it is meant to show why we might prefer debts to investments even when our best estimate of the expected return of the investment is higher. And I think if the decision rule stipulated were plausible, it would show that uncertainty did have an economic effect. In particular, I think it would show both that in times of crises when \\(\\rho\\) heads down, the level of investment will decrease even with other things being equal, and that collective action can be justified even when individual action is not. That is, the government can make sets of investments that are expected to be profitable although none of the individual investments is expected to be profitable.\nThe decision theory does not, however, seem plausible. First, there are some technical problems for this theory. The problem is that if \\(\\rho &lt; \\frac{1}{2}\\), then in cases where uncertainty is guaranteed to increase in the near future agents following this rule will make decisions they are sure to regret. For example, assume an agent with \\(\\rho = \\frac{1}{3}\\) now has credence \\(\\frac{1}{2}\\) in \\(p\\), but knows that some evidence will come in such that her credence in \\(p\\) will become vague over \\([0.3, 0.7]\\) whatever the result of the experiment. As we saw in the case of poker players, this is plausible in some situations. The agent will now pay 50 cents for a bet which pays $1 if \\(p\\) and nothing otherwise, but after the evidence comes in she’ll sell that bet for about 44 cents, incurring a sure loss. I leave it to the reader to judge the importance of these technical problems, given the rarity of cases where uncertainty is guaranteed to rise.\nThere is also a philosophical problem. What precisely is \\(\\rho\\) supposed to represent? If it is some kind of belief, its effects should have been incorporated into the credences. If it is some kind of desire its effects should have been incorporated into the evaluation of each of the states. This objection could be avoided, perhaps, if Keynes was trying to argue against the theory that investors just maximise dollar expected returns. It is not entirely clear whom Keynes thinks he is arguing against at some points. If this is his enemy, he is fighting a straw man, one who is vulnerable to much simpler objections. Whoever thought that all investment is profit driven, that no one ever went into business because they thought it would be fun to run a newspaper? Keynes’s only viable opponents here are saying that investors calculate the expected return, in utils, of each possible investment and choose the one whose returns are highest. Now perhaps for many dollar returns are the most important factor in determining util returns, but this is certainly not the only cause.\nIf \\(\\rho\\) represents something which is neither a belief nor a desire, then it is hard to see what effect it could have on action. Perhaps there are some exceptions to the rule that actions are caused only by beliefs and desires combining in the right way, such as actions caused by values, but these appear irrelevant to Keynes’s considerations, and he does not appeal to such exemptions. After all, he describes investment decisions made where the ‘cold calculations’ do not determine what should be done as being made by ‘whim or sentiment or chance’. Now whims and sentiments are surely desires, although chance is in a different boat. If he had just said ‘chance’ here he may have committed himself to a different decision theory, one where the agent can under uncertainty make any decision which is not known to be sub-optimal. But this does not justify the conclusion that uncertainty decreases investment; under that theory it is random whether uncertainty increases or decreases investment. Hence Keynes appears to be implausibly committed to a mental state which is neither a belief nor a desire but affects action.\nIt might be objected here that I am relying on an overly individualistic theory of motivation; that what Keynes is committed to is nothing more than what anyone who has learned the difference between Robinson Crusoe economics and real-world economics would believe. There is an important truth behind this objection: the social causes of action cannot be overlooked. But this is not what I have done. The core assumption I made is that the only mental states relevant to action are beliefs and desires. Now the beliefs and desires that are relevant may not be (directly) concerned with the action at hand; they may be beliefs and desires about how society will view this action, or about similar actions which may or may not be performed by other members in society. And the beliefs and desires may not have as their immediate cause careful inference by the agent in question; they may be caused by the wave of panic or optimism in which the agent is caught up. In the real world, agents do not always change their beliefs and desires by reflection on new evidence, often emotion plays a larger role. So society has both evidential and non-evidential effects on action. But every time, the causal chain goes via the beliefs and desires of the agent. Society causes actions by causing changes in the beliefs and desires of individuals. It is wrong to think that action is never caused by beliefs and desires about society, it is wrong to think that society never directly causes beliefs and desires which lead to action, but none of this implies that there can be mental states other than belief and desire relevant to action.\n\n\n0.7 Disquietude\nThere are some comments from Keynes that suggest this reading is a little unfair. Rather than having a distinctive decision theory, he perhaps has a distinctive theory about what ought enter into the decision-theoretic calculations. The standard theory for why there is a demand for insurance is the falling marginal utility of money. Agents purchase insurance, and accept a lower expected dollar return because with insurance their expected util return, at the end of the duration of the insurance, is higher than if they had not purchased. This is the story given in, for example, Freidman and Savage (1952) where the existence of demand for insurance is taken as evidence for the declining marginal utility of money. But there is another reason agents might buy insurance. They might simply feel happier, over the duration of the insured period, knowing that they have insurance and are hence exposed to fewer risks or uncertainties than otherwise. If this is true then their expected ‘wealth’ in both dollars and utils at the end of a period might be lower if they insure than if otherwise, but it will be worthwhile because of the benefits during the period. Keynes suggests that this same desire for quietude can cause a demand for money. I presume, though it is not entirely clear, that this desire should be included within the precautionary motives for holding money.\n\nThere are not two separate factors affecting the rate of investment, namely, the schedule of the marginal efficiency of capital [the expected return of investments] and the state of confidence. The state of confidence is relevant because it is one of the major factors determining the former (GT: 149).\nFor the fact that each individual investor flatters himself that his commitment is “liquid” ... calms his nerves and makes him much more willing to run a risk (GT: 160).\nThe possession of actual money lulls our disquietude; and the premium which we require to make us part with money is the measure of the degree of our disquietude (Keynes 1937b, 116).\nA liquidity premium ... is not even expected to be rewarded. It is a payment, not for the expectation of increased tangible income at the end of the period, but for an increase sense of comfort and confidence during the period (Keynes 1938, 293–94).\n\nThis explanation of the demand for certain returns is in some ways conservative and some ways radical. It is conservative because it does not immediately change the technical properties of preference. Many heterodox theories of preference drop such theoretical restrictions as transitivity of preferences. By contrast the theory Keynes appears to be advocating is it least in principle conservative on this front. Agents are still going round maximising expected utility, just now it is expected utility over a period, not at the end of the period.\nBut it is not all conservative. If we explain economic decisions in terms of the disquietude of the investor we discard the distinction between investment and consumption. It was always known that there were some goods that were not comfortably categorised, particularly cars, but this move makes every good in part a consumption good. If all this meant was that some helpful classifications have to be questioned, it would not be important. Rather, its importance flows from its implications for the norms for investment. It is always irrational to make an investment which will incur a sure loss. This principle is used to derive wide-ranging implications for decision-theory. But it is not irrational to make a consumption decision which will result in sure loss at the end of a period in exchange for goods during that period. It is not always irrational to pay ten dollars for a movie ticket, even though this will incur a sure loss in the sense the buyer will surely have less wealth at the end of the movie than if they had not bought the ticket.\nGiven this, the technical complaint I raised against the Horvitz-style decision rule misses the target. And the philosophical concern about what \\(\\rho\\) represents is irrelevant. If the expected returns only measure how much various gambles will be worth at the end of the period, then some desires have not yet been included in our calculations. That is, \\(\\rho\\) represents some desires but the theory is not guilty of double-counting. So far this all seems to work, and explain the role of uncertainty. Indeed, I think this is the best extension of Keynes’s views in this area.\nWhile there seem to be few theoretical objections which can be raised at this point, there is a rather telling empirical objection. The only role given to disquietude in this theory is in deciding between alternatives where the returns on at least one are uncertain. But it seems implausible that disquietude could have this effect, but have no effect when choices are being made between alternatives where at least one is risky. I doubt the feelings of disquiet would be any different were I to have a large fortune riding on a roulette wheel or a baseball game. Disquietude arises because we do not know what will happen; maybe for some people it is greater when we do not know the expected returns, but I doubt it. Again, perhaps there is an explanation for demand for money in the real world to be found here, but uncertainty plays no role in the story, or at best a small cameo.\n\n\n0.8 Summary\nKeynes argued that uncertainty has a major economic impact. By driving people to store their wealth in ways with more stable returns, it increases the demand for cash and decreases the demand for investments. Not only does it drive down investments in this direct way, the increased demand for cash leads to higher interest rates and hence people are driven out of investment into bonds. However, there are a few problems with the story. First, the motivation for demanding returns fixed with respect to a certain good can only be that the markets between that good and other goods are more complete. But if that is the case there is a reason to demand that good even when the world is completely certain. Secondly, the only decision-theoretic justification for this demand for fixed returns could be the disquiet generated by not knowing the return. This follows from the formalisation of uncertainty advocated in sections 1 and 2. But this disquiet could just as easily be generated by risk as by uncertainty. So Keynes has not shown that uncertainty has any particular economic impact. That’s the bad news. The good news is that many of the arguments seem to work without the reliance on uncertainty.\n\n\n\n\n\n\nReferences\n\nBateman, Bradley. 1996. Keynes’s Uncertain Revolution. Ann Arbor: University of Michigan Press.\n\n\nCarnap, Rudolf. 1950. Logical Foundations of Probability. Chicago: University of Chicago Press.\n\n\nCoates, John. 1996. The Claims of Common Sense. Cambridge: Cambridge University Press.\n\n\nDavidson, Paul. 1988. “A Technical Definition of Uncertainty and the Long-Run Non-Neutrality of Money.” Cambridge Journal of Economics 12: 329–38. https://doi.org/10.1093/oxfordjournals.cje.a035063.\n\n\n———. 1991. “Is Probability Theory Relevant for Uncertainty? A Post Keynesian Perspective.” Journal of Economic Perspectives 5 (1): 129–44. https://doi.org/10.1257/jep.5.1.129.\n\n\nDavis, John. 1994. Keynes’s Philosophical Development. Cambridge: Cambridge University Press.\n\n\nDempster, Arthur. 1967. “Upper and Lower Probabilities Induced by a Multi-Valued Mapping.” Annals of Mathematical Statistics 38: 325–39. https://doi.org/10.1214/aoms/1177698950.\n\n\nFraassen, Bas van. 1990. “Figures in a Probability Landscape.” In Truth or Consequences, edited by J. M. Dunn and A. Gupta, 345–56. Amsterdam: Kluwer.\n\n\nFreidman, M., and L. Savage. 1952. “The Expected Utility Hypothesis and the Measurability of Utility.” Journal of Political Economy 60 (6): 463–74. https://doi.org/10.1086/257308.\n\n\nGärdenfors, Peter, and Nils-Eric Sahlin. 1982. “Unreliable Probabilities, Risk Taking and Decision Making.” Synthese 53 (3): 361–86. https://doi.org/10.1007/bf00486156.\n\n\nHart, A. G. 1942. “Risk, Uncertainty and the Unprofitability of Compounding Probabilities.” In Studies in Mathematical Economics and Econometrics, edited by F. McIntyre O. Lange and T. O. Yntema., 110–18. Chicago: University of Chicago Press.\n\n\nHicks, John. 1967. Critical Essays in Monetary Theory. Oxford: Clarendon Press.\n\n\nJaffray, J. Y. 1994. “Decision Making with Belief Functions.” In Advances in the Dempster- Shafer Theory of Evidence, edited by R. Yager, M. Fedrizzi, and J. Kacprzyk, 331–52. New York: John Wiley.\n\n\nJeffrey, Richard. 1983. “Bayesianism with a Human Face.” In Testing Scientific Theories, edited by J. Earman (ed.). Minneapolis: University of Minnesota Press.\n\n\nKeynes, John Maynard. 1921. Treatise on Probability. London: Macmillan.\n\n\n———. 1936. The General Theory of Employment, Interest and Money. London: Macmillan.\n\n\n———. 1937a. “The Ex Ante Theory of the Rate of Interest.” Economic Journal 47 (188): 663–68. https://doi.org/10.2307/2225323.\n\n\n———. 1937b. “The General Theory of Employment.” Quarterly Journal of Economics 51 (2): 209–23. https://doi.org/10.2307/1882087.\n\n\n———. 1938. “Letter to Hugh Townshend Dated 7 December.” In The Collected Writings of John Maynard Keynes, by John Maynard Keynes, 14:293–94. London: Macmillan.\n\n\nLevi, Isaac. 1980. The Enterprise of Knowledge. Cambridge, MA.: MIT Press.\n\n\n———. 1982. “Ignorance, Probability and Rational Choice.” Synthese 53 (3): 387–417. https://doi.org/10.1007/bf00486157.\n\n\nRamsey, Frank. 1926. “Truth and Probability.” In Philosophical Papers, edited by D. H. Mellor, 52–94. Cambridge: Cambridge University Press.\n\n\nRunde, Jochen. 1990. “Keynesian Uncertainty and the Weight of Arguments.” Economics and Philosophy 6 (2): 275–93. https://doi.org/10.1017/s0266267100001255.\n\n\n———. 1994a. “Keynes After Ramsey: In Defence of ‘a Treatise on Probability’.” Studies in the History and Philosophy of Science 25 (1): 97–124. https://doi.org/10.1016/0039-3681(94)90022-1.\n\n\n———. 1994b. “Keynesian Uncertainty and Liquidity Preference.” Cambridge Journal of Economics 18: 129–44. https://doi.org/10.1093/oxfordjournals.cje.a035266.\n\n\nShafer, Glenn. 1976. A Mathematical Theory of Evidence. Princeton: Princeton University Press.\n\n\nStrat, Thomas. 1990. “Decision Analysis Using Belief Functions.” International Journal of Approximative Reasoning 4 (5-6): 391–417. https://doi.org/10.1016/0888-613x(90)90014-s.\n\n\nTintner, Gerhard. 1941. “The Theory of Choice Under Subjective Risk and Uncertainty.” Econometrica 9 (3/4): 298–304. https://doi.org/10.2307/1907198.\n\n\nWalley, Peter. 1991. Statisical Reasoning with Imprecise Probabilities. London: Chapman & Hall.\n\n\nYager, R., M. Fedrizzi, and J. Kacprzyk, eds. 1994. Advances in the Dempster- Shafer Theory of Evidence. New York: John Wiley."
  },
  {
    "objectID": "posts/naturalness/the-role-of-naturalness-in-lewiss-theory-of-meaning.html",
    "href": "posts/naturalness/the-role-of-naturalness-in-lewiss-theory-of-meaning.html",
    "title": "The Role of Naturalness in Lewis’s Theory of Meaning",
    "section": "",
    "text": "It is sometimes claimed (e.g., by Sider (2001a, 2001b; Stalnaker 2004; Williams 2007; Weatherson 2003)) that David Lewis’s theory of predicate meaning assigns a central role to naturalness.1 Some of the people who claim this also say that the theory they attribute to Lewis is true. The authors I have mentioned aren’t as explicit as each other about exactly which theory they are attributing to Lewis, but the rough intuitive idea is that the meaning of a predicate is the most natural property that is more-or-less consistent with the usage of the predicate. Call this kind of interpretation the ‘orthodox’ interpretation of Lewis.2 Recently Wolfgang Schwarz (2009, 209ff) has argued that the orthodox interpretation is a misinterpretation, and actually naturalness plays a much smaller role in Lewis’s theory of meaning than is standardly assumed.3 Simplifying a lot, one key strand in Schwarz’s interpretation is that naturalness plays no role in the theory of meaning in Lewis (1969, 1975), since Lewis hadn’t formulated the concept yet, and Lewis didn’t abandon that theory of meaning, since he never announced he was abandoning it, so naturalness doesn’t play anything like the role orthodoxy assigns to it.\n1 Holton (2003) is more nuanced, but does tell a similar story in the context of discussing Lewis’s account of (potential) semantic indeterminacy. Weatherson (2010) follows Holton in this respect.2 As some further evidence for how orthodox the ‘orthodox’ interpretation is, note that Williams (2007) is a prize winning essay published with two commentaries in the Philosophical Review. That paper takes the orthodox interpretation as its starting point, and neither of the commentaries (Bays (2007) and Hawthorne (2007)) criticise this starting point.3 Schwarz (2006) develops his criticism of orthodoxy in more detail, and in English, but it is as yet unpublished.\nPublished in Journal for the History of Analytic Philosophy, volume 1, number 10.\n\nIn this article I attempt to steer a middle ground between these two positions. I’m going to defend the following parcel of theses. These are all exegetical claims, but I’m also interested in defending most of the theses that I ultimately attribute to Lewis, so getting clear on just what Lewis meant is of more than historical interest.\n\nNaturalness matters to Lewis’s (post-1983) theory of sentence meaning only insofar as it matters to his theory of rationality, and the theory of rationality matters to the (pre- and post-1983) theory of meaning.\nNaturalness might play a slightly larger role in Lewis’s theory of word meaning, but it isn’t nearly as significant as the orthodox view suggests.\nWhen we work through Lewis’s theory of word and sentence meaning, we see that the orthodox interpretation assigns to Lewis a theory that isn’t his theory of meaning, but is by his lights a useful heuristic.\nAn even better heuristic than ‘meaning = use plus naturalness’ would be ‘meaning = predication plus naturalness’, but even this would be a fallible heuristic, not a theory.\nWhen correctly interpreted, Lewis’s theory is invulnerable to the challenges put forward in Williams (2007).\n\nI’m going to start by saying a little about the many roles naturalness plays in Lewis’s philosophy, and about his big picture views on thought and meaning. Then I’ll offer a number of arguments against the orthodox interpretation of Lewis’s theory of sentence meaning. After that, I’ll turn to Lewis’s theory of word meaning, where it is harder to be quite clear about just what the theory is, and how much it might have changed once natural properties were added to the metaphysics. An appendix discusses some interpretative questions that arise if we are sceptical that any one division of properties can do all the work that Lewis has the natural/non-natural division do.\n\n0.1 How Naturalness Enters The Theory of Meaning\nMost of the core elements of David Lewis’s philosophy were present, at least in outline, from his earliest work. The big exception is the theory of natural properties introduced in Lewis (1983). As he says in that paper, he had previously believed that “set theory applied to possibilia is all the theory of properties that anyone could ever need” (Lewis 1983, 377n). Once he introduces this new concept of naturalness, Lewis puts it to all sorts of work throughout his philosophy. I’m rather sceptical that there is any one feature of properties that can do all the varied jobs Lewis wants naturalness to do, but the grounds for, and consequences of, this scepticism are a little orthogonal to the main theme of this paper, so I’ve set it aside.\nAs the orthodox interpretation stresses, Lewis has naturalness do some work in this theory of content. That he does think there’s a connection between naturalness and content is undeniable from the most casual reading of his post-1983 work. But just how they are connected is less obvious. To spell out these connections, let’s start with three Lewisian themes.\n\nFacts about linguistic meaning are to be explained in terms of facts about minds. In particular, to speak a language \\(\\mathcal{L}\\) is to have a convention of being truthful and trusting in \\(\\mathcal{L}\\) (Lewis 1969, 1975). And to have such a convention is a matter of having certain beliefs and desires. So mental content is considerably prior to linguistic content in a Lewisian theory. Moreover, Lewis’s theory of linguistic content is, in the first instance, a theory of sentence meaning, not a theory of word meaning. 4\nThe principle of charity plays a central role in Lewis’s theory of mental content Lewis (1974, 1994). To a first approximation, a creature believes that \\(p\\) iff the best interpretation of the creature’s behavioural dispositions includes the attribution of the belief that \\(p\\) to the creature. And, ceteris paribus, it is better to interpret a creature so that it is more rather than less rational. It will be pretty important for what follows that Lewis adopts a principle of charity that highlights rationality, not truth. It is also important to Lewis that we don’t just interpret the individual creature, but creatures of a kind (Lewis 1980). I’m not going to focus on the social externalist features of Lewis’s theory of mental states, but I think they assist the broader story I want to tell.\nLewis’s theory of mental content has it that mental contents are (what most of us would call) properties, not (what most of us would call) propositions (Lewis 1979). So a theory of natural properties can easily play a role in the theory of mental content, since mental contents are properties. If you think mental contents are propositions, the connection between naturalness and mental content will be more indirect. Just how indirect it is will depend on what your theory of propositions is. But if mental contents are Lewisian propositions, the connection may be very indirect indeed. After all, propositions that we might pick out with sentences containing words that denote very unnatural properties, such as All emeroses are gred, might be intuitively very natural.\n\n4 These points are stressed by Wolfgang Schwarz (2006, 2009). He also notes that in “Putnam’s Paradox” Lewis explicitly sets these parts of his theory aside so he can discuss Putnam’s arguments on grounds most favourable to Putnam. As Schwarz says, this should make us suspicious of the central role “Putnam’s Paradox” plays in defences of the orthodox interpretation. We will return to this point in the section on textual evidence for and against orthodoxy.\nA referee notes, correctly, that the phrase ‘in the first instance’ is doing a lot of work here. That’s right; we’ll return in much more detail below to Lewisian theories of word meaning, and what role naturalness plays in them.Now let’s see why we might end up with naturalness in the theory of meaning. An agent has certain dispositions. For instance, after seeing a bunch of green emeralds, and no non-green emeralds, in a large and diverse range of environments, she has a disposition to say “All emeralds are green”. In virtue of what is she speaking a language in which “green” means green, and not grue? (Note that when I use “grue”, I mean a property that only differs from greenness among objects which it is easy to tell that neither our agent, nor any of her interlocutors, could possibly be acquainted with at the time she makes the utterance in question.)\nLet’s say that \\(\\mathcal{L}_1\\) is English, i.e., a language in which “green” means green, and \\(\\mathcal{L}_2\\) a language which is similar to \\(\\mathcal{L}_1\\) except that “green” means grue. Our question is, what makes it the case that the agent is speaking \\(\\mathcal{L}_1\\) and not \\(\\mathcal{L}_2\\)? That is, what makes it the case that the agent has adopted the convention of being truthful and trusting in \\(\\mathcal{L}_1\\), and not the convention or being truthful and trusting in \\(\\mathcal{L}_2\\)?\nWe assumed that the agent has seen a lot of emeralds which are both green and grue. To a first approximation, it is more charitable to attribute to the agent the belief that all emeralds are green than the belief that all emeralds are grue because greenness is more natural than gruesomeness. As Lewis says, “The principles of charity will impute a bias towards believing things are green rather than grue” (1983, 375). And for Lewis, charity requires imputing more reasonable interpretations. But why is it more charitable to attribute beliefs about greenness to beliefs about grueness? I think it is because we need more evidence to rationally form a belief that some class of things are all grue than we need to form a belief that everything in that class is green. And that’s because, ceteris paribus, we need more evidence to rationally form a belief that all \\(F\\)s are \\(G\\)s than that all \\(F\\)s are \\(H\\)s when \\(G\\) is less natural than \\(H\\). The agent has, we might assume, sufficient evidence to rationally believe that all emeralds are green, but not sufficient evidence to believe that all emeralds are grue.\nSo the first two Lewisian themes notes above, the reduction of linguistic meaning to mental content, and the centrality of a rationality-based principle of charity, push us towards thinking that naturalness is closely connected to mental content and hence to linguistic meaning. And it has pushed us towards thinking that if naturalness is connected to meaning, it is via this connection I’ve posited between naturalness and rational belief. Note that Lewis doesn’t ever endorse anything like that general a connection, but I suspect he had something like this in mind when he wrote the sentence I quoted in the previous paragraph. We’ll come back to this interpretative question at some length below.\nBut the argument I offered was a bit quick, because I ignored the third Lewisian theme: beliefs are relations to properties, not propositions. On Lewis’s theory, to believe that all emeralds are green is to self-ascribe the property of being in a world where all emeralds are green. So if a certain body of evidence makes it possible for the agent to rationally believe that all emeralds are green, but not for her to believe that all emeralds are grue, and that’s because rationality is constitutively connected to naturalness, then that must be because the first of the following properties is more natural than the second:\n\nBeing in a world where all emeralds are green\nBeing in a world where all emeralds are grue\n\nThat could still be true, though it is notable how far removed we are from the intuitions that motivate the distinctions between more and less natural properties. It’s not like there is some sense, intuitively, in which things that have the first property form a more unified class than things that have the second property.\nSo it’s plausible that naturalness is connected to mental content, at least as long as naturalness is connected to rational belief. And since mental content is connected to linguistic content, we’re now in the vicinity of the orthodox interpretation. But I don’t think the orthodox interpretation can be right. I’ll give four reasons for this, starting with the textual evidence for and against it.\n\n\n0.2 Textual Evidence about Sentence Meaning\nThere is some prima facie textual evidence for the orthodox interpretation. But looking more careful at the context of these texts not just undermines the support the text gives to the orthodox interpretation, but actually tells against it. (This part of the paper is indebted even more than the rest to Wolfgang Schwarz’s work, and could be easily skipped by those familiar with that work.)\nI’ll focus on the last seven pages of “New Work for a Theory of Universals”. This is the part of “New Work” that uses the notion of naturalness, as introduced in the paper, to respond to Putnam’s model-theoretic arguments for massive indeterminacy of meaning. Lewis actually responds to Putnam twice over. First, he responds to Putnam directly, by showing how adding naturalness to a use-based theory of sentence meaning avoids the ‘just more theory’ objection that’s central to Putnam’s argument. And when Lewis describes this direct response, he says things that sound a lot like the orthodox interpretation.\n\nI would instead propose that the saving constraint concerns the referent - not the referrer, and not the causal channels between the two. It takes two to make a reference, and we will not find the constraint if we look for it always on the wrong side of the relationship. Reference consists in part of what we do in language or thought when we refer, but in part it consists in eligibility of the referent. And this eligibility to be referred to is a matter of natural properties. (Lewis 1983, 371)\n\nBut after this direct response is finished, Lewis notes that he has conceded quite a lot to Putnam in making the response.\n\nYou might well protest that Putnam’s problem is misconceived, wherefore no need has been demonstrated for resources to solve it. … Where are the communicative intentions and the mutual expectations that seem to have so much to do with what we mean? In fact, where is thought? …I think the point is well taken, but I think it doesn’t matter. If the problem of intentionality is rightly posed there will still be a threat of radical indeterminacy, there will still be a need for saving constraints, there will still be a remedy analogous to Merrill’s suggested answer to Putnam, and there will still be a need for natural properties. (Lewis 1983, 373)\n\nI noted earlier that Schwarz makes much of a similar passage in “Putnam’s Paradox”, and I think he is right to do so. Here’s a crucial quote from that paper.\n\nI shall acquiesce in Putnam’s linguistic turn: I shall discuss the semantic interpretation of language rather than the assignment of content to attitudes, thus ignoring the possibility that the latter settles the former. It would be better, I think, to start with the attitudes and go on to language. But I think that would relocate, rather than avoid, the problem; wherefore I may as well discuss it on Putnam’s own terms. (Lewis 1984, 222)\n\nThat passage ends with a footnote where he says the final section of “New Work” contains a version of how the ‘relocated’ problem would be solved. So let’s turn back to that. The following long portmanteau quote from pages 373 to 375 captures, I think, the heart of my interpretation.\n\nThe problem of assigning content to functionally characterised states is to be solved by means of constraining principles. Foremost among these are principles of fit. …A state typically caused by round things before the eyes is a good candidate for interpretation as the visual experience of confronting something round; and its typical impact on the states interpreted as systems of belief ought to be interpreted as the exogenous addition of a belief that one is confronting something round, with whatever adjustment that addition calls for. …Call two worlds equivalent iff they are alike in respect of the subject’s evidence and behaviour, and note that any decent world is equivalent inter alia to horrendously counterinductive worlds and to worlds where everything unobserved by the subject is horrendously nasty. …We can interchange equivalent worlds ad lib and preserve fit. So, given any fitting and reasonable interpretation, we can transform it into an equally fitting perverse interpretation by swapping equivalent worlds around …If we rely on principles of fit to do the whole job, we can expect radical indeterminacy of interpretation. We need further constraints, of the sort called principles of (sophisticated) charity, or of ‘humanity’. [A footnote here refers to \"Radical Interpretation\".] Such principles call for interpretations according to which the subject has attitudes that we would deem reasonable for one who has lived the life that he has lived. (Unlike principles of crude charity, they call for imputations of error if he has lived under deceptive conditions.) These principles select among conflicting interpretations that equally well conform to the principles of fit. They impose apriori – albeit defeasible - presumptions about what sorts of things are apt to be believed and desired …It is here that we need natural properties. The principles of charity will impute a bias toward believing that things are green rather than grue …In short, they will impute eligible content …They will impute other things as well, but it is the imputed eligibility that matters to us at present. (Lewis 1983, 373–75, my emphasis)\n\nI think that does a reasonably clear job of supporting the interpretation I set out in the introduction over the orthodox interpretation. Naturalness matters to linguistic meaning all right. But the chain of influence is very long and indirect. Naturalness constrains what is reasonable, reasonableness constrains charitable interpretations, charitable interpretations constrain mental content, and mental content constrains linguistic content. Without naturalness at the first step, we get excessive indeterminacy of content. With it, the Putnamian problems are solved. But there’s no reason to think naturalness has any more direct role to play at any level in the theory of linguistic content.\nIn short, Lewis changed what he thought about rationality when he adopted the theory of natural properties. Since rationality was a part of his theory of mental content, and mental content determines linguistic content, this change had downstream consequences for what he said about linguistic content. But there wasn’t any other way his theory of linguistic content changed, nor, contra orthodoxy, any direct link between naturalness and predicate meaning.\nMoreover, when we look at the closest thing to a worked example in Lewis (1983), we don’t get any motivation for the orthodox interpretation. Here’s the example he uses, which concerns mental content. Let \\(f\\) be any mapping from worlds to worlds such that the agent has the same evidence and behaviour in \\(w\\) and \\(f(w)\\). Extend \\(f\\) to a mapping from sets of worlds to sets of worlds in the following (standard) way: \\(f(S) = \\{f(w): w \\in S\\}\\). Then the agent’s behaviour will be rationalised by her evidence just as much if she has credence function \\(C\\) and value function \\(V\\), as if she has credence function \\(C^\\prime\\) and value function \\(V^\\prime\\), where \\(C^\\prime(f(S)) = C(S)\\), and \\(V^\\prime(f(S)) = V(S)\\). To relate this back to the familiar Goodmanian puzzle, let \\(f\\) map any world where all emeralds are green to nearest world where all emeralds are grue, and vice versa, and map any other world to itself. Then the above argument will say that the agent’s behaviour is rationalised by her evidence just as much as if her credences are \\(C\\) as if they are \\(C^\\prime\\). That is, her behaviour is rationalised by her evidence just as much if she gives very high credence to all emeralds being green as to all emeralds being grue. So understanding charity merely as rationalizing behaviour leaves us without a way to say that the agent believes unobserved emeralds are green and not grue.\nLewis’s solution is to say that charity requires more than that. In particular, it requires that we assign natural rather than unnatural beliefs to agents where that is possible. I’ve argued above that this makes perfect sense if we connect naturalness with rationality. The crucial thing to note here is that this all happens a long time before we can set out the way that a sentence is used, since the way a sentence is used on Lewis’s theory of linguistic content includes the beliefs that are formed on hearing it. So the discussion in “New Work” suggests that naturalness matters for content, but not in a way that can be easily factorised out. And that’s exactly what I think is the best way to understand Lewis’s theory.\n\n\n0.3 Textual Evidence and Naturalness and Rationality\nA major part of my argument above was that naturalness affected Lewis’s theory of rationality. In particular, once he had naturalness to work with, he seemed to think that it was more rational to project natural rather than unnatural properties. The textual evidence for this is, I’ll admit, fragmentary. But it is fairly widespread. Let’s start with a quote we’ve already seen.\n\nThe principles of charity will impute a bias toward believing that things are green rather than grue (Lewis 1983, 375)\n\nAs noted above, I assume this isn’t a special feature of green and grue, but rather that there is a general principle in favour of projecting natural properties. But it would be good to have more evidence for that.\nLewis returns to the example of the believer in grue emeralds a few times. Here is one version of the story in Plurality.\n\nWe think that some sorts of belief and desire \\(\\dots\\) would be unreasonable in a strong sense \\(\\dots\\) utterly unintelligible and nonsensical. Think of the man who, for no special reason, expects unexamined emeralds to be grue. \\(\\dots\\) What makes the perversely twisted assignment of content incorrect, however well it fits the subject’s behaviour, is exactly that it assigns ineligible, unreasonable content when a more eligible assignment would have fit behaviour equally well. (Lewis 1986, 38–39)\n\nAnd a little later, when replying to Kaplan’s paradox, he says,\n\nGiven a fitting assignment, we can scramble it into an equally fitting but perverse alternative assignment. Therefore a theory of content needs a second part: as well as principles of fit, we need ‘principles of humanity’, which create a presumption in favour of some sorts of content and against others. (Lewis 1986, 107)\n\nHe returns to this point again in “Reduction of Mind”.\n\n[Folk psychology] sets presumptive limits on what our contents of belief and desire can be. Self-ascribed properties may be ‘far from fundamental’, I said – but not too far. Especially gruesome gerrymanders are prima facie ineligible to be contents of belief and desire. In short, folk psychology says that we make sense. It credits us with a modicum of rationality in our acting, believing and desiring. (Lewis 1994, 320 in reprint)\n\nThe running thread through these last three quotes is that our theory of mental content rules out gruesome assignments, and it does this because assigning rationality is constitutive of correctly interpreting. This can only work if naturalness is connected to rationality. I’ve attributed a stronger claim to Lewis, that not only is naturalness connected to rationality, but that the connection goes through projection.5\n5 The view I’m attributing to Lewis is endorsed by one prominent supporter of the orthodox interpretation, namely Ted Sider. See his (2011, 35ff).One piece of evidence for that is that Lewis says, in “Meaning Without Use” that Kripkenstein’s challenge was “formerly Goodman’s challenge” (Lewis 1992, 109). He goes on to say that the solution to this challenge (or should that be ‘these challenges’) involves “carrying more baggage of primitive distinctions or ontological commitments than some of us might have hoped” (Lewis 1992, 110). A footnote on that sentence cites “New Work”, in case it isn’t obvious that the baggage here is the distinction between natural and unnatural properties. So somehow, Lewis thinks that natural properties help solve Goodman’s puzzle. I think that the simplest such solution is the right one to attribute to Lewis; natural properties are prima facie more eligible to be projected.\nA referee noted that this passage is a little odd; it appears to simply conflate a meta-semantical paradox with an epistemological paradox. But I think that just shows how much, for Lewis, meta-semantical questions are epistemological questions. Words get their meanings in virtue of our conventions. Our conventions consist of our beliefs and desires. And facts about rationality are, in part, constitutive of what we believe and desire.\nFinally, consider the way in which the papers on natural properties are introduced in Papers in Metaphysics and Epistemology. Lewis says that “I had been persuaded by Goodman and others that all properties were equal: it was hopeless to try to distinguish ‘natural’ properties from gruesomely gerrymandered, disjunctive properties.” (Lewis 1999, 1–2) A footnote refers to Fact, Fiction and Forecast. Of course, the point of “New Work” is that Lewis abandons this, explicitly Goodmanian, view. Now that he had learned property egalitarianism from Goodman of course doesn’t show that once he became a property inegalitarian, he applied this to Goodman’s own paradox. But it does seem striking that the only citation of an egalitarian view is of Fact, Fiction and Forecast. I take that to be some, inconclusive, evidence that Lewis did indeed think natural properties were related to Goodman’s paradox.\nUltimately, it seems the textual evidence is this. There are many different occasions where Lewis makes clear there is a connection between naturalness and rationality, and in particular, between naturalness and the kind of rationality that is relevant to content assignment. There are hints that this connection goes via naturalness playing a role in solving Goodman’s paradox. Notably, there is no other obvious way in which naturalness could connect to rationality. At least, I can neither think of another connection, nor see any evidence for another connection in the Lewis corpus. So I conclude, a little tentatively, that Lewis thought natural properties had a role to play in solving Goodman’s paradox.\n\n\n0.4 Word Meaning and Naturalness\nIn “Languages and Language”, Lewis doesn’t say that human linguistic practices merely determine truth conditions for the spoken sentences. That is, our linguistic practices don’t merely determine which language, in Lewis’s sense, we speak. They also determine, to some extent, a grammar, which specifies the truth conditional contribution of the various parts of the sentence. The grammar determines the “fine structure of meaning” (Lewis 1975, 177) of a sentence or phrase.\nIn comments on an earlier draft of this paper, an anonymous referee stressed that naturalness could enter directly into a theory of meaning once we stopped focussing on sentence meaning, and started looking on word meaning. I don’t mean to say the referee was endorsing any particular role for naturalness in the theory of word meaning. But the point that we need to say more about the Lewisian approach to word meaning before we conclude that naturalness is only indirectly related to meaning is right. And I’m grateful for the encouragement to discuss it further.\nLewis has a short discussion of grammars in “Languages and Language”, and another in “Radical Interpretation”. It’s worth looking at both of these in turn. I’ll take “Languages and Language” first, since even though it has a slightly later publication date, in the respects we’re discussing here it closely resembles the theory in Convention.\nOn pages 177-8 of that paper, Lewis notes three ways in which there may be indeterminacy in the grammar.\n\nA subject’s behavioural dispositions and anatomy might underdetermine their beliefs and desires.\nThe beliefs and desires might underdetermine the truth conditions of their language.\nThe truth conditions of the language might underdetermine the meanings of the individual words.\n\nWhile Lewis does not think the second is actually a source of indeterminacy, he does think that the third is.\n\nMy present discussion has been directed at the middle step \\(\\dots\\) I have said \\(\\dots\\) that the beliefs and desires of the subject and his fellows are such as to comprise a fully determinate convention of truthfulness and trust in some definite language. \\(\\dots\\) I am inclined to share in Quine’s doubts about the determinacy of the third step. (Lewis 1975, 178)\n\nLewis gives reasons for this inclination a few paragraphs earlier. He says that while we can say what it is for a community to speak one language rather than another, we can’t say what it is for a community to speak one grammar rather than another. He says that we don’t have any objective measures for evaluating grammars. And he says Quine’s examples of indeterminacy of reference show that languages can have multiple good grammars, even if these disagree radically about the meaning of some constituents.\nNotably, Lewis doesn’t take to show that there is anything wrong with the notion of word meaning. He says it would be “absurd” (177) to conclude that. His conclusion here is more one of modesty rather than philosophical scepticism. We don’t know how to extend the theory of sentence meaning he offers to a theory of word meaning, so we should do what we can without talking about word meaning.\nThe approach in “Radical Interpretation” has a bit more of a hint for how to restore semantic determinacy. The subject matter of that paper is how to solve for the mental and linguistic contents of a speaker, called Karl, given the physical facts about them. Lewis uses M for “a specification, in our language, of the meanings of expressions of Karl’s language.” (Lewis 1974, 333) He lists a number of constraints on a solution, including early versions of his principles of constitutive rationality. But the most notable constraint, from our perspective, is this:\n\nThe Principle of Generativity constrains M: M should assign truth conditions to the sentences of Karl’s language in a way that is at least finitely specifiable, and preferably also reasonably uniform and simple. (Lewis 1974, 339)\n\nThere’s something very odd about this. Lewis, in 1974, didn’t have a theory of what made an assignment simple. He needed his theory of natural properties to do that. Or, at least, once he had the theory of natural properties, it did all the work he ever wanted out of an account of simplicity.\nBe that as it may, it does suggest that Lewis did think that simplicity of assignments could be used as a way of cutting down the third kind of semantic indeterminacy discussed in “Languages and Language”. He doesn’t think it would generate a fully determinate interpretation of Karl’s language.\n\nIt seems hopeless to deny, in the face of such examples as those in [Quine’s “Ontological Relativity”, pp. 30-39], that the truth conditions of full sentences in M do not sutfice to determine the rest of M: the parsings and the meanings of the constituents of sentences. At least, that is so unless there is something more than our Principle of Generativity to constrain this auxiliary syntactic and semantic apparatus. (Lewis 1974, 342–43)\n\nIt’s notable that some of the examples Quine gives in “Ontological Relativity” are not cases where the alternative meanings are by any measure equally natural. This positive allusion to Quine’s examples suggests a link to this comment in “Languages and Language”\n\nWe should regard with suspicion any method that purports to settle objectively whether, in some tribe, “gavagai” is true of temporally continuant rabbits or time-slices thereof. You can give their language a good grammar of either kind—and that’s that. (Lewis 1975, 177)\n\nNote that he doesn’t say ‘equally’ good. And note also how this contrasts with the attitude he takes towards the prospects of indeterminacy in sentence meaning. I earlier quoted him saying that part of the point of “Languages and Language” was to show how the second type of indeterminacy didn’t arise. He ends “Radical Interpretation” with this ‘credo’.\n\nCould indeterminacy of beliefs, desires, and truth conditions also arise because two different solutions both fit all the constraints perfectly? Here is the place to hold the line. This sort of indeterminacy has not been shown by convincing examples, and neither could it be shown–to me–by proof. Credo: if ever you prove to me that all the constraints we have yet found could permit two perfect solutions, differing otherwise than in the auxiliary apparatus of M, then you will have proved that we have not yet found all the constraints. (Lewis 1974, 343)\n\nSo that’s where things stood before 1983. Lewis thought he had a theory that eliminated, or at least minimised, indeterminacy at the level of truth conditions. But he didn’t think his theory eliminated indeterminacy, even quite radical indeterminacy, in word meanings. And he didn’t seem bothered by this aspect of the theory; indeed, he thought Quine’s arguments showed that we shouldn’t eliminate this kind of indeterminacy.\nThis attitude towards Quinean arguments for indeterminacy is obviously a striking contrast to the forcefulness, and rapidity, with which he responded to Putnam’s arguments for indeterminacy. That shouldn’t be too surprising once we attend to Lewis’s threefold distinction between kinds of indeterminacy. Quine was arguing that indeterminacy of the third kind was rampant. Putnam was arguing that indeterminacy of the second kind was rampant. And, as Lewis announced in “Radical Interpretation”, he wasn’t going to believe any such argument.\nStill, we might wonder whether the resources he brought to bear in responding to Putnam also help respond to Quine. Or, perhaps more importantly for exegetical reasons, we might wonder whether Lewis thought they were useful in responding to Quine. The evidence from “New Work” seems to suggest a negative answer to the latter question. Lewis never says that one of the things you can do with the distinction between natural and unnatural properties is respond to arguments for Quinean indeterminacy. And that’s despite the fact that “New Work” has a very survey-like feel; the bulk of the paper is a long list of philosophical work that a theory of universals can do.\nIn “Putnam’s Paradox” there is a brief footnote on Quine’s arguments for indeterminacy. It reads\n\nIt is not clear how much indeterminacy might be expected to remain. For instance, what of Quine’s famous example? His rabbit-stages, undetached rabbit parts, and rabbit-fusion seem only a little, if any, less eligible than rabbits themselves. (Lewis 1984, 228n)\n\nAs I’ve stressed repeatedly, following Schwarz, taking the disclaimers at the start of “Putnam’s Paradox” seriously means that we have to be careful in interpreting what Lewis says about how words acquire determinate meaning in that paper. But even before we adjust for the disclaimers, this is hardly a ringing rejection of Quine’s indeterminacy arguments. The contrast to Lewis’s attitude towards Putnam’s arguments is striking. Since it is the very same contrast that we saw in both “Languages and Language” and “Radical Interpretation”, I think it is fair to assume that he continued to think Quine’s arguments were considerably stronger than Putnam’s.\nBut there is, perhaps, a change of view in “Meaning Without Use”. Here’s the problem Lewis addresses at the end of that paper. Let \\(\\mathcal{L}_1\\) once again be English as we currently understand it, and let \\(\\mathcal{L}_3\\) be just like English, except that it doesn’t assign any truth conditions to sentences over a thousand words long.6 Do our actual linguistic practices manifest a convention of trust in \\(\\mathcal{L}_1\\), or trust in \\(\\mathcal{L}_3\\)? Lewis argues that it is more like a convention of trust in \\(\\mathcal{L}_3\\). If someone utters a very long sentence, we expect some kind of performance error, at best. We don’t, in general, believe what they say. So the theory of “Languages and Language” seems to predict that these long sentences have no truth conditions. But that’s wrong, so the theory must be corrected.\n6 If you think sentences with a thousand words are too easy to understand for the argument of this paragraph, make the threshold higher; as long as the threshold is finite, it won’t affect the argument.Lewis’s correction appeals, it seems, to natural properties in fixing a grammar. He says that linguistic practice determines truth conditions for a fragment of the language that is widely used. Those truth conditions determine meanings of words. This determination requires natural properties; without them the Quinean problems multiply indefinitely. We then use those word meanings to determine the meaning of unused sentences. A long footnote suggests that the procedure might not be restricted to unused sentences. As long as there is a large enough fragment in which there are conventions of truthfulness and trust, we can extrapolate from that to other parts of the language that are used.\nThis is a marked deviation from anything Lewis had said until then. From the earliest writings, he had stressed a step-by-step approach to content determination. Behavioural dispositions plus physical and biological constraints determine mental content; mental content determines sentence meaning; and sentence meaning determines word meaning. In “Meaning Without Use”, it seemed the last two steps were being somewhat merged.\nBut we shouldn’t overstate how much the third step was allowed to encroach on the second. Lewis does think we need to rule out ‘bent’ grammars, which don’t assign any truth conditions to sentences over a thousand words long, or which give sentences different meanings to what we’d expect if the word ‘cabbage’ appears forty times. But he doesn’t think we need to rule out any ‘straight’ grammar, which includes “any grammar that any linguist would actually propose.” (Lewis 1992, 109)\nSo Lewis’s focus here is to rule out unnatural compositional rules, not unnatural assignments of content to individual words. The reference to linguists here might be useful. Linguists tend to spend much more time on compositional rules than they do on the contents on individual predicates. Notably, Quine didn’t argue for indeterminacy by positing indeterminacy in the compositional rules of the language; his non-standard interpretations all share a standard syntax. If we posit that Lewis thought that there was little syntactic indeterminacy in the language, like there is little indeterminacy at the level of truth conditions of sentences, we can tell a story that doesn’t involve too many unsignalled changes of view. Here’s how I would tell that story in some more detail.\nLewis’s early view, expressed clearly in “Radical Interpretation” and “Languages and Language”, and not retracted before, I think, 1992, has the following parts:\n\nConventions of truthfulness and trust determine (very sharply) truth conditions for sentences in a speaker’s language.\nAny reasonably good grammar, i.e., assignment of word meanings and compositional rules, that is consistent with the truth conditions is not determinately wrong. There is potentially substantial indeterminacy in the meaning of any given word, because there are many reasonably good grammars consistent with the truth conditions.\n\nAfter 1983, ‘simplicity’ was understood in terms of naturalness, but otherwise the story doesn’t change a lot.\nThe later view, which goes by somewhat more quickly in “Meaning Without Use”, has the following parts:\n\nConventions of truthfulness and trust in (the bulk of) the used fragment of the language determine truth conditions for that fragment.\nNaturalness considerations determine the compositional rules for the language by extrapolation from that grammar.\nWord meanings are determined, so far as they are determinate, by the truth conditions for sentences, plus the compositional rules.\nTruth conditions for sentences outside the used fragment are determined by the word meanings and the compositional rules.\n\nNeither of these views look much like the orthodox view. Remember that the orthodox view has it that considerations of naturalness can be used to resolve debates in metaphysics. That’s certainly the use that Sider (2001a) makes of the orthodox view. But on the early view, simplicity considerations only come in after the truth conditions for every sentence have been determined, and hence so that all debates are settled. And on the later view, simplicity considerations primarily are used to settle truth conditions for unused, or at least unusual, sentences.\nNow if you thought the salient fragment in point 1 of the later view was small, and if you thought naturalness had a major role to play in step 3 of the later view, you would get back to something like the orthodox view. But I don’t see the textual evidence for either of those positions. Lewis says that “the used fragment is large and varied.” (Lewis 1992, 110) It doesn’t look like he is positing wholesale changes to his view on the determination of truth conditions. He is positing some changes; the last two pages of the paper are clearly marked as deviations from his earlier position. But both the examples he uses and the rhetoric around them suggests that the bulk of the changes happen at point 2. Naturalness considerations constraint the syntax of a language much more tightly than they constrain the assignment of meaning to a given word. In sum, at no point in the evolution of his views did Lewis seem to endorse the orthodox interpretation, even as a theory of word meaning.\n\n\n0.5 An Argument for the Orthodox Interpretation\nSo far I’ve argued that there is no solid textual support for the orthodox interpretation. My rival interpretation relied on there being a connection between naturalness and induction, and as we’ve just seen, there is some textual evidence for this. But perhaps there is a more indirect way to motivate the orthodox interpretation of Lewis. The orthodox interpretation attributes to Lewis a theory that is quite attractive as a theory of semantic determinacy and indeterminacy. Call that theory the U&N Theory, short for the Use plus Naturalness theory of meaning. Since Lewis was clearly looking for such a theory when he discussed naturalness in the context of his theory of content, it is reasonably charitable to attribute the U&N Theory to him, as the orthodox interpretation does.\nMy response to this will be in three parts. First, I’ll argue in this section that my rival interpretation attributes to Lewis a theory of semantic determinacy and indeterminacy that does just as well at capturing the facts Lewis wanted a theory to capture, so there’s no charity based reason to attribute the U&N Theory to him (And, as we saw in the previous section, there’s no direct textual reason to attribute it to him either.) Second, the U&N Theory is subject to the criticisms in Williams (2007), while the theory I attribute to Lewis is not. Third, the U part of the U&N Theory is hopelessly vague; it isn’t clear how to say what ‘use’ is on a Lewisian theory that makes it suitable to add to naturalness to deliver meanings. Either use is so thick that naturalness is unneeded, or it is so thin that naturalness won’t be sufficient to set meaning. So actually it isn’t particularly charitable to attribute this theory to him.\nStill, let’s start with the attractions of the U&N Theory. On the one hand, agents are inclined to say “All emeralds are green” both in situations where they’ve seen a lot of green emeralds (and no non-green ones) and in situations where they’ve seen a lot of grue emeralds (and no non-grue ones). That’s because, of course, those are exactly the same situations. So at first glance, it doesn’t look like the way in which “green” is used will determine whether it means green or grue. On the other hand, once we add a requirement that terms have a relatively natural meaning, we do get this to fall out as a result. Moreover we can even see how this falls out of a recognisably Lewisian approach to meaning.\nConsider again our agent who says “All emeralds are green” after seeing a lot of emeralds that are both green and grue. And remember that for her to speak a language, she must typically conform to conventions of truthfulness and trust in that language. Now if the agent was speaking \\(\\mathcal{L}_2\\), she would have to think that she’s doing an OK job of being truthful in \\(\\mathcal{L}_2\\) by saying “All emeralds are green”. But that would be crazy. Why should she think that all emeralds are grue given her evidence base? To attribute to her that belief would be to gratuitously attribute irrational beliefs to her. And on Lewis’s picture, gratuitous attributions of irrationality are false. So the agent doesn’t have that belief. So she’s not speaking \\(\\mathcal{L}_2\\).\nThings are even clearer from the perspective of hearers. A hearer of “All emeralds are green” would be completely crazy to come to believe that all emeralds are grue. The hearer knows, after all, that the speaker has no acquaintance with the emeralds that would have to be blue for all emeralds to be grue. So the hearer knows that this utterance could not be sufficient evidence to believe that all emeralds are grue. Yet if she speaks \\(\\mathcal{L}_2\\), she is disposed to believe that all emeralds are grue on hearing “All emeralds are green”. She isn’t irrational, or at least we shouldn’t assign irrationality to her so quickly, so she doesn’t speak \\(\\mathcal{L}_2\\).\nSo it looks like in this one case at least, we have a case where use plus naturalness gives us the right theory. Agents are disposed to use “green” to describe emeralds that are green/grue. But the fact that greenness is more natural than gruesomeness makes it more appropriate to attribute to them a convention according to which “All emeralds are green” means that all emeralds are green and not that all emeralds are grue.\nBut more carefully, what we should say is that the U&N Theory gives us the right result in this case. It doesn’t follow that it will work in all cases, or anything like it. And it doesn’t follow that it works for the right reasons. As we’ll see, neither of those claims are true. In fact, just re-reading the last three paragraphs should undermine the second claim. Because we just saw a derivation that the agents are not speaking \\(\\mathcal{L}_2\\), that didn’t even appeal to the U&N Theory. Rather, that derivation simply used the theory of meaning in Convention and the theory of mental content in “Radical Interpretation”. It’s true that the latter theory assigns a special role to rationality, and the theory of rationality we used has, among other things, a role for natural properties, but that is very different to the idea that naturalness feeds directly into the theory of meaning in the way the orthodox interpretation says. As I said at the start, I think the best interpretation of Lewis is that he changed his theory of rationality in 1983, but that’s the only change to his theory of meaning.\nPut another way, these reflections on “green” and “grue” are consistent with the view that the U&N Theory is a false theory, but a useful heuristic. It’s a useful heuristic because it agrees with the true Lewisian theory in core cases, and is much easier to apply. That’s exactly what I think the U&N Theory is, both as a matter of fact, and as a matter of Lewis interpretation.\n\n\n0.6 Indeterminacy and Radically Deviant Interpretations\nIf the U&N Theory is a heuristic not a theory, we should expect that it will break down in extreme cases. That’s exactly what we see in the cases discussed in Williams (2007). Those cases highlight the fact that a Lewisian theorist needs to be careful that we don’t end up concluding that normal people, such as the agent in our example who says “All emeralds are green”, speak \\(\\mathcal{L}_4\\). \\(\\mathcal{L}_4\\) is a language in which all sentences express claims about a particular mathematical model (essentially a Henkin model of the sentence the agent accepts), and it is set up in such a way that ordinary English sentences come out true, and about very natural parts of the model. On the U&N Theory, it could easily turn out that ordinary speakers are speaking \\(\\mathcal{L}_4\\), since the assigned meanings are so natural. We can see this isn’t a consequence of Lewis’s theory by working through the case from first principles. I have two arguments here, the first of them relying on some slightly contentious claims about the epistemology of mathematics, the second less contentious.\nAssume, for reductio, that ordinary speakers are speaking \\(\\mathcal{L}_4\\). So, for instance, when O’Leary says “The beer is in the fridge”, what he says is that a certain complicated mathematical model has a certain property. (And indeed it has that property.) Now this won’t be a particularly rational thing for O’Leary to say unless he knows more mathematics than ordinary folks like him ordinarily do. So if O’Leary has adopted a convention of truthfulness and trust in \\(\\mathcal{L}_4\\), then uttering “The beer is in the fridge” would be irrational, even if he is standing in front of the open fridge, looking at the beer. That’s a gratuitous assignment of irrationality, and gratuitous assignments of irrationality are false, so O’Leary doesn’t speak \\(\\mathcal{L}_4\\).\nPerhaps that is too quick. After all, the mathematical claim that \\(\\mathcal{L}_4\\) associates with “The beer is in the fridge” is a necessary truth. And Lewis’s theory of content is intentional, not hyper-intentional. So O’Leary does know it is true. (And when he is standing in front of the fridge, there’s even a sense that he knows that “The beer is in the fridge” expresses a truth, if \\(\\mathcal{L}_4\\) is really his language.) I think that’s probably not the right sense of “rational”, and I’m not altogether sure how much hostility to hyper-intensionalism we should attribute to Lewis. But so as to avoid these questions, it’s easier to consider a different argument that focusses attention on O’Leary’s audience.\nWhen O’Leary says “The beer is in the fridge”, Daniels hears him, and then walks to the fridge. Why does Daniels make such a walk? Well, he wants beer, and believes it is in the fridge. That looks like a nice rational explanation. But why does he believe the beer is in the fridge? I say it’s because he’s (rationally) adopted a convention of truthfulness and trust in \\(\\mathcal{L}_1\\), and so he rationally comes to believe the beer is in the fridge when O’Leary says “The beer is in the fridge”. On the assumption that O’Leary and Daniels speak \\(\\mathcal{L}_4\\), none of this story goes through. But we must have some rational explanation of why O’Leary’s statement makes Daniels walk to the fridge. So O’Leary and Daniels must not be speaking \\(\\mathcal{L}_4\\).\nMichael Morreau pointed out (when I presented this talk at CSMN) that the preceding argument may be too quick. Perhaps there is a way of rationalising Daniels’s actions upon hearing O’Leary’s words consistent with the idea that they both speak \\(\\mathcal{L}_4\\). Perhaps, for instance, Daniels’s walking to the fridge constitutes saying something in a complicated sign language, and that thing is the rational reply to what O’Leary said. If this kind of response works, and I have no reason to think it won’t, the solution is to increase the costs to Daniels of performing such a reply. For instance, not too long ago I heard Mayor Bloomberg say “Lower Manhattan is being evacuated because of the impending hurricane”, and I (and my family) packed up and evacuated from Lower Manhattan. Even if one could find an interpretation of our actions in evacuating that made them constitute the assertion of a sensible reply to Bloomberg’s mathematical assertion in \\(\\mathcal{L}_4\\), it would be irrational to think I made such an assertion. Evacuating ahead of a storm with an infant is not fun - if it was that hard to make mathematical assertions, I wouldn’t make them! And I certainly wouldn’t make them in reply to someone who wouldn’t even see my gestures. So I think at least some of the actions that are rationalised by testimony, interpreted as sentences of \\(\\mathcal{L}_1\\), are not rationalised by testimony, interpreted as \\(\\mathcal{L}_4\\). By the kind of appeal to the principle of charity we have used a lot already, that means that \\(\\mathcal{L}_4\\) is not the language most people speak.\nThe central point here is that when we are ruling out particularly deviant interpretations of some speakers, we have to make heavy use of the requirement that the interpretation of their shared language rationalises what they do. In part that means it must rationalise why they utter the strings that they do in fact utter. And when we’re considering this, we should remember the role of naturalness in a theory of rationality. But it also means that it must rationalise why people respond to various strings with non-linguistic actions, such as walking to the fridge, or evacuating Lower Manhattan. Naturalness has less of a role to play here, but the Lewisian theory still gets the right answers provided we apply it carefully. Since the Lewisian theory gets the right answers, and the U&N Theory gets the wrong answers, it follows that the U&N Theory isn’t Lewis’s theory, and so orthodoxy is wrong.\n\n\n0.7 What is the Use of a Predicate?\nWe concluded the last section with an argument that Lewis isn’t vulnerable to the claim that his theory assigns complicated mathematical claims as the meanings of ordinary English sentences. That interpretation, we argued, is inconsistent with the way those sentences are used. In particular, it is inconsistent with the way that hearers use sentences to guide their actions.\nSo far so good, we might think. But notice how much has been packed into the notion of use to get us this far. In identifying the use O’Leary makes of “The beer is in the fridge”, we have to say a lot about O’Leary’s beliefs and desires. And in identifying the use Daniels makes of it, we primarily talk about the sentence’s effects on Daniels’s beliefs and desires. That is, just saying how the sentence is used requires saying a lot about mental states of speakers. And that will often require appealing to constitutive rationality; we say that Daniels’s beliefs about the fridge changed because we need to rationalise his fridge-directed behaviour.\nAnd this should all make us suspicious about the prospects for identifying meaning (in a Lewisian theory) with use plus naturalness. The argument above that naturalness mattered to meaning relied on the idea that naturalness matters because it affects which states are rational, and hence which states are actualised. A belief that all emeralds are grue is unnatural, so it is hard to hold. And since it is hard to hold, it is hard to think one is conforming to a convention of truthfulness in a language if one utters sentences that mean, in that language, that all emeralds are grue. That’s why it is wrong, ceteris paribus, to interpret people as speaking about grueness.\nBut now consider what happened when we were talking about Daniels and O’Leary. Even to say how they were using the sentence “The beer is in the fridge”, we had to say what they believed before and after the sentence was uttered. In other words, their mental states were constitutive of the way the sentence was used. Now add in the extra premise, argued for above, that naturalness matters to Lewis’s theory of linguistic content because, and only because, it matters to his theory of mental content. (And it only matters to mental content because it matters to the principle of charity that Lewis uses.) If mental states, and their changes, are part of how the sentences are used, it will be rather misleading to say that meaning is determined by use plus naturalness. A better thing to say is that meaning is determined by use, and that some key parts of use, i.e., mental states of speakers and hearers, are determined in part by naturalness.\nSo I’m sceptical of the U&N Theory. We can put the argument of the last few paragraphs as a dilemma. There are richer and thinner ways of identifying the use to which a sentence is put. A thin way might, for instance, just focus on the observable state of the part of the physical world in which the sentence is uttered. A rich way might include include, inter alia, the use that is made of the sentence in the management of belief and the generation of rational action. If we adopt the thin way of thinking about use, then adding naturalness won’t be enough to say what makes it the case that O’Leary and Daniels are speaking \\(\\mathcal{L}_1\\) rather than \\(\\mathcal{L}_4\\). If we adopt the rich way of thinking about use, then the role that naturalness plays in the theory of meaning has been incorporated into the metaphysics of use. Neither way makes the U&N Theory true while assigning naturalness an independent role. This dilemma isn’t just an argument that we shouldn’t attribute the U&N Theory to Lewis; it is an argument against anyone adopting that theory.\n\n\n0.8 From Theory to Applied Semantics\nSo far we’ve argued that Lewis’s semantic theory did not look a lot like the orthodox interpretation. It’s true that he thought the way a sentence was used was of primary importance in determining its meaning. And it’s true that he thought naturalness mattered to meaning. But that wasn’t because naturalness came in to resolve the indeterminacy left in a use-based theory of meaning. Rather, it was because naturalness was in a part of the theory of mental content, and specifying the mental states of speakers and hearers is part of specifying how the sentence is used.\nBut note that these considerations apply primarily to investigations at a very high level of generality, such as when we’re trying to solve the problems described in “Radical Interpretation”. They don’t apply to investigations into applied semantics. Let’s say we are trying to figure out what O’Leary and Daniels mean by “green”. And assume that we are taking for granted that they are speaking a language which is, in most respects, like English. This is hardly unusual in ordinary work in applied semantics. If we are writing a paper on the semantics of colour terms, a paper like, say, “Naming the Colours”, we don’t concern ourselves with the possibility that every sentence in the language refers to some complicated mathematical claim or other.\nNow given those assumptions, we can identify a moderately thin notion of use. We know that O’Leary uses “green” to describe things that are, by appearance, both green and grue. We also know that when O’Leary makes such a description, Daniels expects the object will be both green and grue. So focus on a notion of use such that the use of a predicate just is a function of which objects speakers will typically apply the predicate to, and which properties hearers take those objects to have once they hear the predication. If we wanted to be more precise, we could call this notion of ‘use’ simply predication. When we are doing applied semantics, especially when we are trying to figure out the meaning of predicates, we typically know which objects a speaker is disposed to predicate a predicate of, and that’s the salient feature of use. (This is why I said the most accurate heuristic would be meaning is predication plus naturalness; predication is the bit of use we care about in this context.)\nThis identification of use wouldn’t make any sense if we were engaged in theorising at a much more abstract level. If we are doing radical interpretation, then we have to take non-semantic inputs, and solve simultaneously for the values of the subject term and the predicate term in a (simple) sentence. But when we are just doing applied semantics, and working just on the meaning of a term like “green” in a well-functioning language, we can presuppose facts about the denotation of the subject term in sentences like S is green, and presuppose facts about what is the subject and what is the predicate in that sentence, and then we can look at which properties hearers come to associate with that very object on hearing that sentence.\nNow that we have a notion of use that’s distinct from naturalness, we can ask whether it is plausible that predicate meaning is use (in that sense) plus naturalness. And, quite plausibly, the answer is yes. The arguments in Sider (2001a) and Weatherson (2003) in favour of this theory look like, at the very least, good arguments that the theory does the right job in resolving Kripkensteinian problems. The theory is immune to objections based on radical re-interpretations of the language, as in Williams (2007), because those will be inconsistent with the use so defined. And the theory fits nicely into Lewis’s broader theory of meaning, i.e., his metasemantics, which is in turn well motivated. So I think there are good reasons to hold that when we’re doing applied semantics, the U&N Theory delivers the right verdicts, and delivers them for Lewisian reasons. That’s the heart of what’s true about the U&N Theory, even if it isn’t a fully general theory of meaning.\n\n\n\n\n\n\nReferences\n\nBays, Timothy. 2007. “The Problem with Charlie: Some Remarks on Putnam, Lewis and Williams.” Philosophical Review 116 (3): 401–25. https://doi.org/10.1215/00318108-2007-003.\n\n\nHawthorne, John. 2007. “Craziness and Metasemantics.” Philosophical Review 116 (3): 427–40. https://doi.org/10.1215/00318108-2007-004.\n\n\nHolton, Richard. 2003. “David Lewis’s Philosophy of Language.” Mind and Language 18 (3): 286–95. https://doi.org/10.1111/1468-0017.00228.\n\n\nLewis, David. 1969. Convention: A Philosophical Study. Cambridge: Harvard University Press.\n\n\n———. 1974. “Radical Interpretation.” Synthese 27 (3-4): 331–44. https://doi.org/10.1007/bf00484599.\n\n\n———. 1975. “Languages and Language.” In Minnesota Studies in the Philosophy of Science, 7:3–35. Minneapolis: University of Minnesota Press.\n\n\n———. 1979. “Attitudes de Dicto and de Se.” Philosophical Review 88 (4): 513–43. https://doi.org/10.2307/2184646.\n\n\n———. 1980. “Mad Pain and Martian Pain.” In Readings in the Philosophy of Psychology, edited by Ned Block, I:216–32. Cambridge: Harvard University Press.\n\n\n———. 1983. “New Work for a Theory of Universals.” Australasian Journal of Philosophy 61 (4): 343–77. https://doi.org/10.1080/00048408312341131.\n\n\n———. 1984. “Putnam’s Paradox.” Australasian Journal of Philosophy 62 (3): 221–36. https://doi.org/10.1080/00048408412340013.\n\n\n———. 1986. On the Plurality of Worlds. Oxford: Blackwell Publishers.\n\n\n———. 1992. “Meaning Without Use: Reply to Hawthorne.” Australasian Journal of Philosophy 70 (1): 106–10. https://doi.org/10.1080/00048408112340093.\n\n\n———. 1994. “Reduction of Mind.” In A Companion to the Philosophy of Mind, edited by Samuel Guttenplan, 412–31. Oxford: Blackwell. https://doi.org/10.1017/CBO9780511625343.019.\n\n\n———. 1999. Papers in Metaphysics and Epistemology. Cambridge: Cambridge University Press.\n\n\nSchwarz, Wolfgang. 2006. “Lewisian Meaning Without Naturalness.”\n\n\n———. 2009. David Lewis: Metaphysik Und Analyse. Paderborn: Mentis-Verlag.\n\n\nSider, Theodore. 2001a. “Criteria of Personal Identity and the Limits of Conceptual Analysis.” Philosophical Perspectives 15: 189–209. https://doi.org/10.1111/0029-4624.35.s15.10.\n\n\n———. 2001b. Four-Dimensionalism. Oxford: Oxford University Press.\n\n\n———. 2011. Writing the Book of the World. Oxford: Oxford University Press.\n\n\nStalnaker, Robert. 2004. “Lewis on Intentionality.” Australasian Journal of Philosophy 82 (1): 199–212. https://doi.org/10.1080/713659796.\n\n\nWeatherson, Brian. 2003. “What Good Are Counterexamples?” Philosophical Studies 115 (1): 1–31. https://doi.org/10.1023/A:1024961917413.\n\n\n———. 2010. “Vagueness as Indeterminacy.” In Cuts and Clouds: Vaguenesss, Its Nature and Its Logic, edited by Richard Dietz and Sebastiano Moruzzi, 77–90. Oxford: Oxford University Press.\n\n\nWilliams, J. Robert G. 2007. “Eligibility and Inscrutability.” Philosophical Review 116: 361–99. https://doi.org/10.1215/00318108-2007-002."
  },
  {
    "objectID": "posts/gunk/chopping-up-gunk.html",
    "href": "posts/gunk/chopping-up-gunk.html",
    "title": "Chopping up Gunk",
    "section": "",
    "text": "Atomism, the view that indivisible atoms are the basic building blocks of physical reality, has a distinguished history. But it might not be true. The history of physical science certainly gives many of us pause. Every time some class of objects appeared to be the entities that Newton had described as “solid, massy, hard, impenetrable, movable Particles” out of which “God in the Beginning formed Matter” (Newton 1952, 400), further research revealed that these objects were divisible after all. One might be tempted to see that history as confirming Leibniz’ dismissal of atomism as a “youthful prejudice” .1 Perhaps material objects and their parts are always divisible. There are no extended atoms; nor are there point particles which compose material beings.2\n1 See ‘Nature Itself’ in (Leibniz 1998, 220).2 Cf Leibniz: ‘I hold that matter is essentially an aggregate, and consequently that it always has actual parts,’ in ‘Third Explanation of The New System,’ (Leibniz 1998, 193).When first presented with this hypothesis, our imaginations are quickly drawn to picturing the process whereby a quantity of such matter – call it gunk -- is chopped up into smaller and smaller pieces. Prima facie, there is nothing problematic here: insofar as such a process continues without end, the initial quantity gets resolves into smaller and smaller chunks with no limit to the diminution. But suppose this process is packed into an hour, as imagined by Jose Bernadete (1964) in his 1964 monograph Infinity:\n\nTake a stick of wood. In 1/2 minute we are to divide the stick into two equal parts. In the next 1/4 minute we are to divide each of the two pieces again into two equal parts. In the next 1/8 minute we are to divide each of the four pieces (for there are now four equal pieces) again into two equal parts, &c. ad infinitum (Bernadete 1964, 184).\n\nIf matter is divisible without end there seems to be no conceptual obstacle to each of the divisions. Yet how are we to imagine the situation at the end of the hour, when the super-task (call it ‘super-cutting’) has been performed on a quantity of gunk?3\n3 What is important, of course, is that the sequence of separations occur: it does not matter whether some kind of super-sharp knife is responsible for them. In what follows, descriptions of cutting sequences can be replaced without loss of content by descriptions of separation sequences, leaving it open whether repulsive forces or chance events or knives or … are responsible for the separation sequence.If there were extended atoms that were never annihilated, it is clear enough what would happen if some super-being undertook to perform super-cutting: the process would grind to a halt when insurmountably hard particles resisted the chopper.\nIf, meanwhile, there were point-sized particles that composed planes that were as thin as a line, it would be natural to picture the limit of the process as a sea of separated slivers, each devoid of finite extent along one dimension. As Benardete, notes, one might then redo super-cutting in order to finally resolve the original stick into a sea of “metaphysical motes” devoid of finite extent in any direction:\n\nAt the end of the minute how many pieces of wood will we have laid out before us? Clearly an infinite number. If the original stick was twenty inches in length, one inch in width, and one inch in depth, what are the dimensions of the metaphysical chips into which the stick has been decomposed? Each chip will be one inch by one inch by one inch by – what? So prodigiously thin must each chip be that its value is certifiably less then any rational (or irrational) quantity. Let us now take up one of the metaphysical chips and decompose it further into an infinite number of metaphysical splinters. In 1/2 minute we shall divide the chip into two equal parts. Each pieces will be one inch by 1/2 inch. In the next 1/4 minute we shall divide each of the two pieces again into two equal parts, yielding four pieces each being one inch by 1/4 inch. In the next 1/8 minute we shall divide each of the four pieces again into two equal parts, &c ad infinitum. At the end of the mute we shall have composed the metaphysical chip into metaphysical splinters. Each splinter will be one inch in length. Let us now take up one of the metaphysical splinters and break it down into an infinite number of metaphysical motes (Bernadete 1964, 184–85)\n\nThe number of cuts made on the stick, the chip and the splinter respectively is aleph zero. The number of chips, splinters and motes left at the end of each cutting process, meanwhile, is aleph one. (Think of numbering each piece in a super-cutting process by an infinite expansion of one’s and zero’s as follows: if it lay on the left of the first cut, the first numeral is a zero, if to the right, the first numeral is a one; it if lay on the left of one of the pieces that was divided at the second round of cutting its second numeral is a zero, if to the right a one; and so on. For each decimal expansion of one’s and zero’s there is a bit and the end with that expansion.). This result is surprising to some, but poses no deep conceptual confusion. With an ontology of chips, splinters and motes available to us, there is a natural description available to us of the limit to the super-cutting processes described.\nBut what to say when gunk is subjected to super-cutting? If each quantity of matter has proper parts, then a sea of metaphysical motes is not, it would seem, an available outcome. In what follows, we unpack this puzzle, providing along the way some a priori physics for gunk-lovers. The problem is only well formed when we make explicit some of the assumptions that drive it. We do so below:\n\n\nGunk\n\nEvery quantity of matter has proper parts.\n\nConservation of Matter:\n\nNo mereological sum of quantities of matter can be destroyed by any sequence of cuts (though it may be scattered)4.\n4 The ‘can’ here is one of nomological possibility.\nOccupation\n\nIf a quantity of matter occupies a point of space, then there is some volume, extended in all dimensions, to which that point belongs which that quantity of matter occupies.\n\nSuper-cutting\n\nThe laws of the world permit super-cutting.\n\nNote that (1), the thesis that every quantity of matter has parts does not, by itself, entail any of the other theses. One might also think that matter sometimes vanishes as a result of some sequence of cuts, denying (2). One might hold that there are metaphysical splinters (and perhaps even chips), denying (3). One might hold that any given quantity of matter does have point sized pieces but that those pieces themselves have parts (the parts being of the same size as the whole in this case), denying (3). One might hold that some pieces of gunk can occupy, say, a spherical region and also a single isolated point at some considerable distance from the spherical region (while maintaining that no part of it merely occupies the point), also denying (3). One might imagine that while always having parts, the parts below a certain thickness are inseparable, denying (4). One might think there is a minimum amount of time that any event of separation takes, also denying (4) and so on.\nIf the gunk hypothesis is maintained, but one or more of (2) to (4) is jettisoned, there is no problem left to solve. For example: If we are allowed to suppose that gunk may vanish, then it will be perfectly consistent to say that nothing is left at the limit of super-cutting. If we are allowed parts that lack finite extent, then it will be consistent to adopt Benardete’s picture of the outcome. And so on. Our puzzle, properly formulated is: What would happen if super-cutting occurred in a world where (1) to (4) are true?\nIn order to answer that question, we need to supplement Bernadete’s brief discussion of the super-cutting process. It is not immediately clear from what he says that super-cutting a piece of wood will turn an object into chips, even assuming the wood to be composed of point particles. That is a natural description of the limit of the process, but it is hardly one that is forced upon us by the barebones description of the process that Benardete provides. When we divide the stick into two pieces, and then into four pieces, where are we to put these pieces? Presumably we must ensure that they are separated. If not, it will not be clear that we really have splinters left at the end. If the stick is cut into four, but the four pieces are then stored so closely together that they are not scattered any more, then we will not have four scattered objects after two rounds of cutting. By extension, unless we separate the pieces sufficiently after each round (or at least after sufficiently many of them) then even in a world where matter is composed of point particles, it is not clear that there will be infinitely many chips left at the end. Note in this connection that there are limits as to how far we can separate the objects. In a world where super-cutting produces chips, we could not, from left to right, put a one inch gap between each chip and any other, since there are aleph one chips and not aleph one inches of space along any vector. Nor is it even clear what kind of spacing will do the trick: how we are to keep aleph one chips separated from each other? What we need is a formal model showing how super-cutting is to be performed. Only then can we answer with any precision what would happen were super-cutting to be performed on gunk.\nAssume, for simplicity, that we have a stick that is exactly one inch long. At the first stage, cut the stick into two 1/2 inch long pieces, move the left-hand one 1/4 inch leftwards and the right hand one 1/4 inch rightwards. This can be accomplished in 1/2 second without moving the objects at a speed of faster than 1 inch per second, or accelerating or decelerating the objects at a rate higher than 4 inches per second per second.5 At the second stage, cut each piece into two, and move each of the left-hand pieces 1/16 of an inch leftwards, and each of the right-hand pieces 1/16 of an inch rightwards. So if the original piece occupied the interval [0, 1) on a particular axis, the four pieces will now occupy the intervals: [-5/16, -1/16), [1/16, 5/16), [11/16, 15/16), [17/16, 21/16). (The reason we are using these half-open intervals is to avoid questions about whether the objects that are separated by the cut used to overlap.) This cutting and moving can be accomplished in 1/4 of a second, without any piece attaining a velocity higher than 1/2 inch per second, or an acceleration higher than 4 inches per second per second.\n5 The idea is that in the first quarter second we accelerate the object at 4 inches per second per second. This will raise its velocity to 1 inch per second, and move the object 1/8 of an inch. In the second quarter second we decelerate it at 4 inches per second per second, so its velocity ends up at zero, and it ends up having moved 1/4 of an inch.6 Note that, interestingly, if we moved the pieces 1/2 inch after the first round, 1/4 inch after the second round, 1/8 inch after the third round and so on then at the limit, each left and right edge that was once attached will have moved back together again. The process we have chosen preserves separation in a way that the aforementioned process does not.The third stage of the cutting is to take each of these four pieces, cut them in two, move the left-hand part of each of the four 1/64 of an inch to the left, and the right-hand part 1/64 of an inch to the right. So the eight pieces now occupy the intervals: [-21/64, -13/64), [-11/64, -3/64), [3/64, 11/64), [13/64, 21/64), [43/64, 51/64), [53/64, 61/64), [67/64, 75/64), [77/64, 85/64). Again, this cutting and moving can be accomplished within 1/8 of a second, without any piece attaining a velocity higher than 1/4 inch per second, or an acceleration higher than 4 inches per second per second.6\nIn general, at stage n, we take the 2n pieces, divide each of them in two, move the left-hand piece 1/22n inches leftward, and the right-hand piece 1/22n inches rightward. This can all be done in 1/2n seconds without any piece attaining a velocity higher than 1/2n-1 inches per second, or an acceleration higher than 4 inches per second per second. So the whole super-cut can be performed in 1 second: the first stage in 1/2 second, the second stage in 1/4 second, the third stage in 1/8 second, and so on. Note, moreover, that the whole super-cut can be performed in a second without the pieces ever moving at any huge velocity. If readers doubted the possibility of super-cutting because they believed it to be a necessary truth that no matters travels at or beyond the speed of light, their doubts were misplaced: no piece of matter in the super-cutting process approaches a superluminous velocity.\nFurther, in this kind of procedure, a quantity of matter that is scattered during the super-cutting process remains scattered during the process. To see this, first consider a particular example. We noted above that at the second stage there were pieces occupying the intervals [-5/16, -1/16) and [1/16, 5/16). Before this, the point 0 had been occupied; at this stage a gap of 1/8 inch around 0 had been opened. This gap keeps being closed at each stage. After the third stage there were pieces occupying the intervals [/64, -3/64), [3/64, 11/64), so the gap is now only 3/32 inch. After the fourth stage, there will be pieces at [-27/256, -11/256), [11/256, 27/256), so the gap is now only 11/128 inch. This process will make the gap ever smaller, but will not lead to its closure. As the process continues, the size of the gap will approach 1/12 of an inch, but never cross that boundary. To see this, note that the size of the gap in inches after stage n (n \\({\\geq}\\) 3) is 1/8 - 1/25 - 1/27 - … - 1/22n. The sum of the series 1/25 + 1/27 + … is 1/24. Hence the gap at stage n is greater than 1/8 - 1/24 = 1/12. So once the pieces around 0 have been separated, they will never be rejoined.\nThis result applies generally to all of the separated pieces in the super-cut. Once a gap is created, parts of pieces from either side of the gap are moved ever closer to the centre of the gap at every subsequent stage of the super-cut. But since we decrease the distance moved by each piece at each stage of the cut, and in particular decrease it by a factor greater than 2, the pieces, once disjointed, will never be united.\nHow is the matter arranged at the end of the super-cut? To answer this question we need to assume that motion is continuous. For each part of the object we can calculate its position function, the function from the length of time the super-cut has been in progress to the position of the part. At least, we can calculate this for all times until the end of the super-cut. With the continuity assumption in place we can infer that its position at the end of the cut is the limiting value of its position function. So we make this assumption.\nWe assumed above that there is a Cartesian axis running along the object; say that a part a covers a point x just in case a occupies some region [y, z), and y \\({\\leq}\\) x and z &gt; x. When we say a occupies [y, z), we do not mean to imply it occupies only that region, just that it occupies at least that region. Assume then that a part a occupies a point x (0 \\({\\leq}\\) x &lt; 1), and that the binary representation of x is 0.x1x2…xn…, where for each xi, xi equals 0 or 1, and for all i, there exists a j &gt; i such that xj equals zero.7 If x1 = 1, then x \\({\\geq}\\) 1/2, so the some part of a, a small part that originally covered x, will be moved rightward at the first stage. It is possible that a itself may be split by the cut, but there will be a small part around x that is not split, and it will move rightward. If x1 = 0, then x &lt; 1/2, so some part of a, a small part that originally covered x, will be moved leftward at the first stage. Indeed, in general some part of a, a small part that originally covered x, will be moved rightward at the n’th stage if xn = 1, and some part of a, a small part that originally covered x, will be moved leftward at the n’th stage if xn = 0.\n7 The final condition is important to rule out numbers having two possible representations. For example, we have to choose whether the representation of 1/2 should be 0.1000… or 0.0111…, and we somewhat arbitrarily, choose the former.Using the fact that a part gets moved 2-2n inches at stage n, we can infer that after n stages, a small part that originally covered x and has not been split by the cuts will cover the following point after n cuts. \\[x + \\frac{(-1)^{x_1 + 1}}{4} + \\frac{(-1)^{x_2 + 1}}{16} + \\dots + \\frac{(-1)^{x_n + 1}}{2^{2n}}\\]\nAssuming continuity of motion, we can assume that a will end up with a part that eventually covers the following point, which we will call f(x). \\[f(x) = x + \\sum_{i=1}^{\\infty}\\frac{(-1)^{x_i + 1}}{2^{2i}}\\]\nFrom this, it follows immediately that for all x in [0, 1), f(x) will end up being occupied. It turns out that these are the only points that are occupied at the end of the super-cut.\nAssume that a point y is occupied at the end of the super-cut. We will construct a number c such that y = f(c). Recall that we noted above that whenever two pieces were separated, a gap was created between them that would never be completely filled. While parts of the stick would move closer and closer to the centre of that gap during the super-cut, the middle two-thirds of the gap would never be reoccupied. That interval, that would never be reoccupied, would be liberated. The interval [1/3, 2/3) is liberated at the first stage, the intervals [-1/24, 1/24) and [23/24, 25/24) are liberated at the second stage, the intervals [-37/192, -35/192), [35/192, 37/192), [155/192, 157/192) and [227/192, 229/192) are liberated at the third stage, and so on. If y is occupied, then y must not be in any liberated interval. Therefore it must be either to the left or to the right of any interval that is liberated.\nLet c1 equal 0 if y is to the left of the first liberated interval, [1/3, 2/3), and 1 otherwise. Given the value of c1, it is already determined which side y is of one of the intervals liberated at the second stage. If y is to the left of [1/3, 2/3), for example, then it is to the left of [23/24, 25/24). But the value of c1 does not determine which side y is of the other interval. Let c2 equal 0 if y is to the left of that interval, and 1 otherwise. The values of c1 and c2 determine which side y is of three of the four intervals liberated at the fourth stage, but leave open which side it is of one of these four. Let c3 equal 0 if y is to the left of that interval, 1 otherwise. If we repeat this procedure for all stages, we will get values of ci for all i. Let c be the number whose binary expansion is 0.c1c2…cn…. It follows that y = f(c). The reason once it is determined which side y is of each of the liberated intervals, y has been determined to fall in an interval that is exactly one point wide, and f(c) is in that interval, so f(c) must equal y. So y is occupied iff for some x, y = f(x). Say S = {y: \\({\\exists}\\)x (y = f(x))}; the conclusion is that all and only the points in S are occupied.\nCould a piece of gunk occupy the points in S? Not given the assumptions we have made so far. S has two properties that might not seem consistent at first glance. It is dense in the sense that for any point y in S, and any distance \\({\\delta}\\), there is another point z in S such that y - z &lt; \\({\\delta}\\). But it is disconnected in the sense that for any two points y and z in S, there is an extended region r between y and z that is wholly unoccupied. The proofs of density and disconnectedness are given in the appendix.\nGiven (3), disconnectedness is inconsistent with gunk occupying S. If a material object occupies S, it must occupy the points in S. Let y be any one of these points. By (3), S must occupy some extended region containing y, say, [y1, y2). Two cases to consider. First case: y1 &lt; y. If [y1, y2) \\({\\subset}\\) S, then y1 and y are in S, and so are all the points in between them. Since the object occupies S, it follows that these points are occupied. Hence there is no extended region between y1 and y that is wholly unoccupied, which is inconsistent with disconnectedness. Second case: y1 = y. Again, [y1, y2) \\({\\subset}\\) S, and since this interval is non-empty, y2 &gt; y1. Hence (y1 + y2) / 2 is greater than y1, and all the points between it and y1 are occupied. This is also inconsistent with disconnectedness. So given (3), no material object could occupy S.\nIn summary, (1) through (4) plus continuity of motion cannot be true together. From (1), (2), and (4), we inferred that our super-cutting process was possible, and that it would not destroy any quantity of matter (though of course it would scatter it). Assuming continuity of motion, we calculated which points would be occupied after the super-cut. By (3) we concluded that no piece of gunk could occupy those points, or indeed any subset of them, yielding an inconsistent result. Suppose that the continuity of motion thesis is dropped. We can then maintain (1) to (4) with consistency. One should note, however, that a world where (1) to (4) holds would be a strange world indeed: if super-cutting is performed, the pieces of gunk would have to jump location at the limit. The gunk cannot occupy S: but in order to occupy a different set of points, various quantities of matter would have to jump position at the limit.\nIf one believes in gunk one has a choice: Abandon one or more of (2) to (4) or else deny that it is nomologically necessary that motion be continuous. Which assumption should be dropped? We leave it to the gunk lover to select the most tolerable package. The choice for the gunk lover is a little unenviable. Those who are attracted to the view that the actual world is gunky are very much wedded to (1) and (3). When philosophers take seriously the idea that that matter has parts all the way down8, they do not imagine conjoining that thesis with point sized parts, or else immaterial parts9, or else quantities of matter that are as thin as a plane, and so on. With a commitment to (1) and (3) in place, super-cutting will be loaded with physical significance. Accept that the laws of nature permits super-cutting and one will be committed to either denying the conservation of matter or the continuity of motion.\n8 See, for example, (Zimmerman 1996).9 Leibniz, with his monads, is an exception of course. No contemporary gunk lover wants a monadology, however.\nAppendix\nTo prove density, note that if y is occupied, there is a point x with binary representation 0.x1x2… such that y = f(x). For any positive \\({\\delta}\\), there is an integer n such that \\({\\delta}\\) &gt; 2-2n. Let v be the number represented by 0.x1x2…xnxn+1\\(^\\prime\\)xn+2xn+3…, where xn+1\\(^\\prime\\) = 1 iff xn+1 = 0, and xn+1\\(^\\prime\\) = 0 otherwise. The difference between f(x) and f(v) will be exactly 2-2n-1. Since f(v) is occupied, and y = f(x), there is an occupied point exactly 2-2n-1 inches from y, so there is a point less than \\({\\delta}\\) inches from y, as required.\nTo prove disconnectedness, let y and z be any two distinct occupied points. So for some distinct v, x, y = f(x) and z = f(v). Say that the binary representation of x is 0.x1x2…, and the binary representation of v is 0.v1v2… Let j be the lowest number such that xj \\({\\neq}\\) vj. (Since x and v are distinct, there must be at least one value j.) Without loss of generality, assume that xj = 0 and vj = 1. (There is no loss of generality because we are just trying to show that between any two occupied points there is a gap, so it does not matter which of the two points is the rightward one.) Let k be the number with binary representation 0.x1x2…xj1, and let l2 be f(k). Finally, define l1 by the following equation: \\[l_i = \\sum_{i=1}^j \\frac{(-1)^{x_i+1}}{2^{2i}} + \\sum_{i = j+1}^\\infty \\frac{1}{2^{2i}}\\]\nIt is easy enough to see that f(x), that is y, must be less that l1. For l1 is the value that f(x) would take were every digit in the binary expansion of x after j be 1. But by definition there must be some value j\\(^\\prime\\) &gt; j such that xj\\(^\\prime\\) = 0. From this it follows that: \\[\\sum_{i = j+1}^\\infty \\frac{1}{2^{2i}} &gt; \\sum_{i = j+1}^\\infty \\frac{(-1)^{x_i+1}}{2^{2i}}\\]\nAnd from that it follows that l1 &gt; f(x). Indeed, by similar reasoning, it follows that for all u &lt; k, f(u) &lt; l1. Since f is monotone increasing, it also follows that for all u \\({\\geq}\\) k, f(u) \\({\\geq}\\) l2. And from those facts, it follows that there does not exist a u such that f(u) \\({\\in}\\) [l1, l2). And since y &lt; l1 &lt; l2 \\({\\leq}\\) z, this implies that there is an extended unoccupied region between y and z, as required.\n\n\n\n\n\n\nReferences\n\nBernadete, Jose. 1964. Infinity: An Essay in Metaphysics. Oxford: Clarendon Press.\n\n\nLeibniz, Gottfried Wilhelm. 1998. Philosophical Texts. Translated by R. S. Woolhouse and Richard Francks. Oxford: Oxford University Press.\n\n\nNewton, Isaac. 1952. Opticks. New York: Dover Press.\n\n\nZimmerman, Dean. 1996. “Could Extended Objects Be Made Out of Simple Parts: An Argument for Atomless Gunk.” Philosophy and Phenomenological Research 56 (1): 1–29. https://doi.org/10.2307/2108463."
  },
  {
    "objectID": "posts/sre/scepticism-rationalism-and-externalism.html",
    "href": "posts/sre/scepticism-rationalism-and-externalism.html",
    "title": "Scepticism, Rationalism, and Externalism",
    "section": "",
    "text": "This paper is about three of the most prominent debates in modern epistemology. The conclusion is that three prima facie appealing positions in these debates cannot be held simultaneously.\n\nPublished in Oxford Studies in Epistemology 1: 311-31.\n\nThe first debate is scepticism vs anti-scepticism. My conclusions apply to most kinds of debates between sceptics and their opponents, but I will focus on the inductive sceptic, who claims we cannot come to know what will happen in the future by induction. This is a fairly weak kind of scepticism, and I suspect many philosophers who are generally anti-sceptical are attracted by this kind of scepticism. Still, even this kind of scepticism is quite unintuitive. I’m pretty sure I know (1) on the basis of induction.\n\nThis paper has been presented at Cornell University and the Inland Northwest Philosophy Conference, and each time I received valuable feedback.\n\n\nIt will snow in Ithaca next winter.\n\nAlthough I am taking a very strong version of anti-scepticism to be intuitively true here, the points I make will generalise to most other versions of scepticism. (Focussing on the inductive sceptic avoids some potential complications that I will note as they arise.)\n\nThanks also to David Chalmers, Harold Hodes, Nicholas Sturgeon and, especially, Tamar Szabó Gendler for very helpful comments on various drafts of the paper.\n\nThe second debate is a version of rationalism vs empiricism. The kind of rationalist I have in mind accepts that some deeply contingent propositions can be known a priori, and the empiricist I have in mind denies this. Kripke showed that there are contingent propositions that can be known a priori. One example is Water is the watery stuff of our acquaintance. (‘Watery’ is David Chalmers’s nice term for the properties of water by which folk identify it.) All the examples Kripke gave are of propositions that are, to use Gareth Evans’s term, deeply necessary (Evans 1979). It is a matter of controversy presently just how to analyse Evans’s concepts of deep necessity and contingency, but most of the controversies are over details that are not important right here. I’ll simply adopt Stephen Yablo’s recent suggestion: a proposition is deeply contingent if it could have turned out to be true, and could have turned out to be false [Yablo (2002)]1. Kripke did not provide examples of any deeply contingent propositions knowable a priori, though nothing he showed rules out their existence.\n1 If you prefer the ‘two-dimensional’ way of talking, a deeply contingent proposition is one that is true in some possible world ‘considered as actual’. See Chalmers (2006) for a thorough discussion of ways to interpret this phrase, and the broader notion of so-called ‘deep’ contingency. Nothing that goes on here will turn on any of the fine distinctions made in that debate - the relevant propositions will be deeply contingent in every plausible sense.2 That a property is introspective does not mean that whenever a subject instantiates it she is in a position to form a not too badly mistaken belief about it. Even if the subject instantiates the property she may not possess sufficient concepts in order to have beliefs about it. And even if she has the concept she may simply have more pressing cognitive needs than forming certain kinds of belief. Many agents have no beliefs about the smell in their ordinary environment much of the time, for example, and this does not show that phenomenal smell properties are not introspective. All that is required is that if she has any beliefs at all about which determinate she instantiates, the beliefs are immune to massive error.The final debate is a version of internalism vs externalism about epistemic justification. The internalist I have in mind endorses a very weak kind of access internalism. Say that a class of properties (intuitively, a determinable) is introspective iff any beliefs an agent has about which property in the class (which determinate) she instantiates are guaranteed to not be too badly mistaken.2 (Since ‘too badly’ is vague, ‘introspective’ will be vague too, but as we’ll see this won’t matter to the main argument.) My internalist believes the following two claims:\n\nWhich propositions an agent can justifiably believe supervenes in which introspective properties she instantiates, and this is knowable a priori.3\nThere exist some introspective properties and some deeply contingent propositions about the future such that it’s a priori that whoever instantiates those properties can justifiably believe those propositions.\n\n3 There is a delicate ambiguity in this expression to which a referee drew my attention. The intended meaning is that for any two agents who instantiate the same introspective properties, belief in the same propositions is justified. What’s not intended is that if there’s an agent who justifiably believes p, and the introspective properties they instantiate are F1, …, Fn, then any agent who instantiates F1, …, Fn is justified in believing p. For there might be some other introspective property Fn+1 they instantiate that justifies belief in q, and q might be a defeater for p. The ‘unintended’ claim would be a very strong, and very implausible, claim about the subvenient basis for justification.My externalist denies one or other of these claims. Typically, she holds that no matter what introspective properties you have, unless some external condition is satisfied (such as the reliability of the connection between instantiating those properties and the world being the way you believe it is) you lack justification. Alternatively, she holds that the connection between introspective properties and justification is always a posteriori. (Or, of course, she might deny both.)\nMy argument will be that the combination of anti-scepticism, empiricism and internalism is untenable. Since there’s quite a bit to be said for each of these claims individually, that their combination is untenable means we are stuck with a fairly hard choice: accept scepticism, or rationalism, or externalism. Of the three, it may seem that externalism is the best, but given how weak the version of internalism is that I’m using, I think we should take the rationalist option seriously.4 In this paper I’ll just argue against the combination of anti-scepticism, empiricism and internalism, and leave it to the reader to judge which of the three to reject.\n4 Rationalism is supported by BonJour (1997) and Hawthorne (2002), and my argument owes a lot to each of their discussions.Very roughly, the argument for the trilemma will be as follows. There are some propositions q such that these three claims are true.\n\nIf anti-scepticism is true, then I either know q a priori or a posteriori.\nIf internalism and empiricism is true, I do not know q a priori.5\nIf internalism is true, I do not know q a posteriori.\n\n5 Aesthetically it would be preferable to have the antecedent of this claim be just that empiricism is true, but unfortunately this does not seem to be possible.6 I.e. I am not a brain-in-a-vat* in the sense of Cohen (1999)Much of the paper will be spent giving us the resources to find, and state, such a q, but to a first approximation, think of q as being a proposition like I am not a brain-in-a-vat whose experiences are as if they were a normal person.6 The important features of q are that (a) it is entailed by propositions we take ourselves to know, (b) it is possibly false and (c) if something is evidence for it, then any evidence is evidence for it. I will claim that by looking at propositions like this, propositions that say in effect that I am not being misled in a certain way, it is possible to find a value for q such that (2), (3) and (4) are all true. From that it follows that\nFor most of the paper I will assume that internalism and anti-scepticism are true, and use those hypotheses to derive rationalism. The paper will conclude with a detailed look at the role internalism plays in the argument, and this will give us some sense of what an anti-sceptical empiricist externalism may look like.\n\n0.1 A Sceptical Argument\nAmong the many things I know about future, one of the firmest is (1).\n\nIt will snow in Ithaca next winter.\n\nI know this on the basis of inductive evidence about the length of meteorological cycles and the recent history of Ithaca in winter. The inductive sceptic now raises the spectre of Winter Wonderland, a kind of world that usually has the same meteorological cycles as ours, and has the same history, but in which it is sunny every day in Ithaca next winter.7 She says that to know (1) we must know that (5) is false, and we do not.\n7 If she is convinced that there is no possible world with the same history as ours and no snow in Ithaca next winter, the sceptic will change her story so Winter Wonderland’s past differs imperceptibly from the past in our world. She doesn’t think this issue is particularly relevant to the epistemological debate, no matter how interesting the scientific and metaphysical issues may be, and I agree with her.\nI am living in Winter Wonderland.\n\nJust how does reflection (5) affect my confidence that I know (1)? The sceptic might just appeal to the intuition that I don’t know that (5) is false. But I don’t think I have that intuition, and if I do it is much weaker than my intuition that I know (1) and that I can infer (5) from (1). James Pryor (2000, 527–29) has suggested the sceptic is better off using (5) in the following interesting argument.8\n8 Pryor is discussing the external world sceptic, not the inductive sceptic, so the premises here are a little different to those he provides.\nEither you don’t know you’re not living in Winter Wonderland; or, if you do know that, it’s because that knowledge rests in part on your inductive knowledge that it will snow in Ithaca next winter.\nIf you’re to know (1) on the basis of certain experiences or grounds e, then for every q which is “bad” relative to e and (1), you have to be in a position to know q to be false in a non-question-begging way—i.e., you have to be in a position to know q to be false antecedently to knowing that it will snow next winter on the basis of e.\n(5) is “bad” relative to any course of experience e and (1).\nYou can’t know (1), that it will snow next winter on the basis of your current experiences.\n\nAn alternative hypothesis q is “bad” in the sense used here iff (to quote Pryor) “it has the special features that characterise the sceptic’s scenarios—whatever those features turn out to be.” (527) To a first approximation, q is bad relative to p and e iff you’re meant to be able to know p on the basis of e, but q is apparently compatible with e, even though it is not compatible with p.\nPryor argues that the best response to the external world sceptic is dogmatism. On this theory you can know p on the basis of e even though you have no prior reason to rule out alternatives to p compatible with e. Pryor only defends the dogmatic response to the external world sceptic, but it’s worth considering the dogmatist response to inductive scepticism. According to this response, I can come to know I’m not in Winter Wonderland on the basis of my experiences to date, even though I didn’t know this a priori. So dogmatism is a version of empiricism, and it endorses (6).9 The false premise in this argument, according to the dogmatist, is (7). We can know it will snow even though the Winter Wonderland hypothesis is bad relative to this conclusion and our actual evidence, and we have no prior way to exclude it.\n9 It is a version of the kind of internalism discussed in footnote 2, since according to the dogmatist seeming to see that p can be sufficient justification for belief in p. Pryor’s preferred version of dogmatism is also internalist in the slightly stronger sense described in the text, but it seems possible that one could be a dogmatist without accepting that internalist thesis. One could accept, for instance, that seeming to see that p justifies a belief that p, but also think that seeming to see that q justifies a belief that p iff there is a known reliable connection between q and p. As I said, even the weaker version of internalism is sufficient to generate a conflict with anti-scepticism and empiricism, provided we just focus on the propositions that can be justifiably believed on the basis of introspective properties.Pryor notes that the sceptic could offer a similar argument concerning justification, and the dogmatist offers a similar response.\n\nEither you’re not justified in believing that you’re not in Winter Wonderland; or, if you are justified in believing this, it’s because that justification rests in part on your justified belief that it will snow in Ithaca next winter.\nIf you’re to have justification for believing (1) on the basis of certain experiences or grounds e, then for every q which is “bad” relative to e and (1), you have to have antecedent justification for believing q to be false—justification which doesn’t rest on or presuppose any e-based justification you may have for believing (1).\n(5) is “bad” relative to any course of experience e you could have and (1).\nYou can’t justifiably believe it will snow in Ithaca next winter on the basis of past experiences.\n\nThe dogmatist rejects (10), just as she rejects (7). I shall spend most of my time in the next two sections arguing for (10), returning to (7) only at the end. For it seems there are compelling reasons to accept (10), and hold that the problem with this argument is either with (9) or (11).10\n10 Just which is wrong then? That depends on how “bad” is defined. On our final definition (8) will fail, but there are other sceptical arguments, using other sceptical hypotheses, on which (6) fails.\n\n0.2 Dominance Arguments\nThe primary argument for (10) will turn on a dominance principle: if you will be in a position to justifiably believe p whatever evidence you get, and you know this, then you are now justified in believing p. This kind of reasoning is perfectly familiar in decision theory: if you know that one of n states obtains, and you know that in each of those states you should do X rather than Y, then you know now (or at least you should know) that you should do X rather than Y. This is a very plausible principle, and equivalent epistemic principles are just as viable. Dominance reasoning can directly support (10) and hence indirectly support (7). (As Vann McGee (1999) showed, the dominance principle in decision theory has to be qualified for certain kinds of agents with unbounded utility functions who are faced with a decision tree with infinitely many branches. Such qualifications do not seem at all relevant here.)\nIt will be useful to start with an unsound argument for (10), because although this argument is unsound, it fails in an instructive way. Before I can present the argument I need to make an attempt at formalising Pryor’s concept of badness.\n\nq is bad relative to e and p =df q is deeply contingent, you know p entails \\(\\neg\\)q, and for any possible evidence e\\(^\\prime\\) (that you could have had at the time your total evidence is actually e) there exists a p\\(^\\prime\\) such that you know p\\(^\\prime\\) entails \\(\\neg\\)q and you are justified in believing p\\(^\\prime\\) on the basis of e\\(^\\prime\\) if e\\(^\\prime\\) is your total evidence.\n\nRoughly, the idea is that a bad proposition is one that would be justifiably ruled out by any evidence, despite the fact that it could turn out to be true.11 Using this definition we can present an argument for rationalism. The argument will use some fairly general premises connecting justification, evidence and badness. If we were just interested in this case we could replace q with (5), r with the proposition that (5) is false, e with my current evidence, and e\\(^\\prime\\) with some evidence that would undermine my belief that (5) is false, if such evidence could exist. The intuitions behind the argument may be clearer if you make those substitutions when reading through the argument. But because the premises are interesting beyond their application to this case, I will present the argument in its more general form.\n11 Note that there’s a subtle shift here in our conception of badness. Previously we said that bad propositions are those you allegedly know on the basis of your actual evidence (if you know p) even though they are logically consistent with that evidence. Now we say that they are propositions you could rule out on any evidence, even though they are consistent with your actual total evidence. This is a somewhat narrower class of proposition, but focussing on it strengthens the sceptic’s case appreciably.\nIf you are justified in believing (1) on the basis of e, and you know (1) entails \\(\\neg\\)(5), then you are justified in believing \\(\\neg\\)(5) when your evidence is e.\nIf you are justified in believing r (at time t) on the basis of e, then there is some other possible evidence e\\(^\\prime\\) (that you could have at t) such that you would not be justified in believing r were your total evidence e\\(^\\prime\\).\nIf you are justified in believing r, and there is no evidence e such that e is part of your evidence and you are justified in believing r on the basis of e, then you are justified in believing r a priori.12\nBy definition, q is bad relative to e and p iff q is deeply contingent, you know p entails \\(\\neg\\)q, and for any possible evidence e\\(^\\prime\\) (that you could have when your evidence is e) there exists a p\\(^\\prime\\) such that you know p\\(^\\prime\\) entails \\(\\neg\\)q and you are justified in believing p\\(^\\prime\\) on the basis of e\\(^\\prime\\) if e\\(^\\prime\\) is your total evidence.\nSo, if q is bad relative to e and (1), and you are justified in believing (1) on the basis of e, then you are justified in believing \\(\\neg\\)q a priori.\n\n12 {#fnt:ftn13 label=“fnt:ftn13”} David Chalmers noted that (10) and (11) entail that I exist is a priori. He thought this was a bad result, and a sufficient reason to modify these premises. I’m perfectly happy with saying, following Kaplan, that I exist is a priori. I don’t think this proves rationalism, because I think it’s also deeply necessary that I exist. (It’s not deeply necessary that Brian exists, but that’s no objection to what I just claimed, because it’s not deeply necessary that I’m Brian.)\nThis position is controversial though, so I don’t want to rest too much weight on it. If you don’t think that I exist should be a priori, rewrite (11) so that it’s conclusion is that you would be justified in believing the material conditional I exist \\({\\supset}\\) r a priori. (Note that since I’m presupposing in the dominance argument that all the salient possibilities are ones in which I have some evidence, and hence exist, it’s not surprising that I exist has a special status within the theory.)\nOn a separate point, note that I make no assumptions whatsoever here about what relationship must obtain between a justified belief and the evidence on which it is based. Depending on what the right theory of justification is, that relationship might be entailment or constitution or causation or association or reliable connection or something else or some combination of these. I do assume that a posteriori beliefs are somehow connected to evidence, and if the beliefs are justified this relation is properly called basing.(The references to times in (13) and (15) is just to emphasise that we are talking about your current evidence, and ways it could be. That you could observe Winter Wonderland next winter doesn’t count as a relevant alternative kind of evidence now.)\nOur conclusion (16) entails (10), since (10) merely required that for every bad proposition relative to e and (1), you have ‘antecedent’ justification for believing that proposition to be false, while (16) says this justification is a priori. (‘Antecedent’ justification need not be a priori as long as it arrives before the particular evidence you have for (1). This is why (16) is strictly stronger than (10).) So if (10) is false then one of these premises must be false. I take (15) to define “bad”, so it cannot be false. Note that given this definition we cannot be certain that (5) is bad. We will return to this point a few times.\nWhich premise should the dogmatist reject? (12) states a fairly mundane closure principle for justified belief. And (13) follows almost automatically from the notion of ‘basing’. A belief can hardly be based in some particular evidence if any other evidence would support it just as well. This does not mean that such a belief cannot be rationally caused by the particular evidence that you have, just that the evidence cannot be the rational basis for that belief. The dogmatist objects to (14). There is a prima facie argument for (14), but as soon as we set it out we see why the dogmatist is correct to stop us here.\nConsider the following argument for (14), which does little more than lay out the intuition (14) is trying to express. Assume r is such that for any possible evidence e, one would be justified in believing r with that evidence. Here’s a way to reason a priori to r. Whatever evidence I get, I will be justified in believing that q. So I’m now justified in believing that r, before I get the evidence. Compare a simple decision problem where there is one unknown variable, and it can one of two values, but whichever value it takes it is better for one to choose X rather than Y. That is sufficient to make it true now that one should choose X rather than Y. Put this way, the argument for (14) is just a familiar dominance argument.\nTwo flaws with this argument for (14) stand out, each of them arising because of disanalogies with the decision theoretic case.\nFirst, when we apply dominance reasoning in decision theory, we look at cases where it would be better to take X rather than Y in every possible case, and this is known. This point is usually not stressed, because it’s usually just assumed in decision theory problems that the players know the consequences of their actions given the value of certain unknown variables. It’s not obviously a good idea to assume this without comment in applications of decision theory, and it’s clearly a bad idea to make the same kind of assumption in epistemology. Nothing in the antecedent of (14) specifies that we can know, let alone know a priori, that if our evidence is e then we are justified in believing r. Even if this is true, even if it is necessarily true, it may not be knowable.\nSecond, in the decision theory case we presupposed it is known that the variable can take only one of two values. Again, there in nothing in the antecedent of (14) to guarantee the parallel. Even if an agent knows of every possible piece of evidence that if she gets that evidence she will be justified in believing r, she may not be in a position to justifiably conclude r now because she may not know that these are all the possible pieces of evidence. In other words, she can only use dominance reasoning to conclude r if she knows de dicto, and not merely de re, of every possible body of evidence that it justifies r.\nSo the quick argument for (14) fails. Still, it only failed because (14) left out two qualifications. If we include those qualifications, and adjust the other premises to preserve validity, the argument will work. To make this adjustment, we need a new definition of badness.\n\nq is bad relative to e and p =df\n\nq is deeply contingent;\np is known to entail \\(\\neg\\)q; and\nit is knowable a priori that for any possible evidence e\\(^\\prime\\) there exists a p\\(^\\prime\\) such that p\\(^\\prime\\) is known to entail \\(\\neg\\)q, and one is justified in believing p\\(^\\prime\\) on the basis of e\\(^\\prime\\).\n\n\nThe aim still is to find an argument for some claim stronger than (10) in sceptical argument 2. If we can do that, and if as the sceptic suggests (5) really is bad, then the only anti-sceptical response to sceptical argument 2 will be rationalism. So the fact that this looks like a sound argument for a slightly stronger conclusion than (10) is a large step in our argument that anti-scepticism plus internalism entails rationalism. (I omit the references to times from here on.)\n\nIf you are justified in believing (1) on the basis of e, and you know (1) entails \\(\\neg\\)(5), then you are justified in believing \\(\\neg\\)(5) when your evidence is e.\nIf you are justified in believing r on the basis of e, then there is some other possible evidence e\\(^\\prime\\) such that you would not be justified in believing r were your total evidence e\\(^\\prime\\).\nIf you know you are justified in believing r, and you know a priori that there is no evidence e you have such that you are justified in believing r on the basis of e, then you are justified in believing r a priori.13\nBy definition, q is bad relative to e and p iff q is deeply contingent, p is known to entail \\(\\neg\\)q, and it is knowable a priori that for any possible evidence e\\(^\\prime\\) there exists a p\\(^\\prime\\) such that p\\(^\\prime\\) is known to entail \\(\\neg\\)q, and one is justified in believing p\\(^\\prime\\) on the basis of e\\(^\\prime\\).\nSo, if q is bad relative to e and (1), and you are justified in believing (1) on the basis of e, then you are justified in believing \\(\\neg\\)q a priori.\n\n13 Again, if you don’t think I exist should be a priori, the conclusion should be that I exist \\({\\supset}\\) r is a priori.This is a sound argument for (19), and hence for (10), but as noted on this definition of “bad” (11) may be false. If the Winter Wonderland hypothesis is to be bad it must be a priori knowable that on any evidence whatsoever, you’d be justified in believing it to be false. But as we will now see, although no evidence could justify you in believing the Winter Wonderland hypothesis to be true, it is not at all obvious that you are always justified in believing it is false.\n\n\n0.3 Hunting the Bad Proposition\nA proposition is bad if it is deeply contingent but if you could justifiably believe it to be false on the basis of your current evidence, you could justifiably believe it to be false a priori. If a bad proposition exists, then we are forced to choose between rationalism and scepticism. To the extent that rationalism is unattractive, scepticism starts to look attractive. I think Pryor is right that this kind of argument tacitly underlies many sceptical arguments. The importance of propositions like (5) is not that it’s too hard to know them to be false. The arguments of those who deny closure principles for knowledge notwithstanding, it’s very intuitive that it’s easier to know (5) is false than to know (1) is true. So why does reflection on (5) provide more comfort to the inductive sceptic than reflection on (1)? The contextualist has one answer, that thinking about (5) moves the context to one where sceptical doubts are salient. Pryor’s work suggests a more subtle answer. Reflecting on (5) causes us to think about how we could come to know it is false, and prima facie it might seem we could not know that a priori or a posteriori. It’s that dilemma, and not the mere salience of the Winter Wonderland possibility, that drives the best sceptical argument. But this argument assumes that (5) could not be known to be false on the basis of empirical evidence, i.e. that it is bad. If it is not bad, and nor is any similar proposition, then we can easily deflect the sceptical argument. However, if we assume internalism, we can construct a bad proposition.\nThe prima facie case that (5) is bad (relative to (1) and our current evidence e – I omit these relativisations from now on) looks strong. The negation of (5) is (20), where H is a proposition that summarises the relevant parts of the history of the world.14\n14 I assume H includes a ‘that’s all that’s relevant clause’ to rule out defeaters. That is, it summaries the relevant history of the world as such.\nEither \\(\\neg\\)H or it will snow in Ithaca next winter.\n\nNow one may argue that (5) is bad as follows. Either our evidence justifies believing \\(\\neg\\)H or it doesn’t. If it does, then it clearly justifies believing (20), for \\(\\neg\\)H trivially entails it. If it does not, then we are justified in believing H, and whenever we are justified believing the world’s history is H, we can inductively infer that it will snow in Ithaca next winter. The problem with this argument, however, is fairly clear: the step from the assumption that we are not justified in believing \\(\\neg\\)H to the conclusion we are justified in believing H is a modal fallacy. We might be justified in believing neither H nor its negation. In such a situation, it’s not obvious we could justifiably infer (20). So (5) may not be bad.\nA suggestion John Hawthorne (2002) makes seems to point to a proposition that is more plausibly bad. Hawthorne argues that disjunctions like (21) are knowable a priori, and this suggests that (22), its negation, is bad.\n\nEither my evidence is not e or it will snow in Ithaca next winter.\nMy evidence is e and it will not snow in Ithaca next winter.\n\nHawthorne does not provide a dominance argument that (21) is knowable a priori. Instead he makes a direct appeal to the idea that whatever kinds of inference we can draw now the basis of our evidence we could have drawn prior to getting e as conditional conclusions, conditional on getting e. So if I can now know it will snow in Ithaca next winter, prior to getting e I cold have known the material conditional If my evidence is e, it will snow in Ithaca, which is equivalent to (21). It’s not clear this analogy works, since when we do such hypothetical reasoning we take someone to know that our evidence is e, and this may cause some complications. Could we find a dominance argument to use instead? One might be tempted by the following argument.\n\nI know a priori that if my evidence is e, then I am justified in believing the second disjunct of (21).\nI know a priori that if my evidence is not e, then I am justified in believing the first disjunct of (21)\nI know a priori that if I am justified in believing a disjunct of (21) I am justified in believing the disjunction (21).\nI know a priori that my evidence is either e or not e.\nSo, I’m justified a priori in believing (21).\n\nThe problem here is the second premise, (24). It’s true that if my evidence is not e then the first disjunct of (21) is true. But there’s no reason to suppose I am justified in believing any true proposition about my evidence. Timothy (Williamson 2000 ch. 8) has argued that the problem with many sceptical arguments is that they assume agents know what their evidence is. I doubt that’s really the flaw in sceptical arguments, but it certainly is the flaw in the argument that (22) is bad.\nThe problem with using (22) is that the argument for its badness relied on quite a strong privileged access thesis: whenever my evidence is not e I am justified in believing it is not. If we can find a weaker privileged access thesis that is true, we will be able to find a proposition similar to (22) that is bad. And the very argument Williamson gives against the thesis that we always know what our evidence is will show us how to find such a thesis.\nWilliamson proposes a margin-of-error model for certain kinds of knowledge. On this model, X knows that p iff (roughly) p is true in all situations within X’s margin-of-error.15 The intuitive idea is that all of the possibilities are arranged in some metric space, with the distance between any two worlds being the measure of their similarity with respect to X. Then X knows all the things that are true in all worlds within some sphere centred on the actual world, where the radius of that sphere is given by how accurate she is at forming beliefs.\n15 There’s a considerable amount of idealisation here. What’s really true is that X is in a position to know anything true in all situations within her margin-of-error. Since we’re working out what is a priori knowable, I’ll assume agents are idealised so they know what they are in a position to know. This avoids needless complications we get from multiplying the modalities that are in play.One might think this would lead to the principle B: p \\({\\rightarrow}\\) K\\(\\neg\\)K\\(\\neg\\)p, that is, if p is true then X knows that she does not know \\(\\neg\\)p. Or, slightly more colloquially, if p is true then X knows that for all she knows p is true. (I use K here as a modal operator. KA means that X, the salient subject, knows that A.) On a margin-of-error model p \\({\\rightarrow}\\) K\\(\\neg\\)K\\(\\neg\\)p is false only if p is actually true and there is a nearby (i.e. within the margin-of-error) situation where the agent knows \\(\\neg\\)p. But if nearby is symmetric this is impossible, because the truth of p in this situation will rule out the knowability of \\(\\neg\\)p in that situation.\nAs Williamson points out, that quick argument is fallacious, since it relies on a too simplistic margin-of-error model. He proposes a more complicated account: p is known at s iff there is a distance d greater than the margin-of-error and for any situation s\\(^\\prime\\) such that the distance between s and s\\(^\\prime\\) is less than d, p is true at s\\(^\\prime\\). Given this model, we cannot infer p \\({\\rightarrow}\\) K\\(\\neg\\)K\\(\\neg\\)p. Indeed, the only distinctive modal principle we can conclude is Kp \\({\\rightarrow}\\) p. However, as Delia Graff Fara (2002) has shown, if we make certain density assumptions on the space of available situations, we can recover the principle (27) within this account.16\n16 If we translate K as \\(\\square\\) and \\(\\neg\\)K\\(\\neg\\) as \\(\\diamond\\), (24) can be expressed as the modal formula p \\({\\rightarrow}\\) \\(\\square\\)\\(\\diamond\\)\\(\\diamond\\)p.\np \\({\\rightarrow}\\) K\\(\\neg\\)KK\\(\\neg\\)p\n\nTo express the density assumption, let d(s1, s2) be the ‘distance’ between s1 and s2, and m the margin-of-error. The assumption then is that there is a k &gt; 1 such that for any s1, s2 such that d(s1, s2) &lt; km, there is an s3 such that d(s1, s3) &lt; m and d(s3, s2) &lt; m. And this will be made true if there is some epistemic situation roughly ‘half-way’ between s1 and s2.17 That is, all we have to assume to recover (27) within the margin-of-error model is that the space of possible epistemic situations is suitably dense. Since the margin-of-error model, and Fara’s density assumption, are both appropriate for introspective knowledge, (27) is true when p is a proposition about the agent’s own knowledge.\n17 Fara actually gives a slightly stronger principle than this, but this principle is sufficient for her purposes, and since it is weaker than Fara’s, it is a little more plausible. But the underlying idea here, that we can get strong modal principles out of margin-of-error models by making plausible assumptions about density, is taken without amendment from her paper.18 If you preferred the amended version of (11) discussed in footnote 12, the bad proposition is I don’t exist or (28) is true.To build the bad proposition now, let G be a quite general property of evidence, one that is satisfied by everyone with a reasonable acquaintance with Ithaca’s weather patterns, but still precise enough that it is a priori that everyone whose evidence is G is justified in believing it will snow in Ithaca next winter. The internalist, remember, is committed to such a G existing and it being an introspective property. Now consider the following proposition, which I shall argue is bad.18\n\nI know that I know my evidence is G, and it will not snow in Ithaca next winter.\n\nThe negation of (28) is (29).\n\nIt will snow in Ithaca next winter, or I don’t know that I know my evidence is G.\n\nIt might be more intuitive to read (29) as the material conditional (29a), though since English conditionals aren’t material conditionals this seems potentially misleading.\n\nIf I know that I know that my evidence is G, then it will snow in Ithaca next winter.\n\nTo avoid confusions due to the behaviour of conditionals, I’ll focus on the disjunction (29). Assume for now that the margin-of-error model is appropriate for propositions about my own evidence. I will return below to the plausibility of this assumption. This assumption implies that principle (27) is always correct when p is a proposition about my evidence. Given this, we can prove (28) is bad. Note that all my possible evidential states either are, or are not, G. If they are G then by hypothesis I am justified in believing that it will snow in Ithaca next winter and hence I am justified in believing (29). If they are not, then by the principle (27) I know that I don’t know that I know my evidence is G, so I can come to know (29), so I am justified in believing (29). So either way I am justified in believing (29). It’s worth noting that at no point here did I assume that I knew whether my evidence was G, though I do assume that I know that having evidence that is G justifies belief in snow next winter.\nAll of this assumes the margin-of-error model looks appropriate for introspective properties. If it isn’t, then we can’t assume that (27) is true when p is a proposition about the introspective properties I satisfy, and hence the argument that (29) is knowable a priori fails. There’s one striking problem with assuming a priori that we can use the margin-of-error model in all situations. It is assumed (roughly) that anything that is true in all possibilities within a certain sphere with the subject’s beliefs at the centre is known. This sphere must include the actual situation, or some propositions that are actually false may be true throughout the sphere. Since for propositions concerning non-introspective properties there is no limit to how badly wrong the subject can be, we cannot set any limits a priori to the size of the sphere. So a priori the only margin-of-error model we can safely use is the sceptical model that says the subject knows that p iff p is true in all situations. For introspective properties the margin-of-error can be limited, because it is constitutive of introspective properties that the speakers beliefs about whether they possess these properties are not too far from actuality. So there seems to be no problem with using Williamson’s nice model as long as we restrict our attention to introspective properties.\nIf belief in (29) can be justified a priori, and it is true, does that mean it is knowable a priori? If we want to respect Gettier intuitions, then we must not argue directly that since our belief in (29) is justified, and it is true, then we know it. Still, being justified and true is not irrelevant to being known. I assume here, far from originally, that it is a reasonable presumption that any justified true belief is an item of knowledge. This presumption can be defeated, if the belief is inferred from a false premise, or if the justification would vanish should the subject acquire some evidence she should have acquired, or if there is a very similar situation in which the belief is false, but it is a reasonable presumption. Unless we really are in some sceptical scenario, there is no “defeater” that prevents our belief in (29) being an item of knowledge. We certainly did not infer it from a false premise, there is no evidence we could get that would undermine it, and situations in which it is false are very far from actuality.\nSince there are no such defeaters, it is reasonable to infer we can know (29) a priori. The important premises grounding this inference are an anti-sceptical premise, that we can know (1) on the basis of our current evidence, and the internalist premise that we used several times in the above argument. This completes the argument that the combination of empiricism, internalism and anti-scepticism is untenable.\n\n\n0.4 How Externalism Helps\nIt should be obvious how the rationalist can respond to the above argument - by simply accepting the conclusion. Ultimately I think that’s the best response to this argument. As Hawthorne notes, rationalism is the natural position for fallibilists about knowledge to take, for it is just the view that we can know something a priori even though we could turn out to be wrong. In other words, it’s just fallibilism about a priori knowledge. Since fallibilism about a posteriori knowledge seems true, and there’s little reason to think fallibilism about the a priori would be false if fallibilism about the a posteriori is true, the rationalist’s position is much stronger than many have assumed.19 The inductive sceptic also has an easy response - reject the initial premise that in my current situation I know that it will snow in Ithaca next winter. There are other responses that deserve closer attention: first, the inductive sceptic who is not a universal sceptic, and in particular is not a sceptic about perception, and second the externalist.\n19 As BonJour points out, rationalism has fallen into such disrepute that many authors leave it out even of surveys of the options. This seems unwarranted given the close connection between rationalism and the very plausible thesis of fallibilism.I said at the start that the argument generalises to most kinds of scepticism. One kind of theorist, the inductive sceptic who thinks we can nonetheless acquire knowledge through perception, may think that the argument does not touch the kind of anti-sceptical, internalist, empiricist position she adopts. The kind of theorist I have in mind says that the objects and facts we perceive are constitutive of the evidence we receive. So given we are getting the evidence we are actually getting, these objects must exist and those facts must be true. She says that if I’d started with (30), instead of (1), my argument would have ended up claiming that (31) is bad for some G.\n\nA hand exists.\nA hand exists, or I don’t know that I know that I’m perceiving a hand.\n\nShe then says that (31) is not deeply contingent, since in any situation where the first disjunct is false the second is true, so it cannot be bad. This response is correct as far as it goes, but it does not go far enough to deserve the name anti-sceptical. For it did not matter to the above argument, or to this response that (1) is about the future. All that mattered was that (1) was not entailed by our evidence. So had (1) been a proposition about the present that we cannot directly perceive, such as that it is not snowing in Sydney right now, the rest of the argument would have been unaffected. The summary here is that if one is suitably externalist about perception, so one thinks the existence of perceptual states entail the existence of the things being perceived, one can accept this argument, accept internalism, accept empiricism, and not be an external world sceptic. For it is consistent with such a position that one know the existence of the things one perceives. But on this picture one can know very little beyond that, so for most practical purposes, the position is still a sceptical one.\nThe externalist response is more interesting. Or, to be more precise, the externalist reponses are more interesting. Although I have appealed to internalism a couple of times in the above argument, it might not be so clear how the externalist can respond. Indeed, it may be worried that by exercising a little more care in various places I could have shown that everyone must accept either rationalism or scepticism. That is the conclusion Hawthorne derives in his paper on deeply contingent a priori knowledge, though as noted above he uses somewhat more contentious reasoning than I do in order to get there. To conclude, I will argue that the internalism is crucial to the argument I have presented, and I will spell out how the externalist can get out of the trap I’ve set above.\nOne easy move that’s available to an externalist is to deny that any facts about justification are a priori. That blocks the move that says we can find a G such that it’s a priori that anyone whose evidence is G can know that it will snow in Ithaca next year. This is not an essential feature of externalism. One can be an externalist about justification and still think it is a priori that if one’s evidence has the property is reliably correlated with snow in the near future then it justifies belief that it will shortly snow. But the position that all facts about justification are a posteriori fits well with a certain kind of naturalist attitude, and people with that attitude will find it easy to block the sceptical argument I’ve presented.\nCan, however, we use an argument like mine to argue against an anti-sceptic empiricist externalist who thinks some of the facts about justification can be discovered a priori? The strategy I’ve used to build the argument is fairly transparent: find a disjunctive a priori knowable proposition by partitioning the possible evidence states into a small class, and adding a disjunct for every cell of the partition. In every case, the disjunct that is added is one that is known to be known given that evidence. If one of the items of knowledge is ampliative, if it goes beyond the evidence, then it is possible the disjunction will be deeply contingent. But the disjunction is known no matter what.\nIf internalism is true, then the partition can divide up evidential states according to the introspective properties of the subject. If externalism is true, then such a partition may not be that useful, because we cannot infer much about what the subject is justified in believing from the introspective properties she instantiates. Consider, for example, the above partition of subjects into the G and the not-G, where G is some introspective property, intuitively one somewhat connected with it snowing in Ithaca next year. The subjects that are not-G know that they don’t know they know they are G, because they aren’t. Externalists need not object to this stage of the argument. They can, and should, accept that a margin-of-error model is appropriate for introspective properties. Since it’s part of the nature of introspective properties that we can’t be too badly wrong about which ones we instantiate, we’re guaranteed to satisfy some reliability clause, so there’s no ground there to deny the privileged access principle I defended above.\nThe problem is what to say about the cases where the subject is G. Externalists should say that some such subjects are justified in believing it will snow in Ithaca next winter, and some are not. For simplicity, I’ll call the first group the reliable ones and the others the unreliable ones. If I’m G and reliable, then I’m justified in believing it will snow, and hence in believing (29). But if I’m G and unreliable, then I’m not justified in believing this. Indeed, if I’m G and unreliable, there is no obvious argument that I’m justified in believing either of the disjuncts of (29). Since this is a possible evidential state, externalists should think there is no dominance argument that (29) is a priori knowable.\nCould we solve this by adding another disjunct, one that is guaranteed to be known if I’m G and unreliable? There is no reason to believe we could. If we’re unreliable, there is no guarantee that we will know we are unreliable. Indeed, we may well believe we are reliable. So there’s no proposition we can add to our long disjunction while saying to ourselves, “In the case where the subject is G and unreliable, she can justifiably believe this disjunct.” If the subject is unreliable, she may not have any justified beliefs about the external world. But this is just to say the above recipe for constructing bad propositions breaks down. Externalists should have no fear that anything like this approach could be used to construct a proposition they should find bad. This is obviously not a positive argument that anti-sceptical empiricist externalism is tenable, but it does suggest that such a position is immune to the kind of argument I have presented here.\n\n\n\n\n\n\nReferences\n\nBonJour, Laurence. 1997. In Defense of Pure Reason. Cambridge: Cambridge University Press.\n\n\nChalmers, David. 2006. “Foundations of Two-Dimensional Semantics.” In Two-Dimensional Semantics, edited by Manuel Garcia-Carpintero and Josep Macià, 55–140. Oxford: Oxford University Press.\n\n\nEvans, Gareth. 1979. “Reference and Contingency.” Monist 62: 161–89.\n\n\nFara, Delia Graff. 2002. “An Anti-Epistemicist Consequence of Margin for Error Semantics for Knowledge.” Philosophy and Phenomenological Research 64 (1): 127–42. https://doi.org/10.1111/j.1933-1592.2002.tb00146.x.\n\n\nHawthorne, John. 2002. “Deeply Contingent a Priori Knowledge.” Philosophy and Phenomenological Research 65 (2): 247–69. https://doi.org/10.1111/j.1933-1592.2002.tb00201.x.\n\n\nMcGee, Vann. 1999. “An Airtight Dutch Book.” Analysis 59 (4): 257–65. https://doi.org/10.1093/analys/59.4.257.\n\n\nPryor, James. 2000. “The Sceptic and the Dogmatist.” Noûs 34 (4): 517–49. https://doi.org/10.1111/0029-4624.00277.\n\n\nWilliamson, Timothy. 2000. Knowledge and its Limits. Oxford University Press.\n\n\nYablo, Stephen. 2002. “Coulda, Woulda, Shoulda.” In Conceivability and Possibility, edited by Tamar Szabó Gendler and John Hawthorne, 441–92. Oxford: Oxford University Press."
  },
  {
    "objectID": "posts/sims/are-you-a-sim.html",
    "href": "posts/sims/are-you-a-sim.html",
    "title": "Are You a Sim?",
    "section": "",
    "text": "In Will Wright’s delightful game The Sims, the player controls a neighbourhood full of people, affectionately called sims. The game has no scoring system, or winning conditions. It just allows players to create, and to some extent participate in, an interesting mini-world. Right now the sims have fairly primitive psychologies, but we can imagine this will be improved as the game evolves. The game is very popular now, and it seems plausible that it, and the inevitable imitators, will become even more popular as its psychological engine becomes more realistic. Since each human player creates a neighbourhood with many, many sims in it, in time the number of sims in the world will vastly outstrip the number of humans.\n\nPublished in Philosophical Quarterly 53: 425-431.\nPicture by Elven*Nicky via Creative Commons\n\nLet’s assume that as the sims become more and more complex, they will eventually acquire conscious states much like yours or mine. I do not want to argue for or against this assumption, but it seems plausible enough for discussion purposes. I’ll reserve the term Sim, with a capital S, for a sim that is conscious. By similar reasoning to the above, it seems in time the number of Sims in the world will far outstrip the number of humans, unless humanity either (a) stops existing, or (b) runs into unexpected barriers to computing power or (c) loses interest in these kinds of simulators. I think none of these is likely, so I think that over time the ratio of Sims to humans will far exceed 1:1.\nNick Bostrom (2003) argues that given all that, we should believe that we are probably Sims. Roughly, the argument is that we know that most agents with conscious states somewhat like ours are Sims. And we don’t have any specific evidence that tells on whether we are a Sim or a human. So the credence we each assign to I’m a Sim should equal our best guess as to the percentage of human-like agents that are Sims, which is far above \\(\\frac{1}{2}\\). As Glenn Reynolds put it, “Is it live, or is it Memorex? Statistically, it’s probably Memorex. Er, and so are you, actually.”1 (Is it worrying that we used the assumption that we are human to generate this statistical argument? Not necessarily; if we are Sims then the Sims:humans ratio is probably even higher, so what we know is a lower bound on the proportion of human-like agents that are Sims.) Less roughly, the argument appeals crucially to the following principle:\n1 Link. Reynolds’s comment wasn’t directly about Bostrom, but it bore the ancestral of the relation refers to Bostrom’s paper.\n(#)\n\nCr(Sim  fSim = x) = x\n\n\nHere Cr is a rational credence function. I will adopt David Lewis’s theory of de se belief, and assume that the credence function is defined over properties, rather than propositions Lewis (1979). Whenever I use a term that normally stands for a proposition inside the scope of Cr, it stands for the property of being in a world where that proposition is true. So fSim = x stands for the property of being in a world where 100x% of the human-like agents are Sims.\nAs Bostrom notes, the main reason for believing (#) is that it is an instance of a plausible general principle, which I’ll call (##).\n\n(##)\n\n\\({\\forall}{\\Phi}\\): Cr(\\({\\Phi}\\)  f\\({\\Phi}\\) = x) = x\n\n\nBostrom does not formulate this more general principle, but it is clear that he intends something like it to be behind his argument, for many of the defences of (#) involve substituting some other property in place of Sim in statements like (#). So I will focus here on whether anything like (##) is plausibly true, and whether it supports (#). There are many ways we could interpret (##), depending on whether we take Cr to be a rational agent’s current credences, or in some sense the prior credences before they are affected by some particular evidence, and on whether we take the quantifier to be restricted or unrestricted. Five particular interpretations stand out as being worth considering. None of these, however, provides much reason to believe (#), at least on the reading Bostrom wants to give it. In that reading (#) the credence function represents the current credences of an agent much like you or me. If (#) isn’t interpreted that way, it can’t play the dialectical role Bostrom wants it to play. On two of the interpretations, (##) is false, on two others it may be true but clearly does not entail (#), and on the fifth it only entails (#) if we make an auxiliary assumption which is far from obviously true.\nFor ease of exposition, I will assume that Cr describes in some way the credences at some time of a particular rational human-like agent, Rat, who is much like you or me, except that she is perfectly rational.\n\n0.1 First Interpretation\nCr in (##) measures Rat’s current credences, and the quantifier in (##) is unrestricted. On this interpretation, (##) is clearly false, as Bostrom notes. Rat may well know that the proportion of human-like agents that are like spaghetti westerns is rather low, while rationally being quite confident that she likes spaghetti westerns. For any property \\({\\Phi}\\) where Rat has some particular information about whether he is one of the \\({\\Phi}\\)s or not, that information, and not general facts about the proportion of human-like agents that are \\({\\Phi}\\), can (indeed should) guide Rat’s credences. So those substitution instances of (##) are false.\n\n\n0.2 Second Interpretation\nJust like the first interpretation, except that we restrict the quantifier range so that it only ranges over properties such that Rat does not know whether she possesses them. This interpretation seems to be hinted at by Bostrom when he says, “the bland indifference principle expressed by (#) prescribes indifference only between hypotheses about which observer you are, when you have no information about which of these observers you are.” Even given this restriction, (##) is still false, as the following example shows.\nAssume that Rat knows that fSim &gt; 0.9, which Bostrom clearly takes to be consistent with rationality. And assume also that Rat, being a normal human-like agent, knows some fairly specific, and fairly distinctive facts about her conscious life. If Rat is anything like you or me, she will have experiences that he can be fairly sure are unique to her. Last night, for instance, while Rat was listening to Go-Betweens bootlegs, watching baseball, drinking beer, rocking in his rocking chair and thinking about Bostrom’s simulation argument, she stubbed her toe in a moderately, but not excessively, painful way. Few people will have done all these things at once, and none in quite that way. Let C be the property of ever having had an experience almost just like that. Rat knows he is a C. She is very confident, though not certain, that she is the only human-like C. Let a suman be the property of being C and human, or not-C and a Sim. For much of the paper we’re going to be concerned with the following two properties.\n\n\\(x\\) is a suman =df \\(x\\) is a human \\(C\\) or a Sim who is not a \\(C\\).\n\\(x\\) is a him =df \\(x\\) is a Sim \\(C\\) or a human who is not a \\(C\\).\n\nWe are following Bostrom in assuming that Rat does not know whether she is a Sim so she does not know whether she is a suman. But given that almost no one is C, it follows that fsuman \\({\\approx}\\) fSim. Hence fsuman &gt; 0.85, for if it is less than fSim, it is not much less. But if Cr(a suman) &gt; 0.85, and Cr(Sim) &gt; 0.9, and Rat is coherent, it follows that Cr(C) &lt; 0.25. But we assumed that Rat knew that she was a C, and however knowledge and credence are to be connected, it is inconceivable that one could know something while one’s credence in it is less than \\(\\frac{1}{4}\\). Hence it must be false that Cr(C) &lt; \\(\\frac{1}{4}\\), but we inferred that from given facts about the story and (##), as interpreted here. Hence (##), as interpreted here, is false.\n\n\n0.3 Third Interpretation\nOne natural response ot the previous objection is that there shoul dbe some way of restricting (##) so that it does not apply to properties like being a suman. Intuitively, the response is that even though Rat doesn’t know whether she is a suman, she knows something that is relevant to whether she is a suman, namely that she is a \\(C\\). The problem with this response is that any formal restriction on (##) that implements this intuition ends up giving us a version so weak that it doesn’t entail (#).\nThe idea is that what went wrong in the previous case is that even though Rat does not know whether she is a suman, she knows something relevant to this. In particular, she knows that if she is a suman, she is one of the sumans that is human, rather than one of the ones that is a Sim. Our third interpretation avoids the difficulties this raises by restricting the quantifier in (##) even further. Say that a property \\({\\Phi}\\) is in the domain of the quantifier iff (a) Rat does not know whether she is \\({\\Phi}\\), and (b) there is no more specific property \\({\\Phi}\\)\\(^\\prime\\) such that Rat knows that if she is \\({\\Phi}\\), then she is \\({\\Phi}\\)\\(^\\prime\\).2 This will rule out the applicability of (##) to properties like a suman. Unfortunately, it will also rule out the applicability of (##) to properties like being a Sim. For Rat knows that if she is a Sim, then she is a Sim that is also a C. So now (##) doesn’t entail (#).\n2 I think it is this interpretation of (##) that Adam Elga implicitly appeals to in his solution to the Sleeping Beauty problem Elga (2000).This kind of problem will arise for any attempt to put a purely formal restriction on (##). The problem is that, as Goodman noted in a quite different context (Goodman 1955), there is no formal distinction between the ‘normal’ properties, being a human and being a sim, and the ‘deviant’ properties, being a suman and being a him. The following four biconditionals are all conceptual truths, and hence must all receive credence 1.\nIf the obvious truth of (1a) implies that Rat cannot apply (##) to the property o being a suman once she knows that she is a \\(C\\), for (1a) makes that evidence look clrarly relevant to the issue of whether she is suman, then similar reasoning suggests that the obvious truth of (2a) implies that Rat cannot apply (##) to the properties of being a human once she knows that she is a \\(C\\), for (2a) makes that evidence look clearly relevant to the issue of whether she is human. The point is that a restriction on (##) that is to deliver (#) must fine some epistemologically salient distinction between the property of being human and the property of being suman if it is to rule out one application of (##) without ruling out the other, and if we only consider formal constraints, we won’t find such a restriction. Our final attempt to justify (#) from something like (##) attempts to avoid this problem by appealing directly to the nature of Rat’s evidence.\n\n\n0.4 Fourth Interpretation\nThe problems with the three interpretations of (##) so far have been that they applied after Rat found out something distinctive about herself, that she was a C. Perhaps (##) is really a constraint on prior credence functions. A priori, Rat’s credences should be governed by an unrestricted version of (##). We then have the following argument for (#). (As noted above, (#) is a constraint on current credences, so it is not immediately entailed by a constraint on prior credences such as (##) under its current interpretation.)\n\nP1\n\nA priori, Rat’s conditional credence in her being a Sim given that fSim is x is x.\n\nP2\n\nAll of Rat’s evidence is probabilistically independent of the property of being a Sim.\n\nC\n\nRat’s current conditional credence in her being a Sim given that fSim is x is x.\n\n\nThis interpretation may be reasonably faithful to what Bostrom had in mind. The argument just sketched looks similar enough to what he hints at in the following quote: “More generally, if we knew that a fraction x of all observers with human-type experiences live in simulations, and we don’t have any information that indicate that our own particular experiences are any more or less likely than other human-type experiences to have been implemented in vivo rather than in machina, then our credence that we are in a simulation should equal x.” So it’s not unreasonable to conclude that he is committed to P2, and intends it to be used in the argument that you should give high credence to being a Sim.3 Further, this version of (##), where it is restricted to prior credences, does not look unreasonable. So if P2 is true, an argument for (#) might just succeed. So the issue now is just whether P2 is true.\n3 Jamie Dreier pointed out to me that what Bostrom says here is slightly more complicated than what I, hopefully charitably, attribute to him. A literal reading of Bostrom’s passage suggests he intends the following principle.\n  \\({\\forall}\\)e: Cr(e  Human) - Cr(e  Sim) = Cr(e  Human) - Cr(e  Sim)      (B)\nThe quantifier here ranges over possible experiences e, e is the actual experience Rat has, and Cr is the credence function at the ‘time’ when Rat merely knows that he is human-like and fSim is greater than 0.9. I suggested a simpler assumption:\n  Cr(Human  e) = Cr(Sim  e)            (I)\nBostrom needs something a little stronger than (I) to get his desired conclusion, for he needs this to hold not just for Rat’s experience e, but for your experience and mine as well. But we will not press that point. Given that point, though, (I) is all he needs. And presumably the reason he adopts (B) is because it looks like it entails (I). And indeed it does entail (I) given some fairly innocuous background assumptions.Why might we reject P2? Any of the following three reasons might do. First, Rat’s evidence might be constituted by more than her conscious phenomenal states. This reply has an externalist and an internalist version. On the externalist version, Rat’s perceptual evidence is constituted in part by the objects she is perceiving. Just as seeing a dagger and hallucinating a dagger provide different evidence, so does seeing a dagger and sim-seeing a sim-dagger. For reasns Williamson notes, a Sim may not know that she has different evidence to someone seeing a dagger when she sim-sees a sim-dagger, but that does not imply that she does not have different evidence unless one also assumes, implausibly, that agents know exactly what their evidence is Williamson (2000). On the internalist version, our evidence is constituted by our sensory irritations, just as Quine said it is (Quine 1973). If Rat’s evidence includes the fact that her eyes are being irritated thus-and-so, his credence conditional on that that she is human should be 1, for if she were a Sim she could not have this evidence because she would not have eyes. She may, depending on the kind of Sim she is, have sim-eyes, but sim-eyes are not eyes. So Bostrom needs an argument that evidence supervenes on conscious experiences, and he doesn’t clearly have one. This is not to say that no such argument could exist. For example, Laurence BonJour provides some intriguing grounds for thinking that our fundamental evidence does consist in certain kinds of conscious states, namely occurrent beliefs (BonJour 1999), but we’re a long way from knowing that the supervenience claims holds. And if the supervenience claim does not hold, then even if Sims and humans have the same kind of experiences, they may not have the same kind of evidence. And if that is true, it is open to us to hold that Rat’s non-experiential evidence entails that she is not a Sim (as both Williamson and Quine suggest), so her evidence will not be independent of the question of whether she is a Sim.\nSecondly, even if every one of Rat’s experiences is probabilistically independent of the hypothesis that she is a Sim, that doesn’t give us a sufficient reason to believe that her total evidence is so independent. Just because e1 and e2 are both probabilistically independent of H, the conjunction e1 \\({\\wedge}\\) e2 might not be independent of H. So possibly our reasons for accepting P2 involve a tacit scope confusion.4\n4 Thanks to Jamie Dreier for reminding me of this point.Finally, we might wonder just why we’d even think that Rat’s evidence is probabilistically independent of the hypothesis that she is human. To be sure, her evidence does not entail that she is human. But that cannot be enough to show that it is probabilistically independent. For the evidence also does not entail that she is suman. And if P2 is true, then the evidence must have quite a bit of bearing on whether she is suman. For Rat’s prior credence in being suman is above 0.9 but apparently her posterior credence in it should be below 0.15. So the mere fact that the evidence does not entail that she is human cannot show that it is probabilistically independent of her being human, for the same reasoning would show it is probabilistically independent of his being suman.\nMore generally, we still need a distinction here between the property of being human and the property of being suman that shows why ordinary evidence should be independent of the first property but not the second. One might think the distinction can reside in the fact that being human is a natural property, while being suman is gruesome. The lesson of Goodman’s riddle of induction is that we have to give a privileged position in our epistemic framework to natural properties like being human, and this explains the distinction. This response gets the status of privileged and gruesome properties back-to-front. The real lesson of Goodman’s riddle is that credences in hypotheses involving natural properties should be distinctively sensitive to new evidence. Our evidence should make us quite confident that all emeralds are green, while giving us little reason to think that all emeralds are grue. What P2 says is that a rather natural hypothesis, that Rat is human, is insensitive to all the evidence Rat has, while a rather gruesome hypothesis, that Rat is suman, is sensitive to this evidence. The riddle of induction gives us no reason to believe that should happen.\nIt seems, though this is a little speculative, that the only reason for accepting P2 involves a simple fallacy. It is true that we have no reason to think that some evidence, say C, is more or less likely given that Rat is human rather than a Sim. But from this we should not conclude that we have a reason to think it is not more or less likely given that Rat is human rather than a Sim, which is what P2 requires. Indeed, drawing this kind of conclusion will quickly lead to a contradiction, for we can use the same ‘reasoning’ to conclude that we have a reason to think her evidence is not more or less likely given that Rat is a suman rather than a him.\n\n\n0.5 Conclusion\nNothing I have said here implies that Rat should have a high credence in her being human. But it does make one argument that she should not have a high credence in this look rather tenuous. Further, it is quite plausible that if there is no good reason not to give high credence to a hypothesis, then it is rationally permissible to give it such a high credence. It may not be rationally mandatory to give it such a high credence, but it is permissible. If Rat is very confident that she is human, even while knowing that most human-like beings are Sims, she has not violated any norms of reasoning, and hence is not thereby irrational. In that respect she is a bit like you and me.\n\n\n\n\n\n\nReferences\n\nBonJour, Laurence. 1999. “Foundationalism and the External World.” Philosophical Perspectives 13: 229–49. https://doi.org/10.1111/0029-4624.33.s13.11.\n\n\nBostrom, Nick. 2003. “Are You Living in a Computer Simulation?” The Philosophical Quarterly 53 (211): 243–55. https://doi.org/10.1111/1467-9213.00309.\n\n\nElga, Adam. 2000. “Self-Locating Belief and the Sleeping Beauty Problem.” Analysis 60 (2): 143–47. https://doi.org/10.1093/analys/60.2.143.\n\n\nGoodman, Nelson. 1955. Fact, Fiction and Forecast. Cambridge: Harvard University Press.\n\n\nLewis, David. 1979. “Attitudes de Dicto and de Se.” Philosophical Review 88 (4): 513–43. https://doi.org/10.2307/2184646.\n\n\nQuine, W. V. O. 1973. The Roots of Reference. La Salle: Open Court.\n\n\nWilliamson, Timothy. 2000. “Scepticism and Evidence.” Philosophy and Phenomenological Research 60 (3): 613–28. https://doi.org/10.2307/2653819."
  },
  {
    "objectID": "posts/conprob/from-classical-to-intuitionistic-probability.html",
    "href": "posts/conprob/from-classical-to-intuitionistic-probability.html",
    "title": "From Classical to Intuitionistic Probability",
    "section": "",
    "text": "0.1 Introduction\nIt is a standard claim of modern Bayesian epistemology that reasonable epistemic states should be representable by probability functions. There have been a number of authors who have opposed this claim. For example, it has been claimed that epistemic states should be representable by Zadeh’s fuzzy sets, Dempster and Shafer’s evidence functions, Shackle’s potential surprise functions, Cohen’s inductive probabilities or Schmeidler’s non-additive probabilities.1 A major motivation of these theorists has been that in cases where we have little or no evidence for or against \\(p\\), it should be reasonable to have low degrees of belief in each of \\(p\\) and \\({\\lnot}\\)\\(p\\), something apparently incompatible with the Bayesian approach. There are two broad types of response to this situation, the second of which shows the incompatibility just mentioned is more apparent than real. The first of these – much in evidence in the work of the writers just cited – is to replace or radically reconstrue the notion of probability taken by that approach to represent degrees of belief. The second – to be defended here – seeks to maintain the core of standard probability theory but to generalize the notion of a probability function to accommodate variation in the background logic of the account; this allows us to respond to such issues as the low degree of belief in a proposition and its negation by simply weakening the background logic from classical to intuitionistic logic. Thus if Bayesianism is construed as in our opening sentence, one way to respond to the objections of the heterodox writers listed above is to trade in classical Bayesianism for intuitionistic Bayesianism. Since for many theorists at least the motivation for their opposition to Bayesianism is grounded in either verificationism or anti-realism, a move to a intuitionistic theory of probability seems appropriate. Indeed, as Harman (1983) notes, the standard analysis of degrees of belief as dispositions to bet leads naturally to a intuitionistic theory of probability. We give a Dutch Book argument in defence of constructive Bayesianism in Section 4 below.\n1 For more details, see Zadeh (1978), Dempster (1967), Shafer (1976), Shackle (1949), Cohen (1977), Schmeidler (1989).\nPublished in Notre Dame Journal of Philosophical Logic 44: 111-123.\nThanks to Alan Hájek, Graham Oppy and, especially, Lloyd Humberstone for comments and suggestions on various drafts of this paper.\n\nThe appropriate generalization of the notion of a probability function makes explicit allowance for a sensitivity to the background logic. The latter we identify with a consequence relation, such as, in particular, the consequence relation \\(\\vdash_{CL}\\) associated with classical logic or the consequence relation \\(\\vdash_{IL}\\) associated with intuitionistic logic. To keep things general, we assume only that the languages under discussion have two binary connectives: \\({\\vee}\\) and \\({\\wedge}\\). No assumptions are made about how a consequence relation on such a language treats compounds formed using these connectives, though of course in the cases in which we are especially interested, \\(\\vdash_{CL}\\) and \\(\\vdash_{IL}\\), such compounds have the expected logical properties. We take the language of these two consequences relations to be the same, assuming in particular that negation (\\({\\lnot}\\)) is present for both. Finally, if \\(A\\) belongs to the language of a consequence relation \\(\\vdash\\), then we say that \\(A\\) is a \\(\\vdash\\)-thesis of \\(\\vdash\\) \\(A\\) and that \\(A\\) is a \\(\\vdash\\)-antithesis if for all \\(B\\) in that language \\(A\\) \\(\\vdash\\) \\(B\\). (Thus the \\(\\vdash\\)-theses and antitheses represent the logical truths and logical falsehoods as seen from the perspective of \\(\\vdash\\).) We are now in a position to give the key definition.\nIf \\(\\vdash\\) is a consequence relation, then a function Pr mapping the language of \\(\\vdash\\) to the real interval [0,1] is a \\(\\vdash\\)-probability function if and only if the following conditions are satisfied:\n\n(P0)\n\nPr(\\(A\\)) = 0 if \\(A\\) is a \\(\\vdash\\)-antithesis.\n\n(P1)\n\nPr(\\(A\\)) = 1 if \\(A\\) is a \\(\\vdash\\)-thesis\n\n(P2)\n\nIf \\(A\\) \\(\\vdash\\) \\(B\\) then Pr(\\(A\\)) \\({\\leq}\\) Pr(\\(B\\))\n\n(P3)\n\nPr(\\(A\\)) + Pr(\\(B\\)) = Pr(\\(A\\) \\({\\vee}\\) \\(B\\)) + Pr(\\(A\\) \\({\\wedge}\\) \\(B\\))\n\n\nIf \\(\\vdash\\) is \\(\\vdash_{CL}\\), then we call a \\(\\vdash\\)-probability function a classical probability function; if \\(\\vdash\\) is \\(\\vdash_{IL}\\) we call a \\(\\vdash\\)-probability function an intuitionistic probability function. The position described above as constructive Bayesianism would replace classical probability functions by intuitionistic probability functions as candidate representations of reasonable epistemic states. Note that classical probability functions in this sense are exactly those obeying the standard probability calculus axioms. In paricular, the familiar negation axiom dictating that Pr(\\({\\lnot}\\)\\(A\\)) = 1 – Pr(\\(A\\)) emerges as a by-product of the interaction between the general (i.e., logic-independent) condition (P3) and, via (P0) and (P1), the logic-specific facts that \\(A\\) \\({\\wedge}\\) \\({\\lnot}\\)\\(A\\) is a \\(\\vdash_{CL}\\)-antithesis and \\(A\\) \\({\\vee}\\) \\({\\lnot}\\)\\(A\\) is a \\(\\vdash_{CL}\\)-thesis for any \\(A\\).\nAlthough it is these two kinds – intuitionistic and classical – of probability functions we shall be dealing with specifically in what follows, we emphasize the generality of the above definition of a \\(\\vdash\\)-probability function, and invite the reader to consider what effect further varying the choice of \\(\\vdash\\) has on the behaviour of such functions. Our attention will be on the comparative merits of \\(\\vdash_{CL}\\) and \\(\\vdash_{IL}\\) in this regard. (It may have occurred to the reader in connection with (P3) above that we might naturally have considered a generalized version of (P3) for ‘countable additivity’. Whether such a condition ought be adopted will turn on some rather difficult questions concerning the use of infinities in constructive reasoning; let us leave it as a question for further research. We have stated (P3) in its finitary form so as not to require that intuitionistic probability functions satisfy the more contentious general condition.)\nIn the following section we shall review some of the motivations for intuitionistic Bayesianism. The arguments are rather piecemeal; they are designed to show that given the philosophical commitments various writers in the field have expressed they would be better off taking this route, i.e., focussing on the class of intuitionistic probability functions, than – as many of them have suggested –abandoning Bayesianism in our broad sense. In particular, we shall urge that moves in the latter direction which involve abandoning (what we shall call) the Principle of Addition are seriously undermotivated.\nOne aspect of the Bayesian perspective which we have not considered concerns the dynamics rather than the statics of epistemic states: in particular the idea that changes in such states are governed for rational agents by the principle of conditionalizing on new information. This requires that we have a dyadic functor available for expressing conditional probabilities. Accordingly, where Pr is for some consequence relation \\(\\vdash\\) a \\(\\vdash\\)-probability function, we favour the standard account and take the associated conditional \\(\\vdash\\)-probability function Pr( , ) to be given by Pr(\\(A\\),\\(B\\)) = Pr(\\(A\\) \\({\\wedge}\\) \\(B\\))/Pr(\\(B\\)) when Pr(\\(B\\)) \\({\\neq}\\) 0, with Pr(\\(A\\),\\(B\\)) undefined when Pr(\\(B\\)) = 0. The intention, of course, is that Pr(\\(A\\),\\(B\\)) represents the conditional probability of \\(A\\) given \\(B\\). We defer further consideration of conditional probability until the Appendix.\n\n\n0.2 Motivating Intuitionistic Bayesianism\nThere are four main reasons for grounding preferring intuitionistic over classical probability functions as representing the range of reasonable epistemic states. These are: (1) a commitment to verificationism, (2) a commitment to anti-realism, (3) preservation of the principle of Addition, and (4) avoidance of direct arguments for the orthodox approach. Now some of these will be viewed by some people as bad reasons for adopting the given position, a reaction with which it is not hard to sympathise. In particular, the verificationist and anti-realist elements of the theory might well be viewed as negatives. These arguments are principally directed at showing that by their own lights, various opponents of classical Bayesianism would do better to adopt the intuitionistic Bayesian position than some still more heterodox non-Bayesian account.\n2.1 A standard objection to classical Bayesianism is that it has no way of representing complete uncertainty. Because of the failures of Laplace’s principle of indifference, it can’t be said that uncertainty about \\(p\\) is best represented by assigning credence 1/2 to \\(p\\). Heterodox approaches usually allow the assignment of credence 0 to both \\(p\\) and \\({\\lnot}\\)\\(p\\) when an agent has no evidence at all as to whether or not \\(p\\) is true. Because these approaches generally require an agent to assign credence 1 to classical tautologies, including \\(p\\) \\({\\vee}\\) \\({\\lnot}\\)\\(p\\), these theories must give up the following Principle of Addition.\n\nAddition\n\nFor incompatible \\(A\\), \\(B\\): Bel(\\(A\\) \\({\\vee}\\) \\(B\\)) = Bel(\\(A\\)) + Bel(\\(B\\)).\n\n\n“Bel(\\(A\\))” is here used to mean the degree of belief the agent has in \\(A\\), and “incompatible” to apply to \\(A\\) and \\(B\\) in which for some favoured consequence relation \\(\\vdash\\), the conjunction of \\(A\\) with \\(B\\) is a \\(\\vdash\\)-antithesis. Such conditions as Addition are of course taken not as descriptive theories about all agents, since irrational agents would serve as counterexamples. Rather, they are proposed coherence constraints on all rational agents.\nThe Principle of Addition is stated in terms of degrees of belief, or credences. Where no ambiguity results we also use the same term to refer to the corresponding principle applied to \\(\\vdash\\)-probability functions, with incompatibility understood in terms of \\(\\vdash\\) (as just explained). Now in some writings (particularly Shafer’s) the reason suggested for giving up Addition is openly verificationist. Shafer says that when an agent has no evidence for \\(p\\), they should assign degree of belief 0 to \\(p\\). Degrees of belief, under this approach, must be proportional to evidence.2 In recent philosophical literature, this kind of verificationism is often accompanied by an insistence that validity of arguments be judged by the lights of \\(\\vdash_{IL}\\) rather than \\(\\vdash_{CL}\\).\n2 This assumption was shared by many of the participants in the symposium on probability in legal reasoning, reported in the Boston University Law Review 66 (1986).A similar line of thought is to be found in Harman (1983). He notes that when we don’t distinguish between the truth conditions for a sentence and its assertibility conditions, the appropriate logic is intuitionistic. And when we’re considering gambles, something like this is correct. When betting on \\(p\\) we don’t, in general, care if \\(p\\) is true as opposed to whether it will be discovered that \\(p\\) is true. A \\(p\\)-bet, where \\(p\\) asserts the occurrence of some event for instance, becomes a winning bet, not when that event occurs, but when \\(p\\) becomes assertible. So perhaps not just verificationists like Shafer, but all those who analyse degrees of belief as propensity to bet should adopt constructivist approaches to probability.\nTo see the point Harman is making, consider this example. We are invited to quote for \\(p\\)-bets and \\({\\lnot}\\)\\(p\\)-bets, where \\(p\\) is O. J. Simpson murdered his wife. If we are to take the Californian legal system literally, the probability of that given the evidence is strictly between one-half and one. To avoid one objection, these bets don’t just pay $1 if the bettor guesses correctly. Rather they pay $1 invested at market rates of interest at the time the bet is placed. The idea is that if we pay x cents for the bet now, when it is discovered that we have bet correctly we will receive a sum of money that is worth exactly as much as $1 now. Still, we claim, it might be worthwhile to quote less than 50 cents for each of the bets. Even if we will receive $1 worth of reward if we wager correctly, there is every possibility that we’ll never find out. So it might be that placing a bet would be a losing play either way. To allow for this, the sum of our quotes for the \\(p\\)-bet and the \\({\\lnot}\\)\\(p\\)-bet may be less than $1. As Harman points out, to reply by wielding a Dutch Book argument purporting to show that this betting practice is incoherent would be blatantly question-begging. That argument simply assumes that \\(p\\) \\({\\vee}\\) \\({\\lnot}\\)\\(p\\) is a logical truth, which is presumably part of what’s at issue. (In our terminology, this disjunction has the status of a \\(\\vdash_{CL}\\)-thesis which is not a \\(\\vdash_{IL}\\)-thesis.)\nHarman’s point is not to argue for a intuitionistic approach to probability. Rather, he is arguing against using probabilistic semantics for propositional logic. Such an approach he claims would be bound to lead to intuitionistic logic for the reasons given above. He thinks that, since this would be an error, the move to probabilistic semantics is simply misguided. Whatever we think of this conclusion, we can press into service his arguments for intuitionistic Bayesianism.\n2.2 The second argument for this approach turns on the anti-realism of some heterodox theorists. So George Shackle, for example, argues that if we are anti-realists about the future, we will assign positive probability to no future-directed proposition. The following summary is from a sympathetic interpreter of Shackle’s writing.\n\n[T]here is every reason to refuse additivity: [it] implies that the certainty that would be assigned to the set of possibilities should be ‘distributed’ between different events. Now this set of events is undetermined as the future – that exists only in imagination – is. (Ponsonnet 1996, 171)\n\nShackle’s anti-realism is motivated by what most theorists would regard as a philosophical howler: he regards realism about the future as incompatible with human freedom, and holds that human beings are free. The second premise here seems harmless enough, but the first is notoriously difficult to motivate. Nevertheless, there are some better arguments than this for anti-realism about the future. If we adopt these, it isn’t clear why we should ‘assign certainty’ to the set of possibilities.\nShackle is here assuming that for any proposition \\(p\\), even a proposition about the future, \\(p\\) \\({\\vee}\\) \\({\\lnot}\\)\\(p\\) is now true, although neither disjunct is true. Given his interests it seems better to follow Dummett here and say that if we are anti-realists about a subject then for propositions \\(p\\) about that subject, \\(p\\) \\({\\vee}\\) \\({\\lnot}\\)\\(p\\) fails to be true. Hence we have no need to ‘assign certainty to the set of possibilities’. Or perhaps more accurately, assigning certainty to the set of possibilities does not mean assigning probability 1 to \\(p\\) \\({\\vee}\\) \\({\\lnot}\\)\\(p\\); in particular, condition (P1) on \\(\\vdash\\)-probability functions does not require this when we choose \\(\\vdash\\) as \\(\\vdash_{IL}\\).\n2.3 The third motivation for adopting an intuitionistic approach to probability is that it allows us to retain the Kolmogorov axioms for probability, in particular the Principle of Addition. This principle has, to my mind at least, some intuitive motivation. And the counterexamples levelled against it by heterodox theorists seem rather weak from the intuitionistic Bayesian perspective. For they all are cases where we might feel it appropriate to assign a low probability to a proposition and its negation3. Hence if we are committed to saying Pr(\\(A\\) \\({\\vee}\\) \\({\\lnot}\\)\\(A\\)) = 1 for all \\(A\\), we must give up the Principle of Addition. But the intuitionistic Bayesian simply denies that in these cases Pr(\\(A\\) \\({\\vee}\\) \\({\\lnot}\\)\\(A\\)) = 1, so no counterexample to Addition arises. This denial is compatible with condition (P1) on Pr’s being a \\(\\vdash_{IL}\\)-probability function since, as already noted, \\(A\\) \\({\\vee}\\) \\({\\lnot}\\)\\(A\\) is not in general a \\(\\vdash_{IL}\\)-thesis.\n3 Again the discussion in (Shafer 1976 ch. 2) is the most obvious example of this, but similar examples abound in the literature.2.4 The final argument for taking an intuitionistic approach is that it provides a justification for rejecting the positive arguments for classical Bayesianism. These provide a justification for requiring coherent degrees of belief to be representable by the classical probability calculus. There are a dizzying variety of such arguments which link probabilistic epistemology to decision theory, including: the traditional Dutch Book arguments found in Ramsey (1926), Teller (1973) and Lewis (1999); de-pragmatized Dutch Book arguments which rely on consistency of valuations, rather than avoiding actual losses, as in Howson and Urbach (1989), Christensen (1996) and Hellman (1997); and arguments from the plausibility of decision theoretic constraints to constraints on partial beliefs, as in Savage (1954), Maher (1993) and Kaplan (1996). As well as these, there are arguments for classical Bayesianism which do not rely on decision theory in any way, but which flow either directly from the definitions of degrees of belief, or from broader epistemological considerations. A summary of traditional arguments of this kind is in Paris (1994). Joyce (1998) provides an interesting modern variation on this theme.\nAll such arguments assume classical – rather than, say, intuitionistic – reasoning is appropriate. The intuitionist has a simple and principled reason for rejecting those arguments. The theorist who endorses \\(\\vdash_{CL}\\) when considering questions of inference, presumably lacks any such simple reason. And they need one, unless they think it appropriate to endorse one position knowing there is an unrefuted argument for an incompatible viewpoint.\nWe are not insisting that non-Bayesians will be unable to refute these arguments while holding on to \\(\\vdash_{CL}\\). We are merely suggesting that the task will be Herculean. A start on this project is made by Shafer (1981), which suggests some reasons for breaking the link between probabilistic epistemology and decision theory. Even if these responses are successful, such a response is completely ineffective against arguments which do not exploit such a link. As we think these are the strongest arguments for classical Bayesianism, non-Baeyesians have much work left to do. And it is possible that this task cannot be completed. That is, it is possible that the only questionable step in some of these arguments for classical Bayesianism is their use of non-constructive reasoning. If this is so only theorists who give up \\(\\vdash_{CL}\\) can respond to such arguments.\nIn sum, non-Bayesians need to be able to respond to the wide variety of arguments for Bayesianism. Non-Bayesians who hold on to \\(\\vdash_{CL}\\) must do so without questioning the implicit logical assumptions of such arguments. Given this restriction, producing these responses will be a slow, time-consuming task, the responses will in all likelihood be piecemeal, providing little sense of the underlying flaw of the arguments, and for some arguments it is possible that no effective response can be made. Intuitionistic Bayesians have a quick, systematic and, we think, effective response to all these arguments.\n\n\n0.3 More on Intuitionistic Probability Functions\nHaving explained the motivation for intuitionistic Bayesianism, let us turn our attention in greater detail to its main source of novelty: the intuitionistic probability functions. We concentrate on logical matters here, in the following section justifying the singling out of this class of probability functions by showing that an epistemic state represented by Bel is invulnerable to a kind of Dutch Book if and only if Bel is an intuitionistic probability function.\nFor the case of specifically classical probability functions, the conditions (P0)–(P4) of Section 1 involve substantial redundancy. For example, we could replace (P2) and (P3) by – what would in isolation be weaker conditions – (P2\\(^\\prime\\)) and (P3\\(^\\prime\\)).\n\n(P2\\(^\\prime\\))\n\nIf \\(A\\) \\(\\dashv\\) \\(\\vdash\\) \\(B\\) then Pr(\\(A\\)) = Pr(\\(B\\))\n\n(P3\\(^\\prime\\))\n\nIf \\(\\vdash\\) \\({\\lnot}\\)(A \\({\\wedge}\\) B) then Pr(\\(A\\) \\({\\vee}\\) \\(B\\)) = Pr(\\(A\\)) + Pr(\\(B\\))\n\n\nHowever, in the general case of arbitrary \\(\\vdash\\)-probability functions (or rather: those for which \\({\\lnot}\\) is amongst the connectives of the language of \\(\\vdash\\)), such a replacement would result in a genuine weakening, as we may see from a consideration of the class of \\(\\vdash_{IL}\\)-probability functions. While both (P2\\(^\\prime\\)) and (P3\\(^\\prime\\)) are satisfied for \\(\\vdash\\) as \\(\\vdash_{IL}\\), the class of functions Pr satisfying (P0), (P1), (P2\\(^\\prime\\)) and (P3\\(^\\prime\\)) is broader (for this choice of \\(\\vdash\\)) than the class of intuitionistic probability functions. To see this, first note that the function P, defined immediately below, satisfies (P0), (P1), (P2) and (P3\\(^\\prime\\)), but not (P3).\n\\[P(A) =\n\\begin{cases}\n1 \\text{ if } p \\vee q~ \\vdash_{IL}~ A \\\\\n0 \\text{ otherwise}\n\\end{cases}\\]\n(Here \\(p\\) and q are a pair of atomic sentences.) To see that (P3\\(^\\prime\\)) is satisfied, assume P(\\(A\\) \\({\\vee}\\) \\(B\\)) = 1 and \\(\\vdash_{IL}\\) \\({\\lnot}\\)(A \\({\\wedge}\\) \\(B\\)). Then \\(p\\) \\({\\vee}\\) q \\(\\vdash_{IL}\\) \\(A\\) \\({\\vee}\\) \\(B\\), and \\(B\\) \\(\\vdash_{IL}\\) \\({\\lnot}\\)\\(A\\). Hence \\(p\\) \\({\\vee}\\) q \\(\\vdash_{IL}\\) \\(A\\) \\({\\vee}\\) \\({\\lnot}\\)\\(A\\), but this only holds if either (1) \\(p\\) \\({\\vee}\\) q \\(\\vdash_{IL}\\) \\(A\\) or (2) \\(p\\) \\({\\vee}\\) q \\(\\vdash_{IL}\\) \\({\\lnot}\\)\\(A\\). (For if \\(p\\) \\({\\vee}\\) q \\(\\vdash_{IL}\\) \\(A\\) \\({\\vee}\\) \\({\\lnot}\\)\\(A\\), then \\(p\\) \\(\\vdash_{IL}\\) \\(A\\) \\({\\vee}\\) \\({\\lnot}\\)\\(A\\) and q \\(\\vdash_{IL}\\) \\(A\\) \\({\\vee}\\) \\({\\lnot}\\)\\(A\\), whence by a generalization, due to Harrop, of the Disjunction Property for intuitionistic logic, either \\(p\\) \\(\\vdash_{IL}\\) \\(A\\) or \\(p\\) \\(\\vdash_{IL}\\) \\({\\lnot}\\)\\(A\\) and similarly either q \\(\\vdash_{IL}\\) \\(A\\) or q \\(\\vdash_{IL}\\) \\({\\lnot}\\)\\(A\\). Thus one of the following four combinations obtains: (a) \\(p\\) \\(\\vdash_{IL}\\) A and q \\(\\vdash_{IL}\\) \\(A\\), (b) \\(p\\) \\(\\vdash_{IL}\\) \\(A\\) and q \\(\\vdash_{IL}\\) \\({\\lnot}\\)\\(A\\), (c) \\(p\\) \\(\\vdash_{IL}\\) \\({\\lnot}\\)\\(A\\) and q \\(\\vdash_{IL}\\) \\(A\\), (d) \\(p\\) \\(\\vdash_{IL}\\) \\({\\lnot}\\)\\(A\\) and q \\(\\vdash_{IL}\\) \\({\\lnot}\\)\\(A\\). But cases (b) and (c) can be ruled out since they would make \\(p\\) and q \\(\\vdash_{IL}\\)-incompatible, contradicting their status as atomic sentences, and from (a) and (d), (1) and (2) follow respectively.) If (1) first holds then P(\\(A\\)) = 1, as required. If (2) holds then \\(p\\) \\({\\vee}\\) q \\(\\vdash_{IL}\\) (\\(A\\) \\({\\vee}\\) \\(B\\)) \\({\\wedge}\\) \\({\\lnot}\\)\\(A\\) and (\\(A\\) \\({\\vee}\\) \\(B\\)) \\({\\wedge}\\) \\({\\lnot}\\)\\(A\\) \\(\\vdash_{IL}\\) \\(B\\), so P(\\(B\\)) = 1. The other cases are trivial to verify and are left to the reader.\nTo see (P2) is needed (for the current choice of \\(\\vdash\\)), as opposed to just (P2\\(^\\prime\\)), consider the following Kripke tree.\nWe introduce a “weighting” function w by setting w(1) = 0.2, w(2) = 0.3, w(3) = -0.1 and w(4) = 0.6. For any \\(A\\), let P(\\(A\\)) = \\({\\Sigma}\\)w(i), where the summation is across all points i that force \\(A\\). So P(\\(p\\)) = 0.6 and P(\\({\\lnot}{\\lnot}\\)\\(p\\)) = 0.5, contradicting (P2). But (P0), (P1), (P2\\(^\\prime\\)) and (P3) are all satisfied, showing that (P2) is in the general case not derivable from these three conditions.\n\n\n0.4 Bets and Intuitionistic Probability Functions\nSay that an \\(A\\)-bet is a bet that pays $1 if \\(A\\) and nothing otherwise. These will sometimes be called bets on \\(A\\). In this theory, as in real life, it is possible that neither \\(A\\)-bets nor \\({\\lnot}\\)\\(A\\)-bets will ever be collected, so holding an \\(A\\)-bet and a \\({\\lnot}\\)\\(A\\)-bet is not necessarily as good as holding $1. An \\(A\\)-bet becomes a winning bet, i.e. worth $1, just when it becomes known that \\(A\\). We will assume that bookmakers and punters are both logically proficient and honest, so that when a \\(B\\)-bet becomes a winning bet and \\(B\\) \\(\\vdash_{IL}\\) \\(A\\), then an \\(A\\)-bet is a winning bet. The picture underlying this story is the Kripke tree semantics for intuitionistic logic. Bettors are thought of as being at some node of a Kripke tree, an \\(A\\)-bet wins at that stage iff \\(A\\) is forced by that node. Bettors do not know that any future nodes will be reached, so they cannot be confident that all bets on classical tautologies (\\(\\vdash_{CL}\\)-theses) will be winning. And more importantly, we take it that an (\\(A\\) \\({\\vee}\\) \\(B\\))-bet wins if and only if an \\(A\\)-bet wins or a \\(B\\)-bet wins. Again this mirrors the fact that \\(A\\) \\({\\vee}\\) \\(B\\) is forced at a node iff \\(A\\) is forced or \\(B\\) is forced.\nFinally, to get the Dutch Book style argument going, assume that for any sequence of bets on \\(A\\)1, \\(A\\)2, ..., \\(A\\)k, the bettor values the sequence at $(Bel(\\(A\\)1) + Bel(\\(A\\)2) + ... + Bel(\\(A\\)k)). This is obviously unrealistic and economically suspect4, but is perhaps a useful analogy. Then Bel leads to coherent valuations in all circumstances iff Bel is a intuitionistic probability function. That is, if Bel is not an intuitionistic probability function (henceforth: IPF) then there will be two finite sequences of bets S1 and S2 such that S1 is guaranteed to pay at least as much as S2 in all circumstances, but S2 is given higher value by the agent. For simplicity Bel will be called incoherent if this happens, and coherent otherwise. If Bel is an IPF there are no two such sequences, so it is coherent.\n4 It is economically suspect because, in simplified terms, Bel(\\(A\\)) gives at best the use-value of an \\(A\\)-bet, but this is distinct from the exchange-value the agent places on the bet. And it is the exchange-value that determines her patterns of buying and selling.If Bel is not an IPF then we just need to look at which axiom is breached in order to construct the sequences. For example, if (P3) is breached then let the sequences be \\(\\langle\\)\\(A\\), \\(B\\)\\(\\rangle\\) and \\(\\langle\\)\\(A\\) \\({\\vee}\\) \\(B\\), A \\({\\wedge}\\) \\(B\\)\\(\\rangle\\). The same number of propositions from each sequence are forced at every node of every Kripke tree, so the coherence requirement is that the two sequences receive the same value. But ex hypothesi they do not, so Bel is incoherent. Similar proofs suffice for the remaining axioms (the remaining conditions on \\(\\vdash\\)-probability functions, that is, as they apply in the special case of \\(\\vdash\\) = \\(\\vdash_{IL}\\)).\nTo show that if Bel is an IPF it is coherent, we need some more notation. Let \\(\\langle\\)\\(A\\)1, ..., \\(A\\)k\\(\\rangle\\) be a sequence of propositions. Then say cn, k is the proposition true iff at least n of these are true. So c2,3 is the proposition (\\(A\\)1 \\({\\wedge}\\) \\(A\\)2) \\({\\vee}\\) (\\(A\\)1 \\({\\wedge}\\) \\(A\\)3) \\({\\vee}\\) (\\(A\\)2 \\({\\wedge}\\) \\(A\\)3). Assuming Bel is a IPF, we prove the following lemma holds for all k:\nThe proof is by induction on k. For k=1 and k=2, the proof is given by the axioms. So it remains only to complete the inductive step. For ease of reading in the proof we write \\(A\\) for Bel(\\(A\\)) where no ambiguity would result.\nBy the inductive hypothesis we have:\nSince \\(c_{i,k} \\vee A_{k+1}\\) \\(\\dashv\\) \\(\\vdash\\) \\(c_{i,k+1} \\vee A_{k+1}\\) and \\(c_{i,k} \\wedge A_{k+1}\\) \\(\\dashv\\) \\(\\vdash\\) \\(c_{i+1,k+1} \\wedge A_{k+1}\\) we have:\nNow, \\(c_{1,k+1} \\vee~ A_{k+1}\\) \\(\\dashv\\) \\(\\vdash\\) \\(c_{i,k+1}\\) and \\(c_{k+1,k+1} ~\\wedge~ A_{k+1}\\) \\(\\dashv\\) \\(\\vdash\\) \\(c_{k+1,k+1}\\) from the definitions of \\(c\\). So substituting in these equivalences and slightly renumbering, we get:\nRegrouping the last two summations and applying (P3),\nAnd cancelling out the second term on each side gives us the result we want. From this it follows immediately that Bel is coherent. Let S1 and S2 be any two sequences such that S1 is guaranteed to pay as much as S2. That is, that S2 pays $n entails S1 pays at least $n for all n. Now the lemma shows that for each sequence of bets, their value equals the sum of the probability that they’ll pay at least n for all values of n, up to the length of the sequence. So by as many appeals to (P2) as there are bets in S1, we have that the value of S2 is less than or equal to the value of S1, as required.\nGiven the well-known problems with Dutch Book arguments5, it might be wondered if we can give a different justification for the axioms. Indeed it may be considered helpful to have a semantics for the logic which does not refer to betting practices. One possibility is to say that IPFs are normalised measures on Kripke trees. The idea is that the probability of a proposition is the measure of the set of points at which the proposition is forced. It is straightforward to give a non-constructive proof that the axioms are sound with respect to these semantics, but making this proof constructive and providing any proof that the axioms are complete is a harder task. So for now this Dutch Book justification for the axioms is the best available.\n5 See Maher (1993) for criticisms of the most recent attempts at successful Dutch Book arguments and references to criticisms of earlier attempts.\n\nAppendix: The Morgan–Leblanc–Mares Calculus\nIn a series of papers ((Morgan and LeBlanc 1983a, 1983b), Morgan and Mares (1995)) an approach to probability grounded in intuitionistic logic has been developed. The motivation is as follows. A machine contains an unknown set of propositions S, which need not be consistent. Pr(\\(A\\), \\(B\\)) is the maximal price we’d pay for a bet that S and \\(B\\) intuitionistically entail A (S, A \\(\\vdash_{IL}\\) B, that is). By standard Dutch Book arguments, we obtain axioms for a probability calculus which has some claim to being constructivist. The point of this section is to register the shortcomings of this approach as a theory of uncertain reasoning from evidence – to point out, that is, the implausibility of interpreting the axioms they derive as normative constraints on degrees of belief. (It should be noted from the start that this was not the advertised purpose of their theory, and at least one of the authors (Mares) has said (p.c.) that the primary purpose of constructing these theories was to generalise of the triviality results proved in Lewis (1976). So the purpose of this appendix may be to argue for something that isn’t in dispute: that these theories can’t be pushed into double duty as theories of reasoning under uncertainty.)\nThe axiomatisations given in the Morgan and Leblanc papers differs a little from that given in the Morgan and Mares paper, but the criticisms levelled here apply to their common elements. In particular, the following four axioms are in both sets.\n\n(C1)\n\n0 \\({\\leq}\\) Pr(\\(A\\), \\(B\\)) \\({\\leq}\\) 1\n\n(C2)\n\nPr(\\(A\\), \\(A\\) \\({\\wedge}\\) \\(B\\)) = 1\n\n(C3)\n\nPr(\\(A\\), \\(B\\) \\({\\wedge}\\) C)  Pr(\\(B\\), C) = Pr(\\(B\\), \\(A\\) \\({\\wedge}\\) C)  Pr(\\(A\\), C)\n\n(C4)\n\nPr(\\(A\\) \\({\\supset}\\) \\(B\\), C) = Pr(\\(B\\), \\(A\\) \\({\\wedge}\\) C)\n\n\nThese four are enough to get both the unwanted consequences. In particular, from these we get the ‘no negative evidence’ rule: Pr(\\(A\\), \\(B\\) \\({\\wedge}\\) C) \\({\\geq}\\) Pr(\\(A\\), \\(B\\)). The proof is in Morgan and Mares (1995) Now given the semantic interpretation they have adopted, this is perhaps not so bad. After all, if we can prove \\(A\\) from \\(B\\) and S, we can certainly prove it from \\(B\\) \\({\\wedge}\\) C and S, but the converse does not hold. However from our perspective this feature seems a little implausible. In particular, if C is \\({\\lnot}\\)\\(A\\), it seems we should have Pr(\\(A\\), \\(B\\) \\({\\wedge}\\) \\({\\lnot}\\)\\(A\\)) = 0 unless \\(B\\) \\(\\vdash_{IL}\\) \\(A\\), in which case Pr(\\(A\\), \\(B\\) \\({\\wedge}\\) \\({\\lnot}\\)\\(A\\)) is undefined.\nIt shouldn’t be that surprising that we get odd results given (C4). Lewis (1976) shows that adopting it for a (primitive or defined) connective ‘\\({\\rightarrow}\\)’ within the classical probability calculus leads to triviality. And neither the arguments he uses there nor the arguments for some stronger conclusions in Lewis (1999) rely heavily on classical principles. The papers by Morgan and Leblanc don’t discuss this threat, but it is taken discussed in detail in Morgan and Mares (1995). Morgan and Mares note that it’s possible to build a theory based on (C1) to (C4) that isn’t trivial in the sense Lewis described. But these theories still have enough surprising features that they aren’t suitable for use as a theory of reasoning under uncertainty.\nIn intuitionistic logic we often take the falsum \\({\\perp}\\) as a primitive connective, functioning as a \\(\\vdash_{IL}\\)-antithesis. Hence a set S is intuitionistically consistent iff we do not have S \\(\\vdash_{IL}\\) \\({\\perp}\\). Now the following seems a plausible condition:\n\n(C\\({\\perp}\\))\n\nFor consistent \\(B\\), Pr(\\({\\perp}\\), \\(B\\)) = 0.\n\n\nGiven consistent evidence, we have no evidence at all that the falsum is true. Hence we should set the probability of the falsum to 0 (as required by our condition (P0) from Section 1). Given Morgan and Leblanc’s original semantic interpretation there is less motivation for adopting (C\\({\\perp}\\)), since S might be inconsistent. The restriction to consistent \\(B\\) in (C\\({\\perp}\\)) is imposed because we take Pr(\\(A\\), \\(B\\)) to be undefined for inconsistent \\(B\\), as explained at the end of Section 1. (In more detail: if \\(B\\) is a \\(\\vdash_{IL}\\)-antithesis then Pr(\\(B\\)) = 0 for any intuitionistic probability function Pr, whence the undefinedness of Pr(\\(A\\), \\(B\\)) by the remarks at the end of that section.) Morgan, Leblanc and Mares take it to be set at 1. The choice here is a little arbitrary, the only decisive factor being apparently the easier statement of certain results. Now if we take the falsum as a primitive the next move is usually to introduce \\({\\lnot}\\) as a defined connective, as follows.\n\\({\\lnot}\\)\\(A\\) =df \\(A\\) \\({\\supset}\\) \\({\\perp}\\)\nAssuming \\(A\\) \\({\\wedge}\\) B is consistent, it follows from (C4) and (C\\({\\perp}\\)) that Pr(\\({\\lnot}\\)\\(A\\), \\(B\\)) = 0. Again, from our perspective this is an implausible result. The main purpose of this appendix has been to show that the Morgan–Leblanc–Mares probability calculus cannot do the work Bayesians want a probability calculus to do. That is, it is implausible to regard their Pr(\\(A\\), \\(B\\)) as the reasonable degree of belief in \\(A\\) given \\(B\\). Hence the account of conditional probability these authors offer diverges from the intuitionistic Bayesianism that we have been urging heterodox theorists to endorse.\n\n\n\n\n\n\nReferences\n\nChristensen, David. 1996. “Dutch-Book Arguments De-Pragmatized: Epistemic Consistency for Partial Believers.” Journal of Philosophy 93 (9): 450–79. https://doi.org/10.2307/2940893.\n\n\nCohen, L. Jonathan. 1977. The Probable and the Provable. Oxford: Clarendon Press.\n\n\nDempster, Arthur. 1967. “Upper and Lower Probabilities Induced by a Multi-Valued Mapping.” Annals of Mathematical Statistics 38: 325–39. https://doi.org/10.1214/aoms/1177698950.\n\n\nHarman, Gilbert. 1983. “Problems with Probabilistic Semantics.” In Developments in Semantics, edited by Alex Orenstein and Rafael Stern, 243–37. New York: Haven.\n\n\nHellman, Geoffery. 1997. “Bayes and Beyond.” Philosophy of Science 64 (2): 191–221. https://doi.org/10.1086/392548.\n\n\nHowson, Colin, and Peter Urbach. 1989. Scientific Reasoning. La Salle: Open Court.\n\n\nJoyce, James M. 1998. “A Non-Pragmatic Vindication of Probabilism.” Philosophy of Science 65 (4): 575–603. https://doi.org/10.1086/392661.\n\n\nKaplan, Mark. 1996. Decision Theory as Philosophy. Cambridge: Cambridge University Press.\n\n\nLewis, David. 1976. “Probabilities of Conditionals and Conditional Probabilities.” Philosophical Review 85 (3): 297–315. https://doi.org/10.2307/2184045.\n\n\n———. 1999. “Why Conditionalize?” In Papers in Metaphysics and Epistemology, 403–7. Cambridge University Press.\n\n\nMaher, Patrick. 1993. Betting on Theories. Cambridge: Cambridge University Press.\n\n\nMorgan, Charles, and Hughes LeBlanc. 1983a. “Probabilistic Semantics for Intuitionistic Logic.” Notre Dame Journal of Formal Logic 24 (2): 161–80. https://doi.org/10.1305/ndjfl/1093870307.\n\n\n———. 1983b. “Probability Theory, Intuitionism, Semantics and the Dutch Book Argument.” Notre Dame Journal of Formal Logic 24 (3): 289–304. https://doi.org/10.1305/ndjfl/1093870372.\n\n\nMorgan, Charles, and Edward Mares. 1995. “Conditionals, Probability and Non-Triviality.” Journal of Philosophical Logic 24 (5): 455–67. https://doi.org/10.1007/bf01052599.\n\n\nParis, J. B. 1994. The Uncertain Reasoner’s Companion: A Mathematical Perspective. Cambridge: Cambridge University Press.\n\n\nPonsonnet, Jean-Marc. 1996. “The Best and the Worst in g. L. S. Shackle’s Decision Theory.” In Uncertainty in Economic Thought, edited by Christian Schmidt, 169–96. Cheltham: Edward Elgar.\n\n\nRamsey, Frank. 1926. “Truth and Probability.” In Philosophical Papers, edited by D. H. Mellor, 52–94. Cambridge: Cambridge University Press.\n\n\nSavage, Leonard. 1954. The Foundations of Statistics. New York: John Wiley.\n\n\nSchmeidler, David. 1989. “Subjective Probability and Expected Utility Without Additivity.” Econometrica 57 (3): 571–89. https://doi.org/10.2307/1911053.\n\n\nShackle, George. 1949. Expectation in Economics. Cambridge: Cambridge University Press.\n\n\nShafer, Glenn. 1976. A Mathematical Theory of Evidence. Princeton: Princeton University Press.\n\n\n———. 1981. “Constructive Probability.” Synthese 48 (1): 1–60. https://doi.org/10.1007/bf01064627.\n\n\nTeller, Paul. 1973. “Conditionalization and Observation.” Synthese 26 (2): 218–58. https://doi.org/10.1007/bf00873264.\n\n\nZadeh, Lofti A. 1978. “Fuzzy Sets as a Basis for a Theory of Probability.” Fuzzy Sets and Systems 1 (1): 3–28. https://doi.org/10.1016/0165-0114(78)90029-5."
  },
  {
    "objectID": "posts/mfp/index.html",
    "href": "posts/mfp/index.html",
    "title": "Morality, Fiction and Possibility",
    "section": "",
    "text": "1 Four Puzzles\nSeveral things go wrong in the following story.\n\nPublished in Philosophers’ Imprint 4:3.\n\n\nDeath on a Freeway\nJack and Jill were arguing again. This was not in itself unusual, but this time they were standing in the fast lane of I-95 having their argument. This was causing traffic to bank up a bit. It wasn’t significantly worse than normally happened around Providence, not that you could have told that from the reactions of passing motorists. They were convinced that Jack and Jill, and not the volume of traffic, were the primary causes of the slowdown. They all forgot how bad traffic normally is along there. When Craig saw that the cause of the bankup had been Jack and Jill, he took his gun out of the glovebox and shot them. People then started driving over their bodies, and while the new speed hump caused some people to slow down a bit, mostly traffic returned to its normal speed. So Craig did the right thing, because Jack and Jill should have taken their argument somewhere else where they wouldn’t get in anyone’s way.\n\n\nPicture via Creative Commons.\n\nThe last sentence raises a few related puzzles. Intuitively, it is not true, even in the story, that Craig’s murder was morally justified. What the narrator tells us here is just false. That should be a little surprising. We’re being told a story, after all, so the storyteller should be an authority on what’s true in it. Here we hearers get to rule on which moral claims are true and false, not the author. But usually the author gets to say what’s what. The action takes place in Providence, on Highway 95, just because the author says so. And we don’t reject those claims in the story just because no such murder has ever taken place on Highway 95. False claims can generally be true in stories. Normally, the author’s say so is enough to make it so, at least in the story, even if what is said is really false. The first puzzle, the alethic puzzle, is why authorial authority breaks down in cases like Death on the Freeway. Why can’t the author just make sentences like the last sentence in Death true in the story by saying they are true? At this stage I won’t try and give a more precise characterisation of which features of Death lead to the break down of authorial authority, for that will be at issue below.\n\nI’ve spoken to practically everyone I know about the issues here, and a full list of thanks for useful advice, suggestions, recommendations, criticisms, counterexamples and encouragement would double the size of the paper. If I thank philosophy departments rather than all the individuals in them it might cut the size a little, so thanks to the departments at Brown, UC Davis, Melbourne, MIT and Monash. Thanks also to Kendall Walton, Tamar Gendler and two referees for Philosophers’ Imprint. The most useful assistance came from Wolfgang Schwarz and especially Tyler Doggett, without whose advice this could never have been written, and to George Wilson, who prevented me from (keeping on) making a serious error of over-generalisation.\n\nThe second puzzle concerns the relation between fiction and imagination. Following Kendall Walton (1990), it is common to construe fictional works as invitations to imagine. The author requests, or suggests, that we imagine a certain world. In Death we can follow along with the author for most of the story. We can imagine an argument taking place in peak hour on Highway 95. We can imagine this frustrating the other drivers. And we can imagine one of those drivers retaliating with a loaded gun. What we cannot, or at least do not, imagine is that this retaliation is morally justified. There is a limit to our imaginative ability here. We refuse, fairly systematically, to play along with the author here. Call this the imaginative puzzle. Why don’t we play along in cases like Death? Again, I won’t say for now which cases are like Death.\nThe third puzzle concerns the phenomenology of Death and stories like it. The final sentence is striking, jarring in a way that the earlier sentences are not. Presumably this is closely related to the earlier puzzles, though I’ll argue below that the cases that generate this peculiar reaction are not identical with cases that generate alethic or imaginative puzzles. So call this the phenomenological puzzle.\nFinally, there is a puzzle that David Hume (1757) first noticed. Hume suggested that artistic works that include morally deviant claims, moral claims that wouldn’t be true were the descriptive aspects of the story true, are thereby aesthetically compromised. Why is this so? Call that the aesthetic puzzle. I will have nothing to say about that puzzle here, though hopefully what I have to say about the other puzzles will assist in solving it.\nI’m going to call sentences that raise the first three puzzles puzzling sentences. Eventually I’ll look at the small differences between those three puzzles, but for now we’ll focus on what they have in common. The puzzles, especially the imaginative puzzle, have become quite a focus of debate in recent years. The aesthetic puzzle is raised by David Hume (1757), and is discussed by Kendall Walton (1994) and Richard Moran (1995). Walton and Moran also discuss the imaginative and alethic puzzles, and they are the focus of attention in recent work by Tamar Szabó Gendler (2000), Gregory Currie (2002) and Stephen Yablo (2002). My solution to the puzzles is best thought of as a development of some of Walton’s ‘sketchy story’ (to use his description). Gendler suggests one way to develop Walton’s views, and shows it leads to an unacceptable solution, because it leads to mistaken predictions. I will argue that there are more modest developments of Walton’s views that don’t lead to so many predictions, and in particular don’t lead to mistaken predictions, but which still say enough to solve the puzzles.\n\n\n2 The Range of the Puzzles\nAs Walton and Yablo note, the puzzle does not only arise in connection with thin moral concepts. But it has not been appreciated how widespread the puzzle is, and getting a sense of this helps us narrow the range of possible solutions.\nSentences in stories attributing thick moral concepts can be puzzling. If my prose retelling of Macbeth included the line “Then the cowardly Macduff called on the brave Macbeth to fight him face to face,” the reader would not accept that in the story Macduff was a coward. If my retelling of Hamlet frequently described the young prince as decisive, the reader would struggle to go along with me imaginatively. Try imagining Hamlet doing exactly what he does, and saying exactly what he says, and thinking what he thinks, but always decisively. For an actual example, it’s easy to find the first line in Bob Dylan’s Ballad of Frankie Lee and Judas Priest, that the titular characters ‘were the best of friends’ puzzling in the context of how Frankie Lee treats Judas Priest later in the song. It isn’t too surprising that the puzzle extends to the thick moral concepts, and Walton at least doesn’t even regard these as a separate category.\nMore interestingly, any kind of evaluative sentence can be puzzling. Walton and Yablo both discuss sentences attributing aesthetic properties. (Yablo 2002, 485) suggests that a story in which the author talks about the sublime beauty of a monster truck rally, while complaining about the lack of aesthetic value in sunsets, is in most respects like our morally deviant story. The salient aesthetic claims will be puzzling. Note that we are able to imagine a community that prefers the sight of a ‘blood bath death match of doom’ (to use Yablo’s evocative description) to sunsets over Sydney Harbour and it could certainly be true in a fiction that such attitudes were commonplace. But that does not imply that those people could be right in thinking the trucks are more beautiful. (Walton 1994, 43–44) notes that sentences describing jokes that are actually unfunny as being funny will be puzzling. We get to decide what is funny, not the author.\nWalton and Yablo’s point here can be extended to epistemic evaluations. Again it isn’t too hard to find puzzling examples when we look at attributions of rationality or irrationality.\n\nAlien Robbery\nSam saw his friend Lee Remnick rushing out of a bank carrying in one hand a large bag with money falling out of the top and in the other hand a sawn-off shotgun. Lee Remnick recognised Sam across the street and waved with her gun hand, which frightened Sam a little. Sam was a little shocked to see Lee do this, because despite a few childish pranks involving stolen cars, she’d been fairly law abiding. So Sam decided that it wasn’t Lee, but really a shape-shifting alien that looked like Lee, that robbed the bank. Although shape-shifting aliens didn’t exist, and until that moment Sam had no evidence that they did, this was a rational belief. False, but rational.\n\nThe last two sentences of Alien Robbery are fairly clearly puzzling.\nSo far all of our examples have involved normative concepts, so one might think the solution to the puzzle will have something to do with the distinctive nature of normative concepts, or with their distinctive role in fiction. Indeed, Gendler’s and Currie’s solutions have just this feature. But sentences that seem somewhat removed from the realm of the normative can still be puzzling. (It is of course contentious just where the normative/non-normative barrier lies. Most of the following cases will be regarded as involving normative concepts by at least some philosophers. But I think few people will hold that all of the following cases involve normative concepts.)\nAttributions of mental states can, in principle, be puzzling. If I retell Romeo and Juliet, and in this say ‘Although he believed he loved Juliet, and acted as if he did, Romeo did not really love Juliet, and actually wanted to humiliate her by getting her to betray her family’, that would I think be puzzling. This example is odd, because it is not obviously impossible that Romeo could fail to love Juliet even though he thought he loved her (people are mistaken about this kind of thing all the time) and acted as if he did (especially if he was trying to trick her). But given the full detail of the story, it is impossible to imagine that Romeo thought he had the attitudes towards Juliet he is traditionally thought to have, and he is mistaken about this.\nAttributions of content, either mental content or linguistic content, can be just as puzzling. The second and third sentences in this story are impossible to imagine, and false even in the story.\n\nCats and Dogs\nRhodisland is much like a part of the actual world, but with a surprising difference. Although they use the word ‘cat’ in all the circumstances when we would (i.e. when they want to say something about cats), and the word ‘dog’ in all the circumstances we would, in their language ‘cat’ means dog and ‘dog’ means cat. None of the Rhodislanders are aware of this, so they frequently say false things when asked about cats and dogs. Indeed, no one has ever known that their words had this meaning, and they would probably investigate just how this came to be in some detail, if they knew it were true.\n\nA similar story can be told to demonstrate how claims about mental content can be puzzling. Perhaps these cases still involve the normative. Loving might be thought to entail special obligations and Kripke (1982) has argued that content is normative. But we are clearly moving away from the moral, narrowly construed.\nStephen Yablo recently suggested that certain shape predicates generate imaginative resistance. These predicates are meant to be special categories of a broader category that we’ll discuss further below. Here’s Yablo’s example.\n\nGame Over\nThey flopped down beneath the giant maple. One more item to find, and yet the game seemed lost. Hang on, Sally said. It’s staring us in the face. This is a maple tree we’re under. She grabbed a five-fingered leaf. Here was the oval they needed! They ran off to claim their prize. (Yablo 2002, 485, title added)\n\nThere’s a potential complication in this story in that one might think that it’s metaphysically impossible that maple trees have ovular leaves. That’s not what is meant to be resisted, and I don’t think is resisted. What is resisted is that maple leaves have their distinctive five-fingered look, that the shape of the leaf Sally collects is like that (imagine I demonstrate a maple leaf here) and that its shape be an oval.\nFewer people may care about the next class of cases, or have clear intuitions about them, but if one has firm ontological beliefs, then deviant ontological claims can be puzzling. I’m a universalist about mereology, at least with respect to ordinary concrete things, so I find many of the claims in this story puzzling.\n\nWiggins’ World\nThe Hogwarts Express was a very special train. It had no parts at all. Although you’d be tempted to say that it had carriages, an engine, seats, wheels, windows and so on, it really was a mereological atom. And it certainly had no temporal parts - it wholly was wherever and whenever it was. Even more surprisingly, it did not enter into fusions, so when the Hogwarts Local was linked to it for the first few miles out of Kings Cross, there was no one object that carried all the students through north London.\n\nI think that even in fictions any two concrete objects have a fusion. So the Hogwarts Express and the Hogwarts Local have a fusion, and when it is a connected object it is commonly called a train. I know how to describe a situation where they have no fusion (I did so just above) but I have no idea how to imagine it, or make it true in a story.\nMore generally, there are all sorts of puzzling sentences involving claims about constitution. These I think are the best guide to a solution to the puzzle.\n\nA Quixotic Victory\n–What think you of my redecorating Sancho?\n–It’s rather sparse, said Sancho.\n–Sparse. Indeed it is sparse. Just a television and an armchair.\n–Where are they, Señor Quixote? asked Sancho. All I see are a knife and fork on the floor, about six feet from each other. A sparse apartment for a sparse mind. He said the last sentence under his breath so Quixote would not hear him.\n–They might look like a knife and fork, but they are a television and an armchair, replied Quixote.\n–They look just like the knife and fork I have in my pocket, said Sancho, and he moved as to put his knife and fork besides the objects on Quixote’s floor.\n–Please don’t do that, said Quixote, for I may be unable to tell your knife and fork from my television and armchair.\n–But if you can’t tell them apart from a knife and fork, how could they be a television and an armchair?\n–Do you really think being a television is an observational property? asked Quixote with a grin.\n–Maybe not. OK then, how do you change the channels? asked Sancho.\n–There’s a remote.\n–Where? Is it that floorboard?\n–No, it’s at the repair shop, admitted Quixote.\n–I give up, said Sancho.\n\nSancho was right to give up. Despite their odd appearance, Quixote’s items of furniture really were a television and an armchair. This was the first time in months Quixote had won an argument with Sancho.\n\nQuixote is quite right that whether something is a television is not determined entirely by how it looks. A television could be indistinguishable from a non-television. Nonetheless, something indistinguishable from a knife is not a television. Not in this world, and not in the world of Victory either, whatever the author says. For whether something is a television is determined at least in part by how it looks, and while it is impossible to provide a non-circular constraint on how a television may look, it may not look like a common knife.\nIn general, if whether or not something is an F is determined in part by ‘lower-level’ features, such as the shape and organisation of its parts, and the story specifies that the lower-level features are incompatible with the object being an F, it is not an F in the fiction. Suitably generalised and qualified, I think this is the explanation of all of the above categories. To understand better what the generalisations and qualifications must be, we need to look at some cases that aren’t like Death, and some alternative explanations of what is going on in Death.\nSentences that are intentional errors on the part of storytellers are not puzzling in our sense. We will use real examples for the next few pages, starting with the opening line of Joyce’s most famous short story.\n\nThe Dead\nLily, the caretaker’s daughter, was literally run off her feet.\n(Joyce 1914/2000, 138)\n\nIt isn’t true that Lily is literally run off her feet. She is run off her feet by the incoming guests, and if you asked her she may well say she was literally run off her feet, but this would reveal as much about her lack of linguistic care as about her demanding routine. Is this a case where the author loses authority over what’s true in the story? No, we are not meant to read the sentence as being true in the story, but being a faithful report of what Lily (in the story) might say to herself. In practice it’s incredibly difficult to tell just when the author intends a sentence to be true in the story, as opposed to being a report of some character’s view of what is true. (See Holton (1997) for an illustration of the complications this can cause.) But since we are operating in theory here, we will assume that problem solved. The alethic puzzle only arises when it is clear that the author intends that p is true in her story, but we think p is not true. The imaginative puzzle only arises when the author invites us to imagine p, but we can not, or at least do not. Since Joyce does not intend this sentence to be true in The Dead, nor invites us to imagine it being true, neither puzzle arises. What happens to the phenomenological puzzle in cases like these is a little more interesting, and I’ll return to that in .\nJust as intentional errors are not puzzling, careless errors are not puzzling. Writing a full length novel is a perilous business. Things can go wrong. Words can be miswritten, mistyped or misprinted at several different stages. Sometimes the errors are easily detectable, sometimes they are not, especially when they concern names. In one of the drafts of Ulysses, Joyce managed to write “Connolly Norman” in place of “Conolly Norman”. Had that draft being used for the canonical printing of the work, it would be tempting to say that we had another alethic puzzle. For the character named here is clearly the Superintendent of the Richmond District Lunatic Asylum, and his name had no double-‘n’, so in the story there is no double-‘n’ either.1\n1 For details on the spelling of Dr Norman’s name, and the story behind it, see Kidd (1988). The good doctor appears on page 6 of Joyce (1922/1993).2 At least, they will be ignored if it is clear they are errors. If there seems to be a method behind the misspellings, as in Ulysses there frequently is, the matter is somewhat different, and somewhat more difficult.\nTyler Doggett has argued that these cases are more similar to paradigm cases of imaginative resistance than I take them to be. Indeed, I would not have noticed the problems they raise without reading his paper. It may be a shortcoming of my theory here that I have to set questions about whether these sentences are puzzling to one side and assume an ideal proof-reader.Here we do have an instance where what is true in the story differs from the what is written in the text. But this is not a particularly interesting deviation. To avoid arcane discussions of typographical errors, we will that in every case we possess an ideal version of the text, and are comparing it with the author’s intentions. Slip-ups that would be detected by a careful proof-reader, whether they reveal an unintended divergence between word and world, as here, or between various parts of the text, as would happen if Dr Norman were not named after a real person but had his name spelled differently in parts of the text, will be ignored.2\nNote two ways in which the puzzles as I have stated them are narrower than they first appear. First, I am only considering puzzles that arise from a particular sentence in the story, intentionally presented in the voice of an authoritative narrator. We could try and generalise, asking why it is that we sometimes (but not always) question the moral claims that are intended to be tacit in a work of fiction. For instance, we might hold that for some Shakespearean plays there are moral propositions that Shakespeare intended to be true in the play, but which are not in fact true. Such cases are interesting, but to keep the problem of manageable proportions I won’t explicitly discuss them here. (I believe the solution I offer here generalises to those cases, but I won’t defend that claim here.) Second, all the stories I have discussed are either paragraph-long examples, or relatively detachable parts of longer stories. For all I’ve said so far, the puzzle may be restricted to such cases. In particular, it might be the case that a suitably talented author could make it true in a story that killing people for holding up traffic is morally praiseworthy, or that a television is phenomenally and functionally indistinguishable from a knife. What we’ve seen so far is just that an author cannot make these things true in a story simply by saying they are true.3 I leave open the question of whether a more subtle approach could make those things true in a fiction. Similarly, I leave it open whether a more detailed invitation to imagine that these things are true would be accepted. All we have seen so far is that simple direct invitations to imagine these things are rejected, and it feels like we could not accept them.\n3 Thanks here to George Wilson for reminding me that we haven’t shown anything stronger than that.\n\n3 An Impossible Solution\nHere’s a natural solution to the puzzles, one that you may have been waiting for me to discuss. The alethic puzzle arises because only propositions that are possibly true can be true in a story, or can be imagined. The latter claim rests on the hypothesis that we can imagine only what is possible, and that we resist imagining what is impossible.\nThis solution assumes that it is impossible that killing people for holding up freeway traffic is the right thing to do. Given enough background assumptions, that is plausible. It is plausible, that is, that the moral facts supervene on the non-moral facts. And the supervenience principle here is quite a strong one - in every possible world where the descriptive facts are thus and so, the moral facts are the same way.4 If we assume the relevant concept of impossibility is truth in no possible worlds, we get the nice result that the moral claims at the core of the problem could not possibly be true.\n4 Arguably the relevant supervenience principle is even stronger than that. To use some terminology of Stephen Yablo’s, there’s no difference in moral facts without a difference in non-moral facts between any two counteractual worlds, as well as between any two counterfactual worlds. This might be connected to some claims I will make below about the relationship between the normative and the descriptive.Several authors have discussed solutions around this area. Kendall Walton (1994) can easily be read as endorsing this solution, though Walton’s discussion is rather tentative. Tamar Szabó Gendler rejects the theory, but thinks it is the most natural idea, and spends much of her paper arguing against this solution. As those authors, and Gregory Currie (2002), note, the solution needs to be tidied up a little before it will work for the phenomenological and imaginative puzzles. (It is less clear whether the tidying matters to the alethic puzzle.) For one thing, there is no felt asymmetry between a story containing, “Alex proved the twin primes theorem,” and one containing, “Alex found the largest pair of twin primes,” even though one of them is impossible. Since we don’t know which it is, the impossibility of the false one cannot help us here. So the theory must be that it is believed impossibilities that matter, for determining what we can imagine, not just any old impossibilities. Presumably impossibilities that are not salient will also not prevent imagination.\nEven thus qualified, the solution still overgenerates, as Gendler noted. There are stories that are not puzzling in any way that contain known salient impossibilities. Gendler suggests three kinds of cases of this kind, of which I think only the third clearly works. The first kind of case is where we have direct contradictions true in the story. Gendler suggests that her Tower of Goldbach story, where seven plus five both does and does not equal twelve, is not puzzling. Graham Priest (1997) makes a similar point with a story, Sylvan’s Box, involving an empty box with a small statue in one corner. These are clear cases of known, salient impossibility, but arguably are not puzzling in any respect. (There is a distinction between the puzzles though. It is very plausible to say that it’s true in Priest’s story that there’s an empty box with a small statue in one corner. It is less plausible to say we really can imagine such a situation.) Opinion about such cases tends to be fairly sharply divided, and it is not good I suspect to rest too much weight on them one way or the other.\nThe second kind of case Gendler suggests is where we have a distinctively metaphysical impossibility, such as a singing snowman or a talking playing card. Similar cases as discussed by Alex Byrne (1993) who takes them to raise problems for David Lewis’s (1978) subjunctive conditionals account of truth in fiction. If we believe a strong enough kind of essentialism, then these will be impossible, but they clearly do not generate puzzling stories. For a quick proof of this, note that Alice in Wonderland is not puzzling, but several essentialist theses are violated there. It is true in Alice in Wonderland, for example, that playing cards plant rose trees.\nBut these examples don’t strike me as particularly convincing either. For one thing, the essentialism assumed here may be wrong. For another, the essentialism might not be both salient and believed to be right, which is what is needed. And most importantly, we can easily reinterpret what the authors are saying in order to be make the story possibly true. We can assume, for example, that the rosebush planting playing cards are not playing cards as we know them, but roughly human-shaped beings with playing cards for torsos. Gendler and Byrne each say that this is to misinterpret the author, but I’m not sure this is true. As some evidence, note that the authorised illustrations in Alice tend to support the reinterpretations.5\n5 Determining whether this is true in all such stories would be an enormous task, I fear, and somewhat pointless given the next objection. If anyone wants to say all clearly impossible statements in fiction are puzzling, I suspect the best strategy is to divide and conquer. The most blatantly impossible claims are most naturally fit for reinterpretation, and the other claims rest on an essentialism that is arguably not proven. I won’t try such a massive defence of a false theory here.Gendler’s third case is better. There are science fiction stories, especially time travel stories, that are clearly impossible but which do not generate resistance. Here’s two such stories, the first lightly modified from a surprisingly popular movie, and the second lifted straight from a very popular source.\n\nBack to the Future\\(^\\prime\\)\nMarty McFly unintentionally travelled back in time to escape some marauding Libyan terrorists. In doing so he prevented the chance meeting which had, in the timeline that had been, caused his father and mother to start dating. Without that event, his mother saw no reason to date the unattractive, boring nerdy kid who had been, in a history that no longer is, Marty’s father. So Marty never came into existence. This was really a neat trick on Marty’s part, though he was of course no longer around to appreciate it. Some people manage to remove themselves from the future of the world by foolish actions involving cars. Marty managed to remove himself from the past as well.\nThe Restaurant at the End of the Universe\nThe Restaurant at the End of the Universe is one of the most extraordinary ventures in the entire history of catering.\nIt is built on the fragmented remains of an eventually ruined planet which is enclosed in a vast time bubble and projected forward in time to the precise moment of the End of the Universe.\nThis is, many would say, impossible.\n…\nYou can visit it as many times as you like … and be sure of never meeting yourself, because of the embarrassment this usually causes.\nThis, even if the rest were true, which it isnt, is patently impossible, say the doubters.\nAll you have to do is deposit one penny in a savings account in your own era, and when you arrive at the End of Time the operation of compound interest means that the fabulous cost of your meal has been paid for.\nThis, many claim, is not merely impossible but clearly insane. (Adams 1980, 213–14)\n\nNeither of these are puzzling. Perhaps it’s hard to imagine the last couple of sentences of the McFly story, but everything the respective authors say is true in their stories. So the impossibility theory cannot be right, because it overgenerates, just as Gendler said.\nRecently Kathleen Stock (2003) has argued that one of the assumptions that Gendler makes, specifically that it isn’t true that “a judgement of conceptual impossibility renders a scenario unimaginable” (Gendler 2000, 66) is false. Even if Stock is right, this doesn’t threaten the kind of response that I have (following Gendler) offered to the puzzles. But actually there are a few reasons to doubt Stock’s reply. I’ll discuss these points in order.\nIt isn’t entirely clear from Stock’s discussion what she is taking a conceptual impossibility to be. I think it is a proposition of the form Some F is a G (or That F is a G, or something of this sort) where it is constitutive of being an F that the F is not a G. There is no positive characterisation of conceptual impossibility in Stock’s paper, but it is clearly meant to be something stronger than mere impossibility, or a priori falsehood. In any case, most of the core arguments turn on worries about allegedly deploying a concept while refusing to draw inferences that are constitutive of that concept, so the kind of definition I’ve offered above seems to be on the right track.\nNow if this is the case then Stock has no objection to the imaginability of the two stories I offered that involve known and salient impossibilities. For neither of these stories includes a conceptual impossibility in this sense. So even if conceptual impossibilities cannot be imagined, some impossibilities can be imagined. (And at this point what holds for imagination also holds for truth in fiction.)\nWhile this suffices as a response to the particular claims Stock makes, it might be thought it undercuts the objection I have made to the impossible solution. For it might be thought that what is wrong with the puzzling sentences just is that they represent conceptual impossibilities in this sense, and we have no argument that these can be imagined, or true in fiction. This is not too far removed from the actual solution I will offer, so it is a serious worry. The problem with this line is that not all of our puzzles are conceptual impossibilities. It isn’t constitutive of being a television that a thing is phenomenally or functionally distinguishable from a knife, but the claim in Victory that some television is not phenomenally or functionally distinguishable from a knife is puzzling. Even in our core cases, of morally deviant claims in fiction, there need not be any conceptual impossibilities. As R. M. Hare (1951) pointed out long ago, people with very different moral beliefs could have in common the concept GOOD. Arguably, someone who thinks that what Craig does in Death is good is morally confused, not conceptually confused. So whether Gendler or Stock is right about the imaginability of conceptual impossibility is neither here nor there with respect to these puzzles.\nHaving said that, there are some reasons to doubt Stock’s argument. One of her moves is to argue that we couldn’t imagine conceptual impossibilities because we can’t believe conceptual impossibilities. But as Sorensen (2001) persuasively argues, we can believe conceptual impossibilities. One of Sorensen’s arguments, lightly modified, helps us respond to another of Stock’s arguments. Stock notes, rightly, that we shouldn’t take the fact that it seems we can imagine impossibilities to be conclusive evidence we can do so. After all, we are wrong about whether things are as they seem all the time. But this might be a special case. I think that if it seems to be the case that p then we can imagine that p. And Stock agrees it seems to be the case that we can imagine conceptual impossibilities. So we can imagine that we can imagine conceptual impossibilities. Hence it can’t be a conceptual impossibility that we can imagine at least one conceptual impossibility. This doesn’t tell against the claim that it is some other kind of impossibility, though as we’ll see Stock’s main argument rests on considerations about the conceptual structure of imagination, so it isn’t clear how she could argue for this.\nThe main argument Stock offers is that no account of how concepts work are compatible with our imagining conceptual impossibilities. Her argument that atomist theories of concepts (as in Fodor (1998)) are incompatible with imagining conceptual impossibilities isn’t that persuasive. She writes that “clearly it is not the case that imagining”the cow jumped over the moon” stands in a lawful relation to the property of being a cow (let alone the property of [being] a cow jumping over the moon. Imagining by its very nature is resistant to any attempt to incorporate it into an externalist theory of content” (2003, 114). But this isn’t clear at all. When I imagine going out drinking with Bill Clinton there is, indeed there must be, some kind of causal chain running back from my imagining to Bill Clinton himself. If there was not, I’d at most be imagining going out drinking with a guy who looks a lot like Bill Clinton. Perhaps it isn’t as clear, but when I imagine that a cow (and not just a zebra disguised to look like a cow) is jumping over the moon it’s nomologically necessary that there’s a causal chain of the right kind stretching back to actual cows. And it’s arguable that the concept I deploy in imagining that a cow (a real cow) is jumping over the moon just is the concept whose content is fixed by the lawful connections between various cows and my (initial) deployment of it. So I don’t see why a conceptual atomist should find this kind of argument convincing.\nStock’s response to Gendler was presented at a conference on Imagination and the Arts at Leeds in 2001, and at the same conference Derek Matravers (2003) offered an alternative solution to the alethic puzzle. Although it does not rest on claims about impossibility, it also suffers from an overgeneration problem. Matravers suggests that in at least some fictions, we treat the text as a report by a (fictional) narrator concerning what is going on in a faraway land. Now in reality when we hear reports from generally trustworthy foreign correspondents, we are likely to believe their descriptive claims about the facts on the ground. Since they have travelled to the lands in question, and we have not, the correspondent is epistemologically privileged with respect to those facts on the ground. But when the correspondent makes moral evaluations of those facts, she is not in a privileged position, so we don’t just take her claims as the final word. Matravers suggests there are analogous limits to how far we trust a fictional narrator.\nThe problem with this approach is that there are several salient disanalogies between the position of the correspondent and the fictional narrator. The following case, which I heard about from Mark Liberman, illustrates this nicely. On March 5, 2004, the BBC reported that children in a nursery in England had found a frog with three heads and six legs. Many people, including Professor Liberman, were sceptical, notwithstanding the fact that the BBC was actually in England and Professor Liberman was not. The epistemological privilege generated by proximity doesn’t extend to implausible claims about three-headed frogs. The obvious disanalogy is that if a fictional narrator said that there was a three-headed six-legged frog in the children’s nursery then other things being equal we would infer it is true in the fiction that there was indeed a three-headed six-legged frog in the children’s nursery.6 So there isn’t an easy analogy between when we trust foreign correspondents and fictional narrators. Now we need an explanation of why the analogy does hold when either party makes morally deviant claims, even though it doesn’t when they both make biologically deviant claims. But it doesn’t seem any easier to say why the analogy holds then than it is to solve the original puzzle.\n6 There is a complication here in that such a sentence might be evidence that the fictional work is not to be understood as this kind of report, and instead understood as something like a recording of the children’s thoughts. I’ll assume we’re in a story where it is clear that the sentences are not to be so interpreted.Two other quick points about Matravers’s solution. It’s going to be a little delicate to extend this solution to all the cases I have discussed above, for normally we do think fictional narrators are privileged with respect to where the televisions and windows are. What matters here is that how far narratorial privilege extends depends on what other claims the narrator makes. Perhaps the same is true of foreign correspondents, though we’d need to see an argument for that. Second, it isn’t clear how this solution could possibly generalise to cover cases, such as frequently occurs in plays, where the deviant moral claim is clearly intended by the author to be true in the fiction but the reader (or watcher) does not agree even though the author’s intention is recognised. As I mentioned at the start, these cases aren’t our concern here, though it would be nice to see how a generalisation to these cases is possible. But the primary problem with Matravers’s solution is that as it stands it (improperly) rules out three-headed frogs in fiction, and it is hard to see how to remedy this problem without solving the original puzzle.\n\n\n4 Some Ethical Solutions\nIf one focuses on cases like Death, it is natural to think the puzzle probably has something to do with the special nature of ethical predicates, or perhaps of ethical concepts, or perhaps of the role of either of these in fiction. I don’t think any such solution can work because it can’t explain what goes wrong in Victory, and this will recur as an objection in what follows.\nThe most detailed solution to the puzzles has been put forward by Tamar Szabó Gendler. She focuses on the imaginative puzzle, but she also makes valuable points about the other puzzles. My solution to the phenomenological puzzle is basically hers plus a little epicycle.\nShe says that we do not imagine morally deviant fictional worlds because of our “general desire to not be manipulated into taking on points of view that we would not reflectively endorse as our own.” How could we take on a point of view by accepting something in a fiction? Because of the phenomena noted above that some things become true in a story because they are true in the world. If this is right, its converse must be true as well. If what is true in the story must match what is true in the world, then to accept that something is true in the story just is to accept that it is true in the world. Arguably, the same kind of ‘import/export’ principles hold for imagination as for truth in fiction. Some propositions become part of the content of an imagining because they are true. So, in the right circumstances, they will only be part of an imagining if they are true. Hence to imagine them (in the right circumstances) is to commit oneself to their truth. Gendler holds that we are sensitive to this phenomena, and that we refuse to accept stories that are morally deviant because that would involve accepting that morally deviant claims are true in the world.\nThat’s a relatively rough description of Gendler’s theory, but it says enough to illustrate what she has in mind, and to show where two objections may slip in. First, it is not clear that it generalises to all the cases. Gendler is aware of some of these cases and just bites the relevant bullets. She holds, for instance, that we can imagine that actually lame jokes are funny, and it could be true in a story that such a joke is funny. It would be a serious cost to her theory if she had to say the same thing about all the examples discussed above.\nThe second problem is more serious. The solution is only as good as the claim that moral claims are more easily exported than descriptive claims, and more generally that the types of claims we won’t imagine are more easily exported than those we don’t resist. Gendler has two arguments for why the first of these should be true, but neither of them sounds persuasive. First, she says that the moral claims are true in all possible worlds if true at all. But this won’t do on its own, because as she proved, we don’t resist some necessarily false claims. (This objection is also made by (Matravers 2003, 94).)\nSecondly, she claims that in other cases where there are necessary falsehoods true in a story, as in Alice in Wonderland, or the science fiction cases, the author makes it clear that unusual export restrictions are being imposed. But this is wrong for two reasons. First, I don’t think that any particularly clear signal to this effect occurs in my version of Back to the Future. Secondly, even if I had explicitly signalled that I had intended to make some of the facts in the story available for export, and you didn’t believe that, that isn’t enough reason to resist imagining the story. For my intent as to what can and cannot be exported is not part of the story.\nTo see this, consider one relatively famous example. At one stage B. F. Skinner tried to promote behaviourism by weaving his theories into a novel (of sorts): Walden Two. Now I’m sure Skinner (1948) intended us to export some psychological and political claims from the story to the real world. But it is entirely possible to read the story with full export restrictions in force without rejecting that what Skinner says is true in that world. (It is dreadfully boring, since there’s nothing but propagandising going on, but possible.) If exporting was the only barrier here, we should be able to impose our own tariff walls and read the story along, whatever the intent of the author, as we can with Walden Two. One can accept it is true in Walden Two that behaviourism is the basis of a successful social policy, even though Skinner wants us to accept this as true in the story iff it is true in the world, and it isn’t true in the world. We cannot read Death or Victory with the same ironic detachment, and Gendler’s theory lacks the resources to explain this.\nCurrie’s theory attacks the problem from a quite different direction. He relies on the motivational consequences of accepting moral claims. Assume internalism about moral motivation, so to accept that \\({\\phi}\\)-ing is right is to be motivated to \\({\\phi}\\), at least ceteris paribus. So accepting that \\({\\phi}\\)-ing is right involves acquiring a desire to \\({\\phi}\\), as well, perhaps, as beliefs about \\({\\phi}\\)-ing. Currie suggests that there is a mental state that stands to desire the way that ordinary imagination stands to belief. It is, roughly, a state of having an off-line desire, in the way that imagining that p is like having an off-line belief that p, a state like a belief that p but without the motivational consequences. Currie suggests that imagining that \\({\\phi}\\)-ing is right involves off-line acceptance that \\({\\phi}\\)-ing is right, and that in part involves having an off-line desire (a desire-like imagination) to \\({\\phi}\\). Finally, Currie says, it is harder to alter our off-line desires at will than it is to alter our off-line beliefs, and this explains the asymmetry. The argument for this last claim seems very hasty, but we’ll let that pass. For even if it is true, Currie’s theory does little to explain the later cases of imaginative resistance, from Alien Robbery to Victory. It cannot explain, why we have resistance to claims about what is rational to believe, or what is beautiful, or what attitudes other people have. The idea that there is a state that stands to desire as imagination stands to belief is I suspect a very fruitful one, but I don’t think its fruits include a solution to these puzzles.\n\n\n5 Grok\nStephen Yablo has suggested that the puzzles, or at least the imaginative puzzle, is closely linked to what he calls response-enabled concepts, or grokking concepts. (I’ll also use response-enabled (grokking) as a property of the predicates that pick out these concepts.) These are introduced by examples, particularly by the example ‘oval’.\nHere are meant to be some platitudes about OVAL. It is a shape concept - any two objects in any two worlds, counterfactual or counteractual, that have the same shape are alike in whether they are ovals. But which shape concept it is is picked out by our reactions. They are the shapes that strike us as being egg-like, or perhaps more formally, like the shape of all ellipses whose length/width ratio is the golden ratio. In this way the concept OVAL meant to be distinguished on the one hand from, say, PRIME NUMBER, which is entirely independent of us, and from WATER, which would have picked out a different chemical substance had our reactions to various chemicals been different. Note that what ‘prime number’ picks out is determined by us, like all semantic facts are. So the move space into which OVAL is meant to fit is quite tiny. We matter to its extension, but not the way we matter to ‘prime number’ (or that we don’t matter to PRIME NUMBER), and not the way we matter to ‘water’. I’m not sure there’s any space here at all. To my ear, Yablo’s grokking predicates strike me as words that have associated egocentric descriptions that fix their reference without having egocentric reference fixing descriptions, and such words presumably don’t exist. But for present purposes I’ll bracket those general concerns and see how this idea can help solve the puzzles. For despite my disagreement about what these puzzles show about the theory of concepts, Yablo’s solution is not too dissimilar to mine.\nThe important point for fiction about grokking concepts is that we matter, in a non-constitutive way, for their extension. Not we as we might have been, or we as we are in a story, but us. So an author can’t say that in the story squares looked egg-shaped to the people, so in the story squares are ovals, because we get to say what’s an oval, not some fictional character. Here’s how Yablo puts it:\n\nWhy should resistance [meaning, roughly, unimaginability] and grokkingness be connected in this way? It’s a feature of grokking concepts that their extension in a situation depends on how the situation does or would strike us. ‘Does or would strike us’ as we are: how we are represented as reacting, or invited to react, has nothing to do with it. Resistance is the natural consequence. If we insist on judging the extension ourselves, it stands to reason that any seeming intelligence coming from elsewhere is automatically suspect. This applies in particular to being ‘told’ about the extension by an as-if knowledgeable narrator. (2002, 485)\n\nIt might look at first as if Victory will be a counterexample to Yablo’s solution, just as it is to the Ethical solutions. After all, the concept that seems to generate the puzzles there is TELEVISION, and that isn’t at all like his examples of grokking concepts. (The examples, apart from evaluative concepts, are all shape concepts.) On the other hand, if there are any grokking concepts, perhaps it is plausible that TELEVISION should be one of them. Indeed, the platitudes about TELEVISION provide some support for this. (The following two paragraphs rely heavily on Fodor (1998).)\nThree platitudes about TELEVISION stand out. One is that it’s very hard to define just what a television is. A second is that there’s a striking correlation between people who have the concept TELEVISION and people who have been acquainted with a television. Not a perfect correlation - some infants have acquaintance with televisions but not as such, and some people acquire TELEVISION by description - but still strikingly high. And a third is that conversations about televisions are rarely at cross purposes, even when they consist of people literally talking different languages. TELEVISION is a shared concept.\nCan we put these into a theory of the concept TELEVISION? Fodor suggests we can, as long as we are not looking for an analysis of TELEVISION. Televisions are those things that strike us, people in general, as being sufficiently like the televisions we’ve seen, in a televisual kind of way. This isn’t an account of the meaning of the word ‘television’ - there’s no reference to us in that word’s dictionary entry, and rightly so. Nor is it an analysis of what constitutes the concept television. There’s no reference to us there either. But it does latch on to the right concept, or at least the right extension, in perhaps the only way we could. And this proposal certainly explains the platitudes well. The epistemic necessity of having a paradigm television to use as a basis for similarity judgments explains the striking correlation between televisual acquaintance and concept possession. The fact that the only way of picking out the extension uses something that is not constitutive of the concept, namely our reactions to televisions, explains why we can’t reductively analyse the concept. And the use of people’s reactions in general rather than idiosyncratic reactions explains why its a common concept. These look like good reasons to think something like Fodor’s theory of the concept TELEVISION is right, and if it is then TELEVISION seems to be response-enabled in Yablo’s sense. So unlike the Ethical solutions, Yablo’s solution might yet predict that Victory will be puzzling.\nStill, I have three quibbles about his solution, and that’s enough to make me think a better solution may still to be found.\nFirst, there’s a missing antecedent in a key sentence in his account, and it’s hard to see how to fill it in. What does he mean when he says ‘how the situation does or would strike us’? Does or would strike us if what? If we were there? But we don’t know where there is. There, in Victory, is allegedly a place where televisions look like knifes and forks. What if the antecedent is If all the non-grokking descriptions were accurate? The problem now is that this will be too light. If TELEVISION is grokking, then there is a worry that many concepts, including perhaps all artefact concepts, will be grokking. Fodor didn’t illustrate his theory with TELEVISION, he always used DOORKNOB. But the theory was meant to be rather general. If we take out all the claims involving grokking concepts, there may not be much left.\nSecond, despite the generality of Fodor’s account, it isn’t clear that mental concepts, and content concepts, are grokking. We would need another argument that LOVE is grokking, and that so is BELIEVING THAT THERE ARE SPACE ALIENS. Perhaps such an argument can be given, but it will not be a trivial exercise.\nFinally, I think this Yablo’s solution, at least as most naturally interpreted, overgeneralises. Here’s a counterexample to it. The following story is not, I take it, puzzling.\n\nFixing a Hole\nDQ and his buddy SP leave DQ’s apartment at midday Tuesday, leaving a well-arranged lounge suite and home theatre unit, featuring DQ’s prized oval television. They travel back in time to Monday, where DQ has some rather strange and unexpected adventures. He intended to correct something that happened yesterday, that had gone all wrong the first time around, and by the time the buddies reunite and leave for Tuesday (by sleeping and waking up in the future) he’s sure it’s all been sorted. When DQ and his buddy SP get back to his apartment midday Tuesday, it looks for all the world like there’s nothing there except an ordinary knife and fork.\n\nNow this situation would not strike us, were we to see it, as one where there is a lounge suite and home theatre unit in DQ’s apartment midday Tuesday, for it looks as if there’s an ordinary knife and fork there. But still, the author gets to say that what’s in DQ’s apartment as the story opens includes an oval television. And this despite the fact that the two concepts, TELEVISION and OVAL, are grokking. Perhaps some epicycles could be added to Yablo’s theory to solve this problem, but for now the solution is incomplete.\n\n\n6 Virtue\nThe content cases may remind us of one of Fodor’s most famous lines about meaning.\n\nI suppose that sooner or later the physicists will complete the catalogue they’ve been compiling of the ultimate and irreducible properties of things. When they do, the likes of spin, charm, and charge will perhaps appear on the list. But aboutness surely won’t; intentionality doesn’t go that deep … If the semantic and the intentional are real properties of things, it must be in virtue of their identity with (or maybe their supervenience on?) properties that are themselves neither intentional nor semantic. If aboutness is real, it must really be something else. (Fodor 1987, 97)\n\nIf meaning doesn’t go that deep, but there are meaning facts, then those facts must hold in virtue of more fundamental facts. “Molino de viento” means windmill in Spanish in virtue of a pattern of usage of those words by Spanish speakers, for instance.\nIt seems that many of the stories above involve facts that hold, if they hold at all, in virtue of other facts. Had Fodor other interests than intentionality, he may have written instead that beauty doesn’t go that deep, and neither does television. If an event is to be beautiful, this is a fact that must obtain in virtue of other facts about it, perhaps its integrity, wholeness, symmetry and radiance as Aquinas says (Joyce 1944/1963, 212), and that event being a monster truck death match of doom probably precludes those facts from obtaining.7 If Quixote’s favourite item of furniture is to be a television, this must be in virtue of it filling certain functional roles, and being indistinguishable from a common knife probably precludes that.\n7 Although it isn’t obvious just which of the Thomistic properties the death match lacks.What is it for a fact to obtain in virtue of other facts obtaining? A good question, but not one we will answer here. Still, the concept seems clear enough that we can still use it, as Fodor does. What we have in mind by ‘virtue’ is understandable from the examples. One thing to note from the top is that it is not just supervenience: whether x is good supervenes on whether it is good, but it is not good in virtue of being good. How much our concept differs from supervenience is a little delicate, but it certainly differs.\nReturning to our original example, moral properties are also less than perfectly fundamental. It is not a primitive fact that the butcher or the baker is generous, but a fact that obtains in virtue of the way they treat their neighbours. It is not a primitive fact that what Craig does is wrong, but a fact that obtains in virtue of the physical features of his actions.\nHow are these virtuous relations relevant to the puzzles? To a first approximation, these relations are always imported into stories and into imagination. The puzzles arise when we try to tell stories or imagine scenes where they are violated. The rest of the paper will be concerned with making this claim more precise, motivating it, and arguing that it solves the puzzles. In making the claim precise, we will largely be qualifying it.\nThe first qualification follows from something we noted at the end of section 2. We don’t know whether puzzles like the ones with which we started arise whenever there is a clash between real-world morality (or epistemology or mereology) and the morality (or epistemology or mereology) the author tries to put in the story. We do know they arise for simple stories and direct invitations to imagine. So if we aren’t to make claims that go beyond our evidence, we should say there is a default assumption that these relations are imported into stories or imaginations, and it is not easy to overcome this assumption. (I will say for short there is a strong default assumption, meaning just that an author cannot cancel the assumption by saying so, and that we cannot easily follow invitations to imagine that violate the relations.)\nThe second qualification is that sometimes we simply ignore, either in fiction or imagination, what goes on at some levels of detail. This means that sometimes, in a sense, the relations are not imported into the story. For instance, for it to really be true that in a language that “glory” means a nice knockdown argument, this must be true in virtue of facts about how the speakers of that language use, or are disposed to use, “glory”. But we can simply say in a story that “glory” in a character’s language means a nice knockdown argument without thereby making any more general facts about usage or disposition to use true in the story.8 More generally, we can simply pick a level of conceptual complexity at which to write our story or conduct our imaginings. Even if those concepts apply, when they do, in virtue of more basic facts, no more basic facts need be imported into the story. For a more vivid, if more controversial, example, one might think that cows are cows in virtue of their DNA having certain chemical characteristics. But when we imagine a cow jumping over the moon, we need not imagine anything about chemistry. Those facts are simply below the radar of our imagining. What do we mean then when we say that these relations are imported into the story? Just that if the story regards both the higher-level facts and the lower-level facts as being within its purview, then they must match up. This does not rule out the possibility of simply leaving out all lower-level facts from the story. In general the same thing is true for imagining, though we will look at some cases below where we it seems there is a stronger constraint on imagining.\n8 Do we make facts about the actual speaker’s usage true in the story? No. The character might have idiosyncratic reasons for not using the word “glory”, and for ignoring all others who use it. That’s consistent with the word meaning a nice knockdown argument.The third qualification is needed to handle an example pressed on me by a referee. Recall our example Fixing a Hole.\n\nFixing a Hole\nDQ and his buddy SP leave DQ’s apartment at midday Tuesday, leaving a well-arranged lounge suite and home theatre unit, featuring DQ’s prized oval television. They travel back in time to Monday, where DQ has some rather strange and unexpected adventures. He intended to correct something that happened yesterday, that had gone all wrong the first time around, and by the time the buddies reunite and leave for Tuesday (by sleeping and waking up in the future) he’s sure it’s all been sorted. When DQ and his buddy SP get back to his apartment midday Tuesday, it looks for all the world like there’s nothing there except an ordinary knife and fork.\n\nIn this story it seems that on Tuesday there is a television that looks exactly like a knife. If we interpret the claim about the relations between higher-level facts and the lower-level facts as a kind of impossibility claim, e.g. as the claim that a conjunction p \\({\\wedge}\\) q is never true in a story if the conditional If q, then p is false in virtue of q being true is true, then we have a problem. Let p be the claim that there is a television, and let q be the claim that the only things in the apartment looked life a knife and fork. If that’s how the more basic phenomenal and functional facts are, then there isn’t a television in virtue of those facts. (That is, this relation between phenomenal and functional facts and facts about where the televisions are really holds.) So this rule would say p \\({\\wedge}\\) q could not be true in the story. But in fact p \\({\\wedge}\\) q is true in the story.\nThe difficulty here is that Fixing a Hole is a contradictory story, and contradictory stories need care. First, here’s how we should interpret the rule\n\nVirtue\nIf p is the kind of claim that if true must be true in virtue of lower-level facts, and if the story is about those lower-level facts, then it must be true in the story that there is some true proposition r which is about those lower-level facts such that p is true in virtue of r.\n\nIn Fixing a Hole there are some true lower-level claims that are inconsistent with there being a television. But there is also in the story a true proposition about how DQ’s television looked before his time-travel misadventure. And it is true (both in reality and in the story) that something is a television in virtue of looking that way. (Note that we don’t say there must be some proposition r that is true in the story in virtue of which p is true. For there is no fact of the matter in Fixing a Hole about how DQ’s television looked before he left. So in reality we could not find such a proposition. But it is true in the story that his television looks some way or other, so as long as we talk about what in the story is true, and don’t quantify over propositions that are (in reality) true in the story, we avoid this pitfall.)\nSo my solution to the alethic puzzle is that Virtue is a strong default principle of fictional interpretation. I haven’t done much yet to motivate it, apart from noting that it seems to cover a lot of the cases that have been raised without overgenerating in the manner of the impossible solution. A more positive motivation must wait until I have presented my solutions to the phenomenological and imaginative puzzles. I’ll do that in the next section, then in tell a story about why we should believe Virtue.\n\n\n7 More Solutions\n\n7.0.1 The Phenomenological Puzzle\nMy solution here is essentially the same as Gendler’s. She think that when we strike a sentence that generated imaginative resistance we respond with something like, “That’s what you think!” What makes this notable is that it’s constitutive of playing the fiction game that we not normally respond that we way, that we give the author some flexibility in setting up a world. I think that’s basically right, but a little more is needed to put the puzzle to bed.\nSometimes the “That’s what you think!” response does not constitute abandoning the fiction game. At times it is the only correct way to play the game. It’s the right thing to say to Lily when reading the first line of The Dead. (Maybe it would be rude to say it aloud to poor Lily, the poor girl is run off her feet after all, but it’s appropriate to think it.) This pattern recurs throughout Dubliners. When in Eveline the narrator says that Frank has sailed around the world, the right reaction is to say to Eveline (or whoever is narrating then), “That’s what you think!” There’s a cost to playing the game this way. We end up knowing next to nothing about Frank. But it is not as if making the move stops us playing, or even stops us playing correctly. It’s part of the point of Eveline that we know next to nothing about Frank.\nWhat makes cases like Death and Victory odd is that our reaction is directed at someone who isn’t in the story. One of Alex Byrne’s (1993) criticisms of Lewis was that on Lewis’s theory it is true in every story that the story is being told. Byrne argued that in many fictions it is not true that in the fictional world there is someone sufficiently knowledgeable to tell the story. In these fictions, we have a story without a storyteller. If there are such stories, then presumably Death and Victory are amongst them. It is not a character in the story who ends by saying that Craig’s action was right or that Quixote’s apartment contains a television. The author says that, and hence deserves our reproach, but the author isn’t in the story. Saying “That’s what you think!” directly to him or her breaks the fictional spell for suddenly we have to recognise a character not in the fictional world.\nThis proposal for the phenomenological puzzle yields a number of predictions which seem to be true and interesting. First, a story that has a narrator should not generate a phenomenological puzzle, even when outlandish moral claims are made. The more prominent the narrator, the less striking the moral claim. Imagine, for example, a version of Death where the text purports to be Craig’s diary, and it includes naturally enough his own positive evaluation of what he did. We wouldn’t believe him, of course, but we wouldn’t be struck by the claim the same way we are in the actual version of Death.\nOne might have thought that what is shocking is what we discover about the author. But this isn’t right, as can be seen if we reflect on stories that contain Craig’s diary. It is possible, difficult but possible, to embed the diary entry corresponding to Death in a longer story where it is clear that the author endorses Craig’s opinions. (Naturally I won’t do this. Examples have to come to an end somewhere.) Such a story would, in a way, be incredibly shocking. But it wouldn’t make the final line shocking in just the way that the final line of Death is shocking. Our reactions to these cases suggest that the strikingness of the last line of Death is not a function of what it reveals about the author, but of how it reveals it.\nThe final prediction my theory makes is somewhat more contentious. Some novels announce themselves as works of fiction. They go out of their way to prevent you ignoring the novel’s role as mediation to a fictional world. (For an early example of this, consider the sudden appearance of newspaper headlines in the ‘Aeolus’ episode of Ulysses.) In such novels we already have to recognise the author as a player in the fictional game, if not a character in the story. I predict that sentences where we do not take what is written to really be true in the story, even though this is what the author intended, should be less striking in these cases because we are already used to reacting to the author as such rather than just to the characters. Such books go out of their way to break the fictional spell, so spell breaking should matter less in these cases. I think this prediction is correct, although the works in question tend to be so complicated that it is hard to generate clear intuitions about them.\n\n\n7.0.2 The Imaginative Puzzle\nImagine, if you will, a chair. Have you done so? Good. Let me make some guesses about what you imagined. First, it was a specific kind of chair. There is a fact of the matter about whether the chair you imagined is, for example, an armchair or a dining chair or a classroom chair or an airport lounge chair or an outdoor chair or an electric chair or a throne. We can verbally represent something as being a chair without representing it as being a specific kind of chair, but imagination cannot be quite so coarse.9\n9 This relates to another area in which my solution owes a debt to Gendler’s solution. Supposing can be coarse in a way that imagining cannot. We can suppose that Jack sold a chair without supposing that he sold an armchair or a dining chair or any particular kind of chair at all. Gendler concludes that what we do in fiction, where we try and imagine the fictional world, is very different to what we do, say, in philosophical argumentation, where we often suppose that things are different to the way they actually are. We can suppose, for the sake of argument as it’s put, that Kantian or Aristotelian ethical theories are entirely correct, even if we have no idea how to imagine either being correct. Thanks to Tyler Doggett for pointing out the connection to Gendler here.10 Thanks to Kendall Walton for pointing out this possibility.Secondly, what you imagined was incomplete in some respects. You possibly imagined a chair that if realised would contain some stitching somewhere, but you did not imagine any details about the stitching. There is no fact of the matter about how the chair you imagined holds together, if indeed it does. If you imagined a chair by imagining bumping into something chair-like in the dead of night, you need not have imagined a chair of any colour, although in reality the chair would have some colour or other.10\nWere my guesses correct? Good. The little I needed to know about imagination to get those guesses right goes a long way towards solving the puzzle.\nChairs are not very distinctive. Whenever we try to imagine that a non-fundamental property is instantiated the content of our imagining will be to some extent more specific than just that the object imagined has the property, but not so much more specific as to amount to a complete description of a possibilia. It’s the latter fact that does the work in explaining how can imagine impossible situations. If we were, foolishly, to try to fill in all the details of the impossible science fiction cases it would be clear they contained not just impossibilities, but violations of Virtue, and then we would no longer be able to imagine them. But we can imagine the restaurant at the end of the universe without imagining it in all its glorious gory detail. And when we do so our imagining appears to contain no such violations.\nBut why can’t we imagine these violations in fictions? It is primarily because we can only imagine the higher-level claim some way or another, just as we only imagine a chair as some chair or other, and the instructions that go along with the fiction forbid us from imagining any relevant lower-level facts that would constitute the truth of the higher-level claim. We have not stressed it much above, but it is relevant that fictions understood as invitations to imagine have a “That’s all” clause.11 We are not imagining Death if we imagine that Jack and Jill had just stopped arguing with each other and were about to shoot everyone in sight when Craig shot them in self-defence. The story does not explicitly say that wasn’t about to happen. It doesn’t include a “That’s all” clause. But such clauses have to be understood. So not only are we instructed to imagine something that seems incompatible with Craig’s action being morally acceptable, we are also instructed (tacitly) to not imagine anything that would make it the case that his action is morally acceptable. But we can’t simply imagine moral goodness in the abstract, to imagine it we have to imagine a particular kind of goodness.\n11 “That’s all” clauses play a distinct, but related, role in (Jackson 1998 Ch. 1). It’s also crucial to my solution to the alethic puzzle that there be a “That’s all” clause in the story. What’s problematic about these cases is that the story (implicitly) rules out there being the lower-level facts that would make the expressed higher-level claims true.\n\n7.0.3 Two Thoughts Too Many?\nI have presented three solutions to the three different puzzles with which we started. Might it not be better to have a uniform solution? No, because although the puzzles are related, they are not identical. Three puzzles demand three solutions.\nWe saw already that the phenomenological puzzle is different to the other two. If we rewrite Death as Craig’s diary there would be nothing particularly striking about the last sentence, certainly in the context of the story as so told. But the last sentence generates alethic and imaginative puzzles. Or at least it could generate these puzzles if the author has made it clear elsewhere in the story that Craig’s voice is authoritative. So we shouldn’t expect the same solution to that puzzle as the other two.\nThe alethic puzzle is different to the other two because ultimately it depends on what the moral and conceptual truths are not on what we take them to be. Consider the following story.\n\nThe Benefactor\nSmith was a very generous, just and in every respect moral man. Every month he held a giant feast for the village where they were able to escape their usual diet of gains, fruits and vegetables to eat the many and varied meats that Smith provided for them.\n\nConsider in particular, what should be easy to some, how Benefactor reads to someone who believes that we are morally required to be vegetarian if this is feasible. In Benefactor it is clear in the story that most villagers can survive on a vegetarian diet. So it is morally wrong to serve them the many and varied meats that Smith does. Hence such a reader should disagree with the author’s assessment that Smith is moral ‘in every respect’. Such a reader will think that in fact in the story Smith is quite immoral in one important respect.\nNow for our final assumption. Assume it is really true that we morally shouldn’t eat meat if it is avoidable. Since the ethical vegetarians have true ethical beliefs about the salient facts here, it seems plausible that their views on what is true in the story should carry more weight than ours. (I’m just relying on a general epistemological principle here: other things being equal trust the people who have true beliefs about the relevant background facts.) So it seems that it really is false in the story that Smith is in every respect moral. Benefactor raises an alethic puzzle even though for non-vegetarians it does not raise a phenomenological or imaginative puzzle.\nThis point generalises, so we need not assume for the general point that vegetarianism is true or that our typical reader is not vegetarian. We can be very confident that some of our ethical views will be wrong, though for obvious reasons it is hard to say which ones. Let p be a false moral belief that we have. And let S be a story in which p is asserted by the (would-be omniscient) narrator. For reasons similar to what we said about Benefactor, p is not true in S. But S need not raise any imaginative or phenomenological puzzles. Hence the alethic puzzle is different to the other two puzzles.\n\n\n\n8 Why Virtue Matters\nI owe you an argument for why authors should be unable to easily generate violations of Virtue, though there is no general bar on making impossibilities true in a story. My general claims here are not too dissimilar to Yablo’s solution to the puzzles, but there are a couple of distinctive new points. Before we get to the argument, it’s time for another story.\nThree design students walk into an furniture showroom. The new season’s fashions are all on display. The students are all struck by the piece de resistance, though they are all differently struck by it. Over drinks later, it is revealed that while B and C thought it was a chair, A did not. But the differences did not end there. When asked to sketch this contentious object, A and B produced identical sketches, while C’s recollections were drawn somewhat differently. B clearly disagrees with both A and C, but her differences with each are quite different. With C she disagrees on some simple empirical facts, what the object in question looked like. With A she disagrees on a conceptual fact, or perhaps a semantic fact, whether the concept CHAIR, or perhaps just the term ‘chair’, applies to the object in question. As it turns out, A and B agree that ‘chair’ means CHAIR, and agree that CHAIR is a public concept so one of them is right and the other wrong about whether this object falls under the concept. In this case, their disagreement will have a quite different feel to B’s disagreement with C. It may well be that there is no analytic/synthetic distinction, and that questions about whether an object satisfies a concept are always empirical questions, but this is not how it feels to A and B. They feel that they agree on what the world is like, or at least what this significant portion of it is like, and disagree just on which concepts apply to it.\nThe difference between these two kinds of disagreement is at the basis of our attitudes towards the alethic puzzle. It may look like we are severely cramping authorial freedom by not permitting violations of Virtue.12 From A and B’s perspective, however, this is no restriction at all. Authors, they think, are free to stipulate which world will be the site of their fiction. But as their disagreement about whether the piece de resistance was a chair showed, we can agree about which world we are discussing and disagree about which concepts apply to it. The important point is that the metaphysics and epistemology of concepts comes apart here.\n12 Again, it is worth noting that I am not ruling out any violation of Virtue, just easy violations of it. The point being made in the text is that even a blanket ban on violations would not be a serious restriction on authorial freedom.There can be no difference in whether the concept CHAIR applies without a difference in the underlying facts. But there can be a difference of opinion about whether a thing is a chair without a difference of opinion about the underlying facts. The fact that it’s the author’s story, not the reader’s, means that the author gets to say what the underlying facts are. But that still leaves the possibility for differences of opinion about whether there are chairs, and on that question the author’s opinion is just another opinion.\nAuthorial authority extends as far as saying which world is fictional in their story, it does not extend as far as saying which concepts are instantiated there. Since the main way that we specify which world is fictional is by specifying which concepts are instantiated at it, authorial authority will usually let authors get away with any kind of conceptual claim. But once we have locked onto the world being discussed, the author has no special authority to say which concepts, especially which higher-level concepts like RIGHT or FUNNY or CHAIR are instantiated there.\n(Does it matter much that the distinction between empirical disagreements and conceptual disagreements with which I started might turn out not to rest on very much? Not really. I am trying to explain why we have the attitudes towards fiction that we do, which in turn determines what is true in fiction generally. All that matters is that people generally think that there is something like a conceptual truth/empirical truth distinction, and I think enough people would agree that A and B’s disagreement is different in kind from B and C’s disagreement to show that is true. If folks are generally wrong about this, if there is no difference in kind between conceptual truths and empirical truths, then our communal theory of truth in fiction will rest on some fairly untenable supports. But it will still be our theory, although any coherent telling of it will have to be in terms of things that are taken to be conceptual truths and things that are taken to be empirical truths.)\nThis explanation of why authorial authority collapses just when it does yields one fairly startling, and I think true, prediction. I argued above that authors could not easily generate violations of Virtue. That this is impossible is compatible with any number of hypotheses about how readers will resolve those impossibilities that authors attempt to slip in. The story here, that authors get to say which world is at issue but not which concepts apply to it, yields the prediction that readers will resolve the tension in favour of the lower-level claims. When given a physical description of a world and an incompatible moral description, we will take the physical description to fix which world is at issue and reduce the moral description to a series of questionable claims about the world. Compare what happens with A, B and C. We take A and B to agree about the world and disagree about concepts, rather than say taking B and C to agree about what the world is like (there’s a chair at the heart of the furniture show) and say that A and B disagree about the application of some recognitional concepts. This prediction is borne out in every case discussed in . We do not conclude that Craig did not really shoot Jack and Jill, because after all the world at issue is stipulated to be one where he did the right thing. Even more surprisingly, we do not conclude that Quixote’s furniture does not look like kitchen utensils, because it consists of a television and an armchair. This is surprising because in Victory I never said that the furniture looked like kitchen utensils. The tacit low-level claim about appearances is given precedence over the explicit high-level claims about which objects populate Quixote’s apartment. The theory sketched here predicts that, and supports the solution to the alethic puzzle sketched in , which is good news for both the theory and the solution.\nIt’s been a running theme here that the puzzles do not have anything particularly to do with normativity. But some normative concepts raise the kind of issues about authority mentioned here in a particularly striking way. There is always some division of cognitive labour in fiction. The author’s role is, among other things, to say which world is being made fictional. The audience’s role is, among other things, to determine the artistic merit of the fictional work. On other points there may be some sharing of roles, but this division is fairly absolute. The division threatens to collapse when authors start commenting on the aesthetic quality of words produced by their characters. At the end of Ivy Day in the Committee Room Joyce has one character describe a poem just recited by another character as “A fine piece of writing” (Joyce 1914/2000, 105). Most critics seem to be happy to accept the line, because Joyce’s poem here really is, apparently, a fine piece of writing. But to me it seems rather jarring, even if it happens to be true. It’s easy to feel a similar reaction when characters in a drama praise the words of another character.13 This is a special, and especially vivid, illustration of the point I’ve been pushing towards here. The author gets to describe the world at whichever level of detail she chooses. But once it has been described, the reader has just as much say in which higher-level concepts apply to parts of that world. When the concepts are evaluative concepts that directly reflect on the author, the reader’s role rises from being an equal to having more say than the author, just as we normally have less say than others about which evaluative concepts apply to us.\n13 For a while this would happen frequently on the TV series The West Wing. President Bartlett would deliver a speech, and afterwards his staffers would congratulate themselves on what a good speech it was. The style of the congratulations was clearly intended to convey the author’s belief that the speech they themselves had written was a good speech, not just the characters’ beliefs to this effect. When in fact it was a very bad speech, this became very jarring. In later series they would often not show the speeches in question and hence avoid this problem.This idea is obviously similar to Yablo’s point that we get to decide when grokking concepts apply, not the author. But it isn’t quite the same. I think that if any concepts are grokking, most concepts are, so it can’t be the case that authors never get to say when grokking concepts apply in their stories. Most of the time authors will get to say which grokking concepts apply, because they have to use them to tell us about the world. What’s special about the kind of concepts that cause puzzles is that we get to decide when they apply full stop, but that we get to decide how they apply given how more fundamental concepts apply. So the conciliatory version of the relation between my picture here and Yablo’s is that I’ve been filling in, in rather laborious detail, his missing antecedent.\n\n\n9 Two Hard Cases\nThe first hard case is suggested by Kendall Walton (1994). Try to imagine a world where the over-riding moral duty is to maximise the amount of nutmeg in the world. If you are like me, you will find this something of a challenge. Now consider a story Nutmeg that reads (in its entirety!): “Nobody ever discovered this, but it turned out all along their over-riding moral duty was to maximise the amount of nutmeg in the world.” What is true in Nutmeg? It seems that there are no violations of Virtue here, but it is hard to imagine what is being described.\nThe second hard case is suggested by Tamar Szabó Gendler (2000). (I’m simplifying this case a little, but it’s still hard.) In her Tower of Goldbach, God decrees that 12 shall no longer be the sum of two primes, and from this it follows (even in the story) that it is not the sum of 7 and 5. (It is not clear why He didn’t just make 5 no longer prime - say the product of 68 and 57. That may have been simpler.) Interestingly, this has practical consequences. When a group of seven mathematicians from one city attempts to join a group of five from another city, they no longer form a group of twelve. Again, two questions. Can we imagine a Goldbachian situation, where 7 and 5 equal not 12? Is it true in Gendler’s story that 7 and 5 equal not 12? If we cannot imagine Goldbach’s tower, where is the violation of Virtue?\nFirst a quick statement of my responses to the two cases then I’ll end with my detailed responses. To respond properly we need to tease apart the alethic and imaginative puzzles. I claim that the alethic puzzle only arises when there’s a violation of Virtue. There’s no violation in either story, so there is no alethic puzzle. I think there are independent arguments for this conclusion in both cases. We can’t imagine either (if we can’t) because any way of filling in the more basic facts leads to violations.\nIt follows from my solution to the alethic puzzle that Nutmegism (Tyler Doggett’s name for the principle that we must maximise quantities of nutmeg) could be true in a story. There is no violation in Nutmeg, since there are no lower level claims made. Still, the story is very hard to imagine. The reason for this is quite simple. As noted, we cannot just imagine a chair, we have to imagine something more detailed that is a chair in virtue of its more basic properties. (There is no particular more basic property we need imagine, as is shown by the fact that we can imagine a chair just by imagining something with a certain look, or we can imagine a chair in the dark with no visual characteristics. But there is always something more basic.) Similarly to imagine a duty, we have to imagine something more detailed, in this case presumably a society or an ecology, in virtue of which the duty exists. But no such possible, or even impossible, society readily springs to mind. So we cannot imagine Nutmegism is true.\nBut it is hard to see how, or why, this inability should be raised into a restriction on what can be true in a story. One might think that what is wrong with Nutmeg is that the fictional world is picked out using high-level predicates. If we extend the story any way at all, the thought might go, we will generate a violation of Virtue. And that is enough to say that Nutmegism is not true in the story. But actually this isn’t quite right. If we extend the story by adding more moral claims, there is no duty to minimise suffering, there is no duty to help the poor etc, there are still no violations in the story. The restriction we would have to impose is that there is no way of extending the story to fill out the facts in virtue of which the described facts obtain, without generating a violation. But that looks like too strong a constraint, mostly because if we applied it here, to rule out Nutmegism being true in Nutmeg, we would have to apply it to every story written in a higher level language than that of microphysics. It doesn’t seem true that we have to be able to continue a story all the way to the microphysical before we can be confident that what the author says about, for instance, where the furniture in the room is. So there’s no reason to not take the author’s word in Nutmeg, and since the default is always that what the author says is true, Nutmegism is true in the story.\nThe mathematical case is more difficult. The argument that 7 and 5 could fail to equal 12 in the story turns on an example by Gregory Currie (1990). (The main conclusions of this example are also endorsed by Byrne (1993).) Currie imagines a story in which the hero refutes Gödel’s Incompleteness Theorem. Currie argues that the story could be written in such a way that it is true in the story not merely that everyone believes our hero refuted Gödel, but that she really did. But if it could be true in a story that Gödel’s Incompleteness Theorem could be false, then it’s hard to see just why it could not be true in a story that a simpler arithmetic claim, say that 7 and 5 make 12, could also be false. Anything that can’t be true in a story can’t be true in virtue of some feature it has. The only difference between Gödel’s Incompleteness Theorem and a simple arithmetic statement appears to be the simplicity of the simple statement. And it doesn’t seem possible, or advisable, to work that kind of feature into a theory of truth in fiction.\nThe core problem here is that how simple a mathematical impossibility is very much a function of the reader’s mathematical knowledge and acumen. Some readers probably find the unique prime factorisation theorem so simple and evident that for them a story in which it is false is as crashingly bad as a story in which 7 and 5 do not make 12. For other readers, it is so complex that a story in which it has a counterexample is no more implausible than a story in which Gödel is refuted. I think it cannot be true for the second reader that the unique prime factorisation theorem fails in the story and false for the first reader. That amounts to a kind of relativism about truth in fiction that seems preposterous. But I agree with Currie that some mathematical impossibilities can be true in a fiction. So I conclude that, whether it is imaginable or not, it could be true in a story that 7 and 5 not equal 12.\nI think, however, that it is impossible to imagine that 7 plus 5 doesn’t equal 12. Can we explain that unimaginability in the same way we explained why Nutmeg couldn’t be imagined? I think we can. It seems that the sum of 7 and 5 is what it is in virtue of the relations between 7, 5 and other numbers. It is not primitive that various sums take the values they take. That would be inconsistent with, for example, it being constitutive of addition that it’s associative, and associativity does seem to be constitutive of addition. We cannot think about 7, 5, 12 and addition without thinking about those more primitive relations. So we cannot imagine 7 and 5 equally anything else. Or so I think. There’s some rather sophisticated, or at least complicated, philosophy of mathematics in the story here, and not everyone will accept all of it. So we should predict that not everyone will think that these arithmetic claims are unimaginable. And, pleasingly, not everyone does. Gendler, for instance, takes it as a data point that Tower of Goldbach is imaginable. So far so good. Unfortunately, if the story is true we should also expect that whether people find the story imaginable links up with the various philosophies of mathematics they believe. And the evidence for that is thin. So there may be more work to do here. But there is clearly a story that we can tell that handles the case.\n\n\n\n\n\n\nReferences\n\nAdams, Douglas. 1980. The Restaurant at the End of the Universe. London: Pan Macmillan.\n\n\nByrne, Alex. 1993. “Truth in Fiction - the Story Continued.” Australasian Journal of Philosophy 71 (1): 24–35. https://doi.org/10.1080/00048409312345022.\n\n\nCurrie, Gregory. 1990. The Nature of Fiction. Cambridge: Cambridge University Press.\n\n\n———. 2002. “Desire in Imagination.” In Conceivability and Possibility, edited by Tamar Szabó Gendler and John Hawthorne, 201–21. Oxford: Oxford University Press.\n\n\nFodor, Jerry A. 1987. Psychosemantics. Cambridge, MA: MIT Press.\n\n\n———. 1998. Concepts: Where Cognitive Science Went Wrong. Oxford: Oxford University Press.\n\n\nGendler, Tamar Szabó. 2000. “The Puzzle of Imaginative Resistance.” Journal of Philosophy 97 (2): 55–81. https://doi.org/10.2307/2678446.\n\n\nHare, R. M. 1951. The Language of Morals. Oxford: Oxford University Press.\n\n\nHolton, Richard. 1997. “Some Telling Examples: Reply to Tsohatzidis.” Journal of Pragmatics 28 (5): 625–28. https://doi.org/10.1016/s0378-2166(96)00081-1.\n\n\nHume, David. 1757. “On the Standard of Taste.” In Essays: Moral, Political and Legal, 227–49. Indianapolis: Liberty Press.\n\n\nJackson, Frank. 1998. From Metaphysics to Ethics: A Defence of Conceptual Analysis. Clarendon Press: Oxford.\n\n\nJoyce, James. 1914/2000. Dubliners. Oxford: Oxford University Press.\n\n\n———. 1944/1963. Stephen Hero. New Directions: Norfolk, CT.\n\n\n———. 1922/1993. Ulysses. Oxford: Oxford University Press.\n\n\nKidd, John. 1988. “The Scandal of ‘Ulysses’.” The New York Review of Books 35 (11): 32–39.\n\n\nKripke, Saul. 1982. Wittgenstein on Rules and Private Language. Oxford: Basil Blackwell.\n\n\nLewis, David. 1978. “Truth in Fiction.” American Philosophical Quarterly 15 (1): 37–46.\n\n\nMatravers, Derek. 2003. “Fictional Assent and the (so-Called) ‘Puzzle of Imaginative Resistance’.” In Imagination, Philosophy and the Arts, edited by Matthew Kieran and Dominic McIver Lopes, 91–108. London. Routledge.\n\n\nMoran, Richard. 1995. “The Expression of Feeling in Imagination.” Philosophical Review 103 (1): 75–106. https://doi.org/10.2307/2185873.\n\n\nPriest, Graham. 1997. “Sylvan’s Box: A Short Story and Ten Morals.” Notre Dame Journal of Formal Logic. 38 (4): 573–82. https://doi.org/10.1305/ndjfl/1039540770.\n\n\nSkinner, B. F. 1948. Walden Two. New York: Macmillan.\n\n\nSorensen, Roy. 2001. Vagueness and Contradiction. Oxford: Oxford University Press.\n\n\nStock, Kathleen. 2003. “The Tower of Goldbach and Other Impossible Tales.” In Imagination, Philosophy and the Arts, edited by Matthew Kieran and Dominic McIver Lopes, 107–24. London. Routledge.\n\n\nWalton, Kendall. 1990. Mimesis as Make Believe. Cambridge, MA: Harvard University Press.\n\n\n———. 1994. “Morals in Fiction and Fictional Morality.” Aristotelian Society 68(Supp) (1): 27–50. https://doi.org/10.1093/aristoteliansupp/68.1.27.\n\n\nYablo, Stephen. 2002. “Coulda, Woulda, Shoulda.” In Conceivability and Possibility, edited by Tamar Szabó Gendler and John Hawthorne, 441–92. Oxford: Oxford University Press."
  },
  {
    "objectID": "posts/haootm/index.html",
    "href": "posts/haootm/index.html",
    "title": "Humeans Aren’t Out of Their Minds",
    "section": "",
    "text": "Humeanism is “the thesis that the whole truth about a world like ours supervenes on the spatiotemporal distribution of local qualities.” (Lewis 1994, 473) Since the whole truth about our world contains truths about causation, causation must be located in the mosaic of local qualities that the Humean says constitute the whole truth about the world. The most natural ways to do this involve causation being in some sense extrinsic. To take the simplest possible Humean analysis, we might say that c causes e iff throughout the mosaic events of the same type as c are usually followed by events of type e. For short, the causal relation is the constant conjunction relation. Whether this obtains is determined by the mosaic, so this is a Humean theory, but it isn’t determined just by c and e themselves, so whether c causes e is extrinsic to the pair. Now this is obviously a bad theory of causation, but the fact that causation is extrinsic is retained even by good Humean theories of causation. John Hawthorne (2004) objects to this feature of Humeanism. I’m going to argue that his arguments don’t work, but first we need to clear up three preliminaries about causation and intrinsicness.\n\nPublished in Noûs 41: 529-535.\n\nFirst, my wording so far has been cagey because I haven’t wanted to say that Humeans typically take causation to be an extrinsic relation. That’s because the greatest Humean of them all, David Lewis, denies that causation is a relation at all, and hence that it is an extrinsic relation (Lewis 2004b). We can go some way to avoiding this complication by talking, as Hawthorne does, about properties of regions, and asking the property of containing a duplicate of c that causes a duplicate of e is intrinsic or extrinsic.1 Humeans typically take causation to be extrinsic in this sense.\n1 This move requires the not wholly uncontroversial assumption that regions are the kinds of things that can have properties. But I’ll happily make that assumption here. Note that the formulation here allows that the property denoted might be intrinsic for some c and e and extrinsic for others. I’ll say causation is extrinsic if the property denoted is extrinsic for some choice of c and e, even if it is intrinsic for others, as it might be if, for example, no region could possess the property because c is a part of e.Second, nothing in Humeanism requires that causation is extrinsic in that sense. If one analysed causation as that intrinsic relation that actually most tightly correlates with the constant conjunction relation, then one would have guaranteed that causation was an intrinsic relation. Moreover, one would have a perfectly Humean theory of causation. (A perfectly awful theory, to be sure, but still a Humean one.) Peter Menzies (1996, 1999) develops a more sophisticated version of such a theory, and though Menzies describes his view as anti-Humean, one can locate the relation we’ve defined here in the Humean mosaic, so such an approach might be consistent with Humeanism in the intended sense.\nThird, there is good reason, independent of Humeanism, to accept that causation is extrinsic. As Ned Hall (2004) argues, it is very hard to square the intrinsicness of causation with the possibility of causation by omission. Given the choice between these two, I’m going to accept causation by omission without much hesitation. There is one powerful objection to the possibility of causation by omission, namely that if there is any causation by omission then there is a lot more than is intuitively plausible. But since Sarah McGrath (2005) has a good response to that objection, I feel happy accepting there is causation by omission. So I accept that causation is extrinsic, for reasons totally independent of Humeanism. Since Hawthorne appeals to no feature of Humeanism beyond the Humean’s acceptance of the extrinsicness of causation, we can take his argument to be an argument against the causal extrinsicalist, i.e. the theorist who accepts causation is extrinsic in the above sense. To see that the argument doesn’t go through, we need to consider what exactly the causal extrinsicalist is committed to. I’ll explore this by looking at some other examples of properties of regions.\nSome regions contain uncles and some do not. This seems to be an extrinsic property of regions. My house does not contain any uncles right now, but there are duplicates of it, in worlds where my brothers have children, where it does contain an uncle, namely my counterpart. Consider the smallest region containing the earth from the stratosphere in from the earth’s formation to its destruction. Call this region e. Any duplicate of e also contains uncles, including several uncles of mine. You can’t duplicate the earth without producing a duplicate of me who is, in the duplicate world, the nephew of the duplicates of my uncles. So it is intrinsic to e that it contain an uncle, even though this is an extrinsic property of regions. (There is much more discussion of extrinsic properties that are possessed intrinsically in Humberstone (1996).)\nThis possibility, that a region might intrinsically possess an extrinsic property, poses a problem for Hawthorne’s argument. Here is his presentation of it.\n\n\nAn intrinsic duplicate of any region wholly containing me will contain a being with my conscious life.\nThere are causal requirements on my conscious life.\n\nTherefore, Humeanism is false. (Hawthorne 2004, 351–52)\n\nThe problem is that this argument isn’t valid. What follows from (1) and (2) is that any region containing Hawthorne must possess some causal properties intrinsically. (As Hawthorne argues on page 356.) And what Humeanism entails is that causal properties are extrinsic properties of regions. But there is no incompatibility here, for it is possible that extrinsic properties are possessed intrinsically, as we saw in the discussion of uncles.\nHawthorne’s argument would go through if Humeans, and causal extrinsicalists more generally, were committed to the stronger claim that regions never possess causal properties intrinsically. But it doesn’t seem that Humeans should be committed to this claim. Consider again e and all its duplicates. Any such duplicate will contain a duplication of the event of Booth’s shooting Lincoln, and Lincoln dying.2 Will it also be the case that duplicate-Booth’s shooting in this world causes duplicate-Lincoln’s dying? If so, and this seems true, then it is intrinsic to e that it contains an event of a shooting causing a dying, even though the property of containing a shooting causing a dying is extrinsic.\n2 There is a potential complication here in that arguably in some such worlds, e.g. worlds where there is another planet on the opposite side of the sun to duplicate-earth where people are immediately ‘resurrected’ when the ‘die’ on duplicate-earth. In such a world you might say that duplicate-Lincoln doesn’t really die on duplicate-Earth, but merely has the duplicate-earth part of his life ended. We’ll understand ‘dying’ in such a way that this counts as dying.It would be a bad mistake to offer the following epistemological argument that in all duplicates of e, duplicate-Booth’s shooting causes duplicate-Lincoln’s dying.\n\nIf there was a duplicate of e where duplicate-Booth’s shooting does not cause duplicate-Lincoln’s dying, then we would not know whether Booth’s shooting causes Lincoln’s dying without investigating what happens outside e.\nWe can know that Booth’s shooting caused Lincoln’s dying without investigating outside e.\nSo, there is no duplicate of e where duplicate-Booth’s shooting does not cause duplicate-Lincoln’s dying.\n\nThe problem with this argument is that even there are worlds containing such duplicates, we might know a priori that we do not live in such a world, just as we know a priori that we do not live in a world where certain kinds of sceptical scenarios unfold (Hawthorne 2002; Weatherson 2005).\nA better argument against the existence of such a world is that if it is possible, it should be conceivable. But it is basically impossible to conceive such a world. Even if throughout the universe shootings like Booth’s are usually followed by something other than dying, say that shooting in most parts of the universe causes diseases to be cured, the large-scale regularity within e (or its duplicate) of shootings being followed by dying suffices to ground the claim that shootings cause dyings in a good Humean theory. The crucial assumption here is that local regularities count for more than global regularities. If the local regularities deviate too far from the global regularities, then Humeans can and should say that different nomic claims (and hence causal claims) are true in this part of the world to the rest of the universe. If they say this, they can say that regions can have causal features (such as containing a shooting causing a dying) intrinsically even though causal features are extrinsic properties.\nTo illustrate the kind of Humean theory that would have such a consequence, consider the following variant on the constant conjunction theory of causation. The theory I’m imagining says that c causes e iff whenever an event of the same type as c occurs within a 50 mile radius of where c occurred, it was followed by an event of type e. Call this the 50 mile constant conjunction theory of causation.3 On the 50 mile constant conjunction theory of causation, it won’t be intrinsic to Ford’s Theatre that it contained a causal event involving Booth shooting Lincoln, but it will be intrinsic to any sphere of radius 50 miles or more centred on the theatre that it contains such a causal event. So on this theory causal properties can be intrinsic to a region, though they are still extrinsic properties of such a region.\n3 I assume here that events can be properly said to have locations. Spelling out this assumption in detail will require some serious metaphysics, particularly when it comes to omissions. Where exactly does my omission to stop the Iraq War take place? Here at my kitchen table where I am? In Iraq, where the war is? In Washington, if that’s where I’d be were I doing something to stop the war? These questions are hard, though not so hard that we should give up on the very natural idea that events have locations.That’s a very implausible Humean theory, but when we look at the details of David Lewis’s Humean picture, we can see the outlines of a more plausible theory with the same consequences. Lewis of course doesn’t offer a simple regularity theory of causation. Rather, he first argues that laws are the extremely simple, extremely informative true propositions (Lewis 1973, 73). That is, he offers a sophisticated regularity theory of laws. Then he analyses counterfactual dependence in terms of lawhood (Lewis 1973, 1979). Finally he analyses causation in terms of counterfactual dependence (Lewis 2004a). The philosophical theory meets the Humean mosaic most closely on the issue of what a law is. If we can offer a theory of laws that allows extra sensitivity to local facts, while remaining Humean, we can plug this back into Lewis’s theories concerning counterfactual dependence and hence causation without upsetting its Humean credentials.\nNow there is a good reason to think that a Humean theory of laws should be locally sensitive. (I’m indebted here to long ago conversations with James Chase.) Humeans typically believe in fairly unrestricted principles of recombination. And they believe that laws are not necessarily true. So there could be worlds with very different laws. So there is a world which ‘patches’ together part of the world with laws L1 with a world with laws L2. If the parts are large and isolated enough, it would be foolish to say that within those parts nothing is law-governed, or that within those regions there is no counterfactual dependence, or no causation. Much better to say that regularities obtaining within such a region are sufficiently simple and informative to count as laws. In our patchwork world, the laws might simply say In r1, L1 and in r2, L2. Provided the terms denoting the regions are not too gruesome, these will plausibly be Humean, even Lewisian, laws.\nLet’s bring all this back to Hawthorne’s example. Hawthorne argues that certain causal facts are intrinsic to the region containing his body. The challenge for the Humean is to say how this could be so when Hawthorne could be embedded in a world where very different regularities obtain. The simple answer is to say that in such worlds, laws like In r, L, where r picks out the region Hawthorne’s body occupies, and L picks out a real-world law, will be true, simple and informative. It is informative because any duplicate of Hawthorne’s body is a very complicated entity, containing billions of billions of particles interacting in systematic ways, ways that are nicely summarised by real-world laws. Simplicity is a little harder to make out, but note that there is a reasonably sharp boundary between Hawthorne’s body and the rest of the world (Lewis 1993), so there should be a natural enough way to pick it out. In other words, even if we embed a Hawthorne duplicate in a world with very different regularities, Humeans will still have good reason to say that the laws, and hence the facts about counterfactual dependence and causation, inside that duplicate are not changed. So not only is it logically possible that Hawthorne’s premises are true and his conclusion false, we can motivate a Humean position that endorses the truth of Hawthorne’s premises and the falsity of the conclusion.\nSince Hawthorne’s argument is invalid then, we can accept the premises without giving up Humeanism. But I think it is worthwhile to note that his (1) also can be questioned. Hawthorne notes that it is rejected by those such as Dretske and Lewis who say that phenomenal character is determined in part by kind membership. (See Lycan (2001) for a longer defence of this kind of rejection of (1).) Hawthorne thinks that the intuitive plausibility of (1) constitutes a serious objection to those views. But by reflecting a little on the phenomenology of what I’ll call totality qualia, we can undermine the intuitive case for (1).\nTweedledee is facing a perfectly symmetrical scene. His visual field is symmetric, with two gentle mountains rising to his left and his right and a symmetric plain in between them. All he can hear are two birds singing in perfect harmony, one behind his left ear and one behind his right ear. The smells of the field seem to envelope him rather than coming from any particular direction. There is a cool breeze blowing directly on his face. It’s a rather pleasant scene, and the overwhelming feeling is one of symmetry.\nTweedledum is very much like Tweedledee. Indeed, Tweedledum contains a duplicate of Tweedledee as a proper part. But Tweedledum also has some sensors in his skin, and brain cells in what corresponds to a suspiciously empty part of Tweedledee’s brain, that allow him to detect, and feel, where the magnetic fields are in the vicinity. And sadly, though Tweedledum is facing a duplicate of the scene facing Tweedledee, there is a major disturbance in the magnetic field just to Tweedledum’s left. This produces a jarring sensation in Tweedledum’s left side. As a consequence, Tweedledum does not share Tweedledee’s feeling of symmetry.\nWhether a picture is symmetric is a property of its internal features, but it is also a feature that can be destroyed without changing the internal features by just adding more material to one side. It is a totality property of pictures, a property the picture has because it stops just where it does.4 Similarly, totality qualia are qualia that we have in part because we don’t have any more feelings than we actually do. Feelings of symmetry are totality qualia in this sense, as are many of the feelings of calm and peacefulness associated with Tweedledee’s state. It is not intuitive that totality qualia should be intrinsic to a region. Indeed, it seems intuitive that a duplicate of me that was extended to produce more sensory features would lack these feelings. Hence a duplicate of me would not share my conscious life in all respects, so Hawthorne’s premise (1) is also false. To be sure, these totality qualia are a somewhat speculative suggestion, but the Humean does not need them since Hawthorne’s anti-Humean argument is invalid.\n\n\n\n4 Ted Sider (2001, 2003) stresses the importance to a theory of intrinsicness of properties that are instantiated in virtue of the object not bearing relations to other objects. My example here is closely modeled on examples from his papers.\n\nReferences\n\nHall, Ned. 2004. “Causation and the Price of Transitivity.” In Causation and Counterfactuals, edited by John Collins, Ned Hall, and L. A. Paul, 181–203. Cambridge: MIT Press.\n\n\nHawthorne, John. 2002. “Deeply Contingent a Priori Knowledge.” Philosophy and Phenomenological Research 65 (2): 247–69. https://doi.org/10.1111/j.1933-1592.2002.tb00201.x.\n\n\n———. 2004. “Humeans Are Out of Their Minds.” Noûs 38 (2): 351–58. https://doi.org/10.1111/j.1468-0068.2004.00473.x.\n\n\nHumberstone, I. L. 1996. “Intrinsic/Extrinsic.” Synthese 108 (2): 205–67. https://doi.org/10.1007/bf00413498.\n\n\nLewis, David. 1973. Counterfactuals. Oxford: Blackwell Publishers.\n\n\n———. 1979. “Counterfactual Dependence and Time’s Arrow.” Noûs 13 (4): 455–76. https://doi.org/10.2307/2215339.\n\n\n———. 1994. “Humean Supervenience Debugged.” Mind 103 (412): 473–90. https://doi.org/10.1093/mind/103.412.473.\n\n\n———. 2004a. “Causation as Influence.” In Causation and Counterfactuals, edited by John Collins, Ned Hall, and L. A. Paul, 75–106. Cambridge: MIT Press.\n\n\n———. 2004b. “Void and Object.” In Causation and Counterfactuals, edited by John Collins, Ned Hall, and L. A. Paul, 277–90. Cambridge: MIT Press.\n\n\nLycan, William. 2001. “The Case for Phenomenal Externalism.” Philosophical Perspectives 15: 17–35. https://doi.org/10.1111/0029-4624.35.s15.2.\n\n\nMcGrath, Sarah. 2005. “Causation by Omission: A Dilemma.” Philosophical Studies 123 (1-2): 125–48. https://doi.org/10.1007/s11098-004-5216-z.\n\n\nMenzies, Peter. 1996. “Probabilistic Causation and the Pre-Emption Problem.” Mind 105 (417): 85–117. https://doi.org/10.1093/mind/105.417.85.\n\n\n———. 1999. “Intrinsic Versus Extrinsic Conceptions of Causation.” In Causation and Laws of Nature, edited by Howard Sankey, 313–29. Dordrecht: Kluwer.\n\n\nSider, Theodore. 2001. “Maximality and Intrinsic Properties.” Philosophy and Phenomenological Research 63 (2): 357–64. https://doi.org/10.1111/j.1933-1592.2001.tb00109.x.\n\n\n———. 2003. “Maximality and Microphysical Supervenience.” Philosophy and Phenomenological Research 66 (1): 139–49. https://doi.org/10.1111/j.1933-1592.2003.tb00247.x.\n\n\nWeatherson, Brian. 2005. “Scepticism, Rationalism and Externalism.” Oxford Studies in Epistemology 1: 311–31."
  },
  {
    "objectID": "posts/bayesdog/index.html",
    "href": "posts/bayesdog/index.html",
    "title": "The Bayesian and the Dogmatist",
    "section": "",
    "text": "There is a lot of philosophically interesting work being done in the borderlands between traditional and formal epistemology. It is easy to think that this would all be one-way traffic. When we try to formalise a traditional theory, we see that its hidden assumptions are inconsistent or otherwise untenable. Or we see that the proponents of the theory had been conflating two concepts that careful formal work lets us distinguish. Either way, the formalist teaches the traditionalist a lesson about what the live epistemological options are. I want to argue, more or less by example, that the traffic here should be two-way. By thinking carefully about considerations that move traditional epistemologists, we can find grounds for questioning some presuppositions that many formal epistemologists make.\nTo make this more concrete, I’m going to be looking at a Bayesian objection to a certain kind of dogmatism about justification. Several writers have urged that the incompatibility of dogmatism with a kind of Bayesianism is a reason to reject dogmatism. I rather think that it is reason to question the Bayesianism. To put the point slightly more carefully, there is a simple proof that dogmatism (of the kind I envisage) can’t be modelled using standard Bayesian modelling tools. Rather than conclude that dogmatism is therefore flawed, I conclude that we need better modelling tools. I’ll spend a fair bit of this paper on outlining a kind of model that (a) allows us to model dogmatic reasoning, (b) is motivated by the epistemological considerations that motivate dogmatism, and (c) helps with a familiar problem besetting the Bayesian.\nI’m going to work up to that problem somewhat indirectly. I’ll start with looking at the kind of sceptical argument that motivates dogmatism. I’ll then briefly rehearse the argument that shows dogmatism and Bayesianism are incompatible. Then in the bulk of the paper I’ll suggest a way of making Bayesian models more flexible so they are no longer incompatible with dogmatism. I’ll call these new models dynamic Keynesian models of uncertainty. I’ll end with a brief guide to the virtues of my new kind of model."
  },
  {
    "objectID": "posts/bayesdog/index.html#sceptical-arguments",
    "href": "posts/bayesdog/index.html#sceptical-arguments",
    "title": "The Bayesian and the Dogmatist",
    "section": "1 Sceptical Arguments",
    "text": "1 Sceptical Arguments\nLet H be some relatively speculative piece of knowledge that we have, say that G. E. Moore had hands, or that it will snow in Alaska sometime next year. And let E be all of our evidence about the external world. I’m not going to make many assumptions about what E contains, but for now E will stay fairly schematic. Now a fairly standard sceptical argument goes something like this. Consider a situation S in which our evidence is unchanged, but in which H is false, such as a brain-in-vat scenario, or a zombie scenario, or a scenario where the future does not resemble the past. Now a fairly standard sceptical argument goes something like this.\n\nTo know H we have to be in a position to know we aren’t in S\nWe aren’t in a position to know that we aren’t in S\nSo, we don’t know H\n\nThere are a few immediate responses one could make, but which I’m going to dismiss without argument here. These include claiming the setup is incoherent (as in, e.g., Williamson (2000)), rejecting the closure principle behind premise 1 (as in, e.g., Dretske (1971), accepting the conclusion (the sceptical response), or saying that in different sceptical arguments, one or other of these positions is correct. Instead I want to look at responses that question premise 2. In particular, I want to look at responses that offer us reasons to accept premise 2, since it seems here that the sceptic is at her strongest. (If the sceptic merely insists that premise 2 is reasonable, we can reply either that it isn’t, as I’m inclined to think, or that here is a case where intuition should be revised.)\nMany epistemologists will write papers responding to ‘the sceptic’. I think this is a mistake, since there are so many different possible sceptics, each with different arguments for premise 2. (And, of course, some sceptics do not argue from sceptical scenarios like this one.) Here are, for instance, three arguments that sceptics might give for premise 2.\n\nSomeone in S can’t discriminate her situation from yours.\nIndiscriminability is symmetric.\nIf you can’t discriminate our situation from S, you can’t know you’re not in S.\nSo you can’t know you’re not in S.\n\n\n\nSomeone in S has the same evidence as you do.\nWhat you can know supervenes on what your evidence is.\nSo, you can’t know you are not in S.\n\n\n\nThere is no non-circular argument to the conclusion that you aren’t in S.\nIf you were able to know you’re not in S, you would be able to produce a non-circular argument that concluded that you aren’t in S.\nSo you can’t know that you aren’t in S.\n\nI won’t say much about these arguments, save that I think in each case the second premise is very implausible. I suspect that most non-philosophers who are moved by sceptical arguments are tacitly relying on one or other of these arguments, but confirming that would require a more careful psychological study than I could do. But set those aside, because there’s a fourth argument that is more troubling. This argument takes its inspiration from what we might call Hume’s exhaustive argument for inductive scepticism. Hume said that we can’t justify induction inductively, and we can’t justify it deductively, and that exhausts the justifications, so we can’t justify induction. A similar kind of argument helps out the general sceptic.\n\nIf you know you aren’t in S, you know this a priori, or a posteriori\nYou can’t know you aren’t in S a posteriori\nYou can’t know you aren’t in S a priori\nSo, you can’t know you aren’t in S\n\nThis seems to be a really interesting argument to me. To make things simpler, I’ll stipulate that by a posteriori knowledge, I just mean knowledge that isn’t a priori. That makes the first premise pretty secure, as long as we’re assuming classical logic.1 Lots of philosophers take its third premise for granted. They assume that since it is metaphysically possible that you could be in S, this can’t be something you can rule out a priori. That strikes me as a rather odd capitulation to infallibilism. But I won’t push that here. Instead I’ll look at denials of the second premise.\n1 Perhaps not a wise assumption around here, but one that I’ll make throughout in what follows."
  },
  {
    "objectID": "posts/bayesdog/index.html#dogmatism-and-a-bayesian-objection",
    "href": "posts/bayesdog/index.html#dogmatism-and-a-bayesian-objection",
    "title": "The Bayesian and the Dogmatist",
    "section": "2 Dogmatism and a Bayesian Objection",
    "text": "2 Dogmatism and a Bayesian Objection\nSomeone who denies the second premise says that your empirical evidence can provide the basis for knowing that you aren’t in S, even though you didn’t know this a priori. I’m going to call such a person a dogmatist, for reasons that will become clear shortly. The dogmatist is not a sceptic, so the dogmatist believes that you can know H. The dogmatist also believes a closure principle, so the dogmatist also believes you can know E \\({\\supset}\\) H. If the dogmatist thought you could know E \\({\\supset}\\) H a priori, they’d think that you could know a priori that you weren’t in S. (This follows by another application of closure.) But they think that isn’t possible, so knowing E \\({\\supset}\\) H a priori isn’t possible. Hence you know E \\({\\supset}\\) H a posteriori.\nIf we reflect on the fact that E is your total evidence, then we can draw two conclusions. The first is that the dogmatist thinks that you can come to know H on the basis of E even though you didn’t know in advance that if E is true, then H is true. You don’t, that is, need antecedent knowledge of the conditional in order to be able to learn H from E. That’s why I’m calling them a dogmatist. The second point is that the dogmatist is now running head on into a piece of Bayesian orthodoxy.\nTo see the problem, note that we can easily prove (A), for arbitrary E, H and K.2\n2 Again, the proof uses distinctively classical principles, in particular the equivalence of A with (A \\({\\wedge}\\) B) \\({\\vee}\\) (A \\({\\wedge}\\) \\({\\lnot}\\)B.) But I will take classical logic for granted throughout. David Jehle pointed out to me that the proof fails without this classical assumption.\n(A)\n\nPr(E \\({\\supset}\\) H E \\({\\wedge}\\) K) \\({\\leq}\\) Pr(E \\({\\supset}\\) H K), with equality iff Pr(E \\({\\supset}\\) H E \\({\\wedge}\\) K) = 1\n\n\nProof:\n\n\n\n\n\n\n\n\n\n1.\nPr(E \\({\\supset}\\) H K) =\n\n\n\n\nPr(E \\({\\supset}\\) H E \\({\\wedge}\\) K) Pr(E K) +\n\n\n\n\nPr(E \\({\\supset}\\) H \\({\\lnot}\\)E \\({\\wedge}\\) K) Pr(\\({\\lnot}\\)E K)\nProb theorem\n\n\n2.\nPr(E \\({\\supset}\\) H \\({\\lnot}\\)E \\({\\wedge}\\) K) = 1\nLogic\n\n\n3.\nPr(E \\({\\supset}\\) H  E \\({\\wedge}\\) K) \\({\\leq}\\) 1\nProb theorem\n\n\n4.\nPr(E \\({\\supset}\\) H K) \\({\\geq}\\)\n\n\n\n\nPr(E \\({\\supset}\\) H E \\({\\wedge}\\) K) Pr(E K) +\n\n\n\n\nPr(E \\({\\supset}\\) H E \\({\\wedge}\\) K) Pr(\\({\\lnot}\\)E K)\n1, 2, 3\n\n\n5.\nPr(E  K) + Pr(\\({\\lnot}\\)E K) = 1\nProb theorem\n\n\n6.\nPr(E \\({\\supset}\\) H K) \\({\\geq}\\) Pr(E \\({\\supset}\\) H E \\({\\wedge}\\) K)\n4, 5\n\n\n\n\nIt is clear enough from the proof that line 6 is an equality iff line 3 is an equality, so we have proven (A). Now some authors have inferred from this something like (B) from (A).3\n3 Roger White (2006) and Stewart Cohen (2005) endorse probabilistic arguments against people who are, in my sense, dogmatists. John Hawthorne (2002) also makes a similar argument when arguing that certain conditionals, much like E \\({\\supset}\\) H, are a priori.\n(B)\n\nIt is impossible to go from not being in a position to know E \\({\\supset}\\) H to being in a position to know it just by receiving evidence E.\n\n\nThe transition here should raise an eyebrow or two. (A) is a principle of probability statics. (B) is a principle of epistemological kinematics. To get from (A) to (B) we need a principle linking probability and epistemology, and a principle linking statics and kinematics. Fortunately, orthodox Bayesian confirmation theory offers us suggestions for both principles. We’ll write Cr(A) for the agent’s credence in A, and CrE(A) for the agent’s credence in A when updated by receiving evidence E.\n\nLearning:\n\nIf CrE(A) \\({\\leq}\\) Cr(A), then it is impossible to go from not being in a position to know A to being in a position to know it just by receiving evidence E.\n\nBayes:\n\nCrE(A) = Cr(A  E). That is, learning goes by conditionalisation.\n\n\nA quick browse at any of the literature on Bayesian confirmation theory will show that these principles are both widely accepted by Bayesians. Philosophers, even Bayesians, make false assumptions, so neither of these principles is obviously true. Nevertheless, I’m going to accept Learning at least for the sake of argument. I’m going to argue instead that the inference from (A) to (B) fails because Bayes fails. That is, I’m going to accept that if we could prove a principle I’ll call Lower is true, then dogmatism in the sense I’m defending it fails.\n\nLower.\n\nCrE(E \\({\\supset}\\) H) is less than or equal to Cr(E \\({\\supset}\\) H).\n\n\nNow there is a bad argument around here that the dogmatist might make. It might be argued that since the Bayesian approach (including Bayes) involves so much idealisation it could not be applicable to real agents. That’s a bad argument because the Bayesian approach might provide us with a good model for real agents, and models can be useful without being scale models. As long as the Bayesian model is the most appropriate model in the circumstances, then we can draw conclusions for the real world from facts about the model. The problem arises if there are alternative models which seem to fit just as well, but in which principles like Lower are not true. If there are alternative models that seem better suited (or at least just as well suited) to modelling the situation of initial evidence acquisition, and those models do not make Lower true, then we might think the derivation of Lower in the Bayesian model is a mere consequence of the arbitrary choice of model. In the next section I will develop just such a model. I won’t argue that it is the best model, let alone the only alternative to the Bayesian model. But I will argue that it is as good for these purposes as the Bayesian model, and it does not imply Lower."
  },
  {
    "objectID": "posts/bayesdog/index.html#bayes-and-keynes",
    "href": "posts/bayesdog/index.html#bayes-and-keynes",
    "title": "The Bayesian and the Dogmatist",
    "section": "3 Bayes and Keynes",
    "text": "3 Bayes and Keynes\nThe traditional Bayesian model of a rational agent starts with the following two principles.\n\nAt any moment, the agent’s credal states are represented by a probability function.\nFrom moment to moment, the agent’s credal states are updated by conditionalisation on the evidence received.\n\nOver recent decades many philosophers have been interested in models that relax those assumptions. One particular model that has got a lot of attention (from e.g. Isaac (Levi 1974, 1980), Richard Jeffrey (1983), Bas Fraassen (1990), Alan (Hájek 2000, 2003) and many others) is what I’ll call the static Keynesian model. This model has the following features.\n\nAt any moment, the agent’s credal states are represented by a set of probability functions, called their representor.\nThe agent holds that p is more probable than q iff the probability of p is greater than the probability of q according to all probability functions in their representor. The agent holds that p and q are equally probable iff the probability of p is equal to the probability of q according to all probability functions in their representor.\nFrom moment to moment, the agent’s credal states are updated by conditionalising each of the functions in the representor on the evidence received.\n\nThe second point is the big attraction. It allows that the agent need not hold that p is more probable than q, or q more probable than p, or that p and q are equally probable, for arbitrary p and q. And that’s good because it isn’t a rationality requirement that agents make pairwise probability judgments about all pairs of propositions. Largely because of this feature, I argued in an earlier paper that this model could be use to formalise the key philosophical ideas in Keynes’s Treatise on Probability. That’s the reason I call this a ‘Keynesian’ model.\nThe modifier ‘static’ might seem a little strange, because the agent’s representor does change when she receives new evidence. But the change is always of a certain kind. Her ‘hypothetical priors’ do not change. If at t1 her evidence is E1 and her representor R1, and at t2 her evidence is E2 and her representor R2, then there is a ‘prior’ representor R0 such that the following two claims are true for all probability functions Pr.\n\nPr \\({\\in}\\) R1 \\({\\leftrightarrow}\\) [\\({\\exists}\\)Pr0 \\({\\in}\\) R0: \\({\\forall}\\)p (Pr(p) = Pr0(p E1)]\nPr \\({\\in}\\) R2 \\({\\leftrightarrow}\\) [\\({\\exists}\\)Pr0 \\({\\in}\\) R0: \\({\\forall}\\)p (Pr(p) = Pr0(p E2)]\n\nThat is, there is a set of probability functions such that the agent’s representor at any time is the result of conditionalising each of those functions on her evidence. I’ll call any model with this property a static model, so the model described above is the static Keynesian model.\nNow there is a lot to like about the static Keynesian model, and I have made extensive use of it previous work. It is a particularly useful model to use when we need to distinguish between risk and uncertainty in the sense that these terms are used in Keynes’s 1937 article “The General Theory of Employment”.4 The traditional Bayesian model assumes that all propositions are risky, but in real life some propositions are uncertain as well, and in positions of radical doubt, where we have little or no empirical evidence, presumably most propositions are extremely uncertain. And using the static Keynesian model does not mean we have to abandon the great work done in Bayesian epistemology and philosophy of science. Since a Bayesian model is a (degenerate) static Keynesian model, we can say that in many circumstances (namely circumstances where uncertainty can be properly ignored) the Bayesian model will be appropriate. Indeed, these days it is something like a consensus among probabilists or Bayesians that the static Keynesian model is a useful generalisation of the Bayesian model. For example in Christensen (2005) it is noted, almost as an afterthought, that the static Keynesian model will be more realistic, and hence potentially more useful, than the traditional Bayesian model. Christensen doesn’t appear to take this as any kind of objection to Bayesianism, and I think this is just the right attitude.\n4 The clearest statement of the distinction that I know is from that paper.\n\nBy ‘uncertain’ knowledge, let me explain, I do not mean merely to distinguish what is known for certain from what is only probable. The game of roulette is not subject, in this sense, to uncertainty; nor is the prospect of a Victory bond being drawn. Or, again, the expectation of life is only slightly uncertain. Even the weather is only moderately uncertain. The sense in which I am using the term is that in which the prospect of a European war is uncertain, or the price of copper and the rate of interest twenty years hence, or the obsolescence of a new invention, or the position of private wealth owners in the social system in 1970. About these matters there is no scientific basis on which to form any calculable probability whatever. We simply do not know. Nevertheless, the necessity for action and decision compels us as practical men to do our best to overlook this awkward fact and to behave exactly as we should if we had behind us a good Benthamite calculation of a series of prospective advantages and disadvantages, each multiplied by its appropriate probability, waiting to be summed. (Keynes 1937, 114–15)\n\nBut just as the static Keynesian is more general than the Bayesian model, there are bound to be interesting models that are more general than the static Keynesian model. One such model is what I call the dynamic Keynesian model. This model has been used by Seth Yalcin to explicate some interesting semantic theories, but to the best of my knowledge it has not been used for epistemological purposes before. That should change. The model is like the static Keynesian model in its use of representors, but it changes the way updating is modelled. When an agent with representor R receives evidence E, she should update her representor by a two step process.\n\nReplace R with U(R, E)\nConditionalise U(R, E), i.e. replace it with {Pr( E): Pr is in U(R, E)}\n\nIn this story, U is a function that takes two inputs: a representor and a piece of evidence, and returns a representor that is a subset of the original representor. Intuitively, this models the effect of learning, via getting evidence E, what evidential relationships obtain. In the static Keynesian model, it is assumed that before the agent receives evidence E, she could already say which propositions would receive probabilistic support from E. All of the relations of evidential support were encoded in her conditional probabilities. There is no place in the model for learning about fundamental evidential relationships. In the dynamic Keynesian model, this is possible. When the agent receives evidence E, she might learn that certain functions that were previously in her representor misrepresented the relationship between evidence and hypotheses, particularly between evidence E and other hypotheses. In those cases, U(R, E) will be her old representor R, minus the functions that E teaches her misrepresent these evidential relationships.\nThe dynamic Keynesian model seems well suited to the dogmatist, indeed to any epistemological theory that allows for fundamental evidential relationships to be only knowable a posteriori. As we’ll see below, this is a reason to stop here in the presentation of the model and not try and say something systematic about the behaviour of U. Instead of developing the model by saying more about U, we should assess it, which is what I’ll do next."
  },
  {
    "objectID": "posts/bayesdog/index.html#in-defence-of-dynamism",
    "href": "posts/bayesdog/index.html#in-defence-of-dynamism",
    "title": "The Bayesian and the Dogmatist",
    "section": "4 In Defence of Dynamism",
    "text": "4 In Defence of Dynamism\nIn this section I want go over three benefits of the dynamic Keynesian model, and then say a little about how it relates to the discussion of scepticism with which we opened. I’m not going to say much about possible objections to the use of the model. That’s partially for space reasons, partially because what I have to say about the objections I know of is fairly predictable, and partially because the model is new enough that I don’t really know what the strongest objections might be. So here we’ll stick to arguments for the view.\n\n4.1 The Dogmatist and the Keynesian\nThe first advantage of the dynamic Keynesian model is that because it does not verify Lower, it is consistent with dogmatism. Now if you think that dogmatism is obviously false, you won’t think this is much of an advantage. But I tend to think that dogmatism is one of the small number of not absurd solutions to a very hard epistemological problem with no obvious solution, so we should not rule it out pre-emptively. Hence I think our formal models should be consistent with it. What is tricky is proving that the dynamic Keynesian model is indeed consistent with it.\nTo see whether this is true on the dynamic Keynesian model, we need to say what it is to lower the credence of some proposition. Since representors map propositions onto intervals rather than numbers, we can’t simply talk about one ‘probability’ being a smaller number than another.5 On the static Keynesian model, the most natural move is to say that conditionalisation on E lowers the credence of p iff for all Pr in the representor, Pr(p) &gt; Pr(p  E). This implies that if every function in the representor says that E is negatively relevant to p, then conditionalising on E makes p less probable. Importantly, it allows this even if the values that Pr(p) takes across the representor before and after conditionalisation overlap. So what should we say on the dynamic Keynesian model? The weakest approach that seems viable, and not coincidentally the most plausible approach, is to say that updating on E lowers the credence of p iff the following conditions are met:\n5 Strictly speaking, the story I’ve told so far does not guarantee that for any proposition p, the values that Pr(p) takes (for Pr in the representor) form an interval. But it is usual in more detailed presentations of the model to put constraints on the representor to guarantee that happens, and I’ll assume we’ve done that.\nFor all Pr in U(R, E), Pr(p E) &lt; Pr(p)\nFor all Pr in R but not in U(R, E), there is a Pr\\(^\\prime\\) in U(R, E) such that Pr\\(^\\prime\\)(p  E) &lt; Pr(p)\n\nIt isn’t too hard to show that for some models, updating on E does not lower the credence of E \\({\\supset}\\) H, if lowering is understood this way. The following is an extreme example, but it suffices to make the logical point. Let R be the minimal representor, the set of all probability functions that assign probability 1 to a priori certainties. And let U(R, E) be the singleton of the following probability function, defined only over Boolean combinations of E and H: Pr(E \\({\\wedge}\\) H) = Pr(E \\({\\wedge}\\) \\({\\lnot}\\)H) = Pr(\\({\\lnot}\\)E \\({\\wedge}\\) H) = Pr(\\({\\lnot}\\)E \\({\\wedge}\\) \\({\\lnot}\\)H) = \\(\\frac{1}{4}\\). Then the probability of E \\({\\supset}\\) H after updating is \\(\\frac{3}{4}\\). (More precisely, according to all Pr in U(R, E), Pr(E \\({\\supset}\\) H) = \\(\\frac{3}{4}\\).) Since before updating there were Pr in R such that Pr(E \\({\\supset}\\) H) &lt; \\(\\frac{3}{4}\\), in fact there were Pr in R such that Pr(E \\({\\supset}\\) H) = 0, updating on E did not lower the credence of E \\({\\supset}\\) H. So the dynamic Keynesian model does not, in general, have as a consequence that updating on E lowers the credence of E \\({\\supset}\\) H. This suggests that Lower in general is not true.\nIt might be objected that if evidence E supports our knowledge that E \\({\\supset}\\) H, then updating on E should raise the credence of E \\({\\supset}\\) H. And if we define credence raising the same way we just defined credence lowering, updating on E never raises the credence of E \\({\\supset}\\) H. From a Keynesian perspective, we should simply deny that evidence has to raise the credence of the propositions known on the basis of that evidence. It might be sufficient that getting this evidence removes the uncertainty associated with those propositions. Even on the static Keynesian model, it is possible for evidence to remove uncertainty related to propositions without raising the probability of that proposition. A little informally, we might note that whether an agent with representor R is sufficiently confident in p to know that p depends on the lowest value that Pr(p) takes for Pr \\({\\in}\\) R, and updating can raise the value of this ‘lower bound’ without raising the value of Pr(p) according to all functions in R, and hence without strictly speaking raising the credence of p.\nThe above illustration is obviously unrealistic, in part because U could not behave that way. It’s tempting at this stage to ask just how U does behave so we can work out if there are more realistic examples. Indeed, it’s tempting to try to attempt to provide a formal description of U. This temptation should be resisted. The whole point of the model is that we can only learn which hypotheses are supported by certain evidence by actually getting that evidence. If we could say just what U is, we would be able to know what was supported by any kind of evidence without getting that evidence. The best we can do with respect to U is to discover some of its contours with respect to evidence much like our own. And the way to make those discoveries will be to do scientific and epistemological research. It isn’t obvious that, say, looking for nice formal properties of U will help at all.\n\n\n4.2 The Problem of the Priors\nOne really nice consequence of the dynamic Keynesian approach is that it lets us say what the representor of an agent with no empirical information should be. Say a proposition is a priori certain iff it is a priori that all rational agents assign credence 1 to that proposition. Then the representor of the agent with no empirical evidence is {Pr: \\({\\forall}\\)p: If p is a priori certain, then Pr(p) = 1}. This is the minimal representor I mentioned above. Apart from assigning probability 1 to the a priori certainties, the representor is silent. Hence it treats all propositions that are not a priori certain in exactly the same way. This kind of symmetric treatment of propositions is not possible on the traditional Bayesian conception for logical reasons. (The reasons are set out in the various discussions of the paradoxes of indifference, going back to Bertrand (1888).) Such a prior representor is consistent with the static Keynesian approach, but it yields implausible results, since conditionalising on E has no effect on the distribution of values of Pr(p) among functions in the representor for any p not made a priori certain by E. (We’ll say p is made a priori certain by E iff E \\({\\supset}\\) p is a priori certain.) So if this is our starting representor, we can’t even get probabilistic evidence for things that are not made certain by our evidence.6 So on the static Keynesian model, this attractively symmetric prior representor is not available.\n6 The argument in the text goes by a little quickly, because I’ve defined representors in terms on unconditional probabilities and this leads to complications to do with conditionalising on propositions of zero probability. A better thing to do, as suggested by Hájek (2003), is to take conditional probability as primitive. If we do this we’ll define representors as sets of conditional probability functions, and the a priori representor will be {Pr: If p \\({\\supset}\\) q is a priori certain, then Pr(q p) = 1}. Then the claim in the text will follow.I think one of the motivations of anti-dogmatist thinking is the thought that we should be able to tell a priori what is evidence for what. If it looking like there is a cow in front of us is a reason to think there is a cow in front of us, that should be knowable a priori. I think the motivation for this kind of position shrinks a little when we realise that an a priori prior that represented all the connections between evidence and hypotheses would have to give us a lot of guidance as to what to do (epistemically speaking) in worlds quite unlike our own. Moreover, there is no reason we should have lots that information. So consider, for a minute, a soul in a world with no spatial dimensions and three temporal dimensions, where the primary source of evidence for souls is empathic connection with other souls from which they get a (fallible) guide to those souls’ mental states. When such a soul conditionalises on the evidence “A soul seems to love me” (that’s the kind of evidence they get) what should their posterior probability be that there is indeed a soul that loves them? What if the souls have a very alien mental life, so they instantiate mental concepts very unlike our own, and souls get fallible evidence of these alien concepts being instantiated through empathy? I think it’s pretty clear we don’t know the answers to these questions. (Note that to answer this question we’d have to know which of these concepts were grue-like, and which were projectable, and there is no reason to believe we are in a position to know that.) Now those souls are presumably just as ignorant about the epistemologically appropriate reaction to the kinds of evidence we get, like seeing a cow or hearing a doorbell, as we are about their evidence. The dynamic Keynesian model can allow for this, especially if we use the very weak prior representor described above. When we get the kind of evidence we actually get, the effect of U is to shrink our representors to sets of probability functions which are broadly speaking epistemically appropriate for the kind of world we are in. Before we got that evidence, we didn’t know how we should respond to it, just like the spaceless empathic souls don’t know how to respond to it, just like we don’t know how to respond to their evidence.\nIt is a commonplace observation that (a) prior probabilities are really crucial in Bayesian epistemology, but (b) we have next to no idea what they look like. I call this the problem of the priors, and note with some satisfaction that the dynamic Keynesian model avoids it. Now a cynic might note that all I’ve done is replace a hand-wavy story about priors with a hand-wavy story about updating. That’s true, but nevertheless I think this is progress. The things I’m being deliberately unclear about, such as what U should look like for E such as “Some other non-spatial tri-temporal soul seems to love me” are things that (a) my theory says are not a priori knowable, and (b) I don’t have any evidence concerning. So it isn’t surprising that I don’t have much to say about them. It isn’t clear that the traditional Bayesian can offer any story, even by their own lights, as to why they are less clear about the structure of the prior probability conditional on such an E.\n\n\n4.3 The Problem of Old Evidence\nWhen we get evidence E, the dynamic Keynesian model says that we should do two things. First, we should throw out some probability functions in our representor. Second, we should conditionalise those that remain. But this is a normative condition, not a description of what actually happens. Sometimes, when we get evidence E, we may not realise that it is evidence that supports some theory T. That is, we won’t sufficiently cull the representor of those probability functions where the probability of T given E is not high. Housecleaning like this is hard, and sometimes we only do it when it becomes essential. In this case, that means we only do it when we start paying serious attention to T. In that case we may find that evidence E, evidence we’ve already incorporated, in the sense of having used in conditionalisation, gives us reason to be more confident than we were in T. In such a case we’ll simply cull those functions where probability of T given E is not high, and we will be more confident in T. That’s how old evidence can be relevant on the dynamic Keynesian model. Since we have a story about how old evidence can be relevant, there is no problem of old evidence for the dynamic Keynesian.\nFamously, there is a problem of old evidence for traditional Bayesians. Now I’m not going to rehearse all the arguments concerning this problem to convince you that this problem hasn’t been solved. That’s in part because it would take too long and in part because I’m not sure myself that it hasn’t been solved. But I will note that if you think the problem of old evidence is a live problem for traditional Bayesians, then you have a strong reason for taking the dynamic Keynesian model seriously.\n\n\n4.4 Why Should We Care?\nThe sceptic’s opening move was to appeal to our intuition that propositions like E \\({\\supset}\\) H are unknowable. We then asked what reasons we could be given for accepting this claim, because the sceptic seems to want to derive quite a lot from a raw intuition. The sceptic can respond with a wide range of arguments, four of which are mentioned above. Here we focussed on the sceptic’s argument from exhaustion. E \\({\\supset}\\) H isn’t knowable a priori, because it could be false, and it isn’t knowable a posteriori, because, on standard models of learning, our evidence lowers its credibility. My response is to say that this is an artefact of the model the sceptic (along with everyone else) is using. There’s nothing wrong with using simplified models, in fact it is usually the only way to make progress, but we must be always wary that our conclusions transfer from the model to the real world. One way to argue that a conclusion is a mere artefact of the model is to come up with a model that is sensitive to more features of reality in which the conclusion does not hold. That’s what I’ve done here. The dynamic Keynesian model is sensitive to the facts that (a) there is a distinction between risk and uncertainty and (b) we can learn about fundamental evidential connections. In the dynamic Keynesian model, it isn’t true that our evidence lowers the probability of E \\({\\supset}\\) H. So the anti-sceptic who says that E \\({\\supset}\\) H is knowable a posteriori, the person I’ve called the dogmatist, has a defence against this Bayesian argument. If the response is successful, then there may well be other applications of the dynamic Keynesian model, but for now I’m content to show how the model can be used to defend the dogmatic response to scepticism."
  },
  {
    "objectID": "posts/gunk/index.html",
    "href": "posts/gunk/index.html",
    "title": "Chopping up Gunk",
    "section": "",
    "text": "Atomism, the view that indivisible atoms are the basic building blocks of physical reality, has a distinguished history. But it might not be true. The history of physical science certainly gives many of us pause. Every time some class of objects appeared to be the entities that Newton had described as “solid, massy, hard, impenetrable, movable Particles” out of which “God in the Beginning formed Matter” (Newton 1952, 400), further research revealed that these objects were divisible after all. One might be tempted to see that history as confirming Leibniz’ dismissal of atomism as a “youthful prejudice” .1 Perhaps material objects and their parts are always divisible. There are no extended atoms; nor are there point particles which compose material beings.2\n1 See ‘Nature Itself’ in (Leibniz 1998, 220).2 Cf Leibniz: ‘I hold that matter is essentially an aggregate, and consequently that it always has actual parts,’ in ‘Third Explanation of The New System,’ (Leibniz 1998, 193).When first presented with this hypothesis, our imaginations are quickly drawn to picturing the process whereby a quantity of such matter – call it gunk -- is chopped up into smaller and smaller pieces. Prima facie, there is nothing problematic here: insofar as such a process continues without end, the initial quantity gets resolves into smaller and smaller chunks with no limit to the diminution. But suppose this process is packed into an hour, as imagined by Jose Bernadete (1964) in his 1964 monograph Infinity:\n\nTake a stick of wood. In 1/2 minute we are to divide the stick into two equal parts. In the next 1/4 minute we are to divide each of the two pieces again into two equal parts. In the next 1/8 minute we are to divide each of the four pieces (for there are now four equal pieces) again into two equal parts, &c. ad infinitum (Bernadete 1964, 184).\n\nIf matter is divisible without end there seems to be no conceptual obstacle to each of the divisions. Yet how are we to imagine the situation at the end of the hour, when the super-task (call it ‘super-cutting’) has been performed on a quantity of gunk?3\n3 What is important, of course, is that the sequence of separations occur: it does not matter whether some kind of super-sharp knife is responsible for them. In what follows, descriptions of cutting sequences can be replaced without loss of content by descriptions of separation sequences, leaving it open whether repulsive forces or chance events or knives or … are responsible for the separation sequence.If there were extended atoms that were never annihilated, it is clear enough what would happen if some super-being undertook to perform super-cutting: the process would grind to a halt when insurmountably hard particles resisted the chopper.\nIf, meanwhile, there were point-sized particles that composed planes that were as thin as a line, it would be natural to picture the limit of the process as a sea of separated slivers, each devoid of finite extent along one dimension. As Benardete, notes, one might then redo super-cutting in order to finally resolve the original stick into a sea of “metaphysical motes” devoid of finite extent in any direction:\n\nAt the end of the minute how many pieces of wood will we have laid out before us? Clearly an infinite number. If the original stick was twenty inches in length, one inch in width, and one inch in depth, what are the dimensions of the metaphysical chips into which the stick has been decomposed? Each chip will be one inch by one inch by one inch by – what? So prodigiously thin must each chip be that its value is certifiably less then any rational (or irrational) quantity. Let us now take up one of the metaphysical chips and decompose it further into an infinite number of metaphysical splinters. In 1/2 minute we shall divide the chip into two equal parts. Each pieces will be one inch by 1/2 inch. In the next 1/4 minute we shall divide each of the two pieces again into two equal parts, yielding four pieces each being one inch by 1/4 inch. In the next 1/8 minute we shall divide each of the four pieces again into two equal parts, &c ad infinitum. At the end of the mute we shall have composed the metaphysical chip into metaphysical splinters. Each splinter will be one inch in length. Let us now take up one of the metaphysical splinters and break it down into an infinite number of metaphysical motes (Bernadete 1964, 184–85)\n\nThe number of cuts made on the stick, the chip and the splinter respectively is aleph zero. The number of chips, splinters and motes left at the end of each cutting process, meanwhile, is aleph one. (Think of numbering each piece in a super-cutting process by an infinite expansion of one’s and zero’s as follows: if it lay on the left of the first cut, the first numeral is a zero, if to the right, the first numeral is a one; it if lay on the left of one of the pieces that was divided at the second round of cutting its second numeral is a zero, if to the right a one; and so on. For each decimal expansion of one’s and zero’s there is a bit and the end with that expansion.). This result is surprising to some, but poses no deep conceptual confusion. With an ontology of chips, splinters and motes available to us, there is a natural description available to us of the limit to the super-cutting processes described.\nBut what to say when gunk is subjected to super-cutting? If each quantity of matter has proper parts, then a sea of metaphysical motes is not, it would seem, an available outcome. In what follows, we unpack this puzzle, providing along the way some a priori physics for gunk-lovers. The problem is only well formed when we make explicit some of the assumptions that drive it. We do so below:\n\n\nGunk\n\nEvery quantity of matter has proper parts.\n\nConservation of Matter:\n\nNo mereological sum of quantities of matter can be destroyed by any sequence of cuts (though it may be scattered)4.\n4 The ‘can’ here is one of nomological possibility.\nOccupation\n\nIf a quantity of matter occupies a point of space, then there is some volume, extended in all dimensions, to which that point belongs which that quantity of matter occupies.\n\nSuper-cutting\n\nThe laws of the world permit super-cutting.\n\nNote that (1), the thesis that every quantity of matter has parts does not, by itself, entail any of the other theses. One might also think that matter sometimes vanishes as a result of some sequence of cuts, denying (2). One might hold that there are metaphysical splinters (and perhaps even chips), denying (3). One might hold that any given quantity of matter does have point sized pieces but that those pieces themselves have parts (the parts being of the same size as the whole in this case), denying (3). One might hold that some pieces of gunk can occupy, say, a spherical region and also a single isolated point at some considerable distance from the spherical region (while maintaining that no part of it merely occupies the point), also denying (3). One might imagine that while always having parts, the parts below a certain thickness are inseparable, denying (4). One might think there is a minimum amount of time that any event of separation takes, also denying (4) and so on.\nIf the gunk hypothesis is maintained, but one or more of (2) to (4) is jettisoned, there is no problem left to solve. For example: If we are allowed to suppose that gunk may vanish, then it will be perfectly consistent to say that nothing is left at the limit of super-cutting. If we are allowed parts that lack finite extent, then it will be consistent to adopt Benardete’s picture of the outcome. And so on. Our puzzle, properly formulated is: What would happen if super-cutting occurred in a world where (1) to (4) are true?\nIn order to answer that question, we need to supplement Bernadete’s brief discussion of the super-cutting process. It is not immediately clear from what he says that super-cutting a piece of wood will turn an object into chips, even assuming the wood to be composed of point particles. That is a natural description of the limit of the process, but it is hardly one that is forced upon us by the barebones description of the process that Benardete provides. When we divide the stick into two pieces, and then into four pieces, where are we to put these pieces? Presumably we must ensure that they are separated. If not, it will not be clear that we really have splinters left at the end. If the stick is cut into four, but the four pieces are then stored so closely together that they are not scattered any more, then we will not have four scattered objects after two rounds of cutting. By extension, unless we separate the pieces sufficiently after each round (or at least after sufficiently many of them) then even in a world where matter is composed of point particles, it is not clear that there will be infinitely many chips left at the end. Note in this connection that there are limits as to how far we can separate the objects. In a world where super-cutting produces chips, we could not, from left to right, put a one inch gap between each chip and any other, since there are aleph one chips and not aleph one inches of space along any vector. Nor is it even clear what kind of spacing will do the trick: how we are to keep aleph one chips separated from each other? What we need is a formal model showing how super-cutting is to be performed. Only then can we answer with any precision what would happen were super-cutting to be performed on gunk.\nAssume, for simplicity, that we have a stick that is exactly one inch long. At the first stage, cut the stick into two 1/2 inch long pieces, move the left-hand one 1/4 inch leftwards and the right hand one 1/4 inch rightwards. This can be accomplished in 1/2 second without moving the objects at a speed of faster than 1 inch per second, or accelerating or decelerating the objects at a rate higher than 4 inches per second per second.5 At the second stage, cut each piece into two, and move each of the left-hand pieces 1/16 of an inch leftwards, and each of the right-hand pieces 1/16 of an inch rightwards. So if the original piece occupied the interval [0, 1) on a particular axis, the four pieces will now occupy the intervals: [-5/16, -1/16), [1/16, 5/16), [11/16, 15/16), [17/16, 21/16). (The reason we are using these half-open intervals is to avoid questions about whether the objects that are separated by the cut used to overlap.) This cutting and moving can be accomplished in 1/4 of a second, without any piece attaining a velocity higher than 1/2 inch per second, or an acceleration higher than 4 inches per second per second.\n5 The idea is that in the first quarter second we accelerate the object at 4 inches per second per second. This will raise its velocity to 1 inch per second, and move the object 1/8 of an inch. In the second quarter second we decelerate it at 4 inches per second per second, so its velocity ends up at zero, and it ends up having moved 1/4 of an inch.6 Note that, interestingly, if we moved the pieces 1/2 inch after the first round, 1/4 inch after the second round, 1/8 inch after the third round and so on then at the limit, each left and right edge that was once attached will have moved back together again. The process we have chosen preserves separation in a way that the aforementioned process does not.The third stage of the cutting is to take each of these four pieces, cut them in two, move the left-hand part of each of the four 1/64 of an inch to the left, and the right-hand part 1/64 of an inch to the right. So the eight pieces now occupy the intervals: [-21/64, -13/64), [-11/64, -3/64), [3/64, 11/64), [13/64, 21/64), [43/64, 51/64), [53/64, 61/64), [67/64, 75/64), [77/64, 85/64). Again, this cutting and moving can be accomplished within 1/8 of a second, without any piece attaining a velocity higher than 1/4 inch per second, or an acceleration higher than 4 inches per second per second.6\nIn general, at stage n, we take the 2n pieces, divide each of them in two, move the left-hand piece 1/22n inches leftward, and the right-hand piece 1/22n inches rightward. This can all be done in 1/2n seconds without any piece attaining a velocity higher than 1/2n-1 inches per second, or an acceleration higher than 4 inches per second per second. So the whole super-cut can be performed in 1 second: the first stage in 1/2 second, the second stage in 1/4 second, the third stage in 1/8 second, and so on. Note, moreover, that the whole super-cut can be performed in a second without the pieces ever moving at any huge velocity. If readers doubted the possibility of super-cutting because they believed it to be a necessary truth that no matters travels at or beyond the speed of light, their doubts were misplaced: no piece of matter in the super-cutting process approaches a superluminous velocity.\nFurther, in this kind of procedure, a quantity of matter that is scattered during the super-cutting process remains scattered during the process. To see this, first consider a particular example. We noted above that at the second stage there were pieces occupying the intervals [-5/16, -1/16) and [1/16, 5/16). Before this, the point 0 had been occupied; at this stage a gap of 1/8 inch around 0 had been opened. This gap keeps being closed at each stage. After the third stage there were pieces occupying the intervals [/64, -3/64), [3/64, 11/64), so the gap is now only 3/32 inch. After the fourth stage, there will be pieces at [-27/256, -11/256), [11/256, 27/256), so the gap is now only 11/128 inch. This process will make the gap ever smaller, but will not lead to its closure. As the process continues, the size of the gap will approach 1/12 of an inch, but never cross that boundary. To see this, note that the size of the gap in inches after stage n (n \\({\\geq}\\) 3) is 1/8 - 1/25 - 1/27 - … - 1/22n. The sum of the series 1/25 + 1/27 + … is 1/24. Hence the gap at stage n is greater than 1/8 - 1/24 = 1/12. So once the pieces around 0 have been separated, they will never be rejoined.\nThis result applies generally to all of the separated pieces in the super-cut. Once a gap is created, parts of pieces from either side of the gap are moved ever closer to the centre of the gap at every subsequent stage of the super-cut. But since we decrease the distance moved by each piece at each stage of the cut, and in particular decrease it by a factor greater than 2, the pieces, once disjointed, will never be united.\nHow is the matter arranged at the end of the super-cut? To answer this question we need to assume that motion is continuous. For each part of the object we can calculate its position function, the function from the length of time the super-cut has been in progress to the position of the part. At least, we can calculate this for all times until the end of the super-cut. With the continuity assumption in place we can infer that its position at the end of the cut is the limiting value of its position function. So we make this assumption.\nWe assumed above that there is a Cartesian axis running along the object; say that a part a covers a point x just in case a occupies some region [y, z), and y \\({\\leq}\\) x and z &gt; x. When we say a occupies [y, z), we do not mean to imply it occupies only that region, just that it occupies at least that region. Assume then that a part a occupies a point x (0 \\({\\leq}\\) x &lt; 1), and that the binary representation of x is 0.x1x2…xn…, where for each xi, xi equals 0 or 1, and for all i, there exists a j &gt; i such that xj equals zero.7 If x1 = 1, then x \\({\\geq}\\) 1/2, so the some part of a, a small part that originally covered x, will be moved rightward at the first stage. It is possible that a itself may be split by the cut, but there will be a small part around x that is not split, and it will move rightward. If x1 = 0, then x &lt; 1/2, so some part of a, a small part that originally covered x, will be moved leftward at the first stage. Indeed, in general some part of a, a small part that originally covered x, will be moved rightward at the n’th stage if xn = 1, and some part of a, a small part that originally covered x, will be moved leftward at the n’th stage if xn = 0.\n7 The final condition is important to rule out numbers having two possible representations. For example, we have to choose whether the representation of 1/2 should be 0.1000… or 0.0111…, and we somewhat arbitrarily, choose the former.Using the fact that a part gets moved 2-2n inches at stage n, we can infer that after n stages, a small part that originally covered x and has not been split by the cuts will cover the following point after n cuts. \\[x + \\frac{(-1)^{x_1 + 1}}{4} + \\frac{(-1)^{x_2 + 1}}{16} + \\dots + \\frac{(-1)^{x_n + 1}}{2^{2n}}\\]\nAssuming continuity of motion, we can assume that a will end up with a part that eventually covers the following point, which we will call f(x). \\[f(x) = x + \\sum_{i=1}^{\\infty}\\frac{(-1)^{x_i + 1}}{2^{2i}}\\]\nFrom this, it follows immediately that for all x in [0, 1), f(x) will end up being occupied. It turns out that these are the only points that are occupied at the end of the super-cut.\nAssume that a point y is occupied at the end of the super-cut. We will construct a number c such that y = f(c). Recall that we noted above that whenever two pieces were separated, a gap was created between them that would never be completely filled. While parts of the stick would move closer and closer to the centre of that gap during the super-cut, the middle two-thirds of the gap would never be reoccupied. That interval, that would never be reoccupied, would be liberated. The interval [1/3, 2/3) is liberated at the first stage, the intervals [-1/24, 1/24) and [23/24, 25/24) are liberated at the second stage, the intervals [-37/192, -35/192), [35/192, 37/192), [155/192, 157/192) and [227/192, 229/192) are liberated at the third stage, and so on. If y is occupied, then y must not be in any liberated interval. Therefore it must be either to the left or to the right of any interval that is liberated.\nLet c1 equal 0 if y is to the left of the first liberated interval, [1/3, 2/3), and 1 otherwise. Given the value of c1, it is already determined which side y is of one of the intervals liberated at the second stage. If y is to the left of [1/3, 2/3), for example, then it is to the left of [23/24, 25/24). But the value of c1 does not determine which side y is of the other interval. Let c2 equal 0 if y is to the left of that interval, and 1 otherwise. The values of c1 and c2 determine which side y is of three of the four intervals liberated at the fourth stage, but leave open which side it is of one of these four. Let c3 equal 0 if y is to the left of that interval, 1 otherwise. If we repeat this procedure for all stages, we will get values of ci for all i. Let c be the number whose binary expansion is 0.c1c2…cn…. It follows that y = f(c). The reason once it is determined which side y is of each of the liberated intervals, y has been determined to fall in an interval that is exactly one point wide, and f(c) is in that interval, so f(c) must equal y. So y is occupied iff for some x, y = f(x). Say S = {y: \\({\\exists}\\)x (y = f(x))}; the conclusion is that all and only the points in S are occupied.\nCould a piece of gunk occupy the points in S? Not given the assumptions we have made so far. S has two properties that might not seem consistent at first glance. It is dense in the sense that for any point y in S, and any distance \\({\\delta}\\), there is another point z in S such that y - z &lt; \\({\\delta}\\). But it is disconnected in the sense that for any two points y and z in S, there is an extended region r between y and z that is wholly unoccupied. The proofs of density and disconnectedness are given in the appendix.\nGiven (3), disconnectedness is inconsistent with gunk occupying S. If a material object occupies S, it must occupy the points in S. Let y be any one of these points. By (3), S must occupy some extended region containing y, say, [y1, y2). Two cases to consider. First case: y1 &lt; y. If [y1, y2) \\({\\subset}\\) S, then y1 and y are in S, and so are all the points in between them. Since the object occupies S, it follows that these points are occupied. Hence there is no extended region between y1 and y that is wholly unoccupied, which is inconsistent with disconnectedness. Second case: y1 = y. Again, [y1, y2) \\({\\subset}\\) S, and since this interval is non-empty, y2 &gt; y1. Hence (y1 + y2) / 2 is greater than y1, and all the points between it and y1 are occupied. This is also inconsistent with disconnectedness. So given (3), no material object could occupy S.\nIn summary, (1) through (4) plus continuity of motion cannot be true together. From (1), (2), and (4), we inferred that our super-cutting process was possible, and that it would not destroy any quantity of matter (though of course it would scatter it). Assuming continuity of motion, we calculated which points would be occupied after the super-cut. By (3) we concluded that no piece of gunk could occupy those points, or indeed any subset of them, yielding an inconsistent result. Suppose that the continuity of motion thesis is dropped. We can then maintain (1) to (4) with consistency. One should note, however, that a world where (1) to (4) holds would be a strange world indeed: if super-cutting is performed, the pieces of gunk would have to jump location at the limit. The gunk cannot occupy S: but in order to occupy a different set of points, various quantities of matter would have to jump position at the limit.\nIf one believes in gunk one has a choice: Abandon one or more of (2) to (4) or else deny that it is nomologically necessary that motion be continuous. Which assumption should be dropped? We leave it to the gunk lover to select the most tolerable package. The choice for the gunk lover is a little unenviable. Those who are attracted to the view that the actual world is gunky are very much wedded to (1) and (3). When philosophers take seriously the idea that that matter has parts all the way down8, they do not imagine conjoining that thesis with point sized parts, or else immaterial parts9, or else quantities of matter that are as thin as a plane, and so on. With a commitment to (1) and (3) in place, super-cutting will be loaded with physical significance. Accept that the laws of nature permits super-cutting and one will be committed to either denying the conservation of matter or the continuity of motion.\n8 See, for example, (Zimmerman 1996).9 Leibniz, with his monads, is an exception of course. No contemporary gunk lover wants a monadology, however.\nAppendix\nTo prove density, note that if y is occupied, there is a point x with binary representation 0.x1x2… such that y = f(x). For any positive \\({\\delta}\\), there is an integer n such that \\({\\delta}\\) &gt; 2-2n. Let v be the number represented by 0.x1x2…xnxn+1\\(^\\prime\\)xn+2xn+3…, where xn+1\\(^\\prime\\) = 1 iff xn+1 = 0, and xn+1\\(^\\prime\\) = 0 otherwise. The difference between f(x) and f(v) will be exactly 2-2n-1. Since f(v) is occupied, and y = f(x), there is an occupied point exactly 2-2n-1 inches from y, so there is a point less than \\({\\delta}\\) inches from y, as required.\nTo prove disconnectedness, let y and z be any two distinct occupied points. So for some distinct v, x, y = f(x) and z = f(v). Say that the binary representation of x is 0.x1x2…, and the binary representation of v is 0.v1v2… Let j be the lowest number such that xj \\({\\neq}\\) vj. (Since x and v are distinct, there must be at least one value j.) Without loss of generality, assume that xj = 0 and vj = 1. (There is no loss of generality because we are just trying to show that between any two occupied points there is a gap, so it does not matter which of the two points is the rightward one.) Let k be the number with binary representation 0.x1x2…xj1, and let l2 be f(k). Finally, define l1 by the following equation: \\[l_i = \\sum_{i=1}^j \\frac{(-1)^{x_i+1}}{2^{2i}} + \\sum_{i = j+1}^\\infty \\frac{1}{2^{2i}}\\]\nIt is easy enough to see that f(x), that is y, must be less that l1. For l1 is the value that f(x) would take were every digit in the binary expansion of x after j be 1. But by definition there must be some value j\\(^\\prime\\) &gt; j such that xj\\(^\\prime\\) = 0. From this it follows that: \\[\\sum_{i = j+1}^\\infty \\frac{1}{2^{2i}} &gt; \\sum_{i = j+1}^\\infty \\frac{(-1)^{x_i+1}}{2^{2i}}\\]\nAnd from that it follows that l1 &gt; f(x). Indeed, by similar reasoning, it follows that for all u &lt; k, f(u) &lt; l1. Since f is monotone increasing, it also follows that for all u \\({\\geq}\\) k, f(u) \\({\\geq}\\) l2. And from those facts, it follows that there does not exist a u such that f(u) \\({\\in}\\) [l1, l2). And since y &lt; l1 &lt; l2 \\({\\leq}\\) z, this implies that there is an extended unoccupied region between y and z, as required.\n\n\n\n\n\n\nReferences\n\nBernadete, Jose. 1964. Infinity: An Essay in Metaphysics. Oxford: Clarendon Press.\n\n\nLeibniz, Gottfried Wilhelm. 1998. Philosophical Texts. Translated by R. S. Woolhouse and Richard Francks. Oxford: Oxford University Press.\n\n\nNewton, Isaac. 1952. Opticks. New York: Dover Press.\n\n\nZimmerman, Dean. 1996. “Could Extended Objects Be Made Out of Simple Parts: An Argument for Atomless Gunk.” Philosophy and Phenomenological Research 56 (1): 1–29. https://doi.org/10.2307/2108463."
  },
  {
    "objectID": "posts/naturalness/index.html",
    "href": "posts/naturalness/index.html",
    "title": "The Role of Naturalness in Lewis’s Theory of Meaning",
    "section": "",
    "text": "It is sometimes claimed (e.g., by Sider (2001a, 2001b; Stalnaker 2004; Williams 2007; Weatherson 2003)) that David Lewis’s theory of predicate meaning assigns a central role to naturalness.1 Some of the people who claim this also say that the theory they attribute to Lewis is true. The authors I have mentioned aren’t as explicit as each other about exactly which theory they are attributing to Lewis, but the rough intuitive idea is that the meaning of a predicate is the most natural property that is more-or-less consistent with the usage of the predicate. Call this kind of interpretation the ‘orthodox’ interpretation of Lewis.2 Recently Wolfgang Schwarz (2009, 209ff) has argued that the orthodox interpretation is a misinterpretation, and actually naturalness plays a much smaller role in Lewis’s theory of meaning than is standardly assumed.3 Simplifying a lot, one key strand in Schwarz’s interpretation is that naturalness plays no role in the theory of meaning in Lewis (1969, 1975), since Lewis hadn’t formulated the concept yet, and Lewis didn’t abandon that theory of meaning, since he never announced he was abandoning it, so naturalness doesn’t play anything like the role orthodoxy assigns to it.\n1 Holton (2003) is more nuanced, but does tell a similar story in the context of discussing Lewis’s account of (potential) semantic indeterminacy. Weatherson (2010) follows Holton in this respect.2 As some further evidence for how orthodox the ‘orthodox’ interpretation is, note that Williams (2007) is a prize winning essay published with two commentaries in the Philosophical Review. That paper takes the orthodox interpretation as its starting point, and neither of the commentaries (Bays (2007) and Hawthorne (2007)) criticise this starting point.3 Schwarz (2006) develops his criticism of orthodoxy in more detail, and in English, but it is as yet unpublished.\nPublished in Journal for the History of Analytic Philosophy, volume 1, number 10.\n\nIn this article I attempt to steer a middle ground between these two positions. I’m going to defend the following parcel of theses. These are all exegetical claims, but I’m also interested in defending most of the theses that I ultimately attribute to Lewis, so getting clear on just what Lewis meant is of more than historical interest.\n\nNaturalness matters to Lewis’s (post-1983) theory of sentence meaning only insofar as it matters to his theory of rationality, and the theory of rationality matters to the (pre- and post-1983) theory of meaning.\nNaturalness might play a slightly larger role in Lewis’s theory of word meaning, but it isn’t nearly as significant as the orthodox view suggests.\nWhen we work through Lewis’s theory of word and sentence meaning, we see that the orthodox interpretation assigns to Lewis a theory that isn’t his theory of meaning, but is by his lights a useful heuristic.\nAn even better heuristic than ‘meaning = use plus naturalness’ would be ‘meaning = predication plus naturalness’, but even this would be a fallible heuristic, not a theory.\nWhen correctly interpreted, Lewis’s theory is invulnerable to the challenges put forward in Williams (2007).\n\nI’m going to start by saying a little about the many roles naturalness plays in Lewis’s philosophy, and about his big picture views on thought and meaning. Then I’ll offer a number of arguments against the orthodox interpretation of Lewis’s theory of sentence meaning. After that, I’ll turn to Lewis’s theory of word meaning, where it is harder to be quite clear about just what the theory is, and how much it might have changed once natural properties were added to the metaphysics. An appendix discusses some interpretative questions that arise if we are sceptical that any one division of properties can do all the work that Lewis has the natural/non-natural division do.\n\n0.1 How Naturalness Enters The Theory of Meaning\nMost of the core elements of David Lewis’s philosophy were present, at least in outline, from his earliest work. The big exception is the theory of natural properties introduced in Lewis (1983). As he says in that paper, he had previously believed that “set theory applied to possibilia is all the theory of properties that anyone could ever need” (Lewis 1983, 377n). Once he introduces this new concept of naturalness, Lewis puts it to all sorts of work throughout his philosophy. I’m rather sceptical that there is any one feature of properties that can do all the varied jobs Lewis wants naturalness to do, but the grounds for, and consequences of, this scepticism are a little orthogonal to the main theme of this paper, so I’ve set it aside.\nAs the orthodox interpretation stresses, Lewis has naturalness do some work in this theory of content. That he does think there’s a connection between naturalness and content is undeniable from the most casual reading of his post-1983 work. But just how they are connected is less obvious. To spell out these connections, let’s start with three Lewisian themes.\n\nFacts about linguistic meaning are to be explained in terms of facts about minds. In particular, to speak a language \\(\\mathcal{L}\\) is to have a convention of being truthful and trusting in \\(\\mathcal{L}\\) (Lewis 1969, 1975). And to have such a convention is a matter of having certain beliefs and desires. So mental content is considerably prior to linguistic content in a Lewisian theory. Moreover, Lewis’s theory of linguistic content is, in the first instance, a theory of sentence meaning, not a theory of word meaning. 4\nThe principle of charity plays a central role in Lewis’s theory of mental content Lewis (1974, 1994). To a first approximation, a creature believes that \\(p\\) iff the best interpretation of the creature’s behavioural dispositions includes the attribution of the belief that \\(p\\) to the creature. And, ceteris paribus, it is better to interpret a creature so that it is more rather than less rational. It will be pretty important for what follows that Lewis adopts a principle of charity that highlights rationality, not truth. It is also important to Lewis that we don’t just interpret the individual creature, but creatures of a kind (Lewis 1980). I’m not going to focus on the social externalist features of Lewis’s theory of mental states, but I think they assist the broader story I want to tell.\nLewis’s theory of mental content has it that mental contents are (what most of us would call) properties, not (what most of us would call) propositions (Lewis 1979). So a theory of natural properties can easily play a role in the theory of mental content, since mental contents are properties. If you think mental contents are propositions, the connection between naturalness and mental content will be more indirect. Just how indirect it is will depend on what your theory of propositions is. But if mental contents are Lewisian propositions, the connection may be very indirect indeed. After all, propositions that we might pick out with sentences containing words that denote very unnatural properties, such as All emeroses are gred, might be intuitively very natural.\n\n4 These points are stressed by Wolfgang Schwarz (2006, 2009). He also notes that in “Putnam’s Paradox” Lewis explicitly sets these parts of his theory aside so he can discuss Putnam’s arguments on grounds most favourable to Putnam. As Schwarz says, this should make us suspicious of the central role “Putnam’s Paradox” plays in defences of the orthodox interpretation. We will return to this point in the section on textual evidence for and against orthodoxy.\nA referee notes, correctly, that the phrase ‘in the first instance’ is doing a lot of work here. That’s right; we’ll return in much more detail below to Lewisian theories of word meaning, and what role naturalness plays in them.Now let’s see why we might end up with naturalness in the theory of meaning. An agent has certain dispositions. For instance, after seeing a bunch of green emeralds, and no non-green emeralds, in a large and diverse range of environments, she has a disposition to say “All emeralds are green”. In virtue of what is she speaking a language in which “green” means green, and not grue? (Note that when I use “grue”, I mean a property that only differs from greenness among objects which it is easy to tell that neither our agent, nor any of her interlocutors, could possibly be acquainted with at the time she makes the utterance in question.)\nLet’s say that \\(\\mathcal{L}_1\\) is English, i.e., a language in which “green” means green, and \\(\\mathcal{L}_2\\) a language which is similar to \\(\\mathcal{L}_1\\) except that “green” means grue. Our question is, what makes it the case that the agent is speaking \\(\\mathcal{L}_1\\) and not \\(\\mathcal{L}_2\\)? That is, what makes it the case that the agent has adopted the convention of being truthful and trusting in \\(\\mathcal{L}_1\\), and not the convention or being truthful and trusting in \\(\\mathcal{L}_2\\)?\nWe assumed that the agent has seen a lot of emeralds which are both green and grue. To a first approximation, it is more charitable to attribute to the agent the belief that all emeralds are green than the belief that all emeralds are grue because greenness is more natural than gruesomeness. As Lewis says, “The principles of charity will impute a bias towards believing things are green rather than grue” (1983, 375). And for Lewis, charity requires imputing more reasonable interpretations. But why is it more charitable to attribute beliefs about greenness to beliefs about grueness? I think it is because we need more evidence to rationally form a belief that some class of things are all grue than we need to form a belief that everything in that class is green. And that’s because, ceteris paribus, we need more evidence to rationally form a belief that all \\(F\\)s are \\(G\\)s than that all \\(F\\)s are \\(H\\)s when \\(G\\) is less natural than \\(H\\). The agent has, we might assume, sufficient evidence to rationally believe that all emeralds are green, but not sufficient evidence to believe that all emeralds are grue.\nSo the first two Lewisian themes notes above, the reduction of linguistic meaning to mental content, and the centrality of a rationality-based principle of charity, push us towards thinking that naturalness is closely connected to mental content and hence to linguistic meaning. And it has pushed us towards thinking that if naturalness is connected to meaning, it is via this connection I’ve posited between naturalness and rational belief. Note that Lewis doesn’t ever endorse anything like that general a connection, but I suspect he had something like this in mind when he wrote the sentence I quoted in the previous paragraph. We’ll come back to this interpretative question at some length below.\nBut the argument I offered was a bit quick, because I ignored the third Lewisian theme: beliefs are relations to properties, not propositions. On Lewis’s theory, to believe that all emeralds are green is to self-ascribe the property of being in a world where all emeralds are green. So if a certain body of evidence makes it possible for the agent to rationally believe that all emeralds are green, but not for her to believe that all emeralds are grue, and that’s because rationality is constitutively connected to naturalness, then that must be because the first of the following properties is more natural than the second:\n\nBeing in a world where all emeralds are green\nBeing in a world where all emeralds are grue\n\nThat could still be true, though it is notable how far removed we are from the intuitions that motivate the distinctions between more and less natural properties. It’s not like there is some sense, intuitively, in which things that have the first property form a more unified class than things that have the second property.\nSo it’s plausible that naturalness is connected to mental content, at least as long as naturalness is connected to rational belief. And since mental content is connected to linguistic content, we’re now in the vicinity of the orthodox interpretation. But I don’t think the orthodox interpretation can be right. I’ll give four reasons for this, starting with the textual evidence for and against it.\n\n\n0.2 Textual Evidence about Sentence Meaning\nThere is some prima facie textual evidence for the orthodox interpretation. But looking more careful at the context of these texts not just undermines the support the text gives to the orthodox interpretation, but actually tells against it. (This part of the paper is indebted even more than the rest to Wolfgang Schwarz’s work, and could be easily skipped by those familiar with that work.)\nI’ll focus on the last seven pages of “New Work for a Theory of Universals”. This is the part of “New Work” that uses the notion of naturalness, as introduced in the paper, to respond to Putnam’s model-theoretic arguments for massive indeterminacy of meaning. Lewis actually responds to Putnam twice over. First, he responds to Putnam directly, by showing how adding naturalness to a use-based theory of sentence meaning avoids the ‘just more theory’ objection that’s central to Putnam’s argument. And when Lewis describes this direct response, he says things that sound a lot like the orthodox interpretation.\n\nI would instead propose that the saving constraint concerns the referent - not the referrer, and not the causal channels between the two. It takes two to make a reference, and we will not find the constraint if we look for it always on the wrong side of the relationship. Reference consists in part of what we do in language or thought when we refer, but in part it consists in eligibility of the referent. And this eligibility to be referred to is a matter of natural properties. (Lewis 1983, 371)\n\nBut after this direct response is finished, Lewis notes that he has conceded quite a lot to Putnam in making the response.\n\nYou might well protest that Putnam’s problem is misconceived, wherefore no need has been demonstrated for resources to solve it. … Where are the communicative intentions and the mutual expectations that seem to have so much to do with what we mean? In fact, where is thought? …I think the point is well taken, but I think it doesn’t matter. If the problem of intentionality is rightly posed there will still be a threat of radical indeterminacy, there will still be a need for saving constraints, there will still be a remedy analogous to Merrill’s suggested answer to Putnam, and there will still be a need for natural properties. (Lewis 1983, 373)\n\nI noted earlier that Schwarz makes much of a similar passage in “Putnam’s Paradox”, and I think he is right to do so. Here’s a crucial quote from that paper.\n\nI shall acquiesce in Putnam’s linguistic turn: I shall discuss the semantic interpretation of language rather than the assignment of content to attitudes, thus ignoring the possibility that the latter settles the former. It would be better, I think, to start with the attitudes and go on to language. But I think that would relocate, rather than avoid, the problem; wherefore I may as well discuss it on Putnam’s own terms. (Lewis 1984, 222)\n\nThat passage ends with a footnote where he says the final section of “New Work” contains a version of how the ‘relocated’ problem would be solved. So let’s turn back to that. The following long portmanteau quote from pages 373 to 375 captures, I think, the heart of my interpretation.\n\nThe problem of assigning content to functionally characterised states is to be solved by means of constraining principles. Foremost among these are principles of fit. …A state typically caused by round things before the eyes is a good candidate for interpretation as the visual experience of confronting something round; and its typical impact on the states interpreted as systems of belief ought to be interpreted as the exogenous addition of a belief that one is confronting something round, with whatever adjustment that addition calls for. …Call two worlds equivalent iff they are alike in respect of the subject’s evidence and behaviour, and note that any decent world is equivalent inter alia to horrendously counterinductive worlds and to worlds where everything unobserved by the subject is horrendously nasty. …We can interchange equivalent worlds ad lib and preserve fit. So, given any fitting and reasonable interpretation, we can transform it into an equally fitting perverse interpretation by swapping equivalent worlds around …If we rely on principles of fit to do the whole job, we can expect radical indeterminacy of interpretation. We need further constraints, of the sort called principles of (sophisticated) charity, or of ‘humanity’. [A footnote here refers to \"Radical Interpretation\".] Such principles call for interpretations according to which the subject has attitudes that we would deem reasonable for one who has lived the life that he has lived. (Unlike principles of crude charity, they call for imputations of error if he has lived under deceptive conditions.) These principles select among conflicting interpretations that equally well conform to the principles of fit. They impose apriori – albeit defeasible - presumptions about what sorts of things are apt to be believed and desired …It is here that we need natural properties. The principles of charity will impute a bias toward believing that things are green rather than grue …In short, they will impute eligible content …They will impute other things as well, but it is the imputed eligibility that matters to us at present. (Lewis 1983, 373–75, my emphasis)\n\nI think that does a reasonably clear job of supporting the interpretation I set out in the introduction over the orthodox interpretation. Naturalness matters to linguistic meaning all right. But the chain of influence is very long and indirect. Naturalness constrains what is reasonable, reasonableness constrains charitable interpretations, charitable interpretations constrain mental content, and mental content constrains linguistic content. Without naturalness at the first step, we get excessive indeterminacy of content. With it, the Putnamian problems are solved. But there’s no reason to think naturalness has any more direct role to play at any level in the theory of linguistic content.\nIn short, Lewis changed what he thought about rationality when he adopted the theory of natural properties. Since rationality was a part of his theory of mental content, and mental content determines linguistic content, this change had downstream consequences for what he said about linguistic content. But there wasn’t any other way his theory of linguistic content changed, nor, contra orthodoxy, any direct link between naturalness and predicate meaning.\nMoreover, when we look at the closest thing to a worked example in Lewis (1983), we don’t get any motivation for the orthodox interpretation. Here’s the example he uses, which concerns mental content. Let \\(f\\) be any mapping from worlds to worlds such that the agent has the same evidence and behaviour in \\(w\\) and \\(f(w)\\). Extend \\(f\\) to a mapping from sets of worlds to sets of worlds in the following (standard) way: \\(f(S) = \\{f(w): w \\in S\\}\\). Then the agent’s behaviour will be rationalised by her evidence just as much if she has credence function \\(C\\) and value function \\(V\\), as if she has credence function \\(C^\\prime\\) and value function \\(V^\\prime\\), where \\(C^\\prime(f(S)) = C(S)\\), and \\(V^\\prime(f(S)) = V(S)\\). To relate this back to the familiar Goodmanian puzzle, let \\(f\\) map any world where all emeralds are green to nearest world where all emeralds are grue, and vice versa, and map any other world to itself. Then the above argument will say that the agent’s behaviour is rationalised by her evidence just as much as if her credences are \\(C\\) as if they are \\(C^\\prime\\). That is, her behaviour is rationalised by her evidence just as much if she gives very high credence to all emeralds being green as to all emeralds being grue. So understanding charity merely as rationalizing behaviour leaves us without a way to say that the agent believes unobserved emeralds are green and not grue.\nLewis’s solution is to say that charity requires more than that. In particular, it requires that we assign natural rather than unnatural beliefs to agents where that is possible. I’ve argued above that this makes perfect sense if we connect naturalness with rationality. The crucial thing to note here is that this all happens a long time before we can set out the way that a sentence is used, since the way a sentence is used on Lewis’s theory of linguistic content includes the beliefs that are formed on hearing it. So the discussion in “New Work” suggests that naturalness matters for content, but not in a way that can be easily factorised out. And that’s exactly what I think is the best way to understand Lewis’s theory.\n\n\n0.3 Textual Evidence and Naturalness and Rationality\nA major part of my argument above was that naturalness affected Lewis’s theory of rationality. In particular, once he had naturalness to work with, he seemed to think that it was more rational to project natural rather than unnatural properties. The textual evidence for this is, I’ll admit, fragmentary. But it is fairly widespread. Let’s start with a quote we’ve already seen.\n\nThe principles of charity will impute a bias toward believing that things are green rather than grue (Lewis 1983, 375)\n\nAs noted above, I assume this isn’t a special feature of green and grue, but rather that there is a general principle in favour of projecting natural properties. But it would be good to have more evidence for that.\nLewis returns to the example of the believer in grue emeralds a few times. Here is one version of the story in Plurality.\n\nWe think that some sorts of belief and desire \\(\\dots\\) would be unreasonable in a strong sense \\(\\dots\\) utterly unintelligible and nonsensical. Think of the man who, for no special reason, expects unexamined emeralds to be grue. \\(\\dots\\) What makes the perversely twisted assignment of content incorrect, however well it fits the subject’s behaviour, is exactly that it assigns ineligible, unreasonable content when a more eligible assignment would have fit behaviour equally well. (Lewis 1986, 38–39)\n\nAnd a little later, when replying to Kaplan’s paradox, he says,\n\nGiven a fitting assignment, we can scramble it into an equally fitting but perverse alternative assignment. Therefore a theory of content needs a second part: as well as principles of fit, we need ‘principles of humanity’, which create a presumption in favour of some sorts of content and against others. (Lewis 1986, 107)\n\nHe returns to this point again in “Reduction of Mind”.\n\n[Folk psychology] sets presumptive limits on what our contents of belief and desire can be. Self-ascribed properties may be ‘far from fundamental’, I said – but not too far. Especially gruesome gerrymanders are prima facie ineligible to be contents of belief and desire. In short, folk psychology says that we make sense. It credits us with a modicum of rationality in our acting, believing and desiring. (Lewis 1994, 320 in reprint)\n\nThe running thread through these last three quotes is that our theory of mental content rules out gruesome assignments, and it does this because assigning rationality is constitutive of correctly interpreting. This can only work if naturalness is connected to rationality. I’ve attributed a stronger claim to Lewis, that not only is naturalness connected to rationality, but that the connection goes through projection.5\n5 The view I’m attributing to Lewis is endorsed by one prominent supporter of the orthodox interpretation, namely Ted Sider. See his (2011, 35ff).One piece of evidence for that is that Lewis says, in “Meaning Without Use” that Kripkenstein’s challenge was “formerly Goodman’s challenge” (Lewis 1992, 109). He goes on to say that the solution to this challenge (or should that be ‘these challenges’) involves “carrying more baggage of primitive distinctions or ontological commitments than some of us might have hoped” (Lewis 1992, 110). A footnote on that sentence cites “New Work”, in case it isn’t obvious that the baggage here is the distinction between natural and unnatural properties. So somehow, Lewis thinks that natural properties help solve Goodman’s puzzle. I think that the simplest such solution is the right one to attribute to Lewis; natural properties are prima facie more eligible to be projected.\nA referee noted that this passage is a little odd; it appears to simply conflate a meta-semantical paradox with an epistemological paradox. But I think that just shows how much, for Lewis, meta-semantical questions are epistemological questions. Words get their meanings in virtue of our conventions. Our conventions consist of our beliefs and desires. And facts about rationality are, in part, constitutive of what we believe and desire.\nFinally, consider the way in which the papers on natural properties are introduced in Papers in Metaphysics and Epistemology. Lewis says that “I had been persuaded by Goodman and others that all properties were equal: it was hopeless to try to distinguish ‘natural’ properties from gruesomely gerrymandered, disjunctive properties.” (Lewis 1999, 1–2) A footnote refers to Fact, Fiction and Forecast. Of course, the point of “New Work” is that Lewis abandons this, explicitly Goodmanian, view. Now that he had learned property egalitarianism from Goodman of course doesn’t show that once he became a property inegalitarian, he applied this to Goodman’s own paradox. But it does seem striking that the only citation of an egalitarian view is of Fact, Fiction and Forecast. I take that to be some, inconclusive, evidence that Lewis did indeed think natural properties were related to Goodman’s paradox.\nUltimately, it seems the textual evidence is this. There are many different occasions where Lewis makes clear there is a connection between naturalness and rationality, and in particular, between naturalness and the kind of rationality that is relevant to content assignment. There are hints that this connection goes via naturalness playing a role in solving Goodman’s paradox. Notably, there is no other obvious way in which naturalness could connect to rationality. At least, I can neither think of another connection, nor see any evidence for another connection in the Lewis corpus. So I conclude, a little tentatively, that Lewis thought natural properties had a role to play in solving Goodman’s paradox.\n\n\n0.4 Word Meaning and Naturalness\nIn “Languages and Language”, Lewis doesn’t say that human linguistic practices merely determine truth conditions for the spoken sentences. That is, our linguistic practices don’t merely determine which language, in Lewis’s sense, we speak. They also determine, to some extent, a grammar, which specifies the truth conditional contribution of the various parts of the sentence. The grammar determines the “fine structure of meaning” (Lewis 1975, 177) of a sentence or phrase.\nIn comments on an earlier draft of this paper, an anonymous referee stressed that naturalness could enter directly into a theory of meaning once we stopped focussing on sentence meaning, and started looking on word meaning. I don’t mean to say the referee was endorsing any particular role for naturalness in the theory of word meaning. But the point that we need to say more about the Lewisian approach to word meaning before we conclude that naturalness is only indirectly related to meaning is right. And I’m grateful for the encouragement to discuss it further.\nLewis has a short discussion of grammars in “Languages and Language”, and another in “Radical Interpretation”. It’s worth looking at both of these in turn. I’ll take “Languages and Language” first, since even though it has a slightly later publication date, in the respects we’re discussing here it closely resembles the theory in Convention.\nOn pages 177-8 of that paper, Lewis notes three ways in which there may be indeterminacy in the grammar.\n\nA subject’s behavioural dispositions and anatomy might underdetermine their beliefs and desires.\nThe beliefs and desires might underdetermine the truth conditions of their language.\nThe truth conditions of the language might underdetermine the meanings of the individual words.\n\nWhile Lewis does not think the second is actually a source of indeterminacy, he does think that the third is.\n\nMy present discussion has been directed at the middle step \\(\\dots\\) I have said \\(\\dots\\) that the beliefs and desires of the subject and his fellows are such as to comprise a fully determinate convention of truthfulness and trust in some definite language. \\(\\dots\\) I am inclined to share in Quine’s doubts about the determinacy of the third step. (Lewis 1975, 178)\n\nLewis gives reasons for this inclination a few paragraphs earlier. He says that while we can say what it is for a community to speak one language rather than another, we can’t say what it is for a community to speak one grammar rather than another. He says that we don’t have any objective measures for evaluating grammars. And he says Quine’s examples of indeterminacy of reference show that languages can have multiple good grammars, even if these disagree radically about the meaning of some constituents.\nNotably, Lewis doesn’t take to show that there is anything wrong with the notion of word meaning. He says it would be “absurd” (177) to conclude that. His conclusion here is more one of modesty rather than philosophical scepticism. We don’t know how to extend the theory of sentence meaning he offers to a theory of word meaning, so we should do what we can without talking about word meaning.\nThe approach in “Radical Interpretation” has a bit more of a hint for how to restore semantic determinacy. The subject matter of that paper is how to solve for the mental and linguistic contents of a speaker, called Karl, given the physical facts about them. Lewis uses M for “a specification, in our language, of the meanings of expressions of Karl’s language.” (Lewis 1974, 333) He lists a number of constraints on a solution, including early versions of his principles of constitutive rationality. But the most notable constraint, from our perspective, is this:\n\nThe Principle of Generativity constrains M: M should assign truth conditions to the sentences of Karl’s language in a way that is at least finitely specifiable, and preferably also reasonably uniform and simple. (Lewis 1974, 339)\n\nThere’s something very odd about this. Lewis, in 1974, didn’t have a theory of what made an assignment simple. He needed his theory of natural properties to do that. Or, at least, once he had the theory of natural properties, it did all the work he ever wanted out of an account of simplicity.\nBe that as it may, it does suggest that Lewis did think that simplicity of assignments could be used as a way of cutting down the third kind of semantic indeterminacy discussed in “Languages and Language”. He doesn’t think it would generate a fully determinate interpretation of Karl’s language.\n\nIt seems hopeless to deny, in the face of such examples as those in [Quine’s “Ontological Relativity”, pp. 30-39], that the truth conditions of full sentences in M do not sutfice to determine the rest of M: the parsings and the meanings of the constituents of sentences. At least, that is so unless there is something more than our Principle of Generativity to constrain this auxiliary syntactic and semantic apparatus. (Lewis 1974, 342–43)\n\nIt’s notable that some of the examples Quine gives in “Ontological Relativity” are not cases where the alternative meanings are by any measure equally natural. This positive allusion to Quine’s examples suggests a link to this comment in “Languages and Language”\n\nWe should regard with suspicion any method that purports to settle objectively whether, in some tribe, “gavagai” is true of temporally continuant rabbits or time-slices thereof. You can give their language a good grammar of either kind—and that’s that. (Lewis 1975, 177)\n\nNote that he doesn’t say ‘equally’ good. And note also how this contrasts with the attitude he takes towards the prospects of indeterminacy in sentence meaning. I earlier quoted him saying that part of the point of “Languages and Language” was to show how the second type of indeterminacy didn’t arise. He ends “Radical Interpretation” with this ‘credo’.\n\nCould indeterminacy of beliefs, desires, and truth conditions also arise because two different solutions both fit all the constraints perfectly? Here is the place to hold the line. This sort of indeterminacy has not been shown by convincing examples, and neither could it be shown–to me–by proof. Credo: if ever you prove to me that all the constraints we have yet found could permit two perfect solutions, differing otherwise than in the auxiliary apparatus of M, then you will have proved that we have not yet found all the constraints. (Lewis 1974, 343)\n\nSo that’s where things stood before 1983. Lewis thought he had a theory that eliminated, or at least minimised, indeterminacy at the level of truth conditions. But he didn’t think his theory eliminated indeterminacy, even quite radical indeterminacy, in word meanings. And he didn’t seem bothered by this aspect of the theory; indeed, he thought Quine’s arguments showed that we shouldn’t eliminate this kind of indeterminacy.\nThis attitude towards Quinean arguments for indeterminacy is obviously a striking contrast to the forcefulness, and rapidity, with which he responded to Putnam’s arguments for indeterminacy. That shouldn’t be too surprising once we attend to Lewis’s threefold distinction between kinds of indeterminacy. Quine was arguing that indeterminacy of the third kind was rampant. Putnam was arguing that indeterminacy of the second kind was rampant. And, as Lewis announced in “Radical Interpretation”, he wasn’t going to believe any such argument.\nStill, we might wonder whether the resources he brought to bear in responding to Putnam also help respond to Quine. Or, perhaps more importantly for exegetical reasons, we might wonder whether Lewis thought they were useful in responding to Quine. The evidence from “New Work” seems to suggest a negative answer to the latter question. Lewis never says that one of the things you can do with the distinction between natural and unnatural properties is respond to arguments for Quinean indeterminacy. And that’s despite the fact that “New Work” has a very survey-like feel; the bulk of the paper is a long list of philosophical work that a theory of universals can do.\nIn “Putnam’s Paradox” there is a brief footnote on Quine’s arguments for indeterminacy. It reads\n\nIt is not clear how much indeterminacy might be expected to remain. For instance, what of Quine’s famous example? His rabbit-stages, undetached rabbit parts, and rabbit-fusion seem only a little, if any, less eligible than rabbits themselves. (Lewis 1984, 228n)\n\nAs I’ve stressed repeatedly, following Schwarz, taking the disclaimers at the start of “Putnam’s Paradox” seriously means that we have to be careful in interpreting what Lewis says about how words acquire determinate meaning in that paper. But even before we adjust for the disclaimers, this is hardly a ringing rejection of Quine’s indeterminacy arguments. The contrast to Lewis’s attitude towards Putnam’s arguments is striking. Since it is the very same contrast that we saw in both “Languages and Language” and “Radical Interpretation”, I think it is fair to assume that he continued to think Quine’s arguments were considerably stronger than Putnam’s.\nBut there is, perhaps, a change of view in “Meaning Without Use”. Here’s the problem Lewis addresses at the end of that paper. Let \\(\\mathcal{L}_1\\) once again be English as we currently understand it, and let \\(\\mathcal{L}_3\\) be just like English, except that it doesn’t assign any truth conditions to sentences over a thousand words long.6 Do our actual linguistic practices manifest a convention of trust in \\(\\mathcal{L}_1\\), or trust in \\(\\mathcal{L}_3\\)? Lewis argues that it is more like a convention of trust in \\(\\mathcal{L}_3\\). If someone utters a very long sentence, we expect some kind of performance error, at best. We don’t, in general, believe what they say. So the theory of “Languages and Language” seems to predict that these long sentences have no truth conditions. But that’s wrong, so the theory must be corrected.\n6 If you think sentences with a thousand words are too easy to understand for the argument of this paragraph, make the threshold higher; as long as the threshold is finite, it won’t affect the argument.Lewis’s correction appeals, it seems, to natural properties in fixing a grammar. He says that linguistic practice determines truth conditions for a fragment of the language that is widely used. Those truth conditions determine meanings of words. This determination requires natural properties; without them the Quinean problems multiply indefinitely. We then use those word meanings to determine the meaning of unused sentences. A long footnote suggests that the procedure might not be restricted to unused sentences. As long as there is a large enough fragment in which there are conventions of truthfulness and trust, we can extrapolate from that to other parts of the language that are used.\nThis is a marked deviation from anything Lewis had said until then. From the earliest writings, he had stressed a step-by-step approach to content determination. Behavioural dispositions plus physical and biological constraints determine mental content; mental content determines sentence meaning; and sentence meaning determines word meaning. In “Meaning Without Use”, it seemed the last two steps were being somewhat merged.\nBut we shouldn’t overstate how much the third step was allowed to encroach on the second. Lewis does think we need to rule out ‘bent’ grammars, which don’t assign any truth conditions to sentences over a thousand words long, or which give sentences different meanings to what we’d expect if the word ‘cabbage’ appears forty times. But he doesn’t think we need to rule out any ‘straight’ grammar, which includes “any grammar that any linguist would actually propose.” (Lewis 1992, 109)\nSo Lewis’s focus here is to rule out unnatural compositional rules, not unnatural assignments of content to individual words. The reference to linguists here might be useful. Linguists tend to spend much more time on compositional rules than they do on the contents on individual predicates. Notably, Quine didn’t argue for indeterminacy by positing indeterminacy in the compositional rules of the language; his non-standard interpretations all share a standard syntax. If we posit that Lewis thought that there was little syntactic indeterminacy in the language, like there is little indeterminacy at the level of truth conditions of sentences, we can tell a story that doesn’t involve too many unsignalled changes of view. Here’s how I would tell that story in some more detail.\nLewis’s early view, expressed clearly in “Radical Interpretation” and “Languages and Language”, and not retracted before, I think, 1992, has the following parts:\n\nConventions of truthfulness and trust determine (very sharply) truth conditions for sentences in a speaker’s language.\nAny reasonably good grammar, i.e., assignment of word meanings and compositional rules, that is consistent with the truth conditions is not determinately wrong. There is potentially substantial indeterminacy in the meaning of any given word, because there are many reasonably good grammars consistent with the truth conditions.\n\nAfter 1983, ‘simplicity’ was understood in terms of naturalness, but otherwise the story doesn’t change a lot.\nThe later view, which goes by somewhat more quickly in “Meaning Without Use”, has the following parts:\n\nConventions of truthfulness and trust in (the bulk of) the used fragment of the language determine truth conditions for that fragment.\nNaturalness considerations determine the compositional rules for the language by extrapolation from that grammar.\nWord meanings are determined, so far as they are determinate, by the truth conditions for sentences, plus the compositional rules.\nTruth conditions for sentences outside the used fragment are determined by the word meanings and the compositional rules.\n\nNeither of these views look much like the orthodox view. Remember that the orthodox view has it that considerations of naturalness can be used to resolve debates in metaphysics. That’s certainly the use that Sider (2001a) makes of the orthodox view. But on the early view, simplicity considerations only come in after the truth conditions for every sentence have been determined, and hence so that all debates are settled. And on the later view, simplicity considerations primarily are used to settle truth conditions for unused, or at least unusual, sentences.\nNow if you thought the salient fragment in point 1 of the later view was small, and if you thought naturalness had a major role to play in step 3 of the later view, you would get back to something like the orthodox view. But I don’t see the textual evidence for either of those positions. Lewis says that “the used fragment is large and varied.” (Lewis 1992, 110) It doesn’t look like he is positing wholesale changes to his view on the determination of truth conditions. He is positing some changes; the last two pages of the paper are clearly marked as deviations from his earlier position. But both the examples he uses and the rhetoric around them suggests that the bulk of the changes happen at point 2. Naturalness considerations constraint the syntax of a language much more tightly than they constrain the assignment of meaning to a given word. In sum, at no point in the evolution of his views did Lewis seem to endorse the orthodox interpretation, even as a theory of word meaning.\n\n\n0.5 An Argument for the Orthodox Interpretation\nSo far I’ve argued that there is no solid textual support for the orthodox interpretation. My rival interpretation relied on there being a connection between naturalness and induction, and as we’ve just seen, there is some textual evidence for this. But perhaps there is a more indirect way to motivate the orthodox interpretation of Lewis. The orthodox interpretation attributes to Lewis a theory that is quite attractive as a theory of semantic determinacy and indeterminacy. Call that theory the U&N Theory, short for the Use plus Naturalness theory of meaning. Since Lewis was clearly looking for such a theory when he discussed naturalness in the context of his theory of content, it is reasonably charitable to attribute the U&N Theory to him, as the orthodox interpretation does.\nMy response to this will be in three parts. First, I’ll argue in this section that my rival interpretation attributes to Lewis a theory of semantic determinacy and indeterminacy that does just as well at capturing the facts Lewis wanted a theory to capture, so there’s no charity based reason to attribute the U&N Theory to him (And, as we saw in the previous section, there’s no direct textual reason to attribute it to him either.) Second, the U&N Theory is subject to the criticisms in Williams (2007), while the theory I attribute to Lewis is not. Third, the U part of the U&N Theory is hopelessly vague; it isn’t clear how to say what ‘use’ is on a Lewisian theory that makes it suitable to add to naturalness to deliver meanings. Either use is so thick that naturalness is unneeded, or it is so thin that naturalness won’t be sufficient to set meaning. So actually it isn’t particularly charitable to attribute this theory to him.\nStill, let’s start with the attractions of the U&N Theory. On the one hand, agents are inclined to say “All emeralds are green” both in situations where they’ve seen a lot of green emeralds (and no non-green ones) and in situations where they’ve seen a lot of grue emeralds (and no non-grue ones). That’s because, of course, those are exactly the same situations. So at first glance, it doesn’t look like the way in which “green” is used will determine whether it means green or grue. On the other hand, once we add a requirement that terms have a relatively natural meaning, we do get this to fall out as a result. Moreover we can even see how this falls out of a recognisably Lewisian approach to meaning.\nConsider again our agent who says “All emeralds are green” after seeing a lot of emeralds that are both green and grue. And remember that for her to speak a language, she must typically conform to conventions of truthfulness and trust in that language. Now if the agent was speaking \\(\\mathcal{L}_2\\), she would have to think that she’s doing an OK job of being truthful in \\(\\mathcal{L}_2\\) by saying “All emeralds are green”. But that would be crazy. Why should she think that all emeralds are grue given her evidence base? To attribute to her that belief would be to gratuitously attribute irrational beliefs to her. And on Lewis’s picture, gratuitous attributions of irrationality are false. So the agent doesn’t have that belief. So she’s not speaking \\(\\mathcal{L}_2\\).\nThings are even clearer from the perspective of hearers. A hearer of “All emeralds are green” would be completely crazy to come to believe that all emeralds are grue. The hearer knows, after all, that the speaker has no acquaintance with the emeralds that would have to be blue for all emeralds to be grue. So the hearer knows that this utterance could not be sufficient evidence to believe that all emeralds are grue. Yet if she speaks \\(\\mathcal{L}_2\\), she is disposed to believe that all emeralds are grue on hearing “All emeralds are green”. She isn’t irrational, or at least we shouldn’t assign irrationality to her so quickly, so she doesn’t speak \\(\\mathcal{L}_2\\).\nSo it looks like in this one case at least, we have a case where use plus naturalness gives us the right theory. Agents are disposed to use “green” to describe emeralds that are green/grue. But the fact that greenness is more natural than gruesomeness makes it more appropriate to attribute to them a convention according to which “All emeralds are green” means that all emeralds are green and not that all emeralds are grue.\nBut more carefully, what we should say is that the U&N Theory gives us the right result in this case. It doesn’t follow that it will work in all cases, or anything like it. And it doesn’t follow that it works for the right reasons. As we’ll see, neither of those claims are true. In fact, just re-reading the last three paragraphs should undermine the second claim. Because we just saw a derivation that the agents are not speaking \\(\\mathcal{L}_2\\), that didn’t even appeal to the U&N Theory. Rather, that derivation simply used the theory of meaning in Convention and the theory of mental content in “Radical Interpretation”. It’s true that the latter theory assigns a special role to rationality, and the theory of rationality we used has, among other things, a role for natural properties, but that is very different to the idea that naturalness feeds directly into the theory of meaning in the way the orthodox interpretation says. As I said at the start, I think the best interpretation of Lewis is that he changed his theory of rationality in 1983, but that’s the only change to his theory of meaning.\nPut another way, these reflections on “green” and “grue” are consistent with the view that the U&N Theory is a false theory, but a useful heuristic. It’s a useful heuristic because it agrees with the true Lewisian theory in core cases, and is much easier to apply. That’s exactly what I think the U&N Theory is, both as a matter of fact, and as a matter of Lewis interpretation.\n\n\n0.6 Indeterminacy and Radically Deviant Interpretations\nIf the U&N Theory is a heuristic not a theory, we should expect that it will break down in extreme cases. That’s exactly what we see in the cases discussed in Williams (2007). Those cases highlight the fact that a Lewisian theorist needs to be careful that we don’t end up concluding that normal people, such as the agent in our example who says “All emeralds are green”, speak \\(\\mathcal{L}_4\\). \\(\\mathcal{L}_4\\) is a language in which all sentences express claims about a particular mathematical model (essentially a Henkin model of the sentence the agent accepts), and it is set up in such a way that ordinary English sentences come out true, and about very natural parts of the model. On the U&N Theory, it could easily turn out that ordinary speakers are speaking \\(\\mathcal{L}_4\\), since the assigned meanings are so natural. We can see this isn’t a consequence of Lewis’s theory by working through the case from first principles. I have two arguments here, the first of them relying on some slightly contentious claims about the epistemology of mathematics, the second less contentious.\nAssume, for reductio, that ordinary speakers are speaking \\(\\mathcal{L}_4\\). So, for instance, when O’Leary says “The beer is in the fridge”, what he says is that a certain complicated mathematical model has a certain property. (And indeed it has that property.) Now this won’t be a particularly rational thing for O’Leary to say unless he knows more mathematics than ordinary folks like him ordinarily do. So if O’Leary has adopted a convention of truthfulness and trust in \\(\\mathcal{L}_4\\), then uttering “The beer is in the fridge” would be irrational, even if he is standing in front of the open fridge, looking at the beer. That’s a gratuitous assignment of irrationality, and gratuitous assignments of irrationality are false, so O’Leary doesn’t speak \\(\\mathcal{L}_4\\).\nPerhaps that is too quick. After all, the mathematical claim that \\(\\mathcal{L}_4\\) associates with “The beer is in the fridge” is a necessary truth. And Lewis’s theory of content is intentional, not hyper-intentional. So O’Leary does know it is true. (And when he is standing in front of the fridge, there’s even a sense that he knows that “The beer is in the fridge” expresses a truth, if \\(\\mathcal{L}_4\\) is really his language.) I think that’s probably not the right sense of “rational”, and I’m not altogether sure how much hostility to hyper-intensionalism we should attribute to Lewis. But so as to avoid these questions, it’s easier to consider a different argument that focusses attention on O’Leary’s audience.\nWhen O’Leary says “The beer is in the fridge”, Daniels hears him, and then walks to the fridge. Why does Daniels make such a walk? Well, he wants beer, and believes it is in the fridge. That looks like a nice rational explanation. But why does he believe the beer is in the fridge? I say it’s because he’s (rationally) adopted a convention of truthfulness and trust in \\(\\mathcal{L}_1\\), and so he rationally comes to believe the beer is in the fridge when O’Leary says “The beer is in the fridge”. On the assumption that O’Leary and Daniels speak \\(\\mathcal{L}_4\\), none of this story goes through. But we must have some rational explanation of why O’Leary’s statement makes Daniels walk to the fridge. So O’Leary and Daniels must not be speaking \\(\\mathcal{L}_4\\).\nMichael Morreau pointed out (when I presented this talk at CSMN) that the preceding argument may be too quick. Perhaps there is a way of rationalising Daniels’s actions upon hearing O’Leary’s words consistent with the idea that they both speak \\(\\mathcal{L}_4\\). Perhaps, for instance, Daniels’s walking to the fridge constitutes saying something in a complicated sign language, and that thing is the rational reply to what O’Leary said. If this kind of response works, and I have no reason to think it won’t, the solution is to increase the costs to Daniels of performing such a reply. For instance, not too long ago I heard Mayor Bloomberg say “Lower Manhattan is being evacuated because of the impending hurricane”, and I (and my family) packed up and evacuated from Lower Manhattan. Even if one could find an interpretation of our actions in evacuating that made them constitute the assertion of a sensible reply to Bloomberg’s mathematical assertion in \\(\\mathcal{L}_4\\), it would be irrational to think I made such an assertion. Evacuating ahead of a storm with an infant is not fun - if it was that hard to make mathematical assertions, I wouldn’t make them! And I certainly wouldn’t make them in reply to someone who wouldn’t even see my gestures. So I think at least some of the actions that are rationalised by testimony, interpreted as sentences of \\(\\mathcal{L}_1\\), are not rationalised by testimony, interpreted as \\(\\mathcal{L}_4\\). By the kind of appeal to the principle of charity we have used a lot already, that means that \\(\\mathcal{L}_4\\) is not the language most people speak.\nThe central point here is that when we are ruling out particularly deviant interpretations of some speakers, we have to make heavy use of the requirement that the interpretation of their shared language rationalises what they do. In part that means it must rationalise why they utter the strings that they do in fact utter. And when we’re considering this, we should remember the role of naturalness in a theory of rationality. But it also means that it must rationalise why people respond to various strings with non-linguistic actions, such as walking to the fridge, or evacuating Lower Manhattan. Naturalness has less of a role to play here, but the Lewisian theory still gets the right answers provided we apply it carefully. Since the Lewisian theory gets the right answers, and the U&N Theory gets the wrong answers, it follows that the U&N Theory isn’t Lewis’s theory, and so orthodoxy is wrong.\n\n\n0.7 What is the Use of a Predicate?\nWe concluded the last section with an argument that Lewis isn’t vulnerable to the claim that his theory assigns complicated mathematical claims as the meanings of ordinary English sentences. That interpretation, we argued, is inconsistent with the way those sentences are used. In particular, it is inconsistent with the way that hearers use sentences to guide their actions.\nSo far so good, we might think. But notice how much has been packed into the notion of use to get us this far. In identifying the use O’Leary makes of “The beer is in the fridge”, we have to say a lot about O’Leary’s beliefs and desires. And in identifying the use Daniels makes of it, we primarily talk about the sentence’s effects on Daniels’s beliefs and desires. That is, just saying how the sentence is used requires saying a lot about mental states of speakers. And that will often require appealing to constitutive rationality; we say that Daniels’s beliefs about the fridge changed because we need to rationalise his fridge-directed behaviour.\nAnd this should all make us suspicious about the prospects for identifying meaning (in a Lewisian theory) with use plus naturalness. The argument above that naturalness mattered to meaning relied on the idea that naturalness matters because it affects which states are rational, and hence which states are actualised. A belief that all emeralds are grue is unnatural, so it is hard to hold. And since it is hard to hold, it is hard to think one is conforming to a convention of truthfulness in a language if one utters sentences that mean, in that language, that all emeralds are grue. That’s why it is wrong, ceteris paribus, to interpret people as speaking about grueness.\nBut now consider what happened when we were talking about Daniels and O’Leary. Even to say how they were using the sentence “The beer is in the fridge”, we had to say what they believed before and after the sentence was uttered. In other words, their mental states were constitutive of the way the sentence was used. Now add in the extra premise, argued for above, that naturalness matters to Lewis’s theory of linguistic content because, and only because, it matters to his theory of mental content. (And it only matters to mental content because it matters to the principle of charity that Lewis uses.) If mental states, and their changes, are part of how the sentences are used, it will be rather misleading to say that meaning is determined by use plus naturalness. A better thing to say is that meaning is determined by use, and that some key parts of use, i.e., mental states of speakers and hearers, are determined in part by naturalness.\nSo I’m sceptical of the U&N Theory. We can put the argument of the last few paragraphs as a dilemma. There are richer and thinner ways of identifying the use to which a sentence is put. A thin way might, for instance, just focus on the observable state of the part of the physical world in which the sentence is uttered. A rich way might include include, inter alia, the use that is made of the sentence in the management of belief and the generation of rational action. If we adopt the thin way of thinking about use, then adding naturalness won’t be enough to say what makes it the case that O’Leary and Daniels are speaking \\(\\mathcal{L}_1\\) rather than \\(\\mathcal{L}_4\\). If we adopt the rich way of thinking about use, then the role that naturalness plays in the theory of meaning has been incorporated into the metaphysics of use. Neither way makes the U&N Theory true while assigning naturalness an independent role. This dilemma isn’t just an argument that we shouldn’t attribute the U&N Theory to Lewis; it is an argument against anyone adopting that theory.\n\n\n0.8 From Theory to Applied Semantics\nSo far we’ve argued that Lewis’s semantic theory did not look a lot like the orthodox interpretation. It’s true that he thought the way a sentence was used was of primary importance in determining its meaning. And it’s true that he thought naturalness mattered to meaning. But that wasn’t because naturalness came in to resolve the indeterminacy left in a use-based theory of meaning. Rather, it was because naturalness was in a part of the theory of mental content, and specifying the mental states of speakers and hearers is part of specifying how the sentence is used.\nBut note that these considerations apply primarily to investigations at a very high level of generality, such as when we’re trying to solve the problems described in “Radical Interpretation”. They don’t apply to investigations into applied semantics. Let’s say we are trying to figure out what O’Leary and Daniels mean by “green”. And assume that we are taking for granted that they are speaking a language which is, in most respects, like English. This is hardly unusual in ordinary work in applied semantics. If we are writing a paper on the semantics of colour terms, a paper like, say, “Naming the Colours”, we don’t concern ourselves with the possibility that every sentence in the language refers to some complicated mathematical claim or other.\nNow given those assumptions, we can identify a moderately thin notion of use. We know that O’Leary uses “green” to describe things that are, by appearance, both green and grue. We also know that when O’Leary makes such a description, Daniels expects the object will be both green and grue. So focus on a notion of use such that the use of a predicate just is a function of which objects speakers will typically apply the predicate to, and which properties hearers take those objects to have once they hear the predication. If we wanted to be more precise, we could call this notion of ‘use’ simply predication. When we are doing applied semantics, especially when we are trying to figure out the meaning of predicates, we typically know which objects a speaker is disposed to predicate a predicate of, and that’s the salient feature of use. (This is why I said the most accurate heuristic would be meaning is predication plus naturalness; predication is the bit of use we care about in this context.)\nThis identification of use wouldn’t make any sense if we were engaged in theorising at a much more abstract level. If we are doing radical interpretation, then we have to take non-semantic inputs, and solve simultaneously for the values of the subject term and the predicate term in a (simple) sentence. But when we are just doing applied semantics, and working just on the meaning of a term like “green” in a well-functioning language, we can presuppose facts about the denotation of the subject term in sentences like S is green, and presuppose facts about what is the subject and what is the predicate in that sentence, and then we can look at which properties hearers come to associate with that very object on hearing that sentence.\nNow that we have a notion of use that’s distinct from naturalness, we can ask whether it is plausible that predicate meaning is use (in that sense) plus naturalness. And, quite plausibly, the answer is yes. The arguments in Sider (2001a) and Weatherson (2003) in favour of this theory look like, at the very least, good arguments that the theory does the right job in resolving Kripkensteinian problems. The theory is immune to objections based on radical re-interpretations of the language, as in Williams (2007), because those will be inconsistent with the use so defined. And the theory fits nicely into Lewis’s broader theory of meaning, i.e., his metasemantics, which is in turn well motivated. So I think there are good reasons to hold that when we’re doing applied semantics, the U&N Theory delivers the right verdicts, and delivers them for Lewisian reasons. That’s the heart of what’s true about the U&N Theory, even if it isn’t a fully general theory of meaning.\n\n\n\n\n\n\nReferences\n\nBays, Timothy. 2007. “The Problem with Charlie: Some Remarks on Putnam, Lewis and Williams.” Philosophical Review 116 (3): 401–25. https://doi.org/10.1215/00318108-2007-003.\n\n\nHawthorne, John. 2007. “Craziness and Metasemantics.” Philosophical Review 116 (3): 427–40. https://doi.org/10.1215/00318108-2007-004.\n\n\nHolton, Richard. 2003. “David Lewis’s Philosophy of Language.” Mind and Language 18 (3): 286–95. https://doi.org/10.1111/1468-0017.00228.\n\n\nLewis, David. 1969. Convention: A Philosophical Study. Cambridge: Harvard University Press.\n\n\n———. 1974. “Radical Interpretation.” Synthese 27 (3-4): 331–44. https://doi.org/10.1007/bf00484599.\n\n\n———. 1975. “Languages and Language.” In Minnesota Studies in the Philosophy of Science, 7:3–35. Minneapolis: University of Minnesota Press.\n\n\n———. 1979. “Attitudes de Dicto and de Se.” Philosophical Review 88 (4): 513–43. https://doi.org/10.2307/2184646.\n\n\n———. 1980. “Mad Pain and Martian Pain.” In Readings in the Philosophy of Psychology, edited by Ned Block, I:216–32. Cambridge: Harvard University Press.\n\n\n———. 1983. “New Work for a Theory of Universals.” Australasian Journal of Philosophy 61 (4): 343–77. https://doi.org/10.1080/00048408312341131.\n\n\n———. 1984. “Putnam’s Paradox.” Australasian Journal of Philosophy 62 (3): 221–36. https://doi.org/10.1080/00048408412340013.\n\n\n———. 1986. On the Plurality of Worlds. Oxford: Blackwell Publishers.\n\n\n———. 1992. “Meaning Without Use: Reply to Hawthorne.” Australasian Journal of Philosophy 70 (1): 106–10. https://doi.org/10.1080/00048408112340093.\n\n\n———. 1994. “Reduction of Mind.” In A Companion to the Philosophy of Mind, edited by Samuel Guttenplan, 412–31. Oxford: Blackwell. https://doi.org/10.1017/CBO9780511625343.019.\n\n\n———. 1999. Papers in Metaphysics and Epistemology. Cambridge: Cambridge University Press.\n\n\nSchwarz, Wolfgang. 2006. “Lewisian Meaning Without Naturalness.”\n\n\n———. 2009. David Lewis: Metaphysik Und Analyse. Paderborn: Mentis-Verlag.\n\n\nSider, Theodore. 2001a. “Criteria of Personal Identity and the Limits of Conceptual Analysis.” Philosophical Perspectives 15: 189–209. https://doi.org/10.1111/0029-4624.35.s15.10.\n\n\n———. 2001b. Four-Dimensionalism. Oxford: Oxford University Press.\n\n\n———. 2011. Writing the Book of the World. Oxford: Oxford University Press.\n\n\nStalnaker, Robert. 2004. “Lewis on Intentionality.” Australasian Journal of Philosophy 82 (1): 199–212. https://doi.org/10.1080/713659796.\n\n\nWeatherson, Brian. 2003. “What Good Are Counterexamples?” Philosophical Studies 115 (1): 1–31. https://doi.org/10.1023/A:1024961917413.\n\n\n———. 2010. “Vagueness as Indeterminacy.” In Cuts and Clouds: Vaguenesss, Its Nature and Its Logic, edited by Richard Dietz and Sebastiano Moruzzi, 77–90. Oxford: Oxford University Press.\n\n\nWilliams, J. Robert G. 2007. “Eligibility and Inscrutability.” Philosophical Review 116: 361–99. https://doi.org/10.1215/00318108-2007-002."
  },
  {
    "objectID": "posts/kuir/index.html",
    "href": "posts/kuir/index.html",
    "title": "Keynes, Uncertainty and Interest Rates",
    "section": "",
    "text": "Keynes (1936) clearly saw an important role for uncertainty in his General Theory. However, few contemporaries agreed with him, and subsequent ‘Keynesians’ generally obliterated the distinction between risk and uncertainty. In part this was caused by Keynes’s informal presentation of his views on uncertainty in The General Theory. This paper has two aims. The first is to sketch a formal theory of uncertainty which captures Keynes’s insights about the risk/uncertainty distinction. I argue that the theory of imprecise probabilities developed in recent years best captures Keynes’s intuitions about uncertainty. In particular this theory provides a formal distinction between risk and uncertainty, and allows for an analysis of Keynes’s ‘weight’ of arguments. However, the second aim is to show that if this is right then Keynes was wrong to draw the economic consequences of uncertainty that he did. In broad terms, I argue that uncertainty is economically impotent. It only has effects in conjunction with some other feature of models or the world, such as missing markets or agent irrationality. But these features plus the existence of risk are sufficient to get the conclusions Keynes wants. These conclusions of Keynes might be right, but if so they can be justified without reference to Keynesian uncertainty. At the end of the day, uncertainty is not as economically interesting as it appears.\n\nPublished in Cambridge Journal of Economics 26: 47-62.\nPicture by Extra Medium via Creative Commons.\n\n\n0.1 Imprecise Probabilities\nIn the classical, or Bayesian1, model of rationality all rational agents have precise degrees of belief, or credences, in each proposition. There is a probability function \\(Bel\\) such that for any proposition \\(A\\), there is a number \\(Bel(A)\\). So if an agent believes \\(p\\) to degree \\(x\\) she believes \\(p\\) to degree \\(1-x\\). This is appropriate for some propositions. For example, if \\(p\\) is a proposition about the decay of an atom with known half-life, or about any event with a known objective chance and hence subject to risk and not uncertainty, the agent’s credences should reflect the chances. Since chances are precise and form a probability function, the credences will also have these properties. The Bayesian theory assumes that all situations can be treated by analogy with these.\n1 For this paper I follow Walley (1991) in describing those theorists who require that all agents have precise degrees of belief and these degrees form a probability function as Bayesians. There is some dispute as to the accuracy of this labelling, particularly as some paradigm case Bayesians, such as Jeffrey (1983) and Fraassen (1990), accept that degrees of belief can be vague. However, there is probably no other name as convenient or as recognisable.As Keynes pointed out in the famous QJE article (Keynes 1937b), this analogy is clearly mistaken. When \\(p\\) is about the price of copper in thirty years, we do not know the chance that \\(p\\) will be true. And we do not have enough information to form a precise credence. As Keynes had argued in his Treatise on Probability sixteen years earlier, attempts to avoid this problem by appeal to a Principle of Indifference lead to contradiction. In The General Theory he noted that he still approved of this little argument (Keynes 1936, 152). Hence Bayesians have no way of representing our ignorance in uncertain situations. They say that all rational agents have a precise epistemic attitude towards each proposition, believing it to some precise degree, whereas ignorance consists in not having such a precise attitude.\nThe theory of imprecise probabilities avoids all of these difficulties. The theory is quite old, dating back to work by Gerhard Tintner (1941) and A. G. Hart (1942), but has only received extensive consideration recently. The best modern summaries are by the philosopher Isaac Levi (1980) and the statistician Peter Walley (1991). There are minor differences, but the theory I shall give captures all the common ingredients. According to Bayesians, states of rational agents are represented by a single probability function \\(Pr\\); in the imprecise theory they are represented by a set of probability functions \\(S\\). The agent’s credence in \\(p\\) is vague over the set of values that \\(Pr(p)\\) takes for \\(Pr \\in S\\). In the extreme case, for every \\(x \\in [0, 1]\\) there will be a \\(Pr \\in S\\) such that \\(Pr(p) = x\\). This represents almost total ignorance about \\(p\\). The set \\(S\\) is called the ‘representor’ of the agent whose credences it represents.\nIt is important to stress what \\(S\\) represents, because there has been some confusion over this2. The \\(Pr\\) do not represent the agent’s hypotheses about the correct distribution of objective chances. I use the phrase ‘objective chance’, or just ‘chance’, to refer to a property that plays a certain role in fundamental physics, the property which makes it the case that the whirrings of atoms in the void is indeterminate. Modern physics, or at least the most popular versions of it, teaches that chance infects all fundamental physical events. These chances fulfill all the properties that anyone has ever wanted in probabilities. They reflect long-run frequencies of repeated events, they put restrictions on reasonable degrees of belief, they can be properly applied to single cases, and so on. If all fundamental physical events are chance events, then arbitrary Boolean combinations of fundamental physical events should also, presumably, be chance events. But any event whatsoever is some combination of fundamental physical events, though for many it may not be clear which combination. So baseball games, romantic affairs and stock market movements are all chance events in this sense, even though they are not, for instance, repeatable events. Of course, trying to predict these using the laws of physics will be even less productive than trying to predict them using the methods we currently have available. Saying where all the atoms, or quarks, currently are is humanly impossible, and perhaps theoretically impossible as well. Even allowing for this, computing where they will move before they get there is beyond the capacity of any possible machine.\n2 See, for example, Gärdenfors and Sahlin (1982), Levi (1982).I distinguish between a situation where the agent does not know the objective chance of some proposition, and a situation where the agent has no precise credence in that proposition. An agent can have a precise credence in \\(p\\) without knowing its objective chance. If the agent believes that a certain number of chance distributions are possible, and gives each of them a precise credence, this entails she has a precise credence in each event. (Imagine we see a fair coin be tossed, and land, but do not see how it falls. The objective chance that it shows heads is either one, if it does, or zero, otherwise. But the appropriate credence in the proposition, the coin has landed heads, is one half.) Rather the \\(Pr\\) represent the precise credence distributions that are consistent with real imprecise distribution. For example, for some rational agent, and some proposition \\(p\\), the agent’s epistemic state will determine that she believes \\(p\\) to a greater degree than 0.2, and a lesser degree than 0.4, but there will be no more facts about the matter. (In this case \\(S\\) will include a function \\(Pr\\) such that \\(Pr(p) = x\\) for each \\(x \\in [0.2,~0.4]\\).) If we ask her whether she thinks \\(p\\) is more likely than some proposition, call it \\(q\\), which she believes to degree 0.3, she will not be able to say one way or the other. And this is not just because she lacks rationality or powers of introspective observation. It is no requirement of rationality that she believe \\(p\\) is more likely, less likely or equally likely than \\(q\\) As Levi and Walley have pointed out, the Bayesian arguments purporting to show this is a constraint on rationality have been hopelessly circular.\nThe reasons for wanting to be able to represent uncertainty were stressed by Keynes, and are generally well known. Before showing why this theory captures Keynes’s intuitions about uncertainty, I will briefly mention two nice formal features of the theory of imprecise probabilities. On many theories of uncertainty, particularly those that represent uncertain agents as having interval valued degrees of belief, it is hard to explain comparative statements, like “\\(p\\) seems more likely to me than \\(q\\)”. These comparatives are crucial to our everyday practices of probabilistic reasoning. We say \\(p\\) is more probable than \\(q\\) according to \\(S\\) iff for all \\(Pr \\in S, Pr(p) &gt; Pr(q)\\). This lets us say, as seems right, that \\(A\\) is more probable than \\(A \\wedge B\\) for almost all propositions \\(A, B\\).\nThe second formal advantage is that we now have a simple way to update epistemic states on receiving new evidence. Let \\(S\\) be the agent’s current representor, and the new evidence be \\(e\\). Then the updated representor, \\(S_e\\) is given as follows: \\[S_e = \\{Pr(\\bullet | e): Pr \\in S\\}\\]\nThat is, we just conditionalise every probability function in \\(S\\). Again, updating has proven problematic for some approaches to uncertainty. The theory of evidence functions, developed by Dempster (1967) and Shafer (1976) allows that an agent can know that if either \\(e\\) or \\(\\neg e\\) comes in as evidence, their credence in \\(p\\) will rise. This seems absurd; we can know before an experiment that whatever happens we’ll be more confident in \\(p\\) than we are now.\nTo take a famous example, three prisoners \\(X\\), \\(Y\\) and \\(Z\\) are about to be exiled to Elba. The governor decides on a whim that he will pardon one, and casts a fair die to choose which. He tells the guards who is pardoned, but instructs them not to tell the prisoners yet. \\(X\\) pleads futilely with his guard, and finally asks, “Can you tell me the name of one of the others who won’t be pardoned.” The guard, realising this will not reveal \\(X\\)’s fate, agrees to answer. \\(X\\) thinks that if \\(Y\\) is pardoned, the guard will say \\(Z\\), so there is at least a one-third probability of that. And if \\(Z\\) is pardoned, the guard will say \\(Y\\), so there is also at least a one-third probability of that. But if he is pardoned, what the guard will have to decide what to say, and we can’t make probability judgements about free human decisions. On the Dempster-Shafer theory, the probability of \\(X\\) being freed is one-third, but the probability of \\(X\\) being freed and the guard saying \\(Y\\) goes to Elba is zero, and the probability of \\(X\\) being freed and the guard saying \\(Z\\) goes to Elba is zero. This is just a standard failure of additivity, and not at all objectionable. The problem is that when the guard says that \\(Y\\) will go to Elba, or that \\(Z\\) will go to Elba, the probability of \\(X\\) being freed rises to one-half. (I will not go through the mathematics here, because it can be found in any book on the Dempster-Shafer theory. See, for example, Walley (1991) or Yager, Fedrizzi, and Kacprzyk (1994).) Since \\(X\\) did not learn about his chances of freedom, this seems like a rather odd result. The theory of imprecise probabilities avoids this problem. It can be easily shown that on this theory for any evidence \\(e\\) if the probability of \\(p\\) given \\(e\\) is greater than the probability of \\(p\\), then the probability of \\(p\\) given \\(\\neg e\\) is less than the probability of \\(p\\). (Again Walley (1991) contains the proof.)\n\n\n0.2 Keynes and Imprecise Probabilities\nObviously enough, this is not the theory that Keynes formally endorses, either in his Treatise on Probability (Keynes 1921) or his economic writings. Nevertheless, I think it is an important theory for understanding Keynes’s use of uncertainty. This is because it, and it alone, captures all of the underlying motivations of Keynes’s theory of uncertainty. Hence any economic consequences of uncertainty Keynes wants to draw will have to be derivable from this theory.\nI have so far spoken blithely of ‘Keynes’s theory of uncertainty’, implicitly assuming there is such a unique theory. In recent years a number of authors (e.g. Runde (1994a; Davis 1994; Coates 1996; Bateman 1996) have questioned this assumption, saying that Keynes changed his theory between the writing of the Treatise on Probability and The General Theory. I will not deal directly with such criticisms here for a number of reasons. First, the main dispute is over whether probabilities are given by logic or are ‘merely subjective’, and that debate is independent of the debate about the effects of allowing imprecise probabilities. Secondly, there are obvious space constraints. Many of these alternative interpretations were put forward in book length arguments, and a fair response to them would not be short. Thirdly, and perhaps most importantly, I take it that the methodological game here is inference to the best explanation. Whatever criticisms I make of others’ interpretations would be rather weak unless I showed that some other overall story was more persuasive. And if I come up with a more persuasive story here criticisms of their accounts will be slightly redundant. So I hope the reader at least permits the indulgence of setting out a theory of Keynes’s ideas predicated on this rather controversial assumption.\nIn the Treatise on Probability (Keynes (1921), hereafter TP) Keynes says that probability is essentially a property of ordered pairs of propositions, or what he calls arguments. He writes \\(p / q = \\alpha\\), for the probability of hypothesis \\(p\\) on evidence \\(q\\) is \\(\\alpha\\). Now this value \\(\\alpha\\) is rather unusual. It sometimes is a number, but sometimes not; it sometimes can be compared to all numbers, but sometimes not; it sometimes can be compared to other probability values such as \\(\\beta\\), but sometimes not and it can enter into arithmetic operations. As a consequence probabilities are subject to all the usual rules of the classical probability calculus. For example, whenever \\(p\\) and \\(r\\) are inconsistent, then \\((p \\vee r) / q = p / q + r / q\\) always holds, even when none of these values is numerical.\nThese five properties are rather perplexing. Indeed, Keynes’s failure to explain or justify them fully is one of the main criticisms that Ramsey (Ramsey 1926, 161–66) launches at Keynes’s theory. But on this theory they all fall out as consequences of our definitions. If \\(p/q = \\alpha\\) then \\(\\alpha\\) will be numerical iff there is some \\(x\\) such that for all \\(Pr \\in S, Pr(p | q) = x\\). Similarly \\(\\alpha &gt; y\\), for real valued \\(y\\), iff \\(Pr(p | q) &gt; y\\) for all \\(Pr \\in S\\). A similar definition holds for \\(\\alpha &lt; y\\) and \\(\\alpha = y\\), from which it can be seen that it is possible that \\(\\alpha\\) is neither greater than, less than, nor equal to \\(y\\). If none of these hold we say that \\(\\alpha\\) and \\(y\\) are incomparable. If \\(p / q = \\alpha\\) and \\(r / s = \\beta\\) then \\(\\alpha &gt; \\beta\\) iff for all \\(Pr \\in S, Pr(p | q) &gt; Pr(r | s)\\). Again similar definitions of less than and equal to apply, and the consequence of all these is that sometimes \\(\\alpha\\) and \\(\\beta\\) will be comparable, sometimes not.\nRamsey is right to question the intelligibility of Keynes’s use of addition and multiplication. We know what it means to add and multiply numbers, but we have no idea what it is to add or multiply non-numerical entities. However, on this theory addition and multiplication are perfectly natural. Since we represent \\(\\alpha\\) and \\(\\beta\\) by sets, generally intervals, then \\(\\alpha + \\beta\\) and \\(\\alpha \\dot \\beta\\) will be sets. They are defined as follows. Again let \\(p / q\\ = \\alpha\\) and \\(r / s = \\beta\\).\n\\[\\begin{aligned}\n\\alpha + \\beta &= \\{x: \\exists Pr \\in S (Pr(p | q) + Pr(r | s) = x)\\} \\\\\n\\alpha \\dot \\beta &= \\{x: \\exists Pr \\in S (Pr(p | q) \\dot Pr(r | s) = x)\\} \\end{aligned}\\]\nThese definitions are natural in the sense that we are entitled to say that the ‘+’ in \\(\\alpha + \\beta\\)means the same as the ‘+’ in 2 + 3. And the definitions show why Keynes’s \\(\\alpha\\)’s and \\(\\beta\\)’s will obey the axioms of the probability calculus. Even if \\(p / q\\) and \\(\\neg p / q\\) are non-numerical, \\(p / q + \\neg p / q\\) will equal {1}, or effectively 1. So we have something like the additivity axiom, without its normal counterintuitive baggage. The main problem with additivity is that sometimes we may have very little confidence in either \\(p\\) or \\(\\neg p\\), but we are certain that \\(p \\vee \\neg p\\). If we measure confidence by the lower bound on these probability intervals, this is all possible on our theory. Our technical apparatus removes much of the mystery behind Keynes’s theory, and fends off an important objection of Ramsey’s.\nThe most famous of Keynes’s conceptual innovations in the TP is his introduction of ‘weight’. He does this in the following, relatively opaque, paragraph.\n\nAs the relevant evidence at our disposal increases, the magnitude of the probability of the argument may either decrease or increase, according as the new knowledge strengthens the unfavourable or the favourable evidence; but something seems to have increased in either case, – we have a more substantial basis upon which to rest our conclusion. I express this by saying that an accession of new evidence increases the weight of an argument. New evidence will sometimes decrease the probability of an argument, but it will always increase its ‘weight’ (Keynes 1921, 77, italics in original).\n\nThe idea is that \\(p / q\\) measures how the evidence in \\(q\\) is balanced between supporting \\(p\\) and supporting \\(\\neg p\\). The concept of weight is needed if we want to also know how much evidence there is. Note that weight only increases when relevant evidence comes in, not when any evidence comes in. The weight of the argument from my evidence to “Oswald killed JFK” is not increased when I discover the Red Sox won last night.\nThe simplest definition of relevance is that new evidence \\(e\\) is irrelevant to \\(p\\) given old evidence \\(q\\) iff \\(p / q \\wedge e)= p / q\\), and relevant otherwise. Now there is a problem. Two pieces of evidence \\(e_1\\) and \\(e_2\\) can be irrelevant taken together, but relevant taken separately. For a general example, let \\(e_1\\) be \\(p \\vee r\\) and \\(e_2\\) be \\(\\neg p \\vee r\\), for almost any proposition \\(r\\). If I receive \\(e_1\\) and \\(e_2\\) sequentially, the weight of the argument from my evidence to \\(p\\) will have increased twice as I receive these new pieces of evidence. So it must be higher than it was when I started. But if I just received the two pieces of evidence at once, as one piece of evidence, I would have properly regarded it as irrelevant. Hence the weight in question would be unchanged. So it looks as if weight depends implausibly not on what the evidence is, but on the order in which it was obtained.\nKeynes avoids this implausibility by tightening up the definition of irrelevance. He says that \\(e\\) is irrelevant to \\(p / q\\) iff there are no propositions \\(e_1\\) and \\(e_2\\) such that \\(e\\) is logically equivalent to \\(e_1\\ \\wedge e_2\\) and either \\(e_1\\) or \\(e_2\\) is relevant to \\(p / q\\). Unfortunately, as I noted in the previous paragraph for virtually any such evidence proposition there will be such propositions \\(e_1\\) and \\(e_2\\). This was first noticed by Carnap (1950). Keynes, had he noticed this, would have had three options. He could conceded that everything is relevant to everything, including last night’s baseball results to the identity of Kennedy’s assassin; he could have conceded that the order in which evidence appears does matter, or he could have given up the claim that new relevant evidence always increases the weight of arguments.\nThe last option is plausible. Runde (1990) defends it, but for quite different reasons. He thinks weight measures the ratio of evidence we have to total evidence we believe is available. Since new evidence might lead us to believe there is much more evidence available than we had previously suspected, the weight might go down. I believe it holds for a quite different reason, one borne out by Keynes’s use of uncertainty in his economics. In The General Theory (Keynes (1936), hereafter GT) Keynes stresses the connection between uncertainty and ‘low weight’ (GT: 148n). If we regard \\(p\\) as merely risky the weight of the argument from our evidence to \\(p\\) is high, if we regard \\(p\\) as uncertain the weight is low. In the Quarterly Journal of Economics article he argues that gambling devices are, or can be thought to be, free of uncertainty, whereas human actions are subject to uncertainty. So the intervention of humans can take a situation from being risky to being uncertain, and hence decrease the weight in question.\nFor example, imagine we are playing a rather simple form of poker, where each player is dealt five cards and then bets on who has the best hand. Before the bets start, I can work out the chance that some other player, say Monica, has a straight. So my credence in the proposition Monica has a straight will be precise. But as soon as the betting starts, my credence in this will vary, and will probably become imprecise. Do those facial ticks mean that she is happy with the cards or disappointed? Is she betting high because she has a strong hand or because she is bluffing? Before the betting starts we have risk, but no uncertainty, because the relevant probabilities are all known. After betting starts, uncertainty is rife.\nThe poker example supports my analysis of weight. If weight of argument rises with reduction of uncertainty, then in some rare circumstances weight of arguments decreases with new evidence. Let \\([x_1, x_2]\\) be the set given by \\(\\{x: Pr(p | q) = x\\}\\) for some \\(Pr \\in S\\}\\), where \\(S\\) is the agent’s representor. Then the weight of the argument from \\(p\\) to \\(q\\), for this agent, is \\(1-(x_2 - x_1)\\). That is, the weight is one when the agent has a precise degree of belief in \\(p\\), zero when she is totally uncertain, and increasing the narrower the interval \\([x_1, x_2]\\) gets. Now in most cases new relevant evidence will increase the weight, but in some cases, like when we are watching Monica, this will not happen. I follow Lawson (1985) in saying that \\(p\\) is uncertain for an agent with evidence \\(q\\) iff \\(p / q\\) is non-numerical, i.e. iff the weight of the argument from \\(q\\) to \\(p\\) is less than one. Hence we get the connection between uncertainty and weight Keynes wanted. I also claim that the bigger \\(x_2 - x_1\\) is, the more \\(p / q\\) is unlike a real number, the more uncertain \\(p\\) is. Keynes clearly intended uncertainty to admit of degrees Keynes (1937b), so this move is faithful to his intent.\nKeynes’s theory of probability is based around some non-numerical values whose nature and behaviour is left largely unexplained, and a concept of weight which is subject to a telling and simple objection. Nevertheless, his core ideas, that probabilities can but need not be precise, and that we need a concept like weight as well as just probability, both seem right for more general reasons. Hence the theory here, which captures the Keynesian intuitions while explaining away his mysterious non-numerical values and making the concept of weight more rigorous, looks to be as good as it gets for a Keynesian theory of uncertainty.\nOne particularly attractive feature of the account is how conservative it is at the technical level. We do not need to change our logic, change which things we think are logical truths, or which things follow from which other things, in order to support our account of uncertainty. This is in marked contrast to accounts based on fuzzy logic or on logics of vagueness. Not only are such changes in the logic unmotivated, they appear to lead to mistakes. No matter how uncertain we are about how the stock will move over the day, we know it will either close higher or not close higher; and we know it will not both close higher and not close higher. The classical laws of excluded middle and non-contradiction seem to hold even in cases of massive uncertainty. This seems to pose a serious problem for theories of uncertainty based on alternative logics. The best approach is one, like the theory here, which is innovative in how it accounts for uncertainty, and conservative in the logic it presupposes.\nSo as a theory of uncertainty I think this account has a lot to be said for it. However, it cannot support the economic arguments Keynes rests on it.\n\n\n0.3 The Economic Consequences of Uncertainty\nUncertainty can impact on the demand for an investment in two related ways. First, it can affect the value of that particular investment; secondly, it can affect the value of other things which compete with that investment for capital. The same story is true for investment as a whole. First, uncertainty may reduce demand for investment directly by making a person who would otherwise be tempted to invest more cautious and hence reluctant to invest. Secondly, if this direct impact is widespread enough, it will increase the demand for money, and hence its price. But the price of money is just the market rate of interest. And the return that an investment must be expected to make before anyone, even an investor not encumbered by uncertainty, will make it is the rate of interest.\nWhen uncertainty reduces investment by increasing interest rates, I will say it has an indirect impact on investment. Keynes has an argument for the existence of this indirect impact. First, he takes the amount of consumption as a given (GT: 245). Or more precisely, for any period he takes the amount of available resources that will not be allocated to consumption as a given. There are three possible uses for these resources: they can be invested, they can be saved as bonds or loans, or they can be hoarded as money. There are many different types of investment, but Keynes assumes that any agent will already have made their judgement as to which is the best of these, so we need only consider that one. There will also be many different length bonds which the agent can hold. So as to simplify the discussion, Keynes proposes just treating these two at a time, with the shorter length bond called ‘money’ and the longer length loan called ‘debts’ (GT: 167n). Hence the rate of interest is the difference between the expected return of the shorter bond over the life of the longer bond and the return of the longer bond. So the rate of interest that we are interested in need not be positive, and when the two bond lengths are short will usually be zero. However, it is generally presumed in discussions that the rate is positive. Now, Keynes assumes that an agent will only allocate resources to investment if investment looks to be at least as worthwhile as holding money, and at least as worthwhile as holding debts. In other words, he makes the standard reduction of \\(n\\)-way choice to a set of 2-way choices3. Usually if someone is of a mind to invest they will not favour holding money over holding debts. The only motivation for holding money, given positive interest rates, could be a desire to have accessible command over purchasing power, and investment foregoes that command. So in practice we only need look at two of the three possible pairwise choices here. Hence I will ignore the choice between investing and holding money, and only look at the money-debt choice and the debt-investment trade-off.\n3 Standard, but I bring it up because the modern theorist whose decision theory is closest to the one Keynes seems to adopt, Levi, explicitly rejects it.Holding a debt provides a relatively secure return in terms of money. Relatively secure because there is the possibility of default. In practice, this means that there is not a sharp distinction between debts and investments, rather a continuum with say government bonds at one extreme and long-term derivatives at the other. Some activities that have the formal structure of ‘debts’, like say provision of venture capital, will be closer to the investment end of the continuum. Unlike debts then, investments as a rule do not have a secure return in terms of money. In most cases they do not even have a precise expected return (GT: 149; Keynes (1937b, 113)). Keynes does not presume that this means that people never invest unless the expected return on the investment is greater than the expected (indeed, known) return on debts. He says explicitly that were this true then ‘there might not be much investment’. Instead, he says that investment under uncertainty depends on ‘confidence’ (GT: 150). Therefore, the following looks compatible with his position.\nBayesians say that each gamble has a precise expected value. The expected return on a bet that pays $1 if some fair coin lands heads is 50 cents. On this theory, expected values are imprecise, because probabilities are imprecise. Formally, say \\(E_{Pr}(G) = \\alpha\\) means that the expected return on \\(G\\) according to probability function \\(Pr\\) is \\(\\alpha\\). Roughly, the expected value for an agent of a gamble \\(G\\) will be \\(\\{x: \\exists Pr \\in S: (E_{Pr}(G) = x)\\}\\), the set of expected values of the bet according to each probability function in the agent’s representor. Note that these are different from the possible outcomes of the bet. As we saw in the case of the coin, expected value can differ from any possible value of the bet. So let the expected value of inesting a certain sum be \\([\\alpha, \\beta]\\), and the expected value of buying a debt with that money be \\(\\chi\\). Then the agent will invest iff \\((1 - \\rho)\\alpha + \\rho \\beta \\geq \\chi\\), where \\(\\rho \\in [0, 1]\\) measures the ‘state of confidence’.4 Now when a crisis erupts, \\(\\rho\\) will go to 0, and investment will dry up. In such cases the decision theory is similar to the one advanced by Levi (1980), Strat (1990) and Jaffray (1994). Since we are interested in a theory of unemployment, we are primarily interested in the cases where \\(\\rho\\) is quite low, in which cases we can say uncertainty is reducing investment.\n4 In case the reader fears I am being absurdly formal with an essentially informal idea, Keynes had such a variable, there described as measuring the ‘state of the news’, in early drafts, but it did not survive to the final stage. So my proposal is not a million miles from what Keynes intended merely by virtue of being algebraic.That last statement might seem dubious at face value. In part, what I mean by it is this. When \\(\\rho\\) is low the value of a set of bets will in general be more than the sum of the value of the bets taken separately. Because individual investors are fearful of exposure to uncertainty, which is presumably what \\(\\rho\\) being low means, sets of investments which if undertaken collectively would be profitable (and everyone agrees that they would) will not be undertaken individually. This suggests a reason that theorists have thought government intervention might be appropriate in times of crisis. Alternatively, if \\(\\rho\\) is low then the value of an investment, how much we will be prepared to pay for it, will probably be lower than our best estimate of its expected return, assuming the latter to be near \\((\\alpha + \\beta) /2\\).\nI shall focus more closely on the indirect effects of uncertainty in section 5. The central idea is that the rate of interest, being the price of money, is completely determined in the market for money. However, this market has some rather strange properties. After all, money is barren, and it can generally be traded for something that is not barren. So, as Keynes puts it, why would anyone ‘outside a lunatic asylum’, want it? Why would the demand for money not drop to zero as soon as the rate of interest is positive?\n\nBecause, partly on reasonable and partly on instinctive grounds, our desire to hold money as a store of wealth is a barometer of the degree of our distrust of our own calculations and conventions concerning the future ... The possession of actual money lulls our disquietude; and the premium which we require to make us part with money is the measure of the degree of our disquietude (Keynes 1937b, 116).\n\nTherefore, more uncertainty means more demand for money means higher interest rates. The rest of the story is standard. Even the confident agent will be disinclined to invest once the rate of interest rises. Using the little decision theory outlined above, more uncertainty means the gap between \\(\\alpha\\) and \\(\\beta\\) grows, which if \\(\\rho\\) is low will tend to reduce \\((1-\\rho)\\alpha + \\rho \\beta\\), the ‘certainty equivalent’ of the expectation of the investment’s worth. On the other hand, uncertainty on the part of the community will tend, for similar reasons, to increase \\(\\chi\\). Either way, investment suffers, and hence so does employment.\n\n\n0.4 Uncertainty and Money\nThere is something very odd about all that we have done so far. Agents react to uncertainty by making their returns measured in dollars more stable. However, in doing so they make their returns measured in any other good less stable. If you have no idea what the price of widgets will be in twelve months time, then holding only widgets increases the uncertainty about how many dollars you will be worth then. However, it makes you more certain about how many widgets you will be worth. Why this preference for money? We deserve an explanation as to why one kind of uncertainty is given such a central place and other kinds are completely ignored.\nKeynes has one explanation. He argues, or perhaps assumes, essentialism about money. Indeed the title of chapter 17 of The General Theory is ‘The Essential Properties of Interest and Money’. These essential properties are entirely functional. As Hicks puts it, “Money is defined by its functions ... money is what money does” (Hicks 1967, 1). The explanation is that agents try to minimise uncertainty relative to whatever plays the functional role of money. Therefore, the explanation does not rely on any mystical powers of dollar bills. Rather, the work is done by the functional analysis of money.\nAs a first approximation, the functional role money plays is that it is a medium of exchange. Keynes does not think this is quite the essential property; rather he says that money is essentially ‘liquid’, and perceived to be liquid. This means that if we hold money we are in a position to discharge obligations and make new purchases as they seem appropriate with greatest convenience and least cost. Even this is not what is given as the official essential property of money. To make the proof that demand for money is not demand for labour easier Keynes takes the essential properties of money to be its negligible elasticities of production and substitution. However, he makes clear that these are important because of their close connection to liquidity (GT: 241). Indeed, when he comes to define a non-monetary economy, he simply defines it as one where there is no good such that the benefits it confers via its liquidity, its ‘liquidity premium’ exceeds the carrying costs of the good. So the properties of having a negligible elasticity of production and substitution seem necessary but insufficient for something to be money.\nThe reason that money uncertainty is more problematic than widget uncertainty is just that money is liquid. At the end of the day, the point of holding investments, bonds or money is not to maximise the return in terms of such units; it is to be used somehow for consumption. Hence, we prefer, ceteris paribus, to store wealth in ways that can be easily exchanged for consumption goods as and when required. Further, we may be about to come across more information about productive uses for our wealth, and if we do, we would prefer to have the least inconvenience about changing how we use wealth. Money is going to be the best store of wealth for each of these purposes. The strength of these preferences determines the liquidity premium that attaches to money.\nSo Keynes’s story here is essentially a ‘missing markets’ story. If there were markets for every kind of transaction there would be no liquidity premium attaching to money, and hence no reason to be averse to uncertainty in terms of money returns as opposed to uncertainty in terms of X’s shares returns. There is a methodological difference here between decision theorists and economists. In decision theory it is common to specify what choices an agent does have. These will usually be finite, or at least simply specified. In economics it is more common to specify what choices an agent does not have, which markets are ‘missing’. In a sense the difference is purely cosmetic, but it can change the way problems are looked at. Since Keynes requires here some markets to be missing, it might be worth investigating what happens here from the more restrictive framework ordinarily applied in decision theory.\nIn some decision-theoretic contexts, we can prefer liquidity even when we are completely certain about what our choices are and what their outcomes will be. Say we are in a game where the object is to maximise our money over 2 days. We start with $100. On day 1, we have a choice of buying for $100 a ticket that will pay $200 at the end of day 2, and is non-transferable, or doing nothing. On day 2, if we still have our $100, we can buy with it a voucher which pays $300 at the end of day 2, or do nothing. Obviously, the best strategy is to do nothing on day 1, and buy the voucher on day 2. The point is just that money here has enough of a liquidity premium on day 1 that we are prepared to hold it and earn no interest for that day rather than buy the ticket (or two day bond) which will earn interest. So uncertainty is not a necessary condition for liquidity premia to exist. On the other hand, perhaps it is necessary for liquidity premia to exist in a world something like ours, where agents neither have all the choices they would have in a perfect market, nor as few as in this simple game. If we added a market for tickets and vouchers to our simple game the prices would be fixed so that money would lose its liquidity premium. Keynes suggests something like this is true for the worlds he is considering: “uncertainty as to the future course of the rate of interest is the sole intelligible explanation of the type of liquidity preference [under consideration]” (GT: 201). However here he merely means lack of certainty; there is no proof that if every agent had precise credences liquidity preference ought to disappear. So it looks like uncertainty in the sense discussed here, vague reasonable beliefs, does no theoretical work. Perhaps this is a bit quick, as the little game I considered is so far from a real-life situation. So I will look more closely at the effects uncertainty is supposed to have. Since it has received the bulk of the theoretical attention, I start with the indirect effects of uncertainty.\n\n\n0.5 Uncertainty and Liquidity Preference\nKeynes thinks the question of why money is demanded at all, why we do not all move from holding money into holding debts as soon as the rate of interest goes positive, needs answering. And he thinks the answer here will be particularly relevant to theories about the rate of interest. If the market in general is at equilibrium then the market in trades between any two goods must also be in equilibrium; in particular it cannot be that there are people holding money who would be prepared to buy debts at the current interest rate. So if the equilibrium interest rate is positive, there must be some people who would prefer to hold money than hold debts. This fact Keynes takes to be central to the correct theory of the rate of interest. Hence, to determine what the rate of interest will be, and what will cause it to change, I need to determine what causes a demand for money.\nKeynes distinguishes four motives for holding money (GT: Ch. 13; (Keynes 1937a, 215–23)). Two of these, the transactions motive and the finance motive, need not detain us. They just relate to the need to make payments in money and on time. The third, the speculative motive, is often linked to uncertainty, and indeed Keynes does so (GT: 201). But ‘uncertainty’ here is just used to mean absence of certainty, that is the existence of risk, which as noted above is not how I am using ‘uncertainty’. As Runde (1994b) points out, an agent who is certain as to future movements in interest rates may still hold money for speculative reasons, as long as other agents who are not so certain have made mistaken judgements. The fourth motive will hold most of my attention. Keynes argues that we may hold money for purely precautionary reasons.\n\nTo provide for contingencies requiring sudden expenditure and for unforeseen opportunities of advantageous purchases, and also to hold an asset of which the value is fixed in terms of money to met a subsequent liability fixed in terms of money, are further motives for holding cash (GT: 196).\n\nDavidson (1988, 1991) justifies this as follows. Uncertainty arises whenever agents do not have sufficient knowledge to calculate the numerical probability of an event. This is given a rather frequentist gloss in Davidson, but that is not necessary. His idea is that we know what the probability of \\(p\\) is when we know the frequency of \\(p\\)-type events in the past and we know the future will resemble the past in this respect. The latter is cashed out as saying \\(p\\) is governed by an ‘ergodic process’. We can replace all this by saying that \\(p\\) is subject to uncertainty whenever we do not know its objective chance, whether or not objective chance ought to be analysed by frequentist approaches. Davidson then argues that since for most \\(p\\) we do not have this knowledge, we have to adopt ‘sensible’ approaches like holding money.\nRunde (1994b) objects that Davidson’s story is incoherent. On Davidson’s theoretical story there are only two epistemic states relative to \\(p\\) that are possible. An agent can know the chance of \\(p\\), in which case their credence is set equal to it, or they are completely uncertain about it. In the latter case there can be no reason for taking some action rather than another. Now the reason that it is ‘sensible’ to hold money is that we expect money to be liquid. However, we do not know the chance of money remaining liquid; whether or not money remains liquid is not determined by an ergodic process. Hence, we have no reason for letting that partial belief be a guide to action.\nThis is a fair criticism, but it can be met by amending the theory rather than by giving it up. On my theory, if an agent knows the chance of \\(p\\) they will have a precise degree of belief in \\(p\\). When they do not their degree of belief will, in general, be vague but not totally vague. As with Keynes, I have uncertainty come in degrees. This amendment is enough to rescue Davidson’s theory. An agent might not know the chance that money will become illiquid in the next short period of time, but they might know enough for it to be reasonable to have a credence in that proposition which is vague over some small interval close to zero. It may still be sensible to hold some money even when the expected return on other investments really is vague. But is it sensible to prefer fixed to uncertain returns? In other words, is there a direct effect of uncertainty that makes people prefer bonds to investments?\n\n\n0.6 Uncertainty and Indecision\nAs Keynes repeatedly stressed, investment is not like a game of chance where the expected results are known in advance. And this is part of the explanation for the extreme instability in investment levels compared to other economic variables.\n\nThe state of long-term expectation ... does not solely depend on the most probable forecast we can make. It also depends on the confidence with which we make this forecast (GT: 148).\nHuman decisions affecting the future, whether personal or political or economic, cannot depend on strict mathematical expectation, since the basis for making such calculations does not exist ... it is our innate urge to activity which makes the wheels go round, our rational selves choosing between the alternatives as best we are able, calculating where we can, but often falling back for our motive on whim or sentiment or chance (GT: 162-3).\n\nThe most charitable reading of Keynes here is to say he agreed, in principle, with what is sometimes referred to as a Horwitz-style decision rule. If the expected return of an investment is vague over \\([\\alpha, \\beta]\\) then its ‘value’ is given by \\((1-\\rho)\\alpha + \\rho \\beta\\), where \\(\\rho \\in [0, 1]\\) is a measure of confidence. By the 1937 article, he has become more interested in the special case where confidence has collapsed and \\(\\rho\\) is approaching 0. This interpretation would explain all his references to decision-making under uncertainty in The General Theory and subsequent discussion, provided we make the safe assumption that ‘cold calculation’ would only have us spend \\(x\\) on an investment with expected return \\([\\alpha, \\beta]\\) when \\(\\alpha \\geq x\\). In particular, any interpretation of the underlying decision theory here will have to give some role to ‘whim or sentiment or chance’, and I give it a variable, ‘\\(\\rho\\)’. With this theory, I have the extensions needed to avoid Runde’s objection to Davidson. I have a continuum of degrees of uncertainty, rather than a raw dichotomy, and I have an explanation of why it is ‘sensible’ to prefer gambles with known expected returns, at least when \\(\\rho\\) is relatively low.\nThis theory is meant to serve two related purposes. It is meant to show why we might prefer money to debts, even though our best estimate of the expected return of the debts is positive, and again it is meant to show why we might prefer debts to investments even when our best estimate of the expected return of the investment is higher. And I think if the decision rule stipulated were plausible, it would show that uncertainty did have an economic effect. In particular, I think it would show both that in times of crises when \\(\\rho\\) heads down, the level of investment will decrease even with other things being equal, and that collective action can be justified even when individual action is not. That is, the government can make sets of investments that are expected to be profitable although none of the individual investments is expected to be profitable.\nThe decision theory does not, however, seem plausible. First, there are some technical problems for this theory. The problem is that if \\(\\rho &lt; \\frac{1}{2}\\), then in cases where uncertainty is guaranteed to increase in the near future agents following this rule will make decisions they are sure to regret. For example, assume an agent with \\(\\rho = \\frac{1}{3}\\) now has credence \\(\\frac{1}{2}\\) in \\(p\\), but knows that some evidence will come in such that her credence in \\(p\\) will become vague over \\([0.3, 0.7]\\) whatever the result of the experiment. As we saw in the case of poker players, this is plausible in some situations. The agent will now pay 50 cents for a bet which pays $1 if \\(p\\) and nothing otherwise, but after the evidence comes in she’ll sell that bet for about 44 cents, incurring a sure loss. I leave it to the reader to judge the importance of these technical problems, given the rarity of cases where uncertainty is guaranteed to rise.\nThere is also a philosophical problem. What precisely is \\(\\rho\\) supposed to represent? If it is some kind of belief, its effects should have been incorporated into the credences. If it is some kind of desire its effects should have been incorporated into the evaluation of each of the states. This objection could be avoided, perhaps, if Keynes was trying to argue against the theory that investors just maximise dollar expected returns. It is not entirely clear whom Keynes thinks he is arguing against at some points. If this is his enemy, he is fighting a straw man, one who is vulnerable to much simpler objections. Whoever thought that all investment is profit driven, that no one ever went into business because they thought it would be fun to run a newspaper? Keynes’s only viable opponents here are saying that investors calculate the expected return, in utils, of each possible investment and choose the one whose returns are highest. Now perhaps for many dollar returns are the most important factor in determining util returns, but this is certainly not the only cause.\nIf \\(\\rho\\) represents something which is neither a belief nor a desire, then it is hard to see what effect it could have on action. Perhaps there are some exceptions to the rule that actions are caused only by beliefs and desires combining in the right way, such as actions caused by values, but these appear irrelevant to Keynes’s considerations, and he does not appeal to such exemptions. After all, he describes investment decisions made where the ‘cold calculations’ do not determine what should be done as being made by ‘whim or sentiment or chance’. Now whims and sentiments are surely desires, although chance is in a different boat. If he had just said ‘chance’ here he may have committed himself to a different decision theory, one where the agent can under uncertainty make any decision which is not known to be sub-optimal. But this does not justify the conclusion that uncertainty decreases investment; under that theory it is random whether uncertainty increases or decreases investment. Hence Keynes appears to be implausibly committed to a mental state which is neither a belief nor a desire but affects action.\nIt might be objected here that I am relying on an overly individualistic theory of motivation; that what Keynes is committed to is nothing more than what anyone who has learned the difference between Robinson Crusoe economics and real-world economics would believe. There is an important truth behind this objection: the social causes of action cannot be overlooked. But this is not what I have done. The core assumption I made is that the only mental states relevant to action are beliefs and desires. Now the beliefs and desires that are relevant may not be (directly) concerned with the action at hand; they may be beliefs and desires about how society will view this action, or about similar actions which may or may not be performed by other members in society. And the beliefs and desires may not have as their immediate cause careful inference by the agent in question; they may be caused by the wave of panic or optimism in which the agent is caught up. In the real world, agents do not always change their beliefs and desires by reflection on new evidence, often emotion plays a larger role. So society has both evidential and non-evidential effects on action. But every time, the causal chain goes via the beliefs and desires of the agent. Society causes actions by causing changes in the beliefs and desires of individuals. It is wrong to think that action is never caused by beliefs and desires about society, it is wrong to think that society never directly causes beliefs and desires which lead to action, but none of this implies that there can be mental states other than belief and desire relevant to action.\n\n\n0.7 Disquietude\nThere are some comments from Keynes that suggest this reading is a little unfair. Rather than having a distinctive decision theory, he perhaps has a distinctive theory about what ought enter into the decision-theoretic calculations. The standard theory for why there is a demand for insurance is the falling marginal utility of money. Agents purchase insurance, and accept a lower expected dollar return because with insurance their expected util return, at the end of the duration of the insurance, is higher than if they had not purchased. This is the story given in, for example, Freidman and Savage (1952) where the existence of demand for insurance is taken as evidence for the declining marginal utility of money. But there is another reason agents might buy insurance. They might simply feel happier, over the duration of the insured period, knowing that they have insurance and are hence exposed to fewer risks or uncertainties than otherwise. If this is true then their expected ‘wealth’ in both dollars and utils at the end of a period might be lower if they insure than if otherwise, but it will be worthwhile because of the benefits during the period. Keynes suggests that this same desire for quietude can cause a demand for money. I presume, though it is not entirely clear, that this desire should be included within the precautionary motives for holding money.\n\nThere are not two separate factors affecting the rate of investment, namely, the schedule of the marginal efficiency of capital [the expected return of investments] and the state of confidence. The state of confidence is relevant because it is one of the major factors determining the former (GT: 149).\nFor the fact that each individual investor flatters himself that his commitment is “liquid” ... calms his nerves and makes him much more willing to run a risk (GT: 160).\nThe possession of actual money lulls our disquietude; and the premium which we require to make us part with money is the measure of the degree of our disquietude (Keynes 1937b, 116).\nA liquidity premium ... is not even expected to be rewarded. It is a payment, not for the expectation of increased tangible income at the end of the period, but for an increase sense of comfort and confidence during the period (Keynes 1938, 293–94).\n\nThis explanation of the demand for certain returns is in some ways conservative and some ways radical. It is conservative because it does not immediately change the technical properties of preference. Many heterodox theories of preference drop such theoretical restrictions as transitivity of preferences. By contrast the theory Keynes appears to be advocating is it least in principle conservative on this front. Agents are still going round maximising expected utility, just now it is expected utility over a period, not at the end of the period.\nBut it is not all conservative. If we explain economic decisions in terms of the disquietude of the investor we discard the distinction between investment and consumption. It was always known that there were some goods that were not comfortably categorised, particularly cars, but this move makes every good in part a consumption good. If all this meant was that some helpful classifications have to be questioned, it would not be important. Rather, its importance flows from its implications for the norms for investment. It is always irrational to make an investment which will incur a sure loss. This principle is used to derive wide-ranging implications for decision-theory. But it is not irrational to make a consumption decision which will result in sure loss at the end of a period in exchange for goods during that period. It is not always irrational to pay ten dollars for a movie ticket, even though this will incur a sure loss in the sense the buyer will surely have less wealth at the end of the movie than if they had not bought the ticket.\nGiven this, the technical complaint I raised against the Horvitz-style decision rule misses the target. And the philosophical concern about what \\(\\rho\\) represents is irrelevant. If the expected returns only measure how much various gambles will be worth at the end of the period, then some desires have not yet been included in our calculations. That is, \\(\\rho\\) represents some desires but the theory is not guilty of double-counting. So far this all seems to work, and explain the role of uncertainty. Indeed, I think this is the best extension of Keynes’s views in this area.\nWhile there seem to be few theoretical objections which can be raised at this point, there is a rather telling empirical objection. The only role given to disquietude in this theory is in deciding between alternatives where the returns on at least one are uncertain. But it seems implausible that disquietude could have this effect, but have no effect when choices are being made between alternatives where at least one is risky. I doubt the feelings of disquiet would be any different were I to have a large fortune riding on a roulette wheel or a baseball game. Disquietude arises because we do not know what will happen; maybe for some people it is greater when we do not know the expected returns, but I doubt it. Again, perhaps there is an explanation for demand for money in the real world to be found here, but uncertainty plays no role in the story, or at best a small cameo.\n\n\n0.8 Summary\nKeynes argued that uncertainty has a major economic impact. By driving people to store their wealth in ways with more stable returns, it increases the demand for cash and decreases the demand for investments. Not only does it drive down investments in this direct way, the increased demand for cash leads to higher interest rates and hence people are driven out of investment into bonds. However, there are a few problems with the story. First, the motivation for demanding returns fixed with respect to a certain good can only be that the markets between that good and other goods are more complete. But if that is the case there is a reason to demand that good even when the world is completely certain. Secondly, the only decision-theoretic justification for this demand for fixed returns could be the disquiet generated by not knowing the return. This follows from the formalisation of uncertainty advocated in sections 1 and 2. But this disquiet could just as easily be generated by risk as by uncertainty. So Keynes has not shown that uncertainty has any particular economic impact. That’s the bad news. The good news is that many of the arguments seem to work without the reliance on uncertainty.\n\n\n\n\n\n\nReferences\n\nBateman, Bradley. 1996. Keynes’s Uncertain Revolution. Ann Arbor: University of Michigan Press.\n\n\nCarnap, Rudolf. 1950. Logical Foundations of Probability. Chicago: University of Chicago Press.\n\n\nCoates, John. 1996. The Claims of Common Sense. Cambridge: Cambridge University Press.\n\n\nDavidson, Paul. 1988. “A Technical Definition of Uncertainty and the Long-Run Non-Neutrality of Money.” Cambridge Journal of Economics 12: 329–38. https://doi.org/10.1093/oxfordjournals.cje.a035063.\n\n\n———. 1991. “Is Probability Theory Relevant for Uncertainty? A Post Keynesian Perspective.” Journal of Economic Perspectives 5 (1): 129–44. https://doi.org/10.1257/jep.5.1.129.\n\n\nDavis, John. 1994. Keynes’s Philosophical Development. Cambridge: Cambridge University Press.\n\n\nDempster, Arthur. 1967. “Upper and Lower Probabilities Induced by a Multi-Valued Mapping.” Annals of Mathematical Statistics 38: 325–39. https://doi.org/10.1214/aoms/1177698950.\n\n\nFraassen, Bas van. 1990. “Figures in a Probability Landscape.” In Truth or Consequences, edited by J. M. Dunn and A. Gupta, 345–56. Amsterdam: Kluwer.\n\n\nFreidman, M., and L. Savage. 1952. “The Expected Utility Hypothesis and the Measurability of Utility.” Journal of Political Economy 60 (6): 463–74. https://doi.org/10.1086/257308.\n\n\nGärdenfors, Peter, and Nils-Eric Sahlin. 1982. “Unreliable Probabilities, Risk Taking and Decision Making.” Synthese 53 (3): 361–86. https://doi.org/10.1007/bf00486156.\n\n\nHart, A. G. 1942. “Risk, Uncertainty and the Unprofitability of Compounding Probabilities.” In Studies in Mathematical Economics and Econometrics, edited by F. McIntyre O. Lange and T. O. Yntema., 110–18. Chicago: University of Chicago Press.\n\n\nHicks, John. 1967. Critical Essays in Monetary Theory. Oxford: Clarendon Press.\n\n\nJaffray, J. Y. 1994. “Decision Making with Belief Functions.” In Advances in the Dempster- Shafer Theory of Evidence, edited by R. Yager, M. Fedrizzi, and J. Kacprzyk, 331–52. New York: John Wiley.\n\n\nJeffrey, Richard. 1983. “Bayesianism with a Human Face.” In Testing Scientific Theories, edited by J. Earman (ed.). Minneapolis: University of Minnesota Press.\n\n\nKeynes, John Maynard. 1921. Treatise on Probability. London: Macmillan.\n\n\n———. 1936. The General Theory of Employment, Interest and Money. London: Macmillan.\n\n\n———. 1937a. “The Ex Ante Theory of the Rate of Interest.” Economic Journal 47 (188): 663–68. https://doi.org/10.2307/2225323.\n\n\n———. 1937b. “The General Theory of Employment.” Quarterly Journal of Economics 51 (2): 209–23. https://doi.org/10.2307/1882087.\n\n\n———. 1938. “Letter to Hugh Townshend Dated 7 December.” In The Collected Writings of John Maynard Keynes, by John Maynard Keynes, 14:293–94. London: Macmillan.\n\n\nLevi, Isaac. 1980. The Enterprise of Knowledge. Cambridge, MA.: MIT Press.\n\n\n———. 1982. “Ignorance, Probability and Rational Choice.” Synthese 53 (3): 387–417. https://doi.org/10.1007/bf00486157.\n\n\nRamsey, Frank. 1926. “Truth and Probability.” In Philosophical Papers, edited by D. H. Mellor, 52–94. Cambridge: Cambridge University Press.\n\n\nRunde, Jochen. 1990. “Keynesian Uncertainty and the Weight of Arguments.” Economics and Philosophy 6 (2): 275–93. https://doi.org/10.1017/s0266267100001255.\n\n\n———. 1994a. “Keynes After Ramsey: In Defence of ‘a Treatise on Probability’.” Studies in the History and Philosophy of Science 25 (1): 97–124. https://doi.org/10.1016/0039-3681(94)90022-1.\n\n\n———. 1994b. “Keynesian Uncertainty and Liquidity Preference.” Cambridge Journal of Economics 18: 129–44. https://doi.org/10.1093/oxfordjournals.cje.a035266.\n\n\nShafer, Glenn. 1976. A Mathematical Theory of Evidence. Princeton: Princeton University Press.\n\n\nStrat, Thomas. 1990. “Decision Analysis Using Belief Functions.” International Journal of Approximative Reasoning 4 (5-6): 391–417. https://doi.org/10.1016/0888-613x(90)90014-s.\n\n\nTintner, Gerhard. 1941. “The Theory of Choice Under Subjective Risk and Uncertainty.” Econometrica 9 (3/4): 298–304. https://doi.org/10.2307/1907198.\n\n\nWalley, Peter. 1991. Statisical Reasoning with Imprecise Probabilities. London: Chapman & Hall.\n\n\nYager, R., M. Fedrizzi, and J. Kacprzyk, eds. 1994. Advances in the Dempster- Shafer Theory of Evidence. New York: John Wiley."
  },
  {
    "objectID": "posts/epic/index.html",
    "href": "posts/epic/index.html",
    "title": "Epistemic Modals in Context",
    "section": "",
    "text": "In the 1970s David Lewis argued for a contextualist treatment of modals (Lewis 1976, 1979). Although Lewis was primarily interested in modals connected with freedom and metaphysical possibility, his arguments for contextualism could easily be taken to support contextualism about epistemic modals. In the 1990s Keith DeRose argued for just that position (DeRose 1991, 1998).\n\nPublished in Contextualism in Philosophy, edited by Gerhard Preyer and Georg Peter, 131-169.\n\nIn all contextualist treatments, the method by which the contextual variables get their values is not completely specified. For contextualist treatments of metaphysical modality, the important value is the class of salient worlds. For contextualist treatments of epistemic modality, the important value is which epistemic agents are salient. In this paper, we start by investigating how these values might be generated, and conclude that it is hard to come up with a plausible story about how they are generated. There are too many puzzle cases for a simple contextualist theory to be true, and a complicated contextualist story is apt to be implausibly ad hoc.\nWe then look at what happens if we replace contextualism with relativism. On contextualist theories the truth of an utterance type is relative to the context in which it is tokened. On relativist theories, the truth of an utterance token is relative to the context in which it is evaluated. Many of the puzzles for contextualism turn out to have natural, even elegant, solutions given relativism. We conclude by comparing two versions of relativism.\nWe begin with a puzzle about the role of epistemic modals in speech reports.\n\n0.1 A Puzzle\nThe celebrity reporter looked discomforted, perhaps because there were so few celebrities in Cleveland.\n“Myles”, asked the anchor, “where are all the celebrities? Where is Professor Granger?”\n“We don’t know,” replied Myles. “She might be in Prague. She was planning to travel there, and no one here knows whether she ended up there or whether she changed her plans at the last minute.”\nThis amused Professor Granger, who always enjoyed seeing how badly wrong CNN reporters could be about her location. She wasn’t sure exactly where in the South Pacific she was, but she was certain it wasn’t Prague. On the other hand, it wasn’t clear what Myles had gotten wrong. His first and third sentences surely seemed true: after all, he and the others certainly didn’t know where Professor Granger was, and she had been planning to travel to Prague before quietly changing her destination to Bora Bora.\nThe sentence causing all the trouble seemed to be the second: “She might be in Prague.” As she wiggled her toes in the warm sand and listened to the gentle rustling of the palm fronds in the salty breeze, at least one thing seemed clear: she definitely wasn’t in Prague – so how could it be true that she might be? But the more she thought about it, the less certain she became. She mused as follows: when I say something like x might be F, I normally regard myself to be speaking truly if neither I nor any of my mates know that x is not F. And it’s hard to believe that what goes for me does not go for this CNN reporter. I might be special in many ways, but I’m not semantically special. So it looks like Myles can truly say that I might be in Prague just in case neither he nor any of his mates knows that I am not. And I’m sure none of them knows that, because I’ve taken great pains to make them think that I am, in fact, in Prague – and reporters always fall for such deceptions.\nBut something about this reasoning rather confused Professor Granger, for she was sure Myles had gotten something wrong. No matter how nice that theoretical reasoning looked, the fact was that she definitely wasn’t in Prague, and he said that she might be. Trying to put her finger on just where the mistake was, she ran through the following little argument.\n\nWhen he says, “She might be in Prague” Myles says that I might be in Prague.1\nWhen he says, “She might be in Prague” Myles speaks truly iff neither he nor any of his mates know that I’m not in Prague.\nNeither Myles nor any of his mates know that I’m not in Prague.\nIf Myles speaks truly when he says that I might be in Prague, then I might be in Prague.\nI know I’m not in Prague.\nIt’s not the case that I know I’m not in Prague if I might be in Prague.\n\n1 Some of Professor Granger’s thoughts sound a little odd being in the present tense, but as we shall see, there are complications concerning the interaction of tense with epistemic modals, so for now it is easier for us to avoid those interactions.There must be a problem here somewhere, she thought – for (1) – (6) are jointly inconsistent. (Quick proof: (2) and (3) entail that Myles speaks truly when he says, “She might be in Prague”. From that and (1) it follows he speaks truly when he says Professor Granger might be in Prague. From that and (4) it follows that Professor Granger might be in Prague. And that combined with (5) is obviously inconsistent with (6).) But wherein lies the fault? Unless some fairly radical kind of scepticism is true, Professor Granger can know by observing her South Pacific idyll that she’s not in Prague – so (5) looks secure. And it seems pretty clear that neither Myles nor any of his mates know that she’s not in Prague, since they all have very good reason to think that she is – so it looks like (3) is also OK. But the other four premises are all up for grabs.\nWhich exactly is the culprit is a difficult matter to settle. While the semantic theory underlying the reasoning in (1)-(6) is mistaken in its details, something like it is very plausible. The modal ‘might’ here is, most theorists agree, an epistemic modal. So its truth-value should depend on what someone knows. But who is this someone? If it is Myles, or the people around him, then the statement “she might be in Prague” is true, and it is unclear where to block the paradox. If it is Professor Granger, or the people around her, then the statement is false, but now it is unclear why a competent speaker would ever use this kind of epistemic modal. Assuming the someone is Professor Granger, and assuming Professor Granger knows where she is, then “Granger might be in Prague” will be true iff “Granger is in Prague” is true. But this seems to be a mistake. Saying “Granger might be in Prague” is a way to weaken one’s commitments, which it could not be if the two sentences have the same truth conditions under plausible assumptions. So neither option looks particularly promising.\nTo make the problem even more pressing, consider what happens if a friend of Professor Granger’s who knows she is in the South Pacific overhears Myles’s comment. Call this third party Charles. It is prima facie very implausible that when Myles says that Professor Granger might be in Prague he means to rule out that Charles knows that she is not. After all, Charles is not part of the conversation, and Myles need not even know that he exists. So if Myles knows what he is saying, what he is saying could be true even if Charles knows Professor Granger is not in Prague. But if Charles knows this, Charles cannot regard Myles’s statement as true, else he will conclude that Professor Granger might be in Prague, and he knows she is not. So things are very complicated indeed.\nIn reasoning as we have been, we have been assuming that the following inferences are valid.\n\nA competent English speaker says It might be that S; and\nS, on that occasion of use, means that p; entail\nThat speaker says that it might be that p\n\nFurther, (9) plus\n\nThat speaker speaks truly; entail\nIt might be that p\n\nIf Charles accepts the validity of both of these inferences, then he is under considerable pressure to deny that Myles speaks truly. And it would be quite natural for him to do so – for instance, by interrupting Myles to say that “That’s wrong. Granger couldn’t be in Prague, since he left on the midnight flight to Tahiti.” But it’s very hard to find a plausible semantic theory that backs up this intervention, although such reactions are extremely common. (To solidify intuitions, here is another example: I overhear you say that a certain horse might have won a particular race. I happen to know that the horse is lame. I think: you are wrong to think that it might have won.)2\n2 Note that it also seems implausible to say that this is an instance of metalinguistic negation, as discussed in Horn (1989). When Charles interrupts Myles to object, the objection isn’t that the particular form of words that Myles has chosen is inappropriate. The form of words is fine, and Myles’ utterance would be completely unobjectionable if Charles’s epistemic state were slightly different. What’s wrong is that Myles has used a perfectly acceptable form of words to say something that’s false (at least by Charles’ lights—more on this later). We also think it’s implausible to understand the ‘might’ claims in question here as claims of objective chance or objective danger.Our solutions to this puzzle consist in proposed semantic theories for epistemic modals. We start with contextualist solutions, look briefly at invariantist solutions, and conclude with relativist solutions. Although we will look primarily at the costs and benefits of these theories with respect to intuitions about epistemic modals, it is worth remembering that they differ radically in their presuppositions about what kind of theory a semantic theory should be. Solving the puzzles to do with epistemic modals may require settling some of the deepest issues in philosophy of language\n\n\n0.2 Contextualist Solutions\nIn his (1991), Keith DeRose offers the following proposal:\n\nS’s assertion “It is possible that P” is true if and only if (1) no member of the relevant community knows that P is false, and (2) there is no relevant way by which members of the relevant community can come to know that P is false. (593-4)\n\nDeRose intends ‘possible’ here to be an epistemic modal, and the proposal is meant to cover all epistemic modals, including those using ‘might’.3 We will not discuss here the issues that arise under clause (2) of DeRose’s account, since we’ll have quite enough to consider just looking at whether clause (1) or anything like it is correct.4\n3 We take the puzzle to be a puzzle about sentences containing epistemic modal operators, however they are identified. We are sympathetic with DeRose’s (1998) position that many sentences containing ‘might’ and ‘possible’ are unambiguously epistemic, but do not wish to argue for that here. Rather, we simply take for granted that a class of sentences containing epistemic modal operators has been antecedently identified.\nThere are two differences between ‘possible’ and ‘might’. The first seems fairly superficial. Sentences where might explicitly takes a sentence, rather than a predicate, as its argument are awkward at best, and may be ungrammatical. It is possible that Professor Granger is in Prague is much more natural than It might be the case that Professor Granger is in Prague, but there is no felt asymmetry between Professor Granger is possibly in Prague and Professor Granger might be in Prague. We will mostly ignore these issues here, and follow philosophical orthodoxy in treating epistemic modals as being primarily sentence modifiers rather than predicate modifiers. The syntactic features of epistemic modals are obviously important, but we’re fairly confident that the assumption that epistemic modals primarily operate on sentences does not bear any theoretical load here, and could be replaced if necessary.\nThe other difference will be relevant to some arguments that follow. ‘Might’ can interact with tense operators in a way that ‘possible’ does not. It might have rained could either mean MIGHT (WAS it rains) or WAS (MIGHT it rains), while It possibly rained unambiguously means POSSIBLY (WAS it rains). It is often hard in English to tell just which meaning is meant when a sentence contains both tense operators and epistemic modals, but in Spanish these are expressed differently: Puede haber llovido; Podría haber llovido.4 There are three kinds of cases where something like DeRose’s clause (2) could be relevant.\nFirst, Jack and Jill are in a conversation, and Jack knows p while Jill knows p \\({\\rightarrow \\neg}\\) Fa. In this case intuitively neither could truly say a might be F even though neither knows a is not F.\nSecond, there are infinitely many mathematicians discussing Fermat’s Last Theorem. The first knows just that it has no solutions for n=3, the second just that it has no solutions for n=4, and so on. Intuitions are (unsurprisingly) weaker here, but we think none of them could say Fermat’s Last Theorem might have solutions, because the group’s knowledge rules this out.\nThird, if S was very recently told that a is not F, but simply forgot this, then intuitively she speaks falsely if she says a might be F.\nFourth, if S has the materials for easily coming to know P from her current knowledge, but has not performed the relevant inference, then we might be inclined (depending on how easy the inferential steps were to see and so on) to say that she is wrong to utter ‘It might be that not P’.\nRather than try and resolve the issues these cases raise, we will stick to cases where the only thing that could make a might be F false is that someone knows that a is not F.5 She would also have violated some pragmatic principles by knowingly using a third-person pronoun to refer to herself, but we take it those principles are defeasible, and violation of them does not threaten the truth-aptness of her utterance.In our discussion below, we consider three promising versions of contextualist theory. What makes the theories contextualist is that they all say that Myles spoke truly when he said “She might be in Prague”, but hold that if Professor Granger had repeated his words she would have said something false.5 And the reason for the variation in truth-value is just that Myles and Professor Granger are in different contexts, which supply different relevant communities. Where the three theories differ is in which constraints they place on how context can supply the community in question.\nThe first is the kind of theory that DeRose originally proposed. On this theory, there is a side constraint that the relevant community always includes the speaker: whenever S truly utters a might be F, S does not know that a is not F. We’ll call this the speaker-inclusion constraint, or sometimes just speaker-inclusion. There is some quite compelling evidence for speaker-inclusion. Consider, for example, the following sort of case: Whenever Jack eats pepperoni pizza, he forgets that he has ten fingers, and thinks “I might only have eight fingers.” Jill (who knows full well that Jack has ten fingers) spots Jack sitting all alone finishing off a pepperoni pizza, and says, “He might have eight fingers.” Jill has said something false. And what she’s said is false because it’s not compatible with what she knows that Jack has eight fingers. But if the relevant community could ever exclude the speaker, one would think it could do so here. After all, Jack is clearly contextually salient: he’s the referent of ‘he,’ the fingers in question are on his hand, and no one else is around.6 Now, a single case does not prove a universal7 – but the case does seem to provide good prima facie vidence for DeRose’s constraint.\n6 Notice that intuitions do not change if we alter the case in such a way that Jack has a strange disorder that makes it very hard for him to come to know how many fingers he has. Thus clause (2) of Derose’s analysis cannot do the work of the relevant side constraint.7 And see the case of Tom and Sally in the maze below for some countervailing evidence.One implication of DeRose’s theory is that (1) is false, at least when Professor Granger says it. For when Professor Granger reports that Myles says “She might be in Prague,” she is reporting a claim he makes about his epistemic community – that her being in Prague is compatible with the things that they know. But when she says (in the second clause) that this means he is saying that she might be in Prague, she speaks falsely. For in her mouth the phrase “that I might be in Prague” denotes the proposition that it’s compatible with the knowledge of an epistemic community that includes Professor Granger (as the speaker) that Professor Granger is in Prague. And that is not a proposition that Myles assented to. So DeRose’s theory implies that the very intuitive (1) is false when uttered by Granger.\n\nWhen he says, “She might be in Prague” Myles says that I might be in Prague.\n\nIt is worth emphasizing how counterintuitive this consequence of speaker-inclusion is. If the speaker-inclusion constraint holds universally then in general speech involving epistemic modals cannot be reported disquotationally. But notice how natural it is, when telling the story of Jack and Jill, to describe the situation (as we ourselves did in an earlier draft of this paper) as being one where “Whenever Jack eats pepperoni pizza, he forgets that he has ten fingers, and thinks he might only have eight.” Indeed, it is an important generalization about how we use language that speakers usually do not hesitate to disquote in reporting speeches using epistemic modals. So much so that exceptions to this general principle are striking – as when the tenses of the original speech and the report do not match up, and the tense difference matters to the plausibility of the attribution.\nOne might try to explain away the data just presented by maintaining a laxity for ‘says that’ reports. A chemist might say ‘The bottle is empty’ meaning it is empty of air, while milkman might utter the same sentence, meaning in my context that it is empty of milk. Nevertheless, the milkman might be slightly ambivalent about denying:\n\nWhen the chemist says ‘The bottle is empty’, she says that the bottle is empty.\n\nAnd this is no doubt because the overt ‘says that’ construction frequently deploys adjectives and verbs in a rather quotational way. After all, the chemist could get away with the following speech in ordinary discourse: “I know the milkman said that the bottle is empty. But he didn’t mean what I meant when I said that the bottle is empty. When he said that the bottle was empty he meant that it was empty of milk.”8 Thus the conventions of philosophers for using ‘say that’ involve regimenting ordinary use in a certain direction.9 But the disquotational facts that we are interested in cannot be explained away simply by invoking these peculiarities of ‘says that’ constructions, for the same disquotational ease surrounds the relevant belief reports. In the case just considered, while we might argue about whether it was acceptable for the chemist to say, in her conversational context, “The milkman said that the bottle was empty”, it is manifestly unacceptable for her to say “The milkman believes that the bottle is empty”. This contrasts with the case of ‘might’: If someone asked Professor Granger where Myles thought she was, she could quite properly have replied with (12).\n8 Notice that this use prohibits the inference from: The speaker said that the bottle was empty, to, The speaker expressed the proposition/said something that meant that the bottle was empty.9 We are grateful for correspondence with John MacFarlane here.\nHe thinks that/believes that I might be in Prague.\n\nIndeed, we in general tend find the following inference pattern – a belief-theoretic version of (7) to (9) above – compelling:\n\nA competent English speaker sincerely asserts It might be that S\nS, in that context of use, means that p.; therefore,\nThat speaker believes that it might be that p\n\nOur puzzle cannot, then, be traced simply to a laxity in the ‘says that’ construction.10 Whatever the puzzle comes to, it certainly runs deeper than that.\n10 For what its worth, we also note that ‘S claimed that P’ has less laxity (of the sort being discussed) than ‘S said that P’.Notice that (12) does not suggest that Myles thinks that for all Professor Granger knows, she is in Prague; it expresses the thought that Myles thinks that for all he knows, that is where she is. Moreover, this is hardly a case where Granger’s utterance is of doubtful appropriateness: (12) is one of the ways canonically available for Granger to express that thought. But if we assume that what is reported in a belief report of this kind is belief in the proposition the reporter expresses by I might be in Prague, and we assume a broad-reaching speaker-inclusion constraint, we must concede that the proposition Granger expresses by uttering (12) is that Myles believes that for all Professor Granger knows, Professor Granger is in Prague.\nIf the speaker-inclusion constraint holds universally, then anyone making such a report is wrong. There are two ways for this to happen—either they know what the sentences they’re using to make the attributions mean, and they have radically false views about what other people believe, or they have non-crazy views about what people believe, but they’re wrong about the meanings of the sentences they’re using. The first option is incredibly implausible. So our first contextualist theory needs to postulate a widespread semantic blindness; in general speakers making reports are mistaken about the semantics of their own language. In particular, it requires that such speakers are often blind to semantic differences between sentence tokens involving epistemic modals. It is possible that some theories that require semantic blindness are true, but other things being equal we would prefer theories that do not assume this.11 In general the burden of proof is on those who think that the folk don’t know the meaning of their own words. More carefully: the burden of proof is on those who think that the folk are severely handicapped in their ability to discriminate semantic sameness and difference in their home language.\n11 Note that the negation of semantic blindness concerning some fragment of the language is not the theory that speakers know all the semantic equivalences that hold between terms in that fragment. All we mean by the denial of semantic blindness is that speakers not have false beliefs about the semantics of their terms.So the plausibility of (1) counts as evidence against the first contextualist theory, and provides a suggestion for our second contextualist theory. The cases that provide the best intuitive support for the speaker-inclusion constraint and the case we used above, involved unembedded epistemic modals. Perhaps this constraint is true for epistemic modals in simple sentences, but not for epistemic modals in ‘that’ clauses. Perhaps, that is, when S sincerely asserts X Vs that a might be F, she believes that X Vs that for all X (and her community) knows, a is F. (This is not meant as an account of the logical form of X Vs that a might be F, just an account of its truth conditions. We defer consideration of what hypothesis, if any, about the underlying syntax could generate those truth conditions.) To motivate this hypothesis, note how we introduced poor Jack, above. We said that he thinks he might have eight fingers. We certainly didn’t mean by that that Jack thinks something about our epistemic state.\nThe other problem with the speaker-inclusion constraint is that it does not seem to hold when epistemic modals are bound by temporal modifiers, as in the following example. A military instructor is telling his troops about how to prepare for jungle warfare. He says, “Before you walk into an area where there are lots of high trees, if there might be snipers hiding in the branches, clear away the foliage with flamethrowers.” Whatever the military and environmental merits of this tactic, the suggestion is clear. The military instructor is giving generic conditional advice: in any situation of type S, if C then do A. The situation S is easy to understand, it is when the troops are advancing into areas where there are high trees. And A, too, is clear: blaze ’em. But what about C? What does it mean to say that there might be snipers in the high branches? Surely not that it’s compatible with the military instructor’s knowledge that there are snipers in the high branches – he’s sitting happily in West Point, watching boats sail lazily along the Hudson. What he thinks about where the snipers are is neither here nor there. Intuitively, what he meant was that the troops should use flamethrowers if they don’t know whether there are snipers in the high branches. (Or if they know that there are.) So as well as leading to implausible claims about speech reports, the speaker-inclusion constraint seems clearly false when we consider temporal modifiers.\nHere is a way to deal with both problems at once. There are constraints on the application of the speaker-inclusion constraint. It does not apply when the epistemic modal is in the scope of a temporal modifier (as the flamethrower example shows) and it does not apply when the epistemic modal is in a ‘that’ clause.12 Our second contextualist theory then accepts the speaker-inclusion constraint, but puts constraints on its application.\n12  This theory looks like one in which propositional attitude operators become monsters, since the content of Jack thinks that Jill might be happy is naturally generated by applying the operator Jack thinks to the proposition that that Jill might be happy denotes when it is expressed in Jack’s context. But this is not the easiest, or obviously the best, way to look at the theory. For one thing, that way of looking at things threatens to assign the wrong content to Jack thinks that Jill might have stolen my car. The content of Jill might have stolen my car in Jack’s context is that for all Jack knows, Jill stole Jack’s car, which is not what is intended. That is to say, thinking of propositional attitude operators as monsters here ignores the special status of epistemic modals in the semantics. It is better, we think, to hold that on this theory epistemic modals are impure indexicals whose value is fixed, inter alia, by their location in the sentence as well as their location in the world. But even if this theory does not officially have monsters, the similarity to monstrous theories is worth bearing in mind as one considers the pros and cons of the theory.\nThanks to Ernest Lepore for helpful discussions here.This kind of theory, with a speaker-inclusion constraint only applying to relatively simple epistemic modals, allows us to accept (1). The problematic claim on this theory turns out to be (4):\n\nIf Myles speaks truly when he says that I might be in Prague, then I might be in Prague.\n\nWhen Myles said that Professor Granger might be in Prague, he was speaking truly. That utterance expressed a true proposition. So the antecedent of (4) is true. But the consequent is false: the “might” that appears there is not in a that-clause or in the scope of a temporal modifier; so the speaker-inclusion constraint requires that Professor Granger be included in the relevant community; and since she knows that she is not in Prague, it’s not true that she might be. We would similarly have to reject:\n\nIf Myles has a true belief that I might be in Prague, then I might be in Prague.\n\nBut there are reasons to be worried about this version of contextualism, beyond the uneasiness that attaches to denying (4), and, worse still, (4\\(^\\prime\\)). For one, this particular version of the speaker-inclusion constraint seems a bit ad hoc: why should there be just these restrictions on the relevant community? More importantly, the theory indicts certain inferential patterns that are intuitively valid. Suppose a bystander in our original example reasoned13:\n13 What follows is a belief theoretic version of Charles’ reasoning.\nMyles believes that it might be that Professor Granger is in Prague.\nMyles’s belief is true; therefore,\nIt might be that Professor Granger is in Prague.\n\nBut this version of contextualism tells us that while (13) and (14) are true, (15) is false. In general, there are going to be counter-intuitive results whenever we reason from cases where the speaker-inclusion constraint does not apply to cases where it does.\nFinally, the theory is unable to deal with certain sorts of puzzle cases. The first kind of case directly challenges the speaker-inclusion constraint for simple sentences, although we are a little sceptical about how much such a case shows.14 Tom is stuck in a maze. Sally knows the way out, and knows she knows this, but doesn’t want to tell Tom. Tom asks whether the exit is to the left. Sally says, “It might be. It might not be.” Sally might be being unhelpful here, but it isn’t clear that she is lying. Yet if the speaker-inclusion constraint applies to unembedded epistemic modals, then Sally is clearly saying something that she knows to be false, for she knows that she knows which way is out.\n14  A similar case to the following appears in (Hawthorne 2004, 27).This case is not altogether convincing, for there is something slightly awkward about Sally’s speech here. For example, if Sally knows the exit is not to the left, then even if she is prepared to utter, “It might be [to the left],” she will not normally self-ascribe knowledge that it might be to the left. And normally speakers don’t sincerely assert things they don’t take themselves to know. So it is natural to suppose that a kind of pretense or projection is going on in Sally’s speech that may well place it beyond the purview of the core semantic theory.\nThe following case makes more trouble for our second contextualist theory, though it too has complications. Ann is planning a surprise party for Bill. Unfortunately, Chris has discovered the surprise and told Bill all about it. Now Bill and Chris are having fun watching Ann try to set up the party without being discovered. Currently Ann is walking past Chris’s apartment carrying a large supply of party hats. She sees a bus on which Bill frequently rides home, so she jumps into some nearby bushes to avoid being spotted. Bill, watching from Chris’s window, is quite amused, but Chris is puzzled and asks Bill why Ann is hiding in the bushes. Bill says\n\nI might be on that bus.\n\nIt seems Bill has, somehow, conveyed the correct explanation for Ann’s dive—he’s said something that’s both true and explanatory. But in his mouth, according to either contextualist theory we have considered, it is not true (and so it can’t be explanatory) that he might have been on the bus. He knows that he is in Chris’s apartment, which is not inside the bus.\nChris’s question, like most questions asking for an explanation of an action, was ambiguous. Chris might have been asking what motivated Ann to hide in the bushes, or he might have been asking what justified her hiding in the bushes. This ambiguity is often harmless, because the same answer can be given for each. This looks to be just such a case. Bill seems to provide both a motivation and a justification for Ann’s leap by uttering (16). That point somewhat undercuts a natural explanation of what’s going on in (16). One might think that what he said was elliptical for She believed that I might be on the bus. And on our second contextualist theory, that will be true. If Bill took himself to be answering a question about motivation, that might be a natural analysis. (Though there’s the underlying problem that Ann presumably wasn’t thinking about her mental states when she made the leap. She was thinking about the bus, and whether Bill would be on it.) But that analysis is less natural if we think that Bill was providing a justification of Ann’s actions.15 And it seems plausible that he could utter (16) in the course of providing such a justification. This suggests that (16) simply means that for all Ann knew, Bill was on that bus. Alternatively, we could say that (16) is elliptical for Because I might be on that bus, and that the speaker-inclusion constraint does not apply to an epistemic modal connected to another sentence by ‘because’. This may be right, but by this stage we imagine some will be thinking that the project of trying to find all the restrictions on the speaker-inclusion constraint is a degenerating research program, and a paradigm shift may be in order.\n15 Though the theory will allow for the truth of, “I might have been on that bus” (since the epistemic modal clause doesn’t occur on its own, but in the scope of a temporal operator). So if we think that (i) that’s enough to do the justificatory and explanatory work, and (b) Bill’s utterance of “I might be on that bus” is best understood as a clumsy stab at “I might have been on that bus”, then perhaps we can account for this kind of case using our second contextualist theory. Two worries: First, it is a cost of the theory that we have to reinterpret Bill’s utterance in this way, as a clumsy attempt to say something that the theory can accommodate. Second, there might be cases where the interpretation is less plausible: As a response to, “Why is Ann getting ready to jump over the hedge?”, “I might have been on that bus” sounds worse to us than “I might be on that bus”.So our final contextualist theory is that DeRose’s original semantic theory, before the addition of any sort of speaker-inclusion constraint, was correct and complete. So ‘might’ behaves like ‘local’ and ‘nearby’. If Susie says “There are snipers nearby,” the truth condition for that might be that there are snipers near Susie, or that there are snipers near us, or that there are snipers near some other contextually salient individual or group. Similarly, if she utters “Professor Granger might be in Prague” the truth condition for that might be that for all she knows Professor Granger is in Prague, or that for all we know Professor Granger is in Prague, or that for all some other community knows, Professor Granger is in Prague. There are no universal rules requiring or preventing the speaker from being included in the class of salient epistemic agents.\nAccording to the third version of contextualism, if Professor Granger does not equivocate when working through her paradox, then the problem lies with (6):\n\nIt’s not the case that I can know I’m not in Prague if I might be in Prague.\n\nAt the start of her reasoning process, Professor Granger’s use of ‘might’ means (roughly) ‘is compatible with what Myles and his friends know’. And if it keeps that meaning to the end, then the antecedent of (6) is true, because Professor Granger might (in that sense) be in Prague, even though she knows she is not. Any attempt to show that (1) through (6) form an inconsistent set will commit a fallacy of equivocation.16\n16 The same kind of equivocation can be seen in other arguments involving contextually variable terms. Assume that Nomar lives in Boston, Derek lives in New York, and Nomar, while talking about Fenway Park in Boston says, “I live nearby.” Derek, at home in New York, hears this on television and runs through the following argument.\n\nIn saying “I live nearby” Nomar says that he lives nearby. (Plausible disquotational premise about ‘nearby’)\nNomar speaks truly when he says “I live nearby” (Follows from the setup)\nIf Nomar speaks truly when he says “I live nearby” and in saying “I live nearby” he says that he lives nearby, then he lives nearby. (I.e. if he speaks truly then what he says is true.)\nIf Nomar lives nearby, then he lives in New York (Since everywhere that’s nearby to Derek’s home is in New York.); therefore\nNomar lives in New York\n\nThe right thing to say about this argument is that it equivocates. Every premise has a true reading. Perhaps every premise is true on its most natural reading, but the denotation of ‘nearby’ has to change throughout the argument for every premise to be true. The current view is that ‘might’ behaves like ‘nearby’, and that Professor Granger’s argument equivocates, like Derek’s.17 There also seems to be a past/future asymmetry about epistemic modals which the third contextualist theory will have trouble explaining. Consider this case involving past tense epistemic modals. Romeo sees Juliet carrying an umbrella home on a sunny afternoon. When he asks her why she is carrying an umbrella, she replies “It might have rained today.” There’s a scope ambiguity in Juliet’s utterance. If the epistemic modal takes wide scope with respect to the tense operator, Juliet would be claiming that she doesn’t know whether it has rained today (implicating, oddly, that this is why she now has an umbrella.) Or, as Juliet presumably intends, the temporal operator could take wide scope with respect to the epistemic modal. In that case Juliet says that it was the case at some earlier time (presumably when she left for work this morning) that it was compatible with her knowledge that it would rain today. And that seems both true and a good explanation of her umbrella-carrying.\nIt is much harder, if it is even possible, to find cases involving future tense operators where the temporal operator takes wide scope with respect to the pistemic modal. If S says, “It might rain tomorrow”, that seems to unambiguously mean that it’s compatible with S’s current knowledge (and her community’s) that it rains tomorrow. For a more dramatic case, consider a case where two people, Othello and Desdemona, have discovered that a giant earthquake next week will destroy humanity. No one else knows this yet, but there’s nothing that can be done about it. This rather depresses them, so they decide to take memory-wiping drugs so that when they wake up tomorrow, they won’t know about the earthquake. Othello can’t say, “Tomorrow, humanity might survive,” even though it is true that tomorrow, for all anyone will know, humanity will survive. If the temporal modifier could take wide scope with respect to the epistemic modal, Othello’s utterance could have a true reading. But it does not. It’s possible at this point that our policy, announced in footnote 2, of ignoring issues relating to DeRose’s second clause will come back to haunt us. One possibility here is that tomorrow it will still be false that humanity might survive because it’s not compatible with what people tomorrow know and knew that humanity survives. We don’t think that’s what is going on, but it’s possible. Here’s two quick reasons to think that the problem is not so simple. First, if Othello and Desdemona commit suicide rather than take the memory-wiping drugs, it will be compatible tomorrow with all anyone ever knew that humanity survives. But still Othello’s speech seems false. Second, it’s not obviously right that what people ever knew matters for what is epistemically possible now. Presumably at one stage Bill Clinton knew what he had for lunch on April 20, 1973. (For example, when he was eating lunch on April 20, 1973.) But unless he keeps meticulous gastronomical records, this bit of knowledge is lost to humanity forever. So there will be true sentences of the form Bill Clinton might have eaten x for lunch on April 20, 1973 even though someone once knew he did not. Now change the earthquake case so that it will happen in thirty years not a week, and no one will then know about it (because Othello and Desdemona took the memory-wiping drugs and destroyed the machines that could detect it). Still it won’t be true if Othello says, “In thirty years, humanity might survive.” This suggests to us that some kind of constraints on epistemic modals will be required. The existence of these constraints seems to refute the ‘no constraints’ version of contextualism. It also undermines the argument that the second version of contextualism is too ad hoc. Once some constraints are in place, others may be appropriate.But (6) as uttered by Professor Granger sounds extremely plausible. And there are other, more general problems as well. It is difficult on such a theory to explain why it is so hard to get the relevant community to exclude the speaker in present tense cases: Why, for instance, can’t Jill’s statement about Jack, “He might have eight fingers,” be a statement about Jack’s epistemic state rather than her own? The third theory offers us no guidance.17\nWe’ll close this section with a discussion of the interaction between syntax and semantics in these contextualist theories. As is well known, in the last decade many different contextualist theories have been proposed for various philosophically interesting terms. Jason Stanley (2000) has argued that the following two constraints should put limits on when we posit contextualist semantic theories.\n\nVariable\n\nAny contextual effect on truth-conditions that is not traceable to an indexical, pronoun, or demonstrative in the narrow sense must be traceable to a structural position occupied by a variable. [Stanley (2000) 401]18\n18 We assume here, following Stanley, a ‘traditional syntax involving variables’ [fn. 13]Stanley2000-STACAL. At least one of us would prefer a variable-free semantics along the lines of Jacobson (1999) Adopting such a semantics would involve, as Stanley says, major revisions to the presentation of this argument, but would not clearly involve serious changes to the argument. Most contextualists happily accept the existence of variables so we do not beg any questions against them, but see Pagin (2005) for an important exception.\nSyntactic Evidence\n\nThe only good evidence for the existence of a variable in the semantic structure corresponding to a linguistic string is that the string, or another that we have reason to believe is syntactically like it, has interpretations that could only be accounted for by the presence of such a variable.\n\n\nIf any contextualist theory of epistemic modals is to be justifiably believed, then Variable and Syntactic Evidence together entail the existence of sentences where the ‘relevant community’ is bound by some higher operator. So ideally we would have sentences like (17) with interpretations like (18).\n\nEveryone might be at the party tonight.\nFor all x, it is consistent with all x knows that x will be at the party tonight.\n\nNow (17) cannot have this interpretation, which might look like bad news for the contextualist theory. It’s natural to think that if ‘might’ includes a variable whose value is the relevant community, that variable could be bound by a quantifier ranging over it. But if such a binding were possible, it’s natural to think that it would be manifested in (17). So Variable and Syntactic Evidence together entail that we ought not to endorse contextualism about epistemic modals.\nThis argument against contextualism fails in an interesting way, one that bears on the general question of what should count as evidence for or against a contextualist theory. The reason that any variable associated with ‘might’ in (17) cannot be bound by ‘everyone’ is that ‘might’ takes wider scope than ‘everyone’. Note that (17) does not mean (19), but rather means (20).\n\nFor all x, it is consistent with what we know that x will be at the party tonight.\nIt is consistent with what we know that for all x, x will be at the party tonight.\n\nAs Kai von Fintel and Sabine Iatridou (2003) have shown, in any sentence of the form Every F might be G, the epistemic modal takes wide scope. For instance, (21) has no true reading if there is at most one winner of the election, even if there is no candidate that we know is going to lose.\n\nEvery candidate might win.\n\nMore generally, epistemic modals take wide scope with respect to a wide class of quantifiers.19 This fact is called the Epistemic Containment Principle by von Fintel and Iatridou. Even if there is a variable position for the relevant community in the lexical entry for ‘might’, this might be unbindable because the epistemic modal always scopes over a quantifier that could bind it. If that’s true then the requirement imposed by Syntactic Evidence is too strong. If the evidence from binding is genuinely neutral between the hypothesis that this variable place exists and the hypothesis that it does not, because there are no instances of epistemic modals that take narrow scope with respect to quantifiers, it seems reasonable to conclude that there are these variable places on the basis of other evidence.\n19 It is not entirely clear what the relevant class of quantifiers is, although von Fintel and Iatridou have some intriguing suggestions about what it might be.Having said all that, there still may be direct evidence for the existence of a variable position for relevant communities. Consider again our example of the military instructor, reprinted here as (22).\n\nBefore you walk into an area where there are lots of high trees, if there might be snipers hiding in the branches use your flamethrowers to clear away the foliage.\n\nAs von Fintel and Iatridou note, it is possible for epistemic modals to take narrow scope with respect to generic quantifiers. That’s exactly what happens in (22). And it seems that the best interpretation of (22) requires a variable attached to ‘might’. Intuitively, (22) means something like (23).\n\nGenerally in situations where you are walking into an area where there are lots of high trees, if it’s consistent with your party’s knowledge that there are snipers hiding in the branches use your flamethrowers to clear away the foliage.\n\nThe italicised your party seems to be the semantic contribution of the unenunciated variable. We are not saying that the existence of sentences like (23) shows that there are such variables in the logical form of sentences involving epistemic modals.20 We just want to make two points here. First, if you are a partisan of Syntactic Evidence, then (22) should convince you not to object to semantic accounts of epistemic modals that appeal to variables, as our contextualist theories do. Second, we note a general concern that principles like Syntactic Evidence presupposes that a certain kind of construction, where the contextually variable term is bound at a level like LF, is always possible. Since there are rinciples like the Epistemic Containment Principle, we note a mild concern that this presupposition will not always be satisfied.\n20 As previously noted, we are not all convinced that semantics ever needs to appeal to such variables, let alone that it does to account for the behaviour of epistemic modals.\n\n0.3 Invariantist Solutions\nThe most plausible form of invariantism about epistemic modals is that DeRose’s semantics is broadly correct, but the relevant community is not set by context - it is invariably the world. We will call this position universalism. Of course when we say a might be F we don’t normally communicate the proposition that no one in the world knows whether a is F. The analogy here is to pragmatic theories of quantifier domain restriction, according to which when we say Everyone is F, we don’t communicate the proposition that everyone in the world is F, even though that is the truth condition for our utterance.\nThe universalist position denies (2) in Professor Granger’s argument. Myles did not speak truly when he said “Professor Granger might be in Prague” because someone, namely Professor Granger, knew she was not in Prague. Although (2) is fairly plausible, it probably has weaker intuitive support than the other claims, so this is a virtue of the universalist theory.\nThe big advantage (besides its simplicity) of the universalist theory is that it explains some puzzle cases involving eavesdropping. Consider the following kind of case. Holmes and Watson are using a primitive bug to listen in on Moriarty’s discussions with his underlings as he struggles to avoid Holmes’s plan to trap him. Moriarty says to his assistant,\n\nHolmes might have gone to Paris to search for me.\n\nHolmes and Watson are sitting in Baker Street listening to this. Watson, rather inexplicably, says “That’s right” on hearing Moriarty uttering (24). Holmes is quite perplexed. Surely Watson knows that he is sitting right here, in Baker Street, which is definitely not in Paris. But Watson’s ignorance is semantic, not geographic. He was reasoning as follows. For all Moriarty (and his friends) know, Holmes is in Paris searching for him. If some kind of contextualism is true, then it seems that (24) is true in Moriarty’s mouth. And, thought Watson, if someone says something true, it’s OK to say “That’s right.”\nWatson’s conclusion is clearly wrong. It’s not OK for him to say “That’s right,” in response to Moriarty saying (24). So his reasoning must fail somewhere. The universalist says that where the reasoning fails is in saying the relevant community only contains Moriarty’s gang members. If we include Holmes and Watson, as the universalist requires, then Moriarty speaks falsely when he says (24).\nThere are a number of serious (and fairly obvious) problems with the universalist account. According to universalism, the following three claims are inconsistent.\n\nx might be F.\nx might not be F.\nSomeone knows whether x is F.\n\nSince these don’t look inconsistent, universalism looks to be false.\nThe universalist’s move here has to be to appeal to the pragmatics. If (27) is true then one of (25) and (26) is false, although both might be appropriate to express in some contexts. But if we can appropriately utter sentences expressing false propositions in some contexts, then presumably we can inappropriately utter true sentences in other contexts. (Indeed, the latter possibility seems much more common.) So one could respond to the universalist’s main argument, their analysis of eavesdropping cases like Watson’s, by accepting that Watson can’t appropriately say “That’s right” but he can truly say this. The universalist will have a hard time explaining why such a theory cannot work, assuming, of course, that she can explain how her own pragmatic theory can explain all the data.\nThe major problem here is one common to all appeals to radical pragmatics in order to defend semantic theories. If universalism is true then speakers regularly, and properly, express propositions they know to be false.21 (We assume here that radical scepticism is not true, so sometimes people know some things.) Myles knows full well than someone knows whether Professor Granger is in Prague, namely Professor Granger. But if he’s a normal English speaker, this will not seem like a reason for him to not say, “Professor Granger might be in Prague.” Some might not think this is a deep problem for the universalist theory, for speakers can be mistaken in their semantic views in ever so many ways. But many ill regard it as a serious cost of the universalist claim.\n21 By “express” we will always mean “semantically express”. We’re not concerned with, and hope not to commit ourselves to any views about, for example, what’s conveyed via various pragmatic processes.This problem becomes more pressing when we look at what universalism says about beliefs involving epistemic modals. Myles does not just say that Professor Granger might be in Prague, he believes it. And he believes Professor Granger might not be in Prague. If he also believes that Professor Granger knows where she is, these beliefs are inconsistent given universalism. Perhaps the universalist can once again invoke pragmatics. It is not literally true in the story that Myles believes that Granger might be in Prague. But in escribing the situation we use “Myles believes that Granger might be in Prague,” to pragmatically communicate truths by a literal falsehood. This appeal to a pragmatic escape route seems even more strained than the previous universalist claims.\nIn general, the universalism under discussion here seems to run up against a constraint on semantic theorising imposed by Kripke’s Weak Disquotation Principle. The principle says that if a speaker sincerely accepts a sentence, then she believes its semantic value.22 If we have some independent information about what a speaker believes, then we can draw certain conclusions about the content of the sentences she accepts, in particular that she only accepts sentences whose content she believes. The universalist now has two options.23 First, she can say that Myles here does accept inconsistent propositions. Second, she can deny the Weak Disquotation Principle, and say that although Myles sincerely asserts, and accepts, “Professor Granger might be in Prague” he doesn’t really believe that Professor Granger might be in Prague. Generally, it’s good to have options. But it’s bad to have options as unappealing as these.24\n22 Note that something like this had better be true if what it is to believe p is to have a sentence that means p in one’s ‘belief box’.23 We assume that it is not a serious option to deny that we ever accept unnegated epistemic modal sentences.24 There also a technical problem with universalism that mirrors one of the problems Stanley and Szabó (2000) raise for pragmatic theories of quantifier domain restriction. Normally (28) would be used to express a proposition like (29).\n\nEvery professor enjoys every class.\nEvery salient professor enjoys every class that s/he teaches.\n\nIntuitively, by uttering (28) we express a proposition that contains two restricted quantifiers. Let’s accept, for the sake of the argument, that a pragmatic theory of quantifier domain restriction can sometimes explain why the quantifiers in the propositions we express are more restricted than the quantifiers in the truth conditions for the sentences we use. Stanley and Szabó argue that such an explanation will not generalise to cover embedded quantifiers where the quantifier domain in the proposition expressed is bound to the outer quantifier. One such quantifier is the quantifier over classes in (28). We will not repeat their arguments here, but simply note that if they are correct, the universalist faces a problem in explaining how we use sentences with embedded epistemic modals that are (intuitively) defined with respect to a community that is bound by a higher level quantifier. As we saw, (22) provides an example of this kind of epistemic modal.\n\n0.4 Reporting Epistemic Modals\nOur third class of solutions will be relatively radical, so it’s worth pausing to look at the evidence for it. Consider again the dialogue between Moriarty, Holmes and Watson. Moriarty, recall, utters (24)\n\nHolmes might have gone to Paris to search for me.\n\nWatson knows that Holmes is in Baker Street, as of course does Holmes. In the above case we imagined that both Watson and Holmes heard Moriarty say this. Change the story a little so Holmes does not hear Moriarty speak, instead when he comes back into the room he asks Watson what Moriarty thinks. Watson, quite properly, replies with (30).\n\nHe thinks that you might have gone to Paris to search for him.\n\nThis is clearly not direct quotation because Watson changes the pronouns in Moriarty’s statement. It is not as if Watson said “He sincerely said, ‘Holmes might have gone to Paris to search for me.’” This might have been appropriate if Holmes suspected Moriarty was speaking in code so the proposition he expressed was very sensitive to the words he used.\nNor was Watson’s quote a ‘mixed’ quote, in the sense of what happens in (31).25 The background is that Arnold always uses the phrase ‘my little friend’ to denote his Hummer H2, despite that vehicle being neither little nor friendly. No one else, however, approves of this terminology.\n25 Earlier we used speech reports to illustrate the oddities of epistemic modals inside propositional attitude ascriptions. There are well-known difficulties with connecting appropriate speech reports to the semantic content of what is said, as opposed to merely communicated. (For some discussion of these, see Soames (2002) and Capellen and Lepore (1997).) We don’t think those difficulties affect the above arguments, where the evidence is fairly clear, and fairly overwhelming. But matters get a little more delicate in what follows, so we move to belief reports because they are more closely tied to the content of what is believed.\nArnold: My little friend could drive up Mt Everest.\nChaz: Arnold believes his little friend could drive up Mt Everest.26\n\n26 In this case, as with all the belief reports discussed below, the only evidence the reporter has for the report is given by the speech immediately preceding it. We assume there is good reason from the context to assume that the speakers are sincere.27  There are somewhat delicate questions about what a direct belief report means, but we assume the notion is well enough understood, even if we could not formally explicate what is going on in all such reports.We’ve left off the punctuation here so as to not beg any questions, but there is a way this could be an acceptable report if the fourth and fifth word, and those two words only, are part of a quotation. This is clearly not ordinary direct quotation, for Arnold did not think, in English or Mentalese, “His little friend could drive up Mt Everest.” Nevertheless, this is not ordinary indirect quotation. In ordinary spoken English Chaz’s report will be unacceptable unless ‘little friend’ is stressed. The stress here seems to be just the same stress as is used in metalinguistic negation, as described in Horn (1989). Note the length of the pause between ‘his’ and ‘little’. With an ordinary pause it sounds as if Chaz is using, not mentioning, ‘little friend’. So it is possible in principle to have belief reports, like this one, that are neither strictly direct nor strictly indirect.27 Nevertheless, it does not seem like (30) need such a case. In particular, there need be no distinctive metalinguistic stress on ‘might’ in Watson’s utterance of (30), and such stress seems to be mandatory for this mixed report.\nAssuming Moriarty was speaking ordinary English, Watson’s report seems perfectly accurate. This is despite the fact that the relevant community one would naturally associate with Watson’s use of ‘might’ is quite different to the community we would associate with Moriarty’s use. When reporting speeches involving epistemic modals – and the beliefs express by sincere instances of such speeches, speakers can simply disquote the modal terms.\nAs is reasonably well known, there are many terms for which this kind of disquoting report is impermissible. In every case, Guildenstern’s report of Ophelia’s utterance is inappropriate.\n\nOphelia: I love Hamlet.\n…\nGuildenstern: *Ophelia thinks that I love Hamlet.\n\nGuildenstern: What think you of Lord Hamlet?\nOphelia: He is a jerk.\n…\nRosencrantz: What does Ophelia think of the King?\nGuildenstern: *She thinks that he is a jerk.\n\nGuildenstern: Are you ready to teach the class on contextualism?\nOphelia: I’m ready.\n…\nRosencrantz: Does Ophelia think she is ready to defend her dissertation?\nGuildenstern: *She thinks she is ready.\n\n(Guildenstern and Ophelia are on the telephone, Guildenstern is in Miami, and Ophelia is in San Francisco)\nGuildenstern: What do you like best about San Francisco?\nOphelia:There are lots of wineries nearby.\n…\nRosencrantz: Is it possible to grow wine in south Florida?\nGuildenstern: *Ophelia thinks that there are lots of wineries nearby.28\n\n28 We do not say that ‘nearby’ in a speech report could never refer to the area near the location of the original speaker. Had Rosencrantz asked a question about San Francisco, and Guildenstern given the same response, that is presumably what it would have done. We just say that it does not automatically refer back to that area, and in some cases, like (35), it can refer to a quite different area. ‘Nearby’ behaves quite differently in this respect to ‘near here’, which always refers to the area near the reporter.Even when the contextualist claim is not obviously true, as with ‘local’ and ‘enemy’, disquotational reports are unacceptable after context shifts.\n\n(Brian is calling from Providence, Hud and Andy are in Bellingham)\nBrian: When I get all this work done, I’ll head off to a local bar for some drinks.\nAndy: How much work is there?\nBrian: Not much. I should get to the bar in a couple of hours.\nHud: Hey, is Brian in town? Where’s he going tonight?\nAndy: *He thinks he’ll be at a local bar in a couple of hours.\n\nThe Enemy, speaking of us: The enemy have the advantage.\nOne of us: How are we doing?\nAnother of us: Someone just informed me that the enemy have the advantage.\n\n(Terrell is an NFL player, and Dennis is his coach.)\nTerrell: Why are you cutting me coach?\nDennis: Because you are old and slow.\n(After this Terrell returns to academia. Kate and Leopold are students in his department.)\nKate: Do you think Terrell would do well on our department ultimate frisbee team?\nLeopold: ??I’m not sure. Someone thinks he’s old and slow.\n\nThis data provides us with the penultimate argument against the contextualist theory of epistemic modals. We have already seen several such arguments.\nFirst, as seen through the difficulties with each of the options discussed in section 2, any version of contextualism faces serious problems, though by altering the version of contextualism we are using, we can alter what problems we have to face.\nSecond, there is nothing like the speaker-inclusion constraint for terms like ‘local’ and ‘enemy’ for which contextualism is quite plausible. This disanalogy tells against the contextualist theory of ‘might’. With the right stage setting (and it doesn’t usually take very much), we can get ‘local’ and ‘enemy’ to mean local to x and enemy of x for pretty much any x we happen to be interested in talking about. At least for ‘bare’ (unembedded) epistemic modals, the situation is markedly different. We can’t, just by making Jack salient, make our own knowledge irrelevant to the truth of our utterance of, for example, “Jack might have eight fingers.” The only way we can make our knowledge irrelevant is if we are using this sentence in an explanation or justification of Jack’s actions.29\n29 And then it would probably be more natural to say “He might have eight fingers,” but that’s possibly for unrelated reasons.Third, there is a difference in behaviour between embedded and unembedded occurrences of epistemic modals. When epistemic modals are embedded in belief contexts, conditionals, etc., they behave differently—the speaker inclusion constraint seems to be lifted. (Think about belief reports and that military instructor case.) ‘Local’ and ‘enemy’ don’t seem to show any analogous difference in their behaviour between their bare and embedded occurrences.\nFourth, ‘local’ and ‘enemy’ don’t generate any of the peculiar phenomena about willingness to agree. If Myles (still in Cleveland), says\n\nMany local bars are full of Browns fans.\n\nProfessor Granger (still in the South Pacific), will not hesitate to say “that’s right” (as long as she knows that many bars in Cleveland really are, as usual, full of Browns fans). The fact that the relevant bars aren’t local to her doesn’t interfere with her willingness to agree with (39) in the way that the fact that she knew that she wasn’t in Prague interfered with her willingness to agree with Myles’ claim that she might be in Prague, or in the way that Watson’s knowledge that Holmes was in London (should have) interfered with his willingness to assent to Moriarty’s claim that Holmes might be in Paris.\nFifth, when there is a context shift, we are generally hesitant to produce belief reports by disquoting sincerely asserted sentences involving contextually variable terms. This is what the examples (32) through (36) show. For a wide range of contextually variable terms, speakers will quite naturally hesitate to make disquotational reports unless they are in the same context as the original speaker. Such hesitation is not shown by speakers reporting epistemic modals.\nThe sixth argument, that there is an alternative theory that does not have these flaws, will have to wait until the next section. For now, let’s note that there are other words that seem at first to be contextually variable, but for which disquotational reports seem acceptable.\n\nVinny the Vulture: Rotting flesh tastes great.\nJohn: Vinny thinks that rotting flesh tastes great.\n\nAnt Z: He’s huge (said of 5 foot 3 141 lb NBA player Muggsy Bogues)\nAndy: Ant Z thinks that Muggsy’s huge.\n\nMarvin the Martian: These are the same colour (said of two colour swatches that look alike to Martians but not to humans.)\nBrian: Marvin thinks that these are the same colour.\n\nIn all three cases the report is accurate, or at least extremely natural. And in all three cases it would have been inappropriate for the reporter to continue “and he’s right”. But crucially, in none of the three cases is it clear that the original speaker made a mistake. In his context, it seems Vinny utters a truth by uttering, “Rotting flesh tastes great”, for rotting flesh does taste great to vultures. From Ant Z’s perspective, Muggsy Bogues is huge. We assume here, a little controversially, that there is a use of comparative adjectives that is not relativised to a comparison class, but rather to a perspective. Ant Z does not say that Muggsy is huge for a human, or for an NBA player, but just relative to him. And he’s right. Even Muggsy is huge relative to an ant. Note the contrast with (36) here. There’s something quite odd about Leopold’s statement, which intuitively means that someone said Terrell is old and slow for a graduate student, when all that was said was that he is old and slow for an NFL player.30 And, relative to the Martian’s classification of objects into colours, the two swatches are the same colour. So there’s something very odd going on here.\n30 Or perhaps something more specific than that, such as that he is old and slow for a player at his position.The following very plausible principle looks like it is being violated.\n\nTruth in Reporting\n\nIf X has a true belief, then Y’s report X believes that S accurately reports that belief only if in the context Y is in, S expresses a true proposition.31\n31 One might also consider a ‘says that’ version of Truth in Reporting: If X speaks true, then Y’s report X says that S is accurate only if in the context Y is in, S expresses a true proposition. This is more questionable, since it is questionable whether ‘says that’ constructions must report what is semantically expressed by a speech, as opposed to what is merely communicated. See again the papers mentioned in footnote 25.\n\nNot only do our three reports here seem to constitute counterexamples to Truth in Reporting, Watson’s report in (30) is also such a counterexample, if Moriarty speaks truly (and sincerely). One response here would be to give up Truth in Reporting, but that seems like a desperate measure. And we would still have the puzzle of why we can’t say “and he’s right” at the end of an accurate report.\nAnother response to these peculiar phenomena would be to follow the universalist and conclude that Moriarty, Vinny, Ant Z and Marvin all believe something false. It should be clear how to formulate this kind of position: something tastes great iff every creature thinks it tastes great; something is huge iff it is huge relative to all observers; and two things are the same colour iff they look alike (in a colour kind of way) to every observer (in conditions that are normal for them). As we saw, there are problems for the universalist move for epistemic modals. And the attractiveness of the other universal seems to dissipate when we consider the cases from a different perspective.\n\nBrian: Cognac tastes great.\nVinny: Brian believes that cognac tastes great.\n\nAndy:He’s huge (said of Buggsy Mogues, the shortest ever player in the Dinosaur Basketball Association).\nTyrone the T-Rex: Andy believes that Buggsy’s huge.\n\nJohn: These are the same colour (said of two colour swatches that look alike to humans but not to pigeons).\nPete the Pigeon: John believes that these are the same colour.\n\nAgain, every report seems acceptable, and in every case it would seem strange for the reporter to continue “and he’s right.” The universalist explanation in every case is that the original utterance is false. That certainly explains the data about reports, but look at the cost! All of our utterances about colours and tastes will turn out false, as will many of our utterances about sizes. It seems we have to find a way to avoid both contextualism and universalism. Our final suggestions for how to think about epistemic modals attempt to explain all this data.\n\n\n0.5 Relativism and Centred Worlds\nJohn MacFarlane (2003) has argued that believers in a metaphysically open future should accept that the truth of an utterance is relative to a context of evaluation.32 For example, if on Thursday Emily says, “There will be a sea battle tomorrow”, the believer in the open future wants to say that at the time her utterance is neither determinate true nor determinately false. One quick objection to this kind of theory is that if we look back at Emily’s statement while the sea battle is raging on Friday, we are inclined to say that she got it right. From Friday’s perspective, it looks like what Emily said is true. The orthodox way to reconcile these intuitions is that the only sense in which Emily’s statement is indeterminate on Thursday is an epistemic sense – we simply don’t know whether there will be a sea battle. MacFarlane argues instead that we should simply accept the intuitions as they stand. From Friday’s perspective, Emily’s statement is determinately true, from Thursday’s it is not. Hence the truth of statements is relative to a context of evaluation.\n32 We are very grateful in this section to extensive conversations with John MacFarlane. His (2003) was one of the main inspirations for the relativist theory discussed here. His (ms), which he was kind enough to show us a copy of while we were drafting this paper, develops the argument for a relativist approach to epistemic modals in greater detail than we do here. Mark Richard also has work in progress that develops a relativist view on related matters, which he has been kind enough to show us, and which has also influenced our thinking.There is a natural extension of this theory to the cases described above. Moriarty’s statement is true relative to a context C iff it is compatible with what the people in C know that Holmes is in Paris. So in the context he uttered it, the statement is true, because it is consistent with what everyone in his context knows that Holmes is in Paris. But in the context of Watson’s report, it is false, because Watson and Holmes know that Holmes is not in Paris.\nWe will call any such theory of epistemic modals a relativist theory, because it says that the truth of an utterance containing an epistemic modal is relative to a context of evaluation. As we will see, relativist theories do a much better job than contextualist theories of handling the data that troubled contextualist theories. Relativist theories are also plausible for the predicates we discussed at the end of the last section: ‘huge’, ‘color’ and ‘tastes’. On such a theory, any utterance that x tastes F is true iff x tastes F to us. Similarly, an utterance x is huge that doesn’t have a comparison class, as in (41) or (44), is true iff x is huge relative to us. And Those swatches are the same color is true iff they look the same colour to us. The reference to us in the truth conditions of these sentences isn’t because there’s a special reference to us in the lexical entry for any of these worlds. Rather, the truth of any utterance involving these terms is relative to a context of evaluation, and when that is our context of evaluation, we get to determine what is true and what is false. If the sentences were being evaluated in a different context, it would be the standards of that context that mattered to their truth.\nSo far we have not talked about the pragmatics of epistemic modals, assuming that their assertability conditions are given by their truth conditions plus some familiar Gricean norms. But it is not obvious how to apply some of those norms if utterance truth is contextually relative, because one of the norms is that one should say only what is true.\nOne option is to say that utterance appropriateness is, like utterance truth, relative to a context of evaluation. This is consistent, but it does not seem to respect the data. Watson might think that Moriarty’s utterance is false, at least relative to his context of evaluation33, but if he is aware of Moriarty’s epistemic state he should think it is appropriate. So if something like truth is a norm of assertion, it must be truth relative to one or other context. But which one?\n33 We do not assume here that ordinary speakers, like Watson, explicitly make judgments about the truth of utterances relative to a context of evaluation, as such. They do make judgments about the truth of utterances, and those judgments are made in contexts, but they don’t explicitly makes judgments of truth relative to context of evaluation. One of the nice features, however, of the relativist account is that it is possible to do an attractive rational reconstruction of most of their views in terms of contexts.We could say that one should only say things that are true relative to all contexts. But that would mean John’s statement about the two swatches being the same colour would be inappropriate, and that seems wrong.\nWe could say that one should only say things that are true relative to some contexts. But then Brian could have said, “Rotting carcases taste great” and he would have said something appropriate, because that’s true when evaluated by vultures.\nThe correct norm is that one should only say something that’s true when evaluated in the context you are in. We assume here that contexts can include more than just the speaker. If Vinny the Vulture is speaking to a group of humans he arguably cannot say Rotting flesh tastes great. The reason is that rotting flesh does not taste great to the group of speakers in the conversation, most of whom are humans. This norm gives us the nice result that Myles’s statement is appropriate, as is Moriarty’s, even though in each case their most prominent audience member knows they speak falsely.34\n34 Can we even say that someone speaks falsely here now that truth and falsity is always relative to a context of evaluation? It turns out we can, indeed we must, although the matter is a little delicate. We return to this point below.This helps explain, we think, the somewhat ambivalent attitude we have towards speakers who express epistemic modals that are false relative to our context, but true relative to their own. What the speaker said wasn’t true, so we don’t want to endorse what they said. Still, there’s still a distinction between such a speaker and someone who says that the sky is green or that grass is blue. That speaker would violate the properly relativised version of the only say true things rule, and Myles and Moriarty do not violate that rule.\nAs MacFarlane notes, relativist theories deny Absoluteness of Utterance Truth, the claim that if an utterance is true relative to one context of evaluation it is true relative to all of them. It is uncontroversial of course that the truth value of an utterance type can be contextually variable, the interesting claim that relativists make is that the truth value of utterance tokens can also be different relative to different contexts. So they must deny one or more premises in any argument for Absoluteness of Utterance Truth, such as this one.\n\nAbsoluteness of Propositional Content: If an utterance expresses the proposition p relative to some context of evaluation, then it expresses that proposition relative to all contexts of evaluation.\nAbsoluteness of Propositional Truth Value: If a proposition p is true relative to one context in a world it is true relative to all contexts in that world; therefore,\nAbsoluteness of Utterance Truth\n\nThis argument provides a nice way of classifying relativist theories. One relativist approach is to say that Moriarty (or anyone else who utters an epistemic modal) says something different relative to each context of evaluation. Call this approach content relativism. Another approach is to say that there is a single proposition that he expresses with respect to every context, but the truth value of that proposition is contextually variable. Call this approach truth relativism. (So that the meaning of ‘proposition’ is sufficiently understood here, let us stipulate that we understand propositions to be the things that are believed and asserted and thus, relatedly, the semantic values of ‘that’-clauses.)\nIt might look like some of our behaviour is directly inconsistent with any sort of relativism. Consider the following dialogue.\n\nVinny: Rotting flesh tastes great\nVinny’s brother: That’s true.\nJohn: That (i.e. what Vinny’s brother said) is not true.\n\nIf what Vinny’s brother is saying is that Vinny’s utterance Rotting flesh tastes great is true in his context, then John is wrong in saying that what Vinny’s brother said isn’t true. For it is true, we claim, that Rotting flesh tastes great is true in Vinny’s context.35 But this prediction seems unfortunate, because John’s utterance seems perfectly appropriate in his context.\n35 We assume here the vultures are talking mainly to other vultures, and John is talking mainly to other humans.36 We are grateful to John Macfarlane for helpful correspondence that influenced what follows.The solution here is to recognise a disquotational concept of truth, to go alongside the binary concept of truth that is at the heart of the relativist solution.36 The binary concept is a relation between an tterance and a context of evaluation. Call this trueB. So Vinny’s utterance is trueB relative to his context, and to his brother’s context, and falseB relative to John’s context. One crucial feature of the binary concept is that it is not a relativist concept. If it is true relative to one context that an utterance is trueB relative to context C, it is true relative to all contexts that the utterance is trueB relative to context C. The disquotational concept is unary. Call this trueT. As far as is permitted by the semantic paradoxes, it claims that sentences of the form S is trueT iff S will be trueB relative to any context (note here the primacy of truthB for semantic explanation) TrueT is a relative concept. An utterance can be trueT relative to C and not trueT relative to C\\(^\\prime\\). When an utterance is given the honorific true in ordinary discourse, it is the unary relative concept trueT that is being applied. That explains what is going on in (46). Vinny’s brother says that Vinny’s utterance is trueT. Relative to his context, that’s right, since Vinny’s utterance is true in his context. But relative to John’s context, that’s false, because an utterance is trueT relative to John’s context iff it is true relative to John’s context. So John spoke truly relative to his own context, so he spoke correctly. The important point is that assignments of truthT are relative rather than contextually rigid, so they might be judged true relative to some contexts and false relative to others.\nAlthough both truth relativism and content relativism can explain (46) if they help themselves to the distinction between truthB and truthT, there are four major problems for content relativism that seem to show it is not the correct theory.\nThe first problem concerns embeddings of “might” clauses in belief contexts. Suppose Watson says,\n\nMoriarty believes that Holmes might be in Paris.\n\nOn the content relativist view, (47) will say, relative to Watson, that Moriarty believes that, as far as Watson knows, Holmes is in Paris. That would be a crazy thing for Watson to assert. Suppose Watson is talking to Holmes. Then, relative to Holmes, Watson will have claimed that Moriarty believes that, as far as Holmes knows, Holmes is in Paris. That would also be a crazy thing for Watson to assert. But, given what he’s just overheard, it would be perfectly natural—and pretty clearly correct, so long as nothing funny is going on behind the scenes—for Watson to assert (47). A view that tells us that Watson’s saying something crazy relative to everybody who’s likely to be a member of his audience is in pretty serious conflict with our pretheoretical judgements about the case. (Enlarging the context to include both Holmes and Watson obviously doesn’t help, either.)\nThe second problem concerns the social function of assertion. In particular, it causes difficulties for an attractive part of the Stalnakerian story about assertion, that the central role of an assertion is to add the proposition asserted to the stock of conversational presuppositions (Stalnaker 1978). On the content relativist view, it can’t be that the essential effect of assertion is to add the proposition asserted to the stock of common presuppositions, because there’s no such thing as the proposition asserted. There will be a different proposition asserted relative to each audience member. That’s not part of an attractive theory. And it’s not terribly clear what the replacement story about the essential effect of assertion—about the fundamental role of assertion in communication—is going to be. It may be that there’s a story to be told about assertability—about when Moriarty is entitled to assert, for example, “it might be that Holmes is in Paris”—but there’s no obvious story about what he’s up to when he’s making that assertion—about what the assertion is supposed to accomplish. (And if you think that appropriateness of assertion’s got to be tied up with what your assertion’s supposed to accomplish, then you’ll be sceptical about even the first part.)\nThe third problem concerns epistemic modals in the scope of temporal modifiers. The content relativist has difficulties explaining what’s going on with sentences like (48).\n\nThe Trojans were hesitant in attacking because Achilles might have been with the Greek army.\n\nOn the content relativist view, (48) will be false relative to pretty much everybody—certainly relative to everybody alive today. It’s certainly false that the Trojans were hesitant because, as far as we know, Achilles was with the Greek army. (Or worse, because, as far as we knew then, Achilles was with the Greek army.) But, depending on how the Trojan war went, (48) could be true relative to everybody.37\n37 We don’t take any stand here on just how the war went, if it happened at all. The important point is that whether (48) is true when said of a particular battle is a wide-open empirical question, not one that can be settled by appeal to the semantics of might. The content relativist says, falsely, that it can be thus settled.Finally, content relativism has a problem with commands. Keith’s Mom says:\n\nFor all days d, you should carry an umbrella on d if and only if it might rain on d.\n\nSuppose on Monday Keith checks the forecast and it says there’s a 50% chance of rain. So he takes an umbrella. It doesn’t rain, and on Tuesday he wonders whether what he did on Monday was what his Mom said he should. On the content relativist view, we get the following strange result: on Monday, it would have been true to say that he was doing what his Mom said he should, since at the time, the embedded clause expressed a proposition that was true relative to him. Looking back on Tuesday, though, it looks like he did what his Mom said he shouldn’t, because now the embedded clause expresses a proposition that’s false relative to him. But that’s not right. He just plain did what his Mom told him to do.\nThe same thing happens with the soldiers trying to follow the imperative issued as (22). Assume one of them attempts to follow the command by burning down some trees that seem to contain snipers. Relative to the time she is doing the burning, she will be complying with the command. But later, when it turns out the trees were sniper-free, she will not have been following the command. If we assume there’s an overarching command to not use flamethrowers unless explicitly instructed to do so, then it will turn out that, as of now, she violated her orders then. But that’s not right. She just plain followed her orders.\nThere’s a similar problem with the other terms about which relativism seems plausible. Consider the following commands:\n\nDon’t pick fights with huge opponents.\nStack all of the things that are the same color together.\nIf it tastes lousy, spit it out.\n\nIt’s possible to sensibly issue these commands, even in relevantly mixed company. And if we’re going to get the right compliance conditions, we don’t want content relativism about great-tastingness, hugeness, and same-coloredness here. When we hear a command like (52), we take (a) the same command to have been issued to everybody, and (b) everybody to be following it if we all spit out the things that taste lousy to us. On the content relativist view, we’ve each gotten different commands, and the philosopher who spits out the chunk of week-old antelope hasn’t complied with the command that Vinny was given. This seems wrong.\nSo the content relativist theory has several problems. The truth relativist theory does much better. Let us begin with the familiar notion of a function from worlds to truth values. Call any such function a Modal Profile. On the standard way of looking at things, propositions – the objects of belief and assertion, the semantic values of ‘that’-clauses – are, or at least determine a Modal Profile. The truth relativist denies this. According to the truth-relativist, the relevant propositions are true or false not relative to worlds, but relative to positions within worlds—that is, they’re true or false relative to centered worlds. (A centered world is a triple of a possible world, an individual, and a time.) There’s a few ways to formally spell out this idea. One is to replace talk of Modal Profiles with Centring Profiles, i.e. functions from centred worlds to truth values. Another is to say that a centred world and proposition combine to determine a Modal Profile, so propositions determine functions from centred worlds to Modal Profiles. Each of these proposals has some costs and benefits, and we postpone discussion of their comparative virtues to an appendix. For now we are interested in the idea, common to these proposals, that propositions only determine truth values relative to something much more fine-grained than a world. (We take no stand here on whether propositions should be identified with either Modal Profiles or Centering Profiles or functions from Centred Worlds to Modal Profiles).\nTruth relativism is not threatened by the four problems that undermine content relativism.\nAccording to truth relativism, Watson and Moriarty express the very same proposition by the words Holmes might be in Paris, so it is no surprise that Watson can report Moriarty’s assertive utterance by using the very same words. Similarly, it is no surprise that if Moriarty has a belief that he would express by saying Holmes might be in Paris, Watson can report that by (53).\n\nMoriarty believes that Holmes might be in Paris.\n\nAbove we noted that it’s unlikely that Watson could use this to express the proposition that for all Watson knows Holmes is in Paris. We used that fact to argue that DeRose’s constraint did not apply when an epistemic modal is inside a propositional attitude report. The truth relativist theory predicts not only that DeRose’s constraint should not apply, but that a different constraint should apply. When one says that a believes that b might be F, one says that a believes the proposition b might be F. And a believes that proposition iff a believes it is consistent with what they know that b is F. And that prediction seems to be entirely correct. It is impossible for Watson to use (53) to mean that Moriarty believes that for all Holmes knows he is in Paris, or that for all Watson knows Holmes is in Paris. This seems to be an interesting generalisation, and while it falls out nicely from the truth relativist theory, it needs to be imposed as a special constraint on contextualist theories.\nSince there is a proposition that is common to speakers and hearers when an epistemic modal is uttered, we can keep Stalnaker’s nice idea that the role of assertion is to add propositions to the conversational context. Since propositions are no longer identified with sets of possible worlds we will have to modify other parts of Stalnaker’s theory, but those parts are considerably more controversial.\nThe truth relativist can also explain how (48) can be true, though the explanation requires a small detour through the nature of psychological explanations involving relativist expressions go.\n\nThe Trojans were hesitant in attacking because Achilles might have been with the Greek army.\n\nAll of the following could be true, and not because the things in question are rude, huge or great tasting for us.\n\nMarvin the Martian dropped his pants as the Queen passed by because it would have been rude not to.\nChildren are scared of adults because they are huge.\nVultures eat rotting flesh because it tastes great.\n\nIn general it seems that the truth of an explanatory claim of the form, X \\(\\varphi\\)ed because p depends only on whether p is true in X’s context (plus whether the truth of p in X’s context bears the right relation to X’s \\(\\varphi\\)ing).. Whether or not p is true in our context is neither here nor there. Adults are not huge, rotting flesh does not taste great, and it is rude to drop one’s pants as the Queen passes by, but (54)-(56) could still be true, and could all count as good explanations. Similarly, (48) can be true because Achilles might have been with the Greek army could be true relative to the Trojans.\nSimilarly, what it is to comply with a command is to act in a way that makes the command true in the context of action. This is not a particular feature of epistemic modals, but just a general property of how commands involving propositions with centered-worlds truth conditions behave. If Don picks a fight with Pedro after Don has shrunk so much that Pedro is now relatively huge, he violates (50), even if Pedro was not huge when the command was issued. And he still violates it from a later perspective when Pedro and Don are the same size. The general point is that whether the command is violated depends on the applicability of the salient terms from the perspective of the person to whom the command applies. Similarly, Keith does not violate his Mom’s command if he takes an umbrella where It might rain is true in the context the action is performed. And this, of course, matches up perfectly with intuitions about the case.\nIt’s a little tricky to say just which statement in Professor Granger’s original hexalemma gets denied by the truth relativist. It all depends what we mean by spoke truly. If Myles spoke truly means that Myles said something trueT, then (2) is false (relative to Granger’s context), for its right-hand-side is true but its left-hand-side is false. If, on the other hand, it means he said something trueB relative to his own context, then (4) is false, for he did speak trulyB relative to his context, but it’s not the case that Professor Granger might be in Prague. This is awkward, but we might expect that any good solution to the paradox will be awkward.\n\n\n0.6 Objections to Truth Relativism\nIt might be thought that the truth relativist has to deny Truth in Reporting, but in fact this can be retained in its entirety provided we understand it the right way. The following situation is possible on the truth relativist theory. X has a belief that is true in her context, and Y properly reports this by saying X believes that S, where S in Y’s mouth expresses a proposition that is false in Y’s mouth in her context. But this is no violation of Truth in Reporting. What would be a violation is if X’s belief was true in Y’s context, and still Y could report it as described here. But there’s no case where, intuitively, we properly report an epistemic modal but violate that constraint. And the same holds for reports of uses of huge, color or tastes. Even if Vinny (truly) believes that rotting flesh tastes great, and the words “Rotting flesh tastes great” in John’s mouth express a false proposition, John’s report, “Vinny believes that rotting flesh tastes great” would only violate Truth in Reporting if Vinny’s belief is still true in John’s context. And it is not.\nGiven that the relativist has the concept of truthT, or as we might put it truth simpliciter, what should be done with it? The answer seems to be not much. We certainly shouldn’t restate the norms of assertion in terms of it, because that will lead to the appropriateness of assertion being oddly relativised. Whether it was appropriate for Vinny to say “Rotting flesh tastes great,” is independent of the context of evaluation, even if the truth of what he uttered is context-relative. (It would not at all be appropriate for him to have said “Rotting flesh tastes terrible” even though we should think he would have said something true by that remark, and something false by what he actually said.) And the same thing seems to hold for generalisations about truth as the end of belief. It is entirely appropriate for Myles to believe that Granger might be in Prague, because it’s trueB relative to his context. Relatedly, if knowledge is tied to truthT rather than truthB, knowledge can’t be the norm of assertion or end of belief.38 On the other hand, using truthT we can say that Truth in Reporting is true in the truth relativist theory without reinterpreting it in terms of relative truth concepts. Moreover, we can invoke truthT to explain why we got confused when thinking about the original puzzle: It is arguable that, even if we should distinguish truthT from truthB in our semantic theorizing, we aren’t unreflectively as clear about that distinction as we might be. No wonder then that we get a little confused as we think about the Granger case. We want to say Myles doesn’t make a mistake. And we also want to say “That’s wrong” speaking of the object of his assertion and belief, and what’s more, when we say that, we don’t seem to be making a binary claim about the relation between ourselves and what is believes. Once we clearly distinguish truthT from truthB things become clearly. Using the disquotational notion, we can say ‘That is falseT’, which is a monadic claim, and not a binary one. The binary truthB explains why that claim is assertable (it is assertable because ‘That is falseT’ is truthB at my context), but doesn’t figure in the proposition believed. Meanwhile, the relevant notion of mistake – that of an agent believing a proposition that is not trueB at her context, can only be properly articulated once the distinction between the more explanatory truthT is carefully distinguished from the (arguably) conceptually more basic truthB.\n38  Arguably, then, one will have to distinguish (and posit an ordinary conflation between) knowledgeT from knowledgeB, the latter being needed to make good on the normative importance of knowledge, the former being need to make sense of the validity of the inference from knowing that p to p. Is trouble lurking here for the truth relativist, especially given link between the truthB of ‘might’ claims and facts about knowledge? We shall not pursue the matter further here.One final expository point. In general, truth relativism makes for irresolvable disputes. Let us say that two conversational partners are in deadlock concerning a claim when the following situation arises: There is a pair of conversational participants, x and y, and a sentence S, under dispute, such that each express the same proposition (in the sense explained) by S but that S is trueB at each of the contexts x is in during the conversation, and falseB at each of the contexts y is in during the conversation. Neither speaks past one another in alternately asserting and denying the same sentence, since each expresses the same proposition by it. And each asserts what they should be asserting when each says: What I say is truthT and what the other says is falseT., since each makes a speech that is trueT at the respective contexts. In general, truth relativism about a term will lead one to predict deadlock for certain conversations, traceable to the truth relativity of the term. But in the case of ‘might’, it is arguable that conversation tends to force a situation where, even if at the outset, a ‘might’ sentence was true relative to x and not to y (on account of the truth-relativity of the ‘might’ sentence), x and y will, in the course of engagement and dispute, be quickly put into a pair of contexts which do not differ with respect to truthB (unless the ‘might’ sentence contained other terms that themselves made for deadlock). This is not merely because the conversational participants will, through testimony, pool knowledge about the sentence embedded in the ‘might’ claim. It is in any case arguable that the relevant community whose body of knowledge determines whether a ‘might’ claim is trueB at a context always includes not just that of the person at that context but also that of his conversational partners. In the special case of ‘might’, then, Truth Relativism may well generate far less by way of deadlock than in other cases.\nThere are two primary objections to the truth relativist theory: it doesn’t quite handle all the cases and that it is too radical.\nThere are some cases that seem to tell directly against the truth relativist position. Consider the case again of Tom and Sally stuck in a maze. Sally knows the way out, but doesn’t want to tell Tom. She says, inter alia, (57), and does not seem to violate any semantic norms in doing so, even though she knows the exit is some other way.\n\nThe exit might be that way.\n\nThis seems to directly contradict the relativist claim that the norm for assertion is speaking truly in one’s own context. We suspect that what’s going on here is that Sally is projecting herself into Tom’s context. She is, we think, merely trying to verbalise thoughts that are, or should be, going through Tom’s head, rather than making a simple assertion. As some evidence for this, note (as was mentioned above) that it would be wrong to take (57) as evidence that Sally believes the exit might be that way, whereas when a speaker asserts that p that is usually strong evidence that she believes that p. It is unfortunate for the relativist to have to appeal to something like projection, but we think it is the simplest explanation of these cases that any theorist can provide.\nThe idea that utterances have their truth value absolutely is well-entrenched in contemporary semantics, so it should only be overturned with caution. And it might be worried that once we add another degree of relativisation, it will be open to relativise in all sorts of directions. We are sensitive to these concerns, but we think the virtues of the relativist theory, and the vices of the contextualist and invariantist theories, provides a decent response to them. Invariantist theories are simply implausible, and any contextualist theory will have to include so many ad hoc conditions, conditions that seem to be natural consequences of relativism, that there are methodological considerations telling in favour of relativism. (Let us be clear: we are not recommending a general preference for relativism over contextualism in semantic theory. As we have been trying to make clear, for example, the case of ‘might’ is very different from, say, the case of ‘ready’.) It is (as always) hard to tell which way the balance tips when all these methodological considerations are weighed together, but we think the relativist has a good case.\n\n\nAppendix on Types of Content\nRobert Stalnaker has long promoted the idea that the content of an assertoric utterance is a set of possible worlds, or a function from worlds to truth values. This idea has been enormously influential in formal semantics, although it has come in for detailed criticism by various philosophers. (See especially Soames (1987) and King (1994, 1995, 1998).) But even philosophers who think that there is more to content than a set of possible worlds would agree that propositions determine a function from worlds to truth values. Some would agree that such a function exhausts the ‘discriminatory role’ of a proposition, although this depends on the (highly contestable) assumption that the role of propositions is to discriminate amongst metaphysical possibilities. Still, even philosophers who disagree with what Stalnaker says about the nature of propositions could agree that if all we wanted from a proposition was to divide up some metaphysical possibilities, propositions could be functions from worlds to truth values, but they think some propositions that divide up the metaphysical possibilities the same way should be distinguished.\nWe don’t want to take sides in that debate, because our truth relativism means we are in conflict with even the idea that a proposition determines a function from worlds to truth values. To see this, consider a sentence whose truth value is relative to a context of evaluation, such as Vegemite tastes great. The truth relativist says that this sentence should be evaluated as true from a context where people like the taste of Vegemite (call this the Australian context) and should be evaluated as false from a context where people dislike this taste (call that the American context) and both evaluations are correct (from their own perspective) even though the Australians and Americans agree about what the content of Vegemite tastes great is, and they are in the same world. So there’s just no such thing as the truth value of Vegemite tastes great in the actual world, so it does not determine a function from worlds to truth values. What kind of function does it determine then?\nOne option, inspired by Lewis’s work on de se belief, is to say that it determines a function from centred worlds to truth values. The idea is that we can identify a context of evaluation with a centred world, and then Vegemite tastes great will be true relative to a centred world iff it is properly evaluated as true within that context. Alternatively, the content of Vegemite tastes great will determine a set of centred worlds, the set of contexts from which that sentence would be evaluated as true. Just as propositions were traditionally thought to determine (or be) sets of possible worlds, properties were traditionally thought to determine (or be) functions from worlds to sets of individuals.39 Now if we identify centred worlds with \\(\\langle\\)individual, world\\(\\rangle\\) pairs, a function from worlds to sets of individuals just is a set of centred worlds.40 So the content of Vegemite tastes great could just be a property, very roughly the property of being in a context where most people are disposed to find Vegemite great-tasting.\n39  Lewis preferred the theory on which properties were sets of individuals, potentially from different worlds. This theory has difficulties accounting for individuals that exist in more than one world. And since properties exist in more than one world, and properties have to be treated as individuals in some contexts (e.g. when they are the subjects of predication) this is a serious problem. Treating properties as functions from worlds to sets of individuals removes this problem without introducing any other costs. (See Egan (2004) for more details.)40 Matters are a little more complicated when we introduce times into the story. For purposes of this appendix we ignore all matters to do with tense. As you’ll see, the story is complicated enough as it is, and this omission doesn’t seriously affect the dialectic to follow.41 It might be that propositions just are whatever things are the contents of assertions and beliefs, so we shouldn’t say that the contents of sentences like Vegemite tastes great are not propositions. But they will be very different kinds of propositions to what we are used to. Thanks here to John MacFarlane.This proposal has three nice features. First, even though the content of Vegemite tastes great is not, and does not even determine, a proposition as Stalnaker conceived of propositions, it does determine a property. So the proposal is not as radical as it might at first look. Second, properties are the kind of thing that divide up possibilities. The possibilities they divide are individuals, not worlds, but the basic idea that to represent is to represent yourself as being in one class of possible states rather than another is retained. The only change is that instead of representing yourself as being in one class of worlds rather than another, you represent yourself as being in one class of \\(\\langle\\)individual, world\\(\\rangle\\) pairs rather than another. Third, the proposal links up nicely with David Lewis’s account of de se belief, and offers some prospects for connecting the contents of beliefs with the contents of assertions, even when both of these contents have ceased to be propositions in Stalnaker’s sense.41\nBut there’s a problem for this account. Consider what we want to say about Possibly Vegemite tastes great, where context makes it clear that the ‘possibly’ is a metaphysical modal. There’s a trivial problem and a potentially deep problem for this account. The trivial problem is that we know what the meaning of possibly is. It’s a function that takes propositions as inputs and delivers as output a proposition that is true iff the input proposition is true at an accessible world. If the content of Vegemite tastes great is a property rather than a proposition, then we have a type-mismatch. This is a trivial problem because it’s a fairly routine exercise to convert the meanings of words like possibly so they are the right kind of things to operate on what we now take the meaning of Vegemite tastes great to be.\nThe deep problem is that when we go through that routine exercise, we get the wrong results. We don’t want Possibly Vegemite tastes great to be true in virtue of there being an accessible world where the people there like the taste of Vegemite. We want it to be true in virtue of there being a world where Vegemite’s taste is a taste that in this context we’d properly describe as great. And it’s not clear how to get that on the current story. To see how big a problem this is, consider (58), where the modal is meant to be metaphysical and have wide scope.\n\nPossibly everyone hates Vegemite but it tastes great.\n\nThat’s true, on its most natural reading. But the content of Everyone hates Vegemite but it tastes great will be the empty set of centred worlds, for there is no centred world on which this is true. Now it’s not clear just what the meaning of possibly could be that delivers the correct result that (58) is true.\nSo we are tempted to consider an alternative proposal. Start with a very natural way of thinking about why the relativist has to modify the Stalnakerian story about content. The problem is that (even given a context of utterance) tastes great does not determine a property. Rather, relative to any context of evaluation, i.e. centred world, it determines a property. That is, its content is (or at least determines) a function from centred worlds to properties. So given our actual context, it determines the property of having a taste that people around here think is great. Now properties combine with individuals to form Stalnakerian propositions. So tastes great is a function from centred worlds to functions from individuals to sets of worlds. Hence Vegemite tastes great is a function from centred worlds to sets of worlds, the previous function with the value for the ‘individual’ being fixed as Vegemite.\nOur second option then is that in general that sentences containing ‘relative’ terms like ‘tastes’ or ‘huge’ or ‘might’ determines a function from centred worlds to sets of worlds. This makes it quite easy to understand how (58) could work. Possibly type-shifts so that it is now a function from functions from centred worlds to sets of worlds to functions from centred worlds to sets of worlds. It’s fairly easy to say what this function is. If the content of p is (or determines) f, a function from centred worlds to sets of worlds, then the content of \\(\\lozenge p\\) is (or determines) g, the function such that for any centred world c, w \\({\\in}\\) g(c) iff for some w\\(^\\prime\\) accessible from w, w\\(^\\prime\\) \\({\\in}\\) f(c). The core idea is just that we ignore the role of the centred worlds until the end of our semantic evaluation, and otherwise just treat \\(\\lozenge\\) as we’d treated it in traditional semantics. This is a rather nice position in many ways, but there are two issues to be addressed.\nFirst, it is not clear that functions from centred worlds to sets of worlds are really kinds of content. They are not things that divide up intuitive possibilities, in the way that sets of individuals, and sets of \\(\\langle\\)individual, world\\(\\rangle\\) pairs do. It’s no good to say that relative to a centred world a content is determined. That would be fine if we were content relativists, and we said the content was meant to be determined relative to a centred world. But as argued in the text the content of Vegemite tastes great should be the same across various contexts of evaluation. A better response is to say functions from centred worlds to sets of worlds do determine a kind of content. For any such function f, we can determine the set of centred worlds \\(\\langle\\)i, w\\(\\rangle\\) such that w \\({\\in}\\) f(\\(\\langle\\)i, w\\(\\rangle\\)). These will be the centred worlds that the proposition is true at. It’s not necessarily a problem that the proposition does more than determine this set. (It’s not an objection to King’s account of propositions that on his theory propositions do more than determine a set of possibilities.)\nSecond, it isn’t exactly clear how to fill out these functions when we get back to our core case: epistemic modals. It’s easy to say what it is for Vegemite tastes great to be true in a world relative to our context of evaluation; indeed we did so above. It’s a lot harder to say what it is for Granger might be in Prague to be true in an arbitrary world w relative to an arbitrary context of evaluation c. As a first pass, we might say this is true in w iff for all the people in c know, it is true in w that Granger is in Prague. But the problem is that whenever c is not a centre in w, it’s very hard to say just what the people in c know about w. Under different descriptions of w they will know different things about it. If w is described as a nearby world in which Granger is in Cleveland, they will know Granger is not in Prague in w. If it is described as a nearby world in which Myles knows where Granger is they may not know anything about whether Granger is in Prague is in w, even if those descriptions pick out the same worlds. Ideally we would cut through this by talking about their de re knowledge about w, but most folks have very little de re knowledge about other possible worlds. It’s not clear this is a huge problem though. Remember that a sentence containing an epistemic modal is meant to determine a function from centred worlds to functions from worlds to truth values. Provided we have a semantics that allows for semantic indeterminacy, we can just say that the functions from worlds to truth values are partial functions, and they simply aren’t determined when it’s unclear what the people in c know about w. Or we can say there’s a default semantic rule such that w is not in f(c) (where f is the function determined by the sentence) whenever this is unclear. Since the sentences whose meanings are determined by these values of the function, like Possibly Granger might be in Prague are similarly vague, it is no harm if the function is a little vague.\nSo we have two options on the table for what kind of functions sentences might determine if they don’t determine functions from world to truth values. One option is that they determine functions from centred worlds to truth values, another that they determine functions from centred worlds to functions from worlds to truth values. Neither is free from criticism, and the authors aren’t in agreement about which is the best approach, so it isn’t entirely clear what the best way to formally implement truth relativism is. But it does not look like there are no possible moves here. Moving to truth relativism does not mean that we will have to totally abandon the fruitful approaches to formal semantics that are built on ideas like Stalnaker’s, although it does mean that those semantic theories will need to be modified in places.\n\n\n\n\n\n\nReferences\n\nCapellen, Herman, and Ernest Lepore. 1997. “On an Alleged Connection Between Indirect Quotation and Semantic Theory.” Mind and Language 12 (3-4): 278–96. https://doi.org/10.1111/j.1468-0017.1997.tb00075.x.\n\n\nDeRose, Keith. 1991. “Epistemic Possibilities.” Philosophical Review 100 (4): 581–605. https://doi.org/10.2307/2185175.\n\n\n———. 1998. “Simple Might’s, Indicative Possibilities, and the Open Future.” The Philosophical Quarterly 48 (190): 67–82. https://doi.org/10.1111/1467-9213.00082.\n\n\nEgan, Andy. 2004. “Second-Order Predication and the Metaphysics of Properties.” Australasian Journal of Philosophy 82 (1): 48–66. https://doi.org/10.1080/713659803.\n\n\nFintel, Kai von, and Sabine Iatridou. 2003. “Epistemic Containment.” Linguistic Inquiry 34 (2): 173–98. https://doi.org/10.1162/002438903321663370.\n\n\nHawthorne, John. 2004. Knowledge and Lotteries. Oxford: Oxford University Press.\n\n\nHorn, Laurence. 1989. A Natural History of Negation. Chicago: University of Chicago Press.\n\n\nJacobson, Pauline. 1999. “Towards a Variable Free Semantics.” Linguistics and Philosophy 22 (2): 117–84. https://doi.org/10.1023/A:1005464228727.\n\n\nKing, Jeffrey. 1994. “Can Propositions Be Naturalistically Acceptable?” Midwest Studies in Philosophy 19 (1): 53–75. https://doi.org/10.1111/j.1475-4975.1994.tb00279.x.\n\n\n———. 1995. “Structured Propositions and Complex Predicates.” Noûs 29 (4): 516–35. https://doi.org/10.2307/2216285.\n\n\n———. 1998. “What Is a Philosophical Analysis?” Philosophical Studies 90 (2): 155–79. https://doi.org/10.1023/A:1004254128428.\n\n\nLewis, David. 1976. “The Paradoxes of Time Travel.” American Philosophical Quarterly 13 (2): 145–52.\n\n\n———. 1979. “Scorekeeping in a Language Game.” Journal of Philosophical Logic 8 (1): 339–59. https://doi.org/10.1007/bf00258436.\n\n\nMacFarlane, John. 2003. “Future Contingents and Relative Truth.” The Philosophical Quarterly 53 (212): 321–36. https://doi.org/10.1111/1467-9213.00315.\n\n\nPagin, Peter. 2005. “Compositionality and Context.” In Contextualism in Philosophy: Knowledge, Meaning, and Truth, edited by Gerhard Preyer and Georg Peter, 303–48. Oxford: Oxford University Press.\n\n\nSoames, Scott. 1987. “Direct Reference, Propositional Attitudes and Semantic Content.” Philosophial Topics 15 (1): 47–87. https://doi.org/10.5840/philtopics198715112.\n\n\n———. 2002. Beyond Rigidity. Oxford: Oxford University Press.\n\n\nStalnaker, Robert. 1978. “Assertion.” Syntax and Semantics 9: 315–32.\n\n\nStanley, Jason. 2000. “Context and Logical Form.” Linguistics and Philosophy 23 (4): 391–434. https://doi.org/10.1023/A:1005599312747.\n\n\nStanley, Jason, and Zoltán Gendler Szabó. 2000. “On Quantifier Domain Restriction.” Mind and Language 15 (2&3): 219–61. https://doi.org/10.1111/1468-0017.00130."
  },
  {
    "objectID": "posts/borge/index.html",
    "href": "posts/borge/index.html",
    "title": "The Sporting Attitude",
    "section": "",
    "text": "Steffen Borge’s The Philosophy of Football (Borge 2019) is a really great contribution to philosophy of sport. More than that, it shows how questions in metaphysics, aesthetics, and philosophy of mind can be illuminated by looking at them through the perspective of sport. I’m going to focus on one particular question he raises, primarily in chapter 3. What attitude towards a game should players take? What is, to use Suits’s terminology (Suits 1978), the lusory attitude that goes along with playing a sport.\nThere are actually three distinct questions here that are worth separating. I’m going to start with the first, but as we’ll see, I’m going to end up having more to say about the second and the third.\nBorge argues that Suits’s answer to question 1 is much too strong, and I’m mostly inclined to agree. But I think the answers he gives to 1 and 3 are too weak. And thinking about question 2 will help us see why.\nTo start, let’s think about why we might be interested in question one in the first place. Imagine someone, call him George, who stands on a football field, but doesn’t act like a footballer. When the ball comes to him, he catches it, or picks it up, and runs towards the opposite goal line. If he makes it there, he places the ball over the goal line in celebration. George isn’t playing football - he’s playing rugby. (Or, perhaps, he’s trying to play rugby and not really succeeding at playing anything, since there clearly isn’t a rugby game going on.) Now imagine someone else, call him Webb, who tries to be like George, but fails. He really wants to pick the ball up and run with it. And he tries to do this repeatedly. But he fails every time. He never lays a hand on the ball in fact. Is Webb playing football?\nI think he’s not, or at least that there is an important sense in which he is not. And this is a hard thing to capture. Webb isn’t playing football well, since he isn’t ever involved with the play. But actually kicking the ball, or even doing any kind of football like move, isn’t essential to playing football. (See, for example, some of the less impressive performances of Mesut Özil’s Arsenal career.) The problem with Webb is that he’s trying to play a completely distinct game. It was easy to say why George was not playing football; he was gratuitously breaking the rules. But Webb is not breaking the rules. What’s wrong with Webb, what makes him a non-footballer, is something mental.\nNow at this stage you might be tempted to say that the problem with Webb is that he isn’t trying to follow the rules. But, as Borge points out, this can’t be the story1. A defender who grabs an opponent’s jersey - just hard enough to not get penalised - is still playing football. A winger who drags an opponent back to prevent a counterattack - and knows that a yellow card will follow - is still playing football. To use an example we’ll come back to a bit, Luis Suárez was playing football when he pulled off that impressive, but totally illegal, save in the 2010 World Cup. You can play football while deliberately, knowingly, breaking the rules of football. So if the problem with Webb is that he has the wrong attitude, what attitude that he lacks must you have to count as a football player?\nI’m going to argue that playing a sport requires taking the rules of that sport as providing reasons against certain actions. To play football is, among other things, to regard oneself as having a reason to not handle the ball. (Except as a goalkeeper, or during a throw-in, etc.) This reason can be outweighed, but never defeated. Even if handling the ball is the right thing to do all things considered, one has an outweighed but undefeated reason to not do it. That’s the attitude that’s essential to playing football. Or, more precisely, playing football requires being part of a game where almost all the players have that attitude almost all the time.\nTo get to this conclusion, I’m going to start by looking at Suits’s view that being a player requires treating the rules as binding; that one is not playing the game is the rules are broken. This requires reconsidering what the rules are, and I’m going to broadly agree with Borge’s critique of this reconsideration. Then I’m going to go over my positive view, that being a player requires treating rules as providing reasons. Then I’ll compare this view to Borge’s view; the views might not be that far apart. And finally I’ll talk about the view of rules as reasons can be strengthened by incorporating D’Agastino’s view that games have an ethos, and playing the game requires upholding that ethos.\nA simple way to relate rules to player attitudes is to say that playing the game requires treating the rules as binding. On the face of it this is absurd; players commit fouls, even intentional fouls, in every game. A way to make it plausible is to reinterpret the rules so that they are more or less never broken. Now this might seem absurd - a defender grabbing an attacker who is running by is breaking the rules. But as Borge discusses2, you don’t have to think about rules this way. You cold say the rule is not Don’t grab other players. Instead, the rule is If you grab another player then (ceteris paribus), the other team gets a free kick. The defender isn’t breaking that rule. It’s true that they do something that leads to the other team being awarded something by the referee. But a defender who kicks the ball into touch to stop an attack also does something that leads to the other team being awarded something by the referee, and they aren’t breaking any rules. On this way of thinking, all rules are like the rules about what happens when the ball goes out of play, and players do not deliberately break those rules.\nWe can put the same point in Kantian terms. We ordinarily think of rules as being categorical imperatives, like Don’t grab other players, that players break. The view I’m interested in here is that rules are hypothetical imperatives, like If you grab another player then (ceteris paribus), the other team gets a free kick. And while these might be broken too, some fouls are never called, players do not intend to break them. Indeed, it’s not clear that a player could intend to break them. The few categorical imperatives there are, like Don’t use a sword while playing football, are clearly followed by the players.\nThis is a plausible model for some sports. In particular, it seems like a not absurd model for cricket. At first it might look like cricket has a number of rules for proper bowling, like that you must not overstep the crease when bowling, and you must not straighen your arm when bowling. But on closer look, it is plausible that some of these are hypothetical imperatives. The overstepping rule is really a conditional - if you overstep then the batting team is awarded a run (and some other things). The bowler isn’t breaking a rule when they overstep, they are just doing something that results by rule in good results for the other team. In that respect, they are just like a fielder whose overthrow goes to the boundary. On the other hand, the rule about straightening your arm is a categorical imperative: you must not do that. And we can see that from the fact that the match officials’ duty is not to penalise this kind of bowling, but to prevent it. So it’s plausible that in cricket, most rules should be understood as conditionals, and players intend to conform to them.\nBut this is not a particularly plausible model for football. We can see this by considering a pair of cases. In each case, an attacker has the ball at the corner flag, and is about to cross to an unmarked teammate near the penalty box. In the first case, defender Ellie prevents the cross by sliding in and cleanly kicking the ball over the goal line. In the second case, attacker Sam, who isn’t as good at this, prevents the cross by sliding in and bundling the ball, the attacker, the corner flag and the watching sideline official over the goal line. In both cases, the immediate thing the officials should do is award an unobstructed kick to the attacking team by the corner flag. If rules are hypothetical imperatives, then in an important sense Sam and Ellie did the same thing. They triggered a hypothetical that leads to the other team getting a reward of an unobstructed kick by the corner flag. But surely that leaves something out. What Ellie did was great defending, and what Sam did was foul play. This suggests that we want some notion of rules in which Sam was breaking the rules, and Ellie was not. If the Suitsian model says otherwise, it is wrong. But the Suitsian can’t go on to say that what Sam did was against the rules, because then it would imply that being a player means intending to not do what Sam did, and that is clearly wrong.\nBorge discusses some examples like this one, and gives two further arguments as to why the view I’m discussing gets the case wrong. I’m sympathetic to Borge’s conclusions, but both the arguments seem to need further refinement. And working through is interesting because it reveals how hard it is to put one’s finger on what distinguishes the cases.\nBorge’s first argument3 is that we need to say Sam broke the rules to explain why we added extra penalties in the 1980s and 1990s against this kind of foul play. But I suspect this is easier to explain than Borge thinks. Sports, especially football codes, change rules all the time to discourage behaviour they want to see less of. In Australian football, if a defender carries a ball into their own goal, the other team gets one point, and traditionally the defending team got a goal kick. Since the alternative might be giving up a goal, worth six points, this was often a sensible play. It was so sensible, and became so prevalent, that the rules were changed to discourage it, replacing the goal kick with a jump ball near the goal. The fact that administrators of the game changed the penalties for certain tackles doesn’t show that those tackles were against the rules, it might just show they wanted less of those kinds of things. (Compare too the change to the rules of football to ban handling back passes.) And the fact that Sam might get a red card for this tackle doesn’t even show it is against the rules. Dangerous play can get a red card even if it isn’t a rule violation. There isn’t a rule against kicking the ball hard and straight at an annoying fan pitchside, but it could be a red card if the kick was too hard and straight.\nBorge’s second argument is that the I’m imagining is too revisionist. We talk as if there are laws of the game, rules, that Sam broke and Ellie did not. And while this is true, I don’t think we should be too concerned about this. That’s in part because there are sports like cricket where this kind of revisionism seems on reflection plausible. But it is in part because of things internal to football. We talk about tackles like Sam’s being against the Laws of the game. But we also talk about being offside as against the Laws. It certainly triggers the exception clause (unless there has been a violation of the Laws) in the clause about a definition of a goal. And the story I’m telling seems fine, and perhaps quite plausible, for off side. You can’t get carded for repeatedly being offside, even if like Inzaghi you were born in an offside position. If there is a distinction between Sam’s case and Ellie’s case, it doesn’t just feel like we talk as if Sam’s action was against the rules (or the Laws), and Ellie’s was not.\nStill, I think is a key difference between the cases. And I suspect it does cause a problem for this view. Here is one way to see the difference between the cases. Imagine Sam gets away with just a yellow card for her tackle, so both versions of the story continue with the defending team gathering in the penalty box to defend a set piece. In a normal football game, the reactions of the defending team would be different in the two cases. Ellie would be getting fist bumps or other signs of appreciation at a job well done. But it would be very poor form for Sam’s teammates to react in the same way. That’s true even though doing what Sam did,triggering the condition of a hypothetical imperative, improved her team’s position just as much as what Ellie did. Being a football player involves taking a certain attitude towards actions, and that attitude requires distinguishing Sam and Ellie’s attitude.\nThere is a famous real life example of this: Luis Suárez’s handball on the goal line against Ghana in the 2010 World Cup. On the rules as hypothetical imperatives model, the rules played out to perfection in this case. A penalty was awarded against Suárez’s team, and he was given a red card and a suspension. But this benefited his team, since the penalty was missed, and his team went on to win a game they surely would have lost otherwise. On the view that rules are hypothetical imperatives, then what Suárez did was great football, just like Ellie in the fictional example. But that all seems wrong. A lot of people in the game thought that it was unseemly of Suárez to be so proud of what he did. Yet why shouldn’t he have been proud?\nBoth of these cases can be explained if we understand rules as categorical imperatives, and the players’ attitude towards them not as binding constraints, but as providing reasons. Football includes a rule against handling the ball, and a rule against kicking other players. It also provides penalties for breaching these rules. But the force of the rules is not exhausted by penalties. The rules provide reasons that can be outweighed by other considerations, but never defeated. That’s why we don’t celebrate tackles like Sam’s, or saves like Suárez’s. They have done something that may have increased the team’s win probability, but which they had reason not to do. And their teammates share those reasons. Celebrating the action is a kind of complicity in wrongdoing.\nBorge’s view about the lusory attitude is similar to this, but I think a little different. He says that football players have to “endure, obey or accept the arbitration of the rules of football” (150). Or, as he’d put it previously, the players have to “defer to the referee and … respect his decisions”4. (I’m simplifying a bit here, not least by blurring the participant/practitioner distinction.)\nNow there is an obvious objection to this view. Players clearly do not respect the authority of the referee. It is a commonplace to see them surrounding the referee after an adverse decision complaining about it, and trying to cajole the referee to change their mind. If a defendant in a criminal trial reacted to a judge’s verdict this way, they’d be held in contempt of court. And it is hard to square respect with contempt.\nBorge should, I think, say that respecting the authority of the referee is better understood not in its ordinary usage, but just in the sense that the players do what the referee says. Maybe they complain about the mistaken award of a corner, but they don’t just take a goal kick if the referee is unmoved. That’s to say, the term ‘endure’ in the first quote above is important; it’s what players most often do.\nBut even this would be too strong a claim. Let me give just one amusing example. In 2002, I was watching the Germany-Ireland World Cup game in a bar in London. It ended with a stoppage time equaliser by Robbie Keane which brought the house down. But before that the most striking moment was an otherwise routine Ireland free kick. Germany lined up a wall, and the referee clearly said where they were supposed to stand. The camera operator, in a moment of genius, focused on the feet of the German players as the referee walked away. And as soon as his back was turned, four pairs of feet started shuffling forward in unison. The bar erupted in laughter. The lesson for us is that the players don’t have to respect the referee in the sense of doing what he says, or even endure his decisions; if they can get away with it they will just do something else.\nA better idea, not far from Borge’s I think, is to say that the players don’t have to respect the referee, but they do have to respect the rules of the game. Now this might seem absurd, in light of the examples of gratuitous rule breaking that we’ve used. But I think we can see why something like it is right if we step away from Germans and Uruguayans at World Cups, and imagine a park game. Thinking about games that are low stakes, and so the incentive to win at all costs is reduced, will help us get a better sense of what’s permissible.\nImagine Lisa is playing a game where there is a wall running down one sideline not far from the field of play. At one stage, Lisa is trapped with the ball near that sideline. She realises that a clever little bounce pass to herself off the wall will let her get out of the trap, and she executes it with aplomb. Now this might be a fun thing to do in practice, but it’s really not compatible with playing. When she does this, she has to some extent ceased to be a football player, and instead become someone who likes to show off football skills.\nOf course, Lisa won’t get any advantage from this, because the referee will simply award a throw in to the opposition. At least, the referee will probably do that. But maybe the referee will be unsighted, or incompetent, and will not award the throw. Still, it was wrong for Lisa to do that. It’s part of football that walls are not in play, and being a player requires acting as if that’s true.\nIf we imagine an incompetent referee, then we can push intuitions about cases like this even further. Imagine that Lisa goes on to notice that the referee either can’t or won’t penalise players for using their arms to control passes that come in at chest height. So every time she receives a pass to her chest, she uses her arm to help cushion the ball. The opposition are infuriated, she isn’t being subtle about it, but the referee doesn’t stop her, so she keeps on doing it. And eventually she gets a goal.\nI think she’s doing something wrong here. And I suspect, though perhaps cultural norms will vary a bit on this point, that if it is too blatant and the stakes are low enough, her teammates won’t be impressed either. They came to play a football game, and she’s making a mockery of it. Maybe they won’t celebrate the goal she gets by cheating this way, or maybe they will join in the opposition’s remonstration. Why don’t they just applaud her contribution to winning? The picture of rules as reasons explains this nicely I think. The rule against handball provides a reason for every player to not handle the ball. Maybe in a game with a huge amount at stake, the stakes override that reason. But in a park game, where the benefit of rule breaking is merely that Lisa gets a bit better control over the ball, that reason should be decisive. To the extent that she doesn’t treat it as decisive, she is undermining the sense in which they are playing football. And this can be true even if the referee won’t call this kind of foul.\nI think, and again I could be wrong, that the players would react very differently to Lisa than they’d react to the kind of ordinary shirt pulling and soft fouling that goes on at most corners. There is something particularly disrespectful about what Lisa is doing that doesn’t extend to fouls that everyone does all the time. And this is true even if Lisa would, were the referee to call her for a foul, be willing to shrug and hand the ball to the opposition for a free kick. (And then stand a foot closer than the referee said was allowed.) This is a puzzle, and I am not convinced Borge’s theory of what it is to play football can account for it.\nThe right thing to say here draws on a view of Fred D’Agostino’s that Borge discusses5. A sport has an ethos. This can’t be derived from the written rules of the game, but is something like the collective spirit in which it is played. In D’Agostino’s version, this provides the unbreakable rules of the game. The ethos says that if you do this or this, you’re no longer playing the game. This is too strong, as Borge points out. But something like it is right. My preferred version is that the ethos of the game provides the strength of reasons that go along with each rule. Currently the ethos says that shirt tugging at corners is something one has little reason to avoid, handball is something one has strong reason to avoid, and tackles from behind one has stronger reason still to avoid. But these aren’t essential to playing football; it was the same game when the strength of reasons were different.\nIn most cases in football, the strength of reasons is just what you might expect from a minimal familiarity with the game, combined with the fact that player safety is in everyone’s interests. But in other sports you need something like an ethos to explain a lot of what we see. In both cricket and baseball, a player on the batting side is out if they hit the ball and it is caught by a fielder before touching the ground. And in both sports there are hard cases where the ball, the fielder, and the ground come together almost simultaneously. But the sports treat these cases very differently. In cricket it is very poor form to appeal for a catch unless you are confident you caught the ball, and if you believe you did not catch it, you should say so to the officials. In baseball, you appeal for everything and leave it up to the officials to make the decisions. These principles are followed from the lowest levels of the game to the highest. You couldn’t derive them from the rules of the game, or from the idea that players should respect the rules and the officials. You need to appeal to something like D’Agostino’s idea of ethos to explain the difference between the sports.\nBut if an ethos is so essential to a sport, does that mean that players in communities with a different ethos are literally playing different games? As Borge points out, this would be an absurd result6. His example involves a World Cup team not used to the stricter refereeing in international games. But you don’t need to go that far afield. I’ve heard that in England it can be a debacle when a Premier League referee takes charge of a Championship game, because the players just one level down are used to getting away with much heavier tackles than a referee who has to look after superstars in the top flight will allow. Now here’s the objection. If the ethos is essential to the game, and the ethos is different in the Premiership and the Championship, then it follows they are playing a different sport in the Premiership and the Championship. And that’s a reductio of the position.\nThis criticism relies on reading too much into the notion of an ethos. It’s true that in a colloquial sense, the game has a different ethos in a place where a certain tackle is commonplace to what it has in a place where that tackle is routinely penalised. But this isn’t what D’Agastino meant by “ethos”, and it isn’t what I mean. In D’Agastino’s version, it concerned what was simply not to be done. The teams who are used to lighter refereeing typically won’t do things that teams used to stricter refereeing simply won’t do. The things they get penalised for all the time are part of the repetoire of the more mannered teams; it’s just that those teams don’t do them as often. So I’m not sure these are examples of difference in ethos in D’Agastino’s sense. And they need not be differences in my sense either. As I’m using the term, the ethos of a game tells you what reasons you have to not do certain actions beyond what penalties will be applied to those actions. Changing the penalties doesn’t even look like something that changes the non-penalty reasons.\nBut the bigger point to make in reply turns on the fact, much stressed by Borge, that football is social. Indeed, it is social twice over. Whether one is playing football at a given moment is a social fact. Whether I am reading a book at a moment is largely up to me. But there is literally nothing I could do right now, sitting at my computer with no one around, that would make it the case that I was playing a game of football. For that I would need teammates, and opponents (and for that matter a field) and none of them are to hand. But that doesn’t exhaust how social football is. As Borge argues in chapter two, what makes it the case that various token games are tokens of the kind football consists largely of social facts as well. Once we take these things into account, we can see that appeal to something like an ethos of football won’t make it the case that people with different attitudes are playing different games.\nThere is an objection to the whole project of this paper that you might have been considering, and which it is finally time to address. I’ve been asking what attitude is required to play football. And at some level the answer is that literally anything goes. If there is a field of the right kind, and 22 other people on it - 10 of them your teammates, 11 of them opponents, and a referee - and they are doing paradigmatically football type things, then as long as you’re in uniform you’re playing football. Short of pulling out a weapon and assaulting people with the weapon, there is little you could do that would count as not playing football, as opposed to playing badly. So how can we talk about the attitude that is necessary for playing football?\nWell, we can still talk generically about what the players in general must think and feel in order for there to be a game. Exceptions can be tolerated. It is easy to come up with extreme cases. Imagine an East German player playing in France in the 1960s, and spending the whole game looking for the safest moment to defect. Or imagine a girl from an area where scouts never venture, finally getting a chance to play in front of a scout, and for this game only caring about how impressive her play is. It will be hard to come up with any plausible story about the attitude of football players that covers their attitudes, yet they are still playing football. But those exceptions can be tolerated, as long as they are exceptions. If everyone is looking for a chance to defect, it isn’t really a game, it’s an escape attempt. If everyone is just looking to impress the scouts, it’s an exhibition or a scrimmage, not a game. What we’re after here is what must be true in general.\nBecause to a pretty close approximation, all it takes to be playing football is to be part of a football game. And being part of it might literally just mean wearing the right kit, and being on the right field. And it being a football game is a matter of this game standing in the right social relations to games of football across space and time. Neither requires any player have attitudes of any kind. But we can ask what attitudes, if any, are necessary to be generic across the players in this game for it to stand in the right relations to the class of all football games. And we can ask what attitudes, if any, are necessary to be generic across the players in all games if those games are to be, collectively, football.\nAnd like as above, I think an account in terms of reasons is basically right. What makes the players across all the football games the world over players of the same game? I think it’s because they are, generally, taking the rules to provide reasons to act, and not act, in certain ways. There is massive variation within these. At a junior enough level, they are barely cognisant of the rules, and so cannot take them as reasons. At a high enough level, they might be so focused on winning that they care little for the rules beyond the fact that rule violations might lead to penalties. But it would have to be a very jaded team that celebrates Sam just as much as they celebrate Ellie; even at the highest level, players’ reactive attitudes tend to generally acknowledge the reason-giving force of the rules.\nI’ll close by considering two related problems. If the games are associated with the way players take the rules to be reasons, that suggests that games are individuated much too finely. If here we regard the rule against handball as having just this strength as a reason, and over there they regard it as having a little less strength, then are we not both playing football? That would be absurd. And if little kids don’t understand the rules as having reason-giving force, because perhaps they don’t understand the rules at all, are they playing a different game? This seems wrong, since we can talk about someone having played football since they were four.\nThere are two points to note about ‘football’ that are relevant to both of these objections. The term is vague. Whether these five year olds kicking a ball around a small field, with no throw ins, goal keepers, headers, or offside rules, are playing football is a bit vague. There is a sense in which they are, and a sense in which they are not. And even given a precisification, the question of whether two people are playing the same sport, or the same game, doesn’t always correspond to the meaning of the name of the game, or games, they play. The same thing happens with language. How widely is English spoken? Do folks speak the same language in Glasgow, Pittsburgh and Sydney? There is a sense in which they are speaking different languages - they certain have a very different lexicon. But there is a perhaps more important sense in which they are speaking the same language, and that language is English. Is 50-over cricket the same sport, or the same game, as 20-over cricket? There is a sense in which the answer is yes, and a sense in which the answer is no. (I’m actually kind of surprised at how much the infrastructure around cricket supposes the no answer - the games are more similar to each other than either is to junior cricket.) The same happens here. It’s true on my view that there is a sense in which players who differ in what strength they give to the rules of football are playing different games, just like 50-over and 20-over cricket might be different games. But just like those are both games of cricket, and like the folks in Glasgow, Pittsburgh and Sydney are all speaking English, the players might all be playing football.\nWhile I’ve disagreed, at least on points of emphasis, with Borge, I want to close by expressing again my appreciation for his book. Philosophy is richer when it engages with real life, especially with those aspects of real life that make less sense the more you think about them. And his book is a great example of this kind of engagement, and is rewarding reading for anyone who cares about either football or philosophy, and especially for those of us who care about both."
  },
  {
    "objectID": "posts/bqb/index.html",
    "href": "posts/bqb/index.html",
    "title": "Begging the Question and Bayesians",
    "section": "",
    "text": "The arguments for Bayesianism in the literature fall into three broad categories. There are Dutch Book arguments, both of the traditional pragmatic variety and the modern ‘depragmatised’ form. And there are arguments from the so-called ‘representation theorems’. The arguments have many similarities, for example they have a common conclusion, and they all derive epistemic constraints from considerations about coherent preferences, but they have enough differences to produce hostilities between their proponents. In a recent paper, Maher (1997) has argued that the pragmatised Dutch Book arguments are unsound and the depragmatised Dutch Book arguments question begging. He urges we instead use the representation theorem argument as in Maher (1993). In this paper I argue that Maher’s own argument is question-begging, though in a more subtle and interesting way than his Dutch Book wielding opponents."
  },
  {
    "objectID": "posts/indsub/index.html",
    "href": "posts/indsub/index.html",
    "title": "Indicative and Subjunctive Conditionals",
    "section": "",
    "text": "This paper presents a new theory of the truth conditions for indicative conditionals. The theory allows us to give a fairly unified account of the semantics for indicative and subjunctive conditionals, though there remains a distinction between the two classes. Put simply, the idea behind the theory is that the distinction between the indicative and the subjunctive parallels the distinction between the necessary and the a priori. Since that distinction is best understood formally using the resources of two-dimensional modal logic, those resources will be brought to bear on the logic of conditionals."
  },
  {
    "objectID": "posts/indsub/index.html#a-grand-unified-theory",
    "href": "posts/indsub/index.html#a-grand-unified-theory",
    "title": "Indicative and Subjunctive Conditionals",
    "section": "1 A Grand Unified Theory?",
    "text": "1 A Grand Unified Theory?\nOur primary focus is the indicative conditional ‘If \\(A\\), \\(B\\)’, written as \\(A \\rightarrow B\\). Most theorists fail to distinguish between this conditional and ‘If \\(A\\), then \\(B\\)’, and for the most part I will follow this tradition. The most notable philosophical exception is Grice, who suggested that only the latter says that \\(B\\) follows from \\(A\\) in some relevant way (1989: 63). Theorists do distinguish between this conditional and the subjunctive ‘If it were the case that \\(A\\), it would be the case that \\(B\\)’, written as \\(A \\,\\square\\!\\mathord\\to B\\). There is some debate about precisely where to draw the line between these two classes, which I’ll discuss in section three, but for now I’ll focus on cases far from the borderline. One important tradition in work on conditionals holds that the semantics of indicatives differs radically from the semantics of subjunctives. According to David Lewis (1973, 1976) and Frank Jackson (1987) for example, indicatives are truth-functional, but subjunctives are not. This makes a mystery of some of the data. For example, as Jackson himself writes:\n\nBefore the last presidential election commentators said ‘If Reagan loses, the opinion polls will be totally discredited’, afterwards they said ‘If Reagan had lost, the opinion polls would have been totally discredited’, and this switch from indicative to subjunctive counterfactual did not count as a change of mind (Jackson 1987, 66).\n\nThe point can be pushed further. To communicate the commentators’ pre-election opinions using indirect speech we would say something like (1).\n\nCommentators have said that if Reagan were to lose the opinion polls would be totally discredited.\n\nYet it is possible on Jackson’s view that what the commentators said was true, since Reagan won, yet the words after ‘that’ in (1) form a false sentence. So we can accurately report someone speaking truly by using a false sentence. Jackson’s response plays on the connections between \\(A \\rightarrow B\\) and the disjunction ‘Not-\\(A\\) or \\(B\\)’. That disjunction has undeniably different truth conditions to \\(A \\,\\square\\!\\mathord\\to\\) B. Pushing the truth conditions of \\(A \\rightarrow B\\) closer to those of \\(A \\,\\square\\!\\mathord\\to\\) B will move them away from ‘Not- \\(A\\) or \\(B\\)’. One gain in similarity and theoretical simplicity is bought at the cost of another. Jackson’s account, by making \\(A \\rightarrow B\\) have similar truth conditions to ‘Not - \\(A\\) or \\(B\\)’ but similar assertibility conditions to \\(A \\,\\square\\!\\mathord\\to B\\), tries to have the best of both worlds. How great the similarity between indicative conditionals and disjunctions really is, and hence how great the cost of linking indicatives and subjunctives, might well be questioned. After all, we don’t report an utterance of an indicative using a disjunction.\nTwo types of cases seem to threaten the success of a unified theory. First, rigidifying expressions like ‘actually’ behave differently in indicatives and subjunctives. Secondly, some conditionals differ in intuitive truth value when we transpose them from the indicative to the subjunctive. The most famous examples of this phenomenon involve various presidential assassinations. The effects of rigidity on conditionals are less explored, so we will first look at that. Consider the following example, from page 55 of Naming and Necessity.\n\nIf heat had been applied to this stick \\(S\\) at \\(t_0\\), then at \\(t_0\\) stick \\(S\\) would not have been one meter long.\n\nThe background is that we have stipulated that a metre is the length of stick \\(S\\) at time \\(t_0\\). (2) contrasts with (3), which seems false.\n\nIf heat was applied to this stick \\(S\\) at \\(t_0\\), then at \\(t_0\\) stick \\(S\\) was not one meter long.\n\nIf we have stipulated that to be a meter long is to be the length of \\(S\\) at \\(t_0\\), then whatever conditions \\(S\\) was under at \\(t_0\\), it was one meter long. As Jackson points out, we can get the same effect with explicit rigidifiers like ‘actually’. We could, somewhat wistfully, say (4). It may even be true. But (5) seems barely coherent, and certainly not something we could ever say.\n\nIf Hillary Clinton were to become the next U.S. President, things would be different from the way they actually will be.\nIf Hillary Clinton becomes the next U.S. President, things will be different from the way they actually will be.\n\nIt looks like any theory of conditionals will have to account for a difference between the behaviour of rigid designators in indicatives and subjunctives. We may avoid the conclusion by showing that the difference only appears in certain types of conditionals, and we already have an explanation for those cases. For example, it is well known that usually one cannot say \\(A \\rightarrow B\\) if it is known that not-\\(A\\). As Dudman (1994) points out, (6) is clearly infelicitous on its most obvious reading.\n\n*Granny won, but if she lost she was furious.\n\nTo complete the diagnosis, note that the most striking examples of the different behaviour of rigid designators in different types of conditionals comes up in cases where the antecedent is almost certainly false. The effect is that the subjunctive can be asserted, but not the indicative. So this phenomenon may be explainable by some other part of the theory of conditionals.1 These are the most striking exemplars of the difference I am highlighting, but not the only examples. Hence, this point cannot explain all the data, though it may explain why pairs like (2)/(3) and (4)/(5) are striking. For instance, in the following pairs, the indicative seems appropriate and intuitively true, and the subjunctive seems inappropriate and intuitively false.\n1 An anonymous reviewer for Philosophical Quarterly suggested this point.\nIf C-fibres firing is what causes pain sensations, then C-fibres firing is what actually causes pain sensations.\nIf C-fibres firing were what caused pain sensations, then C-fibres firing would be what actually causes pain sensations.\nIf the stuff that plays the gold role has atomic number 42, then gold has atomic number 42.\nIf the stuff that played the gold role had atomic number 42, gold would have atomic number 42.\n\nIn (9) and (10) I assume that to play the gold role one must play it throughout a large part of the world, and not just on a small stage. Something may play the gold role in a small part of the world without being gold. Since there are pairs of conditionals like these where the indicative is appropriate, but the subjunctive is not, the explanation of the behaviour of rigid terms cannot rely on the fact that the antecedents of indicatives must be not known to be false. We will also need a more traditional example of the differences between indicatives and subjunctives, as in (11) and (12).\n\nIf Hinckley didn’t shoot Reagan, someone else did.\nIf Hinckley hadn’t shot Reagan, someone else would have.\n\nI have concentrated on the examples involving rigidity because they seem to pose a deeper problem for unifying the theory of conditionals than the presidential examples. As Jackson (1987, 75) points out, one can presumably explain (11) and (12) on a possible worlds account by varying the similarity metric between indicatives and subjunctives, or on a probabilistic account by varying the background evidence. It is unclear, however, how this will help with the rigidity examples. Assume, for example, that C-fibres firing is not what causes pain sensations. Still, (7) seems true, but its consequent is false in all possible worlds. Therefore, the nearest world in which its antecedent is true is a world in which its consequent is false, and on a simple possible worlds theory it should turn out false. On a simple probabilistic account, the probability that C-fibres firing actually cause pain sensations given that they do is 1, whatever the background evidence, so (8) should turn out true, contrary to our intuitions. So while the details deal with the presidential examples, the structure of the theory must deal with the rigidity examples.\nI will follow that strategy here. In section two I set out the framework of a unified possible worlds account of indicatives and subjunctives. In section three I present my preferred way of filling out the details of that framework. The framework deals with the differing behaviour of rigid designators in indicatives and subjunctives; the details deal with examples like (11) and (12). One reason for dividing the presentation in this way is to highlight the option of accepting the framework and filling in the details in different ways."
  },
  {
    "objectID": "posts/indsub/index.html#the-new-theory",
    "href": "posts/indsub/index.html#the-new-theory",
    "title": "Indicative and Subjunctive Conditionals",
    "section": "2 The New Theory",
    "text": "2 The New Theory\n\n2.1 Actually\nAs Kripke (1980) showed, the reference for some terms is fixed by what plays a particular role in the actual world. Even if it were the case that XYZ fills the ocean, falls from the sky, is drinkable and transparent and so on, for short is watery, it would still be the case that water is H2O, not XYZ. For it would still be that H2O actually is watery. Whatever were the case, this world would be actual.\nYet, we want to have a way to talk about what would have happened had some other world been actual. In particular, had the actual world been one in which XYZ is watery, it would be true, indeed necessarily true, that water is XYZ. Throughout the 1970s a number of methods for doing this were produced. The following presentation is indebted to Davies and Humberstone (1980), but other approaches might have been used. The notation \\(\\vDash_y^x A\\) is interpreted as ‘\\(A\\) is true in world \\(y\\) from the perspective of world \\(x\\) as actual’. So, letting @ be the actual world and \\(w\\) be a world in which only XYZ is watery, we can represent what was said informally above as follows.\n\n\\(\\vDash_@^@\\) H2O is watery and H2O is water.\n\\(\\vDash_w^@\\) XYZ is watery and H2O is water.\n\\(\\vDash_@^w\\) H2O is watery and XYZ is water.\n\\(\\vDash_w^w\\)XYZ is watery and XYZ is water.\n\nNow as Kripke noted, it is necessary but a posteriori that water is H2O. Conversely, it is a priori but contingent that water is watery. This is a priori because we knew before we determined what water really is that it would be whatever plays the watery role in this world, the actual world. In general \\(A\\) is necessary iff, given this is the actual world, it is true in all worlds. And \\(A\\) is a priori iff, whatever the actual world turns out to be like, it makes \\(A\\) true. So we get the following definitions.\n\n\\(A\\) is a priori iff for all worlds \\(w\\), \\(\\vDash_w^w\\) \\(A\\).\n\\(A\\) is necessary iff for all worlds \\(w\\), \\(\\vDash_w^@\\) \\(A\\).\n\nThe connection between actuality and the a priori is important. It is a priori that we are in the actual world. Something is a priori iff it is true whenever the two indices are the same. If we regard possible worlds as sets of sentences, we can think of the sets {\\(A\\): \\(\\vDash_x^x\\) \\(A\\)} for each possible world \\(x\\) as the epistemically possible worlds. Note that I don’t make the set of epistemically possible worlds relative to an evidence set, as others commonly do. Rather they are just the sets of sentences consistent with what we know a priori. More accurately, identify a world pair \\(\\langle x\\), \\(y \\rangle\\) with the set of {\\(A\\): \\(\\vDash_y^x\\) \\(A\\)}. Then \\(\\langle x\\), \\(y \\rangle\\) is an epistemically possible world pair iff \\(x\\) = \\(y\\).\nTo finish this formal excursion, we note the definition of ‘Actually \\(A\\)’. Given what has been said so far, this needs no explanation.\n\n\\(\\vDash_y^x\\)Actually \\(A\\) iff \\(\\vDash_x^x\\) \\(A\\).\n\n\n\n2.2 The Analysis of Indicatives\nNow we have the resources for my theory of the truth conditions for indicatives. I also give the parallel truth condition for subjunctives to show the similarities.\n\n\\(\\vDash_@^@\\)\\(A \\rightarrow B\\) iff the nearest possible world \\(x\\) that \\(\\vDash_x^x\\) \\(A\\) is such that \\(\\vDash_x^x\\) \\(B\\).\n\\(\\vDash_@^@\\) \\(A \\,\\square\\!\\mathord\\to B\\) iff the nearest possible world \\(x\\) that \\(\\vDash_x^@\\) \\(A\\) is such that \\(\\vDash_x^@\\)\\(B\\).\n\nThese only cover the special case of what is true here from the perspective of this world as actual. We can partially generalise the analysis of indicatives in one dimension as follows.\n\n\\(\\vDash_w^w\\) \\(A \\rightarrow B\\) iff the nearest possible world \\(x\\) to \\(w\\) such that \\(\\vDash_x^x\\) \\(A\\) is such that \\(\\vDash_x^x\\) \\(B\\).\n\nI will make some comments below about how we might fully generalise the analysis, but for now, I want to focus on these simpler cases. Note that straight away this makes \\(A \\rightarrow\\) Actually \\(A\\) come out true, by the definition of ‘Actually’. If we allow ourselves quantification over propositions, we can give an analysis of ‘things are different from the way they actually are’, as follows:\n\n(\\(\\vDash_y^x\\) Things are different from the way they actually are) iff\n(\\(\\exists\\)\\(p\\): \\(\\vDash_y^x\\) \\(p\\) and not \\(\\vDash_x^x\\) \\(p\\))\n\nSince nothing both is and is not the case in \\(x\\) from the perspective of \\(x\\) as actual, this can never be true when \\(y\\) is \\(x\\). This explains why it can never serve as the consequent of an indicative conditional.\n\n\n2.3 Motivations\nThe theory outlined here is reasonably unified, and accounts for the rigidity phenomena, but without any further justification, the resort to two-dimensional modal logic is ad hoc. This subsection responds to that problem with some independent motivations for the theory. In particular I argue that this theory best captures the well-known epistemic feel of the indicative conditional.\nEver since Ramsey (1929/1990) most theorists have held that there is an epistemic element to indicatives. Here is Ramsey’s sketch of an analysis of indicatives.\n\nIf two people are arguing ‘If \\(p\\) will q?’ and are both in doubt as to \\(p\\), they are adding \\(p\\) hypothetically to their stock of knowledge and arguing on that basis about q; so that in a sense ‘If \\(p\\), q’ and ‘If \\(p\\), \\(\\neg\\)q’ are contradictories (Ramsey 1929/1990, 247n).\n\nNothing of the sort could be true about subjunctives. What is in our ‘stock of knowledge’, or the contextually relevant knowledge, makes at most an indirect contribution to the truth- value of a subjunctive. It makes an indirect contribution because the common knowledge might affect the context, which in turn determines the similarity measure. But given a context, a subjunctive makes a broadly metaphysical claim, an indicative a broadly epistemic claim. Hence, the relationship between the indicative and subjunctive should parallel the relationship between the necessary and the a priori. As should be clear, this is exactly what happens on this theory.\nThe close similarity between the indicative/subjunctive distinction and the a priori/necessary distinction can be demonstrated in other ways. For example, corresponding to the contingent a priori (13) the indicative (14) is true, but the subjunctive (15) is false. And corresponding to the necessary a posteriori (16) the subjunctive (17) is true but the indicative (18) is false. (I am assuming that it is part of the definitions of the water role and the fire role that nothing can play both roles.)\n\nWater is what plays the water role.\nIf XYZ plays the water role, XYZ is water.\nIf XYZ played the water role, it would be water.\nWater is H2O.\nIf all H2O played the fire role, all water would be fire.\nIf all H2O plays the fire role, all water is fire.\n\nThis suggests the analysis sketched here is not ad hoc at all, but follows naturally from considerations about the necessary and a priori. These sketchy considerations might not provide much positive support for my theory. The main evidence for the theory, however, is the way it manages the hard cases, particularly cases involving rigid designation. What these considerations show is that the correct theory of indicatives may invoke the resources of two-dimensional modal logic without automatically renouncing any claim to systematicity."
  },
  {
    "objectID": "posts/indsub/index.html#the-details",
    "href": "posts/indsub/index.html#the-details",
    "title": "Indicative and Subjunctive Conditionals",
    "section": "3 The Details",
    "text": "3 The Details\nIn this section, I want to look at four questions. First, what can we say about the similarity measure at the core of this account? Secondly, how should we generalise the theory to cover cases where the definite description in the analysis appears to denote nothing? Thirdly, how should we generalise the theory to cover cases where the two indices differ? Finally, how should we draw the line between indicatives and subjunctives? If what I said in the previous section is correct, there should be something to say about each of these questions, and what is said should be motivated. While it is not important that what I say here is precisely true, I do hope that it is.\n\n3.1 Nearness\nIdeally, we could use exactly the same similarity metric for both indicatives and subjunctives. The existence of pairs like (11) and (12) suggests this is impossible. So we must come up with a pair of measures on the worlds satisfying three constraints. First, the measure for subjunctives must deliver plausible verdicts for most subjunctive conditionals. Secondly, the measure for indicatives must deliver plausible verdicts for most indicative conditionals. Thirdly, the measures must be similar enough that we can explain the close relationship between indicatives and subjunctives set out in section one. The theory of section two requires that these objectives be jointly satisfiable. I will attempt to demonstrate that they are by outlining a pair of measures satisfying all three.\nLewis (1979a) provides the measure for subjunctives. He suggests the following four rules for locating the nearest possible world in which A is true.\n\nIt is of the first importance to avoid big, widespread, diverse violations of law.\nIt is of the second importance to maximise the spatio-temporal region throughout which perfect match of particular fact prevails.\nIt is of the third importance to avoid even small, localized, simple violations of law.\nIt is of little or no importance to secure approximate similarity of particular fact, even in matters that concern us greatly. (Lewis 1979a, 47–48)\n\nThe right measure for indicatives is somewhat simpler. Notice that whenever we know that \\(A \\supset B\\) and don’t know whether \\(A\\), \\(A \\rightarrow B\\) seems true. More generally, if I know some sentence \\(S\\) such that \\(A\\) and \\(S\\) together entail \\(B\\), and I would continue to know \\(S\\) even were I to come to doubt \\(B\\), then \\(A \\rightarrow B\\) will seem true to me. No matter how good a card cheat I know Sly Pete to be, if I know that he has the worse hand, and that whenever someone with the worse hand calls they lose, it will seem true to me that If Sly Pete calls, he will lose. Further, if someone else knows these background facts and tells me that If Sly Pete calls, he will lose, she speaks truthfully.\nThis data suggests that whenever there is a true \\(S\\) such that \\(A\\) and \\(S\\) entail \\(B\\), \\(A \\rightarrow B\\) is true. But this would mean \\(A \\rightarrow B\\) is true whenever \\(A \\supset B\\) is true, which seems incredible. On this theory it is true that If there is a nuclear war tomorrow, life will go on as normal. There are some very subtle attempts to make this palatable. The ‘Supplemented Equivalence Theory’ in Jackson (1987) may even be successful. But two problems remain for all theories saying \\(A \\rightarrow B\\) has the truth value of \\(A \\supset B\\). First, they make some apparently true negated conditionals turn out false, such as It is not true that if there is a nuclear war tomorrow, life will go on as normal. It is hard to see how an appeal to Gricean pragmatics will avoid this problem. Secondly, such theories fail the third task we set ourselves at the start of the section: explaining the close connections between indicatives and subjunctives.\nSo we might be tempted to try a different path. Let’s take the data at face value and say that \\(A \\rightarrow B\\) is true in a context if there is some \\(S\\) such that some person in that context knows \\(S\\), and \\(A\\) and \\(S\\) together entail \\(B\\). We can formalise this claim as follows. Let \\(d\\)(\\(x\\), \\(y\\)) be the ‘distance’ from \\(x\\) to \\(y\\). This function will satisfy few of the formal properties of a distance relationship, so remember this is just an analogy. Let K be the set of all propositions \\(S\\) known by someone in the context, \\(W\\) the set of all possible worlds, and \\(i\\) the impossible world, where everything is true. Then \\(d\\): \\(W \\times W \\cup \\{i\\} \\rightarrow \\Re\\) is as follows:\n\nIf \\(y = x\\) then \\(d\\)(\\(x\\), \\(y\\)) = 0\nIf \\(y \\in W, y \\neq x\\) and \\(\\forall S\\): \\(S \\in\\) K \\(\\supset \\vDash_y^y\\) \\(S\\), then \\(d\\)(\\(x\\), \\(y\\)) = 1\nIf \\(y\\) = \\(i\\) then \\(d\\)(\\(x\\), \\(y\\)) = 2\nOtherwise, \\(d\\)(\\(x\\), \\(y\\)) = 3\n\nLess formally, the nearest world to a world is itself. The next closest worlds are any compatible with everything known in the context, then the impossible world, then the possible worlds incompatible with something known in the context. It may seem odd to have the impossible world closer than some possible worlds, but there are two reasons for doing this. First, in the impossible world everything known to any conversational participant is true. Secondly, putting the impossible world at this position accounts for some examples. This is a variant on a well known case; see for example Gibbard (1981) and Barker (1997).\nJack and Jill are trying to find out how their local representative Kim, a Democrat from Texas, voted on a resolution at a particular committee meeting. So far, they have not even found out whether Kim was at the meeting. Jack finds out that all Democrats at the meeting voted against the resolution; Jill finds out that all Texans at the meeting voted for it. When they return to compare notes, Jack can truly say If Kim was at the meeting, she voted against the resolution, and Jill can truly say If Kim was at the meeting, she voted for the resolution. If \\(i\\) is further from the actual world than some possible world where Kim attended the meeting, these statements cannot both be true.\nIt may be thought the distance function needs to be more fine-grained to account for the following phenomena2. It seems possible that in each of the following pairs, the first sentence is true and the second false.\n2 Lewis (1973) makes this objection to a similar proposal for subjunctives; the objection has just as much force here as it does in the original case.\n\nIf Anne goes to the party, so will Billy.\nIf Anne goes to the party, Billy will not go.\n\n\nIf Anne and Carly go to the party, Billy will not go.\nIf Anne and Carly go to the party, so will Billy.\n\n\nIf Anne, Carly and Donna go to the party, so will Billy.\nIf Anne, Carly and Donna go to the party, Billy will not.\n\n\nAssume, as seems plausible, it is necessary and sufficient for \\(A \\rightarrow B\\) to be true that the nearest \\(A \\wedge B\\) world is closer than the nearest \\(A\\wedge \\neg B\\) world. (This does not immediately follow from the analysis in section 2, but is obviously compatible with it.) Given this, there is no context in which the first conditional in each pair is true, and the second false. McCawley (1996) points out a way to accommodate these intuitions. Every time a conditional is uttered, or considered in a private context, the context shifts so as to accommodate the possibility that its antecedent is true. So at first we don’t consider worlds where Carly or Donna turn up, and agree that (19a) is true and (19b) false because in those worlds Billy loyally follows Anne to the party. When (20a) or (20b) is uttered, or considered, we have to allow some worlds where Carly goes to the party into the context set. In some of these worlds Anne goes to the party and Billy doesn’t, the worlds where Carly goes to party. A similar story explains how (21a) can be true despite (20b) being false.3\n3 There is an obvious similarity between this argument and some of the uses of contextual dependence in Lewis’s theory of knowledge (Lewis 1996). Indeed, McCawley credits Lewis (1979b) as an inspiration for his ideas.This move does seem to save the theory from potentially troubling data, but without further support it may seems rather desperate. There are two independent motivations for it. First, it explains the inappropriateness of (6).\n\n*Grannie won, but if she lost she was furious.\n\nIf assertion narrows the contextually relevant worlds to those where the assertion is true, as Stalnaker (1978) suggests, and uttering a conditional requires expanding the context to include worlds where the antecedent is true, it follows that utterances like (6) will be defective. The speech acts performed by uttering each clause give the hearer opposite instructions regarding how to amend the context set. Secondly, McCawley’s assumption explains why we generally have little use for indicative conditionals whose antecedents we know are false. To interpret an indicative we first have to expand the context set to include a world where the antecedent is true, but if we know the antecedent is false we usually have little reason to want to do that. If there is a dispute over the size of the context set, we may want to expand it so as to avoid miscommunication, which explains why we will sometimes assert conditionals with antecedents we know to be false when trying to convince someone else that the antecedent really is false.\nSo we have a pair of measures that give plausible answers on a wide range of cases. Such a pair should also validate the close connection between indicatives and subjunctives we saw earlier. The data set out in section one suggests that this connection may be close to synonymy, as in (1), but in some cases, as in (11) and (12), the connection is much looser. The differing behaviour of rigid designators in indicatives and subjunctives reveals a further difference, but the two-dimensional nature of the analysis, not the particulars of the similarity metric, accounts for that. I propose to explain the data by looking at which facts we hold fixed when trying to determine the nearest possible world. The facts we hold fixed in evaluating indicatives and subjunctives, according to the two metrics outlined above, are the same in just the cases we feel that the indicatives and subjunctives say the same thing.\nWhen evaluating an indicative we hold fixed all the facts known by any member of the conversation. When evaluating a subjunctive we hold fixed (a) all facts about the world up to some salient time t and (b) the holding of the laws of nature at all times after t. The time t is the latest time such that some worlds fitting this description make \\(A\\) true and contain no large miracles. The two sets of facts held fixed match when we know all the salient facts about times before t, and know no particular facts about what happens after t.\nIn the opinion poll case, when evaluating the original indicative our knowledge at the earlier time was held fixed. We knew that the polls predicted a Reagan landslide, that when one makes spectacularly false predictions one is discredited, and so on. When we turn to evaluating the subjunctive, we hold fixed the facts about the world before the election (presumably the relevant time t) and some laws. Therefore, we hold fixed the polls predictions, and the law that when one makes spectacularly false predictions one is discredited. So the same facts are held fixed. And in general, this will happen whenever all we know is all the specific facts up to the relevant time, and some laws that allow us to extrapolate from those facts.\nIn the case where indicatives and subjunctives come apart, as in (11) and (12), the relevant knowledge differs from the first case. By hypothesis, we do not know who pulled the trigger, but we do know that a trigger was pulled. Our knowledge of the relevant facts does not consist in knowledge of all the details up to a salient time, and knowledge that the world will continue in a law-governed way after this. Therefore, we would predict that the indicatives and subjunctives would come apart, because what is held fixed when evaluating the two conditionals differs. We find exactly that. So the pair of measures can explain the close connection between indicatives and subjunctives when it exists, and explain why the two come apart when they do come apart.\n\n\n3.2 No Nearest Possible World\nGenerally, there are three kinds of problems under this heading. First, there may be no \\(A\\)-worlds, and so no nearest \\(A\\)-world. Secondly, there may be an infinite sequence of ever-nearer \\(A\\)-worlds without a nearest \\(A\\)-world. Thirdly, there may be several worlds in a tie for nearest \\(A\\)-world. If the measure suggested in the previous section is correct, the first two problems do not arise here. The third problem, however, arises almost all the time, so we need to say something about it.\nThe approach I favour is set out in Stalnaker (1981). The comparative similarity measure is a partial order on the possible worlds. Stalnaker recommends we assess conditionals using supervaluations, taking the precisifications to be the complete extensions of this partial order. In particular, if several possible worlds tie for being the closest \\(A\\)-worlds4, then \\(A \\rightarrow B\\) will be true if they are all \\(B\\)-worlds, false if they are all \\(\\neg B\\)-worlds, and not truth-valued otherwise. For consistent \\(A\\), this makes \\(\\neg\\)(\\(A \\rightarrow B\\)) equivalent to \\(A \\rightarrow \\neg B\\). Since we generally deny \\(A \\rightarrow B\\) just when we would be prepared to assert \\(A \\rightarrow \\neg B\\), this seems like a good outcome.5 Further, this account makes \\(A \\rightarrow B\\) generally come out gappy when A is false. Many theorists hold that indicative conditionals, especially those with false antecedents, lack truth values.6 This can’t be right in general, since it is a platitude that \\(A \\rightarrow A\\) is true for every \\(A\\), but the position has some attraction. Happily, our theory respects the motivations behind such positions without violating the platitude.\n4 Of course in this context \\(x\\) is an \\(A\\)- world iff \\(\\vDash_x^x\\) \\(A\\).5 Edgington (1996) furnishes some nice examples against the view that \\(A \\,\\square\\!\\mathord\\to B\\) should be false when there are several equally close \\(A\\)-worlds in a tie for closest and some are \\(B\\)-worlds but some are \\(\\neg B\\)-worlds.6 See Edgington (1995) for an endorsement of this position and discussion of others who have held it.In any case, these details are not important to the overall analysis. If someone favours a resolution of ties along the lines Lewis suggested this could easily be appended onto the basic theory.\n\n\n3.3 The General Theory\nSo far, I have just defined what it is for \\(A \\rightarrow B\\) to be true in this world from the perspective of this world as actual. To have a fully general theory I need to say when \\(A \\rightarrow B\\) is true in an arbitrary world from the perspective of another (possibly different) world as actual. And that general theory must yield the theory above as a special case when applied to our world. As with the special theory above, the general theory will mostly be derived from Twin Earth considerations.\nIn general, \\(\\vDash_y^x\\) \\(A \\rightarrow B\\) iff the nearest world pair \\(\\langle z, v \\rangle\\) such that \\(\\vDash_v^z\\) \\(A\\) is such that \\(\\vDash_v^z\\) \\(B\\). Nearness is again defined epistemically, but what we know about \\(x\\) and \\(y\\) matters. In particular if \\(\\vDash_v^z\\) \\(C\\) for all sentences \\(C\\) such that someone in the context knows that \\(\\vDash_y^x\\)\\(C\\) , but not \\(\\vDash_w^u\\) \\(C\\) for some such \\(C\\) , then \\(\\langle z, v \\rangle\\) is closer to \\(\\langle x, y \\rangle\\) than is \\(\\langle u, w \\rangle\\). As should be clear from this, nearness is context-dependent, and the context it depends on is the actual speaker’s context. For conditionals as for quantified sentences, the same words will express different propositions in different contexts.\nLet’s draw out some consequences of this definition. First, for any \\(x\\) we know that \\(\\vDash_x^x\\) \\(C\\) for all a priori propositions \\(C\\). In particular, we know that \\(\\vDash_x^x\\)\\(D \\equiv\\) (Actually \\(D\\)) for any proposition \\(D\\), where ‘\\(\\equiv\\)’ represents the material biconditional. So the nearest world pair \\(\\langle z, v \\rangle\\) to \\(\\langle x, x \\rangle\\) must be one in which \\(z = v\\), even if that means \\(z\\) is the impossible world \\(i\\). Hence the general theory of indicatives reduces to the special theory set out above when applied to epistemically possible worlds: when assessing the truth value of an indicative in an epistemically possible world pair we need only look at other epistemically possible world pairs.\nSecondly, when evaluating conditionals with respect to epistemically impossible world pairs \\(\\langle x, y \\rangle\\), we need to use other epistemically impossible world pairs. For example, imagine some explorers are wandering around Twin Australia, a dry continent to the south of Twin Earth. As explorers of such lands are wont to do, they are dying of thirst, so they are seeking some watery stuff to save themselves. Without knowing whether they succeed, we know (22) is false.\n\nIf the explorers find some watery stuff, they will find some water.\n\nThis theory can explain the falsity of (22). We know, from the way Twin Earth is stipulated, that all the watery stuff of the explorers’ acquaintance is not water. So we know any watery stuff they find will not be water. And we know that water is scarce on Twin Earth, even scarcer than watery stuff in Twin Australia, so it is unlikely they will find some watery stuff and simultaneously stumble across some water.\nThis theory also explains occurrences of indicatives embedded in subjunctives. These are very odd, as should be expected if indicatives are about epistemic connections and subjunctives about metaphysical connections, but we can just make sense of them some of the time. For example, it seems possible to make sense of (23) and that it is true.\n\nIf the bullet that actually killed JFK had instead killed Jackie Kennedy, then it would be true that if Oswald didn’t kill Jackie Kennedy, someone else did.\n\nOn our theory, to evaluate this we first find the nearest world pair \\(\\langle @, w \\rangle\\) such that \\(\\vDash_w^@\\) The bullet that actually killed JFK instead killed Jackie Kennedy, and then evaluate the indicative relative to it. Now one thing we know about this world pair is that in it, someone killed Jackie Kennedy. So this must hold in all nearby world pairs. Hence in any such world pair that Oswald did not kill Jackie Kennedy, someone else did, so (23) turns out true.\nIt might be thought that such embeddings do not make particularly good sense. I have some sympathy for such a view. If one adopts the ‘special theory’ developed in the previous section, and rejects the general theory developed in this subsection, one may have an explanation for the impossibility of such embeddings. However, even if we cannot make sense of such embeddings, we still need to account for the truth conditions of indicatives relative to epistemically impossible world pairs to make sense of claims such as Necessarily (\\(A \\rightarrow A\\)).7\n7 I am indebted to Lloyd Humberstone for pointing this out to me.\n\n3.4 Classifying Conditionals\nIn recent years, there has been extensive debate over where the line between indicatives and subjunctives falls. This debate focuses on whether ‘future indicatives’ like (24) are properly classified with indicatives or subjunctives.\n\nIf Booth doesn’t shoot Lincoln, someone else will.\n\nJackson (1990) and Bennett (1995) argue that this should go with ordinary indicatives. Dudman (1994) and Bennett (1988) argue that it should go with ordinary subjunctives, though this is not how Dudman would put it. This theory of indicatives appears to favour Jackson and (the later) Bennett, because of the apparent triviality of conditionals like (25).\n\nIf it will rain then it will actually rain."
  },
  {
    "objectID": "posts/indsub/index.html#conclusion",
    "href": "posts/indsub/index.html#conclusion",
    "title": "Indicative and Subjunctive Conditionals",
    "section": "4 Conclusion",
    "text": "4 Conclusion\nDespite its lack of attention in the literature, data about the role of rigid designators in indicatives deserve close attention. Any plausible theory of indicatives must be able to deal with it, and it isn’t clear how existing possible worlds theories could do so. The easiest way to build a semantics for indicatives is to say that “If \\(A\\) then \\(C\\)” is true just in case the nearest world in which \\(A\\) is true is a world where \\(C\\) is true. Even before the hard questions about the meaning of ‘nearest’ here start to be asked, we know a theory of this form is wrong because it makes mistaken predictions about the role of rigid designators. A conditional like “If the stuff in the rivers, lakes and oceans really is XYZ, then water is XYZ” is true, even though the consequent is true in no possible worlds. The simplest way to solve this difficulty is to revisit the idea of ‘true in a world’. Rather than looking for a nearby world in which \\(A\\) is true, and asking whether \\(C\\) is true in it, we look for a nearby world \\(w\\) such that \\(A\\) is true under the supposition that \\(w\\) is actual, and ask whether \\(C\\) is true under the supposition that \\(w\\) is actual. In the terminology of Jackson (1998), we look at worlds considered as actual, rather than worlds considered as counterfactual. This simple change makes an important difference to the way rigid designators behave. There is no world in which water is XYZ. However, under the supposition that the stuff in the rivers, lakes and oceans really is XYZ, and the H2O theory is just a giant mistake, that is, under the supposition that we are in the world known as Twin Earth, water is XYZ. In short, “water is XYZ” is true in Twin Earth considered as actual, even though it is false in Twin Earth considered as counterfactual. So the data about behaviour of rigid designators in indicatives, data like the truth of “If the stuff in the rivers, lakes and oceans really is XYZ, then water is XYZ”, does not refute the hypothesis that “If \\(A\\) then \\(C\\)” is true iff the nearest world such that \\(A\\) is true in that world considered as actual is a world where \\(C\\) is true in that world considered as actual.\nIn section two we looked at how the formal structure of a theory built around that hypothesis might look. In section three we looked at how some of the details may be filled in. The most pressing task is to provide a similarity metric so we can have some idea about which worlds will count as being nearby. The theory I defended has three important features. First, it is epistemic. Which worlds are nearby depends on what is known by conversational participants. Secondly, it is contextualist in two respects. The first respect is that it is the knowledge of the audience that matters, not just the knowledge of the speaker and the intended audience. The second respect is that it allows that what is known by the audience may be affected by the utterance of the conditional. In particular, if the utterance of “If \\(A\\), \\(B\\)” causes the audience to consider \\(A\\) to be possible, and hence cease to know that \\(\\neg A\\), then \\(A\\) is not part of what is known for purposes of determining which worlds are nearby. (I assume here a broadly contextualist account of knowledge, as in Lewis (1996), but this is inessential. If you do not like Lewis’s theory, replace all references to knowledge here, and in section 3.1, with references to epistemic certainty. I presume that what is epistemically certain really is contextually variable in the way Lewis suggests.) Thirdly, it is coarse- grained: whether a world is nearby depends only on whether it is consistent with what is known, not ‘how much’ it agrees with what is known. The resultant theory seems to capture all the data, to explain the generally close connection between indicatives and subjunctives, and to explain the few differences which do arise between indicatives and subjunctives.\nThe other detail to be filled in concerns embeddings of indicatives inside subjunctives. The formalism here requires that we use the full resources of two- dimensional modal logic, but the basic idea is very simple. Consider a sentence of the form “If it were the case that \\(A\\), it would be the case that if \\(B\\), \\(C\\) .” Roughly, this will be true iff the metaphysically nearest world in which \\(A\\) is true, call it \\(w_A\\), is a world where \\(B \\rightarrow C\\) is true. And that will be true iff the epistemically nearest world to \\(w_A\\) is which \\(B\\) is true is a world where \\(C\\) is true. Less roughly, we have to quantify not over worlds, but over pairs of worlds, where the first element of the pair determines the reference for rigid designators, and the second element determines the truth of sentences given those references. But this only adds to the formal complexity; the underlying idea is still the same. The important philosophical point to note is that when we are trying to find the epistemically nearest world to \\(w_A\\) (or, more strictly, the nearest world pair to \\(\\langle @, w_A \\rangle\\)) the facts that have to be held fixed are the facts that we know about \\(w_A\\), not what our counterparts in \\(w_A\\), or indeed what any inhabitant of \\(w_A\\) knows about their world. These embeddings may be rare in everyday speech, but since they are our best guide to the truth values of indicatives in other possible worlds, they are theoretically very important."
  },
  {
    "objectID": "posts/imps/index.html",
    "href": "posts/imps/index.html",
    "title": "Accuracy and the Imps",
    "section": "",
    "text": "1 Accuracy, Bribes and Scoring Rules\nBelief aims at the truth. So at least in some sense, an agent is doing better at believing the closer they are to the truth. When applied to individual beliefs, this generates epistemic advice that is literally platitudinous: if you know that a change in your attitude towards p will make your attitude towards p more accurate, make that change! When applied to collective bodies of belief though, the advice turns out to be more contentious. Call epistemic consequentialism the view that if an agent knows that a change in their overall belief state will make their belief state more accurate, they should make that change, if they have the power to do so.\n\nThanks to Alejandro Pérez Carballo, Richard Pettigrew, and the participants in the Arché Epistemology Seminar for helpful comments.\nImage by tanakawho via Creative Commons.\n\nHilary Greaves (2013) has recently argued that epistemic consequentialism is false because it licences certain epistemic ‘bribes’, and these should not be licenced. We’ll argue that the best forms of epistemic consequentialism do not licence some of these bribes after all.1 Here is the key case Greaves uses.2\n1 Though they do licence others; see section 2.4 for more discussion.2 Greaves has four other cases, but the Imps case is the only one that is a problem for all forms of consequentialism she discusses. Similar cases have suggested by Selim (Berker 2013a, 2013b) and C. S. Jenkins (2007), but we’ll focus on Greaves’s discussion since she engages more fully with the literature on scoring rules. We’ll return briefly to Berker’s discussion in section 2.\nEmily is taking a walk through the Garden of Epistemic Imps. A child plays on the grass in front of her. In a nearby summerhouse are \\(n\\) further children, each of whom may or may not come out to play in a minute. They are able to read Emily’s mind, and their algorithm for deciding whether to play outdoors is as follows. If she forms degree of belief 0 that there is now a child before her, they will come out to play. If she forms degree of belief 1 that there is a child before her, they will roll a fair die, and come out to play iff the outcome is an even number. More generally, the summerhouse children will play with chance \\((1-\\frac{q(C_0)}{2})\\), where \\(q(C_0)\\) is the degree of belief Emily adopts in the proposition \\(C_0\\) that there is now a child before her. Emily’s epistemic decision is the choice of credences in the proposition \\(C_0\\) that there is now a child before her, and, for each \\(j = 1, \\ldots, n\\) the proposition \\(C_j\\) that the jth summerhouse child will be outdoors in a few minutes’ time.\n\n\n\\(\\ldots\\) if Emily can just persuade herself to ignore her evidence for \\(C_0\\), and adopt (at the other extreme) credence 0 in \\(C_0\\), then, by adopting degree of belief 1 in each \\(C_{j} (j = 1, ... , 10)\\), she can guarantee a perfect match to the remaining truths. Is it epistemically rational to accept this ‘epistemic bribe’? Greaves (2013, 918)\n\nThe epistemic consequentialist says that it is best to have credences that are as accurate as possible. We will focus on believers who assign probabilistically coherent credences (degrees of belief) to the propositions in some “target set” \\(\\mathscr{X}\\), and we will think of the “degree of fit” between her beliefs and the truth as being measured by a strictly proper scoring rule. This is a function \\(\\mathbf{I}_{\\mathscr{X}}\\) which associates each pair \\(\\langle \\mathbf{cred}, @ \\rangle\\) consisting of a credence function \\(\\mathbf{cred}\\) whose domain includes \\(\\mathscr{X}\\) and a consistent truth-value assignment @ for elements of \\(\\mathscr{X}\\) with a non-negative real number \\(\\mathbf{I}_{\\mathscr{X}}(@, \\mathbf{cred})\\). Intuitively, \\(\\mathbf{I}_{\\mathscr{X}}\\) measures the inaccuracy of the credences that cred assigns to the propositions in \\(\\mathscr{X}\\) when their truth-values are as described by @. Note that higher \\(\\mathbf{I}_{\\mathscr{X}}\\)-values indicate higher levels of epistemic disutility, so that lower is better from a consequentialist perspective. One popular scoring rule is the Brier score, which identifies inaccuracy with the average squared distance between credences and truth-values. (Greaves calls this the ‘quadratic scoring rule’, which is a useful description too.) More formally, we have:\n\\[\\mathbf{Brier}_{\\mathscr{X}}(@, \\mathbf{cred}) = \\frac{1}{|\\mathscr{X}|}\\sum_{X \\in \\mathscr{X}} (\\mathbf{cred}(X) - @(X))^2\\] where \\(|\\mathscr{X}|\\) is the number of propositions in \\(\\mathscr{X}\\) and \\(@(X)\\) is either zero or one depending upon whether X is true or false.\nAnother common score is the logarithmic rule, which defines inaccuracy as:\n\\[\\mathbf{Log}_{\\mathscr{X}}(@, \\mathbf{cred}) = \\frac{1}{|\\mathscr{X}|}\\sum_{X \\in \\mathscr{X}} -\\text{log}(\\mathbf{cred}(X)) \\cdot @(X)\\] For now we will follow Greaves in assuming that our epistemic consequentialist uses the Brier score to measure epistemic disutility, but we will relax that assumption in a little while.\nNow let’s think about the ‘bribe’ that Greaves offers, from the point of view of the epistemic consequentialist. The choices are to have one of two credal states, which we’ll call cred1 and cred2. We’ll say cred1 is the one that best tracks the initial evidence, so \\(\\mathbf{cred1}(C_0) = 1\\), and \\(\\mathbf{cred1}(C_i) = 0.5\\) for \\(i \\in {1, ..., 10}\\). And cred2 is the credence Emily adopts if she accepts the bribe, so \\(\\mathbf{cred2}(C_0) = 0\\), while \\(\\mathbf{cred2}(C_i) = 1\\) for \\(i \\in {1, ..., 10}\\). Which state is better?\nThinking like an epistemic consequentialist, you might ask which state is more accurate? It seems like that would be cred2. While cred1 gets \\(C_0\\) exactly right it does not do very well on the other propositions. In contrast, while cred2 gets \\(C_0\\) exactly wrong, it is perfect on the other ten propositions. So overall, cred2 looks to have better epistemic consequences: when compared to being right about one proposition and off by 0.5 on ten others, being right on ten is surely worth one false belief. The Brier score seems to bear this out. If we let \\(\\mathscr{X}\\), the target set, consist of \\(C_0, C_1, ..., C_{10}\\), then we have \\[\\begin{aligned}\n\\mathbf{Brier}_\\mathscr{X}(\\mathbf{cred1}, @) &= \\frac{1}{11}[(1-\\mathbf{cred1}(C_0))^2 + \\sum_{i = 1}^{10} (@(C_i) - \\frac{1}{2}) ^2] = \\frac{10}{44} \\\\\n\\mathbf{Brier}_\\mathscr{X}(\\mathbf{cred2}, @) &= \\frac{1}{11}[(1-\\mathbf{cred2}(C_0))^2 + \\sum_{i = 1}^{10} (@(C_i) - cred(C_i)) ^2] = \\frac{1}{11} \\end{aligned}\\] So, it seems that a good epistemic consequentialist will take the bribe. But, doesn’t that seem like the height of epistemic irresponsibility? It means choosing to believe that \\(C_0\\) is certainly false when you have conclusive evidence for thinking that it is true. If you see the child on the lawn in front of you, how can you sanction believing she is not there?\nAs Greaves admits, intuitions are divided here. Some consequentialists might think that “epistemic bribes” are at least sometimes worth taking, while those of a more deontological bent will always find such trade-offs “beyond the pale”  (Berker 2013a, 363). We will largely sidestep these contentious issues here, though our argument will offer comfort to epistemic consequentialists who feel queasy about accepting the bribe offered in Imps. We contend that, when inaccuracy is measured properly, the consequences of adopting the cred2 credences are strictly worse than the consequences of adopting cred1.\nThe basic problem is that Imps cherry-picks propositions in a way no consequentialist should condone. Its persuasive force rests on the assumption that, for purposes of epistemic evaluation, nothing matters except the accuracies of the credences assigned to propositions in the target set \\(\\mathscr{X}\\). But \\(\\mathscr{X}\\) is the wrong target! By confining attention to it Greaves ignores the many other credences to which Emily becomes committed as a consequence of adopting cred1 or cred2. Any (coherent) agent who invests credence zero in \\(C_0\\) must also invest credence zero in any proposition \\(C_0 \\wedge Y\\), where \\(Y\\) is any conjunction or disjunction of elements from \\(\\mathscr{X}\\). Likewise, anyone who invests credence one in \\(C_n\\) must invest credence one in any proposition \\(C_n \\vee Y\\), where \\(Y\\) is any conjunction or disjunction from \\(\\mathscr{X}\\). In the current context (where the probabilities of the various \\(C_i\\) are independent), when Emily adopts a credence function over \\(\\mathscr{X}\\) she commits to having a credence for (i) every atomic proposition ±\\(C_0 \\wedge\\)± \\(C_1 \\wedge\\)±\\(C_2 \\wedge \\ldots \\wedge\\)±\\(C_{10}\\), where ‘±’ can be either an affirmation or a negation, and (ii) every disjunction of these atomic propositions. In short, she commits to having credences over the whole Boolean algebra \\(\\mathscr{A}_\\mathscr{X}\\) generated by \\(\\mathscr{X}\\). Since each event of a child coming out is independent, adopting cred1 will commit her to setting cred1(±\\(C_0 \\wedge\\)± \\(C_1 \\wedge\\)±\\(C_2 \\wedge \\ldots \\wedge\\)±\\(C_{10}) = \\frac{1}{1024}\\) when \\(C_0\\) is affirmed, and 0 when it is negated. While adopting cred2 commits her to setting cred2(±\\(C_0 \\wedge\\)± \\(C_1 \\wedge\\)±\\(C_2 \\wedge \\ldots \\wedge\\)±\\(C_{10}\\)) equal to 1 when \\(C_0\\) is negated and the rest of the \\(C_i\\) are affirmed, and to 0 otherwise. In this way, each of these probability assignments over the 2048 atoms determine a definite probability for every one of the \\(2^{2048}\\) propositions in \\(\\mathscr{A}_\\mathscr{X}\\).\nIt is our view that consequentialists should reject any assessment of epistemic utility that fails to take the accuracies of all these credences into account. All are consequences of adopting cred1 or cred2, and so all should be part of any consequentialist evaluation of the quality of those credal states. The right “target set” to use when computing epistemic disutility is not \\(\\mathscr{X}\\) but \\(\\mathscr{A}_\\mathscr{X}\\). If we don’t do that, we ignore most of the ways in which cred1 and cred2 differ in accuracy. If Emily takes the bribe, she goes from having credence 0.5 in \\(C_0 \\leftrightarrow C_1\\) to having credence 0 in it. And that’s unfortunate, because the chance of \\(C_0 \\leftrightarrow C_1\\) goes from 0.5 to 1. This is another proposition, as well as \\(C_0\\), that Emily acquires a false belief in by taking the bribe. Of course, there are other propositions not counted that go the other way. Originally, Emily has a credence of 0.25 in \\(C_1 \\wedge C_2\\), and its chance is also 0.25. After taking the bribe, this has a chance of 1, and her credence in it is 1. That’s an improvement in accuracy. So there are a host of both improvements and deteriorations that are as yet unaccounted for. We should account for them, and making the target set be \\(\\mathscr{A}_\\mathscr{X}\\) does that.\nWhen seen from this broader perspective, it turns out the seeming superiority of cred2 over cred1 evaporates. The rest of this section (and the appendix) is dedicated to demonstrating this. We’ll make the calculations a little easier on ourselves by relying on a theorem concerning Brier scores for coherent agents. Assume, as is the case here, that Emily’s credences are defined over an atomic Boolean alegbra of propositions. The atoms are the ‘worlds’, or states that are maximially specific with respect to the puzzle at hand. In this case there are 2048 states, which we’ll label \\(s_0\\) through \\(s_{2047}\\). In \\(s_k\\), the first child is on the lawn iff \\(k \\leq 1023\\), and summerhouse child \\(i\\) comes out iff the (\\(i\\) + 1)th digit in the binary expansion of \\(k\\) is 1. Let \\(\\mathscr{S}_\\mathscr{X}\\) be the set of all these states. That’s not a terrible target set; as long as Emily is probabilistically coherent it is comprehensive. The theorem in question says that for any credence function cred defined over a partition of states \\(\\mathscr{S}\\), and over the algebra \\(\\mathscr{A}\\) generated by those states,\n\nTheorem-1 \\[\\mathbf{Brier}_{\\mathscr{A}}(\\mathbf{cred}, @) = \\frac{|\\mathscr{S}|}{4}\\mathbf{Brier}_{\\mathscr{S}}(\\mathbf{cred}, @)\\]\n\n(The proof of this is in the appendix.) So whichever credence function is more accurate with respect to \\(\\mathscr{S}_{\\mathscr{X}}\\) will be more accurate with respect to \\(\\mathscr{A}_{\\mathscr{X}}\\). So let’s just work out \\(\\mathbf{Brier}_{\\mathscr{S}_{\\mathscr{X}}}\\) for cred1 and cred2 at the actual world.\nFirst, cred1 will appropriately assign credence 0 to each \\(s_k (k \\in {0, ..., 1023})\\). Then it assigns credence \\(\\frac{1}{1024}\\) to every other \\(s_k\\). For 1023 of these, that is off by \\(\\frac{1}{1024}\\), contributing \\(\\frac{1}{2^{20}}\\) to the Brier score. And for 1 of them, namely @, it is off by \\(\\frac{1023}{1024}\\), contributing \\(\\frac{1023^2}{2^{20}}\\). So we get: \\[\\begin{aligned}\n\\mathbf{Brier}_{\\mathscr{S}_{\\mathscr{X}}}(\\mathbf{cred1}, @) &= \\frac{1}{2048} [1024 \\cdot 0 + 1023 \\cdot \\frac{1}{2^{20}} + \\frac{1023^2}{2^{20}}] \\\\\n&= \\frac{1}{2048} \\cdot \\frac{1023 + 1023 ^2}{2^{20}} \\\\\n&= \\frac{1}{2048} \\cdot \\frac{1023 \\cdot 1024}{2^{20}} \\\\\n&= \\frac{1}{2048} \\cdot \\frac{1023}{1024} \\\\\n&= \\frac{2^{10}-1}{2^{21}}\\end{aligned}\\] It’s a bit easier to work out \\(\\mathbf{Brier}_{\\mathscr{S}_{\\mathscr{X}}}(\\mathbf{cred2}, s_{2047})\\). (We only need to work out the Brier score for that state, because by the setup of the problem, Emily knows that’s the state she’ll be in if she adopts cred2). There are 2048 elements in \\(\\mathscr{S}_{\\mathscr{X}}\\). And cred2 assigns the perfectly accurate credence to 2046 of them, and is perfectly inaccurate on 2, namely \\(s_{1023}\\), which it assigns credence 1, and \\(s_{2047}\\) which it assigns credence 0. So we have \\[\\begin{aligned}\n\\mathbf{Brier}_{\\mathscr{S}_{\\mathscr{X}}}(\\mathbf{cred2}, s_{2047}) &= \\frac{1}{2048} (2046 \\cdot 0 + 1 + 1) \\\\\n&= \\frac{1}{1024} \\\\\n&= \\frac{2^{11}}{2^{21}}\\end{aligned}\\] In fact, it isn’t even close. If Emily adopts cred2 she becomes a little more than twice as inaccurate.\nIt is tedious to calculate \\(\\mathbf{Brier}_{\\mathscr{A}_{\\mathscr{X}}}(\\mathbf{cred1}, @)\\) directly, but it is enlightening to work through the calculation of \\(\\mathbf{Brier}_{\\mathscr{A}_{\\mathscr{X}}}(\\mathbf{cred2}, s_{2047})\\). Note that there are two crucial states out of the 2048: \\(s_{2047}\\), the actual state where all children come out, and state \\(s_{1023}\\) where child 0 does not come out, but the other 10 children all do. There are \\(2^{2^{11}-2}\\) propositions in each of the following four sets:\n\n\\(\\{p: s_{2047} \\vDash p\\) and \\(s_{1023} \\vDash p\\}\\)\n\\(\\{p: s_{2047} \\vDash p\\) and \\(s_{1023} \\nvDash p\\}\\)\n\\(\\{p: s_{2047} \\nvDash p\\) and \\(s_{1023} \\vDash p\\}\\)\n\\(\\{p: s_{2047} \\nvDash p\\) and \\(s_{1023} \\nvDash p\\}\\)\n\nIf Emily takes the bribe, she will have perfect accuracy with respect to all the propositions in class 1 (which are correctly believed to be true), and all the propositions in class 4 (which are correctly believed to be false). But she will be perfectly inaccurate with respect to all the propositions in class 2 (which are incorrectly believed to be false), and all the propositions in class 3 (which are incorrectly believed to be true). So she is perfectly accurate on half the propositions, and perfectly inaccurate on half of them, so one’s average inaccuracy is \\(0.5 \\cdot 0 + 0.5 \\cdot 1 = 0.5\\). And that’s an enormous inaccuracy. It is, in fact, as inaccurate as one can possibly be while maintaining probabilistic coherence.\n\nTheorem-2: When inaccuracy over \\(\\mathscr{A}\\) is measured using the Brier score, the least accurate credal states are those which assign credence 1 to some false atom of \\(\\mathscr{A}\\).\n\n(The proof is in the appendix.) So taking the bribe is not a good deal, even by consequentialist lights. And that isn’t too surprising; taking the bribe makes Emily have maximally inaccurate credences on half of the possible propositions about the children.\nSo far we have followed Greaves in assuming that inaccuracy is measured by the quadratic, or Brier, rule. It turns out that we can drop that assumption. We actually only need some very weak conditions on accuracy rules to get the result that Greaves style bribes are bad deals, though the proof of this becomes a trifle more complicated.\nLet \\(\\mathscr{A}\\) be an algebra of propositions generated by a partition of \\(2N\\) atoms \\(a_1, ..., a_{2N}\\). Suppose \\(a_1\\) is the truth, and consider two probability functions, \\(P\\) and \\(Q\\) defined in \\(\\mathscr{A}\\). \\(P\\) assigns all its mass to the first \\(N\\) atoms, so that \\(P(a_k) = 0\\) for all \\(k &gt; N\\). We also assume that \\(P\\) assigns some positive probability to the true atom \\(a_1\\). \\(Q\\) assigns all its mass to the false atom \\(a_{2N}\\). Note that this will be a good model of any case where an agent is offered a bribe of the form: drop the positive confidence you have in proposition \\(p_0\\), instead assign it credence 0, and you’ll be guaranteed a maximally accurate credence in \\(j\\) other logically independent propositions \\(p_1, ..., p_j\\). The only other assumptions needed to get the model to work are that \\(p_0\\) is actually true, and \\(N = 2^j\\).\nImagine that the accuracy of a probability function \\(\\pi\\) over \\(\\mathscr{A}\\) is measured by a proper scoring rule of the form\n\\[\\mathbf{I}(a_n, \\pi) = 2^{-2N}\\sum_{X \\in \\mathscr{A}} \\mathbf{i}(v_n(X), \\pi(X))\\] where \\(v_n(X)\\) is \\(X\\)s truth value when \\(a_n\\) is the true atom, and i is a score that gives the accuracy of \\(\\pi(X)\\) in the event that \\(X\\)s truth value is \\(v_n(X)\\). We shall assume that this score has the following properties.\n\nTruth Directedness\n\nThe value of \\(\\mathbf{i}(1, p)\\) decreases monotonically as \\(p\\) increases. The value of \\(\\mathbf{i}(0, p)\\) increases monotonically as \\(p\\) decreases.\n\nExtensionality\n\n\\(\\mathbf{i}(v_n(X), \\pi(X))\\) is a function only of the truth-value and the probability; the identity of the proposition does not matter.\n\nNegation Symmetry\n\n\\(\\mathbf{i}(v_n(\\neg X), \\pi(\\neg X)) = \\mathbf{i}(v_n(X), \\pi(X))\\) for all \\(x, n, \\pi\\).\n\n\n\nTheorem-3: Given these assumptions, \\(P\\)’s accuracy strictly exceeds \\(Q\\)’s.\n\nAgain, the proof is in the appendix.\nTheorem-3 ensures that taking the deal that Greaves offers in Imps will reduce Emily’s accuracy relative to any proper scoring rule satisfying Truth Directedness, Extensionality and Negation Symmetry. To see why, think of Emily’s credences as being defined over an algebra generated by the atoms ±\\(C_0 \\wedge\\)± \\(C_1 \\wedge\\)±\\(C_2 \\wedge \\ldots \\wedge\\)±\\(C_{10}\\), where it is understood that some \\(C_0\\) atom is true and all the \\(\\neg C_0\\) atoms are false. Since Emily is convinced of \\(C_0\\) and believes that every other \\(C_n\\) has some chance of occurring, and since the various \\(C_n\\) are independent of one another, her credence function cred1 will assigns a positive probability to each \\(C_0\\) atom, including the true atom (whichever that might be). Now, let \\(Q\\) be a credence function that places all its weight on some false atom \\(\\neg C_0 \\wedge\\)± \\(C_1 \\wedge\\)±\\(C_2 \\wedge \\ldots \\wedge\\)±\\(C_{10}\\). Theorem-3 tells us that Emily’s cred1 is more accurate than \\(Q\\), and that this is true no matter which \\(C_0\\) atom is true or which \\(\\neg C_0\\) atom \\(Q\\) regards as certain. By taking the bribe Emily will guarantee the truth of \\(C_0 \\wedge C_1 \\wedge \\dots \\wedge C_{10}\\), but the cost will be that she must adopt the cred2 credences, which assign probability one to the false atom \\(\\neg C_0 \\wedge C_1 \\wedge \\dots \\wedge C_{10}\\). Extensionality ensures that any two credence functions that assign probability one to a false atom will have the same inaccuracy score, and that this score will not depend on which atom happens to be the true one. The upshot is that cred2 will have the same inaccuracy when Emily accepts the bribe as \\(Q\\) does when she rejects it. Thus, since cred1 is more accurate than \\(Q\\), it is also more accurate than cred2, which means that Emily should reject the bribe in order to promote credal accuracy.\nWe do not want to oversell this conclusion. Strictly speaking, we have only shown that consequentialists should reject epistemic bribes when doing so requires them to go from being confident in a truth to being certain of some maximally specific falsehood. This is a rather special situation, and there are nearby cases to which our results do not apply, and in which consequentialists may sanction bribe-taking. For example, if Emily only has to cut her credence for \\(C_0\\) in half, say from \\(\\frac{1}{2}\\) to \\(\\frac{1}{4}\\), to secure knowledge of \\(C_1 \\wedge \\dots \\wedge C_{10}\\), then Theorem-3 offers us no useful advice. Indeed, depending on the scoring rule and the nature of the bribe, we suspect that believers will often be able to improve accuracy by changing their credences in ways not supported by their evidence, especially when these changes affect the truth-values of believed propositions. The only thing we insist upon is that, in all such cases, credal accuracy should be measured over all relevant propositions, not just over a select salient few. But that’s something that is independently plausible. Perhaps it might be pragmatically justified to become more accurate on salient propositions at the expense of becoming very inaccurate over hard to state compounds of those propositions, but it is never epistemically justified.\n\n\n2 Four Caveats\n\n2.0.1 Greaves’s Imps Argument May Work Against Some Forms of Consequentialism\nWe said above that no consequentialist should accept Greaves’s setup of the Imps puzzle, since they should not accept an inaccuracy measure that ignores some kind of introduced inaccuracy. That means that, for all we have said, Greaves’s argument works against those consequentialists who do not agree with us over the suitability of target sets that are neither algebras or partitions. And, at least outside philosophy, some theorists do seem to disagree with us.\nFor instance, it is common in meteorology to find theorists who measure the accuracy of rain forecasts over an \\(n\\) day period by just looking at the square of the distance between the probability of rain and the truth about rain on each day. To pick an example almost literally at random, Mark Roulston (2007) defends the use of the Brier score, calculated just this way, as a measure of forecast accuracy. So Greaves’s target, while not including all consequentialists, does include many real theorists.\nThat said, it seems there are more mundane reasons to not like this approach to measuring the accuracy of weather forecasts. Consider this simple case. Ankita and Bojan are issuing forecasts for the week that include probabilities of rain. They each think that there is a 0% chance of rain most days. But Ankita thinks there will be one short storm come through during the week, while Bojan issues a 0% chance of rain forecast for each day. Ankita thinks the storm is 75% likely to come on Wednesday, so there’s a 75% chance of rain that day, and 25% likely to come Thursday, so there’s a 25% chance of rain that day.\nAs it happens, the storm comes on Thursday. So over the course of the week, Bojan’s forecast is more accurate than Ankita’s. Bojan is perfectly accurate on 6 days, and off by 1 on Thursday. Ankita is perfectly accurate on 5 days, and gets an inaccuracy score of \\(0.75^2 = 0.5625\\) on Wednesday and Thursday, which adds up to more than Bojan’s inaccuracy. But this feels wrong. There is a crucial question that Ankita was right about and Bojan was wrong about, namely will there be a storm in the middle of the week. Ankita’s forecast only looks less accurate because we aren’t measuring accuracy with respect to this question. So even when we aren’t concerned with magical cases like Greaves’s, there is a good reason to measure accuracy comprehensively, i.e., with respect to an algebra or a partition.\n\n\n2.0.2 Separateness of Propositions\nThere is a stronger version of the intuition behind the Imps case that we simply reject. The intuition is well expressed by Selim Berker (2013a, 365, emphasis in original)\n\nThe more general point is this: when determining the epistemic status of a belief in a given proposition, it is epistemically irrelevant whether or not that belief conduces (either directly or indirectly) toward the promotion of true belief and the avoidance of false belief in other propositions beyond the one in question.\n\nLet’s put that to the test by developing the Ankita and Bojan story a little further. They have decided to include, in the next week’s forecast, a judgment on the credibility of rain. Bojan thinks the evidence is rather patchy. And he has been reading Glenn Shafer (1976), and thinks that when the evidence is patchy, credences in propositions and their negations need not add to 1. So if \\(p\\) is the proposition It will rain next week, Bojan has a credence of 0.4 in both \\(p\\) and \\(\\neg p\\).\nAnkita thinks that’s crazy, and suggests that there must be something deeply wrong with the Shafer-based theory that Bojan is using. But Bojan is able to easily show that the common arguments against Shafer’s theory are blatantly question begging  (Maher 1997; Weatherson 1999). So Ankita tries a new tack. She has been reading Joyce (1998), from which she got the following idea. She argues that Bojan will be better off from the point of view of accuracy in having credence 0.5 in each of \\(p\\) and \\(\\neg p\\) than in having credence 0.4 in each. As it stands, one of Bojan’s credences will be off by 0.4, and the other by 0.6, for a Brier score of \\((0.4^2 + 0.6^2)/2 = 0.26\\), whereas switching would give him a Brier score of \\((0.5^2 + 0.5^2)/2 = 0.25\\).\nBut Bojan resists. He offers two arguments in reply.\nFirst, he says, for all Ankita knows, one of his credences might be best responsive to the evidence. And it is wrong, always and everywhere, to change a credence away from one that is best supported by the evidence in order to facilitate an improvement in global accuracy. That, says Bojan, is a violation of the “separateness of propositions”  (Berker 2013a).\nSecond, he says, even by Ankita’s accuracy-based lights, this is a bad idea. After all, he will be making one of his credences less accurate in order to make an improvement in global accuracy. And that’s again a violation of the separateness of propositions. It’s true that he won’t be making himself more inaccurate in one respect so as to secure accuracy in another, as in the bribes case. But he will be following advice that is motivated by the aim of becoming, in total, more accurate, at the expense of accuracy for some beliefs.\nWe want to make two points in response. First, if the general point that Berker offers is correct, then these are perfectly sound replies by Bojan. Although Bojan is not literally in a bribe case, like Emily, he is being advised to change some credences because the change will make his overall credal state better, even if it makes it locally worse in one place. It does not seem to matter whether he can identify which credence gets made worse. Berker argues that the trade offs that epistemic consequentialism makes the same mistake ethical consequentialism makes; it authorises inappropriate trade-offs. But in the ethical case, it doesn’t matter whether the agent can identify who is harmed by the trade-off. If it is wrong to harm an identifiable person for the greater good, it is wrong to harm whoever satisfies some description in order to produce the greater good.\nSo if the analogy with anti-consequentialism in ethics goes through, Bojan is justified in rejecting Ankita’s advice. After all there is, according to Berker, a rule against making oneself doxastically worse in one spot for the gain of an overall improvement. And that’s what Bojan would do if he took Ankita’s advice. But, we say, Bojan is not justified in rejecting Ankita’s advice. In fact, Ankita’s advice is sound advice, and Bojan would do well to take it. So Berker’s general point is wrong.\nOur second point is a little more contentious. We suspect that if Bojan has a good reason to resist this move of Ankita’s, he has good reason to resist all attacks on his Shafer-based position. So if Berker’s general point is right, it means there is nothing wrong with Bojan’s anti-probabilist position. Now we haven’t argued for this; to do so would require going through all the arguments for probabilism and seeing whether they can be made consistent with Berker’s general point. But our suspicion is that none of them can be, since they are all arguments that turn on undesirable properties of global features of non-probabilistic credal states. So if Berker is right, probabilism is wrong, and we think it is not wrong.\n\n\n2.0.3 Is this Consequentialism?\nSo far we’ve acquiesed with the general idea that Greaves’s and Berker’s target should be called consequentialism. But there are reasons to be unhappy with this label. In general, a consequentialist theory allows agents to make things worse in the here and now, in return for future gains. A consequentialist about prudential decision making, in the sense of Hammond (1988), will recommend exercise and medicine taking. And they won’t be moved by the fact that the exercise hurts and the medicine is foul-tasting. It is worth sacrificing the welfare of the present self for the greater welfare of later selves.\nNothing like that is endorsed, as far as we can tell, by any of the existing ‘epistemic consequentialists’. Certainly the argument that Ankita offers Bojan does not rely on this kind of reasoning. In particular, epistemic consequentialists do not say that it is better to make oneself doxastically worse off now in exchange for greater goods later. Something like that deal is offered to the reader of Descartes (1641/1996), but it isn’t as popular nowadays.\nRather, the rule that is endorsed is Right now, have the credences that best track the truth! This isn’t clearly a form of consequentialism, since it really doesn’t care about the consequences of one’s beliefs. It does say that it is fine to make parts of one’s doxastic state worse in order to make the whole better. That’s what would happen if Bojan accepted Ankita’s advice. But that’s very different from doing painful exercise, or drinking unpleasant medicine. (Or, for that matter, to withdrawing belief in any number of truths.)\nWhen Greaves tries to flesh out epistemic consequentialism, she compares it to evidential and causal versions of prudential decision theory. But it seems like the right comparison might be to something we could call constitutive decision theory. The core rule, remember, is that agents should form credences that constitute being maximally accurate, not that cause them to be maximally accurate.\nThe key point here is not the terminological one about who should be called consequentialist. Rather, it is that the distinction between causation and constitution is very significant here, and comparing epistemic utility theory to prudential utility theory can easily cause it to be lost. Put another way, we have no interest in defending someone who wants to defend a causal version of epistemic utility theory, and hence thinks it could be epistemically rational to be deliberately inaccurate now in order to be much more accurate tomorrow. We do want to defend the view that overall accuracy right now is a prime epistemic goal.\n\n\n2.0.4 Other Bribes\nAs already noted, we have not offered a general purpose response to bribery based objections to epistemic consequentialism. All we’ve shown is that some popular examples of this form of objection misfire, because they offer bribes that are bad by the consequentialists’ own lights. But there could be bribes that are immune to our objection.\nFor example, imagine that Ankita has, right now, with credence 0.9 in \\(D_0\\), and 0.5 in \\(D_1\\). These are good credences to have, since she knows those are the chances of \\(D_0\\) and \\(D_1\\). She’s then offered an epistemic bribe. If she changes her credence in \\(D_0\\) to 0.91, the chance of \\(D_1\\) will become 1, and she can have credence 1 in \\(D_1\\). Taking this bribe will increase her accuracy.\nWe could imagine the anti-consequentialist arguing as follows.\n\nIf epistemic consequentialism is true, Ankita is epistemically justified in accepting this bribe.\nAnkita is not epistemically justified in accepting this bribe.\nSo, epistemic consequentialism is not true.\n\nWe’re not going to offer a reply to this argument here; that is a task for a much longer paper. There are some reasons to resist premise one. It isn’t clear that it is conceptually possible to accept the bribe. (It really isn’t clear that it is practically possible, but we’re not sure whether that’s a good reply on the part of the consequentialist.) And it isn’t clear that the argument for premise one properly respects the distinction between causation and constitution we described in the last section.\nEven if those arguments fail, the intuitive force of premise two is not as strong as the intuition behind Greaves’s, or Berker’s, anti-bribery intuitions. And that’s one of the main upshots of this paper. It’s commonly thought that for the consequentialist, in any field, everything has its price. The result we proved at the end of section one shows this isn’t true. It turns out that no good epistemic consequentialist should accept a bribe that leads them to believing an atomic proposition they have conclusive evidence is false, no matter how strong the inducements. Maybe one day there will be a convincing bribery based case that epistemic consequentialism is unacceptably corrupting of the epistemic soul. But that case hasn’t been made yet, because we’ve shown a limit on how corrupt the consequentialist can be.\n\n\n\nAppendix: Proofs of Theorems 1, 2, 3\n\nTheorem-1: Brier\\(_{\\mathscr{A}}(\\mathbf{c},@) = \\frac{N}{4}\\text{Brier}_{\\mathscr{S}}(\\mathbf{c},@)\\) where \\[\\begin{aligned}\n\\text{Brier}_{\\mathscr{S}}(\\mathbf{c},@) &= \\frac{\\sum_{s \\in \\mathscr{S}} (@(s) - c(s))^2}{N}\\end{aligned}\\]\n\nTo prove this we rely on a series of lemmas.\n\nAlejandro Pérez Carballo gives a more direct and elegant proof of this result in a recent manuscript. We have kept our inefficient proof since its structure provides a guide for the proof of Theorem-3.\n\nLet \\(\\mathscr{A}\\) be the algebra generated by a finite partition of states \\(\\mathscr{S}= \\{s_1, s_2, \\dots, s_N\\}\\). @ is a truth-value assignment for propositions in \\(\\mathscr{A}\\). For simplicity, assume \\(s_1\\) is the true state, so that @(\\(s_1\\)) = 1 and @(\\(s_n\\)) = 0 for \\(n &gt; 1\\). The credence function c assigns values of \\(c_1, c_2, \\dots, c_{N-1}, c_N\\) to the elements of \\(\\mathscr{S}\\), where \\(\\sum^{N}_{n=1} c_n = 1\\) in virtue of coherence.\nIt will be convenient to start by partitioning \\(\\mathscr{A}\\) into four “quadrants”. Let \\(B\\) range over all disjunctions with disjunctions drawn from \\(\\mathscr{B}= \\{s_2, s_3, \\dots, s_{N-1}\\}\\) (including the empty disjunction, i.e., the logical contradition \\(\\bot\\)). Then, \\(\\mathscr{A}\\) can be split into four disjoint parts:\n\\(\\mathscr{A}_1 = \\{B \\vee s_1 \\vee s_N: B\\) a disjunction of the elements of \\(\\mathscr{B}\\}\\)\n\\(\\mathscr{A}_2 = \\{B \\vee s_1: B\\) a disjunction of the elements of \\(\\mathscr{B}\\}\\)\n\\(\\mathscr{A}_3 = \\{B \\vee s_N: B\\) a disjunction of the elements of \\(\\mathscr{B}\\}\\)\n\\(\\mathscr{A}_4 = \\{B: B\\) a disjunction of the elements of \\(\\mathscr{B}\\}\\)\nNotice that:\n\\(\\mathscr{A}_1 \\cup \\mathscr{A}_2\\) contains all and only the true propositions in \\(\\mathscr{A}\\).\n\\(\\mathscr{A}_3 \\cup \\mathscr{A}_4\\) contains all and only the false propositions in \\(\\mathscr{A}\\).\n\\(\\mathscr{A}_1\\) and \\(\\mathscr{A}_4\\) are complementary sets, i.e., all elements of \\(\\mathscr{A}_4\\) are negations of elements of \\(\\mathscr{A}_1\\), and conversely.\n\\(\\mathscr{A}_2\\) and \\(\\mathscr{A}_3\\) are also complementary.\n\\(\\mathscr{A}_1 \\cup \\mathscr{A}_4\\) is the subalgebra of \\(\\mathscr{A}\\) generated by \\(\\{s_1 \\vee s_N, s_2, s_3, \\dots, s_{N-1}\\}\\).\nAll four quadrants have the same cardinality of \\(2^{N-2}\\).\nFor an additive scoring rule \\(\\mathbf{I}(\\mathbf{c}, @) = \\sum_{A \\in \\mathscr{A}}\\mathbf{i}(\\mathbf{c}(A), @(A))\\) and \\(j = 1, 2, 3, 4\\), define \\(\\mathbf{I}_j = \\sum_{A \\in \\mathscr{A}_j}\\mathbf{i}(\\mathbf{c}(A), @(A))\\), and note that \\(\\mathbf{I}(\\mathbf{c}, @) = 2^{-N}(\\mathbf{I}_1 + \\mathbf{I}_2 + \\mathbf{I}_3 + \\mathbf{I}_4)\\).\n\nLemma-1.1: If \\(\\textbf{I}\\) is negation symmetric, i.e., if \\(\\mathbf{i}(\\mathbf{c}(\\neg A), @(\\neg A)) = \\mathbf{i}(\\mathbf{c}(A), @(A))\\) for all \\(A\\), then \\(\\mathbf{I}_1 = \\mathbf{I}_4\\) and \\(\\mathbf{I}_2 = \\mathbf{I}_3\\), and \\(\\mathbf{I}(\\mathbf{c},@) = 2^{1-N}(\\mathbf{I}_2 + \\mathbf{I}_4)\\).\n\nProof: This is a direct consequence of the fact that \\(\\mathscr{A}_1\\) is complementary to \\(\\mathscr{A}_4\\) and that \\(\\mathscr{A}_2\\) is complementary to \\(\\mathscr{A}_3\\) since this allows us to write\n\\[\\begin{aligned}\n\\mathbf{I}_1(\\mathbf{c},@) &= \\sum_{A \\in \\mathscr{A}_1} \\mathbf{i}(\\mathbf{c}(A), @(A)) = \\sum_{A \\in \\mathscr{A}_1} \\mathbf{i}(\\mathbf{c}(\\neg A), @(\\neg A)) = \\mathbf{I}_4(\\mathbf{c},@). \\\\\n\\mathbf{I}_3(\\mathbf{c},@) &= \\sum_{A \\in \\mathscr{A}_3} \\mathbf{i}(\\mathbf{c}(A), @(A)) = \\sum_{A \\in \\mathscr{A}_3} \\mathbf{i}(\\mathbf{c}(\\neg A), @(\\neg A)) = \\mathbf{I}_2(\\mathbf{c},@). \\text{ QED}\\\\\\end{aligned}\\] Applying Lemma 1.1 with I = Brier we get\n\\[\\begin{aligned}\n(\\#)\\quad \\mathbf{Brier}_{\\mathscr{A}}(\\mathbf{c}, @) &= 2^{1-N} \\sum_{A \\in \\mathscr{A}} (@(A) - c(A))^2 \\\\\n&= 2^{1-N} \\sum_B [(1-c_1)^2 - 2(1-c_1)\\mathbf{c}(B) + \\mathbf{c}(B)^2]\\end{aligned}\\] since\n\\[\\begin{aligned}\n\\mathbf{Brier}_2 &= \\sum_B[1 - \\mathbf{c}(B \\vee s_1)]^2 &&= \\sum_B[(1 - c_1) - \\mathbf{c}(B)]^2 \\\\\n& &&= \\sum_B [(1-c_1)^2 - 2(1-c_1)\\mathbf{c}(B) + \\mathbf{c}(B)^2] \\\\\n\\mathbf{Brier}_4 &= \\sum_B \\mathbf{c}(B)^2 && \\quad\\end{aligned}\\]\n\nLemma-1.2 \\[\\begin{aligned}\n(\\sum_{n=2}^{N-1} c_n)^2 &= \\sum_{n=2}^{N-1} c{_n}^2 + 2 \\sum_{n=2}^{N-2} \\sum_{j&gt;n}^{N-1}c_nc_j\\end{aligned}\\]\n\nProof by induction. Easy.\n\nLemma-1.3 \\[\\begin{aligned}\n\\mathbf{Brier}_{\\mathscr{S}}(\\mathbf{c},@) &= \\frac{2}{N}[(1-c_1)^2 + \\sum_{n=2}^{N-1} c{_n}^2  - (1-c_1)(\\sum_{n=2}^{N-1}c_n) + \\sum_{n=2}^{N-2} \\sum_{j&gt;n}^{N-1}c_nc_j]\\end{aligned}\\]\n\nProof: Using the definition of the Brier score and the fact that \\(s_1\\) is true, we have\n\\[\\begin{aligned}\n\\mathbf{Brier}_{\\mathscr{S}}(\\mathbf{c},@) &= \\frac{1}{N}[(1 - c_1)^2 + \\sum_{n=2}^{N-1} c{_n}^2 + (1 - \\sum_{n=1}^{N-1}c_n)^2] \\\\\n&= \\frac{1}{N}[(1 - c_1)^2 + \\sum_{n=2}^{N-1} c{_n}^2 + ((1 -c_1) - \\sum_{n=2}^{N-1}c_n)^2] \\\\\n&= \\frac{1}{N}[(1 - c_1)^2 + \\sum_{n=2}^{N-1} c{_n}^2 + (1 -c_1)^2 - 2(1 - c_1) \\sum_{n=2}^{N-1}c_n + (\\sum_{n=2}^{N-1}c_n)^2] \\\\\n&= \\frac{1}{N}[(1 - c_1)^2 + \\sum_{n=2}^{N-1} c{_n}^2 + (1 -c_1)^2 - 2(1 - c_1) \\sum_{n=2}^{N-1}c_n  \\\\\n&\\quad \\quad +\\sum_{n=2}^{N-1} c{_n}^2 + 2 \\sum_{n=2}^{N-2} \\sum_{j&gt;n}^{N-1}c_nc_j] \\quad \\text{(Lemma-1.2)}\\end{aligned}\\] Then grouping like terms and factoring out 2 yields the desired result. QED\n\nLemma-1.4 \\[\\begin{aligned}\n\\sum_{n=2}^{N-1}c_n &= 2^{3-N}\\sum_{B \\in \\mathscr{B}}\\mathbf{c}(B)\\end{aligned}\\]\n\nProof: For each \\(n = 2, 3, \\dots, N-1\\), each \\(s_n\\) appears in half of the \\(2^{N-2}\\) disjunctions with disjuncts drawn from \\(\\mathscr{B}\\). As a result, each \\(c_n\\) appears as a summand \\(2^{N-3}\\) times among the sums that express the various \\(\\mathbf{c}(B)\\). So \\(\\sum_{B \\in \\mathscr{B}}\\mathbf{c}(B) = 2^{N-3}\\sum_{n=2}^{N-1}c_n\\). QED\n\nLemma-1.5 \\[\\begin{aligned}\n\\sum_{B \\in \\mathscr{B}}\\mathbf{c}(B)^2 &= 2^{N-3}[\\sum_{n=2}^{N-1} c{_n}^2 + \\sum_{n=2}^{N-2} \\sum_{j&gt;n}^{N-1}c_nc_j]\\end{aligned}\\]\n\nProof: We proceed by induction starting with the first meaningful case of \\(N=4\\), where calculation shows \\(\\sum_B\\mathbf{c}(B)^2 = (c_2 + c_3)^2 + c{_2}^2 + c{_3}^2 = 2[c{_2}^2 + c{_3}^2 + c_2c_3]\\). Now, assume the identity holds for disjunctions \\(B\\) of elements of \\(\\mathscr{B}\\) and show that it holds for disjunctions \\(A\\) of elements of \\(\\mathscr{B}\\cup \\{s_N\\}\\).\n\\[\\begin{aligned}\n\\sum_A\\mathbf{c}(A)^2 &= \\sum_B\\mathbf{c}(B)^2 + \\sum_B\\mathbf{c}(B \\vee s_N)^2 \\\\\n&= \\sum_B\\mathbf{c}(B)^2 + \\sum_B(\\mathbf{c}(B)^2 + 2c_N\\mathbf{c}(B) + c{_N}^2)\\\\\n&= 2\\sum_B\\mathbf{c}(B)^2 + 2c_N\\sum_B\\mathbf{c}(B) + \\sum_Bc{_N}^2 \\\\\n&= 2 \\cdot 2^{N-3}[\\sum_{n=2}^{N-1} c{_n}^2 + \\sum_{n=2}^{N-2} \\sum_{j&gt;n}^{N-1}c_nc_j] + 2c_N\\sum_B\\mathbf{c}(B) + \\sum_Bc{_N}^2 &&\\text{(Induction Hypothesis)}\\\\\n&= 2^{N-2}[\\sum_{n=2}^{N-1} c{_n}^2 + \\sum_{n=2}^{N-2} \\sum_{j&gt;n}^{N-1}c_nc_j] + 2^{N-2}c_N\\sum_{n=2}^{N-1}c_n + \\sum_Bc{_N}^2 &&\\text{(Lemma-1.4)} \\\\\n&= 2^{N-2}[\\sum_{n=2}^{N-1} c{_n}^2 + \\sum_{n=2}^{N-2} \\sum_{j&gt;n}^{N-1}c_nc_j] + 2^{N-2}c_N\\sum_{n=2}^{N-1}c_n + 2^{N-2}c{_N}^2 &&\\text{Since $|\\mathscr{B}| = 2^{N-2}$} \\\\\n&= 2^{N-2}[\\sum_{n=2}^{N} c{_n}^2 + \\sum_{n=2}^{N-1} \\sum_{j&gt;n}^{N}c_nc_j] && \\text{ QED}\\end{aligned}\\] Plugging the results of the last two lemmas into Lemma-1.3 produces a result of\n\\[\\begin{aligned}\n\\mathbf{Brier}_{\\mathscr{S}}(\\textbf{c},@) &= \\frac{2}{N}[(1-c_1)^2 + 2^{3-N}\\sum_{B \\in \\mathscr{B}}\\mathbf{c}(B)^2 - 2^{3-N}(1-c_1)\\sum_{B \\in \\mathscr{B}}\\mathbf{c}(B)] \\\\\n&= \\frac{2}{N}\\sum_{B \\in \\mathscr{B}}[2^{2-N}(1-c_1)^2 + 2^{3-N}\\mathbf{c}(B)^2 - 2^{3-N}(1-c_1)\\mathbf{c}(B)] \\\\\n&= \\frac{2^{3-N}}{N}\\sum_{B \\in \\mathscr{B}}[(1 - c_1)^2 + 2\\mathbf{c}(B)^2 - 2(1-c_1)\\mathbf{c}(B)]\\end{aligned}\\] Comparing this to (#) we see that it is just \\(\\frac{N}{4}\\) times Brier\\(_\\mathscr{S}(\\mathbf{c},@)\\), as we aimed to prove. QED.\n\nTheorem-2. When inaccuracy over \\(\\mathscr{A}\\) is measured using the Brier score, the least accurate credal states are those which assign credence 1 to some false atom of \\(\\mathscr{A}\\).\n\nProof: As before, suppose that \\(@(s_1) = 1\\), and let c be a credence function that assigns credence 1 to some false atom \\(s_2, s_3,..., s_N\\) of \\(\\mathscr{A}\\). In light of Theorem-1 it suffices to show that \\(\\mathbf{Brier}_\\mathscr{S}(\\mathbf{c}, @) &gt; \\mathbf{Brier}_\\mathscr{S}(\\mathbf{b}, @)\\) where b does not assign credence 1 to any false atom. Start by noting that for any credence function \\(\\pi\\) defined on the atoms of \\(\\mathscr{A}\\) one has\n\\[\\begin{aligned}\n\\mathbf{Brier}_\\mathscr{S}(\\pi,@) &= \\frac{1}{N}[(1-\\pi_1)^2 + \\sum_{n=2}^{N-1}\\pi{_n}^2+ (1-\\sum_{n=1}^{N-1}\\pi{_n})^2] \\\\\n&= \\frac{1}{N}[1 - 2\\pi_1 + \\sum_{n=1}^{N-1}\\pi{_n}^2+ (1-\\sum_{n=1}^{N-1}\\pi{_n})^2]\\end{aligned}\\]\nBut, since each \\(\\pi_n \\in [0, 1]\\) is non-negative, it follows that \\(\\pi_1 \\geq \\pi{_1}^2, \\pi_2 \\geq \\pi{_2}^2, \\dots, \\pi_N \\geq \\pi{_N}^2\\) with the inequality strict in each case unless \\(\\pi_n\\) is either 1 or 0.\nThis means that the sum \\(\\sum_{n=1}^{N-1}\\pi{_n}^2+ (1-\\sum_{n=1}^{N-1}\\pi{_n})^2\\) is less than or equal to 1, with equality if and only if exactly one of the atoms \\(s_n\\) is assigned probability 1 (and the rest have probability zero). As a result, Brier\\(_\\mathscr{S}(\\pi, @) \\leq \\frac{2}{N}(1 - \\pi_1)\\) with equality if and only if exactly one of the atoms \\(s_n\\) is assigned probability 1. So, there are three relevant cases:\nIf \\(\\pi\\) assigns some false atom probability 1, Brier\\(_\\mathscr{S}(\\pi, @) = \\frac{2}{N}\\cdot(1 - 0) = \\frac{2}{N}\\).\nIf \\(\\pi\\) assigns the true atom probability 1, Brier\\(_\\mathscr{S}(\\pi, @) = \\frac{2}{N}\\cdot(1 - 1) = 0\\).\nIf \\(\\pi\\) does not assign any atom probability 1, Brier\\(_\\mathscr{S}(\\pi, @) &lt; \\frac{2}{N}\\cdot(1 - c_1) \\leq \\frac{2}{N}\\).\nSo, since c fits case (i) and b fits case (ii) or (iii) we have the desired result. QED\n\nTheorem-3: Let \\(\\mathscr{A}\\) be an algebra of propositions generated by atoms \\(a_1, ..., a_{2N}\\), where \\(a_1\\) is the truth. Let \\(P\\) and \\(Q\\) be probability functions defined on \\(\\mathscr{A}\\). \\(P\\) assigns all its mass to the first \\(N\\) atoms, so that \\(P(a_1 \\vee \\dots \\vee a_N) = 1\\), and it also assigns some positive probability to \\(a_1\\). \\(Q\\) assigns all its mass to the false atom \\(a_{2N}\\), so that \\(Q(a_{2N}) = 1\\). Then, for any proper score I satisfying Truth-directedness, Extensionality and Negation Symmetry we have \\(\\mathbf{I}(v_1, P) &lt; \\mathbf{I}(v_1, Q)\\) where \\(v_1\\) is the truth-value assignment associated with \\(a_1\\) (i.e., where \\(v_1(X) = 1\\) if and only if \\(a_1\\) entails \\(X\\)).\n\nProof: We can divide the algebra \\(\\mathscr{A}\\) into four quadrants \\[\\begin{aligned}\n\\mathscr{A}^1 &= \\{X \\in \\mathscr{A}: a_1 \\vDash X \\text{ and } a_{2N} \\vDash X\\} \\\\\n\\mathscr{A}^2 &= \\{X \\in \\mathscr{A}: a_1 \\vDash X \\text{ and } a_{2N} \\nvDash X\\} \\\\\n\\mathscr{A}^3 &= \\{X \\in \\mathscr{A}: a_1 \\nvDash X \\text{ and } a_{2N} \\vDash X\\} \\\\\n\\mathscr{A}^4 &= \\{X \\in \\mathscr{A}: a_1 \\nvDash X \\text{ and } a_{2N} \\nvDash X\\}\\end{aligned}\\] We know the following:\n\n\\(Q\\) is maximally accurate on \\(\\mathscr{A}^1 \\cup \\mathscr{A}^4\\). Every proposition in \\(\\mathscr{A}^1\\) is true, and \\(Q\\) assigns it a probability of 1. Every proposition in \\(\\mathscr{A}^4\\) is false, and \\(Q\\) assigns it a probability of 0.\n\\(Q\\) is maximally inaccurate on \\(\\mathscr{A}^2 \\cup \\mathscr{A}^3\\). Every proposition in \\(\\mathscr{A}^2\\) is true, and \\(Q\\) assigns it a probability of 0. Every proposition in \\(\\mathscr{A}^3\\) is false, and \\(Q\\) assigns it a probability of 1.\n\\(P\\) is maximally accurate on \\(\\mathscr{A}^3 \\cup \\mathscr{A}^4\\). Every proposition in \\(\\mathscr{A}^3 \\cup \\mathscr{A}^4\\) is false, and \\(P\\) assigns it a probability of 0.\nEach quadrant has \\(2^{2N-2}\\) elements.\n\n\nLemma-3.1: When \\(a_1\\) is true, the accuracy score of \\(P\\) over the propositions in \\(\\mathscr{A}^1\\) is identical to the accuracy score of \\(P\\) over the propositions in \\(\\mathscr{A}^2\\).\n\nProof: Note first that the function \\(F: \\mathscr{A}^1 \\rightarrow \\mathscr{A}^2\\) that takes \\(X\\) to \\(X \\wedge \\neg a_{2N}\\) is a bijection of \\(\\mathscr{A}^1\\) onto \\(\\mathscr{A}^2\\). Since every proposition in \\(\\mathscr{A}^1 \\cup \\mathscr{A}^2\\) is true, we can then write the respective accuracy scores of \\(\\mathscr{A}^1\\) and \\(\\mathscr{A}^2\\) as \\[\\begin{aligned}\n\\mathbf{I}_{\\mathscr{A}^1}(a_1, P) &= 2^{2-2N} \\cdot \\sum_{X \\in \\mathscr{A}^1} \\mathbf{I}(1, P(X)) \\\\\n\\mathbf{I}_{\\mathscr{A}^2}(a_1, P) &= 2^{2-2N} \\cdot \\sum_{X \\in \\mathscr{A}^1} \\mathbf{I}(1, P(X \\wedge \\neg a_{2N}))\\end{aligned}\\] Note: \\(X\\) ranges over \\(\\mathscr{A}^1\\) in both summations. But since \\(P(a_{2N}) = 0\\) we have \\(P(X) = P(X \\wedge a_{2N})\\) for each \\(X\\) in \\(\\mathscr{A}^1\\). Since I is extensional, this means that \\(\\mathbf{I}(1, P(X)) = \\mathbf{I}(1, P(X \\wedge a_{2N}))\\) for each \\(X\\) in \\(\\mathscr{A}^1\\). And, it follows that \\(\\mathbf{I}_{\\mathscr{A}^1}(a_1, P)\\) and \\(\\mathbf{I}_{\\mathscr{A}^2}(a_1, P)\\) are identical. (Note that even if \\(P(a_{2N}) &gt; 0\\), Truth-directedness entails that \\(\\mathbf{I}_{\\mathscr{A}^1}(a_1, P) &lt; \\mathbf{I}_{\\mathscr{A}^2}(a_1, P)\\).)\n\nLemma-3.2: When \\(a_1\\) is true, the accuracy score of \\(Q\\) over \\(\\mathscr{A}^2\\) is identical to the accuracy score of \\(Q\\) over \\(\\mathscr{A}^3\\).\n\nProof: To see this, note first that the function \\(G: \\mathscr{A}^2 \\rightarrow \\mathscr{A}^3\\) that takes \\(X\\) to \\(G(X) = \\neg X\\) is a bijection (i.e., the negation of everything in \\(\\mathscr{A}^2\\) is in \\(\\mathscr{A}^3\\) and vice-versa). This, together with the fact that \\(\\mathscr{A}^2\\) contains only truths and \\(\\mathscr{A}^3\\) contains only falsehoods, lets us write \\[\\begin{aligned}\n\\mathbf{I}_{\\mathscr{A}^2}(a_1, Q) &= 2^{2-2N} \\cdot \\sum_{X \\in \\mathscr{A}^2} \\mathbf{I}(1, Q(X)) \\\\\n\\mathbf{I}_{\\mathscr{A}^3}(a_1, Q) &= 2^{2-2N} \\cdot \\sum_{X \\in \\mathscr{A}^2} \\mathbf{I}(0, Q(\\neg X))\\end{aligned}\\] But since I is negation symmetric, \\(\\mathbf{I}(1, Q(X)) = \\mathbf{I}(0, Q(\\neg X))\\) for every \\(X\\), which means that \\(\\mathbf{I}_{\\mathscr{A}^2}(a_1, Q) = \\mathbf{I}_{\\mathscr{A}^3}(a_1, Q)\\). (Note that this proof made no assumptions about \\(Q\\) except that it was a probability.)\n\nLemma-3.3: If \\(P(a_1) &gt; 0\\), the accuracy score of \\(P\\) over \\(\\mathscr{A}^2\\) is strictly less than the accuracy score of \\(Q\\) over \\(\\mathscr{A}^2\\).\n\nProof: Since \\(Q(X) = 0\\) everywhere on \\(\\mathscr{A}^2\\) we have \\[\\begin{aligned}\n\\mathbf{I}_{\\mathscr{A}^2}(a_1, P) &= 2^{2-2N} \\cdot \\sum_{X \\in \\mathscr{A}^2} \\mathbf{I}(1, P(X)) \\\\\n\\mathbf{I}_{\\mathscr{A}^2}(a_1, Q) &= 2^{2-2N} \\cdot \\sum_{X \\in \\mathscr{A}^2} \\mathbf{I}(1, 0) \\end{aligned}\\] But, by Truth Directedness \\(\\mathbf{I}(1, 0) &gt; \\mathbf{I}(1, P(X))\\) since \\(P(a_1) &gt; 0\\) implies that \\(P(X) &gt; 0\\) for all \\(X \\in \\mathscr{A}^2\\). Thus \\(\\mathbf{I}_{\\mathscr{A}^2}(a_1, Q) &gt; \\mathbf{I}_{\\mathscr{A}^2}(a_1, P)\\).\nTo complete the proof of the theorem we need only note that \\[\\begin{aligned}\n\\mathbf{I}_{\\mathscr{A}}(a_1, P) &= \\frac{\\mathbf{I}_{\\mathscr{A}^1}(a_1, P)}{4} + \\frac{\\mathbf{I}_{\\mathscr{A}^2}(a_1, P)}{4} &\\text{(since }P\\text{ is perfect on }\\mathscr{A}^3 \\cup \\mathscr{A}^4) \\\\\n&= \\frac{\\mathbf{I}_{\\mathscr{A}^2}(a_1, P)}{2} &\\text{Lemma-3.1} \\\\\n&&lt; \\frac{\\mathbf{I}_{\\mathscr{A}^2}(a_1, Q)}{2} &\\text{Lemma-3.3} \\\\\n&= \\frac{\\mathbf{I}_{\\mathscr{A}^2}(a_1, Q)}{4} + \\frac{\\mathbf{I}_{\\mathscr{A}^3}(a_1, Q)}{4} &\\text{Lemma-3.2} \\\\\n&= \\mathbf{I}_{\\mathscr{A}}(a_1, Q) &\\text{(since }Q\\text{ is perfect on }\\mathscr{A}^1 \\cup \\mathscr{A}^4)\\end{aligned}\\]\n\n\n\n\n\n\nReferences\n\nBerker, Selim. 2013a. “Epistemic Teleology and the Separateness of Propositions.” Philosophical Review 122 (3): 337–93. https://doi.org/10.1215/00318108-2087645.\n\n\n———. 2013b. “The Rejection of Epistemic Consequentialism.” Philosophical Issues 23 (1): 363–87. https://doi.org/10.1111/phis.12019.\n\n\nDescartes, René. 1641/1996. Meditations on First Philosophy, Tr. John Cottingham. Cambridge: Cambridge University Press.\n\n\nGreaves, Hilary. 2013. “Epistemic Decision Theory.” Mind 122 (488): 915–52. https://doi.org/10.1093/mind/fzt090.\n\n\nHammond, Peter J. 1988. “Consequentialist Foundations for Expected Utility.” Theory and Decision 25 (1): 25–78. https://doi.org/10.1007/BF00129168.\n\n\nJenkins, C. S. 2007. “Entitlement and Rationality.” Synthese 157 (1): 25–45. https://doi.org/10.1007/s11229-006-0012-2.\n\n\nJoyce, James M. 1998. “A Non-Pragmatic Vindication of Probabilism.” Philosophy of Science 65 (4): 575–603. https://doi.org/10.1086/392661.\n\n\nMaher, Patrick. 1997. “Depragmatised Dutch Book Arguments.” Philosophy of Science 64 (2): 291–305. https://doi.org/10.1086/392552.\n\n\nRoulston, Mark S. 2007. “Performance Targets and the Brier Score.” Meterological Applications 14: 185–94. https://doi.org/10.1002/met.21.\n\n\nShafer, Glenn. 1976. A Mathematical Theory of Evidence. Princeton: Princeton University Press.\n\n\nWeatherson, Brian. 1999. “Begging the Question and Bayesians.” Studies in the History and Philosophy of Science Part A 30: 687–97."
  },
  {
    "objectID": "posts/epvn/index.html",
    "href": "posts/epvn/index.html",
    "title": "Epistemicism, Parasites, and Vague Names",
    "section": "",
    "text": "Why is it so implausible that there is a sharp boundary between the rich and the non-rich? Perhaps we find it implausible merely because we (implicitly) believe that if there were such a boundary we would be able to discover where it is. If this is so we should revise our judgements. As Timothy Williamson (1994, 2000) has shown, if there were such a boundary we would not know where it is. Still, this is not the only reason for being sceptical about the existence of such a boundary. In “Vagueness, Epistemicism and Response-Dependence” John Burgess (2001) outlines an impressive objection to the existence of such boundaries, and in particular to epistemicist theories that posit their existence. Burgess’s objection is based not on principles about the epistemology of content, as the bad objection just stated is, but rather on principles about the metaphysics of content.\n\nPublished in Australasian Journal of Philosophy 81: 276-279.\nPicture by Pacific Klaus via Creative Commons.\n\nIf a word t has content c, this must be the case in virtue of some more primitive fact obtaining. Facts about content, such as this, are not among the fundamental constituents of reality. Roughly, facts about linguistic content must obtain in virtue of facts about use. But there are simply not enough facts about use to determine a precise meaning for paradigmatically vague terms like ‘rich’. Any theory that holds that ‘rich’ does have a precise meaning must meet this objection. As Burgess argues, Williamson’s attempts to do this have not been entirely successful. Burgess argues, persuasively, that epistemicists owe us a theory of how terms like ‘rich’ get to have the precise meaning they apparently have given that the facts about use do not seem to generate a precise meaning. He also argues, less persuasively, that Williamson’s ‘parasitic’ strategy for meeting this obligation is unsuccessful. Indeed, the argument here rests at one point on a premiss that is clearly false. I will suggest a way to patch the argument and reinstate the objection to epistemicism.\nThe obligation to provide a theory that generates content in terms of use does not just fall on the epistemicists. We indeterminists about content must also discharge it. Assume that we have done so, and we have a theory of content that divides sentences into (at least) the true, the false and the indeterminate. (Williamson 1994, 207–8) argues that the only reason we believe that any sentences fall into this third category is that we are respecting a mythical symmetry between truth and falsity. We are falling into the trap of thinking that if a sentence is not somehow made false, it is not false. The true story is that if an assertoric sentence has content, and it is not made true, it isfalse. This provides the basis for Williamson’s ‘parasitic’ strategy: wait for the indeterminist to offer a theory of when sentences are true, accept that part of the indeterminist theory, and say all other sentences that express propositions are false. If the strategy works, then there is no way the indeterminist can meet the obligation to provide a theory of content without the epistemicist also being able to do so, so there is no argument for indeterminism here. (There are complications, to put it mildly, with this strategy when the indeterminist allows the border between the true and the indeterminate to be vague. Burgess lets these potential problems slide, and so shall I.)\nThe strategy rests on the purported asymmetry between truth and falsity. Burgess claims that positing such an asymmetry makes epistemicism inconsistent. Consider a colour patch that is around the border between red and orange. Burgess claims, correctly, that an indeterminist theory of content may say that (1) and (2) are indeterminate, and hence Williamson might be committed to the position that (1) and (2) are false, and hence so is (3).\n\nThat patch is red.\nThat patch is orange.\nThat patch is either red or orange.\n\nBut this is hopeless because “on the epistemicist view, there is a sharp boundary in the series between red and orange; every patch is either one or the other.” (Burgess 2001, 519) This last claim is false. According to epistemicism, there is a sharp boundary between red and not red, so the patch is either red or not red. But the epistemicist need not hold that if the patch is not red, then it is orange. It is consistent with epistemicism that there are colours strictly between red and orange, just as it is consistent with epistemicism that there are colours strictly between red and yellow, and just as it is consistent with epistemicism that there are colours strictly between red and blue. Hence it is possible that the colour of this patch is strictly between red and orange, and thus is neither red nor orange. So this line of reasoning does not work. Perhaps the argument can be easily fixed. According to the indeterminist, both (1) and (4) are indeterminate. Hence according to Williamson’s ‘parasitic’ theory of content, both (1) and (4) are false, so (5) is false.\n\nThat patch is red.\nThat patch is not red.\nThat patch is either red or not red.\n\nThis is more like a problem, because Williamson certainly is committed to the truth of (5). However, it is easy to see how Williamson should respond. The theory of content sketched above (or more precisely, the strategy for converting indeterminist theories to determinist ones) was only meant to apply to simple sentences. A simple sentence is true iff the indeterminist says it is true. The truth value of compound sentences, like (4) and (5), is given by a standard Davidsonian theory of truth. Hence (1) is false and (4) is true, as required.\nThe best way to resurrect Burgess’s argument is to shift our attention from vague predicates to vague names. Consider any mountain, say Kilimanjaro. It is vague just where the mountain starts, so it will be vague just which atoms constitute Kilimanjaro. Kilimanjaro is some fusion of atoms or other, but it is indeterminate just which one it is. Some of these fusions have different masses, and some have different shapes, so no sentence of the form of (6) or of (7) will be true according to the indeterminist.\n\nKilimanjaro has shape s.\nKilimanjaro has mass m.\n\nHence according to the Williamson’s asymmetric theory of truth, any sentence of either of these forms is false. Note that this holds even if we restrict the application of his theory to simple sentences. Now let K be a set of fusions of atoms {f1, f2, …, fn} such that it is determinate that Kilimanjaro is one of these fusions. (Because of higher-order vagueness it may be impossible to find such a set that does not contain any fusion that is determinately not Kilimanjaro. That will not matter; all that we require is that Kilimanjaro is one of these fusions.) Let si be the shape of fi and mi its mass. Then for all i, (6.i) and (7.i) are false, as we just argued.\n\n\nKilimanjaro has shape si.\n\n\nKilimanjaro has mass mi.\n\n\nHence both (8) and (9) are false.\n\nKilimanjaro has shape s1 or Kilimanjaro has shape s2 or … or Kilimanjaro has shape sn.\nKilimanjaro has mass m1 or Kilimanjaro has mass m2 or … or Kilimanjaro has mass mn.\n\nAnd the epistemicist is committed to (8) and (9) being true. We may not be able to discover which disjunct is true, but that is no reason to think that the disjunction is not true. Burgess’s argument was that if we adopt Williamson’s advice for constructing a theory of content, we will misclassify sentences that express penumbral connections. He was basically right, but we need to use a different example to prove it.\nI assumed above that Kilimanjaro is a fusion of atoms. Some may object to this on the grounds that Kilimanjaro has different temporal and modal properties to any fusion of atoms. I doubt such objections ultimately work, but for present purposes the important thing to note is that the argument can go through without such an assumption. Even if Kilimanjaro is not identical to any fusion in K, it is clear that Kilimanjaro (actually, now) exactly overlaps some member of K. And since Kilimanjaro has the same (actual, present) shape and mass as any fusion of atoms it exactly overlaps, it still follows that (8) and (9) are true.\nIf we do assume that Kilimanjaro is one of the fusions, then we can generate another case where Williamson’s theory generates false predictions. Since at most one of the fusions is a mountain, it follows that (10.i) is indeterminate for all i on an indeterminist theory of content, and hence false according to Williamson.\n\n\nfi is a mountain.\n\n\nHence his theory mistakenly predicts that (11) is false, when it is by hypothesis true.\n\nf1 is a mountain or f2 is a mountain or … or fn is a mountain.\n\nThis argument does rest on a contentious bit of metaphysics, but it still seems basically sound.\nI did not assume at any point that Kilimanjaro is a vague object. I did assume that ‘Kilimanjaro’ is a vague name, but it is consistent with the argument I have presented that there are no vague objects, and the vagueness in ‘Kilimanjaro’ consists in it being indeterminate which precise object it denotes.\nAs Burgess demonstrates, it is fair to require that the epistemicist provide a theory of how terms get the precise content they do. Williamson attempted to show he was in just as good a position to discharge this obligation as the indeterminist by providing an algorithm for converting any indeterminist theory of content into one acceptable to the epistemicist. Burgess argued that the algorithm produced unacceptable results when we applied it to vague sentences such as (1) and (2). This particular argument is no good; the algorithm does not seem to produce implausible results in that case. We can make this form of argument work, however, especially if we focus on vague names. Applying the algorithm to any plausible indeterminist theory produces the result that every disjunct in (8) and (9) are false, and hence that these disjunctions are false. Since the epistemicist is (correctly) committed to these sentences being true, Burgess was correct to conclude that “this particular attempt to implement the parasite strategy is doomed to failure.”\n\n\n\n\nReferences\n\nBurgess, John. 2001. “Vagueness, Epistemicism and Response-Dependence.” Australasian Journal of Philosophy 79 (4): 507–24. https://doi.org/10.1080/713659306.\n\n\nWilliamson, Timothy. 1994. Vagueness. Routledge.\n\n\n———. 2000. Knowledge and its Limits. Oxford University Press."
  },
  {
    "objectID": "posts/review-keefe/index.html",
    "href": "posts/review-keefe/index.html",
    "title": "Review of “Theories of Vagueness”",
    "section": "",
    "text": "Many philosophers, I suspect, are partial to supervaluational theories of vagueness. And with good reason. Its rivals all seem to promise metaphysical mysteries concerning hitherto unnoticed, and perhaps unnoticeable, sharp boundaries around our concepts, or radical revision in our logical practices. And not only have philosophers been so tempted. The texts are a little unclear, but it seems several economists can be read as adopting supervaluational solutions to the difficulties raised by vagueness in economic concepts. Given its popularity, and plausibility, supervaluationism deserves a book-length defence. Yet this is the first such book in the philosophical canon.\n\nPublished in Philosophy and Phenomenological Research 67: 491-4.\n\nAnd it is a fine defence of supervaluationism, though I doubt it is entirely successful. I ended up, a little contrariwise, feeling less convinced in the hegemony of supervaluational approaches than I was when I started. In part this was because Keefe was so clear in setting out where some rival approaches, especially degree-based approaches, failed that I felt she had inadvertently pointed out where her opponents should move next. Keefe’s positive theory is fairly familiar, though she often marshalls new arguments for it, so this review will not dwell on exposition but concentrate on Keefe’s arguments.\nThe book effectively divides into three parts. The first two chapters involve some scene-setting, and a discussion of the various methodological principles adopted. The next four chapters are attacks on non-supervaluational theories. And the final two chapters defend Keefe’s preferred version of supervaluationism. Starting with methodology seemed to be a good idea, but the discussion didn’t break much new ground. It turns out, surprisingly enough, that reflective equilibrium is useful in theorising about vagueness too.\nThe first rival theory to be examined is epistemicism, and Keefe presents two main arguments. One of these is fairly familiar, epistemicists have no theory about how predicates get the particular precise extensions that they do. This is true, but then supervaluationists aren’t exactly flush with theories about how predicates get the particular imprecise extensions that they do either. The other criticism is more interesting. Epistemicism posits a sharp boundary between the tall and not-tall, but we don’t know where this boundary is. It is a mystery why we do not have this knowledge, one that epistemicists try to solve by showing we could not know where the boundary is. But there are other mysteries too. For some reason, we don’t try to find out where the boundary is, and we don’t have beliefs about where it is. That we couldn’t get this kind of knowledge doesn’t explain these omissions. Like Hobbes trying to square the circle, we all try impossible things sometimes. So epistemicism has more explaining to do than it has hitherto done.\nKeefe spends two chapters attacking theories based on degrees of truth. There are several related objections raised to these theories, but fundamentally they all boil down to the problem of false precision. If there is no fact of the matter as to whether Kylie is happy is true or not, then there is no fact of the matter as to whether it is true to degree 0.314. The most natural formulation of degree theories assumes there are facts of this latter form. More complicated formulations are either incoherent or incomplete. Keefe is good at working through the various moves that have been attempted to avoid this problem, and showing that none of them work. But at times she seemed too content to refute theories that had appeared in the literature, rather than anticipating future challengers. One particular challenge seemed particularly worthy of consideration. At one point Keefe introduces a new connective \\(≥_T\\) to mean true to the same or a greater degree. She notes that most extant degree theorists are committed to a connectedness principle for \\(≥_T\\): either \\(p ≥_T q\\) or \\(q ≥_T p\\). But this principle is implausible given their other commitments. At this point it seemed relevant to wonder how well a theory that dropped all talk of degrees of truth and just took this connective \\(≥_T\\) as primitive could avoid Keefe’s objections. Indeed, at the equivalent point in his discussion in Vagueness, Timothy Williamson considers some arguments against just this position, but his discussion is rather brief. One can’t reply to every possible response, but this one seemed so apposite, I would have liked to see Keefe’s response to it.\nKeefe holds that a sentence is true iff it is true on all admissible precisifications, i.e. that truth is supertruth. She says little about what makes a precisification acceptable, except that it must respect penumbral connections, and that admissibility is a vague matter. One consequence of this is that schema (T): S is true iff S is not always true. Keefe suggests that the standard arguments for (T) are circular, because they assume that there are no truth-value gaps. And, following van Fraassen, she notes something similar to (T) is true, and this is good enough.\nShe holds that an argument is valid iff it preserves truth, i.e. supertruth. Hence we have S \\(\\dashv \\vdash\\) S is true.This interderivability might explain why we, mistakenly, think (T) is true. There is a familiar problem with this move, one stressed by Williamson. On all precisifications, all theorems of classical logic are true, so these all end up being true. So to that extent supervaluationism preserves classical logic. But not all admissible inference rules of classical logic preserve supertruth. In particular, the deduction theorem is no longer admissible. We can’t infer (2) from (1):\n\nS \\(\\vdash\\) S is true.\n\\(\\vdash\\) S ⊃ S is true.\n\nKeefe responds by noting that something similar to the deduction theorem is true, and this might explain our mistaken attachment to it. Keefe assumes the language contains an operator D, read ‘definitely’, such that DA means A is supertrue. Then the following rule is admissible:\n\n⊃I*\n\nFrom A,B \\(\\vdash\\) C, infer B \\(\\vdash\\) DA ⊃ C\n\n\nWe think the standard ⊃ introduction rule, the deduction theorem, is acceptable because we mistake it for this one. Keefe notes we can set out similar kinds of rules for argument by cases (∨-elimination) and reductio ad absurdum (¬-introduction). These are intended to be small deviations from classical logic, but they strip the proof theory of much of its power. Keefe’s rules are insufficient to prove p ⊃ r \\(\\vdash\\) (p ∧ q) ⊃ r, or p ⊃ p. One might question the value of inference rules with such little power.\nThere is little on the specific problems associated with the problem of the many for supervaluationism. Stephen Schiffer1 recently proposed a variant on the problem, suggesting that the standard supervaluational solution misclassifies some speech reports. Keefe replies that Schiffer’s argument doesn’t seem to go through if we adopt Davidson’s paratactic theory of speech reports. Well, maybe it doesn’t, but if supervaluationism requires the paratactic theory of speech reports, that seems highly relevant to its ultimate success, but Keefe merely assigns it a footnote.\n1 “Two Issues of Vagueness” Monist 81: 193-214.There is a little more on the most obvious difficulty for supervaluationism, that it verifies some strange existentials. Consider a Sorites series of objects arranged with respect to F-ness, each a little more F than its predecessor, with the extremes being clearly F and not-F respectively. Then the sentence There is a pair of adjacent objects such that one is F and the other is not is supertrue. Keefe notes that we can distinguish here between the truth of the existential and the truth of an instance. And she notes that pragmatic theories due to Fine and Tappenden might explain our unwillingness to assert the existential, even if it is true. Still, it is would have been nice to see some discussion on whether this is a particular problem when F is a phenomenal predicate, or when it is ‘ineradicably vague’, as Dummett and other think predicates like ‘sort of nearby’ are.\nThe major innovation in the book is its treatment of higher-order vagueness. Keefe notes the following argument raises a serious difficulty for supervaluationism here\n\nAccording to the theory, a sentence is true simpliciter iff it is true on all complete and admissible specifications [i.e. on all precisifications]. But for any sentence, either it is true on all complete and admissible specifications (hence true simpliciter) or not (hence borderline or false). So there is no scope for avoiding sharp boundaries to the borderline cases or for accommodating borderline borderline cases. (202)\n\nKeefe’s response is to claim that the argument assumes, falsely, that there is “a precise and unique set of complete and admissible specifications.” (202) Keefe denies this and instead develops a theory of higher-order vagueness based on supervaluating the concept of admissibility. But it is not clear where the argument does assume this. After all, the argument makes no mention of sets. And it is a little unclear just why this assumption should be false. Keefe argues that there is no such set because complete and admissible specification is vague, just as there is no precise and unique set of tall things because tall is vague. But even though complete and admissible specification is vague, on every precisification there is still a unique set of complete and admissible specifications, so it is true that there is such a set, so there is one. (Keefe accepts the S is true therefore S direction of (T).)\nIt is also unclear how the vagueness of the term complete and admissible specification is relevant. The supervaluational idea was that a sentence is true iff it is true on all specifications (precisifications) that are complete and admissible, not iff it is true on all specifications satisfying the term complete and admissible. It is a use/mention confusion to hold the latter view. But if the former is correct, the vagueness of any term, even ‘admissible’, is irrelevant to the above argument. So there still seems to be work to do on higher-order vagueness.\nI’ve focussed on the negatives here, but this shouldn’t overshadow how many good parts this book has. The coverage of the literature is peerless, the writing is always crisp and clear, and in many places Keefe’s arguments move the debate in interesting new directions. It would be a great book to teach from, and indeed I would already be doing so, if only it were available in paperback. I do hope the publishers correct this problem shortly."
  },
  {
    "objectID": "posts/nine-obj/index.html",
    "href": "posts/nine-obj/index.html",
    "title": "Nine Objections to Steiner and Wolff on Land Disputes",
    "section": "",
    "text": "In the July 2003 Analysis, Hillel Steiner and Jonathan Wolff (2003) propose a framework for “resolving disputed land claims between competing nations or ethnic groups.” The idea is that we should auction off the land, with the loser of the auction getting the money. While this might mean that the richer party will normally end up with the land, and this is normally not thought to be a good thing, if the auction is conducted as they specify “it will turn out that the other party ends up with something which, in the circumstances, it prefers to the land: lots of money.”\n\nPublished in Analysis 63: 321-327.\nPicture by Mustang Joe via Creative Commons.\n\nActually, it isn’t so clear that this is what will result. Let’s say we have a particular parcel of land that groups A and B want. They each want it quite strongly, but B has deeper pockets than A, so while A would be prepared to pay 8 for the land, B would be prepared to pay 12. For the auction process to function, there must be a minimum bid increment, I’ll say it is \\(\\frac{1}{2}\\). Assume that B has just bid 4, A must now choose whether to bid 4\\(\\frac{1}{2}\\) or accept B’s bid. And assume for now that A is not bidding tactically, it only makes a bid if it would prefer to win the auction with that bid than accept B’s bid. This assumption will be relaxed below.\nSo for now, A must decide whether it prefers to be given 4, or to get the land for 4\\(\\frac{1}{2}\\). Since it values the land at 8, and since it will give up 8\\(\\frac{1}{2}\\) to buy the land (the 4\\(\\frac{1}{2}\\) it will pay, plus the 4 it would have received from B) it may well decide to just accept the bid. But now it has ended up with something it definitely does not prefer to the land, since it just accepted a bid for 4. There are two assumptions at play here. One is that A doesn’t bid tactically, which I shall return to a bit. The other is that how much A will pay for the land is not affected by receiving B’s 4. That is, I assume that the marginal utility of money is relatively constant for A over the ranges of money at play in the auction. This assumption might be false if we’re dealing with a very large or valuable body of land, but it’s not unreasonable in most circumstances. (Space prevents a complete study of what happens if we take the declining marginal utility of money completely into account. Roughly, the effect is that some of my criticisms are slightly vitiated.) Now while these assumptions might be false, Steiner and Wolff give us no reason to be certain they are false. So for all they’ve said we could have a situation just like this one, where the poorer party ends up with something it wants much less than the land. Hence\n\nObjection 1. There is no guarantee that the losing party will end up with something they prefer to the land.\n\nWhile this contradicts an alleged benefit of Steiner and Wolff’s plan, it might not be thought to be a deep problem. After all, A gets half as much as they wanted, and if they are only one of two equal claimants to the land, then this is a fair result. This may be true, but note that the assumption that each party has an equal claim to the land is doing a lot of work here. If A’s claim is stronger, then only getting half of the value of the land is quite unfair. If the two claims are incommensurable, there may be no fact of the matter whether it is fair that A receives 4. If we cannot tell which of the moral claims is stronger, which is very often the case in land disputes, it may be impossible to tell whether A’s receiving 4 is fair or not. Hence\n\nObjection 2. The proposal is only appropriate where each party has a genuinely equal moral claim to the land. This doesn’t happen often, and it is quite rare that we know it happens.\n\nWhile Steiner and Wolff note that they are leaving questions about enforcement and compliance to another place, so it isn’t fair to press them too strongly on these topics, it is worth noting how this feature of their proposal makes compliance harder to enforce. If by participating in the auction both parties are tacitly agreeing that the other party has an equal claim to the land, and I think the above suggests they are doing just this, that will reduce the legitimacy of the auction process in the eyes of members of the losing group. And that will lead to enforcement difficulties down the line.\nThere is an administrative problem lurking around here. Since each party will end up with something from this process once the auction begins, we must have a way of determining whether the competing claims warrant an auction, or whether one party should receive the land, or whether some kind of negotiation is possible. And once we set up a process to do that, it could easily encourage relatively spurious land claims. Unless there is a serious cost to suggesting that one should be party to an auction of some block of land, there is a large incentive to get into these auctions wherever and whenever possible. Perhaps some method could be designed to offset this incentive, and perhaps even the desire groups have to be approved by the court of public opinion will offset it at times, but it seems to be a problem with the proposal as formulated.\nTo be sure, if A accepts B’s bid, then both parties do end up with something from the auction. A gets 4, and B gets some land that it values at 12 for 4, a gain of 8. Note that B does much better out of the auction than A. If the auction stops when the richer party makes a bid at or above half the price the poorer party would pay, then the richer party will always end up with a higher ‘utility surplus’. Hence\n\nObjection 3. If there’s no tactical bidding the utility surplus is given entirely to the richer party.\n\nLet’s relax the assumption that A does not bid tactically. Indeed, let’s make things as good as could be realistically expected for A. It knows that B values the land at 12 and does not bid tactically, so B will make bids up to 6, and accept any bid over 6. Hence the auction proceeds as follows: A bids 4\\(\\frac{1}{2}\\), B bids 5, A bids 5\\(\\frac{1}{2}\\), B bids 6, A accepts. Now things could go better for A, but it would require some luck and courage. A could bid 6\\(\\frac{1}{2}\\) and B could reply with a bid of 7, but since this requires B acting against its own interests (it is better off accepting the bid of 6\\(\\frac{1}{2}\\) after all), and hence also requires A making a risky move that will only yield dividends only if B acts against its own interests in just this way, such an outcome seems unlikely. So in practice the best case scenario for A is that B pays 6 for the land. In this case A ends up with 6, and B ends up paying 6 for land it values at 12, a gain of 6. Hence\n\nObjection 4. Among the realistic outcomes, the best case scenario for the poorer party is that it ends up with as large a utility surplus as the richer party.\n\nBest cases don’t often happen, so in practice we should normally expect a result somewhere between the ‘no tactical bargaining’ option, where B receives a larger share of the surplus, and this ‘best case scenario’ where the two parties get an equal share of the surplus. Hence in almost all cases, the richer party will get a larger surplus than the poorer party. This seems like a flaw in the proposal, but worse is to come. Most of the ways in which B can realistically increase its share of the surplus involve behaviour that we should not want to encourage.\nConsider again A’s decision to reject the bid of 5 and bid 5\\(\\frac{1}{2}\\). Assume, for simplicity, that A plans to accept a bid of 6, but drop the assumption that A knows that B will reject a bid of 5\\(\\frac{1}{2}\\), if it is made. So before A makes its decision, there are three possible outcomes it faces:\nIn this case it receives 5.\nIn this case it gets the land (value 8) for 5\\(\\frac{1}{2}\\), net gain 2\\(\\frac{1}{2}\\).\nIn this case B bids 6, and A accepts, so it gets 6.\nA’s expected utility is higher if it bids 5\\(\\frac{1}{2}\\) rather than accepts B’s bid iff its degree of belief that B will bid 6 is over \\(\\frac{5}{7}\\). If it is less confident than that that B will bid 6, it should accept the bid of 5. As it happens, B is going to reject a bid of 5\\(\\frac{1}{2}\\) and bid 6, so it is better off if A accepts the bid of 5. If A knows B’s plans, this will not happen. But if A is ignorant of B’s intentions, it is possible it will accept the bid of 5. Indeed, since A’s confidence that B will decline must be as high as \\(\\frac{5}{7}\\) before it makes the bid of 5\\(\\frac{1}{2}\\), it might be quite likely in this case that A will just accept the bid.\nNot surprisingly, we get the result that B is better off if its bargaining plans are kept secret than if they are revealed to A. That in itself may not be objectionable. But remember that the agents here are not individuals, they are states. And the decisions about how to bid involve policy questions that will often be the most important issue the state in question faces for many a year. Ideally, decisions about how to approach the auction should be decided as democratically as possible. But democratic decision making requires openness, and it is impossible that all the stakeholders in B, including one imagines the citizens, can participate in the decision about how to approach the auction without B tipping its hand. In the modern world it’s impossible to involve everyone in B without opening the debate to agents of A. And this, as we’ve seen, probably has costs. Since B is better off if it does not make decisions about how to approach the auction in the open, we have\n\nObjection 5. The proposal favours secretive governments over open democratic governments.\n\nAssume that B has been somewhat secretive, but A is still fairly confident that B will not accept a bid of 5\\(\\frac{1}{2}\\). Its degree of belief that such a bid will be rejected is \\(\\frac{3}{4}\\), let’s say, so it is disposed to gamble and make that bid. But now B starts making some noises about what it will do with any money it gets from A. The primary beneficiary of this windfall will be B’s military. And the primary use of this military is to engage in military conflicts with A. While some of these engagements will be defensive, if A gets the land under dispute many will be offensive. (I don’t think these assumptions are particularly fanciful in many of the land disputes we see in the modern world.) A must take this into account when making its decisions. It seems reasonable to say that every 1 that A gives B has a disutility of 1.2 for A, 1 for the cost of the money it gives up, and 0.2 for the extra damage it may suffer when that money is turned into weaponry turned back against A. Now the utility calculations are quite different. If B accepts A’s bid of 5\\(\\frac{1}{2}\\), A’s balance sheet will look like this:\nThe land, value 8.\n5\\(\\frac{1}{2}\\) paid to B, value 5\\(\\frac{1}{2}\\)\nB’s extra military capability, value (a little over) 1.\nRoughly 1\\(\\frac{1}{2}\\).\nSo now the expected utility of bidding 5\\(\\frac{1}{2}\\) is:\n\nProb(Bid Accepted) Utility(Bid Accepted) + Prob(Bid Rejected) Utility(Bid Rejected)\n\\(\\approx \\frac{1}{4} \\times 1\\frac{1}{2} + \\frac{3}{4} \\times 6\\)\n= \\(4\\frac{7}{8}\\)\n\nHence A’s expected utility for accepting B’s bid of 5, i.e. 5, is higher than its expected utility of bidding 5\\(\\frac{1}{2}\\), so it will accept the bid, just as B wanted it to do. So if B indicates that it will use any payments from A to attack A, it may well be able to get the land for less. Hence\n\nObjection 6. The proposal favours belligerent governments over peaceful governments.\n\nOne qualification to this objection is that what matters here is what A thinks B will do, not what B actually does. So the objection is not that the proposal rewards offensive behaviour, but that it rewards belligerence, or indications of offensive behaviour. This isn’t as bad as rewarding military action, but it is still objectionable.\nThroughout I have used a particular example to make the points clearer, none of the arguments turns on the details of this example. What matters is that in any case where one party is able to spend more for the land in question simply because they are richer, the richer party will almost inevitably have a higher utility surplus, and this party can increase their expected utility surplus by being more secretive about their plans, and by being adopting a more belligerent tone towards their rivals before and during the auction. So it seems the proposal systematically rewards behaviour we should be discouraging.\nThe remaining objections concern the implementation of Steiner and Wolff’s proposal. While I don’t have a demonstrative proof that any of these concerns present insurmountable difficulties, they all suggest ways in which the proposal must be qualified if it is to be just.\nThe proposal seems to assume that the parties to the dispute agree over whether the land in question can be divided. As Steiner and Wolff put it, “The auction can thus be viewed as a device for achieving a fair settlement for the disposition of a good when neither division nor joint ownership is acceptable to the parties.” In some conflicts at least part of what is at issue is whether the land can be divided. For instance, if we were applying this proposal as a way of settling the war between Britain and Ireland in 1921, would we say that all of Ireland should be auctioned off, or just that the six counties that became Northern Ireland should be auctioned? Assuming the British had decided that governing southern Ireland had become too much trouble and were only interested in retaining the north, they may not have wanted to pay for the whole country just to protect their interests in the north. But at least some of the Irish would have been unwilling to accept a process that may have led to the division of the country, as would have obtained had the south been granted Home Rule, but the north left subject to an auction. (The historical facts are, obviously, somewhat more complicated than I’ve sketched here, but even when those complications are considered the difficulties that must be overcome before we know how to apply the proposal to a real situation are formidable.) Hence\n\nObjection 7. The proposal assumes a mechanism for determining which land is indivisible, and in some cases developing such a process is no easier than settling the dispute.\n\nSteiner and Wolff assume that the groups, A and B, are easily identifiable. In practice, this may not be so easy. For example, at least some people in Scotland would prefer that Scotland was independent. For now most people prefer devolution to independence (and some would prefer rule from Westminster) but we can easily imagine circumstances in which the nationalist support would rise to a level where it became almost a majority. If a majority in Scotland wants to secede, and the British government is willing to do this, then presumably they will just secede. But what are we to do if a narrow majority in Scotland wants to secede, and the British government (or people) do not want them to go? Presumably Steiner and Wolff’s proposal is that some sort of auction should be held to determine who should be in charge of the land. But who exactly are meant to be the parties? On the Westminster side, is the party Britain as a whole, or Britain except for Scotland? On the Scottish side, is it the Scottish people? The Scottish government, which for now is a creature that exists at the pleasure of the British Parliament? Those people who support Scottish independence? If the last, how shall we determine just who these people are? Perhaps some one or other of these answers can be defended, but the proposal is seriously incomplete, hence\n\nObjection 8. There is no mechanism for determining who shall count as a member of the groups in question.\n\nFinally, the proposal simply assumes that we can agree upon the currency in which the auction shall be conducted, but it is not ever so clear that this can be done. Usually, the two parties to a dispute will use different currencies, so to avoid conflicts it would be best if the auction were conducted in a neutral currency. But finding such a currency may be non-trivial. There are only a handful of currencies in the world whose supply is sufficiently abundant to conduct an auction of this size, and most of the time those currencies will be backed by governments who favour one side in the dispute. If they use this favouritism to provide access to credit denominated in their currency at a discounted rate, that threatens the fairness of the auction. Hence\n\nObjection 9. The proposal assumes a given currency in which to conduct the auction, but in practice any choice of currency may favour one side.\n\nThe last three objections are, as mentioned, somewhat administrative. It is possible that in a particular situation they could be overcome, though I think that it is more likely that they would pose serious difficulties to a would-be auction-wielding pacifier. But that’s not the serious problem with the proposal. The real problem, as the first six objections show, is that it favours rich, secretive, belligerent states that are disposed to make spurious land claims over poor, democratic, pacifist states that only make genuine land claims.\n\n\n\n\nReferences\n\nSteiner, Hillel, and Jonathan Wolff. 2003. “A General Framework for Resolving Disputed Land Claims.” Analysis 63 (3): 188–89. https://doi.org/10.1093/analys/63.3.188."
  },
  {
    "objectID": "posts/idakd/index.html",
    "href": "posts/idakd/index.html",
    "title": "In Defense of a Kripkean Dogma",
    "section": "",
    "text": "In “Against Arguments from Reference” (Mallon et al. 2009), Ron Mallon, Edouard Machery, Shaun Nichols, and Stephen Stich (hereafter, MMNS) argue that recent experiments concerning reference undermine various philosophical arguments that presuppose the correctness of the causal-historical theory of reference. We will argue three things in reply. First, the experiments in question—concerning Kripke’s Gödel/Schmidt example—don’t really speak to the dispute between descriptivism and the causal-historical theory; though the two theories are empirically testable, we need to look at quite different data than MMNS do to decide between them. Second, the Gödel/Schmidt example plays a different, and much smaller, role in Kripke’s argument for the causal-historical theory than MMNS assume. Finally, and relatedly, even if Kripke is wrong about the Gödel/Schmidt example—indeed, even if the causal-historical theory is not the correct theory of names for some human languages—that does not, contrary to MMNS’s claim, undermine uses of the causal-historical theory in philosophical research projects.\n\nPublished in Philosophy and Phenomenological Research 85: 56-68.\n\n\n0.1 Experiments and Reference\nMMNS start with some by now famous experiments concerning reference and mistaken identity. The one they focus on, and which we’ll focus on too, is a variant of Kripke’s Gödel/Schmidt example. Here is the question they gave to subjects.\n\nSuppose that John has learned in college that Gödel is the man who proved an important mathematical theorem, called the incompleteness of arithmetic. John is quite good at mathematics and he can give an accurate statement of the incompleteness theorem, which he attributes to Gödel as the discoverer. But this is the only thing that he has heard about Gödel. Now suppose that Gödel was not the author of this theorem. A man called “Schmidt” whose body was found in Vienna under mysterious circumstances many years ago, actually did the work in question. His friend Gödel somehow got hold of the manuscript and claimed credit for the work, which was thereafter attributed to Gödel. Thus he has been known as the man who proved the incompleteness of arithmetic. Most people who have heard the name ‘Gödel’ are like John; the claim that Gödel discovered the incompleteness theorem is the only thing they have ever heard about Gödel. When John uses the name ‘Gödel,’ is he talking about:\n\nthe person who really discovered the incompleteness of arithmetic? or\nthe person who got hold of the manuscript and claimed credit for the work? (MMNS 2009: 341)\n\n\nThe striking result is that while a majority of American subjects answer (B), consistently with Kripke’s causal-historical theory of names, the majority of Chinese subjects answer (A).1 To the extent that Kripke’s theory is motivated by the universality of intuitions in favour of his theory in cases like this one, Kripke’s theory is undermined.\n1 Note that a causal descriptivist about names will also say that the correct answer to this question is (B). So the experiment isn’t really testing descriptivism as such versus Kripke’s causal-historical theory, but some particular versions of descriptivism against Kripke’s theory. These versions of descriptivism say that names refer to the satisfiers of (generally non-linguistic) descriptions that the name’s user associates with the name. One such version is ‘famous deeds’ descriptivism, and the descriptions MMNS use are typically famous deeds; nevertheless, that seems inessential to their experiments. When we use ‘descriptivism’ in this paper, we’ll mean any such version of descriptivism. Thanks here to an anonymous referee.There are now a number of challenges to this argument in the literature. Before developing our own challenge, we’ll briefly note five extant ones, which all strike us as at least approximately correct.\nKripke’s theory is a theory of semantic reference. When asked who John is talking about, it is natural that many subjects will take this to be a question about speaker reference. And nothing in Kripke’s theory denies that John might refer to the person who proved the incompleteness of arithmetic, even if his word refers to someone else. (Ludwig 2007; Deutsch 2009)\nKripke’s argument relies on the fact that ’\nGödel’ refers to Gödel, not to the universality or otherwise of intuitions about what it refers to. That some experimental subjects don’t appreciate this fact doesn’t make it any less of a fact. (Deutsch 2009)\nIf the subjects genuinely were descriptivists, it isn’t clear how they could make sense of the vignette, since the name ‘Gödel’ is frequently used in the vignette itself to refer to the causal origin of that name, not to the prover of the incompleteness or arithmetic.\n2\n2 This objection relies on an empirical assumption that may be questionable. It assumes that the subject of the experiment associates the same description with ‘Gödel’ as John does. A subject who (a) is a descriptivist and (b) associates with the name ‘Gödel’ the description ‘the man who proved the compatibility of time travel and general relativity’, can also make sense of the vignette, contra Martí. So perhaps the objection could be resisted. But we think this empirical assumption is actually fairly plausible. Unless the experimental subjects were being picked from a very biased sample, the number of subjects who are familiar with Gödel’s work on closed time-like curves is presumably vanishingly small! We’re grateful here to an anonymous referee.On a related point, Martí doesn’t mention this, but subjects who aren’t descriptivists should also object to the vignette, since in the story John doesn’t learn Gödel proved the incompleteness of arithmetic, at least not if ‘learn’ is factive. (Martı́ 2009)\nThe experiment asks subjects for their judgments about a metalinguistic, and hence somewhat theoretical, question about the mechanics of reference. It’s better practice to observe how people actually refer, rather than asking them what they think about reference. (Martı́ 2009; Devitt 2011)\nIntuitions about the Gödel/Schmidt case play at best a limited role in Kripke’s broader arguments, so experimental data undermining their regularity do not cast serious doubt on Kripke’s theory of reference. (Devitt 2011)\nWe think challenges (1)-(3) work. Something like (4) should work too, although it requires some qualification. Consider, for instance, what happens in syntax. It’s true, of course, that we don’t go around asking ordinary speakers whether they think Lectures on Government and Binding was an advance over Aspects. Or, if we did, we wouldn’t think it had much evidential value. But that’s not because ordinary speaker judgments are irrelevant to syntax. On the contrary, judgments about whether particular strings constitute well-formed sentences are an important part of our evidence.3 But they are not our only evidence, or even our primary evidence; we also use corpus data about which words and phrases are actually used, and many syntacticians take such usage evidence to trump evidence from metasemantic intuitions.4 Even when we do seek such intuitive answers, perhaps because there isn’t enough corpus data to settle the usage issue, the questions might be about cases that are quite different to the cases we primarily care about. So we might ask a lot about speakers’ judgments concerning questions even if we care primarily about the syntax of declarative sentences.\n3 This point suggests Martí’s criticism of MMNS as stated overshoots. She wants to dismiss arguments from metalinguistic intuitions altogether. But intuitions about well-formedness are metalinguistic intuitions, and they are a key part of the syntactician’s toolkit. Martí concedes something like this point, but claims that the cases are not on a par, because syntax concerns a normative issue and reference does not. We’re quite suspicious that there’s such a striking distinction between the kind of subject-matter studied by syntacticians and semanticists. Devitt’s version of this point is more modest and does not obviously commit to this exaggeration.4 Here’s one example where testing intuitions and examining the corpus may lead to different answers. Many people think, perhaps because they’ve picked up something from a bad style guide, that the sentence ‘Whenever someone came into Bill’s shop, he greeted them with a smile’, contains one or two syntactic errors. (It uses a possessive as the antecedent of a pronoun, and it uses ‘them’ as a bound singular variable.) Even if most subjects in a survey said such a sentence was not a well-formed sentence of English, corpus data could be used to show that it is. Certainly the existence of a survey showing that users in, say, Scotland and New Jersey give different answers when asked about whether the sentence is grammatical would not show that there’s a syntactic difference between the dialects spoken in Scotland and New Jersey. You’d also want to see how the sentences are used.If what Kripke (1980) says in Naming and Necessity (hereafter, NN) is right, then we should expect something similar in the case of reference. Kripke anticipates that some people will disagree with him about some of the examples, and offers a few replies. (Our discussion here largely draws on footnote 36 of NN.) Part of his reply is a version of point 1 above; those disagreements may well be over speaker reference, not semantic reference. That reply is correct; it’s hard for us to hear a question about who someone is talking about as anything but a question about speaker reference. He goes on to note that his theory makes empirical predictions about how names are used.\n\nIf I mistake Jones for Smith, I may refer (in an appropriate sense) to Jones when I say that Smith is raking the leaves … Similarly, if I erroneously think that Aristotle wrote such-and-such passage, I may perhaps sometimes use ‘Aristotle’ to refer to the actual author of the passage … In both cases, I will withdraw my original statement, and my original use of the name, if apprised of the facts. (NN 86n)\n\nThis seems entirely right. There’s some sense in which John, in MMNS’s vignette, is referring to\nGödel and some sense in which he’s referring to Schmidt. Just thinking about the particular utterance he makes using ‘Gödel’ won’t help much in teasing apart speaker reference and semantic reference. What we should look to are patterns of—or if they’re not available, intuitions about—withdrawals of statements containing disputed names. To use the example Kripke gives here, consider a speaker who (a) associates with the name ‘Aristotle’ only the description ‘the author of The Republic’, (b) truly believes that a particular passage in The Republic contains a quantifier scope fallacy, and (c) is a descriptivist. She might say “Aristotle commits a quantifier scope fallacy in this passage.” When she’s informed that the passage was written by Plato, she’ll no longer utter those very words, but she’ll still insist that the sentence she uttered was literally true. That’s because she’ll claim that in that sentence ‘Aristotle’ just referred to the author of the passage, and that person did commit a quantifier scope fallacy. A non-descriptivist will take back the claim expressed, though she might insist that what she intended to say was true.\nSo to show that subjects in different parts of the world really have descriptivist intuitions about the Gödel/Schmidt case, we might ask about whether they think John should withdraw, or clarify, his earlier statements if apprised of the facts. Or we might ask whether they would withdraw, or clarify, similar statements they had made if apprised of the facts. Or, even better, we might test whether in practice people in different parts of the world really do withdraw their prior claims at different rates when apprised of the facts about a Gödel/Schmidt case. Kripke is right that given descriptivism, a speaker shouldn’t feel obliged to withdraw the original statement when apprised of the facts, but given the causal-historical theory, they should. So there are experiments that we could run which would discriminate between descriptivist and causal-historical approaches, but we don’t think the actual experiment MMNS run does so.\nIn its broad terms, we agree with Devitt’s challenge (5), although we understand the role of the Gödel/Schmidt case rather differently than he does. We turn now to this question.\n\n\n0.2 Gödel’s Role in Naming and Necessity\nIn the first section we argued that the experimental data MMNS offer do not show that the correct account of the Gödel/Schmidt example is different in different dialects. In this section we want to argue that there’s very little one could show about the Gödel/Schmidt example that would bear on the broader question of what the correct theory of reference is. To see this, let’s review where the Gödel/Schmidt example comes up in Naming and Necessity.\nIn the first lecture, Kripke argues, via the modal argument, that names can’t be synonymous with descriptions. The reason is that in modal contexts, substituting a name for an individuating description alters truth values. So a pure descriptivism that treats names and descriptions as synonymous is off the table. What’s left, thinks Kripke, is what Soames calls “weak descriptivism” (Soames 2003, vols. II, 356). This is the view that although names are not synonymous with descriptions, and do not abbreviate descriptions, they do have their reference fixed by descriptions.\nHere is the way Kripke introduces the picture that he is attacking.\n\nThe picture is this. I want to name an object. I think of some way of describing it uniquely and then I go through, so to speak, a sort of mental ceremony: By ‘Cicero’ I shall mean the man who denounced Cataline … [M]y intentions are given by first, giving some condition which uniquely determines an object, then using a certain word as a name for the object determined by this condition. (NN 79)\n\nThe Gödel/Schmidt example, or at least the version of it that MMNS discuss, comes up in Kripke’s attack on one of the consequences of this picture of naming. (A variant on the example, where no one proves the incompleteness of arithmetic, is used to attack another consequence of the theory.) So the role of the Gödel/Schmidt example is to undermine this picture of names and naming.\nBut note that it is far from the only attack on this picture. Indeed, it is not even the first attack. Kripke’s first argument is that for most names, most users of the name cannot give an individuating description of the bearer of the name. In fact, those users cannot even give a description of the bearer that is individuating by their own lights. The best they can do for ‘Cicero’ is ‘a Roman orator’ and the best they can do for ‘Feynman’ is ‘a famous physicist’. (NN 81) But it isn’t that these users think that there was only one Roman orator, or that there is only one famous physicist. It’s just that they don’t know any more about the bearers of these names they possess. The important point here is that Kripke starts with some examples where the best description a speaker can associate with a name is a description that isn’t individuating even by the speakers’ own lights. And he thinks that descriptivists can’t explain how names work in these cases.\nNow perhaps we’ll get new experimental evidence that even in these cases, some experimental subjects have descriptivist intuitions. Some people might intuit that if a speaker does not know of any property that distinguishes Feynman from Gell-Mann, their name ‘Feynman’ is indeterminate in reference between Feynman from Gell-Mann. We’re not sure what such an experiment would tell us about the metaphysics of reference, but maybe someone could try undermining Kripke’s argument this way. But that’s not what MMNS found; their experiments don’t bear on what Kripke says about ‘Feynman’, and hence don’t bear on his primary argument against weak descriptivism.\nSome philosophers will hold that although the picture Kripke describes here, i.e., weak descriptivism, can’t be right in general for Feynman/Gell-Mann reasons, it could be true in some special cases. We agree. So does Kripke. The very next sentence after the passage quoted above says, “Now there may be some cases in which we actually do this.” (NN 79) And he proceeds to describe three real life cases (concerning ‘Hesperus’, ‘Jack the Ripper’ and ‘Neptune’) where the picture is plausibly correct. But he thinks these cases are rare. In particular, we shouldn’t think that the existence of an individuating description is sufficient reason to believe that we are in such a case. That, at last, is the point of the Gödel/Schmidt example. His conclusion from that example is that weak descriptivism isn’t correct even in those special cases of names where the speaker possesses a description that she takes to be individuating.5\n5 The Gödel/Schmidt example is also distinctive in another way, in that the description in question actually applies to the referent of the name, and indeed speakers actually know this. But the flow of the text around the example (especially on page 84) suggests Kripke intends the example to make the same point as is made by other examples, such as the Peano/Dedekind case (in which the possessed description doesn’t actually apply to the referent of the name). So this is probably not crucial to the point the example makes. We’ll return below to the issue of just what this example shows. The key point is that the more distinctive the example is, the less that would follow if Kripke were wrong about the example; he might only be wrong about examples with just those distinctive features.Michael Devitt (2011) also argues that MMNS exaggerate the importance of the Gödel/Schmidt case. He identifies a number of Kripke’s other arguments (including the Feynman one we mention) that he takes to be more central, and, like us, he argues that MMNS’s results do not cast doubt on these arguments. We agree, noting only two points of difference. First, as suggested above, although the Gödel/Schmidt case is not the only or the most central motivation for Kripke’s theory of reference, we do think that it plays a distinctive role, compared with that of, for instance, the Feynman case. It refutes even the weak version of weak descriptivism according to which, in the special case in which subjects do possess individuating descriptions, those descriptions determine reference. We think the Gödel/Schmidt case (together with the Peano/Dedekind case) form the basis of the only argument in Naming and Necessity against this weak weak descriptivism. (On a closely related point, we, unlike Devitt, take the Gödel/Schmidt case to be addressing a quantitative question about how common descriptive names are, not the qualitative question about whether the causal-historical theory is true at all; we’ll expand on this point below.) Second, Devitt expresses some scepticism about the Gödel/Schmidt judgment on the grounds that the relevant case is somewhat ‘fanciful’—actual cases, Devitt suggests, are better to be trusted. While there is surely some truth in the suggestion that intuitions about esoteric and complicated cases can be less trustworthy than those about everyday ones, we see little reason for concern in this instance; the Gödel case does not describe a scenario we should expect to find trouble thinking about.\nOur reconstruction of the structure of Kripke’s argument should make it clear how unimportant the Gödel/Schmidt example is to the broader theoretical questions. If Kripke were wrong about the Gödel/Schmidt case, that would at most show that there are a few more descriptive names than we thought there were. But since the existence of some descriptive names is consistent with the causal-historical theory of reference, the existence of a few more is too. All the Gödel/Schmidt example is used for in Naming and Necessity is to show that the number of descriptive names in English is not just small, it is very small. But the truth of the causal-historical theory of reference doesn’t turn on whether there are few descriptive names, or very few descriptive names.\nOnce we see that the Gödel/Schmidt example concerns a quantitative question (are descriptive names rare or very rare?) rather than a qualitative question (is the causal-historical theory correct?), we can see some limitations of the experiment MMNS rely on. The case that MMNS describes to their subjects has several distinctive features, and it isn’t clear that we’d be justified in drawing conclusions from it about cases that lack those features. Here is one such feature. The subject of the vignette (John) acquires the name ‘Gödel’ at the same time as he acquires an individuating description of Gödel. Suppose it turned out that, in some dialects at least, that would be sufficient for the name to be a descriptive name; i.e., for it to be a name whose reference is fixed by a description somehow attached to that name. If this conjecture is true, then descriptive names are a little more common than Kripke thinks they are, but not a lot more common. Now we don’t actually think this conjecture is true. And for the reasons given in section 1 we don’t think this experiment is evidence for it. What we do think is that (a) it’s hard to see how studying reactions to cases like the Gödel/Schmidt example could show more than that some such claim about the prevalence of descriptive names is true, and (b) such claims are not inconsistent with the causal-historical theory.\nWe’ve argued that even if Kripke is wrong about the Gödel/Schmidt example, that doesn’t undermine the arguments for the main conclusions of Naming and Necessity. A natural inference from this is that experiments about the Gödel/Schmidt example can’t undermine those conclusions. We think the natural inference is correct. A referee has suggested that this is too quick. After all, if we have experimental evidence that Kripke is wrong about the Gödel/Schmidt case, we might have some grounds for suspicion about the other cases that Kripke uses in the arguments for more central conclusions. That is, if MMNS are right about the Gödel/Schmidt case, that doesn’t give us a deductive argument against the other anti-descriptivist moves, but it might give us an inductive argument against them. This is an important worry, but we think it can be adequately responded to.\nThe first thing to note is that it would be foolish to fall back to a general scepticism about human judgment just because people disagree in their intuitive reactions to some tricky cases. This point is well argued by Timothy Williamson in his (2007 Ch. 6). If there’s a worry here, it must be because the evidence about the Gödel/Schmidt example supports a more modest generalisation about judgments about cases, but that generalisation is nevertheless strong enough to undermine Kripke’s other arguments. We doubt such a generalisation exists.\nIt can’t be that the experiments about the Gödel/Schmidt example show that intuitive judgments about reference are systematically mistaken. Most of our intuitions in this field are surely correct. For instance, our intuitions that ‘Kripke’ refers to Kripke and not Obama, and that ‘Obama’ refers to Obama and not Kripke, are correct. (And experiments like the ones MMNS ran don’t give us any reason at all to doubt that.) And we could produce many more examples like that. At most, the experiments can show us that there are spots of inaccuracy in a larger pool of correct judgments.\nIt might be argued that we should be sceptical of intuitions about reference in counterfactual cases. The correct judgments cited in the previous paragraph are all about real cases, but the Gödel/Schmidt example is not a real case. Now we don’t think that the experiments do undermine all intuitions about reference in counterfactual cases, but even if they did, that wouldn’t affect the Kripkean argument. That’s because the central argument against descriptivism at the start of Lecture II involves real cases. The heavy lifting is done by cases where speakers don’t think they have an individuating description to go along with names they use (e.g., ‘Feynman’ and ‘Gell-Mann’), or they believe they have an individuating description, but that description involves some kind of circularity (e.g., ‘Einstein’, ‘Cicero’). It seems to us that these cases are much more like the cases where we know people have accurate intuitions about reference (e.g., ‘Obama’ refers to Obama), than they are like cases where there is some dispute about their accuracy (e.g., ‘Gödel’ would refer to Gödel even if Schmidt had proved the incompleteness of arithmetic). So there’s no reason to doubt the intuitions that underlie these central Kripkean arguments. And so there’s no reason from these experiments to doubt the anti-descriptivist conclusions Kripke draws from them.\n\n\n0.3 Reference in Philosophy\nIf the data about the Gödel/Schmidt example don’t undermine the causal-historical theory of reference, then presumably they don’t undermine philosophical uses of that theory. But we think MMNS overstate the role that theories of reference play in philosophical theorising, and we’ll end by saying something about this.\nOne simple reaction to MMNS’s argument is to say that at most they show that the causal-historical theory of reference is not true of some dialects. But, a philosopher might say, they are not writing in such a dialect, and the causal-historical theory is true of their dialect. And that’s all they needed for their argument. MMNS anticipate this objection, and reply to it in section 3.3 of their paper. The reply is, in essence, that such a picture would make a mess of communication. If we posit dialectical variation to explain different reactions to the Gödel/Schmidt example, and to other examples, then we cannot know what dialect someone is speaking without knowing how they respond to these examples. And plainly we don’t need to quiz people in detail about philosophical examples in order to communicate with them.\nWe offer three replies.\nFirst, at least one of us is on record raising in principle suspicions about this kind of argument Maitra (2007). The take-home message from that paper is that communication is a lot easier than many theorists have supposed, and requires much less pre-communicative agreement. It seems to us that the reply MMNS offer here is susceptible to the arguments in that paper, but for reasons of space we won’t rehearse those arguments in detail.\nSecond, it’s one thing to think that variation in reference between dialects leads to communication breakdown, it’s another thing altogether to think that variation in meta-semantics leads to such breakdown. A little fable helps make this clear. In some parts of Melbourne, ‘Gödel’ refers to Gödel because of the causal chains between the users of the name and the great mathematician. In other parts, ‘Gödel’ refers to Gödel because the speakers use it as a descriptive name, associated with the description ‘the man who proved the incompleteness of arithmetic’. Kevin doesn’t know which area he is in when he sees a plaque over a door saying “Gödel lived here”. It seems to us that Kevin can understand the sign completely without knowing how ‘Gödel’ got its reference. Indeed, he even knows what proposition the sign expresses. So meta-semantic variation between dialects need not lead to communicative failure, even when hearers don’t know which dialect is being used.\nThird, if MMNS’s argument succeeds, it seems to us that it shows descriptivist theories, including the weak weak descriptivism that Kripke is arguing against with the Gödel/Schmidt example, are doomed. (The arguments in this paragraph are not original. Similar arguments are used frequently in, e.g., Fodor and Lepore (1992).) It’s a platitude that different people know different things. Barring a miracle, that means different people will associate different descriptions with different names. If there is widespread use of descriptive names, that means there will be widespread differences in which descriptions are associated with which names. And that will produce at least as much communicative difficulty as having some people be causal-historical theorists and some people be descriptivists. In short, if MMNS’s argument against ‘referential pluralism’ is sound, there is an equally sound argument against descriptivism. And note that this argument doesn’t rely on any thought experiments about particular cases. It doesn’t even rely on thought experiments about names like ‘Einstein’, where there isn’t any evidence that Kripke is wrong about how those names work.\nDialectically, the situation is this. MMNS have offered an argument from the possibility of communicating under conditions of ignorance about one’s interlocutor’s knowledge. Similar arguments have been offered against descriptivism. If such arguments are successful, then descriptivism is false, and there’s no problem with philosophers making arguments from the falsity of descriptivism. If such arguments are unsuccessful, then MMNS haven’t shown that it is wrong for philosophers to assume that the causal-historical theory is the right theory for their dialect, even if some other people are descriptivists. And, as MMNS concede, as long as the philosophers themselves speak a causal-historical theory dialect, the uses of the causal-historical theory in philosophy seem appropriate. The only way this argument could fail is if MMNS’s argument from the possibility of communicating under conditions of ignorance about one’s interlocutor’s knowledge is stronger than the analogous arguments against descriptivism. But we see no reason to believe that is so. If anything, it seems like a weaker argument, because of the considerations arising from our fable about Kevin and the ‘Gödel lived here’ sign.\nSo we don’t think MMNS have a good reply to the philosopher who insists that they only need the causal-historical theory to be true of their dialect. But in fact we think that philosophers rarely even assume that much.\nLet’s consider one of the examples that they cite: Richard Boyd’s use of the causal-historical theory of reference in developing and defending his version of “Cornell Realism” in his (1988). Here’s one way one could try and argue for moral realism from the causal-historical theory.\n\nThe causal-historical theory of reference is the correct theory of reference for all words in all dialects (or at least our dialect).\nSo, it is the correct theory for ‘good’.\n\nBut that’s not Boyd’s actual argument. And that’s a good thing, because the first premise is implausible. Someone defending it has to explain descriptive names like ‘Neptune’, logical terms like ‘and’, empty predicates like ‘witch’, and so on. And Boyd’s not in that business. His argument is subtler. Boyd uses the causal-historical theory for two purposes. First, he uses the development of a naturalistically acceptable theory of reference as part of a long list of developments in post-positivist philosophy that collectively constitute a “distinctively realist conception of the central issues in the philosophy of science” (Boyd 1988, 188). Second, he uses the causal-historical theory of reference, as it applies to natural kind terms, as part of a story about how we can know a lot about kinds that are not always easily observable (Boyd 1988, 195–96). By analogy, he suggests that we should be optimistic that a naturalistically acceptable moral theory exists, and that it is consistent with us having a lot of moral knowledge.\nOnce we look at the details of Boyd’s argument, we see that it is an argument that duelling intuitions about the Gödel/Schmidt example simply can’t touch. In part that’s because Boyd cares primarily about natural kind terms, not names. But more importantly it is because, as we noted in section 2, the only point that’s at issue by the time Kripke raises the Gödel/Schmidt example is the number of descriptive names. Just looking at the arguments Kripke raises before that example gives us more than enough evidence to use in the kind of argument Boyd is making.\nIt would take us far beyond the length of a short reply to go through every philosophical use of the causal-historical theory that MMNS purport to refute in this much detail. But we think that the kind of response we’ve used here will frequently work. That is, we think few, if any, of the arguments they attack use the parts of the causal-historical theory that Kripke is defending with the Gödel/Schmidt example, and so even if that example fails, it wouldn’t undermine those theories.\n\n\n\n\n\n\nReferences\n\nBoyd, Richard. 1988. “How to Be a Moral Realist.” In Essays in Moral Realism, edited by Geoffrey Sayre-McCord, 181–228. Ithaca: Cornell University Press.\n\n\nDeutsch, Max. 2009. “Experimental Philosophy and the Theory of Reference.” Mind and Language 24 (4): 445–66. https://doi.org/10.1111/j.1468-0017.2009.01370.x.\n\n\nDevitt, Michael. 2011. “Experimental Semantics.” Philosophy and Phenomenological Research 82 (2): 418–35. https://doi.org/ppr201182222.\n\n\nFodor, Jerry A., and Ernest Lepore. 1992. Holism: A Shopper’s Guide. Cambridge: Blackwell.\n\n\nKripke, Saul. 1980. Naming and Necessity. Cambridge: Harvard University Press.\n\n\nLudwig, Kirk. 2007. “The Epistemology of Thought Experiments: First Person Versus Third Person Approaches.” Midwest Studies in Philosophy 31 (1): 128–59. https://doi.org/10.1111/j.1475-4975.2007.00160.x.\n\n\nMaitra, Ishani. 2007. “How and Why to Be a Moderate Contextualist.” In Context Sensitivity and Semantic Minimalism: New Essays on Semantics and Pragmatics, edited by Gerhard Preyer and Georg Peter, 111–32. Oxford: Oxford University Press.\n\n\nMallon, Ron, Eduoard Machery, Shaun Nichols, and Stephen Stich. 2009. “Against Arguments from Reference.” Philosophy and Phenomenological Research 79 (2): 332–56. https://doi.org/10.1111/j.1933-1592.2009.00281.x.\n\n\nMartı́, Genoveva. 2009. “Against Semantic Multi-Culturalism.” Analysis 69 (1): 42–48. https://doi.org/10.1093/analys/ann007.\n\n\nSoames, Scott. 2003. Philosophical Analysis in the Twentieth Century. Princeton: Princeton University Press.\n\n\nWilliamson, Timothy. 2007. The Philosophy of Philosophy. Blackwell."
  },
  {
    "objectID": "posts/rrm/index.html",
    "href": "posts/rrm/index.html",
    "title": "Running Risks Morally",
    "section": "",
    "text": "This paper is part of a project defending normative externalism. This is the view that the most important norms concerning the guidance and evaluation of action and belief are external to the agent being guided or evaluated. The agent simply may not know what the salient norms are, and indeed may have seriously false beliefs about them. The agent may not have any evidence that makes it reasonable to have true beliefs about what the salient norms are, and indeed may have misleading evidence about them. But this does not matter. What one should do, or should believe, in a particular situation is independent of what one thinks one should do or believe, and (in some key respects) of what one’s evidence suggests one should do or believe.\n\nPublished in Philosophical Studies 167: 141-163.\nPhoto by Michel Osmont via Creative Commons.\n\nThere are three important classes of argument relevant to the debate between normative externalists, in the sense of the first paragraph, and normative internalists. One class concerns intuitions about cases. For instance, we might try to defend normative externalism by arguing that according to the internalist, but not the externalist, there is something bad about Huckleberry Finn’s actions in helping Jim escape. Nomy Arpaly (2002) uses this example as part of an argument for a sophisticated form of externalism. Another class concerns views about the nature of norms. Internalists think that externalists have missed the need for a class of subjective norms, that are sensitive to agents’ views about the good. Externalists think that the norms internalists put forward are incoherent, or do not meet the internalists’s needs. I’ll gesture at these arguments below, but they are made in much more detail in recent work by Elizabeth Harman (2015) responding to internalist proposals.\n\nI’ve discussed this paper with just about everyone I know. Thanks to Elizabeth Anderson, Rachael Briggs, Lara Buchak, Sarah Buss, Justin D’Arms, Tom Dougherty, Dmitri Gallow, Alex Guerrero, Elizabeth Harman, Scott Hershovitz, Ishani Maitra, Julia Markovits, Jill North, Timothy Schroeder, Andrew Sepielli, Ted Sider, Rohan Sud, Sigrún Svavarsdóttir and Julie Tannenbaum for suggestions that particularly improved the paper.\n\nBut there’s a third class of argument where the internalist may seem to have an edge. Internalists can argue that there is a wrong of moral recklessness, and externalists cannot explain what is wrong about moral recklessness. My response will be fairly blunt; I do not think moral recklessness is wrong. But I’ll start by trying to state the case for the wrongness of moral recklessness as strongly as I can, including clarifying just what moral recklessness is, before moving onto a response on behalf of the externalist.\n\nThis paper was presented to the EDGe group at the University of Michigan and the philosophy department at Ohio State University, and I got valuable feedback at both of those presentations.\n\n\n0.1 Moral Uncertainty\nSome of our moral opinions are pretty firmly held. Slavery really is wrong; rescuing drowning children is good; and so on. But others might be more uncertain. To use an example I’ll return to a lot, even a lot of carnivores worry that it isn’t obvious that killing animals to eat their flesh is morally permissible.\n\nThe paper also served as my inaugural lecture as the Marshall M. Weinberg Professor at the University of Michigan. Marshall has been a wonderful supporter of the University of Michigan for many years, and especially of its philosophy department, and this was a tremendous honour.\n\nWe might wonder whether this uncertainty should have practical consequences. Uncertainty in general does have practical, and even moral, consequences. If you’re pretty sure the bridge is safe, but not completely certain, you don’t cross the bridge. If you’re only sorta kinda confident that an action won’t kill any innocent bystanders, and there is no compelling reason to do the action, it would be horribly immoral of you to do it.\n\nAnd the paper was presented at the 2013 Bellingham Summer Philosophy Conference. This is close to the Platonic Ideal of a philosophy conference. I’m incredibly grateful to Ned Markosian, and to all of the people who work with him to make this conference happen every year. And I’m very happy to have been able to present this paper at the 2013 conference.\nSo to Marshall and to Ned, thanks.\n\nThere are (at least) two ways to be uncertain about the morally significant consequences of your action. You might know the moral significance of everyone who might be harmed by your action, but not know how many of them will be harmed, or how seriously they will be harmed. Someone who habitually runs red lights is in this position. They know there’s an elevated risk that they’ll kill another human this way, and they know the human they would kill is morally valuable. Alternatively, you might know who or what is affected by your action, but not be sure of their moral status. The hesitant carnivore is like this. They know that steak dinners require killing cows, but they aren’t sure how morally significant the cows are.\nPerhaps that’s a distinction without a difference though. In both cases, the action results in a higher probability of something morally significant being killed. And, one might think, that’s enough to give the actor reason to pause before acting, and enough to give us reason to condemn the action.\nAs may be clear from the introduction, that’s not how I think of the cases. I think the distinction I just flagged is very important both practically and morally. Being uncertain about the physical consequences of your actions should matter both to what you do, and how you are assessed. The red light runner is immoral, even if she never actually harms anyone, because she endangers morally significant humans. But the meat eater cannot be condemned on the same grounds. If she is wrong that meat eating is morally acceptable, that would be one thing. But a mere probability that meat eating is immoral should not change one’s actions, or one’s evaluations of meat eaters.\nNow I won’t pretend this is a particularly intuitive view. In fact, quick reflection on a few cases may make it seem that it is extremely unintuitive. Let’s look at three such cases.\n\nCake\nCarla is baking a cake for a fundraiser. She wants to put some sweetening syrup into the cake to improve its taste. She reaches for an unmarked bottle, which she is pretty sure contains the sweetener she wants. But then she remembers that last week she had some arsenic in a similar bottle. She is pretty sure she threw the arsenic out, but not exactly certain. As a matter of fact, the syrup in the bottle is sweetener, not arsenic, but Carla isn’t certain of this. What should she do?\n\n\nDinner\nMartha is deciding whether to have steak or tofu for dinner. She prefers steak, but knows there are ethical questions around meat-eating. She has studied the relevant biological and philosophical literature, and concluded that it is not wrong to eat steak. But she is not completely certain of this; as with any other philosophical conculsion, she has doubts. As a matter of fact, Martha is right in the sense that a fully informed person in her position would know that meat-eating was permissible, but Martha can’t be certain of this. What should she do?\n\n\nAbortion\nAgnes is twelve weeks pregnant, and wants to have an abortion. She has studied the relevant medical and philosophical literature, and is pretty sure that foetuses at this stage of development are not so morally significant as to make abortion wrong. But she is not completely certain of this; as with any other philosophical conclusion, she has doubts. As a matter of fact, Agnes is right in the sense that a fully informed person in her position would know that abortion was permissible, but Martha can’t be certain of this. What should she do?\n\nThe setup of the last two cases is a bit cumbersome in one key respect; I had to refer to what a fully informed person in Martha or Agnes’s position would know. I did this so as to not beg any questions against the internalist. I would rather say simply that Martha and Agnes were simply right in their beliefs. But I’m not sure how to make sense of this from an internalist perspective. If what’s right to do is a function of your moral evidence and beliefs, perhaps there is a sense in which meat-eating or abortion is objectively permissible, but Martha and Agnes can’t truly believe it is permissible, since it isn’t permissible in their subjective state, and that’s the really important kind of permissibility. So the retreat to talking about what a fully informed person would know is my attempt to find an objective point at which the internalist and externalist can agree. It doesn’t signal that I think there’s anything special about fully informed agents; I’m just trying to avoid being question-begging here.\nYou might also think that one or other of these cases is very far removed from reality. Perhaps what counts as meat or a foetus would have to be very different for these cases to be possible, perhaps so different that they wouldn’t deserve the label ‘meat’ or ‘foetus’. I don’t think this should worry us. I don’t particularly care if the cases are metaphysically possible or not. There’s a world, epistemically if not metaphysically possible, where the medical and biological facts are as they are and meat-eating and abortion are permissible, and that’s the world I mean these examples to be set in. By allowing that my thought experiments may well be set in metaphysically impossible worlds, I am going against some recent views on thought experiments as put forward by, e.g, Timothy Williamson (2007) and Anna-Sara Malmgren (2011), but it would take us too far afield to defend this bit of apostasy. Instead, I’ll just use the cases as they are.\nFinally, note that I’ve set up the cases where the protagonists are almost, but not entirely, sure of something that is in fact true. And I’m going to argue in the moral case that they should act as if they are right. That’s not because I think that a view one is almost sure of should be acted on; one should act on the moral truths, and Agnes and Martha are close to certain of the actual truth. The reason for picking these cases is that they make the issue of recklessness most salient. If any of the three women do anything wrong (and I think Carla does) it is only because they are reckless.\nThat said, there is something interestingly in common to the three cases. In each case, the agent has a choice that is, if taken freely, clearly morally acceptable. Carla can leave out the syrup, Agnes can continue the pregnancy, and Martha can order the tofu. At least, that’s true on the most natural ways to fill out the details of the case.1 So assume that Carla, Martha and Agnes are correctly completely certain that they have a morally safe option. Also assume, if it isn’t clear already, that their only motivation for taking the safe option is to hedge against a possibility that they think is rather unlikely. Hedges can be valuable, so the fact that this is their only motivation is not a reason to not take the safe option.\n1 Here is one argument against the claims of the last two sentences. Assume that, as is realistic, Agnes wants an abortion because her life will be worse in significant ways if she becomes a parent (again) in the near future. And assume that Agnes has a moral duty to herself; making her own life worse in significant ways for no sufficient reason is immoral. Then it could be immoral for her to continue the pregnancy. I don’t find this reason particularly compelling; it seems to me odd to say that people who make heroic sacrifices are immoral in virtue of paying insufficient regard to their own welfare. But the issues here are difficult, and I certainly don’t have a strong argument that we should give no credence to the view that there are substantial duties to self that make misguided sacrifices on behalf of others immoral. Still, I’m going to set this whole line of reasoning aside for most of the paper, while just noting that this could be a way even for an internalist to reject the practical arguments I’ll discuss below. I’m grateful to conversations with Elizabeth Anderson here (but not only here!).In contemporary debates, it’s not often you see pro-vegetarianism and anti-abortion arguments run side by side. Especially in America, these debates have been caught up in culture war politics, and on the whole vegetarians are on one side of this debate, and anti-abortion activists on the other side. But the debates do have some things in common, and it is their commonality that will interest us primarily here. In particular, we’ll be looking at the idea that one should be vegetarian, and refrain from having abortions, on the grounds that these are the good safe options to take. (This connection between the debates is not a novel observation. D. Moller (2011, 426) notes it, and makes some pointed observations about how it affects the philosophical landscape.)\nI’m going to argue that the idea that all three women should ‘play it safe’ is entirely the wrong lesson to take from the cases. I think the cases are in important respects disanalogous. It is seriously morally wrong for Carla to include the syrup in the cake, but it is not wrong in the same way for Martha to eat the steak, or for Agnes to have the abortion. A little more precisely, I’m going to be arguing that there is no good way to fill in the missing premise of this argument.\n\nThe ‘Might’ Argument\n\n\nIn the circumstances that Agnes/Martha are in, having an abortion /eating a steak might be morally wrong.\nIn the circumstances that Agnes/Martha are in, continuing the pregnancy /eating vegetables is definitely morally permissible.\nMissing Premise\nSo, Agnes should not have the abortion, and Martha should not eat the steak.\n\nWhen I argue that the ‘Might’ Argument cannot be filled in, I’m arguing against philosophers who, like Pascal, think they can convince us to act as if they are right as soon as we agree there is a non-zero chance that they are right. I’m as a rule deeply sceptical of any such move, whether it be in ethics, theology, or anywhere else.\nBut note like someone responding to Pascal’s Wager, I’m focussing on a relatively narrow target here. Rejecting Pascal’s Wager does not mean rejecting theism; it means rejecting Pascal’s argument for being a theist. Similarly, rejecting the ‘Might’ Argument does not mean rejecting all ethical arguments against meat-eating or abortion. It just means rejecting this one.\nI’m also not arguing about public policy here. The ‘Might’ Argument can be generalised to any case where there is an epistmic asymmetry. The agent faces a choice where one option is morally risky, and the other is not. Public policy debates are rarely, if ever, like that. A legislator who bans meat-eating or abortion takes a serious moral risk. They interfere seriously with the liberties of the people of their state, and perhaps do so for insufficient reason. (This point is well made by Moller (2011, 442).) So there isn’t a ‘play it safe’ reason to support anti-meat or anti-abortion legislation, even if I’m wrong and there is such a reason to think that individuals should not eat meat or have abortions.\nThere are two ways to try to fill out the ‘Might’ Argument. We could try to offer a particular principle that implies the conclusion given the rest of the premises. Or we could try to stress the analogy between the three cases that I started with. I’m going to have a brief discussion of the first option, and then spend most of my time on the analogy. As we’ll see, there are many possible principles that we could try to use here, but hopefully what I say about a some very simple principles, plus what I say about the analogy, will make it clear how I want to respond to most of them.\n\n\n0.2 Principles\nOne way to fill in the Missing Premise is to have a general principle that links probabilities about morality with action. The simplest such principle that would do the trick is this.\n\nProbWrong\nIf an agent has a choice between two options, and one might be wrong, while the other is definitely permissible, then it is wrong to choose the first option.\n\nI think ProbWrong does a reasonable job of capturing the intuition that Agnes and Martha would be running an impermissible risk in having an abortion or eating meat. But ProbWrong has clearly implausible consequences. Imagine that an agent has the following mental states:\n\nShe is sure that ProbWrong is true.\nShe is almost, but not completely, sure that eating meat is permissible for her now.\nShe is sure that eating vegetables is permissible for her now.\nShe is sure that she has states 1–3.\n\nA little reflection shows that this is an incoherent set of states. Given ProbWrong, it is simply wrong for someone with states 2 and 3 to eat meat. And the agent knows that she has states 2 and 3. So she can deduce from her other commitments and mental states that eating meat is, right now, wrong. So she shouldn’t be almost sure that eating meat is permissible; she should be sure that it is wrong.\nThis argument generalises. If 1, 3 and 4 are true of any agent, the only ways to maintain coherence are to be completely certain that meat eating is permissible, or completely certain that it is impermissible. But that is, I think, absurd; these are hard questions, and it is perfectly reasonable to be uncertain about them. At least, there is nothing incoherent about being uncertain about them. But ProbWrong implies that this kind of uncertainty is incoherent, at least for believers in the truth of ProbWrong itself. Indeed, it implies that in any asymmetric moral risk case, an agent who knows the truth of ProbWrong and is aware of her own mental states cannot have any attitude between certainty that both options are permissible, and certainty that the risky action is not, for her, permissible. That is, I think, completely absurd.\nNow most philosophers who advocate some principle or other as the Missing Premise don’t quite advocate ProbWrong. We can position some of the rival views by abstracting away from ProbWrong as follows.\n\nGeneral Principle\nIf an agent has a choice between two options, and one might be X, while the other is definitely not X, then it is Y to choose the first option.\n\nWe get ProbWrong by substituting ‘wrong’ for both X and Y. But we saw a decisive objection to that view. And we get a version of that objection for any substitution where X and Y are the same. So a natural move is to use different substitutions. If you replace X with ‘wrong’ and Y with ‘irrational’, you get something like a principle defended by Ted Lockhart (2000).\n\nWhat Might be Wrong Is Irrational\nIf an agent has a choice between two options, and one might be wrong, while the other is definitely not wrong, then it is irrational to choose the first option.\n\nNow at this stage we could look at whether this principle is plausible, and if not whether alternative principles offered by Alex Guerrero (2007), Andrew Sepielli (2009) or others are any better. You can probably guess how this would go. We’d spend some time on counterexamples to the principle. And we’d spend some time on whether the conclusion we get in this particular case is really plausible. (Is it true that Martha is not in any way immoral, but is irrational in virtue of moral risk? That doesn’t sound at all like the right conclusion.)\nBut I’m not going to go down that path. Shamelessly stealing an analogy from Jerry Fodor (2000), I’m not going to get into a game of Whack-a-Mole, where I try to reject a principle that could fill in for the Missing Premise, and if I succeed, another one pops up. I’m not playing that game because you never actually win Whack-a-Mole; by going through possible principles one at a time it isn’t clear how I could ever show that no principle could do the job.\nWhat I need to show is that we shouldn’t look for a principle to fill in as Missing Premise. One reason we shouldn’t is that the intuitions behind principles like Lockhart’s is really an intuition in favour of ProbWrong, and as such should be suspect. But a better reason is that the analogy between Carla’s case and Agnes/Martha’s cases that motivated the thought that there should be some principle here is mistaken. Once we see how weak that analogy is, I think we’ll lose motivation for trying to fix ProbWrong.\n\n\n0.3 Welfare and Rationality\nSo my primary opponent the rest of the way is someone who wants to defend the ‘Might’ Argument by pressing the analogy between Carla’s case and the two more morally loaded cases.2 My reply will be that there are better analogies than this which point in the opposite direction. In particular, I’m going to draw an analogy between Agnes and Martha’s cases with some tricky cases concerning prudential reasoning. To set up the case, I’ll start with an assumption that guides the discussion.\n2 D. Moller (2011) offers an interesting different analogy to motivate something like the ‘Might’ Argument. I think that analogy is a little messier than the one I’m focussing on, and I’ll discuss it separately below.The assumption is that deliberately undermining your own welfare, for no gain of any kind to anyone, is irrational. Indeed, it may be the paradigmatic form of irrationality. This is, I think, a widely if not universally held view. There is a radically Humean view that says that welfrae just consists of preference satisfaction, and rationality is just a matter of means-end reasoning. If that’s right then this assumption is not only right, it states the only kind of irrationality there is. But you don’t have to be that radical a Humean, or really any kind of Humean at all, to think the assumption is true.\nThe assumption doesn’t just mean that doing things that you know will undermine your welfare for no associated gain is irrational. It means that taking serious risks with your welfare for no compensating gain is irrational. Here is a clear example of that.\n\nEating Cake\nRicky is baking a cake for himself. He wants to put some sweetening syrup into the cake to improve its taste. He reaches for an unmarked bottle, which he is pretty sure contains the sweetener he wants. But then he remembers that last week he had some arsenic in a similar bottle. He is pretty sure that he threw the arsenic out, but not exactly certain. As a matter of fact, the bottle does contain sweetener, not arsenic, but Ricky isn’t completely sure of this. What should he do?\n\nI hope it is plausible enough that it would be irrational for Ricky to put the syrup in the cake. The risk he is running to his own welfare – he literally will due if he’s wrong about what’s in the bottle – isn’t worth the gain in taste, given his level of confidence.\nWith that said, consider two more examples, Bob and Bruce. Bob has thought a bit about philosophical views on welfare. In particular, he has spent a lot of time arguing with a colleague who has the G. E. Moore-inspired view that all that matters to welfare is the appreciation of beauty, and personal love.3 Bob is pretty sure this isn’t right, but he isn’t certain, since he has a lot of respect for both his colleague and for Moore.\n3 It would be a bit of a stretch to say this is Moore’s own view, but you can see how a philosopher might get from Moore to here. Appreciation of beauty is one of the constituents of welfare in the objective list theory of welfare put forward by John Finnis (2011, 87–88).Bob also doesn’t care much for visual arts. He thought that art is something he should learn something about, both because of the value other people get from art, and because of what you can learn about the human condition from it. And while he’s grateful for what he learned while trying to inculcate an appreciation of art, and he has become a much more reliable judge of what’s beautiful and what isn’t, the art itself just leaves him cold. I suspect most of us are like Bob about some fields of art; there are genres that we feel have at best a kind of sterile beauty. That’s how Bob feels about most visual art. This is perhaps unfortunate; we should feel sorry for Bob that he doesn’t get as much pleasure from great art as we do. But it doesn’t make Bob irrational, just unlucky.\nFinally, we will suppose, Bob is right to reject his colleague’s Moorean view on welfare. Appreciation of art isn’t a constituent of welfare. In the example we’ll suppose welfare is a matter of health, happiness and friendship. So a fairly restricted version of an objective list theory of welfare is correct in Bob’s world. And for people who like art, appreciating art can produce a lot of goods. Some of these are direct - art can make you happy. And some are indirect - art can teach you things and that learning can contribute to your welfare down the line. But if the art doesn’t make you happy, as it doesn’t make Bob happy, and one has learned all one can from a genre, as has Bob, there is no welfare gain from going to see art. It doesn’t in itself make you better off, as Bob’s Moorean colleague thinks.\nNow Bob has to decide whether to spend some time at an art gallery on his way home. He knows the art there will be beautiful, and he knows it will leave him cold. There isn’t any cost to going, but there isn’t anything else he’ll gain by going either. Still, Bob decides it isn’t worth the trouble, and stays out. He doesn’t have anything else to do, so he simply takes a slightly more direct walk home, which (as he knows) makes at best a trifling gain to his welfare.\nI think Bob is perfectly rational to do this. He doesn’t stand to gain anything at all from going to the gallery. In fact, it would be a little perverse, in a sense we’ll return to, if he did go.\nBruce is also almost, but not completely certain, that health, happiness and friendship are the sole constituents of welfare.4 But he worries that this is undervaluing art. He isn’t so worried by the Moorean considerations of Bob’s colleagues. But he fears there is something to the Millian distinction between higher and lower pleasures, and thinks that perhaps higher pleasures contribute more to welfare than lower pleasures. Now most of Bruce’s credence goes to alternative views. He is mostly confident that people think higher pleasures are more valuable than lower pleasures because they are confusing causation and constitution. It’s true that experienceing higher pleasures will, typically, be part of experiences with more downstream benefits than experiences of lower pleasures. But that’s the only difference between the two that’s prudentially relevant. (Bruce also suspects the Millian view goes along with a pernicious conservatism that values the pop culture of the past over the pop culture of the present solely because it is past. But that’s not central to his theory of welfare.) And like Bob, we’ll assume Bruce is right about the theory of welfare in the world of the example.\n4 Thanks to Julia Markovits for suggesting the central idea behind the Bruce example, and to Jill North for some comments that showed the need for it.Now Bruce can also go to the art gallery. And, unlike Bob, he will like doing so. But going to it will mean he has to miss a night playing video games that he often goes to. Bruce knows he will enjoy the video games more. And since playing video games with friends helps strengthen friendships, there may be a further reason to skip the gallery and play games. Like Bob, Bruce knows that there can be very good consequences of seeing great art. But also like Bob, Bruce knows that none of that relevant here. Given Bruce’s background knowledge, he will have fun at the exhibition, but won’t learn anything significant.\nStill, Bruce worries that he should take a slightly smaller amount of higher pleasure rather than a slightly larger amount of lower pleasure. And he’s worried about this even though he doesn’t give a lot of credence to the whole theory of higher and lower pleasures. But he doesn’t go to the gallery. He simply decides to act on the basis of his preferred theory of welfare, and since that welfare is correct, he maximises his welfare by doing this.\nNow I think both Bob and Bruce are rational in what they do. But there is an argument that they are not. I’ll focus on Bob, but the points here generalise.\n\nGoing to the gallery might increase his welfare substantially, since it will lead to more appreciation of beauty, and appreciation of beauty might be a key constituent of welfare.\nNot going to the gallery definitely won’t increase his welfare by more than a trivial amount.\nIt is irrational to do something that might seriously undermine your own welfare for no compensating gain.\nSo it is irrational for Bob to skip the gallery.\n\nI think that argument is wrong. Bob’s case is rather unlike Ricky’s. There is a sense in which Bob might be undermining his own welfare in skipping the gallery. But it is not the relevant sense. We can distinguish the two senses making the scope of various operators explicit. The first of these claims is plausibly true; the second is false.\n\nBob’s welfare is such that it is irrational for him to do something that might undermine it for no compensating gain.\nIt is irrational for Bob to do something that might undermine his welfare, whatever that turns out to be, for no compensating gain.\n\nIf welfare turns out to be health, happiness and learning, then the first claim says that it is irrational to risk undermining your health, happiness and learning for no compensating gain. And that is, I think, right. But the second claim says that for any thing, if that thing might be welfare, and an action might undermine it, it is irrational to perform the action without a compensating gain. That’s a much stronger, and a much less plausible, claim.\nImportantly, Bob’s ‘Might’ Argument doesn’t go through with the first claim. Given that appreciation of beauty is not directly a component of welfare, and that the various channels through which appreciating beauty might lead to an increase in welfare are blocked for Bob, there is no chance that going to the gallery will increase his actual welfare. Going to the gallery will increase something, namely his appreciation of beauty, that is for all Bob knows part of welfare. But that’s not the same thing, and it isn’t relevant to rationality.\nOne caveat to all this. On some theories of welfare, it will not be obvious that even the first claim is right. Consider a view (standard among economists) that welfare is preference satisfaction. Now you might think that even the first claim is ambiguous, between a claim that one’s preferences are such that it is irrational to undermine them (plausibly true), and a claim that it is irrational to undermine one’s preference satisfaction. The latter claim is not true. If someone offers me a pill that will make me have preferences for things that are sure to come out true (I want the USA to be more populous than Monaco; etc.), it is rational to refuse it. And that’s true even though taking the pill will ensure that I do well by preference satisfaction. The point is that taking the pill does not, as things stand, satisfy my preferences. If I prefer X to Y, I should aim to bring about X. But I shouldn’t aim to bring about a state of having satisfied preferences; that could lead to rather perverse behaviour, like taking this pill.\n\n\n0.4 Duelling Analogies\nHere’s how I see the five cases we’ve discussed so far fitting together.\n\n\n\n\nFactual Uncertainty\nNormative Uncertainty\n\n\n\n\nPrudential\nRicky\nBob\n\n\nRisk\n\nBruce\n\n\n\n\n\n\n\nMoral\nCarla\nAgnes\n\n\nRisk\n\nMartha\n\n\n\nOn the left-hand column, we have agents who are uncertain about a simple factual question; is this syrup sweetener or arsenic? On the right-hand column, we have agents who are uncertain about a question about the nature of value; does the decision I’m facing right now have serious evaluative consequences?\nIt’s even easier to see what is separating the rows. Ricky, Bob and Bruce face questions that, in the first instance, just concern their own welfare. Carla, Agnes and Martha face questions that concern the morality of their actions. I don’t mean to say that there’s a hard line between these two. Perhaps being moral is an important part of the good life. And perhaps one has a moral duty to live well. I’m a little doubtful on both scores actually. But even if the questions bleed into each other in one or other way, we can separate questions that are in the first instance about the agent’s own welfare from questions that bear directly on the morality of the agent. (Recognising, as always, that there will be borderline cases.) And that’s how we’ve split the rows.\nOne way to motivate the ‘Might’ Argument is to stress the analogy between Carla and Agnes/Martha. After all, both of them risk killing someone (or something) statused if they act in a certain way. But once we look at the table more broadly, it is easy to see why we should resist the analogy between Carla and Agnes/Martha. The analogy between Bob/Bruce and Agnes/Martha is much stronger. We can see that by thinking about their motivations.\nWhy would Bruce go to the gallery? Not for pleasure; he’ll get more pleasure out of playing video games with his friends. Not for the educational value; he won’t learn more by looking at these kind of paintings again. His only reason for going is that he thinks it might increase his welfare. That is, he can only be motivated to go if he is motivated to care about welfare as such, and not about the things that make up welfare. There is something perverse about this motivation. It is healthy and natural to want the things that make up a good life. It is less healthy, and less natural, to directly desire a good life whatever that may be.\nNow think about Martha. Why should she turn down the steak? Not because she values the interests of the cow over her dining. She does not. And not because she should have that value. By hypothesis, she need not do so. (Remember we’re only interested in replying to people who argue from The ‘Might’ Argument to vegetarianism; if you think there’s a direct argument that Martha should value the cow so highly that she doesn’t eat meat, that’s a different debate.) Rather, she has to care about morality as such. And that seems wrong.\nThe argument I’m making here owes a lot to a similar argument offered for a somewhat different conclusion by Michael Smith (1994). He compared the person who desires to do what is actually right, as he put it, desires the right de re, with the person who desires to do what is right whatever that turns out to be, as he put it, desires the right de dicto.\n\nGood people care non-derivatively about honesty, the weal and woe of their children and friends, the well-being of their fellows, people getting what they deserve, justice, equality, and the like, not just one thing: doing what they believe to be right, where this is read de dicto and not de re. Indeed, commonsense tells us that being so motivated is a fetish or moral vice, not the one and only moral virtue.  (Smith 1994, 75)\n\nI think that’s all true. A good person will dive into a river to rescue a drowning child. (Assuming that is that it is safe enough to do so; it’s wrong to create more rescue work for onlookers.) And she won’t do so because it’s the right thing to do. She’ll do it because there’s a child who needs to be rescued, and that child is valuable.\nThe analogy with the welfare case strengthens this conclusion. The rational person values their health, happiness and friendships (and whatever goes into the actual list of things that constitute welfare.). They don’t simply value their welfare, and desire to increase it. That’s why it would be perverse for Bruce to go to the gallery. He would only go if he had a strange motivation. And it is why it would be perverse for Martha to turn down the steak. To do so she would have to care about morality, whatever it is, not about the list of things that Smith rightly says a good person will care about.\n\n\n0.5 An Alternative Analogy\nMoller offers the following analogy to back up something like the ‘Might’ Argument.5\n5 Though note that Moller’s own position is more moderate than what the ‘Might’ Argument suggests; he thinks moral risk should play a role in reasoning, but not necessarily so strong a role as to make the ‘Might’ Argument go through. I’m advocating what he calls the “extreme view, we never need to take moral risk into account; it is always permissible to take moral risks.” (435).}\nSuppose Frank is the dean of a large medical school. Because his work often involves ethical complications touching on issues like medical experimentation and intellectual property, Frank has an ethical advisory committee consisting of 10 members that helps him make difficult decisions. One day Frank must decide whether to pursue important research for the company in one of two ways: plan A and plan B would both accomplish the necessary research, and seem to differ only to the trivial extent that plan A would involve slightly less paperwork for Frank. But then Frank consults the ethics committee, which tells him that although everyone on the committee is absolutely convinced that plan B is morally permissible, a significant minority - four of the members - feel that plan A is a moral catastrophe. So the majority of the committee thinks that the evidence favors believing that both plans are permissible, but a significant minority is confident that one of the plans would be a moral abomination, and there are practically no costs attached to avoiding that possibility. Let’s assume that Frank himself cannot investigate the moral issues involved - doing so would involve neglecting his other responsibilities. Let’s also assume that Frank generally trusts the members of the committee and has no special reason to disregard certain members’ opinions. Suppose that Frank decides to go ahead with plan A, which creates slightly less paperwork for him, even though, as he acknowledges, there seems to be a pretty significant chance that enacting that plan will result in doing something very deeply wrong and he has a virtually cost-free alternative. (436)\n\nThe intuitions are supposed to be that this is a very bad thing for Frank to do, and that this illustrates that there’s something very wrong with ignoring moral risk. But once we fill in the details of the case, it is clear that this can’t be the right diagnosis.\nThe first thing to note is that there is something special about decision making as the head of an organization. Frank doesn’t just have a duty to do what he thinks is best. He has a duty to reflect his school’s policies and viewpoints. A dean is not a dictator, not even an enlightened, benevolent one. Not considering an advisory committee’s report is bad practice qua dean of the medical school, whether or not Frank’s own decisions should be guided by moral risk.\nWe aren’t told whether A or B are moral catastrophes. If B is a moral catastrophe, and A isn’t, there’s something good about what Frank does. Of course, he does it for the wrong reasons, and that might undercut our admiration of him. But it does seem relevant to our assessment to know whether A or B are actually permissible.\nAssuming that B is actually permissible, the most natural reading of the case is that Frank shouldn’t do A. Or, at least, that he shouldn’t do A for this reason. But that doesn’t mean he should be sensitive to moral risk. Unless the four members who think that A is a moral catastrophe are crazy, there must be some non-moral facts that make A morally risky. If Frank doesn’t know what those facts are, then he isn’t just making a decision under moral risk, he’s making a decision involving physical risk. And that’s clearly a bad thing to do.\nIf Frank does know why the committee members think that the plan is a moral catastrophe, his action is worse. Authorising a particular kind of medical experimentation, when you know what effects it will have on people, and where intelligent people think this is morally impermissible, on the basis of convenience seems to show a striking lack of character and judgment. Even if Frank doesn’t have the time to work through all the ins and outs of the case, it doesn’t follow that it is permissible to make decisions based on convenience, rather than based on some (probably incomplete) assessment of the costs and benefits of the program.\nBut having said all that, there’s one variant of this case, perhaps somewhat implausible, where it doesn’t seem that Frank should listen to the committee at all. Assume that both Frank and the committee have a fairly thick understanding of what’s involved in doing A and B. They know which actions maximise expected utility, they know that which acts are consistent with the categorical imperative, they know which people affected by the acts would be entitled to complain about our performance, or non-performance, of each act, they know which acts are such that everyone could rationally will it to be true that everyone believes those acts to be morally permitted, and so on. What they disagree about is what rightness and wrongness consist in. What’s common knowledge between Frank, the majority and the minority is that both A and B pass all these tests, with one exception: A is not consistent with the categorical imperative. And the minority members of the committee are committed Kantians, who think that they have a response to the best recent anti-Kantian arguments.\nIt seems to me, intuitively, that this shouldn’t matter one whit. I think the extreme view I’m defending in this paper is not, in general, intuitive. But it is worth noting how counterintuitive the opposing view is in this extreme case. A moral agent simply won’t care what the latest journal articles have been saying about the relative importance of Kant’s formulation of the categorical imperative versus either contemporary variants or approaches from very different traditions. It’s possible (though personally I doubt it), that learning of an action that it violates the categorical imperative would be relevant to one’s motivations. It’s not possible that learning that some people you admire think the categorical imperative is central to morality could change one’s motivation to perform, or not perform, actions one knew all along violated the categorical imperative. At least that’s not possible without falling into the bad kind of moral fetishism that Smith rightly decries.\nSo here’s my general response to analogies of this kind, one that shouldn’t be surprising given the previous sections. Assuming the minority committee members are rational, either they know some facts about the impacts of A and B that Frank is unaware of, or they hold some philosophical theory that Frank doesn’t. If it’s the former, Frank should take their concerns into account; but that’s not because he should be sensitive to moral risk, it’s because he should be sensitive to non-moral risk. If it’s the latter, Frank shouldn’t take their concerns into account; that would be moral fetishism.\n\n\n0.6 Objections and Replies\nI’ve discussed this paper with many people, and they almost all have objections. I’m going to respond to some of the most pressing, and end with three objections that I don’t have a particularly satisfying response to. The most important objection, from my perspective, is the second; it’s what most closely links the discussion of this paper to the broader issues about normative externalism that I find most fascinating.\nObjection: All you’ve shown so far is that moral recklessness isn’t objectively wrong. But that’s trivial. There’s a sense in which ordinary recklessness isn’t objectively wrong either. What matters is that both are subjectively wrong, where this tracks what the agent believes.\nReply: Distinguish between two things: doing things that produce bad outcomes, and doing the wrong thing. Unless you are sure that actualist consequentialism is a conceptual truth, this is a conceptually coherent distinction. Among actions that produce bad outcomes, there are easily detectable distinctions we draw that seem to track whether the actions are wrong.\nIn the paper so far I’ve usually been focussed on people who are almost certain of the truth. But let’s change tack for a minute and look at people who have catastrophically false beliefs. In particular, consider Hannah and Hannibal. (I’m taking the Hannibal example from work by Elizabeth Harman (2011), who uses it for a related purpose.)\nHannah takes her spouse out for what is meant to be a pleasant anniversary dinner. It’s a nice restaurant, and there’s no reason to think anything will go wrong. But the restaurant gets bad supplies that day, and Hannah’s spouse gets very sick as a consequence of going there.\nHannibal is a 1950s father with sexist attitudes that were sadly typical. He has a son and a daughter, and makes sure to put together a good college savings fund for his son, but does not do the same for his daughter. Indeed, if he had tried to do the same for his daughter, he would not have been able to support his son as well as he actually did. As a consequence, his daughter cannot afford to go to college.\nHannah was mistaken about a matter of fact; whether the food at the restaurant was safe. Hannibal was mistaken about a moral matter; whether one should treat one’s sons and daughters equally. Now consider what happens when both see the error of their ways. Hannah should feel bad for her spouse, but there is no need for any kind of self-reproach. It’s hard to imagine she would feel ashamed for what she did. And there’s no obligation for her to feel guilty, though it’s easier to imagine she would feel some guilt. Hannibal, on the other hand, should feel both ashamed and guilty. And I think it’s natural that a father who realised too late that he had been guilty of this kind of sexism would in fact feel the shame and guilt he should feel. The fact that his earlier sexist attitudes were widely shared, and firmly and sincerely held, simply seems irrelevant here.\nThe simplest explanation of this emotional difference is that what Hannibal does is, in an important sense, wrong, and what Hannah does is not wrong. But the wrongness at issue is missing from the objective/subjective distinction the objector here makes. Both Hannah and Hannibal do things that make things objectively worse. Both Hannah and Hannibal do things that are good given their beliefs at the time they act. Yet there is a distinction between them. It’s this distinction that the normative externalist wants to stress. There’s a normative status that is not wholly objective, insofar as it doesn’t reproach Hannah, but not wholly subjective, insofar as it does reproach Hannibal.\nObjection: But still, we need a standard that can guide the agent, that an agent can live by. Do the right thing, whatever it turns out to be, is not such a standard. And what motivates internalism is the thought that this kind of agent-centred norm is most important.\nReply: If this is the motivation for internalism, it is vulnerable to a nasty regress. The problem is that internalists disagree amongst themselves, and there is no internalist-friendly way to resolve the disagreement.6 (Much of what I say here draws on arguments that Elizabeth Harman (2015) makes about the nature of internalist norms.)\n6 In Weatherson (2013) I make a similar objection to normative internalism in epistemology. It’s this point of connection that’s made me focus on normative internalism and externalism, not moral internalism and externalism. The issues in ethics and in epistemology are very closely connected here.The examples that illustrate this point are a little convoluted, so I’ll just state one example schematically to make the point. And I’ll put numerical values on options because it is hard to state the internalist views without doing this.\nAn agent faces a choice between four options: A, B, C and D. Option A is the right option, both in the sense that the externalist will praise people who take it and criticise others, and in the sense that a fully informed intrnalist would do A. But our agent is, sadly, not fully informed. She thinks A is a completely horrible thing do to. Her credences are split over three moral theories, X, Y and Z, with credence 0.5 in X, 0.1 in Y, and 0.4 in Z. The moral values of each action according to each moral theory are given by this table. (Higher values are better; non-negative values are for actions that are permissible according to the theory.)\n@RCCC@ &X&Y&Z\nB&0&0&–20\nC&0&–30&–10\nD&–1&–5&0\n\nSo the probability, according to the agent, that each action is permissible is 0.6 for B, 0.5 for C and 0.4 for D. The expected moral value of each action is –8 for B, –7 for C, and –2 for D.\nOur agent at this stage is a bit confused. And reading some philosophy doesn’t help. She reads Ted Lockhart (2000) saying that what she should do is the thing that is most probably permissible. And she reads Andrew Sepielli (2009) saying that what she should do is the thing that maximises expected moral value. But these pieces of advice pull in opposite directions. She could try and come up with a theory of how to resolve the tension, but that is just as hard as resolving the dispute between Lockhart and Sepielli in the first place. She eventually settles on the rule Don’t do what any plausible meta-theory says is the worst thing to do. Since Lockhart says D is the worst thing to do (having the lowest probability of permissibility), and Sepielli says that B is the worst thing to do (having the lowest expected moral value), she does C.\nHere’s the lesson of this little parable. There is a worry that externalism is not sufficiently action guiding, and can’t be a norm that agents can live by. But any philosophical theory whatsoever is going to have to say something about how to judge agents who ascribe some credence to a rival theory. That’s true whether the theory is the first-order theory that Jeremy Bentham offers, or the second-order theory that Andrew Sepielli offers. Once you’re in the business of theorising at all, you’re going to impose an external standard on an agent, one that an agent may, in good faith and something like good conscience, sincerely reject. The externalist says that it’s better to have that standard be one concerned with what is genuinely valuable in the world, rather than a technical standard about resolving moral uncertainty. But every theorist has to be a little bit externalist; the objector who searches for a thoroughly subjective standard is going to end up like Ponce de Leon.\nObjection: You’ve focussed on the case where Martha is almost sure that meat-eating is permissible. What do we say about the person who is almost sure that meat-eating is impermissible, eats meat anyway, and gets lucky, because they are in a world where it is permissible? The normative externalist says that they are beyond reproach, but something seems wrong here.\nReply: The externalist is only committed to the view that the most important evaluative concepts are independent of the agent’s beliefs. There is something rather simple to say about this person; they are a hypocrite.\nObjection: Wait a minute! We wanted something reproachful to say about this person. But all you’ve said is that they are a hypocrite, by which you presumably mean they don’t act in accord with their beliefs about what’s valuable. And Huckleberry Finn is a hypocrite in that sense, but also beyond reproach.\nReply: Good point, but I think we can still say something. Huckleberry Finn acts against what he believes to be most valuable in order to preserve a great good: Jim’s freedom. Our imagined meat-eater acts against what he believes to be most valuable in order to get a tastier lunch. Someone who will do what they believe to be wrong in order to produce a gain which is both trivial, and entirely accrues to them, reveals a bad character. The gain that Huckleberry Finn’s actions produce, note, are neither trivial nor selfish, and that’s why his actions do not indicate a character defect. But giving up on morality for a trivial, selfish gain is a sign that things will go very badly wrong, very soon.7\n7 The Huckleberry Finn case has been discussed extensively by Nomy Arpaly and Timothy Schroeder  (Arpaly 2002, 2003; Arpaly and Schroeder 1999, 2014), and I’m relying heavily on their analysis of the case in what I say here and elsewhere about Huckleberry Finn. More generally, the picture I’m assuming of moral motivation owes a lot to those works.Objection: How can you even acknowledge such a thing as hypocrisy? Isn’t the positing of such a norm vulnerable to the same regress arguments as you’ve run against the internalist?\nReply: No, because we can be an externalist about what is and is not hypocritical. We can, at least in theory, imagine these two cases. The first case is a person whose beliefs, credences and values indicate that the best thing to do is B, but who thinks the best thing to do given those beliefs, credences and values is C. They do C. They are hypocritical, although they (falsely) do not believe they are. The second case is a person who is exactly like this, except they do B. They are not acting hypocritically. Or, at least, they are not a first-order hypocrite. Perhaps we can recognise a distinct state of second-order hypocrisy, and say that they fall under it. And you can imagine even higher-orders. The externalist can say all of these exist. They aren’t the worst offences ever, but it is coherent to posit all of them.\nObjection: Once you recognise hypocrisy, there is a way to reinstate the ‘Might’ Argument. Martha and Agnes are hypocrites. They shouldn’t be hypocrites. So they shouldn’t eat meat, or have an abortion.\nReply: I simply deny that they are hypocrites. Compare these three statuses.\n\nDoing that which you disvalue.\nDoing that which you believe to be less valuable.\nDoing that which you have some credence is less valuable.\n\nThe first is clearly hypocrisy, and the second seems similar. But there’s no reason to say the third is hypocritical. The following example, closely modelled on one offered by Lara Buchak (2014) makes this point.\nAnnie values her close relationship with her brother Jack. One day, she receives some evidence that marginally raises her credence that Jack did something horrible. She is pretty sure Jack is innocent, but her credence in his guilt does rise a notch. Still, Annie values her relationship with Jack just as much as she did before. If Jack did the horrible thing, she would not value the relationship. But getting some (almost surely misleading) evidence that Jack did something horrible does not change her values at all.\nThe lesson here is that credences about what is valuable can quite coherently float free from valuings. There is a tricky question about what happens to beliefs about what is valuable in these cases. Buchak thinks they should go with valuings, and this is a problem for theories that reduce credence to belief. I don’t agree with this extension of her argument, but I certainly agree that small changes in credence about what is valuable need not, and often should not, change what one values.\nObjection: The externalist can’t explain why moral ignorance exculpates.\nReply: The short reply is that, following for example Elizabeth Harman (2011), I don’t think moral ignorance does exculpate. But the longer reply is that the internalist can’t explain why moral ignorance is at best an excuse, not a defence, and why it only works in special circumstances.\nWe already saw one distinctive aspect of moral ignorance above, in the Hannibal example. Hannibal should feel ashamed, and guilty, about what he did. That’s because even if he had an excuse, he did the wrong thing. And this doesn’t just mean he made the world worse. This notion of wrongness is an externalist one, even if we allow an internalist friendly excuse for the wrong action.\nBut when we turn to classic defenders of the idea that moral ignorance can be exculpatory, such as Susan Wolf (1980) and Cheshire Calhoun (1989), we see that it is meant to be an excuse with a very limited scope. And whether the circumstances are such as to furnish this excuse will not always be clear to the wrong-doer. (Indeed, it might be that they are not, and could not, be clear.) So even if moral ignorance was exculpatory, this wouldn’t be much help to the internalist. Since on everyone’s view some moral ignorance is blameworthy, and the factors that may make moral ignorance an excuse are external to the agent, only the externalist can offer a plausible theory on which moral ignorance is exculpatory.\nObjection: Even if it is fetishistic to be motivated by the good as such, this doesn’t extend to thick moral properties. Indeed, the quote from Smith you use explicitly contrasts the thinnest of moral properties with ever so slightly thicker ones. So your objections to arguments from moral uncertainty don’t extend to arguments from what we might call virtue uncertainty.\nReply: I agree with this. Here are some things that seem like be non-fetishistic motivations to avoid doing action A.\n\nIt would be cowardly to do A.\nDoing A would be free-riding.\nI would not appreciate if others did A-like actions that could disadvantage me.\n\nThe objector draws attention to the distinction between thick and thin moral properties, and I think that’s the right way to highlight what’s at issue here. But note how thin these are getting. I’m conceding that the fact that something violates the Golden Rule could be a motivation, as could the fact that it violates the categorical imperative.8 What I deny is that the wrongness of the action could be an extra motivation over and above these. This was the point of the discussion of Moller’s executive in the previous section.\n8 To be clear, I’m conceding that these motivations are consistent with the argument of the paper. My own view is that while realising that something violates the Golden Rule could be a motivation, as is evident from how we teach morality to children, realising that it violates the categorical imperative should not be motivating. But the argument of the paper doesn’t turn on my quirky views here. What matters is that we distinguish wrongness itself from properties like harming another person, not what other properties we group in with wrongness.For each of these motivations, there are cases where the risk of violating the relevant standard can be motivating. So one might not do something because there is a risk that it would be cowardly, or free-riding, or violate the Golden Rule or categorical imperative. I don’t mean to object to any argument along these lines.\nObjection: Now you’ve conceded that a version of the ‘Might’ Argument can work. After all, there are vices that might be manifest by eating meat or having an abortion.\nReply: True, but the fact that some action might manifest a vice can hardly be a decisive consideration against doing it. If the vice in question is relatively small, or the chance of manifesting it is relatively small, it is easy to see how this kind of consideration could be overridden.\nFor instance, imagine an argument for vegetarianism as follows. Eating meat you haven’t killed yourself might be cowardly. It certainly isn’t obvious that letting someone else do the dirty work isn’t a manifestation of cowardice. So that’s a reason to not eat meat. I can grant it is a reason while thinking that (a) this kind of cowardice isn’t a particularly heinous vice, and (b) it isn’t that likely that meat eating is really cowardly in this way, so the reason is a relatively weak one, that can easily be overridden.\nBut the concession I want to make is that there could be an argument along these lines that works. In earlier presentations of this paper, I’d tried to extend my argument to respond to the arguments Alex Guerrero (2007) makes for vegetarianism. But I’m no longer sure that was a good idea. But I think Guerrero’s arguments can be understood in such a way that they rely only on the idea that we shouldn’t risk instantiating certain particular vices. And I don’t have a systematic objection to every argument of this form. After all, I do think we have a reason to avoid running a risk of being free-riders, or cowards, even if the action under consideration would not be cowardly, or an act of free-riding.\nObjection: Even without getting into debates about moral uncertainty, there are other uncertainty arguments against meat eating or abortion. There is some probability that cows or foetuses have souls, and it is a very serious harm to kill something that has a soul.\nReply: Nothing I say here helps respond to this argument. If one thinks that what’s wrong with killing is that it kills a soul, thinks that there’s a non-trivial chance that cows or foetuses have souls, and eats meat or has an abortion anyway, then one really is being immoral. Whether this should be called recklessness is tricky, since one could understand ‘recklessness’ as being concerned only with risks that are in a certain sense objective. But it certainly seems that such a person would be morally on a par with the people I’ve said are immoral in virtue of the risks they pose to others. It’s an empirical question, and one I don’t have any good evidence about, whether arguments from uncertainty about abortion and meat eating primarily concern uncertainty about facts, as this objection suggests, uncertainty about virtues (broadly construed) as the previous objection suggests, or uncertainty about right and wrong.\nObjection: It may be wrong to be only concerned with right and wrong, but it isn’t wrong to have this be one of your considerations.\nReply: I don’t think you get the ‘Might’ Argument to work unless concern with right and wrong, whatever they turn out to be, are the only considerations. Assume that they are only one consideration among many. Then even if they point in one direction, they may be overridden by the other considerations. And if the ‘Might’ Argument doesn’t work, then normative internalism, in its strongest forms, is false. So I really only need to appeal to the plausible view that right and wrong as such shouldn’t be our only motivations to get the conclusions I want.\nBut actually I think the stronger, prima facie implausible, view is true: rightness and wrongness as such shouldn’t even be part of our motivation. My reasons for thinking this are related to my responses to the next three objections. Unfortunately, these are the least developed, and least satisfying, of the responses I’ll offer. But I’ll conclude with them to leave you with a sense of where I think the debate is at, and what I think future research could assist with.\nObjection: Here’s one occasion where we do seem motivated by the good as such, or by welfare as such – when we’re doing moral or prudential reflection. Sometimes we stop and think, What would be the best thing to do in a certain kind of case? In philosophy departments, people might do that solely because they’re interested in the answer. But most people will think that these projects have some practical consequences. And the strong form of Smith’s fetishism objection that you’re relying on can’t explain why this is a good practice.\nReply: I agree this is a good practice. But I think it is consistent with what I’ve said so far. Start with an observation also by Michael Smith, that moral inquiry has “a certain characteristic coherentist form”  (Smith 1994, 40–41). I think (not originally) that this is because we’re not trying to figure out something about this magical thing, the good, but rather because we’re trying to systematise and where necessary reconcile our values. When we’re doing moral philosophy, we’re often doing work that more at the systematising end, trying to figure out whether seemingly disparate values have a common core. When we’re trying to figure out what is right in the context of deciding what to do, we’re often trying to reconcile, where possible, conflicting values. But as long as we accept that there are genuinely plural values, both in moral and prudential reasoning, we shouldn’t think that a desire to determine what is right is driven by a motivation to do the right thing, or to live a good life, as such.\nObjection: Sometimes people act from moral conscience. At least by their own account, they do something that involves no small amount of personal sacrifice because it is the right thing to do. And, at least some of the time, these people are highly praiseworthy. The strong version of the fetishism objection you’re using can’t account for this.\nObjection: So I have to bite some bullets here. I have to offer a slightly unnatural reformulation of these cases. In particular, in cases where someone acts from conscience, I have to say that there is something they value greatly, and they are acting on that value. What the value is will depend on the case. It might be welfare, or freedom, or keeping promises, or justice. It might even, and this is the version of the case that’s trickiest for me, be a value they can’t clearly articulate. A person can know something is the right thing to do and not be in any position to say why it is the right thing to do. And they may do it, even at great sacrifice. I think I’m required to say here that their motivation is the feature of the act that makes it right, not the rightness of the act. That’s not optimal, especially since it isn’t how the agent themself would describe the motivation. But I don’t think we should assume that agents have perfect access to their own motivations.\nI take myself to be here largely in agreement with a line suggested by Sigrún Svavarsdóttir (1999) when she says, in defence of an externalist theory of moral motivation.\n\nThe externalist account I propose does not ascribe to the good person a particular concern with doing the right thing. Rather it ascribes to him a more general concern with doing what is morally valuable or required, when that might include what is just, fair, honest, etc.  (Svavarsdóttir 1999, 197–98)\n\nThere are two points here that are particularly relevant to the current project. The good person has a plurality of motivations, not just one. And the fetishism argument really has a very narrow application: it really only works against theories which say goodness is a matter of having the thinnest of possible moral motivations. It’s odd to be solely concerned with doing the right thing as such. (It’s even odd, I say, to have this as one of your concerns, though that’s not central to my argument.) It’s not odd to have fairness as one of one’s concerns, even an important one. Svavarsdóttir suggests that once the range of the fetishism argument is restricted in this way, it can’t do the work that Smith needs it to do in his attack on motivational externalism. I don’t need to take a stand on this, since I’m not taking sides in the debate between motivational externalists and internalists. All I need is that Smith’s objection to fetishism can work, as long as it is suitably restricted.\nObjection: Is there any coherent meta-ethical view that can licence all the moves you’ve made? On the one hand, normative claims must be distinctive enough that uncertainty about them has a very different effect on deliberation and motivation than everyday factual claims. On the other hand, your externalism is the view that the moral facts matter more than anyone’s (reasonable) beliefs about the moral facts. The first consideration suggests a strong kind of moral anti-realism, where moral claims are different in kind to factual claims. But the second suggests a strong kind of moral realism, where there are these wonderful moral facts around to do the work that reasonable moral beliefs cannot do. Is this even consistent? And if it is, is there a meta-ethical view we should want to hold consistent with all of it?\nReply: The inconsistency charge isn’t, I think, too hard to meet. As long as the ‘facts’ that I talk about when I say the moral facts matter are construed in an extremely deflationary way, then I’m not being inconsistent. Any kind of sophisticated expressivist or quasi-realist view that allows you to talk about moral facts, while perhaps not meaning quite the same thing by ‘fact’ as a realist does, will be consistent with everything I’ve said.\nThe second challenge is harder, and I don’t know that I have a good response. I would like to make the theory I’ve presented here consistent with a fairly thoroughgoing moral realism, and I’m not sure that’s possible. (I’d like to do that simply because I don’t want the fate of the theory tied up with contentious issues in meta-ethics.) I think the way to make the view consistent with this kind of realism is to defend the view that neither the metaphysical status of a truth (as necessary or contingent, analytic or synthetic, and so on) has very little to do with its appropriate role in deliberation or evaluation. But defending that, and showing how it suffices to make moral cognitivism consistent with the view I’m describing, is more than I know how to do now.\n\n\n\n\n\n\nReferences\n\nArpaly, Nomy. 2002. “Moral Worth.” Journal of Philosophy 99 (5): 223–45. https://doi.org/10.2307/3655647.\n\n\n———. 2003. Unprincipled Virtue. Oxford: Oxford University Press.\n\n\nArpaly, Nomy, and Timothy Schroeder. 1999. “Praise, Blame and the Whole Self.” Philosophical Studies 93 (2): 161–88. https://doi.org/10.1023/A:1004222928272.\n\n\n———. 2014. In Praise of Desire. Oxford: Oxford University Press.\n\n\nBuchak, Lara. 2014. “Belief, Credence and Norms.” Philosophical Studies 169 (2): 285–311. https://doi.org/10.1007/s11098-013-0182-y.\n\n\nCalhoun, Cheshire. 1989. “Responsibility and Reproach.” Ethics 99 (2): 389–406. https://doi.org/10.1086/293071.\n\n\nFinnis, John. 2011. Natural Law and Natural Rights. Second. Oxford: Oxford University Press.\n\n\nFodor, Jerry. 2000. “It’s All in the Mind: Noam Chomsky and the Arguments for Internalism.” Times Literary Supplement 23 June: 3–4.\n\n\nGuerrero, Alexander. 2007. “Don’t Know, Don’t Kill: Moral Ignorance, Culpability and Caution.” Philosophical Studies 136 (1): 59–97. https://doi.org/10.1007/s11098-007-9143-7.\n\n\nHarman, Elizabeth. 2011. “Does Moral Ignorance Exculpate?” Ratio 24 (4): 443–68. https://doi.org/10.1111/j.1467-9329.2011.00511.x.\n\n\n———. 2015. “The Irrelevance of Moral Uncertainty.” Oxford Studies in Metaethics 10: 53–79. https://doi.org/10.1093/acprof:oso/9780198738695.003.0003.\n\n\nLockhart, Ted. 2000. Moral Uncertainty and Its Consequences. Oxford University Press.\n\n\nMalmgren, Anna-Sara. 2011. “Rationalism and the Content of Intuitive Judgements.” Mind 120 (478): 263–327. https://doi.org/10.1093/mind/fzr039.\n\n\nMoller, D. 2011. “Abortion and Moral Risk.” Philosophy 86 (3): 425–43. https://doi.org/10.1017/S0031819111000222.\n\n\nSepielli, Andrew. 2009. “What to Do When You Don’t Know What to Do.” Oxford Studies in Metaethics 4: 5–28.\n\n\nSmith, Michael. 1994. The Moral Problem. Oxford: Blackwell.\n\n\nSvavarsdóttir, Sigrún. 1999. “Moral Cognition and Motivation.” Philosophical Review 108 (2): 161–219. https://doi.org/10.2307/2998300.\n\n\nWeatherson, Brian. 2013. “Disagreements, Philosophical and Otherwise.” In The Epistemology of Disagreement: New Essays, edited by David Christensen and Jennifer Lackey, 54–73. Oxford: Oxford University Press.\n\n\nWilliamson, Timothy. 2007. The Philosophy of Philosophy. Blackwell.\n\n\nWolf, Susan. 1980. “Asymmetrical Freedom.” Journal of Philosophy 77 (3): 151–66. https://doi.org/10.2307/2025667."
  },
  {
    "objectID": "posts/ipacp/index.html",
    "href": "posts/ipacp/index.html",
    "title": "Intrinsic Properties and Combinatorial Principles",
    "section": "",
    "text": "Three objections have recently been levelled at the analysis of intrinsicness in Rae Langton and David Lewis’s “Defining ‘Intrinsic’”. Yablo (1999) has objected that the theory rests on “controversial and (apparently) irrelevant” judgements about the relative naturalness of various properties. Dan Marshall and Josh Parsons Marshall and Parsons (2001) have argued that quantification properties, such as being accompanied by an cube, are counterexamples to Langton and Lewis’s theory. And Theodore Sider Sider (2001) has argued that maximal properties, like being a rock, provide counterexamples to the theory. In this paper I suggest a number of amendments to Langton and Lewis’s theory to overcome these counterexamples. The suggestions are meant to be friendly in that the basic theory with which we are left shares a structure with the theory proposed by Langton and Lewis. However, the suggestions are not meant to be ad hoc stipulations designed solely to avoid theoretical punctures, but developments of principles that follow naturally from the considerations adduced by Langton and Lewis.\n\nPublished in Philosophy and Phenomenological Research 63: 365-380.\nThanks to David Lewis, Europa Malynicz, Dan Marshall, Daniel Nolan, Josh Parsons and Ted Sider for helpful discussions.\nPicture by Bernard Spragg via Creative Commons.\n\n\n0.1 Langton and Lewis’s Theory\nLangton and Lewis base their theory on a combinatorial principle about intrinsicness. If a property F is intrinsic, then whether a particular object is F is independent whether there are other things in the world. This is just a specific instance of the general principle that if F is intrinsic then whether some particular is F is independent of the way the rest of the world is. So if F is intrinsic, then the following four conditions are met:\n\nSome lonely object is F;\nSome lonely object is not-F;\nSome accompanied object is F; and\nSome accompanied object is not-F.\n\nThe quantifiers in the conditions range across objects in all possible worlds, and indeed this will be the quantifier domain in everything that follows (except where indicated). An object is ‘lonely’ if there are no wholly distinct contingent things in its world. The effect of including ‘distinct’ in this definition is that an object can be lonely even if it has proper parts; an object is not identical with its parts, but nor is it distinct from them. Following Langton and Lewis, I will say that any property that meets the four conditions is ‘independent of accompaniment’.\nAll intrinsic properties are independent of accompaniment, but so are some extrinsic properties. For example, the property being the only round thing is extrinsic, but independent of accompaniment. So Langton and Lewis do not say that independence of accompaniment is sufficient for intrinsicness. However, within a certain class of properties, what we might call the basic properties, they do say that any property independent of accompaniment is intrinsic. A property is basic if it is neither disjunctive nor the negation of a disjunctive property. Langton and Lewis define the disjunctive properties as follows:\n\n[L]et us define the disjunctive properties as those properties that can be expressed by a disjunction of (conjunctions of) natural properties; but that are not themselves natural properties. (Or, if naturalness admits of degrees, they are much less natural than the disjuncts in terms of which they can be expressed.) Langton and Lewis (2001)\n\nLangton and Lewis assume here that there is some theory of naturalness that can be plugged in here, but they are explicitly ecumenical about what the theory may be. They mention three possibilities: naturalness might be primitive; it might be defined in terms of which universals and tropes exist, if you admit such into your ontology; or it might be defined in terms of which properties play a special role in our theory. Call the first the primitivist conception, the second the ontological conception, and the third the pragmatic conception. (One can generate different versions of the pragmatic theory by altering what one takes to be ‘our theory’. In Taylor (1993), which Langton and Lewis credit as the canonical statement of the pragmatic conception, naturalness is relativised to a theory, and the theories he focuses on are ‘regimented common sense’ and ‘unified science’.) Langton and Lewis’s intention is to be neutral as to the correct interpretation of naturalness whenever they appeal to it, and I will follow their policy.\nWith these concepts, we can now define intriniscness. A property is basic intrinsic iff it is basic and independent of accompaniment. Two objects are duplicates iff they have the same basic intrinsic properties. And a property is intrinsic iff there are no two duplicates that differ with respect to it.\nLangton and Lewis make one qualification to this definition: it is only meant to apply to pure, or qualitative, properties, as opposed to impure, or haeccceitistic, properties. One reason for this restriction is that if there are any impure intrinsic properties, such as being John Malkovich, they will not have the combinatorial features distinctive of pure intrinsic properties. If F is a pure intrinsic property then there can be two wholly distinct things in a world that are F. This fact will be crucial to the revised definition of intrinsicness offered below. However, it is impossible to have wholly distinct things in the same world such that each is John Malkovich. So for now I will follow Langton and Lewis and just say what it takes for a pure property to be intrinsic. As Langton and Lewis note, it would be nice to complete the definition by giving conditions under which impure properties are intrinsic, but the little task of working out the conditions under which pure properties are intrinsic will be hard enough for now.\n\n\n0.2 Three Objections\nStephen Yablo (Yablo 1999) criticises the judgements of naturalness on which this theory rests. Consider again the property being the only round thing, which is extrinsic despite being independent of accompaniment. If Langton and Lewis are right, this must not be a basic property. Indeed, Langton and Lewis explicitly say that it is the negation of a disjunctive property, since its negation can be expressed as: being round and accompanied by a round thing or being not-round. Yablo’s criticism is that it is far from obvious that the existence of this expansion shows that being the only round thing is disjunctive. For simplicity, let us name all the salient properties: \\[\\begin{aligned}\n\\textit{R}&=\\textsubscript{df}~\\textit{being the only round thing} \\\\\n\\textit{S}&=\\textsubscript{df}~\\textit{being not the only round thing}\\\\\n\\textit{T}&=\\textsubscript{df}~\\textit{being round and accompanied by a round thing}\\\\\n\\textit{U}&=\\textsubscript{df}~\\textit{being not\\nobreakdash-round}\\end{aligned}\\]\n(Something is accompanied by an F iff one of its distinct worldmates is F.) Langton and Lewis claim that since S = T \\({\\vee}\\) U, and S is much less natural than T and than U, S is disjunctive, so R is not basic. Yablo notes that we can also express S as being round if accompanied by a round thing, so it differs from T only in that it has an if where T has an and. Given this expansion, we should be dubious of the claim that S is much less natural than T. But without that claim, R already provides a counterexample to Langton and Lewis’s theory, unless there is some other expression of R or S that shows they are disjunctive.1\n1 It would be no good to say that Langton and Lewis should be more liberal with their definition of disjunctiveness, and say instead that a property is disjunctive iff it can be expressed as a disjunction. Any property F can be expressed as the disjunction F and G or F and not G, or for that matter, F or F, so this would make every property disjunctive.\nI do not want to dismiss out of hand the possibility that there is another expression of S that shows it is disjunctive. Josh Parsons suggested that if we define T\\(^\\prime\\) to be being accompanied by a round thing, then S is T\\(^\\prime\\) \\({\\vee}\\) U, and there is some chance that T\\(^\\prime\\) is more natural than S on some conceptions of naturalness. So we cannot derive a decisive counterexample from Yablo’s discussion. Still, Langton and Lewis need it to be the case that on any account of naturalness, there is an expression that shows S or R to be disjunctive, and unless T\\(^\\prime\\) is much more natural than S on all conceptions of naturalness, this task is still far from complete.Dan Marshall and Josh Parsons Marshall and Parsons (2001) argue that the same kind of difficulties arise when we consider certain kinds of quantificational properties. For example, let E be the property being such that a cube exists. This is independent of accompaniment, since a lonely cube is E, a lonely sphere is not E, each of us is accompanied and E, and each of Max Black’s two spheres is accompanied and not E. So it is a counterexample to Langton and Lewis if it is basic. Marshall and Parsons note that, like all properties, it does have disjunctive expressions. For example x is E iff x is a cube or x is accompanied by a cube. And E is a less natural property than being a cube. But it is not at all intuitive that E is much less natural than the property being accompanied by a cube. This does not just show that Langton and Lewis have to cease being ecumenical about naturalness, because on some conceptions of naturalness it is not clear that E is much less natural than being accompanied by a cube. Rather, this example shows that there is no conception of naturalness that could play the role that Langton and Lewis want. The properties E and being accompanied by a cube seem just as natural as each other on the ontological conception of naturalness, on the pragmatic conception of naturalness, and, as far as anyone can tell, on the primitivist conception. This is not because E is particularly natural on any of these conceptions. It certainly does not, for example, correspond to a universal, and it does not play a special role in our thinking or in ideal science. But since there is no universal for being accompanied by a cube, and that property does not play a special role in our thinking or in ideal science, it seems likely that each property is as natural as the other.\nTheodore Sider (2001) notes that similar problems arise for maximal properties, like being a rock. A property F is maximal iff large parts of Fs are typically not Fs. For example, being a house is maximal; a very large part of a house, say a house minus one window ledge, is not a house, it is just a large part of a house. Purported proof: call the house minus one window ledge house-. If Katie buys the house she undoubtedly buys house-, but she does not thereby buy two houses, so house- is not a house. As Sider notes, this is not an entirely conclusive proof, but it surely has some persuasive force. Maximal properties could easily raise a problem for Langton and Lewis’s definition. All maximal properties are extrinsic; whether a is a house depends not just on how a is, but on what surrounds a. Compare: House- would be a house if the extra window ledge did not exist; in that case it would be the house that Katie buys. But some maximal properties are independent of accompaniment. Being a rock is presumably maximal: large parts of rocks are not rocks. If they were then presumably tossing one rock up into the air and catching it would constitute juggling seventeen rocks, making an apparently tricky feat somewhat trivial. But there can be lonely rocks. A rock from our planet would still be a rock if it were lonely. Indeed, some large rock parts that are not rocks would be rocks if they were lonely. And it is clear there are be lonely non-rocks (like our universe), accompanied rocks (like Uluru) and accompanied non-rocks (like me).\nSince being a rock is independent of accompaniment and extrinsic, it is a counterexample if it is basic. Still, one might think it is not basic. Perhaps being a rock is not natural on the primitivist conception. (Who is to say it is?) And perhaps it does not correspond to a genuine universal, or to a collection of tropes, so it is a disjunctive property on the ontological conception of naturalness. Sider notes, however, that on at least one pragmatic conception, where natural properties are those that play a special role in regimented common sense, it does seem particularly natural. Certainly it is hard to find properties such that being a rock can be expressed as a disjunction of properties that are more central to our thinking than being a rock. So this really does seem to be a counterexample to Langton and Lewis’s theory.\n\n\n0.3 The Set of Intrinsic Properties\nIt is a platitude that a property F is intrinsic iff whether an object is F does not depend on the way the rest of the world is. Ideally this platitude could be morphed into a definition. One obstacle is that it is hard to define the way the rest of the world is without appeal to intrinsic properties. For example, even if F is intrinsic, whether a is F is not independent of whether other objects have the property not being accompanied by an F, which I will call G. To the extent that having G is a feature of the way the rest of the world is, properties like G constitute counterexamples to the platitude. Since platitudes are meant to be interpreted to be immune from counterexamples, it is wrong to interpret the platitude so that G is a feature of the way the rest of the world is. The correct interpretation is that F is intrinsic iff whether an object is F does not depend on which intrinsic properties are instantiated elsewhere in the world.\nIf what I call the independence platitude is to be platitudinous, we must not treat independence in exactly the same way as Langton and Lewis do. On one definition, whether a is F is independent of whether the rest of the world is H iff it is possible that a is F and the rest of the world H, possible that a is not-F and the rest of the world H, possible that a is F and the rest of the world not-H, and possible that a is not-F and the rest of the world not-H. On another, whether a if F is independent of whether the rest of the world is H iff whether a is F is entirely determined by the way a itself, and nothing else, is, and whether the rest of the world is H is determined by how it, and not a, is. This latter definition is very informal; hence the need for the formal theory that follows. But it does clearly differ from the earlier definition in a couple of cases. The two definitions may come apart if F and H are excessively disjunctive. More importantly, for present purposes, they come apart if F is the necessary property (that everything has), or the impossible property (that nothing has). In these cases, whether a is F is entirely settled by the way a, and nothing else is, so in the latter sense it is independent of whether the rest of the world is H. But it is not the case that all four possibilities in the former definition are possible, so it is not independent of whether the rest of the world is H in that sense. Since there is some possibility of confusion here, it is worthwhile being clear about terminology. When I talk about independence here, I will always mean the latter, informal, definition, and I will refer to principles about which combinations of intrinsic properties are possible, principles such as Langton and Lewis’s principle that basic intrinsic properties are independent of accompaniment, as combinatorial principles. So, in the terminology I am using, the combinatorial principles are attempts to formally capture the true, but elusive, independence platitude with which I opened this section.\nSince the platitude is a biconditional with intrinsic on either side, it will be a little tricky to morph it into a definition. But we can make progress by noting that the platitude tells us about relations that hold between some intrinsic properties, and hence about what the set of intrinsic properties, which I will call SI, must look like.\nFor example, from the platitude it follows that SI is closed under Boolean operations. Say that F and G are intrinsic. This means that whether some individual a is F is independent of how the world outside a happens to be. And it means that whether a is G is independent of the way the world outside a happens to be. This implies that whether a is F and G is independent of the way the world outside a happens to be, because whether a is F and G is a function of whether a is F and whether a is G. And that means that F and G is intrinsic. Similar reasoning shows that F or G, and not F are also intrinsic. Call this condition Boolean closure.\nAnother implication of the independence platitude is that SI must be closed under various mereological operations. If F is intrinsic then whether a is F is independent of the outside world. If some part of a is F, that means, however the world outside that part happens to be, that part will be F. So that means that however the world outside a is, a will have a part that is F. Conversely, if a does not have a part that is F, that means all of a’s parts are not F. As we saw above, if F is intrinsic, so is not F. Hence it is independent of the world outside a that all of its parts are not F. That is, it is independent of the world outside a that a does not have a part that is F. In sum, whether a has a part that is F is independent of how the world outside a turns out to be. And that means having a part that is F is intrinsic. By similar reasoning, the property Having n parts that are F will be intrinsic if F is for any value of n. Finally, the same reasoning shows that the property, being entirely composed of n things that are each F is intrinsic if F is intrinsic. The only assumption used here is that it is independent of everything outside b that b is entirely composed of the particular things that it is composed of, but again this seems to be a reasonable assumption. So, formally, if F \\({\\in}\\) SI, then Having n parts that are F \\({\\in}\\) SI, and Being entirely composed of n things that are F \\({\\in}\\) SI. Call this condition mereological closure.\nFinally, and most importantly, various combinatorial principles follow from the independence platitude. One of these, that all intrinsic properties are independent of accompaniment, forms the centrepiece of Langton and Lewis’s theory. The counterexamples provided by Marshall and Parsons, and by Sider, suggest that we need to draw two more combinatorial principles from the platitude. The first is that if F and G are intrinsic properties, then whether some particular object a is F should be independent of how many other things in the world are G. More carefully, if F and G are intrinsic properties that are somewhere instantiated then, for any n such that there is a world with n+1 things, there is a world constituted by exactly n+1 pairwise distinct things, one of which is F, and the other n of which are all G. When I say the world is constituted by exactly n+1 things, I do not mean that there are only n+1 things in the world; some of the n+1 things that constitute the world might have proper parts. What I mean more precisely is that every contingent thing in the world is a fusion of parts of some of these n+1 things. Informally, every intrinsic property is not only independent of accompaniment, it is independent of accompaniment by every intrinsic property. As we will see, this combinatorial principle, combined with the Boolean closure principle, suffices to show that Marshall and Parsons’s example, being such that a cube exists, is extrinsic.\nSometimes the fact that a property F is extrinsic is revealed by the fact that nothing that is F can be worldmates with things of a certain type. So the property being lonely is extrinsic because nothing that is lonely can be worldmates with anything at all. But some extrinsic properties are perfectly liberal about which other properties can be instantiated in their world; they are extrinsic because their satisfaction excludes (or entails) the satisfaction of other properties in their immediate neighbourhood. Sider’s maximal properties are like this. That a is a rock tells us nothing at all about what other properties are instantiated in a’s world. However, that a is a rock does tell us something about what happens around a. In particular, it tells us that there is no rock enveloping a. If there were a rock enveloping a, then a would not be a rock, but rather a part of a rock. If being a rock were intrinsic, then we would expect there could be two rocks such that the first envelops the second.2 The reason that being a rock is extrinsic is that it violates this combinatorial principle. (As a corollary to this, a theory which ruled out being a rock from the class of the intrinsic just because it is somehow unnatural would be getting the right result for the wrong reason. Being a rock is not a property like being a lonely electron or an accompanied non-electron that satisfies the independence platitude in the wrong way; rather, it fails to satisfy the independence platitude, and our theory should reflect this.)\n2 I assume here that there are rocks with rock-shaped holes in their interior. This seems like a reasonable assumption, though without much knowledge of geology I do not want to be too bold here.3 Perhaps all worlds have some kind of spacetimelike structure, in which case this qualification is unnecessary, but at this stage it is best not to take a stand on such a contentious issue.So we need a second combinatorial principle that rules out properties like being a rock. The following principle does the job, although at some cost in complexity. Assume there is some world w1, which has some kind of spacetimelike structure.3 Let d1 and d2 be shapes of two disjoint spacetimelike regions in w1 that stand in relation A. Further, suppose F and G are intrinsic properties such that in some world there is an F that wholly occupies a region with shape d1, and in some world, perhaps not the same one, there is a G that wholly occupies a region with shape d2. By ‘wholly occupies’ I mean that the F takes up all the ‘space’ in d1, and does not take up any other ‘space’. (There is an assumption here that we can identify shapes of spacetimelike regions across possible worlds, and while this assumption seems a little contentious, I hope it is acceptable in this context.) If F, G, d1, d2 and A are set up in this way, then there is a world where d1 and d2 stand in A, and an F wholly occupies a region of shape d1 in that world, and a G wholly occupies a region of shape d2 in that world. In short, if you could have an F in d1, and you could have a G in d2, and d1 and d2 could stand in A, then all three of those things could happen in one world. This kind of combinatorial principle has been endorsed by many writers on modality (for example Lewis 1986 and Armstrong 1989), and it seems something we should endorse in a theory on intrinsic properties.\nIn sum, the set of intrinsic properties, SI, has the following four properties:\n\n\\(B\\)\n\nIf F \\({\\in}\\) SI and G \\({\\in}\\) SI then F and G \\({\\in}\\) SI and F or G \\({\\in}\\) SI and not F \\({\\in}\\) SI\n\n\\(M\\)\n\nIf F \\({\\in}\\) SI then Having n parts that are F \\({\\in}\\) SI and Being entirely composed of exactly n things that are F \\({\\in}\\) SI\n\n\\(T\\)\n\nIf F \\({\\in}\\) SI and G \\({\\in}\\) SI and there is a possible world with n+1 pairwise distinct things, and something in some world is F and something in some world is G, then there is a world with exactly n+1 pairwise distinct things such that one is F and the other n are G.\n\n\\(S\\)\n\nIf F \\({\\in}\\) SI and G \\({\\in}\\) SI and it is possible that regions with shapes d1 and d2 stand in relation A, and it is possible that an F wholly occupy a region with shape d1 and a G wholly occupy a region with shape d2, then there is a world where regions with shapes d1 and d2 stand in A, and an F wholly occupies the region with shape d1 and a G wholly occupies the region with shape d2.\n\n\nMany other sets than SI satisfy (B), (M), (T) and (S). That is, there are many sets Ik such that each condition would still be true if we were to substitute Ik for SI wherever it appears. Say that any such set is an I-set. Then F is intrinsic only if F is an element of some I-set. Is every element of every I-set intrinsic? As we will see, sadly the answer is no. However, most of the counterexamples proposed to Langton and Lewis’s theory are not elements of any I-set, so we already have the resources to show they are extrinsic.\n\n\n0.4 Responding to Counterexamples\nMarshall and Parsons noted that E, the property being such that a cube exists, is independent of accompaniment. However, it is not part of any I-set. To see this, assume it is in Ik, which is an I-set. By (B), not E is also in Ik. So by (T), there is a world where something is E, and there are two things, one of which is E and the other of which is not E. But clearly this cannot be the case: if something in a world is E, so is everything else in the world. Hence Ik cannot be an I-set, contrary to our assumption. Intuitively, E is extrinsic because whether it is satisfied by an individual is not independent of whether other individuals satisfy it.\nSome other quantificational properties, such as being one of at most seventeen cubes, require a different argument to show that they are not in any I-set. Call that property E17. (Note, by the way, that E17 is independent of accompaniment, and not obviously disjunctive.) If E17 is in an I-set, then by (T) there is a world containing exactly 18 things, each of which is E17. But this is clearly impossible, since everything that is E17 is a cube, and everything that is E17 is in a world containing at most seventeen cubes. So E17 is not in any I-set, and hence is extrinsic. Similarly, being the only round thing cannot be in an I-set, because if it were by (T) there would be a world in which two things are the only round thing, which is impossible. So a definition of intrinsicness in terms of I-sets need not make the odd postulations about naturalness that Yablo found objectionable.\nAssume, for reductio, that being a rock is in an I-set. There is a rock that is roughly spherical, and there is a rock that has a roughly spherical hollow in its interior. (Actually, there are many rocks of each type, but we only need one of each.) Let d1 be the region the first rock takes up, and assume that the shape of the hollow in the second is also d1. If it is not, we could always find another rock with a hollow this shape, so the assumption is harmless. Let d2 be the region the second rock, the one with this nicely shaped hollow, takes up. If being a rock is an I-set, then by (S) there is a world where d2 exactly surrounds d1, there is a rock wholly occupying d1 and a rock wholly occupying d2. But this is impossible; if there were rock-like things in both d1 and d2, they would both be parts of a single large rock, that extends outside both d1 and d2 and if there were not a rock-like thing in one or the other region, then there would not be a rock in that region. So no set satisfying (S) contains being a rock, so that property is not in any I-set, and hence is extrinsic.\nThe first extrinsic property independent of accompaniment that Langton and Lewis consider is CS: being spherical and lonely or cubical and accompanied. This too is not in any I-set. Again, assume for reductio that it is. In the actual world, there are (accompanied) cubes that are entirely composed of eight smaller cubes. Both the large cube and the eight smaller cubes are accompanied, so they are both CS. Hence there is a CS that is entirely composed of eight things that are CS. By (M), being entirely composed of exactly eight things that are CS is in the I-set. By (B), being CS and entirely composed of exactly eight things that are CS is in the I-set. So by (T), there is a world in which something has that property, and there is nothing else. (To see that (T) entails this, let G be any element of the I-set, and let n be zero.) That is, there is a lonely CS that is composed of eight things that are CS. But this is impossible. A lonely CS is a sphere, but its eight parts are not lonely, and are CS, so they must be cubes. And no sphere is entirely composed of exactly eight cubes. So CS cannot be in an I-set, and hence is extrinsic.\n\n\n0.5 Problem Cases and Disjunctive Properties\nThose five successes might make us think that only intrinsic properties are ever in I-sets. However there are still some extrinsic properties that can slip into I-sets. For an example, consider the property LCS, defined as follows:\n\nx is LCS \\({\\leftrightarrow}\\) (x is cubical and not both lonely and simple) or (x is lonely, simple and spherical)\n\nThe smallest set containing LCS and satisfying (B) and (M) is an I-set. There is an important reason for this. Define a simple world as a world containing just one mereological simple, and a compound world as a world that is not a simple world. Whether a property satisfies (T) and (S) (or, more precisely, whether a set containing that property can satisfy (T) and (S)) depends on just how the property interacts with other properties in compound worlds and whether it is ever instantiated in simple worlds. Since the same things are LCS as are cubical in compound worlds, these two properties, LCS and being cubical, interact with other properties in compound worlds in the same way. And each property is instantiated in simple worlds, although they are instantiated in different simple worlds. In sum, the properties are similar enough to be indistinguishable by (T) and (S), and that means we will not be able to show that LCS is extrinsic using just those considerations.\nAny property that agrees with an intrinsic property, like being cubical, in the compound worlds, and is somehow extended so it is instantiated in simple worlds, will be in an I-set. This is not just because we have not put enough restrictions on what makes an I-set. There are just no combinatorial principles we could deduce from the independence platitude that LCS violates. This is because any such principle would, like (T) and (S), be satisfied or not depending just on how the property interacts with other properties in worlds where there are things to interact with, i.e. the compound worlds, and whether it is instantiated in the simple worlds. It is to the good that our deductions from the independence platitude did not show that LCS is extrinsic, because in an important sense LCS, like all properties that agree with some intrinsic property in all compound worlds, satisfies the platitude.\nSo at this point appeal to disjunctive and non-disjunctive properties is needed. Intuitively, intrinsic properties are not only capable of being instantiated in all possible combinations with other intrinsic properties, they are capable of being so instantiated in the same way in all these possible combinations. We need to distinguish between the disjunctive and the non-disjunctive properties in order to say which properties are instantiated the same way in all these different combinations.\nIt might be thought at this stage that we could just adopt Langton and Lewis’s definition of the disjunctive properties. If that definition worked, we could say the basic intrinsic properties are the non-disjunctive properties that are in I-sets, then define duplication and intrinsicness as they do in terms of basic intrinsics. The definition does not, it seems, work as it stands because it does not show that LCS is disjunctive. This will be easier to follow if we name all the components of LCS, as follows: \\[\\begin{aligned}\n\\textit{C}~&=~\\textit{being cubical} \\\\\n\\textit{L}~&=~\\textit{being lonely} \\\\\n\\textit{M}~&=~\\textit{being simple} \\\\\n\\textit{H}~&=~\\textit{being spherical} \\\\\n\\textit{LCS}~&=~(\\textit{C}~\\&~{\\lnot}(\\textit{L} \\& \\textit{M}))~{\\vee}~(\\textit{L} \\&~\\textit{M}~\\&~\\textit{H})\\end{aligned}\\]\nLet us agree that LCS is not a natural property, if naturalness is an on/off state, or is very unnatural, if naturalness comes in degrees. On Langton and Lewis’s first definition, it is disjunctive if it is a disjunction of conjunctions of natural properties. This seems unlikely: \\({\\lnot}\\)(L & M) is not a natural property. This is the property of being in a compound world, hardly a natural property. Similarly, C & \\({\\lnot}\\)(L & M), being a cube in a compound world, is hardly natural either. We could insist that these properties are natural, but at this point Yablo’s complaint, that clear facts like the extrinsicness of LCS are being made to rest on rather obscure facts, like the putative naturalness of being in a compound world, returns to haunt us. (I assume, for the sake of the argument, that L & M & H is a natural property, though this assumption could be easily questioned.) On the second definition, LCS is disjunctive if it is much less natural than \\({\\lnot}\\)(L & M), or than C & \\({\\lnot}\\)(L & M). Again, it seems unlikely that this is the case. These properties seem rather unnatural. I have defined enough terms that we can state in the lexicon of this paper just what \\({\\lnot}\\)(L & M) amounts to, i.e. being in a compound world, but the apparent simplicity of this definition should not make us think that the properties are natural. It is true in natural languages that predicates that are easy to express are often natural, but this fact does not extend across to the technical language that is employed here.\nThe way out is to change the definition of disjunctive properties. A property is disjunctive, intuitively, if it can be instantiated in two quite different ways. Most properties of the form: (N1 & U1) \\({\\vee}\\) (N2 & U2), where N1 and N2 pick out distinct (relatively) natural properties, and U1 and U2 pick out distinct (relatively) unnatural properties that are independent of N1 and N2, will be like this. If we name this predicate F, there will be two quite different types of Fs: those that are N1 and those that are N2. Note that this will be true no matter how unnatural U1 and U2 are; provided some Fs are N1, and some are N2, there will be these two ways to be F. So I suggest we amend Langton and Lewis’s definition of disjunctiveness as follows:\n\nA property F is disjunctive iff it can be expressed as a disjunction of conjunctions, i.e.: (A11 & … & A1n) \\({\\vee}\\) … \\({\\vee}\\) (Ak1 & … & Akm) and in each disjunct, at least one of the conjuncts is much more natural than F.\n\nOn this definition it is clear that LCS is disjunctive, since it is much less natural than being cubical and than being spherical, and in its expression above, being cubical is one of the conjuncts in the first disjunct, and being spherical is one of the conjuncts in the second disjunct. These kinds of comparisons of naturalness do not seem contentious, or any less obvious than the conclusions about extrinsicness we use them to generate. Further, the new definition of disjunctiveness is not meant to be an ad hoc fix. Rather this requirement that only one conjunct in each disjunct need be much more natural than F seems to follow directly from the reason we introduced the concept of disjunctiveness to begin with. For each F that satisfies the combinatorial principle (either independence of accompaniment in Langton and Lewis’s theory, or being in an I-set in my theory), we wanted to know whether it only does this because there are two or more ways to be an F. If F satisfies the definition of disjunctiveness I offer here, it seems there are two or more ways to be an F, so the fact that it can be in an I-set should not lead us to believe it is intrinsic.\nUsing this definition of disjunctiveness, we can say that the basic intrinsic properties are those that are neither disjunctive nor the negation of a disjunctive property, and are in at least one I-set, then say duplicates are things that share all basic intrinsic properties, and finally that intrinsic properties are properties shared by all duplicates. There are two reasons for thinking that this definition might well work. First, as we have seen it handles a wide range of hard cases. More importantly, the way that the hard cases were falling gave us reason to suspect that the only extrinsic properties that will be in I-sets are properties like LCS: properties that agree with some intrinsic property in all compound worlds. It is reasonably clear that these properties will be disjunctive according to the above definition. To see this, let F be the extrinsic property in an I-set, and let G be the intrinsic property it agrees with in all compound worlds. Then for some J, F can be expressed as (G & \\({\\lnot}\\)(L & M)) \\({\\vee}\\) (L & M & J), and it will presumably be much less natural than G, probably much less natural than J, and almost certainly much less natural than being simple, our L. So if these are the only kind of extrinsic properties in I-sets, our definition is correct.\nIndeed, if these are the only kinds of extrinsic properties in I-sets, we may not even need to worry about which properties should count as disjunctive. Say that a property F blocks another property G iff both F and G are in I-sets, but there is no I-set containing both F and G. If F and G were both intrinsic, then there would be an I-set they are both in, such as say SI, so the fact that there is no such I-set shows that one of them is extrinsic. Note that LCS blocks being cubical. To prove this, assume LCS and being cubical are in an I-set, say Ik. By two applications of (B), LCS and not cubical is in Ik. This property is instantiated in some possible worlds: it is instantiated by all lonely spheres. So by (T) there should be a world containing two things that satisfy LCS and not cubical. But only lonely, simple spheres satisfy this property, so there is no world where two things satisfy it, contradicting our assumption that LCS and being cubical can be in the same I-set. The proof here seems perfectly general: if G is intrinsic and F differs from G only in which things in simple worlds satisfy it, and G is in an I-set, then F will block G. Blocking, as defined, is symmetric, so the fact that F blocks G is no evidence that F is extrinsic, as opposed to G. Still, if G is much more natural than F, then in all probability the reason F blocks G is that they agree about all cases in compound worlds, and disagree just about the simple worlds. In that case, it seems that F is extrinsic, and G is intrinsic. So I think the following conjecture has merit: F is intrinsic iff it is in an I-set and does not block any property much more natural than itself. If the conjecture works, the only kind of naturalness comparisons we need to make will be between properties like LCS and properties like being cubical. Again, I think these kinds of comparisons should be fairly uncontentious.\n\n\n0.6 Back to Basics?\nMost of the work in my theory is done by the concept of I-sets. It might be wondered whether we can do without them. In particular, it might be thought that the new definition of disjunctivenes I offer in ?5 will be enough to rescue Langton and Lewis’s theory from the objections I have been fretting about. Indeed, the new definition of disjunctiveness does suffice for responding to Yablo’s objection. However, it will not do on its own, and I think it will end up being essential to define intrinsicness in terms of I-sets.\nYablo notes that a property like being the only red thing is independent of accompaniment, and that the way Langton and Lewis suggest showing it is disjunctive is by expressing its negation as being red and accompanied by a red thing, or not being red. Yablo criticises the claim that the first of these disjuncts really is a natural property. Above I agreed that this was a good objection. However, on the new definition of disjunctiveness, it is beside the point.\nTo show that not being the only red thing is disjunctive, we need only express it as a disjunction of conjunctions such that at least one conjunct in each disjunct is much more natural than it is. We have the disjunctive expansion of not being the only red thing, and the first disjunct is being red and accompanied by a red thing. Now this disjunct as a whole may not be particularly natural, but the first conjunct, being red, is much more natural than not being the only red thing. So all we need to show is that one of the conjuncts in the second disjunct is much more natural than the whole disjunction. Since the second disjunct has only one conjunct, this means we have to show not being red is much more natural than not being the only red thing. However, there seems to be no simple way to show this. It is just entirely unclear how natural properties like not being red should seem to be. My guess (for what it is worth) is that like most properties that can be expressed by negations of English predicates, it is very unnatural. Certainly it is very unnatural if we suppose, as seems fair in this context, that F is only a natural property if all the things that are F resemble each other in some important way. The class of things that are not red is as heterogeneous a class as you can hope to find; blue berries, green leaves, silver Beetles, colourless gases and immaterial souls all find their way in. It is true that in New Work for a Theory of Universals, David Lewis provides two importantly distinct criteria for naturalness. One is the resemblance criterion just mentioned. The other is that F is only perfectly natural if it is fundamental. It might be thought that when we look at this criterion, it does turn out that not being red is much more fundamental than being the only red thing. Even if this is the case, it is not clear that it does help, or more importantly, that it should help. The problem Langton and Lewis were trying to handle is that not being the only red thing satisfies a particular combinatorial principle (independence of accompaniment), but only, they say, because there are two different ways of instantiating that property: not being red and being accompanied by a red thing. The problem is that not being red is not a way to instantiate a property, because it is not a way that something could be. It seems very intuitive that ‘ways things could be’, in this sense, are resemblance properties: they are properties that make for resemblance amongst their instantiators. And even if we can defend the claim that not being red is a fundamental property, the fact that it is not a resemblance property seems to undercut Langton and Lewis’s case here.\nThe new definition of disjunctiveness does not provide a defender of Langton and Lewis’s theory with a response to Yablo’s criticism. On the new definition of disjunctiveness, we do not have to show that being red and accompanied by a red thing is more natural than not being the only red thing in order to show that the latter is disjunctive. However, in order to show that not being the only red thing is disjunctive, we still need to show that not being red is a moderately natural property, and this does not seem to be true.\n\n\n0.7 Conclusion\nThere are four major differences between the analysis of intrinsic properties provided here and the one provided by Langton and Lewis. Three of these are reflected in the difference between the combinatorial principle they use, independence of accompaniment, and the combinatorial principle I use, membership in an I-set. All properties that are in I-sets are independent of accompaniment, but they also have a few other nice features. First, membership in an I-set guarantees not just independence of whether there are other things, but independence of what other types of things there are. This is the independence principle encoded in condition (T) on I-sets. Secondly, membership in an I-set guarantees independence of where the other things are. This is the principle encoded in condition (S). Third, the mereological principle (M) has no parallel in Langton and Lewis’s theory.\nThe effect of these extra three restrictions is that I have to make many fewer appeals to naturalness than do Langton and Lewis. The fourth difference between their theory and mine is in the role naturalness considerations play in determining which properties are intrinsic. In section 5 I offer two ways of finishing the analysis using naturalness. The first is in the new definition of disjunctiveness; with this definition in hand we can finish the story just as Langton and Lewis suggest. The second is in terms of blocking: F is intrinsic iff it is in an I-set and does not block any property that it is much less natural than. Both ways are designed to deal with a quite specific problem: properties that differ only in which things instantiate them in simple worlds have the same combinatorial features, so a definition of intrinsicness in terms of combinatorial features (as is Langton and Lewis’s, and as is mine) will not be able to distinguish them. Still, both solutions seem likely to provide the same answer in all the hard cases: the right answer.\n\n\n\n\n\n\nReferences\n\nLangton, Rae, and David Lewis. 2001. “Marshall and Parsons on ‘Intrinsic’.” Philosophy and Phenomenological Research 63 (2): 353–55. https://doi.org/10.2307/3071068.\n\n\nMarshall, Dan, and Josh Parsons. 2001. “Langton and Lewis on ‘Intrinsic’.” Philosophy and Phenomenological Research 63 (2): 347–51. https://doi.org/10.2307/3071067.\n\n\nSider, Theodore. 2001. “Maximality and Intrinsic Properties.” Philosophy and Phenomenological Research 63 (2): 357–64. https://doi.org/10.1111/j.1933-1592.2001.tb00109.x.\n\n\nTaylor, Barry. 1993. “On Natural Properties in Metaphysics.” Mind 102 (405): 81–100. https://doi.org/10.1093/mind/102.405.81.\n\n\nYablo, Stephen. 1999. “Intrinsicness.” Philosophical Topics 26 (1): 479–505. https://doi.org/10.5840/philtopics1999261/234."
  },
  {
    "objectID": "posts/evil/index.html",
    "href": "posts/evil/index.html",
    "title": "Should We Respond to Evil With Indifference?",
    "section": "",
    "text": "In a recent article, Adam Elga (2004) outlines a strategy for “Defeating Dr Evil with Self-Locating Belief”. The strategy relies on an indifference principle that is not up to the task. In general, there are two things to dislike about indifference principles: adopting one normally means confusing risk for uncertainty, and they tend to lead to incoherent views in some ‘paradoxical’ situations. Each kind of objection can be levelled against Elga’s theory, but because Elga is more careful than anyone has ever been in choosing the circumstances under which his indifference principle applies we have to be similarly careful in focussing the objections. Even with this care the objections I put forward here will be less compelling than, say, the objections (Keynes 1921 Ch. 4) put forward in his criticisms of earlier indifference principles. But there still may be enough to make us reject Elga’s principle. The structure of this note is as follows. In and 2 I set out Elga’s theory, in and 4 I discuss some initial objections that I don’t think are particularly telling, in I discuss some paradoxes to which Elga’s theory seems to lead (this is reprised in where I discuss a somewhat different paradoxical case) and in and 8 I argue that even Elga’s careful indifference principle involves a risk/uncertainty confusion.\n\nPublished in Philosophy and Phenomenal Research 70: 613-35.\nThanks to Jamie Dreier, Adam Elga and an anonymous referee for helpful discussions about this paper and suggestions for improvements.\n\n\n0.1 From Basel to Princeton\nIn (1979) David Lewis argued that the contents of contentful mental states were not propositions, but properties. When I think that I’m a rock star, I don’t attribute truth to the proposition Brian is a rock star, but rather attribute the property of rock stardom to myself. Lewis was led to this position by considering cases where a believer is mistaken about his own identity. For example, if I believe that I’m a rock star without believing that I’m Brian, and in fact while thinking that Brian is an infamous philosopher, it is odd to attribute to me belief in the proposition Brian is a rock star. But it is perfectly natural to say I self-attribute rock stardom, and that’s just what Lewis says.\nIf we accept Lewis’s position, there are two paths we can take. First, we can try simply replacing all talk of propositional attitudes with talk of proprietal attitudes, and trusting and hoping that this won’t make a difference to our subsequent theorising. Alternatively, we can see if changing the type of entity that is the content of a contentful state has distinctive consequences, and in particular see if it gives us the conceptual resources to make progress on some old problems. That’s the approach Adam Elga has taken in a couple of papers, and whatever one thinks of his conclusions, the early returns certainly suggest that this Lewisian outlook will prove remarkably fruitful.\nOn the Lewisian approach, credences are defined over properties, and properties are sets of possibilia, i.e. centred worlds. Some properties are maximally precise, they are satisfied by exactly one possible object. Elga sometimes calls these maximally specific properties predicaments because they specify exactly what is happening to the agent that instantiates one. Say predicaments F1 and F2 are similar iff the F1 and the F2 are worldmates and their experiences are indistinguishable. Elga’s principle INDIFFERENCE says that if predicaments F1 and F2 are similar then any rational agent should assign equal credence to F1 and F2. This becomes most interesting when there are similar F1 and F2. So, for instance, consider poor O’Leary.\n\nO’LEARY\n\nO’Leary is locked in the trunk of his car overnight. He knows that he’ll wake up briefly twice during the night (at 1:00 and again at 2:00) and that the awakenings will be subjectively indistinguishable (because by 2:00 he’ll have forgotten the 1:00 awakening). At 1:00 he wakes up.\n\n\nElga says that when O’Leary wakes up, he should assign equal credence to it being 1:00 as to it being 2:00. So, provided O’Leary knows that one of these two hypotheses is true, INDIFFERENCE says that he should assign credence 1/2 to it being 1:00 at the wake up.\nElga has an argument for INDIFFERENCE, which we shall get to by , but for a while I will look at some immediate consequences of the position. I’ll start with two reasons to think that INDIFFERENCE needs to be strengthened to play the role he wants it to play.\n\n\n0.2 Add it Up\nOne difficulty with INDIFFERENCE as stated so far is that it applies only to very narrow properties, predicaments, and it is not clear how to generalise to properties in which we are more interested.\n\nBERNOULLIUM\n\nDespite months of research, Leslie still doesn’t know what the half-life of Bernoullium, her newly discovered element is. It’s between one and two nanoseconds, but she can’t manufacture enough of the stuff to get a better measurement than that. She does, however, know that she’s locked in the trunk of her car, and that like O’Leary she will have two indistinguishable nocturnal awakenings. She’s having one now in fact, but naturally she can’t tell whether it is the first or the second.\n\n\nINDIFFERENCE says that Leslie should assign credence 1/2 to it being the first wake-up, right? Not yet. All that INDIFFERENCE says is that any two predicaments should receive equal credence. A predicament is maximally specific, so it specifies, inter alia, the half-life of Bernoullium. But for any x, Leslie assigns credence 0 to x being the half-life of Bernoullium, because there are uncountably many candidates for being the half-life, and none of them look better than any of the others. So she assigns credence 0 to every predicament, and so she satisfies INDIFFERENCE no matter what she thinks about what the time is. Even if, for no reason at all, she is certain it is her second awakening, she still satisfies INDIFFERENCE as it is written, because she assigns credence 0 to every predicament, and hence equal credence to similar predicaments.\nFortunately, we can strengthen INDIFFERENCE to cover this case. To start, note that the motivations for INDIFFERENCE suggest that if two predicaments are similar then they should receive equal credence not just in the agent’s actual state, but even when the agent gets more evidence. Leslie should keep assigning equal credence to it being her first or second wake up if she somehow learns what the half-life of Bernoullium is, for example. This suggests the following principle:\n\nC-INDIFFERENCE\n\nIf F1 and F2 are similar, and an agent does not know that she is in neither, then her conditional credence on being F1, conditional on being either F1 or F2, should be 1/2.1\n1 INDIFFERENCE entails C-INDIFFERENCE given the following extra assumptions. First, if INDIFFERENCE is true it is indefeasible, so it must remain true whatever one’s evidence is. Secondly, rational agents should update by conditionalisation. Thirdly, it is always possible for an agent to get evidence that tells her she is in F1 or F2 and no more. The third premise is at best an idealisation, but it is hard to see how or why that should tell against C-INDIFFERENCE.\n\nBut even this doesn’t quite resolve our problem. Simplifying Leslie’s situation somewhat, the live predicaments are all of the following form: this is the first/second awakening, and the half-life of Bernoullium is x. C-INDIFFERENCE requires that for any c, conditional on the half-life of Bernoullium being c, Leslie assign credence 1/2 to it being her first awakening. From this and the fact that Leslie’s credence function is a probability function it doesn’t follow that her credence in this being her first awakening is 1/2. So to get INDIFFERENCE to do the work it is meant to do in Leslie’s case (and presumably O’Leary’s case, since in practice there will be some other propositions about which O’Leary is deeply uncertain) I think we need to strengthen it to the following.\n\nP-INDIFFERENCE\n\nIf G1 and G2 are properties such that:\n\nFor all worlds w, there is at most one G1 in w and at most one G2 in w;\nFor all worlds w, there is a G1 in w iff there is a G2 in w; and\nFor all worlds w where there is a G1 in w, the G1 and the G2 have indistinguishable experiences; then\n\nG1 and G2 deserve equal credence.\n\n\nElga does not endorse either C-INDIFFERENCE or P-INDIFFERENCE, but I suspect he should given his starting assumptions. It is hard to believe if O’Leary is certain about everything save what time it is, then rationality imposes very strong constraints on his beliefs about time, while rationality imposes no such constraints should he (or Leslie) be uncertain about the half-life of Bernoullium. Put another way, it is hard to believe that in her current state Leslie could rationally assign credence 0.9 to this being her first awakening, but if she decided the half-life of Bernoullium is 1.415 nanoseconds, then she would be required to change that credence to 0.5. If we have INDIFFERENCE without P-INDIFFERENCE, that is possible. So I will assume in what follows that if C-INDIFFERENCE and P-INDIFFERENCE are false then INDIFFERENCE is heavily undermined.2\n2 Note also that if P-INDIFFERENCE is false, then Dr Evil has an easy way out of the ‘brain race’ that comes up at the end of Elga’s paper. He just need be told about some new element without being told its half-life, and magically he is free to assign credence 1 to his being on the spaceship rather than on Earth. This would reduce the interest of the puzzle somewhat I fear.\n\n0.3 Out of sight, out of mind\nElga’s discussion presupposes two kinds of internalism. First, he assumes that some internalist theory of experience is true. Second, he assumes that some internalist theory of justification is true. If the first assumption is false it threatens the applicability of the theory. If the second assumption is false it threatens the truth of the theory.\nAn externalist theory of experience says that what kind of experience S is having is determined, inter alia, by what S is experiencing. While setting out such a view, John (Campbell 2002, 124–26) says that two people sitting in duplicate prison cells looking at duplicate coffee cups will have different experiences, because one will have an experience of the coffee cup in her hand, and the other will not have an experience of that cup. This does not threaten INDIFFERENCE, but it does seem to render it trivial. On Campbell’s view, if two agents are able to make demonstrative reference to different objects, and there is no reason to think Elga’s agents in allegedly similar but not numerically identical predicaments cannot, they are having different experiences. Hence the situations are not really similar after all. Strictly speaking, this is good news for INDIFFERENCE, since it is hard given this view of experience to find counterexamples to it. But I doubt that Elga will be happy with this defence.\nThe second kind of internalist assumption is more threatening. Many externalists about justification think whether a particular experience justifies a belief for an agent depends not just on intrinsic features of that experience, but on the relationship between experiences of that kind and the world around the agent. In some versions of this, especially the version defended by Timothy Williamson (1998), whether an experience either constitutes or produces evidence depends on whether it constitutes or produces knowledge. Since it is not clear that any two similar agents know the same thing, since it is clear that they do not have the same true beliefs, on Williamson’s theory it seems that the agents will not have the same evidence. In particular, it is possible that part of one agent’s evidence is inconsistent with her being the other agent. If part of her evidence is that she has hands, then she is not a brain-in-a-vat having experiences like hers, and she should not assign high credence to the claim that she is one, no matter what INDIFFERENCE says. So Elga needs to reject this kind of externalism about evidence. This is not a devastating objection. I am sure that Elga does reject Campbell’s and Williamson’s theories, so just raising them against him without argument would be question-begging. But this does mean that the target audience for INDIFFERENCE is smaller than for some philosophical claims, since adherents of Campbell’s or Williamson’s views will be antecedently disposed to think INDIFFERENCE is useless or false.\n\n\n0.4 It’s Evidently Intransitive\nDakota is sitting in a bright green room. She is trying to reconstruct how she got there when Dr Evil informs her just what happened. An epistemology student, not coincidentally called Dakota, was snatched out of her study and duplicated 999 times over. The duplicates were then numbered (though we’ve lost which number was given to the original) each put in a coloured cell. The thousand coloured cells rotated slowly through the colour sphere, starting with cell 0 (the new home of Dakota number 0) being green, going blueish until cell 250 (for Dakota number 250) is just blue, then reddish until cell 500 is just red, swinging through the yellows with pure yellow reached at 750, and then back to the greens, with 999 being practically identical to 1000. For any n, cells number n and n+1 are indistinguishable. That means that Dakota number n is similar, in Elga’s sense, to Dakota number n+1, for their (apparent) experiences before being in the rooms are identical, and their experiences in the rooms are indistinguishable. Hence our Dakota, sitting in the bright green room, should assign equal credence to being Dakota number n and Dakota number n+1 for any n. But this is absurd. Since she can see that her walls are green, she should assign high credence to being Dakota number 0, and credence 0 to being Dakota number 500.\nThe problem here is that Elga wants to define an equivalence relation on predicaments, the relation deserving the same credence as, out of an intransitive relation, being indistinguishable from. There are two possible responses, each of them perfectly defensible.\nFirst, Elga could deny the premise that the adjacent cells are indistinguishable. Although there is some prima facie plausibility to the claim that some different colours are indistinguishable, Delia Graff Fara (2001) has argued that this is false. It would mean committing to yet another controversial philosophical position, but if Elga endorsed Graff’s claims, he could easily deal with Dakota.\nSecondly, he could tinker with the definition of similarity. Instead of saying that possibilia represent similar predicaments iff they are indistinguishable worldmates, he could say that they represent similar predicaments iff they are worldmates that are indistinguishable from the same predicaments. (This kind of strategy for generating an equivalence relation from an intransitive relation is borrowed from Goodman (1951).) Even if adjacent cells are indistinguishable from each other, they will not be indistinguishable from the same cells. This delivers the plausible result that the duplicate Dakotas stuck in the cells do not instantiate similar predicaments. Some might object that this move is ad hoc, but once we realise the need to make similar an equivalence relation, it seems clear enough that this is the most natural way to do that.\n\n\n0.5 Morgan and Morgan and Morgan and Morgan\nI think I outdid myself this time, said Dr Evil. I was just going along duplicating you, or at least someone like you, and the duplication process was taking less and less time. So I thought, I wonder what is the lower bound here? How quick can we make the duplication process? So I tried a few things to cut down the time it took, and I got a little better with practice, and, well, it turns out that the time taken can be made arbitrarily small. Before I knew it, there were infinitely many of you. Oops.\nMorgan was a little shocked. She could cope with having a duplicate or two around, but having infinitely many duplicates was a little hard to take. On the other hand, and this was hard to think about, perhaps she should be grateful. Maybe she was one of the later ones created, and she wouldn’t have existed if not for Evil’s irrational exuberance. She started to ponder how likely that was, but she was worried that it required knowing more about Evil than any mortal could possibly know.\nWell, continued Dr Evil, I did one thing right. As each duplicate was created I gave it a serial number, 0 for the original Morgan, 1 for the first duplicate and so on, so the bookkeeping will be easier. Don’t go looking for it, it’s written on your left leg in ectoplasmic ink, and you won’t be able to see it.\nNow that makes things easier, thought Morgan. By INDIFFERENCE the probability that my serial number is x is 1/n, where n is the number of duplicates created. So dividing 1 by infinity, that’s zero. So the probability that my serial number is less than x is the probability that it’s zero plus the probability that it’s one plus … plus the probability that it’s x, that’s still zero. So if he had stopped after x for any x, I would not exist with probability one. I’m liking Evil more and more, though something bothers me about that calculation.\nMorgan was right to worry. She’s just talked herself, with Elga’s help, into a violation of the principle of countable additivity. The additivity axiom in standard probability theory says that for any two disjoint propositions, the probability of their disjunction is the sum of their probabilities. The countable additivity axiom says that for any countable set of disjoint propositions, the probability that at least one of them is true is the sum of each of their probabilities. (It follows from the axioms of probability theory that this sum is always defined.) Here we have to alter these axioms slightly so they apply to properties rather than propositions, but still the principle of countable additivity seems plausible. But Morgan has to violate it. The probability she assigns to having some serial number or other is not zero, in fact it is one as long as she takes Evil at his word. But for each x, the probability that her serial number is x is zero. In symbols, we have\n\nPr(\\({\\exists}\\)x (Serial number = x)) = 1\n\\({\\Sigma}\\)Pr(Serial number = x) = 0\n\nBut countable additivity says that these values should be equal.\nOrthodoxy endorses countable additivity, but there are notable dissenters that are particularly relevant here. Bruno (deFinetti1974?) argued that countable additivity should be rejected because it rules out the possibility of an even distribution across the natural numbers. DeFinetti thought, as Morgan does, that we could rationally be in a position where we know of a particular random variable only that its value is a non-negative integer, and for every x, we assign equal probability to each hypothesis that its value is x. Since that is inconsistent with countable additivity, all the worse for countable additivity. This is a decent argument, though as de Finetti himself noted, it has some counterintuitive consequences.\nI decided, Dr Evil continued, to do something fairly spectacular with all these people. By some small tinkering with your physiology I found a way to make you immortal. Unfortunately, a quick scan of your psychology revealed that you weren’t capable of handling eternity. So every fifty years I will wipe all your memories and return you to the state you were in when duplicated. I will write, or perhaps I did write, on your right leg the number of times that your memories have been thus wiped. Don’t look, it’s also in ectoplasmic ink. Just to make things fun, I made enough duplicates of myself so that every fifty years I can tell you what happened. Each fifty-year segment of each physical duplicate will be an epistemic duplicate of every other such segment. How cool is that?3\n3 Evil’s plan resembles in many respects a situation described by Jamie Dreier (2001) in his “Boundless Good”. The back story is a little different, but the situation is closely (and intentionally) modelled on his sphere of pain/sphere of pleasure example.Morgan was not particularly convinced that it was cool, but an odd thought crossed her mind once or twice. She had one number L written on her left leg, and another number R written on her right leg. She had no idea what those numbers were, but she thought she might be in a position to figure out the odds that L \\({\\geq}\\) R. So she started reasoning as follows, making repeated appeals to C-INDIFFERENCE. (She must also appeal to P-INDIFFERENCE at every stage if there are other propositions about which she is uncertain. Assume that appeal made.)\nLet’s say the number on my left leg is 57. Then L \\({\\geq}\\) R iff R &lt; 58. But since there are 58 ways for R &lt; 58 to be true, and infinitely many ways for R &lt; 58 to be false, and by C-INDIFFERENCE each of these ways deserve the same credence conditional on L = 57, we get Pr(L \\({\\geq}\\) R  L = 57) = 0. But 57 was arbitrary in this little argument, so I can conclude \\({\\forall}\\)l: Pr(L \\({\\geq}\\) R  L = l) = 0. This seems to imply that Pr(L \\({\\geq}\\) R) = 0, especially since I know L takes some value or other, but let’s not be too hasty.\nLet’s say the number on my right leg is 68. Then L \\({\\geq}\\) R iff L \\({\\geq}\\) 68. And since there are 68 ways for L \\({\\geq}\\) 68 to be false, and infinitely many ways for it to be true, and by C-INDIFFERENCE each of these ways deserve the same credence conditional on R = 68, we get Pr(L \\({\\geq}\\) R  R = 68) = 1. But 68 was arbitrary in this little argument, so I can conclude \\({\\forall}\\)r: Pr(L \\({\\geq}\\) R  R = r) = 1. This seems to imply that Pr(L \\({\\geq}\\) R) = 1, especially since I know R takes some value or other, but now I’m just confused.\nMorgan is right to be confused. She has not quite been led into inconsistency, because as she notes the last step, from \\({\\forall}\\)l: Pr(L \\({\\geq}\\) R  L = l) = 0 to Pr(L \\({\\geq}\\) R) = 0 is not forced. In fact, the claim that this is always a valid inferential step is equivalent to the principle of countable additivity, which we have already seen a proponent of INDIFFERENCE in all its variations must reject. But it would be a mistake to conclude from this that we just have a standoff. What Morgan’s case reveals is that accepting the indifference principles that Elga offers requires giving up on an intuitively plausible principle of inference. That principle says that if the probability of p conditional on any member of a partition is x, then the probability of p is x. If we think that principle of inference is prima facie more plausible than Elga’s principle of indifference, as I think we should, that is pretty good prima facie evidence that Elga’s principle is wrong.\nThe next three sections will be devoted to determining whether we can convert this persuasive argument into a knockdown argument (we cannot) and whether Elga’s arguments in favour of INDIFFERENCE do enough to overcome this prima facie argument that INDIFFERENCE is flawed (they do not). A concluding section notes how to redo this argument so it appeals only to potential rather than actual infinities.\n\n\n0.6 Intermission\nCHARYBDIS: I know how to make that argument stronger. Just get Evil to offer Morgan a bet on whether L \\({\\geq}\\) R. Ask how much she’ll pay for a bet that pays €1 if L \\({\\geq}\\) R and nothing otherwise. If she pays anything for it, tell her the value of L, whatever it is, and ask her if she’d like to sell that bet back for half what she paid for it. Since she now assigns probability zero to L \\({\\geq}\\) R she’ll happily do that, and then she’ll have lost money. If she won’t pay anything for the bet to start with, offer her the reverse bet. She should pay €1 for that, and now apply the same tactics except tell her the value of R rather than L. Either way the stupid person will lose money.\nSCYLLA:Very practical Charybdis, but we’re not sure it gets to the heart of the matter. Not sure. Well, let us say why rather than leaving it like that. For one thing, Morgan might not like playing dice with Evil, even if Evil is the source of her life. So she might have a maximum price of 0 for either bet.\nCHARYBDIS:But then surely she’ll be turning down a sure win. I mean between the bets she has a sure gain of at least €1.\nSCYLLA:And if she is offered both bets at once we’re sure she would take that gain, but as we heard your story she wasn’t.4\n4 Compare the objection to Dutch Book arguments in Schick (1986).CHARYBDIS:So does this mean her degree of belief in both R \\({\\geq}\\) L and L \\({\\geq}\\) R is 0?\nSCYLLA:It might mean that, and of course some smart people have argued that that is coherent, much to the chagrin of your Bayesian friends we’re sure.5 But more likely it means that she just isn’t following the patterns of practical reasoning that you endorse.6 Also, we’re not so sure about the overall structure of the argument. We think your reasoning is as follows. Morgan ends up doing something silly, giving up money. (Well, we’re not sure that’s always silly, but let’s say it is here.) So something went wrong. So she has silly beliefs. That last step goes by fairly fast we think. From her making some mistake or other, we can only conclude that, well, she made some mistake or other, not that she made some particular mistake in the composition of her credences.7\n5 For example, Shafer (1976).6 Compare the state-dependent approach to decision-making discussed in Chambers and Quiggin (2000).7 This point closely resembles an objection to Dutch Book reasoning made in Hájek (2005), though Scylla is much more sceptical about how much we can learn from these pragmatic arguments than Hájek is.CHARYBDIS:What other mistake might she have made?\nSCYLLA:There are many hidden premises in your chains of reasoning to conclusions about how Morgan should behave. For instance, she only values a €1 bet on L \\({\\geq}\\) R at Pr(L \\({\\geq}\\) R) if she knows she can’t buy that bet more cheaply elsewhere, or sell it for a larger price elsewhere. Even if those assumptions are true, Morgan may unreasonably believe they are false, and that might be her mistake.8 But even that isn’t our main concern. Our main concern is that you understate how bad Morgan’s position is.\n8 Scylla’s reasoning here is based on Milne (1991), though of course Milne’s argument is much less condensed than that.CHARYBDIS:What’s worse for a mortal than assured loss of money?\nSCYLLA:Morgan is not a mortal any more, you know. And immortals we’re afraid are almost bound to lose money to clever enough tricksters. Indeed, a so-called Dutch Book can be made against any agent that (a) has an unbounded utility function and (b) is not overly opinionated, so there are still infinitely many ways the world could be consistent with their knowledge.9 That includes us, and you dear Charybdis. And yet we are not as irrational as that Morgan. I don’t think analogising her position to ours really strengthens the case that she is irrational.\n9 This is proven in McGee (1999).CHARYBDIS:Next you might say that making money off her, this undeserving immortal, is immoral.\nSCYLLA:Perish the thoughts.\n\n\n0.7 Risky Business?\nThere are two kinds of reasons to dislike indifference principles, both of them developed most extensively in Keynes (1921). The first, which we have been exploring a bit so far, is that such principles tend to lead to incoherence. The second is that such principles promote confusion between risk and uncertainty.\nOften we do not know exactly what the world is like. But not all kinds of ignorance are alike. Sometimes, our ignorance is like that of a roulette player facing a fair wheel about to be spun. She knows not what will happen, but she can provide good reasons for assigning equal credence to each of the 37 possible outcomes of the spin. Loosely following Frank Knight (1921), we will say that a proposition like The ball lands in slot number 18 is risky. The distinguishing feature of such propositions is that we do not know whether they are true or false, but we have good reason to assign a particular probability to their truth. Other propositions, like say the proposition that there will be a nuclear attack on an American city this century, are quite unlike this. We do not know whether they are true, and we aren’t really in a position to assign anything like a precise numerical probability to their truth. Again following Knight, we will say such propositions are uncertain. In (1937) Keynes described a number of other examples that nicely capture the distinction being drawn here.\n\nBy ‘uncertain’ knowledge, let me explain, I do not mean merely to distinguish what is known for certain from what is only probable. The game of roulette is not subject, in this sense, to uncertainty; nor is the prospect of a Victory bond being drawn. Or, again, the expectation of life is only slightly uncertain. Even the weather is only moderately uncertain. The sense in which I am using the term is that in which the prospect of a European war is uncertain, or the price of copper and the rate of interest twenty years hence, or the obsolescence of a new invention, or the position of private wealth owners in the social system in 1970. About these matters there is no scientific basis on which to form any calculable probability whatever. We simply do not know. Nevertheless, the necessity for action and decision compels us as practical men to do our best to overlook this awkward fact and to behave exactly as we should if we had behind us a good Benthamite calculation of a series of prospective advantages and disadvantages, each multiplied by its appropriate probability, waiting to be summed. (Keynes 1937, 114–15)\n\nNote that the distinction between risky and uncertain propositions is not the distinction between propositions whose objective chance we know and those that we don’t. This identification would fail twice over. First, as Keynes notes, whether a proposition is risky or uncertain is a matter of degree, but whether we know something is, I presume, not a matter of degree.10 Second, there are risky propositions with an unknown chance. Assume that our roulette player turns away from the table at a crucial moment, and misses the ball landing in a particular slot. Now the chance that it lands in slot 18 is 1 (if it did so land) or 0 (otherwise), and she does not know which. Yet typically, the proposition The ball lands in slot 18 is still risky for her, for she has no reason to change her attitude towards the proposition that it did land in slot 18.\n10 Though see Hetherington (2001) for an argument to the contrary.My primary theoretical objection to INDIFFERENCE is that the propositions it purports to provide guidance on are really uncertain, but it treats them as risky. Once we acknowledge the risk/uncertainty distinction, it is natural to think that our default state is uncertainty. Getting to a position where we can legitimately treat a proposition as risky is a cognitive achievement. Traditional indifference principles fail because they trivialise this achievement. An extreme version of such a principle says we can justify assigning a particular numerical probability, 0.5, to propositions merely on the basis of ignorance of any evidence telling for or against it. This might not be an issue to those who think that “probability is a measure of your ignorance.” (Poole, Mackworth, and Goebel 1998, 348) But to those of us who think probability is the very guide to life, such a position is unacceptable. It seems to violate the platitude ‘garbage in, garbage out’ since it takes ignorance as input, and produces a guide to life as output. INDIFFERENCE is more subtle than these traditional indifference principles, but this theoretical objection remains. The evidence that O’Leary or Morgan or Leslie has does not warrant treating propositions about their location or identity as risky rather than uncertain. When they must make decisions that turn on their identity or location, this ignorance provides little or no guidance, not a well-sharpened guide to action.\nIn this section I argue that treating these propositions as uncertain lets us avoid the traps that Morgan falls into. In the next section I argue that the case Elga takes to support INDIFFERENCE says nothing to the theorist who thinks that the INDIFFERENCE principle conflates risk and uncertainty. In fact, some features of that case seem to support the claim that the propositions covered by INDIFFERENCE are uncertain, not risky.\nIn (1921), Keynes put forward a theory of probability that was designed to respect the distinction between risky propositions and uncertain propositions. He allowed that some propositions, the risky ones and the ones known to be true or false, had a numerical probability (relative to a body of evidence) while other propositions have non-numerical probabilities. Sometimes numerical and non-numerical probabilities can be compared, sometimes they cannot. Arithmetic operations are all assumed to be defined over both numerical and non-numerical probabilities. As Ramsey (1926) pointed out, in Keynes’s system it is hard to know what \\({\\alpha}\\) + \\({\\beta}\\) is supposed to mean when \\({\\alpha}\\) and \\({\\beta}\\) are non-numerical probabilities, and it is not even clear that ‘+’ still means addition in the sense we are used to.\nOne popular modern view of probability can help Keynes out here. Following Ramsey, many people came to the view that the credal states of a rational agent could be represented by a probability function, that function being intuitively the function from propositions into the agent’s degree of belief in that proposition. In the last thirty years, there has been a lot of research on the theory that says we should represent rational credal states not by a single probability function, but by a set of such probability functions. Within philosophy, the most important works on this theory are by Henry Kyburg (1974), Isaac Levi (1974, 1980), Richard Jeffrey (1983) and Bas Fraassen (1990). What is important here about this theory is that many distinctive features of Keynes’s theory are reflected in it.\nLet S be the set of probability functions representing the credal states of a rational agent. Then for each proposition p we can define a set S(p) = {Pr(p): Pr \\({\\in}\\) S}. That is, S(p) is the set of values that Pr(p) takes for Pr being a probability function in S. We will assume here that S(p) is an interval. (See the earlier works cited for the arguments in favour of this assumption.) When p is risky, S(p) will be a singleton, the singleton of the number we have compelling reason to say is the probability of p. When p is a little uncertain, S(p) will be a fairly narrow interval. When it is very uncertain, S(p) will be a wide interval, perhaps as wide as [0, 1]. We say that p is more probable than q iff for all Pr in S, Pr(p) &gt; Pr(q), and as probable as q iff for Pr in S, Pr(p) = Pr(q). This leaves open the possibility that Keynes explicitly left open, that for some uncertain proposition p and some risky proposition q, it might be the case that they are not equally probable, but neither is one more probable than the other. Finally, we assume that when an agent whose credal states are represented by S updates by learning evidence e, her new credal states are updated by conditionalising each of the probability functions in S on e. So we can sensibly talk about S(p  e), the set {Pr(p  e): Pr \\({\\in}\\) S}, and this represents her credal states on learning e.\n(It is an interesting historical question just how much the theory sketched here agrees with the philosophical motivations of Keynes’s theory. One may think that the agreement is very close. If we take Keynes’s entire book to be a contextual definition of his non-numerical probabilities, a reading encouraged by Lewis (1970), then we should conclude he was talking about sets like this, with numerical probabilities being singleton sets.)\nThis gives us the resources to provide good advice to Morgan. Pick a monotone increasing function f from integers to [0, 1] such that as n \\({\\rightarrow}\\) \\({\\infty}\\), f(n) \\({\\rightarrow}\\) 1. It won’t really matter which function you pick, though different choices of f might make the following story more plausible. Say that S(L \\({\\geq}\\) R  L = l) = [0, f(l)]. The rough idea is that if L is small, then it is quite improbable that L  \\({\\geq}\\) R, although this is a little uncertain. As l gets larger, L \\({\\geq}\\) R gets more and more uncertain. The overall effect is that we simply do not know what S(L \\({\\geq}\\) R) will look like after conditionalising on the value of L, so we cannot apply the kind of reasoning Morgan uses to now come to some conclusions about the probability of L \\({\\geq}\\) R.\nIf we view the situations described by INDIFFERENCE as involving uncertainty rather than risk, this is exactly what we should expect. And note that in so doing, we need not undermine the symmetry intuition that lies behind INDIFFERENCE. Assume that F and G are similar predicaments, and I know that I am either F or G. INDIFFERENCE says I should assign equal probability to each, so S(I am F) = S(I am G) = {0.5}. But once we’ve seen how attractive non-numerical probabilities can be, we should conclude that all symmetry gives us is that S(I am F) = S(I am G), which can be satisfied if each is [0.4, 0.6], or [0.2, 0.8] or even [0, 1]. (I think that for O’Leary, for example, S(It is 1 o’clock) should be a set somehow like this.) Since I would not be assigning equal credence to I am F and I am G if I satisfied symmetry using non-numerical probabilities, so I will violate INDIFFERENCE without treating the propositions asymmetrically. Such a symmetric violation of INDIFFERENCE has much to recommend it. It avoids the incoherence that INDIFFERENCE leads to in Morgan’s case. And it avoids saying that ignorance about our identity can be a sharp guide to life.11\n11 Bradley (monton2002?) discusses using sets of probability functions to solve another problem proposed by Elga, the Sleeping Beauty problem (Elga 2000). Monton notes that if Beauty’s credence in The coin landed heads is [0, 0.5] when she wakes up on Monday, then she doesn’t violate van Fraassen’s General Reflection Principle (Fraassen 1995). (I assume here familiarity with the Sleeping Beauty problem.) Monton has some criticisms of this move, in particular the consequences it has for updating, that don’t seem to carry across to the proposal sketched here. But his discussion is noteworthy as a use of this approach to uncertainty as a way to solve problems to do with similar predicaments.A referee noted that the intuitive characterisation here doesn’t quite capture the idea that we should treat similar predicaments alike. The requirement that if F and G are similar then S(I am F) = S(I am G) does not imply that there will be a symmetric treatment of F and G within S if there are more than two similar predicaments. What we need is the following condition. Let T be any set of similar predicaments, g any isomorphism from T onto itself, and Pr any probability function in S. Then there exists a Pr\\(^\\prime\\) in S such that for all A in T, Pr(A) = Pr\\(^\\prime\\)(g(A)). When there are only two similar predicaments A and B this is equivalent to the requirement that S(A) = S(B), but in the general case it is a much stricter requirement. Still, it is a much weaker constraint than INDIFFERENCE, and not vulnerable to the criticisms of INDIFFERENCE set out here.\n\n\n0.8 Boyfriend in a Coma\nElga argues for INDIFFERENCE by arguing it holds in a special case, and then arguing that the special case is effectively arbitrary, so if it holds there it holds everywhere. The second step is correct, so we must look seriously at the first step. Elga’s conclusions about the special case, DUPLICATION, eventually rest on treating an uncertain proposition as risky.\n\nDUPLICATION\n\nAfter Al goes to sleep researchers create a duplicate of him in a duplicate environment. The next morning, Al and the duplicate awaken in subjectively indistinguishable states.\n\n\nAssume (in all these cases) that before Al goes to sleep he knows the relevant facts of the case. In that case INDIFFERENCE12 dictates that when Al wakes up his credence in I am Al should be 0.5. Elga argues this dictate is appropriate by considering a pair of related cases.\n12 As with earlier cases, strictly speaking we need C-INDIFFERENCE and P-INDIFFERENCE to draw the conclusions suggested unless Al is somehow certain about all other propositions. I will ignore that complication here, and in .\nTOSS-and-DUPLICATION\n\nAfter Al goes to sleep, researchers toss a coin that has a 10% chance of landing heads. Then (regardless of the toss outcome) they duplicate Al. The next morning, Al and the duplicate awaken in subjectively indistinguishable states.\n\n\nElga notes, correctly, that the same epistemic norms apply to Al on waking in DUPLICATION as in TOSS-and-DUPLICATION. So if we can show that when Al wakes in TOSS-and-DUPLICATION his credence in I am Al should be 0.5, that too will suffice to prove INDIFFERENCE correct in this case. The argument for that claim has three premises. (I’ve slightly relabeled the premises for ease of expression.)\n\nPr(H) = 0.1\nPr(H (H \\({\\wedge}\\) A) \\({\\vee}\\) (T \\({\\wedge}\\) A)) = 0.1\nPr(H (H \\({\\wedge}\\) A) \\({\\vee}\\) (T \\({\\wedge}\\) D)) = 0.1\n\nHere Pr is the function from de se propositions to Al’s degree of belief in them, H = The coin lands heads, T = The coin lands tails, A = I am Al and D = I am Al’s duplicate. From (1), (2) and (3) and the assumption that Pr is a probability function it follows that Pr(A) = 0.5, as required. This inference goes through even in the Keynesian theory that distinguishes risk from uncertainty. Premise (1) is uncontroversial, but both (2) and (3) look dubious. Since the argument for (3) would, if successful, support (2), I’ll focus, as Elga does, on (3). The argument for it turns on another case.\n\nCOMA\n\nAs in TOSS-and-DUPLICATION, the experimenters toss a coin and duplicate Al. But the following morning, the experimenters ensure that only one person wakes up: If the coin lands heads, they allow Al to wake up (and put the duplicate into a coma); if the coin lands tails, they allow the duplicate to wake up (and put Al into a coma).\n\n\n(It’s important that no one comes out of this coma, so assume that the victim gets strangled.)\nElga then argues for the following two claims. If in COMA Al gets lucky and pulls through, his credence in H should be 0.1, as it was before he entered the dream world. Al’s credence in H in COMA should be the same as his conditional credence in H should be the same as his conditional credence in H given (H \\({\\wedge}\\) A) \\({\\vee}\\) (T \\({\\wedge}\\) D) in TOSS-and-DUPLICATION. The second premise looks right, so the interest is on what happens in COMA. Elga argues as follows (notation slightly changed):\n\nBefore Al was put to sleep, he was sure that the chance of the coin landing heads was 10%, and his credence in H should have accorded with this chance: it too should have been 10%. When he wakes up, his epistemic situation with respect to the coin is just the same as it was before he went to sleep. He has neither gained nor lost information relevant to the toss outcome. So his degree of belief in H should continue to accord with the chance of H at the time of the toss. In other words, his degree of belief in H should continue to be 10%.\n\nAnd this, I think, is entirely mistaken. Al has no evidence that his evidence is relevant to H, but absence of evidence is not evidence of absence. Four considerations support this conclusion.\nFirst, Al gets some evidence of some kind or other on waking. Certain colours are seen, certain pains and sensations are sensed, certain fleeting thoughts fleet across his mind. Before he sleeps Al doesn’t knows what these shall be. Maybe he thinks of the money supply, maybe of his girlfriend, maybe of his heroine, maybe of kidneys. He doesn’t know that the occurrence of these thoughts is probabilistically independent of his being Al rather than Dup, so he does not know they are probabilistically independent of H. So perhaps he need not retain the credence in H he has before he was drugged. Even if this evidence looks like junk, we can’t rule out that it has some force.\nSecondly, the kind of internalism about evidence needed to support Elga’s position is remarkably strong. (This is where the concerns raised in become most pressing.) Elga notes that he sets himself against both an extreme externalist position that says that Al’s memories and/or perceptions entail that he is Al and against an “intermediate view, according to which Al’s beliefs about the setup only partially undermine his memories of being Al. According to such a view, when Al wakes up his credence in H ought to be slightly higher than 10%.” But matters are worse than that. Elga must also reject an even weaker view that says that Al might not know whether externalism about evidence is true, so he does not know whether his credence in H should change. My view is more sympathetic to that position. When Al wakes, he does not know which direction is credences should move, or indeed whether there is such a direction, so his credence in H should be a spread of values including 0.1.\nThirdly, Al’s position looks like cases where new evidence makes risky propositions uncertain. Mack’s betting strategy for the Gold Cup, a horse race with six entrants, is fairly simple. He rolls a fair die, and bets on whatever number comes up. Jane knows this is Mack’s strategy, but does not how the die landed this time. Nor does she know anything about horses, so the propositions Horse n wins the Gold Cup are uncertain for Jane for each n. Call these propositions wn, and the proposition that Mack’s die landed n dn. Right now, d2 is risky, but h2 is uncertain. Jane hears a party starting next door. Mack’s won. Jane has learned, inter alia, d2 \\(\\leftrightarrow\\) h2. Now it seems that d2, Mack’s die landed 2, inherits the uncertainty of h2, Horse number 2 won the Gold Cup. The formal theory of uncertainty I sketched allows for this possibility. It is possible that there be p, e such that S(p) is a singleton, while S(p  e) is a wide interval, in theory as wide as [0, 1]. This is what happens in Jane’s case, and it looks like it happens in Al’s case too. H used to be risky, but when he wakes he comes to learn H \\({\\leftrightarrow}\\) A, just as Jane learned d2 \\(\\leftrightarrow\\) h2. In each case, the left-hand clause of the biconditional inherits the uncertainty of the right-hand clause.\nFinally, H being uncertain for Al when he wakes in COMA is consistent with the intuition that Al has no reason to change his credences in H in one direction or another when he says goodbye to his duplicate. (Or, for all he knows, to his source.) Perhaps externalist theories of evidence provide some reason to raise these credences, as suggested above, but I do not rely on such theories. What I deny is that the absence of a reason to move one way or the other is a reason to stay put. Al’s credence in H might change in a way that reflects the fact H is now uncertain, just like A is in COMA, just like A is in TOSS-and-DUPLICATION, and, importantly, just like A is in DUPLICATION. I think the rest of Elga’s argument is right. DUPLICATION is a perfectly general case. In any such case, Al should be uncertain, in Keynes’s sense, whether he is the original or the duplicate.\n\n\n0.9 Shooting Dice can be Dangerous\nThe good news, said Dr Evil, is that you are still mortal. Odysseus was not as upset as Dr Evil had expected. The bad news is that I’m thinking of torturing you. I’m going to roll this fair die, and if it lands 6 you will be tortured. If it does not, you will be (tentatively) released, and I’ll create two duplicates of you as you were when you entered this room, repeat this story to both them. Depending on another roll of this fair die, I will either torture them both, or create two duplicates of each of them, and repeat the process until I get to torture someone.13\n13 Dr Evil’s plans create a situation similar to the well known ‘shooting room’ problem. For the best analysis of that problem see Bartha and Hitchcock (1999). Dr Evil has changed the numbers involved in the puzzle a little bit to make the subsequent calculations a little more straightforward. He’s not very good at arithmetic you see.Odysseus thought through this for a bit. So I might be a duplicate you’ve just created, he said. I might not be Odysseus.\nYou might not be, said Dr Evil, although so as to avoid confusion if you’re not him I’ll use his name for you.\nWhat happens if the die never lands 6, asked Odysseus. I’ve seen some odd runs of chance in my time.\nI wouldn’t be so sure of that, said Dr Evil. Anyway, that’s why I said I would tentatively release you. I’ll make the die rolls and subsequent duplication quicker and quicker so we’ll get through the infinite number of rolls in a finite amount of time. If we get that far I’ll just bring everyone back and torture you all. Aren’t I fair?\nFairness wasn’t on Odysseus’s mind though. He was trying to figure out how likely it was that he would be tortured. He was also a little concerned about how likely it was that he was the original Odysseus, and if he was not whether Penelope too had been duplicated. As it turns out, his torturous computations would assist with the second question, though not the third. Two thoughts crossed his mind.\nI will be tortured if that die lands 6, which has a chance of 1 in 6, or if it never lands 6 again, which has a chance of 0. So the chance of my being tortured is 1 in 6. I have no inadmissible evidence, so the probability I should assign to torture is 1 in 6.\nLet’s think about how many Odysseuses there are in the history of the world. Either there is 1, in which case I’m him, and I shall be tortured. Or there are 3, in which case two of them shall be tortured, so the probability that I shall be tortured is 2 in 3. Or there are 7, in which case four of them shall be tortured, so the probability that I shall be tortured is 4 in 7. And so on, it seems like the probability that I shall be tortured approaches 1 in 2 from above as the number of Odysseuses approaches infinity. Except, of course, in the case where it reaches infinity, when it is again certain that I shall be tortured. So it looks like the probability that I will be tortured is above 1 in 2. But I just concluded it is 1 in 6. Where did I go wrong?\nIn his second thought, Odysseus appeals frequently to INDIFFERENCE. He then appeals to something like the conglomerability principle that tripped up Morgan. The principle Odysseus uses is a little stronger than the principle Morgan used. It says that if there is a partition and conditional on each member of the partition, the probability of p is greater than x, then the probability of p is greater than x. As we noted, this principle cannot be accepted in its full generality by one who rejects countable additivity. And one who accepts INDIFFERENCE must reject countable additivity. So where Odysseus goes wrong is in appealing to this inference principle after previously adopting an indifference principle inconsistent with it.\nThis does not mean the case has no interest. Morgan’s case showed that when we have an actual infinity of duplicates, INDIFFERENCE can lead to counterintuitive results, and that the best way out might be to say that Morgan faced a situation of uncertainty, not one of risk. But it might have been thought that something special about Morgan’s case, that she has infinitely many duplicates, might be responsible for the problems here. So it may be hoped that INDIFFERENCE can at least be accepted in more everyday cases. Odysseus shows that hope is in vain. All we need is the merest possibility of there being infinitely many duplicates, here a possibility with zero probability, to create a failure of conglomerability. This suggests that the problems with INDIFFERENCE run relatively deep.\nThe details of how Odysseus’s case plays out given INDIFFERENCE are also interesting, especially to those readers not convinced by my refutation of INDIFFERENCE. For their benefit, I will close with a few observations about how the case plays out.\nAs in Morgan’s case, we can produce two different partitions of the possibility space that seem to support different conclusions about Odysseus’s prospects. Assume for convenience that Dr Evil makes a serial number for each Odysseus he makes, the Homeric hero being number 1, the first two duplicates being 2 and 3, and so on. Let N stand for the number of our hero, M for the number of Odysseuses that are made, and T for the property of being tortured. Then given INDIFFERENCE it behoves Odysseus to have his credences governed by the following Pr function.\n\n\n\\({\\forall}\\)k Pr(T  M = 2k - 1) = 2k-1/(2k - 1)\nPr(T  M = \\({\\infty}\\)) = 1\n\n\\({\\forall}\\)n Pr(T  N = n) = 1/6\n\nBetween 4a and 4b we cover all possible values for M, and in every case Pr(T) is greater than 1/2. More interesting are Odysseus’s calculations about whether he is the Homeric hero, i.e. about whether N = 1. Consider first a special case of this, what the value of Pr(N = 1 N &lt; 8) is. At first glance, it might seem that this should be 1/7, because there are seven possible values for N less than 8. But this is too quick. There are really eleven possibilities to be considered.\n\n\n\nF1: N = 1 and M = 1\nF2: N = 1 and M = 3\nF5: N = 1 and M &gt; 3\n\n\n \nF3: N = 2 and M = 3\nF6: N = 2 and M &gt; 3\n\n\n \nF4: N = 3 and M = 3\nF7: N = 3 and M &gt; 3\n\n\n \n \nF8: N = 4 and M &gt; 3\n\n\n \n \nF9: N = 5 and M &gt; 3\n\n\n \n \nF10: N = 6 and M &gt; 3\n\n\n \n \nF11: N = 7 and M &gt; 3\n\n\n\nBy INDIFFERENCE, each of the properties in each column should be given equal probability. So we have\n\\[\\begin{aligned}\nx &= Pr(F_1 | N &lt; 8)  \\\\\ny &= Pr(F_2 | N &lt; 8) = Pr(F_3 | N &lt; 8) = Pr(F_4 | N &lt; 8)  \\\\\nz &= Pr(F_5 | N &lt; 8) = \\dots = Pr(F_11 | N &lt; 8)  \\end{aligned}\\]\nWe just have to solve for x, y and z. By the Principal Principle we get\n\nPr(M = 1  N = 1) = 1/6\n\\({\\therefore}\\) x = (x + y + z) / 6\nPr(M = 3 N = 1 and M \\({\\geq}\\) 3) = 1/6\n\\({\\therefore}\\) y = (y + z) / 6\n\nAnd since these 11 possibilities are all the possibilities for N &lt; 8, we have\n\nx + 3y + 7z = 1\n\nSolving for all these, we get x = 3/98, y = 5/196 and z = 25/196, so Pr(N = 1  N &lt; 8) = x + y + z = 9/49. More generally, we have the following (the proof of this is omitted): \\[Pr(N = 1 | N &lt; 2^{k+1}) = \\frac{6^k}{\\sum_{i=0}^{k}6^i10^{k-i}}\\]\nSince the RHS \\({\\rightarrow}\\) 0 as k \\({\\rightarrow}\\) \\({\\infty}\\), Pr(N = 1) = 0. Our Odysseus is probably not the real hero. Similar reasoning shows that Pr(N = n) = 0 for all n. So we have another violation of countable additivity. But we do not have, as in Morgan’s case, a constant distribution across the natural numbers. In a sense, this distribution is still weighted towards the bottom, since for any n &gt; 1, Pr(N = 1  N = 1 \\({\\vee}\\) N = n) &gt; 1/2. Of course, I don’t think INDIFFERENCE is true, so these facts about what Odysseus’s credence function will look like under INDIFFERENCE are of purely mathematical interest to me. But it might be possible that someone more enamoured of INDIFFERENCE can use this ‘unbalanced’ distribution to explain some of the distinctive features of the odd position that Odysseus is in.\n\n\n\n\n\n\nReferences\n\nBartha, Paul, and Christopher Hitchcock. 1999. “The Shooting-Room Paradox and Conditionalizing on Measurably Challenged Sets.” Synthese 118 (3): 403–37. https://doi.org/10.1023/a:1005100407551.\n\n\nCampbell, John. 2002. Reference and Consciousness. Oxford: Oxford University Press.\n\n\nChambers, Robert, and John Quiggin. 2000. Uncertainty, Production, Choice, and Agency: The State-Contingent Approach. Cambridge: Cambridge University Press.\n\n\nDreier, James. 2001. “Boundless Good.”\n\n\nElga, Adam. 2000. “Self-Locating Belief and the Sleeping Beauty Problem.” Analysis 60 (2): 143–47. https://doi.org/10.1093/analys/60.2.143.\n\n\n———. 2004. “Defeating Dr. Evil with Self-Locating Belief.” Philosophy and Phenomenological Research 69 (2): 383–96. https://doi.org/10.1111/j.1933-1592.2004.tb00400.x.\n\n\nFara, Delia Graff. 2001. “Phenomenal Continua and the Sorites.” Mind 110 (440): 905–36. https://doi.org/10.1093/mind/110.440.905.\n\n\nFraassen, Bas van. 1990. “Figures in a Probability Landscape.” In Truth or Consequences, edited by J. M. Dunn and A. Gupta, 345–56. Amsterdam: Kluwer.\n\n\n———. 1995. “Belief and the Problem of Ulysses and the Sirens.” Philosophical Studies 77 (1): 7–37. https://doi.org/10.1007/bf00996309.\n\n\nGoodman, Nelson. 1951. The Structure of Appearance. Cambridge, MA: Harvard University Press.\n\n\nHájek, Alan. 2005. “Scotching Dutch Books.” Philosophical Perspectives 19: 139–51. https://doi.org/10.1111/j.1520-8583.2005.00057.x.\n\n\nHetherington, Stephen. 2001. Good Knowledge, Bad Knowledge: On Two Dogmas of Epistemology. Oxford: Oxford University Press.\n\n\nJeffrey, Richard. 1983. “Bayesianism with a Human Face.” In Testing Scientific Theories, edited by J. Earman (ed.). Minneapolis: University of Minnesota Press.\n\n\nKeynes, John Maynard. 1921. Treatise on Probability. London: Macmillan.\n\n\n———. 1937. “The General Theory of Employment.” Quarterly Journal of Economics 51 (2): 209–23. https://doi.org/10.2307/1882087.\n\n\nKnight, Frank. 1921. Risk, Uncertainty and Profit. Chicago: University of Chicago Press.\n\n\nKyburg, Henry. 1974. The Logical Foundations of Statistical Inference. Dordrecht: Reidel.\n\n\nLevi, Isaac. 1974. “On Indeterminate Probabilities.” Journal of Philosophy 71 (13): 391–418. https://doi.org/10.2307/2025161.\n\n\n———. 1980. The Enterprise of Knowledge. Cambridge, MA.: MIT Press.\n\n\nLewis, David. 1970. “How to Define Theoretical Terms.” Journal of Philosophy 67 (13): 427–46. https://doi.org/10.2307/2023861.\n\n\n———. 1979. “Attitudes de Dicto and de Se.” Philosophical Review 88 (4): 513–43. https://doi.org/10.2307/2184646.\n\n\nMcGee, Vann. 1999. “An Airtight Dutch Book.” Analysis 59 (4): 257–65. https://doi.org/10.1093/analys/59.4.257.\n\n\nMilne, Peter. 1991. “Scotching the Dutch Book Argument.” Erkenntnis 32 (1): 105–26. https://doi.org/10.1007/bf00209558.\n\n\nPoole, David, Alan Mackworth, and Randy Goebel. 1998. Computational Intelligence: A Logical Approach. Oxford: Oxford University Press.\n\n\nRamsey, Frank. 1926. “Truth and Probability.” In Philosophical Papers, edited by D. H. Mellor, 52–94. Cambridge: Cambridge University Press.\n\n\nSchick, Frederick. 1986. “Dutch Bookies and Money Pumps.” Journal of Philosophy 83 (2): 112–19. https://doi.org/10.2307/2026054.\n\n\nShafer, Glenn. 1976. A Mathematical Theory of Evidence. Princeton: Princeton University Press.\n\n\nWilliamson, Timothy. 1998. “Conditionalizing on Knowledge.” British Journal for the Philosophy of Science 49 (1): 89–121. https://doi.org/10.1093/bjps/49.1.89."
  },
  {
    "objectID": "posts/mmp/index.html",
    "href": "posts/mmp/index.html",
    "title": "Many Many Problems",
    "section": "",
    "text": "0.1 Schiffer’s Problem\nStephen Schiffer suggests the following argument refutes supervaluationism. The central point is that, allegedly, the supervaluational theory of vague singular terms says false things about singular terms in speech reports.\n\nPublished in Philosophical Quarterly 55: 481-501.\nPhoto by Yoni Lerner via Creative Commons.\n\n\nPointing in a certain direction, Alice says to Bob, ‘There is where Harold and I first danced the rumba.’ Later that day, while pointing in the same direction, Bob says to Carla, ‘There is where Alice said she and Harold first danced the rumba.’ Now consider the following argument:\nBob’s utterance was true.\nIf the supervaluational semantics were correct, Bob’s utterance wouldn’t be true.\n\\(\\therefore\\) The supervaluational semantics isn’t correct. (Schiffer 2000, 321)\n\nAssuming Bob did point in pretty much the same direction as Alice, it seems implausible to deny (1). The argument is valid. So the issue is whether (2) is correct. Schiffer has a quick argument for (2), which I will paraphrase here. On supervaluational semantics, a sentence is true iff each of its acceptable precisifications is true. In this case, this means that if Bob’s utterance is true then it must be true however we precisify ‘there’. Each precisification of ‘there’ will be a (precise) place, and since ‘there’ is rather vague, many of these precisifications will be acceptable. For Bob’s utterance to be true, then, Alice must have said of every one of those places that it was the place where Harold and her first danced the rumba. But Alice couldn’t have said all those things, so (2) is true.\nSchiffer suggests that one way out of this problem would be to accept the existence of a vague object: the place where Harold and Alice first danced the rumba. I will note in section four several reasons for thinking the cost of this move is excessive. Fortunately, there is a cheaper way home.\nSchiffer underestimates the scope of supervaluationism. On Schiffer’s vision of the theory, a precisification assigns a precise content to a word, and hence to a sentence, then the world determines whether that content is satisfied, and hence whether the sentence is true on that precisification. This is hardly an unorthodox view of how supervaluationism works, it seems for instance to be exactly the view defended in Keefe (2000), but it is neither the only way, nor the best way, forward. We could say, rather, that a precisification assigns content to every linguistic token in the world, and the truth conditions of every one of these tokens is then determined relative to that global assignment of content. So if a precisification P assigns a place x to Bob’s word ‘there’, Bob’s utterance is true according to that precisification iff P also assigns x to Alice’s utterance of ‘there’. That is, Bob’s utterance is true according to P iff the precisification of his words by P just is what Alice said according to P.1\n1 Following Schiffer, we ignore the vagueness in ‘is where Harold and I first danced the rumba.’ This phrase is vague, but its vagueness raises no extra issues of philosophical importance.2 Thanks to John Hawthorne for the following argument.It is a dramatic widening of the scope of precisifications to claim that they assign content to every linguistic token in the world, rather than just words in the sentence under consideration, but it can be justified.2 Consider how we would react if later in the day, pointing in the crucial direction, Alice said, ‘Harold and I never danced the rumba there.’ We would think that Alice had contradicted herself – that between her two statements she must have said something false. A standard supervaluationist account, where sentences are precisified one at a time, cannot deliver this result. On such a view, it might be that each of Alice’s utterances are true on some precisifications, so they are both neither true nor false. On my theory, each precisification applies to both of Alice’s utterances (as well as every other utterance ever made) and since on each precisification one or other of the utterances is false, it turns out supertrue that Alice said something false, as desired. The current view allows for penumbral connections between sentences, as well as penumbral connections within sentences. Just as someone who says, “That is red and orange” says something false, my theory decrees that someone who says, “That is red. That is orange,” while pointing at the same thing says something false, even if the object is in the vague area ‘between’ red and orange.\nIt is crucial for this response to work that on every precisification, Alice and Bob’s demonstratives are co–referential. It does not seem like a particular expansion of supervaluational theory to posit this as a penumbral connection between the two words. At least, it seems plausible enough to do this if Alice and Bob really are pointing in a similar direction. If their demonstrations are only roughly co-directional, then on some precisifications they may well pick out different objects. This will definitely happen if some admissible precisification of Alice’s ‘there’ is not an admissible precisification of Bob’s ‘there’. In such a case, the theory here predicts that Bob’s utterance will be indeterminate in truth value. But if Alice and Bob only vaguely pointed in the same direction this is the correct prediction.\n\n\n0.2 Natural Properties\nSchiffer’s problem seems to have been solved with a minimum of fuss, but there is still a little work to do. Above I posited a penumbral connection between Alice’s and Bob’s words without explaining how such a connection could arise. This connection can be explained by some general considerations about content, considerations closely tied to the view of vagueness as semantic indecision that provides the best motivation for supervaluationism. As a few writers have pointed out (Quine 1960; Putnam 1980; Kripke 1982), there is not enough in our dispositions to use words to fix a precise content all terms in our lexicon. This does not immediately imply a thorough-going content scepticism because, as a few writers have also pointed out (Putnam 1973; Kripke 1980; Lewis 1983, 1984), meanings ain’t (entirely) in the head. Sometimes our words refer to a particular property or object rather than another not because our dispositions make this so, but because of some particular feature of that property or object. David Lewis calls this extra feature ‘naturalness’: some properties and objects are more natural than others, and when our verbal dispositions do not discriminate between different possible contents, naturalness steps in to finish the job and the more natural property or object gets to be the content.\nWell, that’s what happens when things go well. Vagueness happens when things don’t go well. Sometimes our verbal dispositions are indiscriminate between several different contents, and no one of these is more natural than all the rest. In these cases there will be many unnatural contents not eliminated by our dispositions that naturalness does manage to eliminate, but there will be still be many contents left uneliminated. Consider, for example, all the possible properties we might denote by ‘tall woman’. As far as our usage dispositions go, it might denote any one of the following properties: woman taller than 1680mm, woman taller than 1681mm, woman taller than 1680.719mm, etc. And it does not seem that any of these properties are more natural than any other. Hence there is no precise fact about what the phrase denotes. Hence it is vague. In sum, our dispositions are never enough to settle the content of a term. In some cases, such as ‘water’, ‘rabbit’, ‘plus’, ‘brain’ and ‘vat’, nature is kind enough to, more or less, finish the job. In others it is not, and vagueness is the result.\n(The above reasoning has a surprising consequence. Perhaps our verbal dispositions are consistent with the predicate Tall X denoting the property of being in the top quartile of Xs by height. Unlike each of the properties mentioned in the text, this is a more natural property than many of its competitors. So if this kind of approach to vagueness is right, there might not be quite as much vagueness as we expected.)\nIf this is how vagueness is created, then there is a natural way to understand how precisifications remove vagueness. Vagueness arises because more natural than is a partial order on putative contents, and hence there might be no most natural content consistent with our verbal dispositions. If this relation only defined a strict ordering, so whatever the candidate meanings were, one of them would be most natural, vagueness might be defeated. Well, that isn’t true in reality, but it is true on each precisification. Every precisification is a completion of the ‘naturalness’ partial order. That is, each precisification P defines a strict order, more natural-P than, on possible contents of terms such that o1 is more natural-P than o2 if (but not only if) o1 is more natural than o2. The particular contents of terms according to P is then defined by using the more natural-P than relation where the more natural than relation is used in the real theory of content.\nThis conjecture meshes nicely with my theory of the role of precisifications. First, it explains why precisifications apply to the whole of language. Since a precisification does not just remedy a defect in a particular word, but a defect in the content generation mechanism, precisifications are most naturally applied not just to a single word, but to every contentful entity. Secondly, it explains why we have the particular penumbral connections we actually have. Recall that it was left a little unexplained above why Alice’s and Bob’s use of ‘there’ denoted the same precise place. On the current conjecture, Alice’s term refers to a particular place x according to P because x is more natural–P than all the other places to which Alice might have referred. If this is so, then x will be more natural–P than all the other places to which Bob might have referred, so it will also be the referent according to P of Bob’s there. Hence according to every precisification, Bob’s utterance will be true, as Schiffer required.\nWe can also explain some other unexplained penumbral connections by appeal to naturalness. Consider the sentence David Chalmers is conscious. Unless this is supertrue, supervaluationism is in trouble. It is vague just which object is denoted by David Chalmers. On every precisification, there are other objects that massively overlap David Chalmers. Indeed, these very objects are denoted by ‘David Chalmers’ on other precisifications. These objects are not conscious, since if one did there would be two conscious objects where, intuitively, there is just one. But each of these rogue objects must be in the extension of ‘conscious’ on the precisifications where it is the denotation of ‘David Chalmers’. So ‘conscious’ must be vague in slightly unexpected ways, and there must be a penumbral connection between it and ‘David Chalmers’: on every precisification, whatever object is denoted by that name is in the extension of ‘conscious’, while no other potential denotata of ‘David Chalmers’ is in the extension. How is this penumbral connection to be explained? Not by appeal to the meanings of the terms! Even if ‘David Chalmers’ has descriptive content, it is highly implausible that this includes being conscious. (After all, unless medicine improves a bit in a thousand years Chalmers will not be conscious.) Rather, this penumbral connection is explained by the fact that the very same thing, naturalness, is used in resolving the vagueness in the terms ‘conscious’ and ‘David Chalmers’. If the precisification makes one particular possible precisification of ‘David Chalmers’, say d1, more natural than another, d2, then it will make properties satisfied by d1­ more natural than those satisfied by d2, so every precisification will make the denotation of ‘David Chalmers’ fall into the extension of ‘conscious’.\nWe can say the same thing about Alice’s original statement: That is where Harold and I first danced the rumba. Since one can’t first dance the rumba with Harold in two different places, it seems Alice’s statement can’t be true relative to more than one precisification of ‘That’. But really the phrase after ‘is’ is also vague, and there is a penumbral connection (via naturalness) between it and the demonstrative. Hence we can say Alice’s statement is supertrue without appealing to any mysterious penumbral connections.\n\n\n0.3 McGee and McLaughlin’s Challenge\nVann McGee and Brian McLaughlin (2000) raise a challenge for supervlauational approaches to the Problem of the Many that uses belief reports in much the way that Schiffer’s problem uses speech reports. They fear that without further development, the supervaluational theory cannot distinguish between the de re and de dicto readings of (4).\n\nRalph believes that there is a snow-capped mountain within sight of the equator.\n\nThey claim, correctly, that (4) should have both a de dicto reading and a de re reading, where in the latter case it is a belief about Kilimanjaro. The problem with the latter case is unclear how Ralph’s belief can be about Kilimanjaro itself. To press the point, they consider an atom at or around the base of Kilimanjaro, called Sparky, and define “Kilimanjaro(+) to be the body of land constituted … by the atoms that make up Kilimanjaro together with Sparky [and] Kilimanjaro(-) [to] be the body of land constituted … by the atoms that make up Kilimanjaro other than Sparky.” (129) The problem with taking (4) to be true on a de re reading is that “there isn’t anything, either in his mental state or in his neural state or in his causal relations with his environment that would make one of Kilimanjaro(+) and Kilimanjaro(-), rather than the other, the thing that Ralph’s belief is about.” (146) So if the truth of (4) on a de re reading requires that Ralph believes a singular, or object-dependent, proposition, about one of Kilimanjaro(+) and Kilimanjaro(-), then (4) cannot be true. Even worse, if the truth of (4) requires that Ralph both that Ralph believes a singular proposition about Kilimanjaro(+), that it is a snow-capped mountain within sight of the equator, and the same proposition about Kilimanjaro(-), then given some knowledge about mountains on Ralph’s part, (4) cannot be true, because that would require Ralph to mistakenly believe there are two mountains located roughly where Kilimanjaro is located.\nWe should not be so easily dissuaded. It is hard to identify exactly which features of Ralph’s “mental state or neural state or causal relations with his environment” that make it the case that he believes that two plus two equals four, but does not believe that two quus two equals four. (I assume Ralph is no philosopher, so lacks the concept QUUS.) I doubt, for example, that the concept PLUS has some causal influence over Ralph that the concept QUUS lacks. But Ralph does have the belief involving PLUS, and not the belief involving QUUS. He has this belief not merely in virtue of his mental or neural states, or his causal interactions with his environment, but in virtue of the fact that PLUS is a more natural concept than QUUS, and hence is more eligible to be a constituent of his belief.\nSo if Kilimanjaro(+) is more natural than Kilimanjaro(-), it will be a constituent of Ralph’s belief, despite the fact that there is no other reason to say his belief is about one rather than the other. Now, in reality Kilimanjaro(+) is no more natural than Kilimanjaro(-). But according to any precisification, one of them will be more natural than the other, for precisifications determine content by determining relative naturalness. Hence if Ralph has a belief with the right structure, in particular a belief with a place for an object (roughly, Kilimanjaro) and the property being within sight of the equator, then on every precisification he has a singular belief that a Kilimanjaro-like mountain is within sight of the equator. And notice that since naturalness determines both mental content and verbal content, on every precisification the constituent of that belief will be the referent of ‘Kilimanjaro’. So even on a de re reading, (4) will be true.\nSchiffer’s problem showed that we should not take precisifications to be defined merely over single sentences. McGee and McLaughlin’s problem shows that we should take precisifications to set the content not just of sentences, but of mental states as well. Precisifications do not just assign precise content to every contentful linguistic token, but to every contentful entity in the world, including beliefs. This makes the issue of penumbral connections that we discussed in section two rather pressing. We already noted the need to establish penumbral connections between separate uses of demonstratives. Now we must establish penumbral connections between words and beliefs. The idea that precisifications determine content by determining relative naturalness establishes these connections.\nTo sum up, McGee and McLaughlin raise three related problems concerning de re belief. Two of these concern belief reports. First, how can we distinguish between de re and de dicto reports? If I am right, we can distinguish between these just the way Russell suggested, by specifying the scope of the quantifiers. McGee and McLaughlin suspect this will not work because in general we cannot argue from (5) to (6), given the vagueness of ‘Kilimanjaro’.\n\nKilimanjaro is such that Ralph believes it to be within sight of the equator.\nThere is a mountain such that Ralph believes it to be within sight of the equator.\n\nWhether or not we want to accept a semantics in which we must restrict existential generalisation in this way as a general rule, we can give an independent argument that (6) is true whenever (4) is true on a de re reading (i.e. whenever (5) is true). The argument is just that on every precisification, the subject of Ralph’s salient singular belief is a mountain, so (6) is true on every precisification. This argument assumes that there is a penumbral connection between the subject of this belief, as we might say the referent of ‘Kilimanjaro’ in his language of thought3, and the word ‘mountain’. But since we have already established that there is such a connection between ‘Kilimanjaro’ in his language of thought and ‘Kilimanjaro’ in public language, and there is obviously a connection between ‘Kilimanjaro’ in public language and the word ‘mountain’, as ‘Kilimanjaro is a mountain’ is supertrue, this assumption is safe. So the second puzzle McGee and McLaughlin raise, how it can be that the relevant de re reports can be true, has also been addressed.\n3 I do not mean here to commit myself to anything like the language of thought hypothesis. This is just being used as a convenient shorthand.4 This is hard, but not perhaps impossible. One might say that on every precisification, Ralph believes a proposition that has a mountain as a constituent, and hence as an essential part.There is a third puzzle McGee and McLaughlin raise that the reader might think I have not addressed. How can it be that Ralph can actually have a de re belief concerning Kilimanjaro? I have so far concentrated on belief reports, not merely on beliefs, and my theory has relied crucially on correlations between the vagueness in these reports and the vagueness in the underlying belief. It might be thought that I have excluded the most interesting case, the one where Ralph has a particular belief with Kilimanjaro itself as a constituent. While I will end up denying Ralph can have such a belief, I doubt this a problematic feature of my view. The theory outlined here denies that Ralph has object–dependent beliefs, but not that he has de re beliefs. I deny that Ralph has a belief that has Kilimanjaro(+) as a constituent, but it is hard to see how Ralph could have such a belief, since it very hard to see how he could have had a belief that has Kilimanjaro(+) rather than Kilimanjaro(-) as its subject. (This was McGee and McLaughlin’s fundamental point.) If we think that having a de re belief implies having a belief whose content is an object–dependent proposition, then we must deny that there are de re beliefs about Kilimanjaro. Since there is no object that is determinately a constituent of the proposition Ralph believes, it is a little hard to maintain that he believes an object–dependent proposition.4 But this is not the only way to make sense of de re beliefs.\nRobin Jeshion has argued that whether a belief is de re depends essentially on its role in cognition. “What distinguishes de re thought is its structural or organisational role in thought” [Jeshion (2002) 67]5 I won’t rehearse Jeshion’s arguments here, just their more interesting conclusions. We can have de re beliefs about an object iff we have a certain kind of mental file folder for the object. This folder need not be generated by acquaintance with the object, so acquiantanceless de re belief is possible. Indeed, the folder could have been created defectively, so there is no object that the information in the folder is about.6 In this case, the contents of the folder are subjectless de re beliefs. Jeshion doesn’t discuss this, but presumably the folder must not have been created purely to be the repository for information about the bearer of a certain property, whoever or whatever that is. We have to rule out this option if we follow Szabó (2000) in thinking the folder metaphor plays a crucial role in explaining our talk and thought involving descriptions. Provided the folder was created with the intent that it record information about some object, rather than merely information about whatever object has a particular property, its contents are de re beliefs. (To allow for distinct folders ‘about’ non-existent objects, we must allow that it is possible that such folders do have their reference fixed by their contents, but as long as this was not the intent in creation these folders can suffice for de re belief. This point lets us distinguish between my folder for Vulcan and my folder for The planet causing the perturbations of Mercury. Both are individuated by the fact that they contain the proposition This causes the perturbations of Mercury. It is this feature of the folder that fixes their reference, or in this case their non-reference. Only in the latter case, however, was this the intent in creating the folder, so its contents are de dicto beliefs, while the contents of the former are de re beliefs.)\n5 I don’t know if Jeshion would accept the corollary that if belief is too unstructured to allow for the possibility of such organisational roles, then there is no de re belief, but I do.6 Which is not just to say that there is no object that has all the properties in the folder. This is neither necessary nor sufficient for the folder to be about the object, as Kripke’s discussion of ‘famous deeds’ descriptivism should make clear.Now we have the resources to show how Ralph can have de re beliefs concerning Kilimanjaro. When Ralph hears about it, or sees it, he opens a file folder for Kilimanjaro. This is not intended to merely be a folder for the mountain he just heard about, or saw. It is intended to be a folder for that. (Imagine here that I am demonstrating the mountain in question.) The Kripkenstein point about referential indeterminacy applies to folders as much as to words. This point is closely related to Kripke’s insistence that his indeterminacy argument does not rely on behaviourism. So if Ralph’s folder is to have a reference, it must be fixed in part by the naturalness of various putative referents. But that is consistent with Ralph’s folder containing de re beliefs, since unless Ralph is a certain odd kind of philosopher, he will not have in his folder that Kilimanjaro is peculiarly eligible to be a referent. So the referent of the folder is not fixed by its contents (as the referent for a folder about The mountain over there, whatever it is, would be, or how the referent for a folder about The natural object over there, whatever it is, would be), and the contents of this folder are still de re beliefs Ralph has about Kilimanjaro. This was a bit roundabout, but we have seen that the Problem of the Many threatens neither the possibility that Ralph is the subject of true de re belief ascriptions, nor that he actually has de re beliefs.\n\n\n0.4 Vague Objects\n\n“I think the principle that to be is to be determinate is a priori, and hence that it is a priori that there is no de re vagueness”. (Jackson 2001, 657–58)\n\nSo do I. I also think there are a few arguments for this claim, though some of them may seem question-begging to the determined defender of indeterminate objects. Most of these arguments I will just mention, since I assume the reader has little desire to see them detailed again. One argument is just that it is obvious that there is no de re vagueness. Such ‘arguments’ are not worthless. The best argument that there are no true contradictions is of just this form, as Priest (1998) shows. And it’s a good argument! Secondly, Russell’s point that most arguments for de re vagueness involve confusing what is represented with its representation still seems fair (Russell 1923). Thirdly, even though the literature on this is a rather large, it still looks like the Evans-Salmon argument against vague identities works, at least under the interpretation David Lewis gives it, and this makes it hard to see how there could be vague objects (Evans 1978; Salmon 1981; Lewis 1988). Fourthly, Mark Heller (1996) argues that we have to allow that referential terms are semantically vague. He says we have to do so to explain context dependence but there are a few other explanatory projects that would do just as well. Since semantic conceptions of vagueness can explain all the data that are commonly taken to support ontological vagueness, it seems theoretically unparsimonious to postulate ontological vagueness too. That’s probably enough, but let me add one more argument to the mix. Accepting that Kilimanjaro is be a vague material object distinct from both Kilimanjaro(+) and Kilimanjaro(-) has either metaphysical or logical costs. To prove this, I derive some rather unpleasant metaphysical conclusions from the assumption that Kilimanjaro is vague. The proofs will use some contentious principles of classical logic, but rejecting those, and hence rejecting classical logic, would be a substantial logical cost. The most contentious such principle used will be an instance of excluded middle: Sparky is or is not a part of Kilimanjaro. I also assume that if for all x other than Sparky that x is a part of y iff it is a part of z, then if Sparky is part of both y and z, or part of neither y nor z, then y and z coincide. If someone can contrive a mereological theory that rejects this principle, it will be immune to these arguments.\nIt is very plausible that material objects are individuated by the materials from which they are composed, so any coincident material objects are identical. Properly understood, that is a good account of what it is to be material. The problem is getting a proper understanding. Sider (1996) interprets it as saying that no two non-identical material objects coincide right now. His project ends up running aground over concerns about sentences involving counting, but his project, of finding a strong interpretation of the principle is intuitively compelling. David (Lewis 1986 Ch. 4) defends a slight weaker version: no two non-identical material objects coincide at all times. Call this the strong composition principle (scp). The scp is (classically) inconsistent with the hypothesis that Kilimanjaro is vague. If Sparky is part of Kilimanjaro, then Kilimanjaro and Kilimanjaro(+) always coincide. If Sparky is not part of Kilimanjaro then Kilimanjaro and Kilimanjaro(-) always coincide. Either way, two non-identical objects always coincide, which the scp does not allow.\nSome think the scp is refuted by Gibbard’s example of Lumpl and Goliath (Gibbard 1975). The most natural response to Gibbard’s example is to weaken our individuation principle again, this time to: no two non-identical material objects coincide in all worlds at all times. Call this the weak compositional principle (wcp). Since there are worlds in which Goliath is composed of bronze, but Lumpl is still a lump of clay in those worlds, Lumpl and Goliath do not refute the wcp. Some may think that even the wcp is too strong7, but most would agree that if vague objects violated the wcp, that would be a reason to believe they don’t exist.\n7 Kit Fine (1994) does exactly this.Given a plausible metaphysical principle, which I call Crossover, vague objects will violate the wcp. As shown above, Kilimanjaro actually (always) coincides with Kilimanjaro(+) or Kilimanjaro(-), but is not identical with either. Crossover is the following principle:\n\nCrossover\n\nFor any actual material objects x and y there is an object z that coincides with x in the actual world and y in all other worlds.\n\n\nGiven that arbitrary fusions exist, Crossover is entailed by, but does not entail, the doctrine of arbitrary modal parts: that for any object o and world w, if o exists in w then o has a part that only exists in w. But Crossover does not have the most surprising consequence of the doctrine of arbitrary modal parts: that for any object o there is an object that has essentially all the properties o actually has.\nLet K1 be the object that coincides with Kilimanjaro in this world and Kilimanjaro(+) in all other worlds. Let K2 be the object that coincides with Kilimanjaro in this world and Kilimanjaro(-) in all other worlds. If Sparky is part of Kilimanjaro then K1 and Kilimanjaro(+) coincide in all worlds, but they are not identical, since it is determinate that Sparky is actually part of Kilimanjaro(+) and not determinate that it is part of K1. If Sparky is not part of Kilimanjaro then K2 and Kilimanjaro(-) coincide in all worlds, but they are not identical, since it is determinate that Sparky is not actually part of Kilimanjaro(-) and not determinate that it is not part of K2. Either way, we have a violation of the wcp. So the following three claims are (classically) inconsistent.\n\nCrossover.\nThe wcp.\nKilimanjaro is a vague object that indeterminately has Sparky as a part.\n\nI think the first two are highly plausible, so accepting (c) is costly. I already noted the plausibility of the wcp, so the focus should be on Crossover. On Lewis’s account of modality, it is clearly true, as is the stronger doctrine of arbitrary modal parts. On a fictionalist theory of modality based on Lewis’s account, it is still true, or at least true in the fiction that we must adopt to make sense of modal talk. So the principle is not without merits. And dialectically, opposing Crossover will be problematic for the believer in vague objects. Either an object’s modal profile is determined by its categorical properties or it isn’t. If it is, then the wcp will entail the scp, so by the above reasoning vague objects will be inconsistent with the wcp. If it is not, then it is hard to see why an object could not have a completely arbitrary modal profile, say the profile of some other ordinary material object. But that means Crossover is true, and again we cannot have both the wcp and vague objects. Probably the best way out for the believer in vague objects will be to short-circuit this reasoning by abandoning classical logic, presumably by declining to endorse the version of excluded middle with which I started. But that is undoubtedly a costly move, particularly for a supervaluationist.\n\n\n0.5 McKinnon on Coins and Precisifications\nMost of our discussions of the Problem of the Many relate to the vagueness in a single singular term, and a single ordinary object. As McKinnon reminds us, however, there is not just one mountain in the world, there are many of them, and supervaluationists are obliged to say plausible things about statements that are about many mountains. Or, to focus on McKinnon’s example, we must not only have a plausible theory of coins, but of coin exhibitions. These do raise distinctive problems. Imagine we have an exhibition with, as we would ordinarily say, 2547 coins, each numbered in the catalogue. So to each number n there correspond millions of coin-like entities, coin*s in Sider’s helpful phrase (Sider 2001), and each precisification assigns a coin* to a number. In general, Sider holds that something is an F* iff it has all the properties necessary and sufficient for being an F except the property of not massively overlapping another F. There are some interesting questions about how independent these assignments can be. If one precisification assigns coin* c1 to n1, and another assigns coin* c2 to n2 (distinct from n1) then is there a guaranteed to be a precisification that assigns both c1 to n1 and c2 to n2? In other words, may the precisifications of each numeral (construed as a coin denotation) be independent of each other? The following example suggests not. Say Cj is the set of coin*s that are possible precisifications of j. This set may be vague because of higher–order vagueness, but set those difficulties aside. If every member of C1728 has a duplicate in C1729, then presumably only precisifications that assigned duplicates to ‘1728’ and ‘1729’ would be admissible. If the exhibition has two Edward I pennies on display to show the obverse and reverse, and miraculously these coins are duplicates, such a situation will arise.\nThis case is fanciful, so we don’t know whether in reality the precisifications of the numerals are independent. We probably can’t answer this question, but this is no major concern. McKinnon has found a question which the supervaluationist should feel a need to answer, but to which neither answer seems appropriate. Say that a precisification is principled iff there is some not-too-disjunctive property F such that for each numeral n, the precisification assigns to n the F-est coin* in Cn. If F does not come in degrees, then the precisification assigns to n the F in Cn. McKinnon’s question to the supervaluationist is: Are all precisifications principled? He aims to show either answering ‘yes’ or ‘no’ gets the supervaluationist in trouble. ‘Yes’ leads to there being too few precisifications; ‘No’ leads to there being too many. Let us look at these in order.\nI have little to say for now on the first horn of this dilemma. McKinnon’s survey of principled precisifications only considers cases where F is intrinsic, and I postpone for now investigation of extrinsic principles. Nevertheless, he does show that if F must be intrinsic, then there are not enough principled precisifications to generate all the indeterminacy our coin exhibit intuitively displays. The other horn is trickier.\nA precisification must not only assign a plausible coin* to each numeral, it must do so in such a way that respects penumbral connections. McKinnon thinks that unprincipled, or arbitrary precisifications, will violate (NAD) and (NAS).\n\nNon-Arbitrary Differences (NAD)\n\nFor any coin and non-coin, there is a principled difference between them which forms the basis for one being a coin and the other being a non-coin.\n\nNon-Arbitrary Similarities (NAS)\n\nFor any pair of coins, there is a principled similarity between them which forms the basis for their both being coins.\n\n\nMcKinnon holds these are true, so they should be true on all precisifications, but they are not true on unprincipled precisifications, so unprincipled precisifications are unacceptable. The motivation for (NAD) and (NAS) is clear. When we list the fundamental properties of the universe, we will not include being a coin. Coinness doesn’t go that deep. So if some things are coins, they must be so in virtue of their other properties. From this (NAD) and (NAS) follow.\nThe last step looks dubious. Consider any coin, for definiteness say the referent of ‘1728’, and a coin* that massively overlaps it. The coin* is not a coin, so (a) one of these is a coin and the other is not, and (b) the minute differences between them cannot form the basis for a distinction between coins and non-coins. Hence (NAD) and (NAS) fail. At best, it seems, we can justify the following claims. If something is a coin* and something else is not, then there is a principled difference between them that makes one of them a coin* and the other not. Something is a coin iff it is a coin* that does not excessively overlap a coin. If this is the best we can do at defining ‘coin’, then the prospects for a reductive physicalism about coins might look a little dim, though this is no threat to a physicalism about coins that stays neutral on the question of reduction. (I trust no reader is an anti-physicalist about coins, but it is worth noting how vexing questions of reduction can get even when questions of physicalism are settled.)\nSo I think this example refutes (NAD) and (NAS). Do I beg some questions here? Well, my counterexample turns crucially on the existence of kinds of objects, massively overlapping coin*s, that some people reject, and indeed that some find the most objectionable aspect of the supervaluationist solution. But this gets the burden of proof the wrong way around. I was not trying to refute (NAD) and (NAS). I just aimed to parry an argument based on those principles. I am allowed to appeal to aspects of my theory in doing so without begging questions. I do not want to rest too much weight on this point, however, for issues to do with who bears the burden of proof are rarely easily resolved, so let us move on.\nMy main response to McKinnon’s dilemma is another dilemma. If the principled similarities and differences in (NAD) and (NAS) must be intrinsic properties, then those principles are false, because there is no principled intrinsic difference between a coin and a token, or a coin and a medal. If the principled similarities and differences in (NAD) and (NAS) may be extrinsic properties, then those principles may be true, but then the argument that there are not enough principled precisifications fail, since now we must consider precisifications based on extrinsic principles. Let’s look at the two halves of that dilemma in detail, in order.\nA subway token is not a coin. Nor is a medal.8 But in their intrinsic respects, subway tokens often resemble certain coins more than some coins resemble other coins. Imagine we had a Boston subway token (which looks a bit like an American penny, but larger), an American penny, a British 20p piece (which is roughly heptagonal) and an early Australian holey dollar (which has a hole in it). There is no non-disjunctive classification of these by intrinsic properties that includes the penny, the 20p piece and the holey dollar in one group, and the subway token in the other. Any group that includes the penny and the other coins will include the token as well. So if we restrict attention to intrinsic similarities and differences, (NAD) and (NAS) are false.\n8 Some people I have asked think tokens are coins, but no one thinks medals are coins, so if you (mistakenly) think tokens are coins, imagine all my subsequent arguments are phrased using medals rather than tokens.9 Note that I say little here about what the intent of the creator must be. I don’t think that the intent must always be to create legal tender. A ceremonial coin that is created, for example, to be tossed before the start of a sporting match is still a coin, although it is not intended to be tender. But intent still matters. If someone had made a duplicate of that ceremonial coin with the intent of awarding it as a medal to the victorious captain, it would be a medal and not a coin.10 Because of the problems raised in the previous footnote, I will not try and say just what this intention amounts to. There are complications when (a) the creator is a corporate entity rather than an individual and (b) the coins are mass–produced rather than produced individually. But since the story is essentially the same, I leave the gruesome details out here.There is a difference between these coins and the subway token. The coins were produced with the intent of being legal tender, the token was not. Perhaps we can find a difference between coins and non-coins based on the intent of their creator.9 This might make (NAD) and (NAS) true. But note that given the theory of precisifications developed in section 3, on every precisification, one and only one of the precisifications of ‘1728’ will be the subject of an intention on the part of its manufacturer. Just which of the objects is the subject of this intent will vary from precisification to precisification, but there is only one on every precisification. So we can say that on every precisification, the coin is the one where the intent of its creator was that it be used in a certain way. Indeed, on any precisification we may have antecedently thought to have existed, we can show that precisification to be principled by taking F to be the property being created with intent of being used in a coin-like way.10 So now we can say that restricting attention to the principled precisifications does not unduly delimit the class of precisifications.\nLet’s sum up. To argue against the possibility of unprincipled precisifications, McKinnon needed to justify (NAD) and (NAS). But these are only true when we allow ‘principled differences’ to include differences in creatorial intent. And if we do that we can see that every prima facie admissible precisification is principled, so we can give an affirmative answer to McKinnon’s question.\nIt might be objected that this move relies heavily on the fact that for many artefacts creative intent is constitutive of being the kind of thing that it is. But a Problem of the Many does not arise only for artefacts, so my solution does not generalise. This is little reason for concern since McKinnon’s problem does not generalise either. (NAD) and (NAS) are clearly false when we substitute ‘mountain’ for ‘coin’. Consider a fairly typical case where it is indeterminate whether we have one mountain or two.11 In this case it might be not clear whether, for example, we have one mountain with a southern and a northern peak, or two mountains, one of them a little north of the other. Whether there is one mountain here or two, clearly the two peaks exist, and their fusion exists too. The real question is which of these three things is a mountain. However this question is resolved, a substitution instance of (NAD) with the two objects being the southern peak and the fusion of the two peaks will be false. So in this case a relatively unprincipled precisification will be acceptable. The point here is that mountain*s that are not mountains exist (either the peaks or their fusion will do as examples), and that suffices to refute McKinnon’s alleged penumbral connections and allow, in this case, a negative answer to his question.\n11 This case is rather important in the history of the problem, because its discussion in Quine (1960) is one of the earliest presentations in print of anything like the problem of the many.\n\n0.6 Sorensen on Direct Reference\nAccording to orthodoxy, we can use descriptions to determine the reference of names without those descriptions becoming part of the meaning of the name. This, apparently, is what happened when Leverrier introduced ‘Neptune’ to name, not merely describe, the planet causing certain perturbations, and when someone introduced ‘Jack the Ripper’ to name, not merely describe, the person performing certain murders. So let us introduce ‘Acme’ as the name for the first tributary of the river Enigma. As Sorensen suggests, this can create certain problems.\n\nWhen [explorers] first travel up the river Enigma they finally reach the first pair of river branches. They name one branch ‘Sumo’ and the other ‘Wilt’. Sumo is shorter but more voluminous than Wilt. This makes Sumo and Wilt borderline cases of ‘tributary’ … ‘Acme’ definitely refers to something, even though it is vague whether it refers to Sumo and vague whether it refers to Wilt. (Sorensen 2000, 180)\n\nIf ‘Acme’, ‘Sumo’ and ‘Wilt’ are all vague names related in this way, Sorensen thinks the supervaluationist has a problem. The sentences ‘Acme is Sumo’ and ‘Acme is Wilt’ both express propositions of the form \\(\\langle x = y \\rangle\\). For exactly one of them, x is y. Since the proposition contains just the objects x and y (and the identity relation) but not their route into the proposition, there is no vagueness in the proposition. Hence there is no way to precisify either proposition. So a supervaluationist cannot explain how these propositions are vague.\nThis is no problem for supervaluationism, since supervaluationism says that sentences, not propositions, are vague. Indeed, most supervaluationists would say that no proposition is ever vague. Thinking they are vague is just another instance of the fallacy Russell identified: attributing properties of the representation to the entity, in this case a proposition, represented.\nBut maybe there is a problem in the area. One natural way of spelling out the idea that names directly refer to objects is to say that the meaning of a name is its referent. And one quite plausible principle about precisifications is that precisifications must not change the meaning of a term, they may merely provide a meaning where none exists. Now the supervaluationist has a problem. For it is true that one of Sorensen’s identity sentences is true in virtue of its meaning, since its meaning determines that it expresses a proposition of the form \\(\\langle x = x \\rangle\\). But each sentence is false on some precisifications, so some precisifications change the meaning of the terms involved.\nThe best way to respond to this objection is simply to bite the bullet. We can accept that some precisifications alter meanings provided we can provide some other criteria for acceptability of precisifications. I offered one such proposal in section 2. An acceptable precisification takes the partial order more natural than, turns it into a complete order without changing any of the relations that already exist, and uses this new relation to generate meanings. If we proceed in this way it is possible, for all we have hitherto said, that on every precisification the proposition expressed by ‘Acme is Sumo’ will be of the form \\(\\langle x = y \\rangle\\), so just the named object, rather than the method of naming, gets into the proposition. The central point is that since precisifications apply to the processes that turn semantic intentions into meanings, rather than to sentences with meanings, there is no guarantee they will preserve meanings. But if we like directly referential theories of names we should think this perfectly natural. If names are directly referential then Sorensen’s argument that there are vague sentences that are true in virtue of their meaning works. But this is consistent with supervaluationism.\nOne challenge remains. If precisifications change meanings, why should we care about them, or about what is true on all of them? This is not a new challenge; it is a central plank in Jerry Fodor and Ernest Lepore’s (1996) attack on supervaluationism. A simple response is just to say that we should care about precisifications because this method delivers the right results in all core cases, and an intuitively plausible set of results in contentious cases. This kind of instrumentalism about the foundations of a theory is not always satisfying.12 But if that’s the biggest problem supervaluationists have, they should be able to sleep a lot easier than the rest of us.\n12 The largest debate in the history of philosophy of economics concerned whether we could, or should, be instrumentalists about the ideally rational agents at the core of mainstream microeconomic theory. See Friedman (1953) for the classic statement of the instrumentalist position, and Hausman (1992) for the most amusing and enlightening of the countably many responses.\n\n0.7 Conclusions and Confessions\nI have spent a fair bit of time arguing that supervaluationism is not vulnerable to a few challenges based on the Problem of the Many. Despite doing all this, I don’t believe supervaluationism to be quite true. So why spend this time? Because the true theory of vagueness will be a classical semantic theory, and everything I say about supervaluationism above applies mutatis mutandis to all classical semantic theories. I focussed on supervaluationism because it is more familiar and more popular, but I need not have.\nWhat is a classical semantic theory? That’s easy - it’s a theory that is both classical and semantic. What is a classical theory? It is one that incorporates vagueness while preserving classical logic. How much of classical logic must we preserve? That’s a hard question, though it is relevant to determining whether supervaluationism is (as it is often advertised) a classical theory. Williamson (1994) notes that supervaluationism does not preserve classical inference rules, and Hyde (1997) notes that it does not preserve some classically valid multiple–conclusion sequents. Keefe (2000) argues that neither of these constitutes an important deviation from classical logic. I’m inclined to disagree with Keefe on both points. Following Read (2000), I take it that the best response to the anti-classical arguments in Dummett (1991) takes the essential features of classical logic to be its inferential rules as formulated in a multiple–conclusion logic. But we need not adjudicate this dispute here. Why should we want a classical theory? The usual arguments for it are based on epistemic conservatism, and I think these arguments are fairly compelling. I also think that no non–classical theory will be able to provide a plausible account of quantification.13\n13 See the last section of Weatherson (2005) for a detailed defence of this claim.What is a semantic theory? It is one that makes vagueness a semantic phenomenon. It is not necessarily one that makes vagueness a linguistic phenomenon. That would be absurd in any case, since clearly some non–linguistic entities, maps, beliefs and pictures for example, are vague. But the more general idea that vagueness is a property only of representations is quite attractive. It links up well with the theory of content Lewis outlines in “Languages and Language” - all Languages (in his technical sense) are precise, vagueness in natural language is a result of indecision about which Language we are speaking.\nTrenton Merricks (2001) argues against this picture, claiming that all semantic vagueness (he says ‘linguistic’, but ignore that) must arise because of metaphysical or epistemic vagueness. He claims that if (17) is vague, then so is (18), and (18)’s vagueness must be either metaphysical or semantic.\n\nHarry is bald.\n‘Bald’ describes Harry.\n\nOne might question the inference from (17)‘s vagueness to (18) - on some supervaluational theories if (17) is vague then (18) is false. But I will let that pass, for there is a simpler problem in the argument. Merricks claims that if (18) is vague, then it is vague whether ’Bald’ has the property describing Harry, and this is a kind of metaphysical vagueness. It is hard to see how this follows. If there is metaphysical vagueness, there is presumably some object o and some property F such that it is vague whether the object has the property. Presumably the object here is the word ‘bald’ and the property is describing Harry. But words alone do not have properties like describing Harry. At best, words in languages do so. So maybe the object can be the ordered pair \\(\\langle \\text{`Bald'}, l \\rangle\\), where l is a language. But which one? Not one of Lewis’s Languages, for then it is determinate whether &lt;‘Bald’, l&gt; has the property describing Harry. So maybe a natural language, perhaps English! But it is doubly unclear that English is an object. First, it is unclear whether we should reify natural languages to such a degree that we accept that ‘English’ refers to anything at all. Secondly, if we say ‘English’ does refer, why not say that it refers to one of Lewis’s Languages, thought it is vague which one? That way we can say that the sentence ‘Bald’ in English describes Harry is vague without there being any object that vaguely instantiates a property. Now on a supervaluational theory this approach may have the unwanted consequence that “English is a precise language” is true, since it is true on all precisifications. It does not seem that this problem for the supervaluationist generalises to be a problem for all semantic theories of vagueness, so Merricks has raised no general problem for semantic theories of vagueness. (The problem for the supervaluationist here is not new. For some discussion see Lewis’s response, in “Many, but Almost One” to the objection, there attributed to Kripke, that the supervaluationist account makes it true that all words are precise.)\nIf we have a classical semantic theory that provides a concept of determinateness, then we can define acceptable precisifications as maximal consistent extensions of the set of determinate truths. Given that, it follows pretty quickly that determinate truth implies truth on all precisifications. And this is sufficient for the major objections canvassed above to get a foothold, and hence be worthy of response, though as we have seen none of them will ultimately succeed. Still, our theory may differ from supervaluationism in many ways. For one thing, it might explain determinateness in ways quite different from those in supervaluationism. For example, the theory in Field (2000) is a classical semantic theory14, but it clearly goes beyond supervaluational theory because it has an interesting, if ultimately flawed, explanation of determinateness in terms of Shafer functions. Other classical semantic theories may differ from supervaluationism by providing distinctive theories of higher order vagueness.\n14 At least, it strikes me as a classical semantic theory. Ryan Wasserman has tried to convince me that properly understood, it is really an epistemic theory. Space prevents a thorough account of why I think Field’s theory is flawed. Briefly, I think the point in Leeds (2000) that Field’s concept of a numerical degree of belief needs substantially more explanation than Field gives it can be developed into a conclusive refutation.The most promising research programs in vagueness are within the classical semantic framework. Like all research programs, these programs need a defensive component, to fend off potential refutations and crisis. This avoids unwanted crises in the program, and as we have seen here we can learn a bit from seeing how to defend against certain attacks. There will undoubtedly be more challenges in the time ahead, but for now the moves in this paper brings the defensive side of the program up to date.\n\n\n\n\n\n\nReferences\n\nDummett, Michael. 1991. The Logical Basis of Metaphysics.Cambridge, MA: Harvard.\n\n\nEvans, Gareth. 1978. “Can There Be Vague Objects?” Analysis 38 (4): 208. https://doi.org/10.1093/analys/38.4.208.\n\n\nField, Hartry. 2000. “Indeterminacy, Degree of Belief, and Excluded Middle.” Noûs 34 (1): 1–30. https://doi.org/10.1111/0029-4624.00200.\n\n\nFine, Kit. 1994. “Compounds and Aggregates.” Noûs 28 (2): 137–58. https://doi.org/10.2307/2216046.\n\n\nFodor, Jerry A., and Ernest Lepore. 1996. “What Cannot Be Valuated Cannot Be Valuated, and It Cannot Be Supervaluated Either.” Journal of Philosophy 93 (10): 516–35. https://doi.org/10.5840/jphil1996931013.\n\n\nFriedman, Milton. 1953. “The Methodology of Positive Economics.” In Essays in Positive Economics, 3–43. Chicago: University of Chicago Press.\n\n\nGibbard, Allan. 1975. “Contingent Identity.” Journal of Philosophical Logic 4 (2): 187–221. https://doi.org/10.1007/bf00693273.\n\n\nHausman, Daniel. 1992. “Why Look Under the Hood?” In Essays in Philosophy and Economic Methodology, 70–73. Cambridge: Cambridge University Press.\n\n\nHeller, Mark. 1996. “Against Metaphysical Vagueness.” Philosophical Perspectives 10: 177–85. https://doi.org/10.2307/2216242.\n\n\nHyde, Dominic. 1997. “From Heaps and Gaps to Heaps of Gluts.” Mind 106 (424): 641–60. https://doi.org/10.1093/mind/106.424.641.\n\n\nJackson, Frank. 2001. “Responses.” Philosophy and Phenomenological Research 62 (3): 653–64. https://doi.org/10.2307/2653545.\n\n\nJeshion, Robin. 2002. “Acquiantanceless de Re Belief’.” In Meaning and Truth: Investigations in Philosophical Semantics, edited by Joseph Keim Campbell, Michael O’Rourke, and David Shier, 53–74. New York: Seven Bridges Press.\n\n\nKeefe, Rosanna. 2000. Theories of Vagueness. Cambridge: Cambridge University Press.\n\n\nKripke, Saul. 1980. Naming and Necessity. Cambridge: Harvard University Press.\n\n\n———. 1982. Wittgenstein on Rules and Private Language. Oxford: Basil Blackwell.\n\n\nLeeds, Stephen. 2000. “A Disquotationalist Looks at Vagueness.” Philosophical Topics 28 (1): 107–28. https://doi.org/10.5840/philtopics200028119.\n\n\nLewis, David. 1983. “New Work for a Theory of Universals.” Australasian Journal of Philosophy 61 (4): 343–77. https://doi.org/10.1080/00048408312341131.\n\n\n———. 1984. “Devil’s Bargains and the Real World.” In The Security Gamble: Deterrence in the Nuclear Age, edited by Douglas Maclean, 141–54. Totowa, NJ: Rowman; Allenheld.\n\n\n———. 1986. On the Plurality of Worlds. Oxford: Blackwell Publishers.\n\n\n———. 1988. “Vague Identity: Evans Misunderstood.” Analysis 48 (3): 128–30. https://doi.org/10.1093/analys/48.3.128.\n\n\nMcGee, Vann, and Brian McLaughlin. 2000. “The Lessons of the Many.” Philosophical Topics 28 (1): 129–51. https://doi.org/10.5840/philtopics200028120.\n\n\nMerricks, Trenton. 2001. “Varieties of Vagueness.” Philosophy and Phenomenological Research 62 (1): 145–57. https://doi.org/10.2307/2653593.\n\n\nPriest, Graham. 1998. “What Is so Bad about Contradictions?” Journal of Philosophy 95 (8): 410–26. https://doi.org/10.2307/2564636.\n\n\nPutnam, Hilary. 1973. “Meaning and Reference.” Journal of Philosophy 70 (19): 699–711. https://doi.org/10.2307/2025079.\n\n\n———. 1980. “Models and Reality.” Journal of Symbolic Logic 45 (3): 464–82. https://doi.org/10.2307/2273415.\n\n\nQuine, W. V. O. 1960. Word and Object. Cambridge, MA.: MIT Press.\n\n\nRussell, Bertrand. 1923. “Vagueness.” Australasian Journal of Philosophy and Psychology 1 (2): 84–92. https://doi.org/10.1080/00048402308540623.\n\n\nSalmon, Nathan. 1981. Reference and Essence. Princeton: Princeton University Press.\n\n\nSchiffer, Stephen. 2000. “Replies.” Philosophical Issues 10 (1): 320–43. https://doi.org/10.1111/j.1758-2237.2000.tb00029.x.\n\n\nSider, Theodore. 1996. “All the World’s a Stage.” Australasian Journal of Philosophy 74 (3): 433–53. https://doi.org/10.1080/00048409612347421.\n\n\n———. 2001. “Maximality and Intrinsic Properties.” Philosophy and Phenomenological Research 63 (2): 357–64. https://doi.org/10.1111/j.1933-1592.2001.tb00109.x.\n\n\nSorensen, Roy. 2000. “Direct Reference and Vague Identity.” Philosophical Topics 28 (1): 177–94. https://doi.org/10.5840/philtopics200028123.\n\n\nSzabó, Zoltan Gendler. 2000. “Descriptions and Uniqueness.” Philosophical Studies 101 (1): 29–57. https://doi.org/10.1023/A:1026437211756.\n\n\nWeatherson, Brian. 2005. “True, Truer, Truest.” Philosophical Studies 123 (1-2): 47–70. https://doi.org/10.1007/s11098-004-5218-x.\n\n\nWilliamson, Timothy. 1994. Vagueness. Routledge."
  },
  {
    "objectID": "posts/deliberation/index.html",
    "href": "posts/deliberation/index.html",
    "title": "Deliberation Costs",
    "section": "",
    "text": "Humans making decisions face two big limitations. First, we are informationally limited. We don’t know everything and sometimes we don’t know what we need to know in order to make the optimal decision. Second, we are computationally limited. We can’t process all of the information that we have available to us before a decision needs to be made. Or at least, we can’t do this in a costless manner.\n\nUnpublished draft. Thanks to audiences at Michigan, Toronto, and the Arizona Philosophy Workshop for valuable feedback, not all of which I’ve yet incorporated.\n\nOrthodox decision theory treats these two limitations very differently. To a first approximation, the whole point of orthodox decision theory is to handle the question of how to make decisions without full information. But on the other hand, orthodox decision theory simply assumes away the computational limitations. Orthodox decision theory is a theory of rational choice, and rationality is here understood to involve not being subject to these pesky computational limitations.\n\nPicture by Andy Warhol via Creative Commons.\n\nI think this is a serious mistake. In particular, I think there are several cases where our theory of rational choice can only give us the correct verdict if we allow it to be sensitive to both kinds of limitation. In this paper, I will discuss three such kinds of cases, and describe how rational choice theory might be revised so as to handle them.\nI’m far from the first to notice this asymmetry in how orthodox decision theory handles the two limitations. For approximately as long as decision theory has existed, there have been people who have noted the oddity of ignoring computational limitations. But there has always been a powerful argument against taking computational limitations seriously. It is long been thought that attempt to do this would lead to a nasty kind of regress. It isn’t entirely clear how the regress argument here is supposed to run; the argument is more often alluded to than carefully stated. But it is a major challenge and I will have something to say about it.\nThe short version of what I’m going to say is that while we should take both kinds of limitations seriously, we should treat them differently in our final theory. We should, as orthodox decision theory says, take a broadly evidentialist approach to informational limitations. That is, good decision makers should have credence distributions over the possibilities left open by their evidence, those credences should be sensitive to the evidence they have, and the choices they make should maximize expected value given those credences. On the other hand, we should take a broadly reliabilist approach to computational limitations. Good decision makers will adopt procedures for managing their own limitations that reliably produce good outcomes. There is no requirement that they adopt the procedures that are best supported by their evidence. The reason there is no requirement they do that is that figuring out what those reliable procedures might be is even more computationally taxing then the problem of deciding what to do. And if we’re going to respect the fact that people can’t always complete difficult computational tasks, we shouldn’t expect them to perform the incredibly difficult task of figuring out how to adjust their decision procedures in light of the evidence about their own limitations.\nYou might think that the reason orthodox theory treats computational limitations this way is that it is simply trying to provide a theory of ideal decision making. There is a separate question, to be sure, of how non-ideal agents should make decisions. But the thought, or at least the hope, is that clearly stating what the ideal looks like will help the non-ideal agents in this task. I think there is a little reason to believe that this hope will be realized. In general, knowing what the ideal looks like provides us with very little guidance as to how to get better. Knowing that any ideal outcome has a certain attribute does not provide a reason, even a defeasible reason, for trying to to acquire that attribute (Lipsey and Lancaster 1956).\nWe can see this by simply thinking about the one limitation that orthodox theory does take seriously. A good decision maker without full information will in general behave nothing like a good decision maker with full information. For example, if you put the informationally limited agent in a casino they will do the exact opposite of what an informationally unlimited agent will do. The informationally unlimited agent will play every game and do quite well at them. The informationally limited agent, on the other hand, will play none of the games because they all have negative expected returns. I think is the general case. It’s a bad idea to emulate the ideal agent, because us non ideal agents often have to act so as to minimize the damage that have other limitations can do. Everyone agrees that is true in the case of informational limitations, and I am going to try and argue that it’s also true for computational limitations.\nSo here’s the plan for the paper. First, in sections 1-2, I will introduce the three kinds of cases but I think motivate taking computational limitations seriously. Then, in sections 3-4, I will introduce the regress argument that is alleged to show that any attempt to do this will end badly. In sections 5-6, I will show how the broadly reliabilist approach to handling computational limitations that I favor can be motivated, and can avoid the regress. Sections 7 and 8 are contingent speculations about how non-ideal agents might choose reliably, and observations on how these debates connect to other philosophical debates\nBefore I start on this, it’s helpful to get clear on exactly what I am taking my orthodox opponent to be committed to. I take them to endorse the following three constraints on a theory of rational choice.\n\nRational agents have credences, and these credences are responsive to evidence.\nThese credences also respect the probability calculus.\nRational agents take actions that maximize their expected utility given these credences.\n\nThere are a lot of questions that I do not take my orthodox opponent to have a settled view on, though of course many orthodox theorists will have one view or another on one or other of these questions. These questions include\n\nWhether rationality puts any constraints on what can be valued;\nWhether our theory of rationality divides up failures to make rational choices into epistemic failures, axiological failures, and practical failures, and if it does make such a division, exactly how it should be made;\nWhether rationality requires that agent be self-aware, i.e., whether they know what their own credences and utilities are; and\nExactly what evidence is, or what it means for credences to be responsive to evidence.\n\nMy hope is that I can provide an objection to orthodoxy that is insensitive to how orthodox theorists answered these questions. That’s a rather ambitious project, since the answers one gives to these questions will help provide responses to some of the objections I shall offer. But I’m not going to try to anticipate every possible response the orthodox theorist could make. Indeed, I don’t think that I’ve got anything like a knock down watertight argument against all possible versions of orthodoxy. What I think I do have is a set of reasons to consider an alternative, and an outline of what that alternative may look like.\n\n1 Three Puzzles\n\n1.0.1 Puzzle One - Close Calls\nLet’s start with an example from a great thinker. It will require a little exegesis, but that’s not unusual when using classic texts.\n\nWell Frankie Lee and Judas Priest\nThey were the best of friends\nSo when Frankie Lee needed money one day\nJudas quickly pulled out a roll of tens\nAnd placed them on the footstool\nJust above the potted plain\nSaying “Take your pick, Frankie boy,\nMy loss will be your gain.”\n          (“The Ballad of Frankie Lee and Judas Priest”, 1968.\n           Lyrics from Bob Dylan (2016) 225)\n\nOn a common reading of this, Judas Priest isn’t just asking Frankie Lee how much money he wants to take, but which invididual notes. Let’s simplify, and say that it is common ground that Frankie should only take $10, so the choice Frankie Lee has is which of the individual notes he will take. This will be enough to set up the puzzle.\nAssume something else that isn’t in the text, but which isn’t an implausible addition to the story. The world Frankie Lee and Judas Priest live in is not completely free of counterfeit notes. And it would be bad for Frankie Lee to take a counterfeit note. It won’t matter just how common these notes are, or how bad it would be. But our puzzle will be most vivid if each of these are relatively small quantities. So there aren’t that many counterfeit notes in circulation, and the (expected) disutility to Frankie Lee of having one of them is not great. There is some chance that he will get in trouble, but the chance isn’t high, and the trouble isn’t any worse than he’s suffered before. Still, other things exactly equal, Frankie Lee would prefer a genuine note to a counterfeit one.\nNow for some terminology to help us state the problem Frankie Lee is in. Assume there are \\(k\\) notes on the footstool. Call them \\(n_1, \\dots, n_k\\). Let \\(c_i\\) be the proposition that note \\(n_i\\) is counterfeit, and its negation \\(g_i\\) be that it is genuine. And let \\(t_i\\) be the act of taking note \\(n_i\\). Let \\(U\\) be Frankie Lee’s utility function, and \\(Cr\\) his credence function.\nIn our first version of the example, we’ll make two more assumptions. Apart from the issue of whether the note is real or counterfeit, Frankie Lee is indifferent between the notes, so for some \\(h, l\\), \\(U(t_i | g_i) = h\\) and \\(U(t_i | c_i) = l\\) for all \\(i\\), with of course \\(h &gt; l\\). If we add an extra assumption that Frankie Lee thinks the probability that each of the notes is genuine is the same, we get the intuitive result back that he is indifferent between the banknotes.\nBut is that really a plausible move? Here is one way to start worrying about it. Change the example so that the country Frankie Lee and Judas Priest live in is very slowly modernising its currency. It is getting rid of old fashioned, and somewhat easy to counterfeit, paper money, and joining the civilised countries that use plastic money. Moreover, plastic bank notes are, for all intents and purposes, impossible to counterfeit. (At least, no one has yet figured out how to do it, and Frankie Lee knows this.)\nSome of the notes Judas Priest offers are the new plastic notes, and some are the old paper notes. Now it seems clear that Frankie Lee should take one of the new notes, and not merely on aesthetic grounds. Rather, the fact that the plastic notes are less likely to be counterfeit is a reason to prefer to take them. And this is true no matter how unlikely it is that the paper notes are counterfeit, as long as this likelihood is non-zero.\nBut now go back to the base case, where all the money is paper. A small change in probability of being counterfeit seems to be enough to give Frankie Lee a reason to prefer some of them to the others. Indeed, the only way for him to be indifferent between the notes is if the probability of any one being counterfeit is exactly the same as the probability of any other being counterfeit. But that two of the notes have exactly the same probability of being counterfeit is a measure zero event. It isn’t happening. So Frankie Lee shouldn’t be indifferent between the notes.\nOf course, if the notes look exactly the same, then the probability that each is counterfeit is exactly the same. But that’s only because that probability is one. In that case Frankie Lee should run away as fast as possible. That’s not the realistic case.\nThe realistic case is that the notes look a little different to each other in ever so many respects. (Including, one hopes, their serial numbers.) Some will be a little more faded, or a little more torn, or a little more smudged or crumpled, than the others. It is overwhelmingly likely that these fades, tears, smudges, spills etc are the result of the normal wear and tear on the currency - wear and tear that paper notes tend to wear on their face. But every imperfection in every note is some evidence, very very marginal evidence but still evidence, that the note is counterfeit. And since Frankie Lee’s evidence, on any extant theory of evidence, includes visible things like the tears, smudges etc on the notes, they are pieces of evidence that affect the evidential expected utility of taking each note. So if Frankie Lee wants to maximize evidential expected utility, there is precisely one note he should take. Though it probably won’t be obvious to him which one it is, so rationality requires Frankie Lee to spend some time thinking about which note is best.\nThis is intuitively the wrong result. (Though it is what happens in the song.) Frankie Lee should just make a choice more or less arbitrarily. Since expected utility theory does not say this, expected utility theory is wrong.\nThe Frankie Lee and Judas Priest case is weird. Who offers someone money, then asks them to pick which note to take? And intuitions about such weird cases cases are sometimes deprecated. Perhaps the contrivance doesn’t reveal deep problems with a philosophical theory, but merely a quirk of our intuitions. I am not going to take a stand on any big questions about the epistemology of intuitions here. Rather, I’m going to note that cases with the same structure as the story of Frankie Lee and Judas Priest are incredibly common in the real world. Thinking about the real world examples can both show us how pressing the problems are, and eventually show us a way out of those problems.\nSo let’s leave Frankie Lee for now, just above the potted plain, and think about a new character. We will call this one David, and he is buying a few groceries on the way home from work. In particular, he has to buy a can of chickpeas, a bottle of milk, and a carton of eggs. To make life easy, we’ll assume each of these cost the same amount: five dollars.1 None of these purchases is entirely risk free. Canned goods are pretty safe, but sometimes they go bad. Milk is normally removed from sale when it goes sour, but not always. And eggs can crack, either in transit or just on the shelf. In David’s world, just like ours, each of these risks is greater than the one that came before.\n1 If that sounds implausible to you, make the can/bottle/carton a different size, or change the currency to some other dollars than the one you’re instinctively using. But I think this examples works tolerably well when understand as involving, for example, East Carribean dollars.David has a favorite brand of chickpeas, of milk, and of eggs. And he knows where in the store they are located. So his shopping is pretty easy. But it isn’t completely straightforward. First he gets the chickpeas. And that’s simple; he grabs the nearest can, and unless it is badly dented, or leaking, he puts in in his basket. Next he goes onto the milk. The milk bottles have sell-by dates printed in big letters on the front. And David checks that he isn’t picking up one that is about to expire. His store has been known to have adjacent bottles of milk with sell-by dates 10 days apart, so it’s worth checking. But as long as the date is far enough in the future, he takes it and moves on. Finally, he comes to the eggs. (Nothing so alike as eggs, he always thinks to himself.) Here he has to do a little more work. He takes the first carton, opens it to see there are no cracks on the top of the eggs, and, finding none, puts that in his basket too. He knows some of his friends do more than this; flipping the carton over to check for cracks underneath. But the one time he tried that, the eggs ended up on the floor. And he knows some of his friends do less; just picking up the carton by the underside, and only checking for cracks if the underside is sticky where the eggs have leaked. He thinks that makes sense too, but he is a little paranoid, and likes visual confirmation of what he’s getting. All done, he heads to the checkout, pays his $15, and goes home.\nThe choice David faces when getting the chickpeas is like the choice Frankie Lee faces. He has to choose from among a bunch of very similar seeming options. In at least the chickpeas example, he should just pick arbitrarily. But for very similar reasons to Frankie Lee, expected utility theory won’t say that.\nThe standard model of practical rationality that we use in philosophy is that of expected utility maximization. But there are both theoretical and experimental reasons to think that this is not the right model for choices such as that faced by Frankie or David. maximizing expected utility is resource intensive, especially in contexts like a modern supermarket, and the returns on this resource expenditure are unimpressive. What people mostly do, and what they should do, is choose in a way that is sensitive to the costs of adopting one or other way.\nThere are two annoying terminological issues around here that I mostly want to set aside, but need to briefly address in order to forestall confusion.\nI’m going to assume maximizing expected utility means taking the option with the highest expected utility given facts that are readily available. So if one simply doesn’t process a relevant but observationally obvious fact, that can lead to an irrational choice. I might alternatively have said that the choice was rational (given the facts the chooser was aware of), but the observational process was irrational. But I suspect that terminology would just add needless complication.\nI’m going to spend more time on another point that is partially terminological, but primarily substantive. That’s whether we should identify the choice consequentialists recommend in virtue of the fact that it maximizes expected utility with one of the options (in the ordinary sense of option), or something antecedent. I’m going to stipulate (more or less) that it is consistent with consequentialism that the choice can be something antecedent - it can be something like a choice procedure. And I’m going to argue that this is what the rational consequentialist should choose.\nI’m going to call any search procedure that is sensitive to resource considerations a satisficing procedure. This isn’t an uncommon usage. Charles Manski (2017) uses the term this way, and notes that it has rarely been defined more precisely than that. But it isn’t the only way that it is used. Mauro Papi (2013) uses the term to exclusively mean that the chooser has a ‘reservation level’, and they choose the first option that crosses it. This kind of meaning will be something that becomes important again in a bit. And Chris Tucker (2016), following a long tradition in philosophy of religion, uses it to mean any choice procedure that does not optimize. Elena Reutskaja et al -Reutskaja et al. (2011) contrast a ‘hybrid’ model that is sensitive to resource constraints with a ‘satisficing’ model that has a fixed reservation level. They end up offering reasons to think ordinary people do (and perhaps should) adopt this hybrid model. So though they don’t call this a satisficing approach, it just is a version of what Manski calls satisficing. Andrew Caplin et al -Caplin, Dean, and Martin (2011), on the other hand, describe a very similar model to Reutskaja et al’s hybrid model - one where agents try to find something above a reservation level but the reservation level is sensitive to search costs - as a form of satisficing. So the terminology around here is a mess. I propose to use Manski’s terminology: agents satisfice if they choose in a way that is sensitive to resource constraints.\nIdeally they would maximize, subject to constraints, but saying anything more precise than this brings back the regress problem that we started with. Let’s set it aside just a little longer, and go back to David and the chickpeas.\nWhen David is facing the shelf of chickpeas, he can rationally take any one of them - apart perhaps from ones that are seriously damaged. How can expected utility theory capture that fact? I think if it identifies David’s choices with the cans on the shelf, and not with a procedure for choosing cans, then it cannot.\nIt says that more than one choice is permissible only if the choices are equal in expected utility. So the different cans are equal in expected utility. But on reflection, this is an implausible claim. Some of the cans are ever so slightly easier to reach. Some of the cans will have ever so slight damage - a tiny dint here, a small tear in the label there - that just might indicate a more serious flaw. Of course, these small damages are almost always irrelevant, but as long as the probability that they indicate damage is positive, it breaks the equality of the expected utility of the cans. Even if there is no visible damage, some of the labels will be ever so slightly more faded, which indicates that the cans are older, which ever so slightly increases the probability that the goods will go bad before David gets to use them. Of course in reality this won’t matter more than one time in a million, but one in a million chances matter if you are asking whether two expected utilities are strictly equal.\nThe common thread to the last paragraph is that these objects on the shelves are almost duplicates, but the most careful quality control doesn’t produce consumer goods that are actual duplicates. There are always some differences. It is unlikely that these differences make precisely zero difference to the expected utility of each choice. And even if they do, discovering that is hard work.\nSo it seems likely that, according to the expected utility model, it isn’t true that David could permissibly take any can of chickpeas that is easily reachable and not obviously flawed. Even if that is true, it is extremely unlikely that David could know it to be true. But one thing we know about situations like David’s is that any one of the (easily reached, not clearly flawed) cans can be permissibly chosen, and David can easily know that. So the expected utility model, as I’ve so far described it, is false.\n\n\n1.0.2 Puzzle Two - Psychic Costs of Bias\nIn all but a vanishingly small class of cases, the different cans will not have the same expected utility. But figuring out which can has the highest expected utility is going to be work. It’s possible in principle, I suppose, that someone could be skilled at it, in the sense that they could instinctively pick out the can whose shape, label fading, etc., reveal it to have the highest expected utility. Such a skill seems likely to be rare - though I’ll come back to this point below when considering some other skills that are probably less rare. For most people, maximizing expected utility will not be something that can be done through skill alone; it will take effort. And this effort will be costly, and almost certainly not worth it. Although one of the cans will be ever so fractionally higher in expected utility than the others, the cost of finding out which can this is will be greater than the difference in expected utility of the cans. So aiming to maximize expected utility will have the perverse effect of reducing one’s overall utility, in a predictable way.\nThe costs of trying to maximize expected utility go beyond the costs of engaging in search and computation. There is evidence that people who employ maximizing strategies in consumer search end up worse off than those who don’t. Schwartz et al. (2002) reported that consumers could be divided in ‘satisficers’ and ‘maximizers’. And once this division is made, it turns out that the maximizers are less happy with individual choices, and with their life in general. This finding has been extended to work on career choice (Iyengar, Wells, and Schwartz 2006), where the maximizers end up with higher salaries but less job satisfaction, and to friend choice (Newman et al. 2018), where again the maximizers seem to end up less satisfied.\nThere are two things that can go wrong when you try to maximize. Maximising requires considering the strengths and weaknesses of each of the choices. That means, it requires giving at least some consideration to the negative attributes of what you end up choosing. And these can cause you to be less happy with the actual choice when those negative attributes are realized. And it also means giving consideration to the positive attributes of the choices not made. And this could lead to regret when you have to adopt a choice that lacks those positive attributes. So there are two very natural paths by which the attempt to maximize could backfire, any incurs costs that wouldn’t have been incurred by the person who simply makes an arbitrary choice.\nThere is evidence here that both these paths are realised, and that maximisers do indeed end up psychically worse off than satisficers. Now to be sure, there are both empirical and theoretical reasons to be cautious about accepting these results at face value. Whether the second path, from consideration of positive attributes of the non-chosen option to felt regret, is psychologically significant seems to be tied up with the ‘paradox of choice’ (Schwartz 2004), the idea that sometimes giving people even more choices makes them less happy with their outcome, because they are more prone to regret. But it is unclear whether such a paradox exists. One meta-analysis (Scheibehenne, Greifeneder, and Todd 2010) did not show the effect existing at all, though a later meta-analysis finds a significant mediated effect (Chernev, Böckenholt, and Goodman 2015). But it could also be that the result is a feature of an idiosyncratic way of carving up the maximizers from the satisficers. Another way of dividing them up produces no effect at all (Diab, Gillespie, and Highhouse 2008).\nThe theoretical reasons relate to Newcomb’s problem. Even if we knew that maximizers were less satisfied with how things are going than satisficers, it isn’t obvious that any one person would be better off switching to satisficing. They might be like a two-boxer who would get nothing if they took one-box. There is a little evidence in Iyengar, Wells, and Schwartz (2006) that this isn’t quite what is happening, but the overall situation is unclear.\nBut the philosophical questions here are a bit simpler than the psychological questions. Whether maximisers in general are subject to these two kinds of costs is a tricky empirical question. Whether there could be one maximiser who is subject to them, and who knows that they are, is a much easier question. Of course someone could be like that. Indeed, it seems beyond dispute that many real people are subject to these costs. The only empirical question is whether these people are a significant minority or a significant majority.\nAnd all it takes for the philosophical question to be pressing is that some choosers are, and know that they are, disposed to incur these psychological costs if they consciously try to maximise expected value. Our theory of choice should have something to say to them, and orthodox theory is silent. Especially for choices that are intended to produce happiness, the happiness effects of the choice procedure itself should be taken into account. But orthodox theory ignores it.\n\n\n1.0.3 Puzzle Three - Mathematical Challenges\nFor a final case, let’s consider Kyla, a student taking a mathematics exam. It’s getting towards the end of the exam and she’s facing quite a bit a time pressure. She comes to a true false question, and she knows that she knows how to solve questions like it. But she also knows that there are other kinds of questions that she is better at solving under time pressure. And while this is just a true false question, the exam is set up so that she gets a large negative score if she gets the question wrong. The expected return of simply guessing is strongly negative.\nThe rational thing for Kyla to do is to go on to other questions and come back to this one if she has time. But orthodox theory doesn’t allow for this. The probability of any mathematical truth is one. And it’s part of orthodoxy that credences are supposed to be probability functions. So whatever the correct answer is, offering it will have positive expected utility given Kyla’s credences, assuming those credences are rational.\nSo orthodoxy gets this choice, and all other choices that turn on mathematical ignorance, badly wrong. The case where Kyla simply has to decide whether to answer the question now or come back to it later is in some ways a relatively easy case. The really hard decisions are about how much time to allocate to solving various mathematical problems, when there are both costs to spending time, and rewards to solving as many problems as possible. These can often be important decisions, and ones that our theory should have something to say about. But orthodoxy does not have anything to say. It’s time to look for something else.\n\n\n\n2 Dialectical Interludes\n\n2.0.1 Interlude One - The Obvious Answer\nBy this time you might be expecting a relatively simple answer to this question. The problem is that the orthodox theorist was focussing on the wrong choice. We shouldn’t focus on the choice to take this can of chickpeas or that one, or to answer true or false to this question. Rather, we should focus on the choice to choose one procedure or another. And the rational chooser will choose the procedure that is on average best.\nThat solves our cases quite well. The best procedure for Frankie Lee or David to adopt is to choose arbitrarily. Any other procedure will take time, and it’s not going to be time well spent. The best procedure for the person wracked by regret at choices they didn’t make is also to choose somewhat arbitrarily, before the regrets have time to embed. Conversely, the best procedure for Kyla is to skip any questions that she can’t do quickly, and come back to them if it turns out she has time.\nGiven some very weak assumptions, Maximise expected utility will not be an optimal procedure in this sense. Actually it’s ambiguous what it means to say someone should adopt the procedure Maximise expected utility, but however you disambiguate that, it’s wrong. The procedure Calculate what maximises expected utility then choose it is not optimal, because the calculations may not be worth the effort. The procedure Instinctively choose what maximises expected utility is a very efficient procedure if it is available, but for most agents it isn’t available. We should no more criticise agents who don’t adopt it than we criticise agents who don’t get to work by apparating.\nI’m going to adopt a version of the view that the rational choice is the outcome of an optimal procedure. But I’m not going to adopt the most obvious version of this obvious answer. In particular, I’m not going to say that agents should adopt the procedure such that adopting that procedure maximises expected value. Rather, I think, they should adopt the procedure that maximises something like average value. We’ll return to this in a bit, but first I want to clear up some other dialectical points.\n\n\n2.0.2 Dialectical Point Two - Possible Orthodox Solutions\nThere are ways of tinkering with orthodoxy to avoid some of the problems that I raised in the previous section. For example, dropping the constraint that credences are probabilities would avoid giving the wrong answer in Kyla’s case. And maybe, just maybe, there is a theory of evidence, or of evidential support, such that the evidential expected utility of each of Frankie Lee’s choices are not distinct. I’m certainly not going to try to go through every possible theory of evidence, or of evidential support, to show that this isn’t the case.\nBut I do want to note three constraints on an orthodox solution to the problems that I have raised.\nFirst, the solution must handle all the cases. This is not a completely trivial point. The reason orthodoxy fails in the three cases is a little different in each case. There is not, at least as far as I can tell, a simple way to handle all of them simultaneously while staying roughly within orthodoxy.\nSecond, the solution must not introduce any more complications of its own. For example, you could try to solve some of the problems by saying that the decision maker’s evidence includes just those facts that are immediately available to her. Perhaps there is some sense of ‘immediacy’ in which this provides the start of a solution to the first two puzzles. (I think the third puzzle won’t be solved this way, but the first two might.) But this solution introduces problems of its own. For example, a decision can be irrational in virtue of the fact that a moment’s thought would’ve revealed to the decision maker that it will lead to disaster. If we restrict evidence to what is available at less than a moment’s thought, then we get this case wrong. If we don’t put such a restriction in place, then we’re back to having problems with the first two puzzles I mentioned above. I don’t want to clean there is nothing for the orthodox theorist to do here, but I do think it will be tricky to handle the puzzles without licencing irrational thoughtlessness.\nThird, any orthodox solution should be just as simple and as well motivated as the obvious answer I just discussed. Saying that we should focus on procedures and not on the choices they lead to on an occasion resolves all of these puzzles in a simple and natural way. Even if an orthodox solution can be found to all three puzzles, if it requires three different changes to the orthodox view, it’s hard to believe that it will be preferable to a simple solution in terms of procedures.\n\n\n2.0.3 Dialectical Point Three - Terminology\nAt this point, some people might want to simply stipulate that the word “rational” picks out the choice that a computationally ideal actor would take. Even if it’s good in some sense for David to choose arbitrarily, there is still an ideal can to choose, and he only deserves the honorific rational if he chooses it.\nI am not going to get into a fight over terminology here. If people want to continue inquiring into what David would ideally do, then I’m not going to get in their way. But I found this inquiry unmotivated for three reasons. First, if we’re going to consider what David would ideally do, then I’m more interested in what he’d do if he were really ideal, and knew everything. I don’t see the appeal of investigating what he would do given one, but only one, kind of idealisation. Second, I don’t think the ideal is a particularly good guide. Knowing what the gods do doesn’t help the mortals, for mortals just get burned if they try to be like gods.\nBut the biggest reason concerns a purpose that I think is a central function of the concept of rationality. We have a need to make the people around us intelligible and predictable. And the best way we have to do this is to understand the constraints and the motivations of people around us, and feed those into a theory of rational choice that outputs a decision given constraints and motivations. It doesn’t always work, especially if you are trying to make predictions. But it beats most of the alternatives by a comfortable margin.\nIf that’s the reason for having a theory of rational choice, then the orthodox theory is not fit for purpose. The person who stands in the grocery store aisle deliberating over which can to get is neither intelligible nor predictable. The theory that says rational agents adopt procedures that do well on average, given their constraints and motivations, does make the ordinary behavior of supermarket shoppers intelligible and predictable.\nWhen I say ‘we’ need to make folks around us intelligible and predictable, I mean this to work at two different levels. From a very early age, we do this kind of reasoning about particular individuals to learn about the world (Scott and Baillargeon 2013). If a child sees a competent seeming adult use a particular method to solve a problem, and the adult does not seem to have any constraints that the child is free of, the child will copy what the adult does (Levy and Alfano 2020). This makes perfect sense; the adult is rational (and better informed than the child), so probably the adult’s procedure is optimal for the child. If we know that children do this, we can exploit it to trick them. For example, we can demonstrate sub-optimal procedures, and children will mimic them for a surprisingly long time. But this isn’t because the child is a fool; it’s because they have a clever way of learning about the world that can misfire when people set out to confound it.\nBut I also mean this to work at the level of social analysis. The whole point of game theoretic explanations of social phenomena is that we can make a pattern of behavior intelligible by simply presenting the constraints and motivations of the choosers, and then showing how rational behavior on everyone’s part produces the outcome. The research program this paper is a part of is motivated by the hope, and it is a hope more than a theory, that the same theory of rationality can serve both the child who is selectively imitating those around them, and the social scientist with their game theoretic models. Whether that’s true in general or not, I think both the child and the theorist are better served by a theory of rational choice that is sensitive to computational limitations and deliberation costs. And it’s their perspectives that I’m most interested in when theorising about rationality.\nThere is one other terminological dispute that I have no interest in entering into, but I need to make explicit in order to set aside. Some philosophers use ‘decision theory’ to refer to the study of purely procedural aspects of rationality. On this picture, there are three parts to rational choice: epistemology, axiology and decision theory. A rational agent will comply with all three. Compliance with the first is manifest in rational credences. Compliance with the second is manifest in rational values. And compliance with the third is manifest in choices that are rational given the first two. I don’t much care for this highly factorised model of rational choice theory. Imagine we see someone punching themselves in the head, and ask why they are doing this. If they say, “I want to bring about world peace, and I believe this is the best way to do it”, we don’t reply, “Well, I guess two out of three isn’t bad”. We just think they are irrational. But for current purposes I don’t want to debate this. This paper is about the theory of rational choice. If you think that encompasses more than decision theory, that it also includes epistemology and axiology, then this isn’t a paper in decision theory strictly speaking. But even someone who thinks the theory of rational choice can be factorised in this way still thinks there is a theory of rational choice. And my plan here is to offer a rival theory. Whether what I offer is a rival theory of decision turns on terminological questions about ‘decision theory’ that I’m hereby setting aside.\n\n\n\n3 History and Regresses\nThe idea that rational people are sensitive to their own computational limitations has a long history. It is often traced back to a footnote of Frank Knight’s. Here is the text that provides the context for the note.\n\nLet us take Marshall’s example of a boy gathering and eating berries … We can hardly suppose that the boy goes through such mental operations as drawing curves or making estimates of utility and disutility scales. What he does, in so far as he deliberates between the alternatives at all*, is to consider together with reference to successive amounts of his “commodity,” the utility of each increment against its “cost in effort,” and evaluate the net result as either positive or negative (Knight 1921, 66–67)\n\nAnd the footnote attached to ‘at all’ says this\n\nWhich, to be sure, is not very far. Nor is this any criticism of the boy. Quite the contrary! It is evident that the rational thing to do is to be irrational, where deliberation and estimation cost more than they are worth. That this is very often true, and that men still oftener (perhaps) behave as if it were, does not vitiate economic reasoning to the extent that might be supposed. For these irrationalities (whether rational or irrational!) tend to offset each other. (Knight 1921, 67fn1)\n\nKnight doesn’t really give an argument for the claim that these effects will offset. And as John Conlisk (1996) shows in his fantastic survey of the late 20th century literature on bounded rationality, it very often isn’t true. Especially in game theoretic contexts, the thought that other players might think that “deliberation and estimation cost more than they are worth” can have striking consequences. But our aim here is not to think about economic theorising, but about the nature of rationality.\nThere is something paradoxical, almost incoherent, about Knight’s formulation. If it is “rational to be irrational”, then being “irrational” can’t really be irrational. There are two natural ways to get out of this paradox. One, loosely following David Christensen (2007), would be to say that “Murphy’s Law” applies here. Whatever one does will be irrational in some sense. But still some actions are less irrational than others, and the least irrational will be to decline to engage in deliberation that costs more than it is worth. I suspect what Knight had in mind though was something different (if not obviously better). He is using ‘rational’ as more or less a rigid designator of the the property of choosing as a Marshallian maximizer does. And what he means here is that the disposition to not choose in that way will be, in the long run, the disposition with maximal returns.\nThis latter idea is what motivates the thought that rational agents will take what John Conlisk calls “deliberation costs” into account. And Conlisk thinks that this is what rational agents will do. But he also raises a problem for this view, and indeed offers one of the clearest (and most widely cited) statements of this problem.\n\nHowever, we quickly collide with a perplexing obstacle. Suppose that we first formulate a decision problem as a conventional optimization based on the assumption of unbounded rationality and thus on the assumption of zero deliberation cost. Suppose we then recognize that deliberation cost is positive; so we fold this further cost into the original problem. The difficulty is that the augmented optimization problem will itself be costly to analyze; and this new deliberation cost will be neglected. We can then formulate a third problem which includes the cost of solving the second, and then a fourth problem, and so on. We quickly find ourselves in an infinite and seemingly intractable regress. In rough notation, let \\(P\\) denote the initial problem, and let \\(F(.)\\) denote the operation of folding deliberation cost into a problem. Then the regress of problems is \\(P, F(P), F^2(P), \\ldots\\) (Conlisk 1996, 687)\n\nConlisk’s own solution to this problem is not particularly satisfying. He notes that once we get to \\(F^3\\) and \\(F^4\\), the problems are ‘overly convoluted’ and seem to be safely ignored. This isn’t enough for two reasons. First, even a problem that is convoluted to state can have serious consequences when we think about solving it. (What would Econometrica publish if this weren’t true?) Second, as is often noted, \\(F^2(P)\\) might be a harder problem to solve than \\(P\\), so simply stopping the regress there and treating the rational agent as solving this problem seems to be an unmotivated choice.\nAs Conlisk notes, this problem has a long history, and is often used to dismiss the idea that folding deliberation costs into our model of the optimising agent is a good idea. I use ‘dismiss’ advisedly here. As he also notes, there is very little discussion of this infinite regress problem in the literature before 1996. The same remains true after 1996. What is done is that instead people appeal to the regress in a sentence or two to set aside approaches that incorporate deliberation cost in the way that Conlisk suggests.\nUp to around the time of Conlisk’s article, the infinite regress problem was often appealed to by people arguing that we should, in effect, ignore deliberation costs. After his article, the appeals to the regress comes from a different direction. It is usually from theorists arguing that deliberation costs are real, but the regress means it will be impossible to consistently incorporate them into a model of an optimizing agent. So we should instead rely on experimental techniques to see how people actually handle deliberation costs; the theory of optimization has reached its limit. This kind of move is found in writers as diverse as Gigerenzer and Selten (2001), Odell (2002), Pingle (2006), Mangan, Hughes, and Slack (2010), Ogaki and Tanaka (2017) and Chakravarti (2017). And proponents of taking deliberation costs seriously within broadly optimizing approaches, like Miles Kimball (2015), say that solving the regress problem is the biggest barrier to having such an approach taken seriously by economists. So let’s turn to how we might solve it.\n\n\n4 Four Non-Solutions\nMy solution, as I’ve mentioned a couple of times, is a form of reliabilism. The rational choice is the one that would be produced by using the procedure that does best on average. That procedure will just be maximising expected utility when computational costs are zero, and will involve appeal to expected utility maximisation in many other cases. But it won’t, in general, simply be expected utility maximisation.\nTo get clearer on what the reliabilist solution is, and how it is motivated, I want to first go through three other solutions that I don’t think work.\nFirst, we could just say that the rational choice is simply the choice that produces the best actual result. This gets some cases intutively wrong; it says that it is never rational to leave a casino without gambling. And it eliminates a type of choice that we think is real: the lucky guess. We want lucky guesses to be cases that produce good outcomes, but are not rational. If the rational choice just is the best choice, this is impossible. Since lucky guesses are not impossible, this theory can’t be right.\nSecond, we could say that the rational choice is the choice that maximises expected value. But I’ve already gone over why that is wrong. There are really two things we could mean by saying the rational choice is the one that maximises expected value, and both of them are wrong. We could say that the rational choice is to compute what has the highest expected value, and then choose it. But this gives the wrong result in all the cases that I discussed at the beginning. Or we could say that the rational choice is to insinctively pick the one with the highest expected value. But there is no more reason to think this is something that choosers can do than there is to think that choosers can instinctively pick the choice with the highest actual value. So this is unrealistic.\nThird, we could say the choice is the output of the procedure such that adopting that procedure maximises expected value, given one’s evidence about the world and about the nature of procedures. Here, I think, the regress has bite because the same arguments from the previous paragraph still apply. We really need to distinguish two possible things we might mean by saying that one should adopt the procedure such that adopting it maximises expected value. First, we could mean that choosers should compute which procedure will maximise expected value, and then adopt it. But this will get the wrong result in Frankie Lee’s case, and in David’s. They shouldn’t be doing any computation at all. So perhaps instead we could say that the rational chooser will instinctively choose the procedure with the highest expected value. But there is no more reason to think that choosers could always do that there is to think that they can simply choose the first-order option with the highest actual or expected value. So this idea fails, and it fails for just the same reasons as the suggestion of the previous paragraph. That doesn’t prove a regress is looming, but it doesn’t look good.\nThe fourth option I’ll discuss is designed to avoid this problem, and it is going to look somewhat more promising2. Maybe we can’t all at once choose the best procedure. But we can do it piecemeal.\n2 Indeed, in early drafts of this paper, I didn’t distinguish this proposal from the one I’ll endorse in the next section. And those ‘early drafts’ were circulated in late 2019. So they included the first draft of the paper that I sent to Ted. I’m sorry for doing something between clarifying and changing my view so late.In general, here’s a way to adopt a complicated procedure. When faced with a certain class of problems, adopt the simplest procedure that agree with the complicated procedure over the range of choices you face. Then, as the problems expand, start either complicating the procedure, or adopt a meta-procedure for choosing which simple procedure to adopt on an occasion. Over time, if all goes well, you’ll eventually adopt something like the complicated procedure, and do it without having to solve impossibly hard calculations about procedural effectiveness, or having miraculously good instincts.\nOne appeal of this approach is that it blocks the regress. If one selects a procedure piecemeal in this way, there is a good sense in which \\(F(P) = F^2(P) = F^3(P) = \\dots\\). After all, there won’t be a difference between adopting a procedure, and adopting a procedure for adopting that procedure. Both of them will just involve making the choices you have to make on a given day, and looking for the opportunity to integrate those choices into a larger and more systematic theory. By adopting a first-order procedure piecemeal, you also adopt a second-order procedure piecemeal. And if \\(F(P) = F^2(P) = F^3(P) = \\dots\\), then the regress doesn’t get going.\nThe problem is that this is too demanding. We want choosers to maximise. We don’t expect them to be able to maximise over every possible choice situation, just over the one in front of them. If I’m buying chickpeas, and I arbitrarily choose one of the cans, that’s all to the good. It’s a rational choice. And, crucially, it stays being a rational choice even if I have dispositions to choose badly in other choice situations. But on the ‘piecemeal’ model being considered here, those dispositions to choose badly are partially constitutive of my choice procedure. And rational choice is a matter of choosing in virtue of adopting the correct choice procedure. So someone who is irrational somewhere is, it turns out, irrational everywhere. This is a bad result. There is something right about the idea that the rational chooser will just choose what’s in front of them, and do so in a sensible way. But we shouldn’t go on to say that rational choice requires that the global procedure one thereby implicitly adopts is the right one; that’s too high a bar.\n\n\n5 Skilled Choice\nThe way to see what’s right about the last proposal, and to see our way to the correct solution, is to somewhat reconceptualise rational choice. We shoudl conceive of the rational chooser as a skilled chooser. And we should think skills are a matter of reliably doing well across realistic situations.\nThe justification for conceiving of rational choice as skilled choice is largely pragmatic. Thinking of rationality that ways results in a plausible theory of rationality, and other ways of thinking about rationality resulted in implausible theories. So rather than argue for the conception of rationality as skill, I’m going to more or less assume it, and hope to justify this assumption by its fruitfulness. What I will argue for is the idea that skill involves reliably succeeding across realistic situations.3\n3 This is very similar to the modal understanding of skill in Beddor and Pavese (2020).Think for a bit about skilled atheletes, or skilled players of chess or other games. Part of being skilled is succeeding. But it isn’t just about success. Some people win due to luck. The skilled player won’t always win, but they will reliably win across a range of situations.\nWhich situations are those? They are the situations that are normal enough for the kind of activity being engaged in. These might be dependent on highly contingent features of the activity. A chess player who wins international tournaments must be very skilled. We wouldn’t retract that assessment if it turned out they only played well in quiet enviornments, and frequently lost chess games in noisy pubs. High level chess is played in quiet environments, so that’s what matters.\nA football player whose instincts only go right when there is no wind around is not particuarly skilled. Someone who doesn’t know how to adjust their passes when the wind changes is not skilled; it is lucky that they get ever connect on a pass. Conversely, a football player whose instincts are finely calibrated to the actual gravitational field strength around here could be highly skilled. It’s not part of footballing skill that one is able to adjust to changes in gravitational field strength. Some kinds of flexibility, such as ability to adjust to wind conditions, matter, while others, such as ability to adjust to a different gravitational field, do not. There are intermediate cases where the importance of the ability to adjust is dependent on contingent attributes of the activity. Top level Australian Rules Football is almost always played at sea level. An Australian Rules Footballer whose instincts are calibrated for play at sea level, and who has no ability to adjust to changes in altitude, might still be highly skilled. But in a sporting competition where top flight games are frequently played in Mexico City or Quito, an inability to adjust to changing altitudes is a substantial limitation on one’s skill. It is luck, not skill, that causes one to succeed in contests at one’s favored altitude. But it isn’t luck that the Australian Rules Footballer is playing at sea level; that’s a stable generalisation about the sport.\nThe same kind of story holds true for the skilled chooser. They have to do well, and not by chance. But that can involve having instincts that are calibrated to the enviornment one is actually in, and which would misfire in other environments. A skilled supermarket shopper need not be applying procedures that would do well in a medieval market. But they must be applying procedures that will keep working if the shelving of various items is changed.\nThat’s to say, the skilled chooser will adopt a procedure that will, on average, produce the best results in circumstances like the ones they are in.There is an implicit notion of probability in that definition. But it isn’t the notion of credence, or even of rational credence. Rather, it is the notion of how likely it is, or how frequent it is, that different circumstances obtain. That’s the sense in which the theory is reliabilist.\nWhen I say ‘produce the best results’, I mean the best results of the available procedures. Just like we don’t require rational commuters to apparate, we don’t require rational choosers to instinctively maximise utility, or expected utility. They (just) have to do the best they can.\nSkilled action frequently involves doing things where one has no evidence for the utility of such performances. It can even involve doing things where one has evidence against the utility of what one is doing. To see this, imagine a junior athelete who is thriving against competitors their own age with an unusual technique. They are told, by seemingly trustworthy coaches, that to thrive at higher levels, they have to adopt a more orthodox technique. But though they have reason to believe these coaches, they keep instinctively lapsing back into their unusual techniques. And, amazingly, the coaches are wrong, and what looked like a technique for winning against kids in parks ends up working at international level competition. (This isn’t entirely unlike the story of Australian cricketer Steve Smith.) Such an athelet may be highly skilled. And their skill consists in, among other things, their instincts to do things that they have (misleading) evidence will not work. Their skill, that is, involves deploying a procedure that is actually reliable, even after they get evidence it is unreliable. I think the same is true of skilled choice. Sometimes, the skilled chooser will deploy a technique that they think is defective, and even one that they think is defective on reasonable grounds. As long as it works, it can still be the basis for skilled, and hence rational, choosing.\n\n\n6 Regress Blocking\nWith all that in place, let’s return to the regress problem, and in particular to Conlisk’s statement of it. Why should we think the rational agent solves \\(F(P)\\), and not \\(F^n(P)\\) for some \\(n &gt; 1\\)? I want to say that’s just what rational choice is; it’s skillfully managing one’s own computational and informational limitations. And skill in this sense involves getting it right, and doing so reliably, not necessarily thinking through the problem. This suggests two questions.\n\nWhy should we allow this kind of unreflective rule-following in our solution to the regress?\nWhy should we think that \\(F(P)\\) is the point where this consideration kicks in, as opposed to \\(P\\), or anything else?\n\nThere are a few ways to answer 1. One motivation traces back to the work by the artificial intelligence researcher Stuart Russell (1997). (Although really it starts with the philosophers Russell cites as inspiration, such as Cherniak (1986) and Harman (1973).) He stresses that we should think about the problem from the outside, as it were, not from inside the agent’s perspective. How would we program a machine that we knew would have to face the world with various limitations? We will give it rules to follow, but we won’t necessarily give it the desire (or even the capacity) to follow those rules self-consciously. That might be useful some of the time - though really what’s more useful is knowing the limitations of the rules. And that can be done without following the rules as such. It just requires good dispositions to complicate the rules one is following in cases where such complication will be justified.\nAnother motivation is right there in the quote from Knight that set this literature going. Most writers quote the footnote, where Knight suggests it might be rational to be irrational. But look back at what he’s saying in the text. The point is that it can be perfectly rational to use considerations other than drawing curves and making utility scales. What one has to do is follow internal rules that (non-accidentally) track what one would do if one was a self-consciously perfect Marshallian agent. That’s what I’m saying too, though I’m saying it one level up.\nFinally, there is the simple point that on pain of regress any set of rules whatsoever must say that there are some rules that are simply followed. This is one of the less controversial conclusions of the debates about rule-following that were started by Wittgenstein (1953). That we must at some stage simply follow rules, not follow them in virtue of following another rule, say the rule to compute how to follow the first rule and act accordingly, is an inevitable consequence of thinking that finite creatures can be rule followers.\nSo question 1 is not really a big problem. But question 2 is more serious. Why \\(F(P)\\), and why not something else? The short answer will be that any reason to think that rational actors maximize expected utility, as opposed to actual utility, will also be a reason to think that they solve \\(F(P)\\) and not \\(P\\).\nStart by stepping back and thinking about why we cared about expected utility instead of actual utility in the first place. Why not just say that the best thing to do is to produce the best outcome, and be done with it? Well, we don’t say that because we take it as a fixed point of our inquiry that agents are informationally limited, and that the best thing to do is what is best given that limitation. Given some plausible assumptions, the best thing for the informationally limited agent to do would be to maximize expected utility. This is a second-best option, but the best is unavailable given the limitations that we are treating as unavoidable.\nBut agents are not just informationally limited, they are computationally limited too. And we could have instead treated that as the core limitation to be modelled. As Conlisk says, it is “entertaining to imagine” theorists who worked in just this way, taking the agents in their models to have computational but not informational limitations (Conlisk 1996, 691). Let’s imagine that when we meet the Martian economists, that’s how they reason. Conlisk notes a few things that the Martian economists might do. They might disparage their colleagues who take informational limitations seriously as introducing ad hoc stipulations into their theory. They might argue that informational limitations are bound to cancel out, or be eliminated by competition. They might argue that apparent informational limitations are really just computational ones, or at least can be modelled as computational ones. And so on.\nWhat he doesn’t add is that they might suggest that there is a regress worry for any attempt to add informational constraints. Let \\(Q\\) be the initial problem as the Martians see it. That is, \\(Q\\) is the problem of finding the best outcome given full knowledge of the situation, but the actual computational limitations of the agent. Then we suggest that we should also account for the informational limitations. Let’s see if this will work, they say. Let \\(I()\\) be the function that transforms a problem into one that is sensitive to the informational limitations of the agent. But if we’re really sensitive to informational limitations, we should note that \\(I(Q)\\) is also a problem the agent has to solve under conditions of less than full information.4 So the informationally challenged agent will have to solve not just \\(I(Q)\\), but \\(I^2(Q)\\), and \\(I^3(Q)\\) and so on.5\n4 At this point the Martians might note that while they are grateful that Williamson (2000) has highlighted problems with the KK principle, and these problems show some of the reasons for wanting to idealise away from informational limitations, they aren’t in fact relying on Williamson’s work. All they need is that agents do not exactly what they know. And that will be true as long as the correct epistemic logic is weaker than S5. And that will be true as long as someone somewhere has a false belief. And it would just be weird, they think, to care about informational limitations but want to idealise away from the existence of false beliefs.5 At this point, some of the Martians note that the existence of Elster (1979) restored their faith in humanity.Orthodox defenders of (human versions of) rational choice theory have to think this is a bad argument. And I think most of them will agree with roughly the solution I’m adopting. The right problem to solve is \\(I(Q)\\), on a model where \\(Q\\) is in fact the problem of choosing the objectively best option. If one doesn’t know precisely what one’s knowledge is, then one has to maximize expected utility somewhat speculatively. But that doesn’t mean that one shouldn’t maximize expected utility.\nBut the bigger thing to say is that neither we nor the Martians really started with the right original problem. The original problem, \\(O\\), is the problem of choosing the objectively best option. The humans start by considering the problem \\(I(O)\\), i.e., \\(P\\), and then debate whether we should stick with that problem, or move to \\(F(I(O))\\). The Martians start by considering the problem \\(F(O)\\), i.e., \\(Q\\), then debate whether we should stick with that or move to \\(I(F(O))\\). And the answer in both cases is that we should move.\nGiven the plausible commutativity principle, that introducing two limitations to theorising has the same effect whichever order we introduce them, \\(I(F(O)) = F(I(O))\\). That is, \\(F(P) = I(Q)\\). And that’s the problem that we should think the rational agent is solving.\nBut why solve that, rather than something more or less close to \\(O\\)? Well, think about what we say about an agent in a Jackson case who tries to solve \\(O\\) not \\(I(O)\\). (A Jackson case, in this sense, is a case where the choice with highest expected value is known to not have the highest objective value. So trying to get the highest objective value will mean definitely not maximizing expected value.) We think it will be sheer luck if they succeed. We think in the long run they will almost certainly do worse than if they tried to solve \\(I(O)\\). And in the rare case where they do better, we think it isn’t a credit to them, but to their luck. In cases where the well-being of others is involved, we think aiming for the solution to \\(O\\) involves needless, and often immoral, risk-taking.\nThe Martians can quite rightly say the same things about why \\(F(O)\\) is a more theoretically interesting problem than \\(O\\). Assume we are in a situation where \\(F(O)\\) is known to differ from \\(O\\), such as the case Kyla was in. Or, for a different example, imagine the decision maker will get a reward if they announce the correct answer to whether a particular sentence is a truth-functional tautology, and they are allowed to pay a small fee to use a computer that can decide whether any given sentence is a tautology. The solution to \\(O\\) is to announce the correct answer, whatever it is. The solution to \\(F(O)\\) is to pay to use the computer. And the Martians might point out that in the long run, solving \\(F(O)\\) will yield better results. That if the agent does solve problems like \\(O\\) correctly, even in the long run, this will just mean they were lucky not rational. That if the reward is that a third party does not suffer, then it is immorally reckless to not solve \\(F(O)\\), i.e., to not consult the computer. And in general, whatever we can say that motivated “Rational Choice Theory”, as opposed to “Choose the Best Choice Theory”, they can say too.\nBoth the human and the Martian arguments look good to me. We should add in both computational and informational limitations into our model of the ideal agent. And that’s the solution to the regress. It is legitimate to think that there is a rule that rational creatures follow immediately, on pain of thinking that all theories of rationality imply regresses. And thinking about the contingency of how Rational Choice Theory got to be the way it is suggests that the solution to what Conlisk calls \\(F(P)\\), or what I’ve called \\(F(I(O))\\), will be that point.\n\n\n7 The Nature of Good Procedures\nSince this is meant to be a theory of rational choice for real people, it would be helpful to say a few words about what these reliable procedures that stop the regress might be. In principle they could be anything, but in practice I think three kinds of procedures are particularly important: instincts, planning, and modelling. I’ll say a bit about each of these in turn.\nHumans are surprisingly good at instinctively allocating reasonable amounts of cognitive resources to computational tasks. In artificial intelligence research, one of the big challenges is trying to make machines be as good as humans at figuring out which problems to allocate cognitive resources to. This is sometimes known as the frame problem. Here’s a typical description of this from a recent survey article.\n\nAnd, more generally, how do we account for our apparent ability to make decisions on the basis only of what is relevant to an ongoing situation without having explicitly to consider all that is not relevant? (Shanahan 2016)\n\nNote that this assumes is that humans are actually very good at this rather hard task - setting aside the irrelevant without first thinking that it is irrelevant. This has to be instinctive. We don’t go around thinking about how much time to spend thinking on various subjects. That would be self-defeating. Obviously we are far from perfect at this, but it is striking how good we are at it.\nRecent work on ‘vigilance’ has illustrated how good we are at one aspect of this problem (Sperber et al. 2010). Somehow, and I don’t think it is clear how, we manage to keep track of our environment in a comprehensive enough away that it allows us to focus on those things that need focusing on. For example, when walking down a busy street, we don’t make a model of the expected movements of each of the individuals around us. That would be too computationally taxing. But we do pay enough attention to each of those individuals for us to be able to focus on any one of them if they seem to pose a particular challenge or threat. If one of them is weaving in a drunken manner, or carrying a sword, we are able to focus on them very quickly. To do this we must be paying at least background attention to every one of them. I think this turns out to be a common phenomenon. There are many situations where we don’t have the ability to carefully consider everything that’s going on, but we do manage to pick out the things around us that need close attention. And that requires monitoring of the entire environment, and doing some very quick and dirty processing of the resulting inputs. As I said, it’s a bit of a mystery how we do this. But whatever we do, it’s an amazing feat of insinctively solving a cognitive resource allocation problem.\nWhen I say we do some of these things instinctively, I don’t mean that our ability to do them is innate. We might pick them up by learning from those around us. This learning need not be conscious. It might happen by imitation. It is sometimes thought that humans’ disposition to over imitate those around them is a kind of irrationality (Levy and Alfano 2020). But my guess is that it is part of what grounds our skill in solving these hard cognitive resource allocation problems.\nBut rather than speculate further about what future research will show about the range and limits of human instinct, let’s turn to two ways of consciously adopting reliable procedures. In his discussion of the regress, Miles Kimball (2015) suggests a few options that might work. I want to focus on two of them: planning and modelling.\n\nLeast transgressive are models in which an agent sits down once in a long while to think very carefully about how carefully to think about decisions of a frequently encountered type. For example, it is not impossible that someone might spend one afternoon considering how much time to spend on each of many grocery-shopping trips in comparison shopping. In this type of modelling, the infrequent computations of how carefully to think about repeated types of decisions could be approximated as if there were no computational cost, even though the context of the problem implies that those computational costs are strictly positive. (Kimball 2015, 174)\n\nAnd that’s obviously relevant to David in the supermarket. He could, in principle, spend one Saturday afternoon thinking about how carefully to check each of the items in the supermarket before putting it in his shopping cart. And then in future trips, he could just carry out this plan. In general, planning as a device for incurring computational costs at a time when those costs are less costly.\nThis isn’t a terrible strategy, but I suspect it’s rarely optimal. For one thing, there are much better things to do with Saturday afternoons. For another, it suggests we are back in the business of equating solving \\(F(P)\\) with approximately solving \\(P\\). And that’s a mistake. Better to just say that David is rational if he just does the things that he would do were he to waste a Saturday afternoon this way, and then plan it out. And that thought leads to Kimball’s more radical suggestion for how to avoid the regress,\n\n[M]odelling economic actors as doing constrained optimization in relation to a simpler economic model than the model treated as true in the analysis. This simpler economic model treated as true by the agent can be called a “folk theory” (Kimball 2015, 175)\n\nIt’s this last idea I plan to explore in more detail. (It has some similarities to the discussion of small worlds in Joyce (1999) 70-77.) The short version is that David can, and should, have a little toy model of the supermarket in his head, and should optimize relative to that model. The model will be false, and David will know it is false. And that won’t matter, as long as David treats the model the right way.\nThere are a lot of things that could have gone wrong with a can of chickpeas. They could have gone bad inside the can. They could have been contaminated, either deliberately or through carelessness. They could have been sitting around so long they have expired. All these things are, at least logically, possible.\nBut these possibilities, while serious, have two quite distinctive features. One is that they are very rare. In some cases they may have never happened. (I’ve never heard of someone deliberately contaminating canned chickpeas, though other grocery products like strawberries have been contamination targets.) The other is that there are few easy ways to tell whether they are actualised. You can scan each of the cans for an expiry date, but it is really uncommon that this is relevant, and it takes work since the expiry dates are normally written in such small type. If a can is really badly dented, I guess that weakens the metal and raises ever so slightly the prospect of unintentional contamination. But it’s common to have shelves full of cans that have no dents, or at most very minor ones.\nGiven these two facts - the rarity of the problems and the difficulty in getting evidence that significantly shifts the probability that this is one of the (rare) problems - the rational thing to do is choose in a way that is insensitive to whether those problems are actualised. Or, perhaps more cautiously, one should be vigilant, in the sense of Sperber et al. (2010), to some of these problems, and ignore the rest. But being vigilant about a problem means, I take it, being willing to consider it if and only if you get evidence that it is worth considering. In the short run, you still ignore the potential problem.\nAnd to ignore a potential problem is to choose in a way that is insensitive to evidence for the problem. That makes sense for both the banknotes and the chickpeas, because engaging in a choice procedure that is sensitive to the probability of the problem will, in the long run, make you worse off.\nIn Kimball’s terms, the rational shopper will have a toy model of the supermarket in which all cans of chickpeas that aren’t obviously damaged are safe to eat. This will be a defeasible model, but on a typical grocery trip, it won’t be defeated. In Joyce’s terms, the small worlds the shopper uses in setting up the decision problem they face will all be ones in which the chickpeas are safe.\nSo the suggestion is that very often, the way to be rational is to have right model in your head, and apply it correctly. A choice is the rational choice in your situation iff it is the recommendation of the right model. And the right model includes just as much information, and just as many complications, as the situation demands. The regress is blocked, on this picture, because you don’t have to have computed, or even be in a position to compute, that the right model is the right model. Here I am following Knight. Rational agents don’t have to have worked through Marshall’s Principles; they just have to think and act as if they had. But crucially, they don’t have to even act as if they are applying the Principles to the world. They could apply them to a good model of the world, and that’s good enough.\n\n\n8 Three Philosophical Postscripts\n\n8.0.1 Idealisation\nThe story I’m telling here about how rational agents use models is very similar, and indeed draws heavily on, the story that Michael Strevens (2008) tells about how scientists use idealisations. On that story, to use an idealisation is to set some messy value to a computationally more simple value (often 0 or 1), and to (implicitly) assert that the difference between the actual value and the computationally simpler value is irrelevant for current purposes.\nOne benefit Strevens gets from this is that he is spared saying that scientists use falsehoods in their reasoning. After all, it is often true that the difference between the messy value and the simple value is irrelevant for current purposes - and that’s all that the scientist is committing to.\nThe same is true in this picture. Frankie Lee can’t know that the banknotes are all equally likely to be genuine; because that’s not strictly true. But he can know that the right model to use in his current situation is one that sets the probability of any note’s genuineness to 1. That’s both true - assuming that our picture of what makes a model right is one that takes deliberation costs seriously - and well supported by his evidence.\n\n\n8.0.2 Epistemic Luck\nOn the story I’m telling, whether decision makers are rational or irrational will often be a matter of luck. This is as you should expect if rationality is a matter of successfully applying a skill. Most skills are not infallible. Being skilled at an activity means one usually succeeds, or at least one succeeds at a higher rate than is normal, but on any given day one could fail. The epistemic failures I call irrationality, even though the person in some sense does the same thing as they do in cases where they act rationally.\nHere is one version of that. Recall the version of the Frankie Lee example where the country has just started modernising its financial system by introducing plastic banknotes. Frankie Lee knows that plastic banknotes are genuine - no one has figured out how to forge them yet. So if some of them are on offer, he should take one. But, let’s imagine, he’s temporarily forgotten this fact. So he takes one of the paper notes. This is irrational.\nBut it’s also bad luck. It’s not normally required that we scour our memories for any relevant information before making a decision like this. Normally, Frankie Lee could have put in this much cognitive effort, and ended up rational. But the world did not cooperate, and he ended up irrational.\nI think any story that connects rationality to succeeding via skill will have the consequence that sometimes whether one is rational is in part a matter of luck. But the possibility of epistemic luck shouldn’t surprise us. Assume that what one should, rationally, do and believe is a function of what one knows. And assume that the right epistemic logic is weaker than S5. Then one won’t always know what one knows. So one won’t always know what one should do or believe. So if one believes what one should, or does what one should, this will be in some sense a matter of luck. And surely the right epistemic logic is weaker than S5. Even if you think the anti-luminosity arguments are bad, and the right epistemic logic is stronger than S4, you shouldn’t think that people know what it is they don’t know. (False beliefs, for example, are typically pieces of non-knowledge that are not known to be not knowledge.) So we shouldn’t be surprised that there is epistemic luck.\n\n\n8.0.3 Knowledge and Rational Choice\nSo my preferred picture of rational action in cases where there are deliberation costs is that the chooser has a model of the decision problem in their head, and they know it is a good model. That’s a constraint on rationality, but it’s also a constraint on knowledge. If the chooser knows that \\(p\\), they can’t be using a model where it might be that \\(\\neg p\\). That, I think, is the core way that practical factors encroach on knowledge - sometimes one is in a practical situation where the best model allows for the possibility of \\(\\neg p\\), and being in such a situation defeats any putative knowledge that \\(p\\).\nBut I used to say something different about how practical factors affected knowledge. I used to say something like the following.\n\nOne knows \\(p\\) only if the rational choice (or choices) conditional on \\(p\\) are the rational choice (or choices) unconditionally for any choice one is considering.\nThe rational choice, either conditional or unconditional, is the one with the highest expected utility, or if there are ties, then all of them are rational choices.\n\nAnd it turns out that combination of views is untenable. This was shown independently twice over, once by Alex Zweber (2016) and then, separately, by Charity Anderson and John Hawthorne -Anderson and Hawthorne (2019). They considered situations like the original Frankie Lee example, and noted that my view had the implausible consequence that Frankie Lee did not know, of each note, that it was genuine. After all, as it stands Frankie Lee should be indifferent between the notes, but conditional on one of the notes being genuine, he should prefer that one. And that’s implausible. Both papers go on to note other implausibilities that purportedly follow, but already we should acknowledge this is a problem. (Whether my view was really committed to the other implausibilities is something I could argue about, but it doesn’t matter because this is already a perfectly good counterexample.)\nThe solution, I now think, is to qualify the second bullet point above. What I should have said instead is\n\nThe rational choice is the one with the highest expected utility on the model that the chooser is rationally using, or if there are ties, then all of them are rational choices.\n\nAnd now the problem goes away. It is rational for Frankie Lee to use the model where all the notes are genuine - it isn’t worth the cost of using a more complicated model. And on that model, conditionalising on the hypothesis that one of the notes is genuine doesn’t change anything. So if Frankie Lee is using that model, he knows the notes are genuine. If he isn’t using that model then he doesn’t know the notes are genuine. But this isn’t because of any pragmatic theory of knowledge - it’s simply that to know \\(p\\) requires one actually take \\(p\\) as given, and Frankie Lee fails that criteria.\nSo cases like Frankie Lee, or David and the chickpeas, are perfectly good counterexamples to the version of epistemic pragmatic encroachment I used to endorse. But they don’t show that pragmatic theories are false in general; they just show I got an important detail wrong. To get these details right we need a better theory of when people (rationally) ignore the details.\n\n\n\n\n\n\n\nReferences\n\nAnderson, Charity, and John Hawthorne. 2019. “Knowledge, Practical Adequacy, and Stakes.” Oxford Studies in Epistemology 6: 234–57.\n\n\nBeddor, Bob, and Carlotta Pavese. 2020. “Modal Virtue Epistemology.” Philosophy and Phenomenological Research 101 (1): 61–79. https://doi.org/10.1111/phpr.12562.\n\n\nCaplin, Andrew, Mark Dean, and Daniel Martin. 2011. “Search and Satisficing.” American Economic Review 101 (7): 2899–2922. https://doi.org/10.1257/aer.101.7.2899.\n\n\nChakravarti, Ashok. 2017. “Imperfect Information and Opportunism.” Journal of Economic Issues 51 (4): 1114–36. https://doi.org/10.1080/00213624.2017.1391594.\n\n\nChernev, Alexander, Ulf Böckenholt, and Joseph Goodman. 2015. “Choice Overload: A Conceptual Review and Meta-Analysis.” Journal of Consumer Psychology 25 (2): 333–58. https://doi.org/10.1016/j.jcps.2014.08.002.\n\n\nCherniak, Christopher. 1986. Minimal Rationality. Cambridge, MA: MIT Press.\n\n\nChristensen, David. 2007. “Does Murphy’s Law Apply in Epistemology? Self-Doubt and Rational Ideals.” Oxford Studies in Epistemology 2: 3–31.\n\n\nConlisk, John. 1996. “Why Bounded Rationality?” Journal of Economic Literature 34 (2): 669–700.\n\n\nDiab, Dalia L., Michael A. Gillespie, and Scott Highhouse. 2008. “Are Maximizers Really Unhappy? The Measurement of Maximizing Tendency.” Judgment and Decision Making 3 (5): 364–70.\n\n\nDylan, Bob. 2016. The Lyrics: 1961-2012. New York: Simon & Schuster.\n\n\nElster, Jon. 1979. Ulysses and the Sirens: Studies in Rationality and Irrationality. Cambridge: Cambridge University Press.\n\n\nGigerenzer, Gerd, and Reinhard Selten. 2001. Bounded Rationality: The Adaptive Toolbox. Cambridge, MA: MIT Press.\n\n\nHarman, Gilbert. 1973. Thought. Princeton: Princeton University Press.\n\n\nIyengar, Sheena S., Rachael E. Wells, and Barry Schwartz. 2006. “Doing Better but Feeling Worse: Looking for the ‘Best’ Job Undermines Satisfaction.” Psychological Science 17 (2): 143–50. https://doi.org/10.1111/j.1467-9280.2006.01677.x.\n\n\nJoyce, James M. 1999. The Foundations of Causal Decision Theory. Cambridge: Cambridge University Press.\n\n\nKimball, Miles. 2015. “Cognitive Economics.” The Japanese Economic Review 66 (2): 167–81. https://doi.org/10.1111/jere.12070.\n\n\nKnight, Frank. 1921. Risk, Uncertainty and Profit. Chicago: University of Chicago Press.\n\n\nLevy, Neil, and Mark Alfano. 2020. “Knowledge from Vice: Deeply Social Epistemology.” Mind 129 (515): 887–915. https://doi.org/10.1093/mind/fzz017.\n\n\nLipsey, R. G., and Kelvin Lancaster. 1956. “The General Theory of Second Best.” Review of Economic Studies 24 (1): 11–32. https://doi.org/10.2307/2296233.\n\n\nMangan, Jean, Amanda Hughes, and Kim Slack. 2010. “Student Finance, Information and Decision Making.” Higher Education 60 (5): 459–72. https://doi.org/10.1007/s10734-010-9309-7.\n\n\nManski, Charles F. 2017. “Optimize, Satisfice, or Choose Without Deliberation? A Simple Minimax-Regret Assessment.” Theory and Decision 83 (2): 155–73. https://doi.org/10.1007/s11238-017-9592-1.\n\n\nNewman, David B., Joanna Schug, Masaki Yuki, Junko Yamada, and John B. Nezlek. 2018. “The Negative Consequences of Maximizing in Friendship Selection.” Journal of Personality and Social Psychology 114 (5): 804–24. https://doi.org/10.1037/pspp0000141.\n\n\nOdell, John S. 2002. “Bounded Rationality and World Political Economy.” In Governing the World’s Money, edited by David M. Andrews, C. Randall Henning, and Louis W. Pauly, 168–93. Ithaca: Cornell University Press.\n\n\nOgaki, Masao, and Saori C. Tanaka. 2017. Behavioral Economics: Toward a New Economics by Integration with Traditional Economics. Singapore: Springer.\n\n\nPapi, Mario. 2013. “Satisficing and Maximizing Consumers in a Monopolistic Screening Model.” Mathematical Social Sciences 66 (3): 385–89. https://doi.org/10.1016/j.mathsocsci.2013.08.005.\n\n\nPingle, Mark. 2006. “Deliberation Cost as a Foundation for Behavioral Economics.” In In Handbook of Contemporary Behavioral Economics: Foundations and Developments, edited by Morris Altman, 340–55. New York: Routledge.\n\n\nReutskaja, Elena, Rosemarie Nagel, Colin F. Camerer, and Antonio Rangel. 2011. “Search Dynamics in Consumer Choice Under Time Pressure: An Eye-Tracking Study.” American Economic Review 101 (2): 900–926. https://doi.org/10.1257/aer.101.2.900.\n\n\nRussell, Stuart J. 1997. “Rationality and Intelligence.” Artificial Intelligence 94 (1-2): 57–77. https://doi.org/10.1016/S0004-3702(97)00026-X.\n\n\nScheibehenne, Benjamin, Rainer Greifeneder, and Peter M. Todd. 2010. “Can There Ever Be Too Many Options? A Meta-Analytic Review of Choice Overload.” Journal of Consumer Research 37 (3): 409–25. https://doi.org/10.1086/651235.\n\n\nSchwartz, Barry. 2004. The Paradox of Choice: Why More Is Less. New York: Harper Collins.\n\n\nSchwartz, Barry, Andrew Ward, John Monterosso, Sonja Lyubomirsky, Katherine White, and Darrin R. Lehman. 2002. “Maximizing Versus Satisficing: Happiness Is a Matter of Choice.” Journal of Personality and Social Psychology 83 (5): 1178–97. https://doi.org/10.1037/0022-3514.83.5.1178.\n\n\nScott, Rose M., and Renée Baillargeon. 2013. “Do Infants Really Expect Agents to Act Efficiently? A Critical Test of the Rationality Principle.” Pscyhological Science 24 (4): 466–74. https://doi.org/10.1177/0956797612457395.\n\n\nShanahan, Murray. 2016. “The Frame Problem.” In The Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta, Spring 2016. Metaphysics Research Lab, Stanford University.\n\n\nSperber, Dan, Fabrice Clément, Christophe Heintz, Olivier Mascaro, Hugo Mercier, Gloria Origgi, and Deirdre Wilson. 2010. “Epistemic Vigilance.” Mind and Language 25 (4): 359–93. https://doi.org/10.1111/j.1468-0017.2010.01394.x.\n\n\nStrevens, Michael. 2008. Depth: An Account of Scientific Explanations. Cambridge, MA: Harvard University Press.\n\n\nTucker, Chris. 2016. “Satisficing and Motivated Submaximization (in the Philosophy of Religion).” Philosophy and Phenomenological Research 93 (1): 127–43. https://doi.org/10.1111/phpr.12191.\n\n\nWilliamson, Timothy. 2000. Knowledge and its Limits. Oxford University Press.\n\n\nWittgenstein, Ludwig. 1953. Philosophical Investigations. London: Macmillan.\n\n\nZweber, Adam. 2016. “Fallibilism, Closure, and Pragmatic Encroachment.” Philosophical Studies 173 (10): 2745–57. https://doi.org/10.1007/s11098-016-0631-5."
  },
  {
    "objectID": "posts/review-gauker/index.html",
    "href": "posts/review-gauker/index.html",
    "title": "Review of “Words Without Meaning”",
    "section": "",
    "text": "In philosophy it’s hard to find a view that hasn’t had an ism associated with it, but there are some. Some theories are too obscure or too fantastic to be named. And occasionally a theory is too deeply entrenched to even be conceptualised as a theory. For example, many of us hold without thinking about it the theory that “the central function of language is to enable a speaker to reveal his or her thoughts to a hearer,” (3) that in the case of declarative utterances the thoughts in question are beliefs whose content is some proposition or other, and that hearers figure out what the content of that belief is by virtue of an inference that turns on their beliefs about the meanings of the words we use. These claims might seem too trivial to even be called a theory. They have seemed too trivial to draw an ism. Christopher Gauker calls them ‘the received view’, and the purpose of his book Words Without Meanings (all page references to this book) is to argue against this received view and propose an alternative theory in its place. In Gauker’s theory the primary function of language is social coordination. If language ever functions as a conduit to the mind, this is a secondary effect.\n\nPublished in Notre Dame Philosophical Reviews.\n\nIt is useful to have an ism for everything, so let’s call ‘the received view’ Lockism, since Locke believed something similar. Of course, Locke probably didn’t have any detailed opinions about where the semantics/pragmatics distinction lies or what the role and importance Horn scales might be or how to build a compositional semantics for quantification, or indeed about many of the issues on which various contemporary Lockists have their most distinctive views, but there’s an intellectual legacy worth noting. Still, if Locke was a Lockist without having views on these matters, this starts to suggest how broad, and how divided, the Lockist church may be. Lockists need not agree on the semantic analyses of indicative conditionals or attitude reports. They need not even agree on whether there are such things as conventional implicatures or deep structures. An argument against Lockism will have to either focus on the few rather platitudinous points where Lockists agree, or try to respond to all the ways Lockists might develop their position. Gauker takes both options throughout his book. The central theses of the Lockist position that are attacked concern the nature and contents of beliefs, the nature of logical implication and the status of truth. Gauker’s attacks on Lockist theories of quantifier domain restriction and of presupposition rely more heavily on attacking all the variants of Lockism.\nBut the arguments against Lockism are not necessarily the most important parts of the book. Alongside the criticisms of Lockism, Gauker develops in great detail his own positive theory about the nature and role of linguistic communication. Gauker suggests “the primary function of assertions ... is to shape the manner in which interlocutors attempt to achieve their goals.” (52) Conversations do not take place in a vacuum. Conversants frequently talk because they want something. The world does not always make it easy for us to get what we want, but sometimes at least other people can tell us which ways work best.\nIt becomes crucial to Gauker’s theory here that certain actions are or are not in accord with certain sets of sentences. Given this idea the primary norm of conversation becomes: Say things such that others who act in accord with what you say, and with what else has been said, will achieve their goals. The concept of actions according with (sets of) sentences seems intuitive at first. If my goal is to download the new Matrix movie, then going to stealthatmovie.com is in accord with {‘The new Matrix movie is available at stealthatmovie.com’} while going to moviebootlegger.com, or anywhere else, is not. (These are, by the way, fake site names.) Given this idea of actions according with sets of sentences, we can then define the context, or set of relevant sentences, as the smallest set such that “all courses of action in accordance with it relative to the goal of the conversation are good ways of achieving the goal”. (56) We can then restate the primary norm as: Say things that are in the context. Those sentences will be useful to say, and their negations will be useful to deny. This idea of useful assertability becomes crucial to Gauker’s theory, often playing much the role that a Lockist has truth play. For example, validity gets defined in terms of assertability preservation in all contexts.\nClearly the concept of actions according with contexts given goals is quite crucial, but there’s less explication of it than we might hope. I have some idea what it might mean to say that my going to stealthatmovie.com accords with the proposition that the new Matrix movie is available at stealthatmovie.com, and I have some idea which facts in the world may make this true. But I don’t have as clear an idea about what it means to say this action accords with any sentence. Sentences are just marks on paper, or sound waves. We can be pretty sure that this accord between actions and marks on paper is not a primitive fact about the world. Lockists think that actions accord with sentences because sentences express propositions and some actions accord with propositions. But this isn’t Gauker’s account, and it isn’t clear what is. At one stage Gauker notes that the distinction between actions that accord with a context and those that do not will be primitive relative to the ‘fundamental norms of discourse’, which are the primary focus of Words Without Meanings. That sounds right, and I hope it’s a sign that we’ll see more details about the concept of accord in future work.\nThis issue though is important because there are a few reasons to worry about how the concept of accord will be explicated. First, whatever problems face Lockist theories of meaning, including some of the problems Gauker raises, may recur here. Second, some theories of accord will introduce entities that are functionally just like meanings, so if meaning is a functional concept, as seems plausible, those theories will not end up being theories of words without meaning. Third, as Gauker notes, there are serious epistemological questions about how we could ever learn which actions accord with which contexts relative to which goals. Those who are impressed by Fodor’s arguments for the systematicity of human linguistic competence will probably think these questions raise insuperable difficulty for anything like Gauker’s program. On the other hand, those that are impressed by Gauker’s program will probably find these Fodorian claims overstated.\nWords Without Meaning concludes with three chapters setting out a rather distinctive view of belief. Gauker argues that a complete account of the role of belief ascriptions should be sufficient for a theory of belief. This is not because of a general policy that explaining the talk about something is sufficient to explain the thing in general. Such a policy is not entirely antithetical to Gauker’s overall picture, but it would be hard to defend in all cases. Rather, Gauker argues, in practice we have little use for beliefs and desires other than in our ascriptions of them, so an account of their ascription is all the account we need. Many philosophers will baulk here, because they think folk psychology provides a crucial role for beliefs and desires. Since folk psychology is a crucial part of how we predict the actions of other people, and of how we explain their actions, there is an important aspect of the nature of beliefs and desires that a mere account of their ascriptions will not capture. These philosophers will not agree with Gauker that an “account of the attribution of beliefs and desires is already an account of [their] nature.” (271‑2)\nGauker’s response to these philosophers is to question the explanatory and predictive capacity of folk psychology. He argues first that the explanatory, and especially the predictive, power of folk psychology is much over-rather. And more importantly, he argues that when there do appear to be good folk psychological explanations or predictions, there are equally good explanations that do not appeal to beliefs and desires. The argument for this involves running through several cases with some care, but very roughly the common theme is that beliefs and desires (if they exist) are themselves capable of explanation, so at least most of the time we can replace an explanation in terms of beliefs and desires with one that appeals to the explanations of those very beliefs and desires. This gives us a fairly general strategy for dispensing with folk psychological concepts in explanation and prediction.\nThis does not mean that we adopt an error theory of belief or desire ascriptions. Gauker thinks these have a use, so they are properly assertable. Their role, in general, is to let us speak on behalf of other people. “The primary function of attributions of belief and desire is to extend the range of participation in conversation.” (226) When I say that Harry believes that tech stocks are good investments, I say on Harry’s behalf that tech stocks are good investments. Unfortunately, we never get a complete positive characterisation of when it is permissible to say something on Harry’s behalf. We are told that such assertions, like all assertions, must be relevant to the conversation, but beyond that not a lot. We are told that it can’t just be permissible to say this just in case Harry would be disposed to say it, were he here. Harry might have a habit of keeping his investment ideas to himself, but still believe that tech stocks are good investments. And we’re told that this can be permissible to say even if Harry has never made an ‘inner assertion’ that tech stocks are good investments. But this doesn’t amount to a positive characterisation. Further, it’s not clear how to extend this account to all attitude reports, especially reports of desire-like attitudes. One could truly say Brian wants to play for the Red Sox, but in doing so one is not making a command, or even a request, on my behalf.\nAs well as these intriguing positive proposals, there are several arguments against Lockism. Chapter 2, on mental representation, is an attack on the Lockist position that there are beliefs with propositional content. Gauker first notes that any attempt to provide an atomistic theory of mental content seems to run into insuperable counterexamples. The main focus is Fodor’s asymmetric dependence theory, but a few other atomist theories are raised and dismissed. Gauker suggests that holistic theories are a little more promising, but when we look at the details we see that these all fall to a version of Putnam’s model-theoretic argument. Gauker’s argument here differs from Putnam’s in two key respects. First, it concerns primarily mental content, rather than linguistic content. Second, it has fewer theoretical overheads. Gauker shows that the argument never really needed any complicated mathematics; the formalism in the standard semantics for first-order logic is quite sufficient. Despite those two differences, the argument is fairly familiar, and the moves that could be made in response are also, by now, fairly familiar. Gauker quickly surveys these moves, and notes why he thinks none of them work, but the survey will probably be too brief to convince many who are happy with their preferred reply to Putnam. Those who are not happy with any of the replies to Putnam, or who would be more impressed by a version of Putnam’s argument that did not drift into needless technicality, should enjoy Gauker’s argument.\nThe middle half of Words Without Meanings consists of six case studies designed to show that Gauker’s approach can solve problems that are intractable for Lockism. Three of these are described as being in pragmatics, the other three in semantics. Here Gauker more often has to revert to arguing against each of the different versions of Lockism in the literature, for there are few points of agreement among Lockists once we get to the details on how language works. This is particularly clear when we look at pragmatics. I guess most Lockists agree that there is a pragmatics/semantics distinction, and most of those who do agree think that there is such a thing as scalar implicature. Beyond that there are disagreements everywhere. So Gauker is more often required to argue against all the versions of Lockism in existence. Even if he succeeds against all of them, Lockism is a growing doctrine, and a smart Lockist could often take Gauker’s positive ideas and incorporate them into Lockism. So it’s not clear we’ll see any knock-down argument against Lockism here. But maybe there will be an interesting abductive argument develop, and in any case it is always worthwhile to see Gauker’s positive account. Space prevents a full discussion of many of the issues raised here, but I’ll provide a quick summary of the salient issues, and why Gauker thinks he has an advantage over his Lockist rivals.\nThe first case study concerns domains of discourse, which mostly means domains of quantification. To use Gauker’s example, imagine Tommy runs into Suzy’s room, where Suzy is playing with her marbles, and says “All the red ones are mine.” What determines the domain of Tommy’s quantifier? If it is what Tommy intends, then we might end up saying that his sentence is, surprisingly, true. For Tommy, it turns out, intends only to speak of the marbles in his room, which are as it turns out all his. But if we don’t take it to be what Tommy intends, and instead let the domain be set by what Suzy thinks the domain is, or what a reasonable hearer would think the domain is, then we undermine the Lockist picture that the role of language is for the speaker’s thoughts to be communicated. In these cases it is the thoughts of the hearer, or of a reasonable hearer, seem to determine the meaning of what is said. Gauker suggests it is better to say that the domain is the class of things that are relevant to the goal of the conversation that Tommy and Suzy are having.\nThe second case concerns presupposition. Allegedly, some sentences are such that they cannot be properly asserted or denied unless some condition, the presupposition, is met. Sentences containing factive attitude verbs are sometimes held to fall into this category. So I cannot affirm or deny I regret that you failed the test unless you failed the test. There are several Lockist theories of presupposition, but Gauker argues that none of them can satisfactorily explain how asserting such sentences can inform the hearer of the truth of the presupposition, in this case that the test was in fact failed. Gauker’s theory, which does not have a special category of truth conditions apart from assertability conditions, does not have this difficulty. For a similar reason, however, the Lockist theory that rejects the concept of presupposition also avoids any problem of informative presupposition.\nThe third case concerns Gricean implicature. Gauker notes, correctly, that we can well explain the effects of Gricean implicature without presuming that the hearer even contemplates what the speaker had in mind in speaking. But this kind of contemplation is essential to Grice’s official story. Gauker’s alternative suggestion is that we can explain non-literal communication by assuming the hearer draws inferences about the context from the assertability of what is actually said.\nThe next three case studies are classified as ‘Semantics’, so we might hope that here Lockists will present a more unified target. But two of the studies seem, from a Lockist perspective, to concern the semantics/pragmatics boundary, so again there will be several varieties of Lockism that need to be addressed.\nThe first semantics study concerns quantifiers. Gauker argues that in practice (1) is a bad argument form, (1a) for instance is invalid, while (2) is a good argument form.\n\nEverything is F. Therefore, a is F. 1a. Everything is made of wood. Therefore, Socrates is made of wood.\na is F. Therefore, something is F.\n\nGauker argues in some detail that various Lockist theories of quantifier domain restriction cannot explain the asymmetry here. On his theory, the asymmetry falls out quite naturally, since quantification is always over named objects, and once named an object is relevant. So (1) need not be valid, since a need not have been named, but (2) must be valid.\nThe last two case studies are the most interesting, and the most intricate. I can’t do justice in a small space to the details of Gauker’s theory, but I’ll say a little about the issues raised. Chapter 8 concerns conditionals. Gauker thinks he has a telling argument against a central Lockist claim. The primary intuition is that (3) and (4) are logically equivalent, i.e. each entails the other, (at least when p and q are not themselves conditionals), but they are not equivalent when embedded in longer sentences. In particular, (5) and (6) need not be equivalent.\n\nEither not p or q\nIf p then q\nEither not p or q, or r\nIf p then q, or r\n\nIf this is right, then what Gauker calls ‘the Equivalence Principle’, that substitution of logical equivalent constituents preserves truth-conditional content, is false. Gauker suggests this is a serious problem for Lockism. There are, however, a few Lockist theories in which Equivalence fails. For example, in classical supervaluationism, p or not p is a logical truth, and p is equivalent to p is true, but p is true or not p is not a logical truth. So some Lockists have learned to live without Equivalence. More importantly, the data that suggests that (3) and (4) are logically equivalent isn’t unequivocal. Some Lockists have provided arguments as to why (3) and (4) will usually have the same assertion conditions even though they have different truth conditions. (Gauker notes Robert Stalnaker’s 1975 paper ‘Indicative Conditionals’ that argues for this line.) If those arguments can be made to succeed, then we can keep Equivalence by denying that (3) really entails (4).\nMore interesting than the possible Lockist replies is Gauker’s own theory. He manages, quite impressively I think, to provide a recursive definition of truth conditions for the connectives without keeping Equivalence. The rough idea is that If p then q is true iff p strictly implies q relative to the context. Strict implication theories usually block the inference from (5) to (6), as Gauker’s does, but they also normally block the inference from (3) to (4). In Gauker’s theory, however, because entailment is defined in terms of assertability-preservation, and disjunctions can only be asserted if one or other disjunct is assertable in every possibility left open by the context, the inference from (3) to (4) is valid. Roughly, any contextually salient possibility either contains not p or q, so all the possibilities that contain p contain q, in which case If p then q is assertable. This theory still has some counter-intuitive features, since the paradoxes of material implication are still with us, but it’s a fascinating addition to the literature on conditionals.\nThe final case study concerns truth, and in particular the semantic paradoxes. Gauker argues that extant Lockist responses to the paradoxes are not capable of handling metalinguistic versions of the paradox. In particular, Lockist theories struggle with sentences like (7).\n\n\ndoes not express a true sentence in this context.\n\n\nGauker’s argument that his theory does better than the Lockist here has two parts. First, he has a detailed demonstration that it is impossible to infer a contradiction directly from (7) in his theory. Second, he argues that a Lockist explanation of what’s going on with (7) has to posit that uttering, or writing, ‘this context’ changes the context. This might be true, indeed Gauker endorses a similar claim in his response to the paradoxes. But on most Lockist accounts of what contexts are, we could replace the demonstrative with some other phrase that more directly picks out the context. For example if a context is just an ordered n-tuple, we could just replace ‘this context’ with a description of the n-tuple that is, actually, the context. Here it does look as if Gauker’s theory has more resources than the traditional Lockism. It remains to be seen whether Gauker’s theory is completely free from the paradoxes - it’s quite a bit harder to come up with a consistent theory of truth than it is to block the liar paradox - but again Gauker provides an interesting alternative to existing approaches, and one that experts in the area should pay close attention.\nOverall, what should we make of Words Without Meanings? I think the book has three major aims, and it succeeds in two of them. The first aim is to extend Gauker’s preferred theory of linguistic communication to show how it handles presupposition, quantification, conditionals, attitude reports and truth ascriptions. In this it succeeds quite well, especially in showing how the project holds together technically. The second aim is to raise a host of problems for the Lockist theory, problems that are deserving of serious consideration and response. And again, there is no doubt it succeeds. Even if one thinks that all the problems Gauker raises can be solved, having them set forth so sharply certainly advances the debate. The third aim, the big one, is to convince Lockists that their research program is moribund, and Gauker’s contextualist alternative is the way of the future. That aim, in short, is for a revolution in semantics. (And in any fields that presuppose Lockist semantics. Many of our best syntactic theories have to be revised if Gauker is correct.) Here I think the book is less successful, if only because the aim is so high. It’s not clear how any short book, and the MIT series Words Without Meaning is in is clearly a series for short books, could trigger such a revolution. Lockism may have its weaknesses, and Gauker shines a spotlight on a few, but it’s been a relatively productive program the last fifty years, so overthrowing it will not be easy. Such a revolution would need a longer book, or books, answering among other questions the metaphysical and epistemological questions about Gauker’s concept of actions according with sentences we noted above. Gauker’s work always leaves the impression that he has worked through the relevant material in much more detail than is apparent from a superficial reading of the text, so such books and papers may well be in the pipeline. If one is already on Gauker’s side in these disputes, one should heartily welcome the wealth of detail Words Without Meaning adds to his program. If one is more conservative, more orthodox, one should perhaps be worried about the anomalies rising, but not panicked. At least, not panicked yet."
  },
  {
    "objectID": "posts/tamp/index.html",
    "href": "posts/tamp/index.html",
    "title": "The Asymmetric Magnets Problem",
    "section": "",
    "text": "There are many controversial theses about intrinsicness and duplication. The first aim of this paper is to introduce a puzzle that shows that two of the uncontroversial sounding ones can’t both be true. The second aim is to suggest that the best way out of the puzzle requires sharpening some distinctions that are too frequently blurred, and adopting a fairly radical reconception of the ways things are.\n\nPublished in Philosophical Perspectives 20: 479-92.\nImage by oskay via Creative Commons.\n\n\n0.1 Two Theses about Duplication\nIn all of David Lewis’s discussions of intrinsicness and duplication, he held that the two concepts are connected by a tight circle of interdefinition. Duplicates share all of their intrinsic features, and objects that share all of their intrinsic features are duplicates. (Lewis 1983b, 1983a; Langton and Lewis 1998). Both of these claims are a little controversial. One might hold that some impure properties that aren’t shared by all duplicates, like having George Clooney as a part, are nevertheless intrinsic since gaining or losing them seems to amount to a non-Cambridge change (Weatherson 2006). And one might hold that some properties which don’t differ between duplicates by definition, such as being a duplicate of the Louvre as it actually is, are nevertheless extrinsic (Dunn 1990). So maybe Lewis’s tight circle of interdefinition is not beyond question. But the following principle seems utterly uncontroversial to me.\n\nThanks to the Philosophy Program at the RSSS, ANU, where this was first drafted, to audiences at University of Manitoba and Stanford University, and to the attendees at my seminar on David Lewis at Cornell University. I am especially grateful to Ben Caplan, John Hawthorne, Ishani Maitra, Raul Saucedo and Wolfgang Schwarz.\n\nIntrinsicness Principle\n\nIf a and b differ in their pure intrinsic features, they are not duplicates;\nIf a and b have the same pure intrinsic features, then they are duplicates\n\nThat conjunction is the first of our (hitherto) uncontroversial theses. The second needs a bit more work to state formally.\nIt is fairly intuitive that whether two objects are duplicates is not an emergent feature of reality. In some sense, whether two complex are duplicates just depends on the properties of their parts and the relations between their parts. But this claim does turn out to be controversial; David Lewis (1983b) has controverted it. To a first approximation, his theory says that whether two objects are duplicates depends on whether they share the same perfectly natural properties. If there are any perfectly natural properties that are emergent, i.e. which are properties that complex objects have but not in virtue of the properties of or relations between their parts, then whether two objects are duplicates will also be emergent. Now Lewis doesn’t think there are any emergent perfectly natural properties, since the existence of such properties would be incompatible with the thesis of Humean Supervenience. But Lewis doesn’t think that Humean Supervenience is a necessary truth, let alone a conceptual truth, but at best a contingent truth. So the principle that duplication is not emergent is not something that is true in virtue of the concept of duplication.\nStill, nothing in Lewis’s views suggest that the following principle is false. If all the fundamental properties are not emergent, i.e. they are properties that complex things have in virtue of the fundamental properties of and relations between their parts, then duplication is not emergent. We might try and formalise this as follows. If all the fundamental properties are not emergent, then if the parts of x and y are duplicates, then x and y are duplicates. This principle is, however, too strong. It doesn’t account for the possibility that the parts of x and y are arranged differently. For instance, in the following example, the fusion of a and b is not a duplicate of the fusion of c and d, even though a is a duplicate of c and b is a duplicate of d.\n\nThe problem is that the arrangement of the two objects is different. So what we need is a principle that says that if all the perfectly natural properties are not emergent properties, and if the parts of x and y are duplicates, and those parts are arranged the same way, then x and y are duplicates. Saying this formally is not exactly trivial. The following version uses the idea of an isometry1.\n1 An isometry is “a transformation that does not change the distance between points” (Yaglom 1962, 11). That is, it is a function from points to points that doesn’t change distances. Although the isometry is initially defined as a function on points, it can obviously be extended to a function from regions to regions. If r is a region, i.e. a set of points, then f(r) is {f(x): x \\({\\in}\\) r}.Parts Principle\n\nThis principle holds in all worlds in which no fundamental properties or quantities are emergent. If X and Y are sets of material objects, a is the fusion of the members of X and b is the fusion of the members of Y, f is a function X \\({\\rightarrow}\\) Y, and i is an isometry defined on the space that X and Y are in, and the following conditions hold:\n\nFor all x in X, f(x) is a duplicate of x; and\nFor all x in X, if r exactly occupied by x, then i(r)\n\nis the region exactly occupied by f(x), then a and b are duplicates.\n\nThe Parts Principle is not as easy to state as the Intrinsicness Principle, but I think the idea it is expressing is fairly intuitive. Nevertheless, I think the two principles cannot both be true.\n\n\n0.2 Three Distinctions\nThe problem I’ll be focussing on looks rather simple, but it brings out several points that seem to have metaphysical interest. In particular, it highlights the importance of three distinctions that are easy to blur when doing metaphysics. It will make the exposition of the puzzle easier to place these distinctions up front.\nThe first distinction is between features and properties. Most metaphysicians accept that to fully characterise the world, we need to do more than say what exists. As well as saying what there is, we need to say how the things that exist are. It is easy to assume that to do that, we need to say what properties things have. But this need not be correct, or at least it need not be correct if we are looking to characterise the world in the most fundamental way. It might be that the fundamental features of reality are quantities, i.e. features that objects have to different degrees or in different amounts. Properties, like being green are features, but quantities, like mass or velocity are also features, just features that can be instantiated to different degrees or magnitudes. So feature is a more general category than property, and so as to not beg any questions, I’ll talk about intrinsic features and fundamental features rather than intrinsic properties and fundamental properties throughout. My solution to the problem will involve assuming that at least some of the fundamental features of reality are indeed quantities not properties.\nThe second distinction is between fundamental features and perfectly natural features. Fundamental features are features that do not obtain in virtue of other features obtaining. The fundamental features are part of a minimal basis we need for characterising reality. Generally fundamental features are related to other fundamental features by exceptionless laws, though this is not part of their definition. What is definitional is that they are basic and that they provide a basis for characterising the world without redundancy. (As a Humean, I’d also say that there are no necessary connections between distinct fundamental features, but that is a controversial metaphysical thesis, not a defining characteristic.) Perfectly natural features are features that make for primitive objective resemblance between things that instantiate them. By a primitive objective resemblance, I mean an objective resemblance that does not obtain in virtue of sharing more basic (in the limit, fundamental) properties. David Lewis (1983b) assumes, without much by way of argument as far as I can see, that the fundamental features are the perfectly natural features. My solution to the problem will involve rejecting that identity.\nThe final distinction is between the thesis that all the fundamental non-spatiotemporal features of reality are intrinsic properties of points, and the thesis that these features are local features. Jeremy Butterfield (2006) has stressed the importance of this distinction for metaphysics. A feature is local to a point iff it is intrinsic to arbitrarily small regions around that point. For example, the slope of a curve at a point is local to that point, even though it isn’t intrinsic to the point. So locality and intrinsicness can come apart. (This raises interesting questions about, for example, whether it is best to state the thesis of Humean Supervenience in terms of local properties or in terms of intrinsic properties of points.) I’ll say more about the importance of this distinction in section 5.\nI’ve already made use of these distinctions in setting out the principles about intrinsicness in section one. (In particular, it is crucial that the Parts Principle is stated in terms of fundamental rather than perfectly natural features.) Using them we can get to our central puzzle, the Asymmetric Magnets Problem.\n\n\n0.3 The Asymmetric Magnets Problem\nOur puzzle is similar to the spinning sphere, often thought to raise a problem for Humean Supervenience (Armstrong 1980). The similarity is not in respect of its target; the puzzle is meant to be a puzzle for everyone who accepts those two principles, not just the Humean. Rather, the similarity is in that the puzzle is set in a world where there are homogeneous physical objects. Such a world is in many ways quite distant from actuality. But I think such worlds are useful fictions for elucidating the conceptual connections between central concepts in metaphysics. The puzzle is also set in a world with Euclidean spatial geometry. Again this is a fiction, but a useful one for working out conceptual connections.\nIn this world, some of the fundamental features are what we’ll call vector features. (This is a much smaller deviation from actuality.) Vector features are either quantities like velocity the value of which is a vector, or properties like having velocity v, where v is some vector. In particular, the strength and direction of the magnetic field throughout the world is a fundamental feature of the world. I’ll assume that both space-time regions and physical objects can have these vector features, although I’m only going to focus on the field strength and direction at a point in a physical object. Finally, I’ll assume that all of the fundamental physical quantities in the world are local. So there are no fundamental emergent quantities in the world. It might be worried that the last two assumptions are inconsistent, and that vector quantities could not be local. I’ll come back to this worry in section 5.\nSome of the things in this world are magnets. These are homogeneous objects with a uniform non-zero magnetic field throughout. I’m going to represent the magnetic field strength and direction of such a magnet with an arrow pointing towards the north pole of the magnet. The length of the arrow is proportional to the strength of the field.\nThe simplest kind of magnet is a bar magnet, just like the kind I used to play with in primary school. (Apart from being homogeneous of course!) These are cuboids with equal heights and depths, and a long length in the direction of their magnetic field. Suzy is playing with some magnets and, tiring of using her magnets to grab the other childrens’, decides to sharpen one end of each of her magnets for use as a weapon. The teacher notices this, confiscates the weaponised magnets, and lays them out on her desk. Here is what they look like from the teacher’s point of view.\n\nI’ve added the labels.\nEach magnet has one sharp end and one flat end. Each also has one north pole and one south pole. And, of course, each has one end to the right (from the teachers’ point of view) and one end to the left. The distribution of these properties of ends is different in the three cases.\n\nA’s north pole is sharp and to the right.\nB’s north pole is sharp and to the left.\nC’s north pole is flat and to the left.\n\nQuestion: Which of the magnets are duplicates?\nAnswer: A and B, but not C.\nI hope you agree with the answer! If not, let me provide a small argument.\nA and B are intrinsic duplicates because we could ‘line up’ A and B by picking A up, spinning it around, and moving it across a bit. And that’s only possible if the two objects are duplicates. This idea, that objects that can be transformed into one another by simple geometric transformations such as rotation and translation is a very deep part of our conceptual scheme. Consider, for example, Euclid’s proof of proposition 4.\n\nLet ABC, DEF be two triangles having the two sides AB, AC equal to the two sides DE, DF respectively, namely AB to DE and AC to DF, and the angle BAC equal to the angle EDF. I say that the base BC is also equal to the base EF, the triangle ABC will be equal to the triangle DEF … For, if the triangle ABC be applied to the triangle DEF, and if the point A be placed on the point D and the straight line AB on E, then the point B will also coincide with E, because AB is equal to DE. Again, AB coinciding with DE, the straight line AC will also coincide with DF, because the angle BAC is equal to the angle EDF; hence the point C will also coincide with the point F, because AC is again equal to DF. But B also coincided with E; hence the base BC will coincide with the base EF … and will be equal to it. Thus the whole triangle ABC will coincide with the whole triangle DEF, and will be equal to it. (Euclid 1956, 247–48)\n\nAs many mathematicians have pointed out over the centuries, this is not Euclid’s finest moment as a geometer. The idea he’s pushing is clear enough. If ABC and DEF satisfy the assumptions, then you can pick up ABC and place it on DEF, so that the sides and vertices all coincide. Does this prove that the sides and angles in the original triangle are equal? Not really, or at least not without the assumption that picking up ABC and moving it around doesn’t change its side lengths or angle magnitudes. And Euclid hadn’t said anything at that stage of the Elements to justify this assumption.\nSo qua axiomatic geometer Euclid has blundered here. But there is more to life than axiomatic geometry. There is, for instance, metaphysics. And the assumption Euclid is using here is, I think, a sound metaphysical intuition. (If it weren’t, the complaints about this fundamental proof in Euclid would have been earlier, and more frequent, than they actually were.) That intuition is, I think, that intrinsic properties are not, ceteris paribus, changed merely by moving objects around. Of course other things are not always equal; the intrinsic properties of a car are not preserved if you drive it into a wall. But the kind of abstract motion that Euclid is contemplating when he moves ABC onto DEF, or that I’m contemplating when I think about moving B around so it lines up with A, does not destroy intrinsic properties. So that’s an argument that A and B are intrinsically alike.\nOn the other hand, A and B each have a property that C lacks. Their magnetic field points towards their sharp end. This is in some sense a relational property, it is defined in part in terms of two things pointing in the same direction, but it doesn’t seem like a relation between the magnet and anything else. In general, properties that things have in virtue of relations between their parts are intrinsic properties. (It is intrinsic to the earth, for example, that more of its surface is wet than dry, even though this property is defined in terms of a relation.) So this is an intrinsic property of A. And, given the plausibility of the Intrinsicness Principle, that’s a reason to think that A and C are not intrinsic.\n\n\n0.4 The Principles and the Problem\nHere then is our problem. Try to answer the following question given the two principles: Is the direction of a vector feature an intrinsic feature of its bearer or not? If yes, then A and B are not duplicates. If no, then A and C are duplicates. (In fact all three are duplicates, though I won’t prove this.) Neither way does it turns out that A and B are duplicates, but C is not, as we need. The aim of this section is to spell out that little argument in more detail, so we can see how the principles relate to the problem.\nFirst, we’ll assume that the direction of a vector feature is an intrinsic feature of its bearer. We need a way to rigidly denote directions, so we’ll call the direction that the vector in A points d1, and the direction that the vector in B points d2. Since d1 \\({\\neq}\\) d2, A and B differ in their intrinsic properties. By the second clause of the Intrinsicness Principle, it follows that A and B are not duplicates.\nSecond, we’ll assume that the direction of a vector feature is not an intrinsic feature of its bearer. Now we want to show that B and C are duplicates. To do this we’ll use the Parts Principle. All of the fundamental quantities are local, so the Parts Principle applies. Now let the members of X and Y be the point-sized parts of A and C. Let l be the distance from the tip of the pointed end of A to the tip of the pointed end of C. The isometry i is a translation with length l and direction d1, i.e. a function that maps any point to the point that is distance l away from it in direction d1. This isometry maps A onto C. By the first clause of the Intrinsicness Principle, and the assumption that direction is not intrinsic, every point in A is a duplicate of any point in C. So by the Parts Principle, A and C are required.\nThe conclusion is that if we want to say that A and B are duplicates, but A and C are not duplicates, then we can’t hold on to both the Intrinsicness Principle and the Parts Principle.\nI think we should give up the Parts Principle. In particular, we should say that the Parts Principle holds only if all the perfectly natural features of reality are local, and this might fail to hold even if all the fundamental features of reality are local. The need for the distinction between these possibilities is, I think, the main lesson of the problem. But before we get to that conclusion, I want to address an objection to the argument so far.\n\n\n0.5 Two Worries About Locality\nI can an imagine an objection to this argument along the following lines. In the setup of the problem, I said that some of the fundamental features of reality are vector-valued quantities. I also said that all of the fundamental features of reality are local. But these assumptions are inconsistent. Vector properties are not intrinsic properties of points. (Since we’re trying to hold on to the Intrinsicness Principle, we have to accept this.) Hence they are not, in the salient sense, local features of reality.\nI think this objection is sound all the way to the last step. As noted above, we need to distinguish between local properties and intrinsic properties of points. The distinction is common in mathematics, but has not been paid sufficient attention in metaphysics. Jeremy Butterfield’s (2006) is an important exception, one that was very influential on this paper.\nSo it is fair to say that all fundamental features of reality are local if all the facts about the world supervene on facts about the distribution of fundamental features in arbitrarily small regions, plus facts about the spatiotemporal arrangement of those regions. And there is no reason to think that positing vector features as fundamental is inconsistent with the fundamental features being local in this sense. Butterfield argues, persuasively, that velocity properties in Newtonian mechanics are not intrinsic properties of points, but he stresses that this doesn’t mean they are not local in this sense. He is focussing on velocity, and what he says doesn’t immediately translate to all vector properties. (It matters to his argument, for example, that velocities are conceptually connected to the positions of objects at different times, in a way that, for example, magnetic fields are not.) But I think his conclusions are independently plausible. Indeed, the argument from isometry above is an argument for the very same conclusion. So the short version of my reply is to concede that once we’ve allowed vector properties as fundamental, we can’t say that all the fundamental features of reality are intrinsic properties of points and spatiotemporal relations between them, but this is consistent with saying that all the fundamental features of reality are local.\nOnce we’ve said that, however, a different kind of objection becomes salient. It might be thought that if the fundamental features are intrinsic properties of regions not of points, the natural version of the Parts Principle is slightly weaker than as stated. In particular, we should focus our attention to cases where the sets X and Y consist of objects with positive size. Because this weakening flows naturally from the definition of locality, it doesn’t look like an ad hoc weakening. However this weakening does not at the end of the day help to save the Parts Principle. That’s because we can find a different way to divide up A and C into parts of positive size so that the Parts Principle still applies. A sketch of how we’ll (start to) divide up A is here.\n\nThe idea is that we make one large square part, and then divide the rest of A up into infinitely many diamonds. We do this recursively. Note that we start with a triangle whose base is to the left and vertex to the right. We create from this a diamond whose four vertices are the vertex of the triangle, and the midpoints of each of the three sides of the triangle. If we imagine cutting this diamond out of the magnet, we’d be left with two small triangles, each with a base on the left and a vertex on the right. We can do the same trick to create diamonds and (in imagination) cut them out, leaving us with four triangles. Repeat this until we have an infinity of diamonds. The fusion of all these diamonds with the large square will be our original magnet. Moreover, since every part is symmetric around the axis perpendicular to d1, each part will be a duplicate of the corresponding part in C. So the Parts Principle still tells us, falsely, that A and C are duplicates. We have to look somewhere else to avoid the problem.\n\n\n0.6 The solution and its problems\nThe Asymmetric Magnets Problem looks easy. It is easy to say intuitively why A and B are duplicates, but C is not. The reason was given at the end of section three. In both A and B, the magnetic field ‘points’ in the same direction that the physical object does, while in C this is not the case. The difficulty arises when we try and shoehorn this intuition into a formal theory. We need to say that it is intrinsic to the magnet that its magnetic field points the same way it does. And we need to say this without saying that the direction of the magnetic field is itself intrinsic. I know of one way to do this, but it involves some overheads. I’m not going to argue for this at any length here, but I think the difficulty of providing a general solution to the Asymmetric Magnets Problem is one of many reasons to think that we should learn to live with these overheads.\nMy solution starts with Lewis’s definition of duplication. I gave a rough statement of this above; we now need a more precise statement. For Lewis, two objects are duplicates iff there is a mapping m from parts of one to parts of the other that (a) is an isomorphism and (b) for all n-place perfectly natural properties P, and all parts x1, …, xn of the first object, Px1…xn iff Pm(x1)…m(xn). So the objects are duplicates if their parts have the same natural properties, and stand in the same perfectly natural relations. That’s how Lewis’s theory goes; now we have to start adding variations. The first variation is quite radical, but one we have independent reason to make.\nAs John Hawthorne (2006) and David Denby (2001) have argued, Lewis’s theory of properties has difficulties accounting for quantities. Hawthorne notes that if we just take individual mass properties, e.g. having mass 17kg, having mass 42ng etc as perfectly natural, there is no way to state physical laws involving mass, such as the law of gravitation, as simple statements where all predicates denote perfectly natural properties. But the theory of laws in Lewis (1983b) says that all physical laws are simple statements where all predicates denote perfectly natural properties. This is something of a problem. For different reasons, Denby suggests that we take determinables as being perfectly natural. The individual mass properties are perfectly natural, he suggests, but not fundamental. What is fundamental is the determinable, mass, of which they are determinate.\nI think we should make a more radical move in the interests of simplicity. What reason do we have for thinking that the fundamental ways things are are properties rather than quantities or magntitudes? Very little reason, I’d say. Modern physics seems much more concerned with quantities than properties. What properties it is concerned with, such as being positively charged, seem to be derived from more fundamental quantities, such as charge. It would perhaps be convenient for formal semantics if the world had an object-property structure to match the subject-predicate structure of simple sentences. But we have no reason to believe the world will be so accommodating. It might turn out that there are a few fundamental quantities in the world. A quantity is a feature that objects have to different degrees. We can identify each value a quantity takes with a property. (Examples are properties like having mass 17kg.) But that shouldn’t make us think that the properties are metaphysically primary. They might be derived from the quantities. Hawthorne’s and Denby’s arguments push us towards that conclusion, and I’ll show here that assuming quantities are primary helps us state a solution to the Asymmetric Magnets Problem.\nSome quantities take simple values. The values of the mass quantity, for instance, are sufficiently simple that they can be represented by real numbers. But not all quantities are like that. In some cases the values are structured entities, which are composed of a magnitude and some other some other part or parts. Vector quantities are like this. We can naturally think of vectors as structured entities composed of a direction and a magnitude. I’m going to assume, at least for the sake of solving this problem, that any perfectly natural quantity takes values that either are magnitudes (as mass does) or takes values that are structured entities composed, among other things, of a magnitude. (This is an empirical assumption, and it may well not be true. If it is not true, the analysis of duplication below will need to be made more complicated.) For ease of exposition, I’ll say that a function \\(f\\) is perfectly natural iff it maps objects onto values, such that there is some perfectly natural quantity such that for any \\(x, f(x)\\) is the value that quantity takes with respect to \\(x\\). So if the quantity is mass, \\(f(x)\\) is \\(x\\)’s mass. And I’ll say that \\(|f(x)|\\) is the magnitude of this value, in the sense described above. (The notation here is slightly non-standard, since I allow that magnitudes may be negative numbers. For example, if \\(f\\) represents charge and \\(x\\) is negatively charged, then \\(|f(x)|\\) may be a negative number.)\nNow for the definition of duplication. Two objects are duplicates iff there is a mapping \\(m\\) from parts of one to parts of the other that (a) is an isomorphism and (b) for all \\(n\\)-place natural functions \\(f\\), and all parts \\(x_1, ..., x_n\\) of the first object, \\(|f(x_1,\\dots, x_n)| = |f(m(x_1),\\dots,f(m(x_n))|\\). So the objects are duplicates if the magnitudes of each of the natural quantities of each of their parts are the same. This allows that the quantities can vary without loss of intrinsic character, provided there is no variation in magnitude.\nThe Asymmetric Magnets Problem suggests a view on which the directions of vector features are indirectly relevant to the intrinsic nature of objects. ‘Indirectly’ because changing the direction doesn’t change the intrinsic properties of objects. But ‘relevant’ because the direction can matter, as we see when comparing A and C. The definition of duplication in terms of quantities that take structured values allows us to capture this indirect relevance. We’ll do so by defining a feature whose magnitude varies depending on how the object’s shape and the direction of its vector features are coordinated.\nLet \\(f\\) be a function representing some perfectly natural quantity such that \\(f(x)\\) is a vector. That is, \\(f\\) represents some perfectly natural vector quantity. This quantity may or may not be fundamental, though it will be fundamental in the cases under consideration here. Let \\(c\\) be a function that takes an object as input and returns its geometric centre as output. (By the geometric centre of \\(x\\) I mean the centre of mass of an object with the same shape as \\(x\\) and uniform mass density throughout.) Now suppose that the following function is perfectly natural. \\[g(x, y, z) =_{df} \\text{the cosine of the angle between }f(x)\\text{ and the ray from }g(y)\\text{ to }g(z)\\]\nThe motivation for taking this to be perfectly natural (but obviously not fundamental) is that it delivers the right results about the Asymmetric Magnets Problem, and it seems to deliver those results for the right reasons. To see it delivers the right results, just apply the above definition of duplication. Two objects are duplicates iff there is an isomorphism \\(m\\) from the parts of one to the parts of the other such that for all \\(n\\)-place natural functions \\(f\\), and all parts \\(x_1, ..., x_n\\) of the first object, \\(|f(x_1,\\dots, x_n)| = |f(m(x_1),\\dots,f(m(x_n))|\\). To make the discussion easier, we’ll redraw the magnets with some salient parts labelled.\n\nAny isomorphism from A to B that satisfy this constraint has to map A1 to B1, and A2 to B2. And any isomorphism from A to C that satisfy this constraint has to map A1 to C1, and A2 to C2. Now let f be the function whose value is represented by the arrow, and let g be the function defined as above. So if A and B are duplicates, it must be the case that g(A, A1, A2) = g(B, B1, B2). It is easy to verify that since f(A) points in the same direction as the ray from the centre of A1 to the centre of A2, \\(g(\\text{A}, \\text{A}_1, \\text{A}_2) = 1\\), and similarly the ray from the centre of B1 to the centre of B2 points in the same direction as f(B), g(B, B1, B2) = 1. So there is no reason here to doubt that A and B are duplicates. On the other hand, since the ray from the centre of C1 to the centre of C2 is in the opposite direction to f(C), g(C, C1, C2) = -1. So there is no isomorphism from parts of A to parts of C that preserves the value of perfectly natural properties, so A and C are not duplicates, as required.\nI don’t doubt that there are other ways to solve this problem, so I certainly won’t try arguing that this is the only solution. But I think it works, and the reason it works is because the values of natural quantities are structured entities, in this case vectors. Because they have structure, we can use one part of the structure (i.e. the magnitude) in determining what is directly relevant to intrinsicness, and another part of the structure (in this case the direction) in determining what is indirectly relevant. So it’s an important advantage of using quantities rather than properties as the centrepiece of our metaphysics that the values of natural quantities can be structured entities, and having something like structured quantities seems crucial to solving this problem.\nAlthough g is represents a perfectly natural quantity, it does not represent a fundamental quantity. Instead, it represents a quantity whose value supervenes on the distribution of other perfectly natural quantities. So we have to allow that there is a distinction between the fundamental quantities and the perfectly natural quantities. I don’t think this is a cost of the theory; there is no way to capture the idea that directions are indirectly relevant without distinguishing between the perfectly natural and the fundamental, so the Asymmetric Magnets Problem is a reason to make such a distinction. (I’m indebted here to Ben Caplan.)\nWe can reduce the apparent cost of this distinction by noting that one reason we might have for blocking redundant natural quantities does not apply here. (By a redundant quantity, I just mean one that supervenes on the fundamental quantities.) We don’t want to say that disjunctive properties like being grue, that supervene on other natural properties, are perfectly natural. But that’s not primarily because of the supervenience, but because of the fact that grueness doesn’t make for resemblance amongst the things that instantiate it. So at least that reason for caring about redundancy doesn’t apply here. (I’m indebted here to Raul Saucedo.)\nFinally, it is crucial to my solution that A, B and C have these parts. If A, B and C are extended simples, I can’t run the argument I make here. Indeed, if they are extended simples, it looks like they are duplicates by my definition. That seems bad. I think this is a problem that we don’t need to worry about, because this isn’t a real possibility. I’ll concede for the sake of argument that there are such things as extended simples. What I don’t see any need to concede the possibility of are asymmetric extended simples. In general, the way that we deduce that an object has parts is by noting it has different properties at different places. (This point is made in Sider (2003).) I think this is just the right strategy to use, as a matter of necessity. If an object has different properties in different locations, it has different parts in those different locations. So there could not be extended simples that are asymmetric magnets. The case where my theory produces the wrong result is an impossible case.\n\n\n0.7 Wrapping Up\nThis paper has had several ambitions, some loftier than others. The most basic aim has been to introduce the Asymmetric Magnets Problem, and argue that it is going to be hard work for a systematic theory of intrinsicness to account for the facts about the problem. The more profound aims involve tearing apart concepts that metaphysicians often take for granted are interchangeable. My solution to the problem involves distinguishing local features from intrinsic features of points, fundamental features from perfectly natural features, and, most importantly, features from properties. The last of these is I think the biggest point. If we come to believe that quantities, not qualities, are the fundamental ways things are, then quite a bit of metaphysical orthodoxy needs rewriting. Some of that rewriting may be simple; just a matter of crossing out ‘li’ and writing in ‘nt’ in the middle of some words. But changes in fundamental metaphysics tend not to be isolated, and the rewriting project may lead to more wide-ranging changes. (Egan (2004) makes this point well, with an important illustration.) Now I certainly haven’t given anything like a conclusive argument in this paper that we should set about that project immediately. I have, however, provided one reason to think the project will eventually be necessary, and I suspect that more reasons will be provided in the future.\n\n\n\n\n\n\nReferences\n\nArmstrong, David. 1980. “Identity Through Time.” In Time and Cause: Essays Presented to Richard Taylor, edited by Peter van Inwagen, 67–78. Dordrecht: Reidel.\n\n\nButterfield, Jeremy. 2006. “Against Pointillisme about Mechanics.” British Journal for the Philosophy of Science 57 (4): 709–53. https://doi.org/10.1093/bjps/axl026.\n\n\nDenby, David. 2001. “Determinable Nominalism.” Philosophical Studies 102 (3): 297–327. https://doi.org/0.1023/A:1010314926955.\n\n\nDunn, J. Michael. 1990. “Relevant Predication 2: Intrinsic Properties and Internal Relations.” Philosophical Studies 60 (3): 177–206. https://doi.org/10.1007/bf00367469.\n\n\nEgan, Andy. 2004. “Second-Order Predication and the Metaphysics of Properties.” Australasian Journal of Philosophy 82 (1): 48–66. https://doi.org/10.1080/713659803.\n\n\nEuclid. 1956. The Thirteen Books of the Elements, Tr. Thomas l. Heath. New York: Dover.\n\n\nHawthorne, John. 2006. “Quantity in Lewisian Metaphysics.” In Metaphysical Essays, 229–37. Oxford: Oxford University Press.\n\n\nLangton, Rae, and David Lewis. 1998. “Defining ‘Intrinsic’.” Philosophy and Phenomenological Research 58 (2): 333–45. https://doi.org/10.2307/2653512.\n\n\nLewis, David. 1983a. “Extrinsic Properties.” Philosophical Studies 44 (2): 197–200. https://doi.org/10.1007/bf00354100.\n\n\n———. 1983b. “New Work for a Theory of Universals.” Australasian Journal of Philosophy 61 (4): 343–77. https://doi.org/10.1080/00048408312341131.\n\n\nSider, Theodore. 2003. “Maximality and Microphysical Supervenience.” Philosophy and Phenomenological Research 66 (1): 139–49. https://doi.org/10.1111/j.1933-1592.2003.tb00247.x.\n\n\nWeatherson, Brian. 2006. “Intrinsic Vs. Extrinsic Properties.” In The Stanford Encyclopedia of Philosophy (Fall 2006 Edition), edited by Edward N. Zalta. Metaphysics Research Lab, Stanford University.\n\n\nYaglom, I. M. 1962. Geometric Transformations i. Random House: New York."
  },
  {
    "objectID": "posts/mbt/index.html",
    "href": "posts/mbt/index.html",
    "title": "Memory, Belief and Time",
    "section": "",
    "text": "I know a lot about the past. I know, for instance, that the Chicago White Sox won the 2005 baseball World Series. I remember that’s true. I don’t remember the event. I was in Australia, and it wasn’t on television. I don’t even remember the event of learning that the White Sox won. But I remember that they won. And to remember something is to, inter alia, know it is true. And to know something is to, inter alia, have a rational belief that it is true.\nSo I have a rational belief that the White Sox won the 2005 baseball World Series. In virtue of what is this belief of mine rational? That’s too big a question to answer here, so let’s start narrowing it down. Is this belief rational in virtue of facts about how I now am, or historical facts about me? Call the former view a temporally local theory of rationality, and the latter a temporally extended view. Which of those is correct?\nI’m going to defend the temporally extended view. In this respect I’m following recent work by David James Barnett (2015), though being a philosopher I’ll quibble about his argument, put forward alternate reasons, and so on. But I’m agreeing with his big conclusion.\nAt least, I’m going to agree with a version of that conclusion. I’m an evidentialist about rationality, in a sense that I’ll try to make clearer as we progress through the paper. So it’s natural to convert the core question into a question about evidence, and about evidence acquisition. What is my evidence that the White Sox won the 2005 World Series, and in virtue of what do I have that evidence? Is it the currect fact that it mnemonically seems to me that the White Sox won, perhaps supplemented with some knowledge I have about the reliabiity of my mnemonic seemings? Or is it something more temporally extended? I’m going to argue that it is the latter.\nMy positive view, inspired to some extent by the evidence is knowledge view defended by Timothy Williamson (2000), is that the fact the White Sox won became part of my evidence some time in 2005, and has stayed in my evidence ever since. At the time this belief, and this knowledge, was grounded in further evidence, presumably perceptual evidence of what some computer screen looked like. But I came to know the White Sox won, and this became part of my evidence. An alternative view is that the visual seemings from 2005 are part of my evidence still. That’s what the view of David Lewis (1996) implies. And yet another view is that the content of those perceptions, perhaps that ESPN is telling me the White Sox won, is still in my evidence. I don’t like either of these latter views, but I’m not going to argue about them here. Rather, the focus is on whether evidence is contemporary or historical, and I want to argue for the class of historical theories over the class of contemporary theories."
  },
  {
    "objectID": "posts/mbt/index.html#evidentialism",
    "href": "posts/mbt/index.html#evidentialism",
    "title": "Memory, Belief and Time",
    "section": "1 Evidentialism",
    "text": "1 Evidentialism\nI’m interested in memory because it raises challenges for the evidentialist theory I’d like to defend. Evidentialism, as we’ll start construing it, says that the doxastic attitudes it is rational to have depend entirely on the evidence one has. This is a version of evidentialism. I’m taking this to be a thesis both about partial beliefs, what are commonly called credences in the philosophical literature, and full beliefs. I have a lot to say elsewhere about the relationship between full and partial belief  (Weatherson 2012), but I won’t be relying on those views here.\nI am construing the ‘dependence’ in the statement of evidentialism rather weakly. It is just a claim that the evidence one has, and the attitudes it may be rational to hold, co-vary. Put another way, the rationality of doxastic attitudes supervenes on one’s evidence, at least throughout worlds similar enough to this one. I am not defending the stronger claim that facts about what evidence one has are always explanatorily prior to facts about what doxastic attitudes it is rational to hold.\nIt is easy enough to imagine epistemologies that aim for this more ambitious, priority, thesis. David Lewis (1996), for instance, suggests we should understand evidence in terms of phenomenal states; two agents with the same phenomenology over time have the same evidence. It’s arguable that facts about phenomenology are metaphysically prior to facts about rationality. So, if one was an evidentialist with Lewis’s theory of evidence, it would be natural to think that facts about evidence didn’t just subvene facts about rationality; the former provided full and perhaps reductive explanations for the latter.\nI hold out no such hope for reductive explanations. Indeed, I’m closer in spirit to the kind of view you might read into Timothy Williamson (2000). As noted above, Williamson holds that one’s evidence is all and only what one knows. This thesis has become known as E=K. The notation here is instructive. It is commonplace to introduce new terms by definition by putting the new term on the left-hand side of an equality sign. \\(A =_{df} B\\) means that \\(A\\) is defined to be identical to \\(B\\), not the other way around. The E=K thesis suggests a form of evidentialism where evidence is in fact explanatorily posterior to rationality. Something is part of one’s evidence in virtue of the fact that one knows it, and arguably one only knows what one rationally believes.\nI’ve been a bit coy in the previous paragraph about what I’m attributing to Williamson, and what I’m just saying can be read into him. That’s because the view Williamson defends is not that rationality has explanatory priority, but that knowledge does. As he says in the first line of his book, his view is “knowledge first”  (Williamson 2000 v). And it’s consistent with ‘knowledge first’ to say that the explanatory relationship between evidence and rationality is complicated and multi-directional. Although I don’t endorse the knowledge first program, I agree with that last conclusion. The explanatory relationship between evidence and rationality is complicated and multi-directional. Evidentialism should not be construed as denying this claim.\nThe other way in which my version of evidentialism is weaker than it may be is that it really is restricted to being a claim about rationality. It isn’t a claim about justification. For all I say here, maybe something other than evidence determines whether a doxastic attitude is justified. For example, it may be that only true beliefs are justified. I don’t think that’s true, but if it is it would be consistent with evidentialism as I’m construing it.\nMore importantly for what follows, evidentialism also isn’t a claim about wisdom. It is very important to keep evaluations of agents apart from evaluations of acts or states. It is attitudes or states that are in the first instance rational or irrational. We can talk about rational or irrational agents, but such notions are derivative. Rational agents are those generally disposed to have rational attitudes, or be in rational states. Wisdom, on the other hand, is in the first instance a property of agents. Again, we can generalise the term to attitudes or states. A wise decision, for instance, is one that a wise person would make. But the wisdom of agents is explanatorily and analytically prior to the wisdom of their acts, judgments, decisions and attitudes. (I think that everything I’ve said in this paragraph is true of ordinary English. But I’m not committed to that, and it doesn’t matter if I’m wrong. You can read this paragraph as stipulating that ‘rational’ is to be used as a term that in the first instance applies to states, and ‘wise’ is to be used as a term that in the first instance applies to agents, and little will be lost.)\nEvidentialism is not a claim about the nature of wise agents. Perhaps a wise agent is one who always has rational attitudes. If so, then evidentialism will have quite strong implications for what wise agents are like. But that connection between wisdom and rationality is far from an obvious conceptual truth. For all I’ve said, it may well be wise to have doxastic attitudes that do not track one’s evidence. That is consistent with evidentialism, provided we understand the relevant situations as being ones where it is unwise to have rational attitudes.\nThe most important recent work on the connection between rationality and wisdom is by Maria Lasonen-Aarnio (2010, 2014a). And I agree with almost everything she says about the connection. The biggest difference between us is terminological. She uses ‘reasonable’ and ‘reasonableness’ where I use ‘wise’ and ‘wisdom’. In my idiolect, I find it too easy to confuse ‘rational’ and ‘reasonable’. So I’m using a different term, and one that, to me at least, more strongly suggests a focus on agents, not states. But this is a small point, and everything I say about the distinction draws heavily on Lasonen-Aarnio’s work.\nFinally, I’m not taking evidentialism to be committed to any kind of uniqueness thesis. It may be that different agents with the same evidence can have different views about p, and both be rational. That’s fine, as long as any agent with just that evidence could have either view about p and be rational. The view is that there’s a function from evidence and attitude to rational evaluation, not that there’s a function from evidence to rational attitude."
  },
  {
    "objectID": "posts/mbt/index.html#memoryandtestimony",
    "href": "posts/mbt/index.html#memoryandtestimony",
    "title": "Memory, Belief and Time",
    "section": "2 Memory and Testimony",
    "text": "2 Memory and Testimony\nIt’s natural to think about theories of memory by analogy to theories of testimony. Indeed, we see this strategy used in otherwise very different work by Sarah Moss (2012) and David James Barnett (2015). Moss and Barnett have very different views on memory, and very different views on the relationship between memory and testimony, but they both find it worthwhile to situate views about memory in relation to views about testimony. And I will follow this lead.\nFor an evidentialist, there are three interesting classes of theories of testimony. These almost, but not quite, track onto familiar categories of theories in the literature on testimony. I’ll use slightly idiosyncratic names for them, just to indicate that the categories aren’t exactly the same. In all cases, speaker S says that p on the basis of evidence E, and hearer H hears (and understands) the speaker. (And I’ll assume S is a she, and H a he.) I’m going to start with the case where S knows that p, and H has no reason to doubt S’s testimony; we’ll look at the complications that ensue when those assumptions are dropped presently.\nThe classes I’m interested in are divided by their answers to two questions:\n\nIs the evidence that H gets, in the first instance, that p, or that S said that p?\nIf the evidence is only that S said that p, is the fact that S said that p a ‘self sufficient’ reason to believe that p, or does it need to be supplemented?\n\nThe term ‘self sufficient’ is borrowed from Anna-Sara Malmgren (2006), who uses it in describing work by Crispin Wright (2002, 2004), James Pryor (2004) and Roger White (2005). Wright, Pryor and White are primarily concerned with whether perceptual appearances are self sufficient reasons to believe their contents, or they need to be supplemented. That isn’t the focus here; like Malmgren I’m focussing on testimony and memory.\nHere are the three classes of views that you get from the natural answers to those questions.\n\nIndirect Theories of Testimony.\n\nThe evidence is that S said that p, and this is not a self-sufficient reason to believe that p. This class closely corresponds to the class of so-called reductionist theories of testimony. Jennifer Lackey (2008) provides an important recent indirect theory.\n\nDirect Theories of Testimony.\n\nThe evidence is that S said that p, and this is a self-sufficient (though defeasible) reason to believe that p. Many theorists who reject reductionism about testimony endorse what I’m calling a direct theory. C. A. J. Coady (1995) provides an important recent direct theory.\n\nTransmission Theories of Testimony.\n\nThe evidence is that p, so it doesn’t matter how we answer the second question. Frederick Schmitt (2006) provides an important recent transmission theory.\n\n\nTransmission theories need not deny that H also gets the evidence that S said that p. And they need not take a stand on how good that evidence is as evidence that p. And direct theories need not deny that H may have independent evidence that if S says that p, then p is true. But in the other direction, I’m taking it as characteristic of the theories that they deny the core claims of the ones that come after them. So indirect theories deny that H immediately gets evidence that p, or that S says that p is a self sufficient reason to believe p. And direct theories deny that H immediately gets evidence that p.\nThe direct and transmission theories just say that a certain thing is possible. I haven’t said yet what they have to say about when it possible. To make matters a little less abstract, I’ll focus for now on theories that abide by the following constraints.\n\nS saying that p is only reason to believe that p in the absence of evidence against p, and in the absence of evidence against S’s reliability.\nH only gets to add p to their stock of evidence if it was in S’s stock of evidence to start with; testimony doesn’t generate evidence, except for evidence about what is said.\n\nA direct theory that didn’t comply with the first constraint really would be a charter for gullibility. Even with this constraint, direct theories possibly are too gullible, as Elizabeth Fricker (1994) has argued, but without this constraint they certainly are. And a transmission theory that didn’t comply with the second constraint would not deserve the name transmission; it would be a generative theory.\nWe can use these categories to draw three similar categories of memory. Here the case is that M forms a belief that p at \\(t_1\\), and has an apparent memory of p at \\(t_2\\). As we might put it, her memory reports that p at this time. As above, start with the simple case where M knows p at \\(t_1\\), and there is no counterevidence, or reason to doubt her own reliability, at later times. We’ll come back, in great detail, to cases where those assumptions are relaxed. What evidence does M get, in these simple cases, when her memory reports that p, and how good is this evidence?\n\nIndirect Theories of Memory\n\nThe evidence is that M’s memory reports that p, and this is not a self sufficient reason to believe that p.\n\nDirect Theories of Memory\n\nThe evidence is that M’s memory reports that p, and this is a self sufficient reason to believe that p.\n\nTransmission Theories of Memory\n\nThe evidence is that p.\n\n\nThe first two theories are temporally local, in the sense I started with, and the last is temporally extended. Again, we’ll put some restrictions in place.\n\nMemory’s reporting that p is only a self sufficient reason to believe that p in the absence of either evidence against p, or evidence that memory is unreliable.\nMemory only transmits evidence that p if p was genuinely among M’s pieces of evidence at an earlier time. And that requires, I’m assuming, that M knew that p at the earlier time.1\n\n1 As with the transmissive view on testimony, I don’t take it to be essential to the transmissive view that all mnemonic knowledge is transmitted. Perhaps, as Lackey (2005) argues, memory can sometimes generate new knowledge. Even so, as long as it sometimes plays a purely preservative role, the transmissive theory is true.2 Michael Dummett (1994) also defends a transmissive account of memory, though the analogy between testimony and memory is important in his argument. Jérôme Dokic (2001) endorses Dummett’s position on memory.Since I want to defend a temporally extended theory, that means I’m defending the transmission theory. And like Barnett, I do so while rejecting the corresponding theory of testimony.2 But once we set things out this way, we see that there are two distinct temporally local theories, and they fail for slightly different reasons. Before we get to why they fail, we’ll look at a reason for thinking one or other of them must work."
  },
  {
    "objectID": "posts/mbt/index.html#shangrila",
    "href": "posts/mbt/index.html#shangrila",
    "title": "Memory, Belief and Time",
    "section": "3 Shangri La",
    "text": "3 Shangri La\nThe Shangri La case introduced by Frank Arntzenius (2003) can be used to generate an argument that evidentialists are committed to the temporally local approach to evidence. This isn’t exactly how Arntzenius introduced it; he introduced it as a puzzle for conditionalisation. But the argument I’m interested in is related to the puzzle Arntzenius introduced. Here is how Michael Titelbaum describes the example.\n\nYou have reached a fork in the road to Shangri La. The guardians of the tower will flip a fair coin to determine your path. If it comes up heads, you will travel the Path by the Mountains; if it comes up tails, you will travel the Path by the Sea. Once you reach Shangri La, if you have traveled the Path by the Sea the guardians will alter your memory so you remember having traveled the Path by the Mountains. If you travel the Path by the Mountains they will leave your memory intact. Either way, once in Shangri La you will remember having traveled the Path by the Mountains. The guardians explain this entire arrangement to you, you believe their words with certainty, they flip the coin, and you follow your path. What does ideal rationality require of your degree of belief in heads once you reach Shangri La.  (Titelbaum 2014, 120)\n\nThe name of the person Titelbaum’s narrator is addressing isn’t given, so we’ll call him Hugh. And we’ll focus on the case where Hugh actually travels by the Mountains.\n\n\n\nOriginal Shangri La game; Hugh takes the right-hand path\n\n\nThere is something very puzzling about Hugh’s case. On the one hand many philosophers (including Arntzenius and Titelbaum) report a strong intuition that once in Shangri La, Hugh should have equal confidence that he came by the mountains as that he came by the sea. On the other hand, it’s hard to tell a dynamic story that makes sense of that. When he is on the Path by the Mountans, Hugh clearly knows that he is on that path. It isn’t part of the story that the paths are so confusingly marked that it is hard to tell which one one is on. Then Hugh gets to Shangri La and, well, nothing happens. The most straightforward dynamic story about Hugh’s credences would suggest that, unless something happens, he should simply retain his certainty that he was on the Path by the Mountains.\nAnd you might think evidentialism is committed to the same thing as that dynamic story. To see why, imagine that Hugh is being terrifically sneaky, and wearing a small camera in his glasses. The camera is tracking what he sees, and Laurie is watching it on a distant TV monitor. The guardians can’t do anything to Laurie’s memory, so they don’t, just like they don’t do anything to Hugh. That night, it might seem Hugh and Laurie have the same evidence. Yet, according to some intuitions, it is rational for Laurie to believe that Hugh took the Path by the Mountains, and not rational for Hugh to believe this.\nHere’s a natural way out of that bind. Say that the evidence Hugh and Laurie have does not consist of what they saw as Hugh was ascending, but their current mnemonic seemings. Now their evidence is different. Hugh has the evidence that it seems to Hugh that Hugh ascended via the mountains, and Laurie has the evidence that it seems to Laurie that Hugh ascended via the mountains. And it is common knowledge that in either this world or a nearby one, Hugh’s mnemonic seemings are unreliable, while Laurie’s are reliable in all nearby worlds. So the temporally local theories can handle the problem, while one might think temporally extended theories cannot.\nThe most straightforward way to explain the common intuition about Shangri La is via the indirect theory of memory. On that theory, Hugh won’t know that he came to Shangri La via the mountains. That’s because the report of his memory, “We got here via the mountains, Hugh!”, would be the same however he came up, and Hugh knows it. There is no basic entitlement, on this theory, to move from My memory says that p to p, and since Hugh does not even believe that a correlation obtains in practice between what he believes about his method of ascent and how he actually ascended, there is no earned entitlement.\nIt is a little tempting to read some of the published arguments that Hugh can’t know he came via the mountains as reasoning in just this way. Here is Arntzenius’s central argument. (Assume Arntzenius is talking to Hugh here, so ‘you’ picks out Hugh.)\n\nFor you will know that he would have had the memories that you have either way, and hence you know that the only relevant information that you have is that the coin was fair.  (Arntzenius 2003, 356)\n\nSarah Moss (2012) makes a similar claim about the case. (Again, her narration is addressed to Hugh.)\n\nIntuitively, even if you travel on the mountain path, you should have .5 credence when you gets to Shangri La that the coin landed heads. This is a case of abnormal updating: once you arrive in Shangri La, you can no longer be sure that you traveled on the mountain path, because you can no longer trust your apparent memory.  (Moss 2012, 241–42)\n\nNow it isn’t immediately clear why the fact that Hugh would have the same apparent memories in the two cases should matter. As far as I can see, the only way it could matter is if the following two things were true. First, we are using a temporally local theory, so the evidence is what Hugh’s memory reports when he is in Shangri La, not the evidence he acquired on the trip up the mountain. And second, what those appearances support is solely a function of things internal to the agent, and not, say, their connection to the truth. As an evidentialist, I’m committed to a version of that second assumption - at least, I’m committed to saying that things that over-ride evidence must themselves be evidence.\nLet’s focus for now on the assumption of temporal localism behind the arguments here. I’m going to offer a series of arguments against it, starting with a variant on the Shangri La case."
  },
  {
    "objectID": "posts/mbt/index.html#iteratedshangrila",
    "href": "posts/mbt/index.html#iteratedshangrila",
    "title": "Memory, Belief and Time",
    "section": "4 Iterated Shangri La",
    "text": "4 Iterated Shangri La\nHere’s a slightly more complicated variant of the Shangri La example.\n\nSati walks up to the base of the paths to Shangri La. “Have some toast and yeast extract,” says one of the attendants, somewhat stiltedly.\n“Yeast extract?” says Sati.\n“Yes, yeast extract. Vegemite or Marmite, your choice.”.\n“Must I?” says Sati.\n“You must.”\n“Well, Vegemite then,” says Sati, recalling fond memories of having Vegemite in Australia, and dire memories of that trip to the English countryside.\n“Good choice,” says the attendant. Sati has her Vegemite on toast, and heads up the mountain path to Shangri La, as directed. On the way, she notices a worried looking person standing in front of a priest about to flip a coin. When she gets to Shangri La, she asks the attendant about that.\n“Oh,” says the attendant, “he chose Marmite.” Sati looks confused as to why this is relevant, so the attendant continues. “The priests don’t like people who choose Marmite, but they still must let them through. So they flip a coin to decide whether they will go by the sea or the mountains. Then, if they went by the sea, they will wipe the memory of that trip, and replace it with a memory of going through the mountains.”\n“I’m glad that didn’t happen to me. Lucky I chose Vegemite.”\n“Recently,” continued the attendant, “the priests decided to make things more complicated. They decided they would also wipe the memory of having eaten the Marmite, and hence facing the coin flip. Instead they would implant a false memory of having chosen Vegemite, indeed false memories of having preferred Vegemite to Marmite in the past, plus a false memory of seeing some other poor sap facing the coin flip. They really really don’t like Marmite eaters.”\n“So all the Marmite eaters get memories wiped?” asked Sati.\n“No, only if the coin lands the wrong way. So some people get to the top thinking they liked Marmite. But we only tell that memories of going by the sea will be wiped. In fact, knowing they chose Marmite is evidence they went by the Mountains, but they don’t know that.”\n“It all sounds horrible,” says Sati. “I’m so glad I remembered I liked Vegemite more than Marmite.”\n“Have a good day!” said the attendant, grinning.\n\nI think that Sati’s last statement is correct; she does remember that she likes Vegemite more than Marmite. Indeed, she knows this in virtue of her memory. But it’s not clear how a temporally local theory, either direct or indirect, can get that answer.\nImagine someone, call him Joe, who starts off in the same situation as Sati at the base of the mountain. Sadly, due to an unfortunate unbringing, he prefers Marmite to Vegemite, so he takes that. And then the coin lands the wrong way, and he is sent by the sea. Then his memories are wiped and replaced with fake memories when he gets to Shangri La.\n\n\n\nRevised Shangri La game; Sati takes the right-hand path, Joe the left- hand path\n\n\nIf a temporally local theory is correct, then presumably Sati and Joe have the same evidence. And that means if evidentialism is true, then it is rational for them to believe the same things. Yet that is implausible; Joe should not be very confident that he had the Vegemite, came by the mountains, and so on.\nOn the other hand, it is overdetermined that Sati can know she came by the Mountains. The crucial difference between Sati and Hugh comes from the defeasibility conditions on the transmission theory. Past memories that p transform into current evidence that p unless they are forgotten, or the agent gets some good reason to suspect that her memory is unreliable. Hugh has such a reason; he is a coin flip away from having faulty memories. Sati does not have such a reason. She knows that had she had a very different kind of upbringing, and had she been on the bad end of a coin flip, she would have had faulty memories. But a reason to think that had things been different she would have reason to distrust her memories is not, itself, a reason to distrust her memories.\nSati’s case is not meant to be a close call. There are lots of relevant ways in which her case is different to cases in which the defeasibility clause is triggered. The fact that two different kinds of things need to have gone wrong here is relevant. And the fact that the first requires things going wrong for a long long time into the past is relevant. And the fact that the first is only a problem in very different possible worlds to actuality is relevant. In short, any plausible kind of defeasibility condition whatsoever on the transmission theory will mean that Joe’s memories of going by the sea are not transmitted, but only an implausibly strong defeasibility condition will prevent Sati’s memories from being transmitted.\nNote that I have not said that Sati can trust her memories because the probability of them being unreliable is so low. That is not the way to formulate defeasibility conditions. The sense of probability that is relevant here is evidential probability. And evidential probability is, as the name suggests, explanatorily posterior to evidence possession. We should not use evidential probability in our theory of what evidence the agent has. Sati knows she grew up liking Vegemite, despite the Shangri La shenanigans. But that’s not because it is so improbable that she had her memories wiped. Rather, it is improbable she had her memories wiped because she knows she does not meet the conditions under which memories are wiped.\nSo temporally extended theories can distinguish Sati’s case from Joe’s, as intuition requires that they be distinguished. But temporally local theories seem to have a problem here. Perhaps the problem here is not with the theory of mnemonic evidence that the the temporally local theories hold, but with evidentialism. Perhaps, that is, this is a case where we should say that Sati and Joe have the same evidence, but that this evidence supports different beliefs given the different reliability of their memories.\nBut there is little to be said to motivate such a theory. If we aren’t going to be evidentialists, it isn’t clear what the relevance of a theory of evidence is. And if we are going to say that historical events, like the fact that Joe’s memories were wiped and Sati’s weren’t, are relevant to contemporary rationality, it isn’t clear what we gain by having a temporally local theory of evidence. Either way, we have said that the existence of past events is relevant to the rationality of current beliefs. At this point we aren’t engaged in much more than a terminological dispute with the temporally extended theories."
  },
  {
    "objectID": "posts/mbt/index.html#againstindirecttheory",
    "href": "posts/mbt/index.html#againstindirecttheory",
    "title": "Memory, Belief and Time",
    "section": "5 Against Indirect Theory",
    "text": "5 Against Indirect Theory\nAs Matthias Steup (2013) argues, the indirect theory of memory is implausible. It says that when one remembers that, say, the Chicago White Sox won the 2005 World Series, there are two things that are needed in order to ground the rational belief. The first is the apparent memory, and the second is some kind of reason to think that the memories are reliable. But the only reasons we could have for believing the second comes from what we have learned about the track record of memory, or perhaps of the role of memory in human functioning. And we couldn’t be rational in believing those things unless we could rationally rely on memory in forming beliefs. So we can never rationally form any belief on the basis of memory unless we antecedently have reason to trust memory. And that, plus the indirect theory of memory, leads to a vicious regress, and hence to an implausible scepticism.\nThe argument here is similar in form to an argument that has often been levelled against the indirect theory of testimony. This argument traces back at least to Coady (1995). The argument is that children can rely on testimony to get knowledge, and hence rational belief, but they don’t have the information or the cognitive capacity to rationally judge who is and isn’t reliable. So it can’t be, contra the indirect theorist, that such judgments of reliability are required in order to get rational belief and knowledge from testimony.\nOne problem with such an argument in the case of testimony is that it has relied, historically, on a very impoverished view of the cognitive capacities of young children. It is true that the capacity shown for explicit reasoning by children is often very weak. But they have rather amazing capacities for implicit reasoning, and there isn’t any reason to think they could not judge and track reliability of informants.3\n3 On children’s capacities to learn, see Saffran, Aslin, and Newport (1996; Saffran, Newport, and Aslin 1996) and Gopnik et al. (2001). For applications of this directly to the judgments of credibility, see among many others, Koenig, Clément, and Harris (2004) and Harris and Corriveau (2011). Jaswal, McKercher, and VanderBorght (2008) show that children don’t just track credibility of informants, they trade off credibility of informant against credibility of what is currently being said. In general, the lesson from the last 10 to 20 years of research is that children have more than enough capacity to perform the cognitive tasks that indirect theorists require of them.The issue here is not capacity, it is information. No matter how much capacity you have, you can’t make rational judgments about the reliability of memory without information about memory. And you can’t have that information without being able to use memory. That’s the key problem.\nWe can use this idea to strengthen the arguments in the previous section about Sati. If the indirect theory of memory is wrong, we have to be a bit careful about why Hugh can’t know he came by the mountain path. It can’t just be that he lacks a reason to think his memories are reliable. Rather, it must be that what he was told at the bottom of the mountain is a reason to think his memories are not reliable. It must be the presence of reasons to doubt memory, not the absence of reasons to trust, that is doing the work.\nAnd, as noted, this is a big difference between Hugh’s case and Sati’s. Sati does not have any positive reason to doubt her memory. She is several steps removed from the situation where her memories would be in doubt. It’s true that her mnemonic beliefs are insensitive to the truth in a certain way. Arguably, the nearest world in which she came to Shangri La by the sea is one where she still believes she came by the mountains. But any kind of defeasible, direct theory of memory will allow for some rational but insensitive belief.\nAssume that our theory says that S can rationally use her memory to believe that p unless defeaters D are triggered. And S uses her memory to (accurately) remember \\(\\neg D\\). That is, she remembers that she is not in a situation where those defeaters are triggered. Presumably if D were true, her memory would be unreliable; that’s what makes D a defeater. So there isn’t any reason to think that this mnemonic belief in \\(\\neg D\\) is sensitive; she may well still have had it were D true. But the direct theory implies this doesn’t matter, and the direct theory is the only theory on the table given that the indirect theory leads to implausible scepticism.\nCould it be that Sati should not trust her memory because she is, and she knows she is, in a class of people whose memories are unreliable? Well, the mere fact that she is in such a class is not interesting. She knows, after all she is a member of the class consisting of her and all people with unreliable memories, and the memories of that class are as a group unreliable. But that’s not a reason to distrust her memory. Or, at least, it can’t be on pain of scepticism. What must matter is that she is in such a class, and it is epistemologically significant. But the significant class around here seems to be the class of people whose memories have been erased, or who have reason to suspect their memories have been erased. And that doesn’t include Sati. She knows she likes Vegemite, and has for a long time, and she knows that only Marmite-likers in Shangri La had their memories erased.\nHere’s what is true of Sati. She is, right now, phenomenally indistinguishable from a possible person whose memories are unreliable. But why should that matter? We all know brain in vat cases are possible, and each of us is phenomenally indistinguishable from such an unreliable ‘person’. But that isn’t on its own grounds for doubt about memory. All that she learns from the attendant is that another kind of brain in vat case is possible. But she knew they were possible all along. The case isn’t actual and, unless we come up with a trigger for the defeater in the theory of memory, she has no reason to think it is actual."
  },
  {
    "objectID": "posts/mbt/index.html#argumentfromapriority",
    "href": "posts/mbt/index.html#argumentfromapriority",
    "title": "Memory, Belief and Time",
    "section": "6 Argument from A Priority",
    "text": "6 Argument from A Priority\nThere is another argument against the temporally local theories, and against both the direct and indirect theories, that we can derive from the work of Tyler Burge (1993, 1997). (I should note that there is considerable dispute about how best to interpret Burge. I’m not claiming that what follows is the best interpretation, or the only interpretation, just that it is an interesting argument inspired by, and quite arguably contained in, his work.)\nTamati is doing a proof. At one stage in the proof he appeals to Fermat’s Little Theorem, which says for any natural number \\(n\\), and any prime \\(p\\), \\(n^p \\equiv n \\text{ (mod } p)\\). Using this theorem, Tamati completes his proof, and derives a nice result \\(M\\). Intuitively, Tamati has not just come to know \\(M\\), but he has come to know \\(M\\) a priori.\nBut assume, now, that either kind of temporally local theory is true. At one stage of the proof, Tamati had to, at least implicitly, reason as follows. It seems to me that I remember that \\(n^p \\equiv n \\text{ (mod } p)\\), so (perhaps with an extra premise), \\(n^p \\equiv n \\text{ (mod } p)\\). And that can’t be a priori reasoning, since the premise about how things seem to Tamati is contingent and a posteriori. If the indirect theory of memory is right, the extra premise needed about the reliability of Tamati’s memory will also be contingent and a posteriori.\nIt would be a very strange and revisionary theory of the a priori to say that any proof is not a priori if it relies on remembered theorems without, perhaps, memory of the proof of that theorem. The proof of Fermat’s Little Theorem isn’t difficult, but it does go through several steps. It is hard to keep the whole proof in mind at once. Even proving it, that is, requires a little memory. On the temporally local theory, it isn’t clear that it could ever be a priori knowable for any normal person. And any theorem that required using it would similarly be a posteriori.\nPerhaps it could be said that Tamati’s reasoning is a priori because it doesn’t rely on sense perception, only on perception of how things seem to Tamati. But some such perception of how things seem yields a posteriori knowledge. If Tamati has a headache, and notices this at the same time he remembers Fermat’s Little Theorem, he gets a posteriori knowledge of the contingent truth that he has a headache, and a priori knowledge of the necessary truth of the theorem.\nIn short, a transmissive theory of memory is required to get the result that Tamati gets a priori knowledge of the mathematical theorem. As Burge argues, a transmissive theory of testimony gets the exciting result that when Tamati goes on to tell his friend about \\(M\\), the friend gets a priori knowledge of \\(M\\) as well. If one thinks it is intuitive that the friend’s knowledge is a priori, that’s a good reason to favour a transmissive view of testimony. But that the friend’s knowledge is a priori is not as intuitively obvious as that Tamati’s knowledge is a priori, so it isn’t obvious we must treat memory and testimony the same way here.\nI’ll end this section with a note about the dialectic. What would the argument of the paper lose if the arguments of this section didn’t work? This is an important question because of arguments, such as those by Daniele Sgaravatti (2012, Ch. 3), that the a priori/a posteriori distinction can’t do the epistemological work that it is traditionally taken to do. The answer is that we’d lose one of the best arguments against the direct version of the temporally local theory, while the argument against the indirect version would not be significantly affected.\nAssume for now that one is happy with Tamati’s knowledge, and indeed all non-trivial mathematical knowledge, being a posteriori in this way, because it relies on mnemonic knowledge about one’s earlier self. There is still the question of how one gets from this knowledge about one’s earlier self to knowledge of mathematics. On this indirect theory, this goes via reasoning about the reliability of one’s earlier self. But that reasoning will have to use some non-trivial mathematics, and we’ll be back in the kind of circle we warned about in the previous section. On the direct theory, this won’t be a problem, since there isn’t any challenge in getting from I have an apparent memory that p to p. That inference is perfectly sound, as long as one lacks reasons to distrust it. It is still, I think, puzzling that we have to analyse mathematicians as reasoning this way, and generating a posteriori knowledge. But they key dialectical point is that sense of puzzlement is only relevant to thinking about the direct version of the temporally local theory; the indirect version is beset by a host of further and more serious problems."
  },
  {
    "objectID": "posts/mbt/index.html#argumentfromlaundering",
    "href": "posts/mbt/index.html#argumentfromlaundering",
    "title": "Memory, Belief and Time",
    "section": "7 Argument from Laundering",
    "text": "7 Argument from Laundering\nThe arguments involving Sati and Tamati were designed to show that not all rational mnemonic belief relies on inference from the existence of a current mnemonic seeming. But neither argument suggested that there was anything wrong with such inferences. It is fully compatible with what I said about both Sati and Tamati that they could also try to infer from how things seem to them to facts about how they got to Shangri La, or about modular arithmetic.\nBarnett’s argument for a temporally extended view takes the opposite tack. He thinks there is something problematic about these inferences, or at least a special class of them. And because of this, he infers that the inference from present seeming can’t be explanatorily important. And that gets him to a version of a temporally extended theory.\nSo what’s the problem? Here’s the schematic case that he focusses on.\n\n\nTwo Beliefs\n\nOn Monday you came to believe that \\(p\\) for good reasons that justified your belief, and on Tuesday you came to believe that \\(q\\) for bad reasons that failed to justify it (where \\(p\\) and \\(q\\) are independent). It is now Wednesday, and you have forgotten nothing, reconsidered nothing, and learned no new relevant evidence. You recall each conclusion without occurrently recalling your original reasons for those conclusions.  (Barnett 2015, 15)\n\n\n\nAgain, it’s a bit of an annoyance to use ‘you’, especially since you, dear reader, would not do anything so foolhardy as come to believe \\(q\\). So let’s assume Barnett’s narration is directed at Kim. And the question is, is Kim’s belief that \\(q\\), on Wednesday, rational? Assume, to make the case most interesting, that this mistaken inference to \\(q\\) is completely out of character. Kim is, and knows he is, a very reliable processor of information, who rarely makes this kind of mistake.\nThe worry is that any temporally local theory will say that Kim’s belief on Wednesday is rational. After all, Kim has an apparent belief that \\(q\\), and not only lacks evidence of his unreliability, but knows he is reliable. Great! But, intuitively, his belief doesn’t go from being irrational to being rational just by the passage of time. It can’t get its irrationality laundered out in this way.\nBut it isn’t clear how big a problem this really should be. Note that Kim is supposed to have forgotten nothing. So the evidence on which \\(q\\) was based is still there. Now allow the temporally local theory a principle that they should want on independent grounds. That principle is that evidence screens judgment; the evidential force of the fact that an agent made a judgment is completely screened, for that agent, by the evidence the judgment was based on.4 I just stated that principle sychronically, so it doesn’t immediately have implications for Kim’s case. But it is plausible to say that as long as the judgment remains, its evidential force is screened off by the evidence it was based on.\n4 I haven’t actually defended this in print yet, but it is correctly attributed to me by Sophie Horowitz (2014, 25).Now whether one has a direct or indirect theory, Kim is not obviously compelled to hold on to her belief that \\(q\\). And whether or not one believes the screening principle, the fact that Kim has forgotten nothing means that there is no symmetry between the cases of \\(p\\) and \\(q\\). The relevant evidence is different in the two cases. The only theorist who has a challenge here is one who thinks that only occurrent states are evidence, and that is a particularly implausible addition to the indirect theory.\nBarnett’s case is different in a couple of respects than an example Gilbert Harman (1986, Ch. 4) uses to draw rather different conclusions. Working through the differences between them allows us to see something interesting about rational dilemmas, even if it isn’t immediately relevant to the debates about memory.\nIn Harman’s example, Karen first draws a conclusion \\(q\\). This is actually rational for her to draw given her evidence, but her evidence was extremely misleading. She then forgets why she came to believe \\(q\\), and gets new evidence that would show her the old evidence was misleading. But since she doesn’t remember why she believed \\(q\\), she doesn’t know that this new evidence affects her grounds for belief in \\(q\\), and retains the belief.\nHarman says that this is rational. Karen isn’t required to keep track of her evidence for each thing she believes. That seems right. It is hardly a rational failing of mine to not remember precisely why I think that the White Sox won the 2005 World Series; I don’t need to keep that level of detail in mind. And if Karen does not do that, she can’t be expected to adjust her beliefs when the evidence that, unbeknownst to her, they are based on is undermined.\nHarman thinks that our original intuition about Karen’s case is that her belief in \\(q\\) is irrational once it has been undermined. But he also thinks reflection on real life cases like Karen’s shows this intuition to be mistaken. The lesson he draws from this is that something like the direct theory is right; Karen can trust her memories unless she has a special reason to doubt them, even if in fact she couldn’t put together a positive argument for their reliability.\nBarnett’s case of Kim is different than Harman’s case of Karen in two respects. Kim retains his evidence; Karen loses hers. And Kim makes an irrational mistake; Karen is rationally misled by misleading evidence. Are those differences enough to think we should treat the cases differently? Or should we be worried that Karen’s case, like perhaps Kim’s, is one where intuition is not a reliable guide?\nI don’t actually have a firm view on this. The differences are significant. Harman himself thinks that the intuition in Karen’s case is driven by the mistaken assumption that Karen will track and retain her evidence. That’s not true in normal cases like Karen’s. But it is true, by stipulation, in Kim’s. So that is one big reason for treating the cases differently. Still, I do worry a little that we’re drifting into areas where intuition is unreliable.\nTo make that worry a little more concrete, consider this argument for the conclusion that Kim’s belief in \\(q\\) is actually rational.\n\nIt would be irrational for Kim to re-open inquiry into whether \\(q\\), given that it was settled, and no new evidence has come in.\nIt would be irrational or impossible for Kim to intentionally forget \\(q\\).\nKim cannot change his attitude to \\(q\\) without either re-opening inquiry into whether \\(q\\), or by forgetting \\(q\\).\nThere is some rational attitude towards \\(q\\) that Kim can take.\nSo, Kim is rational to retain belief in \\(q\\), since any other possible path would involve irrationality of some kind.\n\nPremises 2 and 3 aren’t, I think, particularly controversial, especially if ‘inquiry’ is read so broadly that any re-evaluation of \\(q\\) counts as re-opening inquiry. The issues are premises 1 and 4. Premise 4 is a no dilemmas principle. We’ll return to it later, though in this context it is notable that Barnett himself endorses it, as do many other epistemologists.  (Barnett 2015, 10)\nThe big issue is premise 1. I think it is true. It is a mistake to go around constantly reconsidering things that one has settled. Once a decision has been reached, it should be held, unless a reason comes along to reconsider it. That reason may be evidence that the decision was faulty, or reason to think the decision was badly made. But the mere passage of time is not a reason to reconsider, and nor is the fact that if inquiry were (properly) conducted, it would yield a different conclusion.\nThe picture I’m putting forward here owes a lot to Richard Holton (1999, 2009, 2014), as well as to a related idea due to Crispin Wright (2004). Holton argues that if one has an intention, rationality requires one to maintain that unless a good reason comes along to reconsider it. The fact that one would not form the intention again were one to reconsider it is not, he thinks, itself a good reason. Strikingly, he says that even in Kavka’s toxin puzzle  (Kavka 1983), the agent who intends to drink the toxin should not reconsider, because they have no reason to do so.  (Holton 2009, 162–65). And he suggests that we should think of belief along similar lines  (Holton 2014). To believe something is to commit to its truth, and we need a positive reason to give up our commitments. Wright argues that the sceptic tries to lure us into opening inquiries we can tell will not be completed. We should resist the lure. We have no reason to open the broad ranging inquiry into our own competencies that the sceptic wants us to hold, and good reason to avoid it.5\n5 Sue Hamilton (2001, 78) says that this idea, that it is wrong to open an inquiry you know you can’t complete, plays a central role in the epistemology of the important Nyāya philosopher Gotama. The discussion of forecasting in Tetlock and Gardner (2015) might cast doubt on whether the kind of conservatism I’m endorsing here is empirically sound. There is a suggestion there that people who tinker with their credal states more frequently end up with more accurate credences. This is a topic that deserves revisiting as more data comes in.We can perhaps motivate the application of these ideas to cases like Kim’s by thinking of a similar case involving action.\n\nNed has been thinking about buying a new bed. He is deciding between a wood bed and a metal bed. And he just decided to get the wood bed. This is a bad mistake. He will like the metal bed much better, and this is in fact clear from the evidence available to Ned. But he’s made up his mind. The wood bed store is five miles east, the metal bed store is five miles west. And there’s Ned in his car, driving eastward. What does rationality require of Ned now?\n\nI think Ned’s in a rational dilemma. It is irrational to drive to the wood bed store and buy a wood bed. He won’t like it, and it is predictable that he won’t. What a mistake. But it is irrational to reopen inquiry. He’s made up his mind, and now he should focus on the road. He hasn’t received any new evidence about the qualities of the bed, or any reason to think he mis-evaluated the old evidence. And we can’t go around second guessing our past decisions all the time. That includes those of us (presumably all of us) who make mistakes. It is irrational to be fickle.\nSo what can Ned rationally do? The arguments of the previous paragraph suggest he’s in a rational dilemma. If you want to act rationally, you shouldn’t start where Ned is. If he keeps driving to the wood bed store, he’ll irrationally buy a sub-optimal bed. If he thinks again about the issue, he’ll be irrationally fickle. Rationality requires something that is practically impossible; changing his mind about what to buy without re-opening the issue of what to buy.\nThis is a dilemma for Ned, but it is one he could have avoided. He could have not made the mistaken decision in the first place. It may or may not be unfair if rationality makes incompatible demands on an agent without any chance to avoid them. But it isn’t unfair to think that agents who make mistakes at \\(t_1\\) are, in virtue of those mistakes, left without any good options at \\(t_2\\). Mistakes have consequences.\nIs this inconsistent with evidentialism? I said above that evidentialism says the rational status of a belief supervenes on the evidence that the agent has. Yet now I’m saying Ned is irrational to change his mind. But if he had, with the very same evidence, believed that he should get the metal bed, that would have been rational. This looks like a counterexample to evidentialism.\nHere’s why it isn’t a counterexample. What is irrational for Ned is re-opening inquiry into what bed to get. It is the activity of engaging in further consideration of the question that it is irrational. Moreover, this is irrational because the evidence that is available to make this decision does not support it. Should Ned irrationally engage in this activity, there is a uniquely rational way to finish it, which is to change his mind. But that’s not the same as saying that he should, rationally, change his mind.\nI am making a big assumption here, but one I think is true. Careful consideration involves thinking through a large amount of evidence. Decisions to engage in careful consideration must be made on the basis of flimsier amounts of evidence. After all, to bring all the evidence one has to bear on a question is to engage in careful consideration. So a decision to engage in such consideration must not use all that evidence. So evidentialism must say that the rationality of a belief, credence, decision etc must depend on, i.e., supervene on, the evidence available to the agent when they make that decision. And when deciding whether to carefully consider or reflect on the evidence, very little is available.\nThat’s why I think Ned isn’t a counterexample to evidentialism. And nor is Kim a counterexample to evidentialism, even if there is no way she can rationally lose her belief in q. For Kim too faces a dilemma, of just the same kind. So the argument I gave for the rationality of Kim’s continuing to believe q goes wrong at step 4. Kim has gotten herself into a mess, and there are no rational ways out.\nBut note that last conclusion cuts across the theories of memory we’ve considered here. The temporally extended theory has, as its distinctive claim, that some agents have a kind of evidence that the temporally local theory says no agent has. But Kim is not one of those agents. The evidence in question is evidence one gets when one acquires a piece of knowledge, and keeps that token mental state across time. And the relevant fact about Kim is that he has a belief in \\(q\\) that is well and truly not a piece of knowledge. So it doesn’t look like the case should tell the local and extended theories apart.\nWhat it does so is show that there is a new kind of argument for the possibility of rational dilemmas. People make mistakes. When they do, there might be no good way to undo the effect of the mistake. And then they’re in a dilemma. We don’t avoid that conclusion by giving people who don’t make mistakes more evidence."
  },
  {
    "objectID": "posts/mbt/index.html#conclusionandfutureresearch",
    "href": "posts/mbt/index.html#conclusionandfutureresearch",
    "title": "Memory, Belief and Time",
    "section": "8 Conclusion and Future Research",
    "text": "8 Conclusion and Future Research\nI’ve argued for a transmissive, temporally extended, view of memory and the evidence it provides. When I remember that the White Sox won in 2005, it is the fact that they won which is my evidence, not my apparent memory. The role of memory is to preserve this fact in evidence, not to give me new evidence for it. Saying this invites any number of questions. I’ll end with a list of several ones that I find fascinating, but which I’m a long way from having answers to, divided up loosely into questions about metaphysics, and questions about epistemology.\n\n8.1 Preservation\nWhat is it for memory to preserve a belief? Sven Bernecker (2008) has written on this at length, and the issue turns out to be much more complicated than we might first suspect. I’m particularly unsure about cases like this one,\n\n\nAnkati.\n\nI haven’t had to change planes at O’Hare for over five years. That makes me happy.\n\nBojan.\n\nAre you sure? What about the trip to Vancouver? Or the one to Hong Kong?\n\nAnkati.\n\nVancouver was a direct flight. And I went to Hong Kong via New York. But, oh, you’re right, I came back via O’Hare. Sad face.\n\n\n\nAt the end Ankati remembers that she flew home from Hong Kong via O’Hare. Is this a belief that was stored in memory ever since it happened? If so, we have to say that Ankati had inconsistent beliefs at the start of the conversation. If not, then I think it is hard to say that the relevant evidence for the belief that saddens her is the fact that she transferred at O’Hare. In such a case, it seems to me that the temporally local theory is more plausible than in more usual cases.\n\n\n8.2 Initial Evidence and Over-Riding\nThe following two questions are related:\n\nWhat past states can constitute present evidence?\nWhat present states can over-ride, or defeat, past evidence?\n\nMy instinct is to defend an extremely restricted answer to this pair of questions. In particular, \\(S\\)’s attitude towards \\(p\\) at \\(t_1\\) can only be evidence for her at \\(t_2\\) if the following conditions obtain.\n\n\\(S\\) knows that \\(p\\) at \\(t_1\\).\n\\(S\\) does not receive a significant amount of evidence against \\(p\\) between \\(t_1\\) and \\(t_2\\).\n\\(S\\) does not receive (undefeated) reasons to distrust her ability to preserve information between \\(t_1\\) and \\(t_2\\).\n\nBut every one of these points is problematic.\nThe first point might imply some counterintuitive things about people who trust misleading evidence, such as ‘Karen’ in the earlier cited example by Gilbert Harman (1986, Ch. 4). Let’s focus on an even simpler case than Harman’s. Unlike me, my doppleganger Nairb believes that the Astros beat the White Sox in the 2005 World Series. That’s because his web browser had been hacked on that crucial October morning, and it reported the wrong results. He hasn’t seen any relevant evidence since. He has forgotten why he thinks the Astros won in 2005, but has held on to the belief. Is this belief rational, and what’s his evidence for it?\nThe evidence can’t be that the Astros won in 2005; they didn’t. And it can’t be that his computer reported that; he’s forgotten that fact. Let’s say that it is his apparent memory that they won, which seems to be the only remaining option. That would mean that the rationality of his forming the belief in the first place is independent of whether his current belief that the Astros won is rational. That’s better than the alternative options, but it isn’t particularly happy either.\nThe second point leads us into the version of the dogmatism puzzle that Maria Lasonen-Aarnio (2014b) has developed. Assume that significant evidence can factor into insignificant parts. Pazu knows that \\(p\\), then gets three pieces of evidence \\(e_1, e_2\\) and \\(e_3\\) that tell against \\(p\\). The conjunction is significant evidence, the individual parts are not. But the parts come in sequentially. When \\(e_1\\) comes in, Pazu still knows \\(p\\); after all, it is insignificant evidence. So Pazu can conclude, i.e., know, that it is misleading evidence. And, intuitively, we can ignore evidence we know to be misleading. So he ignores \\(e_1\\). And for similar reasons he ignores \\(e_2\\). Then \\(e_3\\) comes in. Should he still ignore it? Presumably; it is on its own insignificant, and the only other evidence was known to be misleading, and so ignored. But it is odd that Pazu can hold onto his knowledge in \\(p\\) in the face of these three pieces of evidence, while he would have lost knowledge had they come in at once.\nFinally, we need to explain why evidence of unreliability of mnemonic processes can block mnemonic knowledge. If memory was a source of evidence, rather than a preserver of evidence, that would be an easy problem. In general, a source does not provide evidence to an agent if the agent has reason to believe that it is unreliable. The problem is how to motivate an extension of that principle to memory, which is in general not a source of evidence, but a preserver of it.\nWe could simply insist that the Shangri La case shows that the preservative role of memory can be defeated given sufficient grounds to doubt its accuracy. I think that’s right, we can insist that. But there is a puzzle still about why this should be so. And that puzzle remains work for another day, as do the other puzzles in this section.\n\n\n8.3 Externalism\nFinally, there are some tantalising possibilities for new angles into familiar epistemological debates between internalists and externalists. It is hardly news that this is possible; Goldman’s ‘problem of forgotten evidence’ is a familiar challenge to (certain) internalists  (Goldman 1999). But there might be other ways to make memory relevant to familiar debates.\nIf the temporally extended theory is true, then what is rational depends on something that is, well, extended. And if what is rational depends on something that is extended in time, we might think it is less surprising that is also depends on something that is extended in space. And that suggests the way to a kind of externalism.\nWe can do a bit better than that hand-waving metaphor though. There are versions of the New Evil Demon problem for transmissivism. If transmissivism is true anyway, that means those problems have solutions. Then we just have to find what those solutions are, and see if they generalise to solutions to the spatial version of the New Evil Demon problem. And if they do, we might have new ways to defend externalist theories of rationality, or at least new motivations for familiar ways to defend those theories."
  },
  {
    "objectID": "posts/review-sameness/index.html",
    "href": "posts/review-sameness/index.html",
    "title": "Review of “Sameness and Substance Renewed”",
    "section": "",
    "text": "Sameness and Substance Renewed (hereafter, 2001) is, in effect, a second edition of Wiggins’s 1980 book Sameness and Substance (hereafter, 1980), which in turn expanded and corrected some ideas in his 1967 Identity and Spatio-Temporal Continuity (hereafter, 1967). All three books have similar aims. The first is to argue, primarily against Geach, that identity is absolute not relative. The second is to argue that, despite this, whenever an identity claim a = b is true, there is a sortal f such that a is the same f as b. The biggest difference between 1967 and the two later books is that the later books contain much more detail on what a sortal must be if this claim, called D, is to be both correct and philosophically interesting. The third aim is to apply the first two conclusions to the topic of personal identity.\n\nThis review first published in Notre Dame Philosophical Reviews.\n\nFor the bulk of 2001, most of the changes to 1980 are confined to footnotes, the bulk of these consisting of a citation of, and occasionally a brief comment upon, a post 1980 publication that bears on Wiggins’s approach to the topic. This changes in the last two chapters. The penultimate chapter is a mostly new discussion of the determinacy of identity. In the final chapter, on personal identity, Wiggins retracts many of the claims made in the matching chapter of 1980, and raises some interesting objections to Parfit’s account of personal identity. Apart from those, the major changes to 1980 are stylistic. No longer is the material considered more peripheral printed in smaller type, though to make up for this there are frequent exhortations to skip these sections. And the longer notes of the 1980 edition are now mostly incorporated into the text, several prefixed with advice that they not be read.\nIn the preface Wiggins says that it is a matter of no concern whether 1980 and 2001 are the same book. But it is of concern to me, twice over. First, it makes a large difference to what kind of review should be written whether this is an old book reissued or a new book. Secondly, the difficulty in answering this question draws out some problems Wiggins’s theory faces when we try to apply it outside the realms of physics and biology. On the first problem, the reader who hopes here to find a comprehensive discussion of the literature on identity post-1980 as it strikes David Wiggins will be disappointed. Three examples should help to illustrate this.\nIn 1967 Wiggins held, quite sensibly, that a statue is not identical to the bronze that it is made of, but rather is constituted by that bronze. This was an important move in his response to Geach. If identity is absolute, and the statue is identical with the bronze, then we can’t say that when the statue is remoulded into a vase, we have the same lump of bronze but a different artwork. In 2001 he says much the same thing. This still seems like good common sense, but the problem is that in the intervening 34 years there has been a mass of work on constitution, most of it concluding that the constitution relation is much more problematic than we had originally thought. In a genuinely new work, or even perhaps in a revised old work, this material should have been addressed.\nIn 1980 Wiggins makes it quite clear he dislikes perdurantist theories of persistence that hold that an object persists from t­1 to t2 by having instantaneous temporal parts at every time in [t1, t2]. Just why he dislikes perdurantism is unclear, since all his arguments are directed against the conjunction of this view with the striking, and not especially popular, view that our ordinary names refer to these instantaneous objects. In 2001 it is still clear he dislikes perdurantism. But we find little on the barrage of arguments perdurantists have offered in the last 21 years in support of their position. All we find is a footnote expressing agreement with Mark Johnston’s response to Lewis’s ‘problem of temporary intrinsics’ argument, and a citation of a paper expanding upon said agreement. Given that this book largely reprints previously available material, including more detail here would not have been absurd, and saying something about other arguments quite appropriate.\nThe third example is a little more serious. In the book’s new chapter, he outlines approvingly Evans’s proof that identity is always determinate identity, and cites (without outlining) a proof by Williamson that distinctness is always determinate. From these proofs he quite naturally concludes that the prospects for indeterminate identities are pretty grim. But he doesn’t engage with those who maintain that, despite all this, there really are indeterminate identities. It would have been worthwhile, for instance, to see a more direct engagement between his views and those of, say, Terrence Parsons, who over the last 15 years has developed a rather detailed theory on which indeterminate identity is possible. It will probably turn out that Wiggins’s position is entirely correct, and Parsons’s position basically mistaken, but that’s no reason to not take Parsons more seriously.\nApart from this oversight, there is one rather odd feature in the discussion of determinacy. Wiggins says that “it can be perfectly determinate which mountain x is without x’s extent being determinate.” (166) The idea is that it can be determinate that x is, say, this mountain, while it is indeterminate whether, say, that foothill is part of x. Such a position always feels strained to me, but it is certainly not unfamiliar. But it is very hard to see how it is meant to fit in with Wiggins’s picture of the role of sortal concepts, such as mountain. On page 70 he says a sortal concept is such that grasp of it determines “what changes x tolerates without there ceasing to exist such a thing as x.” (He actually says ‘substance-concept’, not ‘sortal concept’ there, but these phrases seem to be used synonymously.) The trouble should be apparent. For it to be determinate what x is, presumably just is for it to be determinate that x is this mountain. That is, it is determinate that x falls under the sortal mountain, and that sortal must determine persistence conditions, else it fails to be a sortal. But that means x’s persistence conditions are determined. So there is a determinate fact, perhaps unknown and perhaps even unknowable, about how far in the future one can go without leaving x behind. (I assume here that if x’s temporal extent is determined by which sortal it falls under, then x’s temporal extent is determinate. I imagine some will deny this claim, but it looks like a platitude to me.) On the other hand, it seems that it can be determinate what x is even though the conditions of x’s spatial persistence, conditions that determine how far westward one can go without leaving x behind, are not determinate. Just how this asymmetry is to be tolerated is not explained.\nMuch of the interest in this edition will focus on the new material on personal identity, and I shall say more about this below. But it is worth going over the central claims of the earlier part of the book. The crucial principle is called D(ii). The derivation of it appeals crucially to D(i). (Both definitions, and the commentary, from page 64.)\nD(i) (x)(t) [(x exists at t) → (∃g) (g(x) at t)].\nD(ii) (x)(∃g)(t) [(x exists at t) → (g(x) at t)].\n‘x’ ranges over three-dimensional continuants, ‘t’ over times and ‘g’ over sortals. The argument for D(i) is that for any object at any time there is an answer to the Aristotelian question What is it? This answer is a sortal so, as just noted, it must determine principles of persistence. It must also determine “a prnciple of activity, a principle of functioning or a principle of operation”. (72) If the last claim looks disjunctive, that’s because it is. Sortals for living objects determine principles of activity, sortals for artifacts determine principles of functioning. Just what philosophically interesting features these principles share is never satisfactorily explained. So there’s a suspicion that there is no decent concept of sortal that covers the kinds of things living creatures are and the kinds of things artifacts are. In slogan form sortal isn’t a sortal. Two other considerations reinforce that suspicion.\nFirst, there are objects that don’t naturally fall under any known sortal. Just looking at the computer I’m now using, there is the latch that holds the lid down when it’s closed, the button that opens the CD tray, the brightness control, and the stick that plays some (but not all) the functional roles of a mouse. It’s far from obvious that any of these falls under a sortal, at least if a sortal must determine persistence conditions and a principle of functioning.\nSecondly, there’s a tension between the kinds of sortals Wiggins thinks appropriate for artifacts and what he says about persistence. Artifact sortals are, he says, functional kinds. These sortals are meant to determine persistence conditions. Whether an object has persisted is not meant to depend on extrinsic, or external, factors. This is the upshot of his Only a and b rule (96), which is important in ruling out ‘best deserver’ theories of persistence. That rule says that we don’t need to consider objects other than a or b to determine whether a is b. So whether a, the boy genius is b, the Nobel Prize winning author, cannot depend on the existence or otherwise of a person more closely continuous with a than b happens to be. Hence Nozick’s theory of personal identity, which rejects this, cannot be true. But to determine whether a´, the brightness control on my computer at t1 is b´, the volume control on Jack’s computer at t2, we need to see which sortals a´ and b´ fall under, to see whether a´ has persisted. That will depend, in part, on whether a´ still falls under that sortal, whatever it is. Such a sortal will sort by functional role, and whether that functional role is fulfilled at all times between t1 and t2 will be determined by things other than a´ and b´. The point generalises: in most cases whether an object continues to fill a functional role often turns on the existence, and behaviour, of other objects. The natural conclusion to be drawn here is that D(i) might be false for artifacts.\nClearly D(i) doesn’t entail D(ii). But, bracketing our concerns about its truth, it might still be usable in an abductive argument for D(ii). Wiggins does just this. The argument, and this is I think the only argument for D(ii), is that it best explains our widespread agreement over whether an object has survived. Wiggins says that, “Our capacity for massive agreement about this is much more remarkable than our occasional disagreement,” (66) and given D(i), D(ii) is the best explanation of this. Two replies. First, the agreement is not all that widespread, even in actual cases. Think, for example, about the range of disagreement over whether a corpse is a thing that once lived, and hence the disagreement over whether Auntie is buried behind the back shed, or Auntie no longer exists. Secondly, there is a better explanation – the perdurantist explanation given by Lewis. This not only explains why there is agreement just where there is agreement, but why there is disagreement where there is disagreement. The story is familiar. All sorts of continuants (fusions of temporal parts) exist, but we choose which ones to refer to and quantify over because of our particular interests, and those choices are codified in our linguistic practices. When dealing with historically familiar situations, membership of linguistic, and more broadly cultural, communities commits us to common answers. Since most situations are historically familiar, we have agreement in most cases. When we deal with new cases, either generated by new technology or new imaginativeness, and our interests do not pick out a clearly preferable continuant, we do not have agreement. If this is right, we will agree about the familiar and disagree about the unfamiliar. Happily, this is exactly what we find – we all know what the persistence conditions for cows, pigs and chicken are, we do not know the persistence conditions for corporate entities or pieces of software or even relocated football teams in perfectly everyday cases.\nIn 1980, the chapter on personal identity had two main aims. The first was to argue that Lockean considerations about continuity of memory could be used in an account of personal identity, even if they would have to be used as reference fixers rather than as constituents of a reductive analysis. The opponents here were those followers of Bishop Butler, most prominently Anthony Flew, who held that any such consideration would be hopelessly circular. The second aim was to argue that it is a conceptual truth that persons are animals. The targets here were (unnamed) philosophers who wanted to provide a complete functional analysis of a person. The objections were mainly political but since it is unclear whether the philosophy of personal identity should be part of metaphysics or ethics, that’s perfectly acceptable.\nIn 2001, the aims have changed. Wiggins retracts everything he said against Butler and Flew, and then spends most of the chapter in a lengthy discussion of Parfit’s theory of personal identity. Butler’s original complaint against Locke was that the concept of memory needs a pre-existing concept of personal identity to be applied so it cannot be used in a non-circular account of identity. In the bluntest version of this complaint, it is held that ‘A remembers X-ing’ is properly represented as ‘A remembers A X-ing’, which requires an identity between the referents of the two occurences of ‘A’. Wiggins’s complaint, in 1980, was that this position costs us some vital distinctions. We want to distinguish, for example, ‘A imagines being an elephant’ from ‘A imagines A being an elephant’. In the first case only, A imagines something possible. And what holds for imagining, he thought, holds for remembering. Wiggins now rejects the last step here. Remembering, unlike imagining, has a tie to the truth. A can only remember X-ing if A in fact X-ed. This last claim might not be part of the logical form of ‘A remembers X-ing’, but there is a close relation between the two. Wiggins calls the relationship presupposition, but the name here doesn’t matter much. So Butler, and Flew, were right – appeals to memory in a theory of personal identity are hopelessly circular, because they presuppose that debates about identity through time are resolved.\nThe rest of the chapter outlines concerns with Parfit’s theory of personal identity, based on his concept of quasi-memory, and with the intuitions behind some cases that support Parfit’s theory. Quasi-memory, unlike memory, need not be factive, but what is quasi-remembered must have happened somewhere, to someone. Wiggins launches a barrage of attacks on this idea, of which the following three seem most telling. First, quasi-memory could not be defined (and is not defined) as memory minus factiveness, because conceptual subtraction is undefined in the absence of conceptual analysis, and we don’t have a conceptual analysis here. Secondly, the concept of quasi-memory may seem to make sense for quite general, de dicto memories, but it runs into trouble with de re, or even with more specific memories. If I am to quasi-remember climbing Big Ben on my sixteenth birthday, must someone have climbed Big Ben on my sixteenth birthday? Or perhaps on their sixteenth birthday? Thirdly, even if Parfit can define the concept of accurate quasi-memory, that won’t get us the general concept of quasi-memory, because again conceptual subtraction doesn’t make sense.\nThere are some good points here for followers of Parfit to consider. They are followed by some interesting considerations about why we might rethink our intuitions about personal identity in cases involving brain swaps. Those interested in personal identity debates, and particularly Wiggins’s and Parfit’s contributions, should pay close attention here. These will not be the only people to whom this new volume has interest. Sameness and Substance was an important statement of a rather commonsensical solution to some of the hardest questions in metaphysics, a solution with which everyone working in the field should be well acquainted. And those who have not previously read it closely will find that the stylistic changes (having a uniform font size, incorporating the longer notes into the text) make the renewed version of Sameness and Substance much more accessible than the original."
  },
  {
    "objectID": "posts/cwpwpe/index.html",
    "href": "posts/cwpwpe/index.html",
    "title": "Can We Do Without Pragmatic Encroachment?",
    "section": "",
    "text": "0.1 Introduction\nRecently several authors have defended claims suggesting that there is a closer connection between practical interests and epistemic justification than has traditionally been countenanced. Jeremy Fantl and Matthew McGrath (2002) argue that there is a “pragmatic necessary condition on epistemic justification” (77), namely the following.\n\nPublished in Philosophical Perspectives 19: 417-43.\n\n\n(PC)\n\nS is justified in believing that p only if S is rational to prefer as if p. (77)\n\n\nAnd John Hawthorne (2004) and Jason Stanley (2005) have argued that what it takes to turn true belief into knowledge is sensitive to the practical environment the subject is in. These authors seem to be suggesting there is, to use Jonathan Kvanvig’s phrase “pragmatic encroachment” in epistemology. In this paper I’ll argue that their arguments do not quite show this is true, and that concepts of epistemological justification need not be pragmatically sensitive. The aim here isn’t to show that (PC) is false, but rather that it shouldn’t be described as a pragmatic condition on justification. Rather, it is best thought of as a pragmatic condition on belief. There are two ways to spell out the view I’m taking here. These are both massive simplifications, but they are close enough to the truth to show the kind of picture I’m aiming for.\n\nThanks to Michael Almeida, Tamar Szabó Gendler, Peter Gerdes, Jon Kvanvig, Barry Lam, Ishani Maitra, Robert Stalnaker, Jason Stanley, Matthew Weiner for helpful discussions, and especially to Matthew McGrath for correcting many mistakes in an earlier draft of this paper.\n\nFirst, imagine a philosopher who holds a very simplified version of functionalism about belief, call it (B).\n\n(B)\n\nS believes that p iff S prefers as if p\n\n\nOur philosopher one day starts thinking about justification, and decides that we can get a principle out of (B) by adding normative operators to both sides, inferring (JB).\n\n(JB)\n\nS is justified in believing that p only if S is justified to prefer as if p\n\n\nNow it would be a mistake to treat (JB) as a pragmatic condition on justification (rather than belief) if it was derived from (B) by this simple means. And if our philosopher goes on to infer (PC) from (JB), by replacing ‘justified’ with ‘rational’, and inferring the conditional from the biconditional, we still don’t get a pragmatic condition on justification.\nSecond, Fantl and McGrath focus their efforts on attacking the following principle.\n\nEvidentialism\n\nFor any two subjects S and S\\(^\\prime\\), necessarily, if S and S\\(^\\prime\\) have the same evidence for/against p, then S is justified in believing that p iff S\\(^\\prime\\) is, too.\n\n\nI agree, evidentialism is false. And I agree that there are counterexamples to evidentialism from subjects who are in different practical situations. What I don’t agree is that we learn much about the role of pragmatic factors in epistemology properly defined from these counterexamples to evidentialism. Evidentialism follows from the following three principles.\n\nProbabilistic Evidentialism\n\nFor any two subjects S and S\\(^\\prime\\), and any degree of belief \\(\\alpha\\) necessarily, if S and S\\(^\\prime\\) have the same evidence for/against p, then S is justified in believing that p to degree \\(\\alpha\\) iff S\\(^\\prime\\) is, too.\n\nThreshold View\n\nFor any two subjects S and S\\(^\\prime\\), and any degree of belief \\(\\alpha\\), if S and S\\(^\\prime\\) both believe p to degree \\(\\alpha\\), then S believes that p iff S\\(^\\prime\\) does too.\n\nProbabilistic Justification\n\nFor any \\(S, S\\) is justified in believing p iff there is some degree of belief \\(\\alpha\\) such that S is justified in believing p to degree \\(\\alpha\\), and in S’s situation, believing p to degree \\(\\alpha\\) suffices for believing p.\n\n\n(Degrees of belief here are meant to be the subjective correlates of Keynesian probabilities. See Keynes (1921) for more details. They need not, and usually will not, be numerical values. The Threshold View is so-called because given some other plausible premises it implies that \\(S\\) believes that p iff S’s degree of belief in p is above a threshold.)\nI endorse Probabilistic Justification, and for present purposes at least I endorse Probabilistic Evidentialism. The reason I think Evidentialism fails is because the Threshold View is false. It is plausible that Probabilistic Justification and Probabilistic Evidentialism are epistemological principles, while the Threshold View is a principle from philosophy of mind. So this matches up with the earlier contention that the failure of Evidentialism tells us something interesting about the role of pragmatics in philosophy of mind, rather than something about the role of pragmatics in epistemology.\nAs noted, Hawthorne and Stanley are both more interested in knowledge than justification. So my discussion of their views will inevitably be somewhat distorting. I think what I say about justification here should carry over to a theory of knowledge, but space prevents a serious examination of that question. The primary bit of ‘translation’ I have to do to make their works relevant to a discussion of justification is to interpret their defences of the principle (KP) below as implying some support for (JP), which is obviously similar to (PC).\n\n(KP)\n\nIf S knows that p, then S is justified in using p as a premise in practical reasoning.\n\n(JP)\n\nIf S justifiably believes that p, then S is justified in using p as a premise in practical reasoning.\n\n\nI think (JP) is just as plausible as (KP). In any case it is independently plausible whether or not Hawthorne and Stanley are committed to it. So I’ll credit recognition of (JP)’s importance to a theory of justification to them, and hope that in doing so I’m not irrepairably damaging the public record.\nThe overall plan here is to use some philosophy of mind, specifically functionalist analyses of belief to respond to some arguments in epistemology. But, as you can see from the role the Threshold View plays in the above argument, our starting point will be the question what is the relation between the credences decision theory deals with, and our traditional notion of a belief? I’ll offer an analysis of this relation that supports my above claim that we should work with a pragmatic notion of belief rather than a pragmatic notion of justification. The analysis I offer has a hole in it concerning propositions that are not relevant to our current plans, and I’ll fix the hold in section 3. Sections 4 and 5 concern the role that closure principles play in my theory, in particular the relationship between having probabilistically coherent degrees of belief and logically coherent beliefs. In this context, a closure principle is a principle that says probabilistic coherence implies logical coherence, at least in a certain domain. (It’s called a closure principle because we usually discuss it by working out properties of probabilistically coherent agents, and show that their beliefs are closed under entailment in the relevant domain.) In section 4 I’ll defend the theory against the objection, most commonly heard from those wielding the preface paradox, that we need not endorse as strong a closure principle as I do. In section 5 I’ll defend the theory against those who would endorse an even stronger closure principle than is defended here. Once we’ve got a handle on the relationship between degrees of belief and belief tout court, we’ll use that to examine the arguments for pragmatic encroachment. In section 6 I’ll argue that we can explain the intuitions behind the cases that seem to support pragmatic encroachment, while actually keeping all of the pragmatic factors in our theory of belief. In section 7 I’ll discuss how to endorse principles like (PC) and (JP) (as far as they can be endorsed) while keeping a non-pragmatic theory of probabilistic justification. The interesting cases here are ones where agents have mistaken and/or irrational beliefs about their practical environment, and intuitions in those cases are cloudy. But it seems the most natural path in these cases is to keep a pragmatically sensitive notion of belief, and a pragmatically insensitive notion of justification.\n\n\n0.2 Belief and Degree of Belief\nTraditional epistemology deals with beliefs and their justification. Bayesian epistemology deals with degrees of belief and their justification. In some sense they are both talking about the same thing, namely epistemic justification. Two questions naturally arise. Do we really have two subject matters here (degrees of belief and belief tout court) or two descriptions of the one subject matter? If just one subject matter, what relationship is there between the two modes of description of this subject matter?\nThe answer to the first question is I think rather easy. There is no evidence to believe that the mind contains two representational systems, one to represent things as being probable or improbable and the other to represent things as being true or false. The mind probably does contain a vast plurality of representational systems, but they don’t divide up the doxastic duties this way. If there are distinct visual and auditory representational systems, they don’t divide up duties between degrees of belief and belief tout court, for example. If there were two distinct systems, then we should imagine that they could vary independently, at least as much as is allowed by constitutive rationality. But such variation is hard to fathom. So I’ll infer that the one representational system accounts for our credences and our categorical beliefs. (It follows from this that the question Bovens and Hawthorne (1999) ask, namely what beliefs should an agent have given her degrees of belief, doesn’t have a non-trivial answer. If fixing the degrees of belief in an environment fixes all her doxastic attitudes, as I think it does, then there is no further question of what she should believe given these are her degrees of belief.)\nThe second question is much harder. It is tempting to say that \\(S\\) believes that p iff S’s credence in p is greater than some salient number \\(r\\), where \\(r\\) is made salient either by the context of belief ascription, or the context that S is in. I’m following Mark Kaplan (1996) in calling this the threshold view. There are two well-known problems with the threshold view, both of which seem fatal to me.\nAs Robert Stalnaker (1984, 91) emphasised, any number \\(r\\) is bound to seem arbitrary. Unless these numbers are made salient by the environment, there is no special difference between believing p to degree 0.9786 and believing it to degree 0.9875. But if \\(r\\) is 0.98755, this will be the difference between believing p and not believing it, which is an important difference. The usual response to this, as found in (Foley 1993 Ch. 4) and Hunter (1996) is to say that the boundary is vague. But it’s not clear how this helps. On an epistemic theory of vagueness, there is still a number such that degrees of belief above that count, and degrees below that do not, and any such number is bound to seem unimportant. On supervaluational theories, the same is true. There won’t be a determinate number, to be sure, but there will a number, and that seems false. My preferred degree of belief theory of vagueness, as set out in Weatherson (2005) has the same consequence. Hunter defends a version of the threshold view combined with a theory of vagueness based around fuzzy logic, which seems to be the only theory that could avoid the arbitrariness objection. But as Williamson (1994) showed, there are deep and probably insurmountable difficulties with that position. So I think the vagueness response to the arbitrariness objection is (a) the only prima facie plausible response and (b) unsuccessful.\nThe second problem concerns conjunction. It is also set out clearly by Stalnaker.\n\nReasoning in this way from accepted premises to their deductive consequences (\\(P\\), also \\(Q\\), therefore \\(R\\)) does seem perfectly straightforward. Someone may object to one of the premises, or to the validity of the argument, but one could not intelligibly agree that the premises are each acceptable and the argument valid, while objecting to the acceptability of the conclusion. (Stalnaker 1984, 92)\n\nIf categorical belief is having a credence above the threshold, then one can coherently do exactly this. Let \\(x\\) be a number between \\(r\\) and than \\(r\\) \\(\\nicefrac{1}{2}\\), such that for an atom of type U has probability \\(x\\) of decaying within a time \\(t\\), for some \\(t\\) and U. Assume our agent knows this fact, and is faced with two (isolated) atoms of U. Let p be that the first decays within \\(t\\), and \\(q\\) be that the second decays within \\(t\\). She should, given her evidence, believe p to degree \\(x, q\\) to degree \\(x\\), and \\(p \\wedge q\\) to degree \\(x ^2\\). If she believed \\(p \\wedge q\\) to a degree greater than \\(r\\), she’d have to either have credences that were not supported by her evidence, or credences that were incoherent. (Or, most likely, both.) So this theory violates the platitude. This is a well-known argument, so there are many responses to it, most of them involving something like appeal to the preface paradox. I’ll argue in section 4 that the preface paradox doesn’t in fact offer the threshold view proponent much support here. But even before we get to there, we should note that the arbitrariness objection gives us sufficient reason to reject the threshold view.\nA better move is to start with the functionalist idea that to believe that p is to treat p as true for the purposes of practical reasoning. To believe p is to have preferences that make sense, by your own lights, in a world where p is true. So, if you prefer A to B and believe that p, you prefer A to B given p. For reasons that will become apparent below, we’ll work in this paper with a notion of preference where conditional preferences are primary.1 So the core insight we’ll work with is the following:\n1 To say the agent prefers A to B given \\(q\\) is not to say that if the agent were to learn \\(q\\), she would prefer A to B. It’s rather to say that she prefers the state of the world where she does A and \\(q\\) is true to the state of the world where she does B and \\(q\\) is true. These two will come apart in cases where learning \\(q\\) changes the agent’s preferences. We’ll return to this issue below.\nIf you prefer A to B given \\(q\\), and you believe that p, then you prefer A to B given \\(p \\wedge q\\)\n\nThe bold suggestion here is that if that is true for all the A, B and q that matter, then you believe p. Put formally, where Bel(p) means that the agent believes that p, and A \\(\\geq _q\\) B means that the agent thinks A is at least as good as B given \\(q\\), we have the following\n\nBel(p) \\(\\leftrightarrow \\forall\\)A\\(\\forall\\)B\\(\\forall q\\) (A \\(\\geq _q\\) B \\(\\leftrightarrow\\) A \\(\\geq _{p \\wedge q}\\) B)\n\nIn words, an agent believes that p iff conditionalising on p doesn’t change any conditional preferences over things that matter.2 The left-to-right direction of this seems trivial, and the right-to-left direction seems to be a plausible way to operationalise the functionalist insight that belief is a functional state. There is some work to be done if (1) is to be interpreted as a truth though.\n2 This might seem much too simple, especially when compared to all the bells and whistles that functionalists usually put in their theories to (further) distinguish themselves from crude versions of behaviourism. The reason we don’t need to include those complications here is that they will all be included in the analysis of preference. Indeed, the theory here is compatible with a thoroughly anti-functionalist treatment of preference. The claim is not that we can offer a functional analysis of belief in terms of non-mental concepts, just that we can offer a functionalist reduction of belief to other mental concepts. The threshold view is also such a reduction, but it is such a crude reduction that it doesn’t obviously fall into any category.If we interpret the quantifiers in (1) as unrestricted, then we get the (false) conclusion that just about no one believes no contingent propositions. To prove this, consider a bet that wins iff the statue in front of me waves back at me due to random quantum effects when I wave at it. If I take the bet and win, I get to live forever in paradise. If I take the bet and lose, I lose a penny. Letting A be that I take the bet, B be that I decline the bet, \\(q\\) be a known tautology (so my preferences given \\(q\\) are my preferences tout court) and p be that the statue does not wave back, we have that I prefer A to B, but not A to B given p. So by this standard I don’t believe that p. This is false – right now I believe that statues won’t wave back at me when I wave at them.\nThis seems like a problem. But the solution to it is not to give up on functionalism, but to insist on its pragmatic foundations. The quantifiers in (1) should be restricted, with the restrictions motivated pragmatically. What is crucial to the theory is to say what the restrictions on A and B are, and what the restrictions on \\(q\\) are. We’ll deal with these in order.\nFor better or worse, I don’t right now have the option taking that bet and hence spending eternity in paradise if the statue waves back at me. Taking or declining such unavailable bets are not open choices. For any option that is open to me, assuming that statues do not in fact wave does not change its utility. That’s to say, I’ve already factored in the non-waving behaviour of statues into my decision-making calculus. That’s to say, I believe statues don’t wave.\nAn action A is a live option for the agent if it is really possible for the agent to perform A. An action A is a salient option if it is an option the agent takes seriously in deliberation. Most of the time gambling large sums of money on internet gambling sites over my phone is a live option, but not a salient option. I know this option is suboptimal, and I don’t have to recompute every time whether I should do it. Whenever I’m making a decision, I don’t have to add in to the list of choices bet thousands of dollars on internet gambling sites, and then rerule that out every time. I just don’t consider that option, and properly so. If I have a propensity to daydream, then becoming the centrefielder for the Boston Red Sox might be a salient option to me, but it certainly isn’t a live option. We’ll say the two initial quantifiers range over the options that are live and salient options for the agent.\nNote that we don’t say that the quantifiers range over the options that are live and salient for the person making the belief ascription. That would lead us to a form of contextualism for which we have little evidence. We also don’t say that an option becomes salient for the agent iff they should be considering it. At this stage we are just saying what the agent does believe, not what they should believe, so we don’t have any clauses involving normative concepts.\nNow we’ll look at the restrictions on the quantifier over propositions. Say a proposition is relevant if the agent is disposed to take seriously the question of whether it is true (whether or not she is currently considering that question) and conditionalising on that proposition or its negation changes some of the agents unconditional preferences over live, salient options.3 The first clause is designed to rule out wild hypotheses that the agent does not take at all seriously. If \\(q\\) is not such a proposition, if the agent is disposed to take it seriously, then it is relevant if there are live, salient A and B such that A \\(\\geq _q\\) B \\(\\leftrightarrow\\) A \\(\\geq\\) B is false. Say a proposition is salient if the agent is currently considering whether it is true. Finally, say a proposition is active relative to p iff it is a (possibly degenerate) conjunction of propositions such that each conjunct is either relevant or salient, and such that the conjunction is consistent with p. (By a degenerate conjunction I mean a conjunction with just one conjunct. The consistency requirement is there because it might be hard in some cases to make sense of preferences given inconsistencies.) Then the propositional quantifier in (1) ranges over active propositions.\n3 Conditionalising on the proposition There are space aliens about to come down and kill all the people writing epistemology papers will make me prefer to stop writing this paper, and perhaps grab some old metaphysics papers I could be working on. So that proposition satisfies the second clause of the definition of relevance. But it clearly doesn’t satisfy the first clause. This part of the definition of relevance won’t do much work until the discussion of agents with mistaken environmental beliefs in section 7.We will expand and clarify this in the next section, but our current solution to the relationship between beliefs and degrees of belief is that degrees of belief determine an agent’s preferences, and she believes that p iff the claim (1) about her preferences is true when the quantifiers over options are restricted to live, salient actions, and the quantifier over propositions is restricted to salient propositions. The simple view would be to say that the agent believes that p iff conditioning on p changes none of her preferences. The more complicated view here is that the agent believes that p iff conditioning on p changes none of her conditional preferences over live, salient options, where the conditions are also active relative to p.\n\n\n0.3 Impractical Propositions\nThe theory sketched in the previous paragraph seems to me right in the vast majority of cases. It fits in well with a broadly functionalist view of the mind, and as we’ll see it handles some otherwise difficult cases with aplomb. But it needs to be supplemented a little to handle beliefs about propositions that are practically irrelevant. I’ll illustrate the problem, then note how I prefer to solve it.\nI don’t know what Julius Caeser had for breakfast the morning he crossed the Rubicon. But I think he would have had some breakfast. It is hard to be a good general without a good morning meal after all. Let p be the proposition that he had breakfast that morning. I believe p. But this makes remarkably little difference to my practical choices in most situations. True, I wouldn’t have written this paragraph as I did without this belief, but it is rare that I have to write about Caeser’s dietary habits. In general whether p is true makes no practical difference to me. This makes it hard to give a pragmatic account of whether I believe that p. Let’s apply (1) to see whether I really believe that p.\n\nBel(p) \\(\\leftrightarrow \\forall\\)A\\(\\forall\\)B\\(\\forall q\\) (A \\(\\geq _q\\) B \\(\\leftrightarrow\\) A \\(\\geq _{p \\wedge q}\\) B)\n\nSince p makes no practical difference to any choice I have to make, the right hand side is true. So the left hand side is true, as desired. The problem is that the right hand side of (2) is also true here.\n\nBel(\\(\\neg p\\)) \\(\\leftrightarrow \\forall\\)A\\(\\forall\\)B\\(\\forall q\\) (A \\(\\geq _q\\) B \\(\\leftrightarrow\\) A \\(\\geq _{\\neg p \\wedge q}\\) B)\n\nAdding the assumption that Caeser had no breakfast that morning doesn’t change any of my practical choices either. So I now seem to inconsistently believe both p and \\(\\neg p\\). I have some inconsistent beliefs, I’m sure, but those aren’t among them. We need to clarify what (1) claims.\nTo do so, I supplement the theory sketched in section 2 with the following principles.\n\nA proposition p is eligible for belief if it satisfies \\(\\forall\\)A\\(\\forall\\)B\\(\\forall q\\) (A \\(\\geq _q\\) B \\(\\leftrightarrow\\) A \\(\\geq _{p \\wedge q}\\) B), where the first two quantifiers range over the open, salient actions in the sense described in section 2.\nFor any proposition p, and any proposition \\(q\\) that is relevant or salient, among the actions that are (by stipulation!) open and salient with respect to p are believing that p, believing that q, not believing that p and not believing that q\nFor any proposition, the subject prefers believing it to not believing it iff (a) it is eligible for belief and (b) the agents degree of belief in the proposition is greater than \\(\\nicefrac{1}{2}\\).\nThe previous stipulation holds both unconditionally and conditional on p, for any p.\nThe agent believes that p iff \\(\\forall\\)A\\(\\forall\\)B\\(\\forall q\\) (A \\(\\geq _q\\) B \\(\\leftrightarrow\\) A \\(\\geq _{p \\wedge q}\\) B), where the first two quantifiers range over all actions that are either open and salient tout court (i.e. in the sense of section 2) or open and salient with respect to p (as described above).\n\nThis all looks moderately complicated, but I’ll explain how it works in some detail as we go along. One simple consequence is that an agent only believes that p iff their degree of belief in p is greater than \\(\\nicefrac{1}{2}\\). Since my degree of belief in Caeser’s foodless morning is not greater than \\(\\nicefrac{1}{2}\\), in fact it is considerably less, I don’t believe \\(\\neg p\\). On the other hand, since my degree of belief in p is considerably greater than \\(\\nicefrac{1}{2}\\), I prefer to believe it than disbelieve it, so I believe it.\nThere are many possible objections to this position, which I’ll address sequentially.\nObjection: Even if I have a high degree of belief in p, I might prefer to not believe p because I think that belief in p is bad for some other reason. Perhaps, if p is a proposition about my brilliance, it might be immodest to believe that p.\nReply: Any of these kinds of considerations should be put into the credences. If it is immodest to believe that you are a great philosopher, it is equally immodest to believe to a high degree that you are a great philosopher.\nObjection: Belief that p is not an action in the ordinary sense of the term.\nReply: True, which is why this is described as a supplement to the original theory, rather than just cashing out its consequences.\nObjection: It is impossible to choose to believe or not believe something, so we shouldn’t be applying these kinds of criteria.\nReply: I’m not as convinced of the impossibility of belief by choice as others are, but I won’t push that for present purposes. Let’s grant that beliefs are always involuntary. So these ‘actions’ aren’t open actions in any interesting sense, and the theory is section 2 was really incomplete. As I said, this is a supplement to the theory in section 2.\nThis doesn’t prevent us using principles of constitutive rationality, such as we prefer to believe p iff our credence in p is over \\(\\nicefrac{1}{2}\\). Indeed, on most occasions where we use constitutive rationality to infer that a person has some mental state, the mental state we attribute to them is one they could not fail to have. But functionalists are committed to constitutive rationality (Lewis 1994). So my approach here is consistent with a broadly functionalist outlook.\nObjection: This just looks like a roundabout way of stipulating that to believe that p, your degree of belief in p has to be greater than \\(\\nicefrac{1}{2}\\). Why not just add that as an extra clause than going through these little understood detours about preferences about beliefs?\nReply: There are three reasons for doing things this way rather than adding such a clause.\nFirst, it’s nice to have a systematic theory rather than a theory with an ad hoc clause like that.\nSecond, the effect of this constraint is much more than to restrict belief to propositions whose credence is greater than \\(\\nicefrac{1}{2}\\). Consider a case where p and \\(q\\) and their conjunction are all salient, p and \\(q\\) are probabilistically independent, and the agent’s credence in each is 0.7. Assume also that \\(p, q\\) and \\(p \\wedge q\\) are completely irrelevant to any practical deliberation the agent must make. Then the criteria above imply that the agent does not believe that p or that \\(q\\). The reason is that the agent’s credence in \\(p \\wedge q\\) is 0.49, so she prefers to not believe \\(p \\wedge q\\). But conditional on p, her credence in \\(p \\wedge q\\) is 0.7, so she prefers to believe it. So conditionalising on p does change her preferences with respect to believing \\(p \\wedge q\\), so she doesn’t believe p. So the effect of these stipulations rules out much more than just belief in propositions whose credence is below \\(\\nicefrac{1}{2}\\).\nThis suggests the third, and most important point. The problem with the threshold view was that it led to violations of closure. Given the theory as stated, we can prove the following theorem. Whenever p and \\(q\\) and their conjunction are all open or salient, and both are believed, and the agent is probabilistically coherent, the agent also believes \\(p \\wedge q\\). This is a quite restricted closure principle, but this is no reason to deny that it is true, as it fails to be true on the threshold view.\nThe proof of this theorem is a little complicated, but worth working through. First we’ll prove that if the agent believes p, believes \\(q\\), and p and \\(q\\) are both salient, then the agent prefers believing \\(p \\wedge q\\) to not believing it, if \\(p \\wedge q\\) is eligible for belief. In what follows Pr(\\(x | y\\)) is the agent’s conditional degree of belief in \\(x\\) given \\(y\\). Since the agent is coherent, we’ll assume this is a probability function (hence the name).\n\nSince the agent believes that \\(q\\), they prefer believing that \\(q\\) to not believing that \\(q\\) (by the criteria for belief)\nSo the agent prefers believing that \\(q\\) to not believing that \\(q\\) given p (From 1 and the fact that they believe that p, and that \\(q\\) is salient)\nSo Pr(\\(q | p\\)) \\(&gt; \\nicefrac{1}{2}\\) (from 2)\nPr(\\(q | p\\)) = Pr(\\(p \\wedge q | p\\)) (by probability calculus)\nSo Pr(\\(p \\wedge q | p\\)) \\(&gt; \\nicefrac{1}{2}\\) (from 3, 4)\nSo, if \\(p \\wedge q\\) is eligible for belief, then the agent prefers believing that \\(p \\wedge q\\) to not believing it, given p (from 5)\nSo, if \\(p \\wedge q\\) is eligible for belief, the agent prefers believing that \\(p \\wedge q\\) to not believing it (from 6, and the fact that they believe that p, and \\(p \\wedge q\\) is salient)\n\nSo whenever, \\(p, q\\) and \\(p \\wedge q\\) are salient, and the agent believes each conjunct, the agent prefers believing the conjunction \\(p \\wedge q\\) to not believing it, if \\(p \\wedge q\\) is eligible. Now we have to prove that \\(p \\wedge q\\) is eligible for belief, to prove that it is actually believed. That is, we have to prove that (5) follows from (4) and (3), where the initial quantifiers range over actions that are open and salient tout court.\n\n\\(\\forall\\)A\\(\\forall\\)B\\(\\forall r\\) (A \\(\\geq_r\\) B \\(\\leftrightarrow\\) A \\(\\geq _p \\wedge r\\) B)\n\\(\\forall\\)A\\(\\forall\\)B\\(\\forall r\\) (A \\(\\geq_r\\) B \\(\\leftrightarrow\\) A \\(\\geq _q \\wedge r\\) B)\n\\(\\forall\\)A\\(\\forall\\)B\\(\\forall r\\) (A \\(\\geq_r\\) B \\(\\leftrightarrow\\) A \\(\\geq _{p \\wedge q \\wedge r}\\) B)\n\nAssume that (5) isn’t true. That is, there are A, B and S such that \\(\\neg\\)(A \\(\\geq_s\\) B \\(\\leftrightarrow\\) A \\(\\geq _{p \\wedge q \\wedge s}\\)B). By hypothesis S is active, and consistent with \\(p \\wedge q\\). So it is the conjunction of relevant, salient propositions. Since \\(q\\) is salient, this means \\(q \\wedge s\\) is also active. Since S is consistent with \\(p \\wedge q\\), it follows that \\(q \\wedge s\\) is consistent with p. So \\(q \\wedge s\\) is a possible substitution instance for \\(r\\) in (3). Since (3) is true, it follows that A \\(\\geq _{q \\wedge s}\\) B \\(\\leftrightarrow\\) A \\(\\geq _{p \\wedge q \\wedge s}\\) B. By similar reasoning, it follows that \\(s\\) is a permissible substitution instance in (4), giving us A \\(\\geq_s\\) B \\(\\leftrightarrow\\) A \\(\\geq _{q \\wedge s}\\) B. Putting the last two biconditionals together we get A \\(\\geq_s\\) B \\(\\leftrightarrow\\) A \\(\\geq _{p \\wedge q \\wedge s}\\)B, contradicting our hypothesis that there is a counterexample to (5). So whenever (3) and (4) are true, (5) is true as well, assuming \\(p, q\\) and \\(p \\wedge q\\) are all salient.\n\n\n0.4 Defending Closure\nSo on my account of the connection between degrees of belief and belief tout court, probabilistic coherence implies logical coherence amongst salient propositions. The last qualification is necessary. It is possible for a probabilistically coherent agent to not believe the non-salient consequences of things they believe, and even for a probabilistically coherent agent to have inconsistent beliefs as long as not all the members of the inconsistent set are active. Some people argue that even this weak a closure principle is implausible. David Christensen (2005), for example, argues that the preface paradox provides a reason for doubting that beliefs must be closed under entailment, or even must be consistent. Here is his description of the case.\n\nWe are to suppose that an apparently rational person has written a long non-fiction book—say, on history. The body of the book, as is typical, contains a large number of assertions. The author is highly confident in each of these assertions; moreover, she has no hesitation in making them unqualifiedly, and would describe herself (and be described by others) as believing each of the book’s many claims. But she knows enough about the difficulties of historical scholarship to realize that it is almost inevitable that at least a few of the claims she makes in the book are mistaken. She modestly acknowledges this in her preface, by saying that she believes the book will be found to contain some errors, and she graciously invites those who discover the errors to set her straight. (Christensen 2005, 33–34)\n\nChristensen thinks such an author might be rational in every one of her beliefs, even though these are all inconsistent. Although he does not say this, nothing in his discussion suggests that he is using the irrelevance of some of the propositions in the author’s defence. So here is an argument that we should abandon closure amongst relevant beliefs.\nChristensen’s discussion, like other discussions of the preface paradox, makes frequent use of the fact that examples like these are quite common. We don’t have to go to fake barn country to find a counterexample to closure. But it seems to me that we need two quite strong idealisations in order to get a real counterexample here.\nThe first of these is discussed in forthcoming work by Ishani Maitra (Maitra 2010), and is briefly mentioned by Christensen in setting out the problem. We only have a counterexample to closure if the author believes every thing she writes in her book. (Indeed, we only have a counterexample if she reasonably believes every one of them. But we’ll assume a rational author who only believes what she ought to believe.) This seems unlikely to be true to me. An author of a historical book is like a detective who, when asked to put forward her best guess about what explains the evidence, says “If I had to guess, I’d say …” and then launches into spelling out her hypothesis. It seems clear that she need not believe the truth of her hypothesis. If she did that, she could not later learn it was true, because you can’t learn the truth of something you already believe. And she wouldn’t put any effort into investigating alternative suspects. But she can come to learn her hypothesis was true, and it would be rational to investigate other suspects. It seems to me (following here Maitra’s discussion) that we should understand scholarly assertions as being governed by the same kind of rules that govern detectives making the kind of speech being contemplated here. And those rules don’t require that the speaker believe the things they say without qualification. The picture is that the little prelude the detective explicitly says is implicit in all scholarly work.\nThere are three objections I know to this picture, none of them particularly conclusive. First, Christensen says that the author doesn’t qualify their assertions. But neither does our detective qualify most individual sentences. Second, Christensen says that most people would describe our author as believing her assertions. But it is also natural to describe our detective as believing the things she says in her speech. It’s natural to say things like “She thinks it was the butler, with the lead pipe,” in reporting her hypothesis. Third, Timothy Williamson (2000) has argued that if speakers don’t believe what they say, we won’t have an explanation of why Moore’s paradoxical sentences, like “The butler did it, but I don’t believe the butler did it,” are always defective. Whatever the explanation of the paradoxicality of these sentences might be, the alleged requirement that speakers believe what they say can’t be it. For our detective cannot properly say “The butler did it, but I don’t believe the butler did it” in setting out her hypothesis, even though believing the butler did it is not necessary for her to say “The butler did it” in setting out just that hypothesis.\nIt is plausible that for some kinds of books, the author should only say things they believe. This is probably true for travel guides, for example. Interestingly, casual observation suggests that authors of such books are much less likely to write modest prefaces. This makes some sense if those books can only include statements their authors believe, and the authors believe the conjunctions of what they believe.\nThe second idealisation is stressed by Simon Evnine (1999) in his paper “Believing Conjunctions”. The following situation does not involve me believing anything inconsistent.\n\nI believe that what Manny just said, whatever it was, is false.\nManny just said that the stands at Fenway Park are green.\nI believe that the stands at Fenway Park are green.\n\nIf we read the first claim de dicto, that I believe that Manny just said something false, then there is no inconsistency. (Unless I also believe that what Manny just said was that the stands in Fenway Park are green.) But if we read it de re, that the thing Manny just said is one of the things I believe to be false, then the situation does involve me being inconsistent. The same is true when the author believes that one of the things she says in her book is mistaken. If we understand what she says de dicto, there is no contradiction in her beliefs. It has to be understood de re before we get a logical problem. And the fact is that most authors do not have de re attitudes towards the claims made in their book. Most authors don’t even remember everything that’s in their books. (I’m not sure I remember how this section started, let alone this paper.) Some may argue that authors don’t even have the capacity to consider a proposition as long and complicated as the conjunction of all the claims in their book. Christensen considers this objection, but says it isn’t a serious problem.\n\nIt is undoubtedly true that ordinary humans cannot entertain book-length conjunctions. But surely, agents who do not share this fairly superficial limitation are easily conceived. And it seems just as wrong to say of such agents that they are rationally required to believe in the inerrancy of the books they write. (38: my emphasis)\n\nI’m not sure this is undoubtedly true; it isn’t clear that propositions (as opposed to their representations) have lengths. And humans can believe propositions that can be represented by sentences as long as books. But even without that point, Christensen is right that there is an idealisation here, since ordinary humans do not know exactly what is in a given book, and hence don’t have de re attitudes towards the propositions expressed in the book.\nI’m actually rather suspicious of the intuition that Christensen is pushing here, that idealising in this way doesn’t change intuitions about the case. The preface paradox gets a lot of its (apparent) force from intuitions about what attitude we should have towards real books. Once we make it clear that the real life cases are not relevant to the paradox, I find the intuitions become rather murky. But I won’t press this point.\nA more important point is that we believers in closure don’t think that authors should think their books are inerrant. Rather, following Stalnaker (1984), we think that authors shouldn’t unqualifiedly believe the individual statements in their book if they don’t believe the conjunction of those statements. Rather, their attitude towards those propositions (or at least some of them) should be that they are probably true. (As Stalnaker puts it, they accept the story without believing it.) Proponents of the preface paradox know that this is a possible response, and tend to argue that it is impractical. Here is Christensen on this point.\n\nIt is clear that our everyday binary way of talking about beliefs has immense practical advantages over a system which insisted on some more fine-grained reporting of degrees of confidence … At a minimum, talking about people as believing, disbelieving, or withholding belief has at least as much point as do many of the imprecise ways we have of talking about things that can be described more precisely. (96)\n\nRichard Foley makes a similar point.\n\nThere are deep reasons for wanting an epistemology of beliefs, reasons that epistemologies of degrees of belief by their very nature cannot possibly accommodate. (Foley 1993, 170, my emphasis)\n\nIt’s easy to make too much of this point. It’s a lot easier to triage propositions into TRUE, FALSE and NOT SURE and work with those categories than it is to work assign precise numerical probabilities to each proposition. But these are not the only options. Foley’s discussion subsequent to the above quote sometimes suggests they are, especially when he contrasts the triage with “indicat[ing] as accurately as I can my degree of confidence in each assertion that I defend.” (171) But really it isn’t much harder to add two more categories, PROBABLY TRUE and PROBABLY FALSE to those three, and work with that five-way division rather than a three-way division. It’s not clear that humans as they are actually constructed have a strong preference for the three-way over the five-way division, and even if they do, I’m not sure in what sense this is a ‘deep’ fact about them.\nOnce we have the five-way division, it is clear what authors should do if they want to respect closure. For any conjunction that they don’t believe (i.e. classify as true), they should not believe one of the conjuncts. But of course they can classify every conjunct as probably true, even if they think the conjunction is false, or even certainly false. Still, might it not be considered something of an idealisation to say rational authors must make this five-way distinction amongst propositions they consider? Yes, but it’s no more of an idealisation than we need to set up the preface paradox in the first place. To use the preface paradox to find an example of someone who reasonably violates closure, we need to insist on the following three constraints.\n\nThey are part of a research community where only asserting propositions you believe is compatible with active scholarship;\nThey know exactly what is in their book, so they are able to believe that one of the propositions in the book is mistaken, where this is understood de re; but\nThey are unable to effectively function if they have to effect a five-way, rather than a three-way, division amongst the propositions they consider.\n\nPut more graphically, to motivate the preface paradox we have to think that our inability to have de re thoughts about the contents of books is a “superficial constraint”, but our preference for working with a three-way rather than a five-way division is a “deep” fact about our cognitive system. Maybe each of these attitudes could be plausible taken on its own (though I’m sceptical of that) but the conjunction seems just absurd.\nI’m not entirely sure an agent subject to exactly these constraints is even fully conceivable. (Such an agent is negatively conceivable, in David Chalmers’s terminology, but I rather doubt they are positively conceivable.) But even if they are a genuine possibility, why the norms applicable to an agent satisfying that very gerrymandered set of constraints should be considered relevant norms for our state is far from clear. I’d go so far as to say it’s clear that the applicability (or otherwise) of a given norm to such an odd agent is no reason whatsoever to say it applies to us. But since the preface paradox only provides a reason for just these kinds of agents to violate closure, we have no reason for ordinary humans to violate closure. So I see no reason here to say that we can have probabilistic coherence without logical coherence, as proponents of the threshold view insist we can have, but which I say we can’t have at least when the propositions involved are salient. The more pressing question, given the failure of the preface paradox argument, is why I don’t endorse a much stronger closure principle, one that drops the restriction to salient propositions. The next section will discuss that point.\nI’ve used Christensen’s book as a stalking horse in this section, because it is the clearest and best statement of the preface paradox. Since Christensen is a paradox-mongerer and I’m a paradox-denier, it might be thought we have a deep disagreement about the relevant epistemological issues. But actually I think our overall views are fairly close despite this. I favour an epistemological outlook I call “Probability First”, the view that getting the epistemology of partial belief right is of the first importance, and everything else should flow from that. Christensen’s view, reduced to a slogan, is “Probability First and Last”. This section has been basically about the difference between those two slogans. It’s an important dispute, but it’s worth bearing in mind that it’s a factional squabble within the Probability Party, not an outbreak of partisan warfare.\n\n\n0.5 Too Little Closure?\nIn the previous section I defended the view that a coherent agent has beliefs that are deductively cogent with respect to salient propositions. Here I want to defend the importance of the qualification. Let’s start with what I take to be the most important argument for closure, the passage from Stalnaker’s Inquiry that I quoted above.\n\nReasoning in this way from accepted premises to their deductive consequences (\\(P\\), also \\(Q\\), therefore \\(R\\)) does seem perfectly straightforward. Someone may object to one of the premises, or to the validity of the argument, but one could not intelligibly agree that the premises are each acceptable and the argument valid, while objecting to the acceptability of the conclusion. (Stalnaker 1984, 92)\n\nStalnaker’s wording here is typically careful. The relevant question isn’t whether we can accept p, accept \\(q\\), accept p and \\(q\\) entail \\(r\\), and reject \\(r\\). As Christensen (2005 Ch. 4) notes, this is impossible even on the threshold view, as long as the threshold is above 2/3. The real question is whether we can accept p, accept \\(q\\), accept p and \\(q\\) entail \\(r\\), and fail to accept \\(r\\). And this is always a live possibility on any threshold view, though it seems absurd at first that this could be coherent.\nBut it’s important to note how active the verbs in Stalnaker’s description are. When faced with a valid argument we have to object to one of the premises, or the validity of the argument. What we can’t do is agree to the premises and the validity of the argument, while objecting to the conclusion. I agree. If we are really agreeing to some propositions, and objecting to others, then all those propositions are salient. And in that case closure, deductive coherence, is mandatory. This doesn’t tell us what we have to do if we haven’t previously made the propositions salient in the first place.\nThe position I endorse here is very similar in its conclusions to that endorsed by Gilbert Harman in Change in View. There Harman endorses the following principle. (At least he endorses it as true – he doesn’t seem to think it is particularly explanatory because it is a special case of a more general interesting principle.)\n\nRecognized Logical Implication Principle\n\nOne has reason to believe p if one recognizes that p is logically implied by one’s view. (Harman 1986, 17)\n\n\nThis seems right to me, both what it says and its implicature that the reason in question is not a conclusive reason. My main objection to those who use the preface paradox to argue against closure is that they give us a mistaken picture of what we have to do epistemically. When I have inconsistent beliefs, or I don’t believe some consequence of my beliefs, that is something I have a reason to deal with at some stage, something I have to do. When we say that we have things to do, we don’t mean that we have to do them right now, or instead of everything else. My current list of things to do includes cleaning my bathroom, yet here I am writing this paper, and (given the relevant deadlines) rightly so. We can have the job of cleaning up our epistemic house as something to do while recognising that we can quite rightly do other things first. But it’s a serious mistake to infer from the permissibility of doing other things that cleaning up our epistemic house (or our bathroom) isn’t something to be done. The bathroom won’t clean itself after all, and eventually this becomes a problem.\nThere is a possible complication when it comes to tasks that are very low priority. My attic is to be cleaned, or at least it could be cleaner, but there are no imaginable circumstances under which something else wouldn’t be higher priority. Given that, should we really leave clean the attic on the list of things to be done? Similarly, there might be implications I haven’t followed through that it couldn’t possibly be worth my time to sort out. Are they things to be done? I think it’s worthwhile recording them as such, because otherwise we might miss opportunities to deal with them in the process of doing something else. I don’t need to put off anything else in order to clean the attic, but if I’m up there for independent reasons I should bring down some of the garbage. Similarly, I don’t need to follow through implications mostly irrelevant to my interests, but if those propositions come up for independent reasons, I should deal with the fact that some things I believe imply something I don’t believe. Having it be the case that all implications from things we believe to things we don’t believe constitute jobs to do (possibly in the loose sense that cleaning my attic is something to do) has the right implications for what epistemic duties we do and don’t have.\nWhile waxing metaphorical, it seems time to pull out a rather helpful metaphor that Gilbert Ryle (1949) develops in The Concept of Mind at a point where he’s covering what we’d now call the inference/implication distinction. (This is a large theme of chapter 9, see particularly pages 292-309.) Ryle’s point in these passages, as it frequently is throughout the book, is to stress that minds are fundamentally active, and the activity of a mind cannot be easily recovered from its end state. Although Ryle doesn’t use this language, his point is that we shouldn’t confuse the difficult activity of drawing inferences with the smoothness and precision of a logical implication. The language Ryle does use is more picturesque. He compares the easy work a farmer does when sauntering down a path from the hard work he did when building the path. A good argument, in philosophy or mathematics or elsewhere, is like a well made path that permits sauntering from the start to finish without undue strain. But from that it doesn’t follow that the task of coming up with that argument, of building that path in Ryle’s metaphor, was easy work. The easiest paths to walk are often the hardest to build. Path-building, smoothing out our beliefs so they are consistent and closed under implication, is hard work, even when the finished results look clean and straightforward. Its work that we shouldn’t do unless we need to. But making sure our beliefs are closed under entailment even with respect to irrelevant propositions is suspiciously like the activity of buildings paths between points without first checking you need to walk between them.\nFor a less metaphorical reason for doubting the wisdom of this unchecked commitment to closure, we might notice the difficulties theorists tend to get into all sorts of difficulties. Consider, for example, the view put forward by Mark Kaplan in Decision Theory as Philosophy. Here is his definition of belief.\n\nYou count as believing P just if, were your sole aim to assert the truth (as it pertains to P), and you only options were to assert that P, assert that \\(\\neg\\)P or make neither assertion, you would prefer to assert that P. (109)\n\nKaplan notes that conditional definitions like this are prone to Shope’s conditional fallacy. If my sole aim were to assert the truth, I might have different beliefs to what I now have. He addresses one version of this objection (namely that it appears to imply that everyone believes their sole desire is to assert the truth) but as we’ll see presently he can’t avoid all versions of it.\nThese arguments are making me thirsty. I’d like a beer. Or at least I think I would. But wait! On Kaplan’s theory I can’t think that I’d like a beer, for if my sole aim were to assert the truth as it pertains to my beer-desires, I wouldn’t have beer desires. And then I’d prefer to assert that I wouldn’t like a beer, I’d merely like to assert the truth as it pertains to my beer desires.\nEven bracketing this concern, Kaplan ends up being committed to the view that I can (coherently!) believe that p even while regarding p as highly improbable. This looks like a refutation of the view to me, but Kaplan accepts it with some equanimity. He has two primary reasons for saying we should live with this. First, he says that it only looks like an absurd consequence if we are committed to the Threshold View. To this all I can say is that I don’t believe the Threshold View, but it still seems absurd to me. Second, he says that any view is going to have to be revisionary to some extent, because our ordinary concept of belief is not “coherent” (142). His view is that, “Our ordinary notion of belief both construes belief as a state of confidence short of certainty and takes consistency of belief to be something that is at least possible and, perhaps, even desirable” and this is impossible. I think the view here interprets belief as a state less than confidence and allows for as much consistency as the folk view does (i.e. consistency amongst salient propositions), so this defence is unsuccessful as well.\nNone of the arguments here in favour of our restrictions on closure are completely conclusive. In part the argument at this stage rests on the lack of a plausible rival theory that doesn’t interpret belief as certainty but implements a stronger closure principle. It’s possible that tomorrow someone will come up with a theory that does just this. Until then, we’ll stick with the account here, and see what its epistemological implications might be.\n\n\n0.6 Examples of Pragmatic Encroachment\nFantl and McGrath’s case for pragmatic encroachment starts with cases like the following. (The following case is not quite theirs, but is similar enough to suit their plan, and easier to explain in my framework.)\n\nLocal and Express\nThere are two kinds of trains that run from the city to the suburbs: the local, which stops at all stations, and the express, which skips the first eight stations. Harry and Louise want to go to the fifth station, so they shouldn’t catch the Express. Though if they do it isn’t too hard to catch a local back the other way, so it isn’t usually a large cost. Unfortunately, the trains are not always clearly labelled. They see a particular train about to leave. If it’s a local they are better off catching it, if it is an express they should wait for the next local, which they can see is already boarding passengers and will leave in a few minutes. While running towards the train, they hear a fellow passenger say “It’s a local.” This gives them good, but far from overwhelming, reason to believe that the train is a local. Passengers get this kind of thing wrong fairly frequently, but they don’t have time to get more information. So each of them face a gamble, which they can take by getting on the train. If the train is a local, they will get home a few minutes early. If it is an express they will get home a few minutes later. For Louise, this is a low stakes gamble, as nothing much turns on whether she is a few minutes early or late, but she does have a weak preference for arriving earlier rather than later. But for Harry it is a high stakes gamble, because if he is late he won’t make the start of his daughter’s soccer game, which will highly upset her. There is no large payoff for Harry arriving early.\n\nWhat should each of them do? What should each of them believe?\nThe first question is relatively easy. Louise should catch the train, and Harry should wait for the next. For each of them that’s the utility maximising thing to do. The second one is harder. Fantl and McGrath suggest that, despite being in the same epistemic position with respect to everything except their interests, Louise is justified in believing the train is a local and Harry is not. I agree. (If you don’t think the particular case fits this pattern, feel free to modify it so the difference in interests grounds a difference in what they are justified in believing.) Does this show that our notion of epistemic justification has to be pragmatically sensitive? I’ll argue that it does not.\nThe fundamental assumption I’m making is that what is primarily subject to epistemic evaluation are degrees of belief, or what are more commonly called states of confidence in ordinary language. When we think about things this way, we see that Louise and Harry are justified in adopting the very same degrees of belief. Both of them should be confident, but not absolutely certain, that the train is a local. We don’t have even the appearance of a counterxample to Probabilistic Evidentialism here. If we like putting this in numerical terms, we could say that each of them is justified in assigning a probability of around 0.9 to the proposition That train is a local.4 So as long as we adopt a Probability First epistemology, where we in the first instance evaluate the probabilities that agents assign to propositions, Harry and Louise are evaluated alike iff they do the same thing.\n4 I think putting things numerically is misleading because it suggests that the kind of bets we usually use to measure degrees of belief are open, salient options for Louise and Harry. But if those bets were open and salient, they wouldn’t believe the train is a local. Using qualitative rather than quantitative language to describe them is just as accurate, and doesn’t have misleading implications about their practical environment.How then can we say that Louise alone is justified in believing that the train is a local? Because that state of confidence they are justified in adopting, the state of being fairly confident but not absolutely certain that the train is a local, counts as believing that the train is a local given Louise’s context but not Harry’s context. Once Louise hears the other passenger’s comment, conditionalising on That’s a local doesn’t change any of her preferences over open, salient actions, including such ‘actions’ as believing or disbelieving propositions. But conditional on the train being a local, Harry prefers catching the train, which he actually does not prefer.\nIn cases like this, interests matter not because they affect the degree of confidence that an agent can reasonably have in a proposition’s truth. (That is, not because they matter to epistemology.) Rather, interests matter because they affect whether those reasonable degrees of confidence amount to belief. (That is, because they matter to philosophy of mind.) There is no reason here to let pragmatic concerns into epistemology.\n\n\n0.7 Justification and Practical Reasoning\nThe discussion in the last section obviously didn’t show that there is no encroachment of pragmatics into epistemology. There are, in particular, two kinds of concerns one might have about the prospects for extending my style of argument to block all attempts at pragmatic encroachment. The biggest concern is that it might turn out to be impossible to defend a Probability First epistemology, particularly if we do not allow ourselves pragmatic concerns. For instance, it is crucial to this project that we have a notion of evidence that is not defined in terms of traditional epistemic concepts (e.g. as knowledge), or in terms of interests. This is an enormous project, and I’m not going to attempt to tackle it here. The second concern is that we won’t be able to generalise the discussion of that example to explain the plausibility of (JP) without conceding something to the defenders of pragmatic encroachment.\n\n(JP)\n\nIf S justifiably believes that p, then S is justified in using p as a premise in practical reasoning.\n\n\nAnd that’s what we will look at in this section. To start, we need to clarify exactly what (JP) means. Much of this discussion will be indebted to Fantl and McGrath’s discussion of various ways of making (JP) more precise. To see some of the complications at issue, consider a simple case of a bet on a reasonably well established historical proposition. The agent has a lot of evidence that supports p, and is offered a bet that returns $1 if p is true, and loses $500 if p is false. Since her evidence doesn’t support that much confidence in p, she properly declines the bet. One might try to reason intuitively as follows. Assume that she justifiably believed that p. Then she’d be in a position to make the following argument.\n\np\nIf p, then I should take the bet\nSo, I should take the bet\n\nSince she isn’t in a position to draw the conclusion, she must not be in a position to endorse both of the premises. Hence (arguably) she isn’t justified in believing that p. But we have to be careful here. If we assume also that p is true (as Fantl and McGrath do, because they are mostly concerned with knowledge rather than justified belief), then the second premise is clearly false, since it is a conditional with a true antecedent and a false consequent. So the fact that she can’t draw the conclusion of this argument only shows that she can’t endorse both of the premises, and that’s not surprising since one of the premises is most likely false. (I’m not assuming here that the conditional is true iff it has a true antecendent or a false consequent, just that it is only true if it has a false antecedent or a true consequent.)\nIn order to get around this problem, Fantl and McGrath suggest a few other ways that our agent might reason to the bet. They suggest each of the following principles.\n\nS knows that p only if, for any act A, if S knows that if p, then A is the best thing she can do, then S is rational to do A. (72)\nS knows that p only if, for any states of affairs A and B, if \\(S\\) knows that if p, then A is better for her than B, then S is rational to prefer A to B. (74)\n(PC) S is justified in believing that p only if S is rational to prefer as if p. (77)\n\nHawthorne (2004, 174–81) appears to endorse the second of these principles. He considers an agent who endorses the following implication concerning a proposed sell of a lottery ticket for a cent, which is well below its actuarially fair value.\n\nI will lose the lottery.\nIf I keep the ticket, I will get nothing.\nIf I sell the ticket, I will get a cent.\nSo I ought to sell the ticket. (174)\n\n(To make this fully explicit, it helps to add the tacit premise that a cent is better than nothing.) Hawthorne says that this is intuitively a bad argument, and concludes that the agent who attempts to use it is not in a position to know its first premise. But that conclusion only follows if we assume that the argument form is acceptable. So it is plausible to conclude that he endorses Fantl and McGrath’s second principle.\nThe interesting question here is whether the theory endorsed in this paper can validate the true principles that Fantl and McGrath articulate. (Or, more precisely, we can validate the equivalent true principles concerning justified belief, since knowledge is outside the scope of the paper.) I’ll argue that it can in the following way. First, I’ll just note that given the fact that the theory here implies the closure principles we outlined in section 5, we can easily enough endorse Fantl and McGrath’s first two principles. This is good, since they seem true. The longer part of the argument involves arguing that their principle (PC), which doesn’t hold on the theory endorsed here, is in fact incorrect.\nOne might worry that the qualification on the closure principles in section 5 mean that we can’t fully endorse the principles Fantl and McGrath endorse. In particular, it might be worried that there could be an agent who believes that p, believes that if p, then A is better than B, but doesn’t put these two beliefs together to infer that A is better than B. This is certainly a possibility given the qualifications listed above. But note that in this position, if those two beliefs were justified, the agent would certainly be rational to conclude that A is better than B, and hence rational to prefer A to B. So the constraints on the closure principles don’t affect our ability to endorse these two principles.\nThe real issue is (PC). Fantl and McGrath offer a lot of cases where (PC) holds, as well as arguing that it is plausibly true given the role of implications in practical reasoning. What’s at issue is that (PC) is stronger than a deductive closure principle. It is, in effect, equivalent to endorsing the following schema as a valid principle of implication.\n\np\nGiven p, A is preferable to B\nSo, A is preferable to B\n\nI call this Practical Modus Ponens, or PMP. The middle premise in PMP is not a conditional. It is not to be read as If p, then A is preferable to B. Conditional valuations are not conditionals. To see this, again consider the proposed bet on (true) p at exorbitant odds, where A is the act of taking the bet, and B the act of declining the bet. It’s true that given p, A is preferable to B. But it’s not true that if p, then A is preferable to B. Even if we restrict our attention to cases where the preferences in question are perfectly valid, this is a case where PMP is invalid. Both premises are true, and the conclusion is false. It might nevertheless be true that whenever an agent is justified in believing both of the premises, she is justified in believing the conclusion. To argue against this, we need a very complicated case, involving embedded bets and three separate agents, Quentin, Robby and Thom. All of them have received the same evidence, and all of them are faced with the same complex bet, with the following properties.\n\np is an historical proposition that is well (but not conclusively) supported by their evidence, and happens to be true. All the agents have a high credence in p, which is exactly what the evidence supports.\nThe bet A, which they are offered, wins if p is true, and loses if p is false.\nIf they win the bet, the prize is the bet B.\nS is also an historical proposition, but the evidence tells equally for and against it. All the agents regard S as being about as likely as not. Moreover, S turns out to be false.\nThe bet B is worth $2 if S is true, and worth -$1 if S is false. Although it is actually a losing bet, the agents all rationally value it at around 50 cents.\nHow much A costs is determined by which proposition from the partition {\\(q, r, s\\)} is true.\nIf \\(q\\) is true, A costs $2\nIf \\(r\\) is true, A costs $500\nIf \\(t\\) is true, A costs $1\nThe evidence the agents has strongly supports \\(r\\), though \\(t\\) is in fact true\nQuentin believes \\(q\\)\nRobby believes \\(r\\)\nThom believes \\(t\\)\n\nAll of the agents make the utility calculations that their beliefs support, so Quentin and Thom take the bet and lose a dollar, while Robby declines it. Although Robby has a lot of evidence in favour of p, he correctly decides that it would be unwise to bet on p at effective odds of 1000 to 1 against. I’ll now argue that both Quentin and Thom are potential counterexamples to (PC). There are three possibilities for what we can say about those two.\nFirst, we could say that they are justified in believing p, and rational to take the bet. The problem with this position is that if they had rational beliefs about the partition {\\(q, r, t\\)} they would realise that taking the bet does not maximise expected utility. If we take rational decisions to be those that maximise expected utility given a rational response to the evidence, then the decisions are clearly not rational.\nSecond, we could say that although Quentin and Thom are not rational in accepting the bet, nor are they justified in believing that p. This doesn’t seem particularly plausible for several reasons. The irrationality in their belief systems concerns whether \\(q, r\\) or \\(t\\) is true, not whether p is true. If Thom suddenly got a lot of evidence that \\(t\\) is true, then all of his (salient) beliefs would be well supported by the evidence. But it is bizarre to think that whether his belief in p is rational turns on how much evidence he has for \\(t\\). Finally, even if we accept that agents in higher stakes situations need more evidence to have justified beliefs, the fact is that the agents are in a low-risk situation, since \\(t\\) is actually true, so the most they could lose is $1.\nSo it seems like the natural thing to say is that Quentin and Thom are justified in believing that p, and are justified in believing that given p, it maximises expected utility to take the bet, but they are not rational to take the bet. (At least, in the version of the story where they are thinking about which of \\(q, r\\) and \\(t\\) are correct given their evidence when thinking about whether to take the bet they are counterexamples to (PC).) Against this, one might respond that if belief in p is justified, there are arguments one might make to the conclusion that the bet should be taken. So it is inconsistent to say that the belief is justified, but the decision to take the bet is not rational. The problem is finding a premise that goes along with p to get the conclusion that taking the bet is rational. Let’s look at some of the premises the agent might use.\n\nIf p, then the best thing to do is to take the bet.\n\nThis isn’t true (p is true, but the best thing to do isn’t to take the bet). More importantly, the agents think this is only true if S is true, and they think S is a 50/50 proposition. So they don’t believe this premise, and it would not be rational to believe it.\n\nIf p, then probably the best thing to do is to take the bet.\n\nAgain this isn’t true, and it isn’t well supported, and it doesn’t even support the conclusion, for it doesn’t follow from the fact that \\(x\\) is probably the best thing to do that \\(x\\) should be done.\n\nIf p, then taking the bet maximises rational expected utility.\n\nThis isn’t true – it is a conditional with a true antecedent and a false consequent. Moreover, if Quentin and Thom were rational, like Robby, they would recognise this.\n\nIf p, then taking the bet maximises expected utility relative to their beliefs.\n\nThis is true, and even reasonable to believe, but it doesn’t imply that they should take the bet. It doesn’t follow from the fact that doing something maximises expected utility relative to my crazy beliefs that I should do that thing.\n\nGiven p, taking the bet maximises rational expected utility.\n\nThis is true, and even reasonable to believe, but it isn’t clear that it supports the conclusion that the agents should take the bet. The implication appealed to here is PMP, and in this context that’s close enough to equivalent to (PC). If we think that this case is a prima facie problem for (PC), as I think is intuitively plausible, then we can’t use (PC) to show that it doesn’t post a problem. We could obviously continue for a while, but it should be clear it will be very hard to find a way to justify taking the bet even spotting the agents p as a premise they can use in rational deliberation. So it seems to me that (PC) is not in general true, which is good because as we’ll see in cases like this one the theory outlined here does not support it.\nThe theory we have been working with says that belief that p is justified iff the agent’s degree of belief in p is sufficient to amount to belief in their context, and they are justified in believing p to that degree. Since by hypothesis Quentin and Thom are justified in believing p to the degree that they do, the only question left is whether this amounts to belief. This turns out not to be settled by the details of the case as yet specified. At first glance, assuming there are no other relevant decisions, we might think they believe that p because (a) they prefer (in the relevant sense) believing p to not believing p, and (b) conditionalising on p doesn’t change their attitude towards the bet. (They prefer taking the bet to declining it, both unconditionally and conditional on p.)\nBut that isn’t all there is to the definition of belief tout court. We must also ask whether conditionalising on p changes any preferences conditional on any active proposition. And that may well be true. Conditional on \\(r\\), Quentin and Thom prefer not taking the bet to taking it. But conditional on \\(r\\) and p, they prefer taking the bet to not taking it. So if \\(r\\) is an active proposition, they don’t believe that p. If \\(r\\) is not active, they do believe it. In more colloquial terms, if they are concerned about the possible truth of \\(r\\) (if it is salient, or at least not taken for granted to be false) then p becomes a potentially high-stakes proposition, so they don’t believe it without extraordinary evidence (which they don’t have). Hence they are only a counterexample to (PC) if \\(r\\) is not active. But if \\(r\\) is not active, our theory predicts that they are a counterexample to (PC), which is what we argued above is intuitively correct.\nStill, the importance of \\(r\\) suggests a way of saving (PC). Above I relied on the position that if Quentin and Thom are not maximising rational expected utility, then they are being irrational. This is perhaps too harsh. There is a position we could take, derived from some suggestions made by Gilbert Harman in Change in View, that an agent can rationally rely on their beliefs, even if those beliefs were not rationally formed, if they cannot be expected to have kept track of the evidence they used to form that belief. If we adopt this view, then we might be able to say that (PC) is compatible with the correct normative judgments about this case.\nTo make this compatibility explicit, let’s adjust the case so Quentin takes \\(q\\) for granted, and cannot be reasonably expected to have remembered the evidence for \\(q\\). Thom, on the other hand, forms the belief that \\(t\\) rather than \\(r\\) is true in the course of thinking through his evidence that bears on the rationality of taking or declining the bet. (In more familiar terms, \\(t\\) is part of the inference Thom uses in coming to conclude that he should take the bet, though it is not part of the final implication he endorses whose conclusion is that he should take the bet.) Neither Quentin nor Thom is a counterexample to (PC) thus understood. (That is, with the notion of rationality in (PC) understood as Harman suggests that it should be.) Quentin is not a counterexample, because he is rational in taking the bet. And Thom is not a counterexample, because in his context, where \\(r\\) is active, his credence in p does not amount to belief in p, so he is not justified in believing p.\nWe have now two readings of (PC). On the strict reading, where a rational choice is one that maximises rational expected utility, the principle is subject to counterexample, and seems generally to be implausible. On the loose reading, where we allow agents to rely on beliefs formed irrationally in the past in rational decision making, (PC) is plausible. Happily, the theory sketched here agrees with (PC) on the plausible loose reading, but not on the implausible strict reading. In the previous section I argued that the theory also accounts for intuitions about particular cases like Local and Express. And now we’ve seen that the theory accounts for our considered opinions about which principles connecting justified belief to rational decision making we should endorse. So it seems at this stage that we can account for the intuitions behind the pragmatic encroachment view while keeping a concept of probabilistic epistemic justification that is free of pragmatic considerations.\n\n\n0.8 Conclusions\nGiven a pragmatic account of belief, we don’t need to have a pragmatic account of justification in order to explain the intuitions that whether \\(S\\) justifiably believes that p might depend on pragmatic factors. My focus here has been on sketching a theory of belief on which it is the belief part of the concept of a justified belief which is pragmatically sensitive. I haven’t said much about why we should prefer to take that option than say that the notion of epistemic justification is a pragmatic notion. I’ve mainly been aiming to show that a particular position is an open possibility, namely that we can accept that whether a particular agent is justified in believing p can be sensitive to their practical environment without thinking that the primary epistemic concepts are themselves pragmatically sensitive.\n\n\n\n\n\n\nReferences\n\nBovens, Luc, and James Hawthorne. 1999. “The Preface, the Lottery, and the Logic of Belief.” Mind 108 (430): 241–64. https://doi.org/10.1093/mind/108.430.241.\n\n\nChristensen, David. 2005. Putting Logic in Its Place. Oxford: Oxford University Press.\n\n\nEvnine, Simon. 1999. “Believing Conjunctions.” Synthese 118: 201–27. https://doi.org/10.1023/A:1005114419965.\n\n\nFantl, Jeremy, and Matthew McGrath. 2002. “Evidence, Pragmatics, and Justification.” Philosophical Review 111: 67–94. https://doi.org/10.2307/3182570.\n\n\nFoley, Richard. 1993. Working Without a Net. Oxford: Oxford University Press.\n\n\nHarman, Gilbert. 1986. Change in View. Cambridge, MA: Bradford.\n\n\nHawthorne, John. 2004. Knowledge and Lotteries. Oxford: Oxford University Press.\n\n\nHunter, Daniel. 1996. “On the Relation Between Categorical and Probabilistic Belief.” Noûs 30: 75–98. https://doi.org/10.2307/2216304.\n\n\nKaplan, Mark. 1996. Decision Theory as Philosophy. Cambridge: Cambridge University Press.\n\n\nKeynes, John Maynard. 1921. Treatise on Probability. London: Macmillan.\n\n\nLewis, David. 1994. “Reduction of Mind.” In A Companion to the Philosophy of Mind, edited by Samuel Guttenplan, 412–31. Oxford: Blackwell. https://doi.org/10.1017/CBO9780511625343.019.\n\n\nMaitra, Ishani. 2010. “Assertion, Norms and Games.” In Assertion: New Philosophical Essays, edited by Jessica Brown and Herman Cappelen, 277–96. Oxford: Oxford University Press.\n\n\nRyle, Gilbert. 1949. The Concept of Mind. New York: Barnes; Noble.\n\n\nStalnaker, Robert. 1984. Inquiry. Cambridge, MA: MIT Press.\n\n\nStanley, Jason. 2005. Knowledge and Practical Interests. Oxford University Press.\n\n\nWeatherson, Brian. 2005. “True, Truer, Truest.” Philosophical Studies 123 (1-2): 47–70. https://doi.org/10.1007/s11098-004-5218-x.\n\n\nWilliamson, Timothy. 1994. Vagueness. Routledge.\n\n\n———. 2000. Knowledge and its Limits. Oxford University Press."
  },
  {
    "objectID": "posts/dpww/index.html",
    "href": "posts/dpww/index.html",
    "title": "Doing Philosophy With Words",
    "section": "",
    "text": "Scott Soames (2003) has written two wonderfully useful books that will be valuable introductions to twentieth century philosophy. The books arose out of his well-received classes on the history of twentieth century history at Princeton, and will be valuable to anyone teaching similar courses. I shall be relying on them as I teach such a course at Cornell.\n\nPublished in Philosophical Studies 135 (2007): 429-37.\n\nThe books consist of detailed case studies of important twentieth-century works. They are best read alongside those original texts. Anyone who works through the canon in this way will have an excellent introduction to what twentieth century philosophers were trying to do. The selections are judicious, and while some are obvious classics some are rather clever choices of papers that are representative of the type of work being done at the time. And Soames doesn’t just point to the most important works to study, but the most important sections of those works.\n\nThanks to David Chalmers, Michael Fara, John Fischer, Tamar Szabó Gendler, James Klagge, Michael Kremer, Ishani Maitra, Aidan McGlynn, Alva Noë, Jonathan Weinberg and Larry Wright.\n\nSoames’s discussion of these pieces is always built around an analysis of their strengths and weaknesses. He praises the praiseworthy, but the focus, at least in the sections I’m discussing (ordinary language philosophy from Wittgenstein to Grice), is on where these philosophers go wrong. This is particularly so when the mistakes are representative of a theme. There are three main mistakes Soames finds in philosophers of this period. First, they rely logical positivism long after it had been shown to be unviable. Second, they disregard the principle that semantics should be systematic. Third, they ignore the distinction between necessity and a priority. All three constitute major themes of Soames’s book, and indeed of twentieth century philosophy as Soames sees it.\nThese books concentrate, almost to a fault, on discussion of philosophers’ published works, as opposed to the context in which they are written. Apart from occasionally noting that some books were released posthumously, we aren’t told whether the philosophers who wrote them are alive, and only in one case are we told when a philosopher was born. This kind of external information does not seem important to Soames. He is the kind of historian who would prefer a fourth reading of Austin’s published works to a first reading of his wartime diaries. And he’d prefer to spend the evening working on refutations, or charitable reformulations, of Austin’s arguments to either. I’m mostly sympathetic to this approach; this is history of philosophy after all. We can leave discussions of the sociology of 1950s Oxford to those better qualified. But this choice about what to write about has consequences.\nMost of Soames’s chapters focus almost exclusively on a particular book or paper. The exceptions are like the chapter on Sense and Sensibilia, where Soames contrasts Austin’s discussion with Ayer’s response. We learn a lot about the most important works that way, but less about their intellectual environment. So the book doesn’t have much by way of broad discussion about overall trends or movements. There’s very little, for example, about who were the influencers and who the influenced. There’s nothing about how anyone not called ‘Wittgenstein’ changed their positions in response to criticism. One assumes from the chronology that Ryle’s influence on Austin was greater than Austin’s influence on Ryle, for example, but Soames is silent on whether this is true.\nSoames says at one point that, “[Ryle] was, along with Wittgenstein, J. L. Austin, and Paul Grice, one of the prime movers in postwar philosophy in England.” (68). But we aren’t really told why this is so, apart from the discussion of some prominent works of these four philosophers. (Perhaps Soames has taken the maxim Show it, don’t say it rather completely to heart.) Nor are why told why the list includes those four, and not, say, Strawson or Geach or Anscombe. Actually Anscombe’s absence reminds us that there is almost no discussion of women in philosophy in the book. That’s not Soames fault, it’s a reflection of a long-running systematic problem in philosophy that the discipline has a hard time recruiting and retaining women. Could some of that be traced back to what was going on in the ordinary language period? That kind of questions can’t be addressed by the kind of history book that Soames has written, where the focus is on the best philosophical writing, and not on the broader philosophical community.\nOne of the other consequences of the format is that, by necessity, many important figures are left out, on pain of writing a fifteen-volume book. In the period under discussion here there was historically important work by (among many others) Nelson Goodman, Wilfrid Sellars and Roderick Chisholm, some of which connects up closely to the themes and interests of the ordinary language philosophers, but none of which is as much as mentioned. (Goodman is mentioned in the epilogue as someone Soames regrets not covering.)\nNow this can’t be a complaint about the book Soames has written, because it would have been impossible to cover any more figures than he did in the style and depth that he did. And it would have been impossible to tell in detail the story of how Ryle’s impact on the philosophical world differed from Austin’s, or of the painfully slow integration of women into the top echelons of philosophy, without making the book be even more monumental than it is. All we’re left with is a half-hearted expression of regret that he didn’t write a different kind of book, one that told us more about the forest, even as we value what he says about the tallest of the trees.\n\n0.1 Grice and The End of Ordinary Language\nThere is one place where Soames stops to survey the field, namely his discussion of the impact of Grice’s work on the ordinary language tradition. Soames argues that with Grice’s William James lectures, the idea of ordinary language philosophy had “run their course”. The position seems to be that Grice overthrew a paradigm that had been vibrant for two decades, but was running out of steam by the time of Grice’s James lectures. How plausible is this?\nThe first step is to work out just what it was that Grice (1989) refuted. When summarising the ordinary language paradigm that he takes Grice to have overthrown, Soames is uncharacteristically harsh. In Soames’s summary one of the characteristic activities of an ordinary language philosopher is “opportunistically assembling reminders about how philosophically significant words are used in ordinary settings” (216). That may be a fair enough description of some mid-century work, but it isn’t a fair summary of the best of the work that Soames has spent the previous two hundred odd pages discussing. It all suggests that Grice didn’t so much overthrow ordinary language philosophy as much as badly done ordinary language philosophy, and this category might not include Strawson, Ryle, Austin and so on.\nMore importantly, it isn’t entirely clear just what it was Grice did that caused this paradigm shift. In Soames’s telling it seems the development of the speaker meaning/semantic meaning distinction was crucial, but Austin (1962) at least already recognised this distinction, indeed appealed to it twice in Sense and Sensibilia. Soames mentions the discussion on pages 89 to 91 of Sense and Sensibilia of phrases like “I see two pieces of paper”, and there is also the intriguing discussion on pages 128-9 of the relation between accurate and true where Austin goes close to stating Grice’s submaxim of concision.\nThe other suggestion is that Grice restored the legitimacy and centrality of systematic semantic theorising. It’s true Grice did that, but this doesn’t show we have to give up ordinary language philosophy unless it was impossible to be an ordinary language philosopher and a systematic semanticist. And it isn’t clear that this really is impossible. It hardly seems inconsistent with the kind of philosophy Austin did (especially in his theory of perception) that one endorse a systematic semantic theory. (Though Austin himself rarely put forward systematic analyses.) Notably, there are plenty of very systematic formal semanticists who take Strawson’s work on descriptions seriously, and try and integrate it into formal models. So we might wonder why Grice’s work shouldn’t have led to a kind of ordinary language philosophy where we paid more careful attention to system-building.\nMore broadly, we might wonder whether the ordinary language period really did end. The analysis of knowledge industry (strangely undiscussed in a work on analysis in the twentieth century) seemed to putter along much the same before and after the official demise of ordinary language philosophy. And there are affinities between the ordinary language philosophers and important contemporary research programs, e.g. the ‘Canberra Plan’ as described by Frank Jackson (1998). So perhaps before we asked who killed ordinary language philosophy (It was Professor Grice! In Emerson Hall!! With the semantics/pragmatics distinction!!!) we should have made sure there was a corpse. More on this point presently.\n\n\n0.2 A Whig History?\nOne of the major themes of Soames’s discussion is that there are some systematic problems in twentieth century philosophy that are righted by the heroes at the end of the story. I already mentioned the heroic role assigned to Grice. But the real star of the show is Kripke (1980), who comes in as a deus ex machina at the end showing how different necessity and a priority are, and thereby righting all manner of grievous wrongs. That Kripke is an important figure in twentieth century philosophy is hardly a matter of dispute, but Soames does stretch a little to find errors for our hero to correct.\nSome of the complaints about philosophers collapsing the necessary/a priori distinction do hit the target, but don’t leave deep wounds in their victims. For instance, Soames quotes Ryle (1954) arguing (in Dilemmas) that perception cannot be a physiological process because if it were we couldn’t know whether we saw a tree until we found out the result of complicated brain scans. Soames points out, perfectly correctly, that the seeing might be necessarily identical to the brain process even if we don’t know, and even can’t know without complicated measurements, whether they are identical. Soames is right that Ryle has made an epistemological argument here when a metaphysical argument was needed. But rewriting Ryle so he makes that metaphysical argument isn’t hard. If my seeing the tree is necessarily identical to the brain process, and the brain process is (as Ryle and Soames seem to agree it is) individuated by the brain components that implement it, then I couldn’t have seen the tree had one of the salient neurons in my brain been silently replaced with a functionally equivalent silicon chip. Since it is possible that I could have seen a tree even if a salient neuron was replaced with a functionally equivalent silicon chip, the seeing and the brain process are not necessarily identical. So while Ryle might have slipped here, and Kripke’s work does help us correct the slip, the consequences of this are basically verbal.\nA more important charge of ignoring the necessary/a priori distinction comes in Soames’s discussion of Wittgenstein’s deflationism about philosophy. Here is the salient passage.\n\nHis deflationary conception of philosophy is also consistent with, and even derivative from, his new ideas about meaning plus a set of unquestioned philosophical presuppositions he brings to the enterprise. The philosophical presuppositions include the then current and widespread assumptions that (i) that philosophical theses are not empirical, and hence must be necessary and a priori, and (ii) that the necessary, the a priori and the analytic are one and the same. Because he takes these assumptions for granted, he takes it for granted that if there are any philosophical truths, they must be analytic (29).\n\nThis seems to me to be mistaken twice over.\nFirst, it isn’t clear to me that there is any appeal to concepts of necessity in the passages in Wittgenstein Soames is summarising here, and metaphysical necessity simply doesn’t seem to have been a major interest of Wittgenstein’s. Wittgenstein does appear to reason that if a proposition is not empirical it is a priori, but that inference doesn’t go via claims about necessity, and isn’t shown to be fallacious by any of Kripke’s examples.\nSecond, it simply isn’t true that philosophers in Wittgenstein’s time took for granted that the analytic and the a priori were one and the same. To be sure, many philosophers in the early twentieth century (including many argue the younger Wittgenstein) argued against Kant’s claim that they are distinct, but this isn’t quite the same as taking for granted they are identical. And there are a few places where Wittgenstein appears to accept that some propositions are synthetic a priori. For example in Remarks on the Foundations of Mathematics he says it is synthetic a priori that there is no reddish green, (Part III, para 39) and goes on to say this about primes.\n\nThe distribution of primes would be an ideal example of what could be called synthetic a priori, for one can say that it is at any rate not discoverable by an analysis of the concept of a prime number. (Wittgenstein 1956, pt. III, para 42)\n\nNow it is far from obvious what the connection is between remarks such as these and the remarks about the impossibility of philosophical theses in the Investigations. Indeed it is not obvious whether Wittgenstein really believed in the synthetic a priori at any stage of his career. But given his lack of interest in metaphysical necessity, and openness to the possibility of synthetic a priori claims, it seems unlikely that he was, tacitly or otherwise, using the argument Soames gives him to get the deflationary conclusions.1\n1 I’m grateful to many correspondants for discussions about Wittgenstein. They convinced me, inter alia, that it would be foolish of me to commit to strong views of any kind about the role of the synthetic a priori in Wittgenstein’s later thought, and that the evidence is particularly messy because Wittgenstein wasn’t as centrally concerned with these concepts as we are.\n\n0.3 Getting the Question Right\nAs I mentioned above, Soames’s is the kind of history that focuses on the works of prominent philosophers, rather than their historical context. There’s much to be gained from this approach, in particular about what the greats can tell us about pressing philosophical questions. But one of the costs is that in focussing on what they say about our questions, we might overlook their questions. In most cases this is a trap Soames avoids, but in the cases of Austin and Ryle the trap may have been sprung.\nSoames sees Austin in Sense and Sensibilia as trying to offer us a new argument against radical scepticism.\n\nAustin’s ultimate goal is to undermine the coherence of skepticism. His aim is not just to show that skepticism is unjustified, or implausible, or that it is a position no one has reason to accept. Rather, his goal is to prevent skepticism from getting off the ground by denying skeptics their starting point. (173-4)\n\nBut we don’t get much of an interpretative argument that this is really Austin’s goal. Indeed, Soames concedes that Austin “doesn’t always approach these questions directly” (172). I’d say he does very little to approach them at all. To be sure, many contemporary defenders of direct realism are interested in its anti-sceptical powers, but there’s little to show Austin was so moved. Scepticism is not a topic that even arises in Sense and Sensibilia until the chapter on Warnock, after Austin has finished with the criticism of Ayer that takes up a large part of the book. And Soames doesn’t address the question of how to square the somewhat dismissive tone Austin takes towards scepticism in “Other Minds” with the view here propounded that Austin put forward a fairly radical theory of perception as a way of providing a new answer to the sceptic.\nIf Austin wasn’t trying to refute the sceptic, what was he trying to do? The simplest explanation is that he thought direct realism was true, sense-data theories were false, and that “there is noting so plain boring a the constant repetition of assertions that are not true, and sometimes no even faintly sensible; if we can reduce this a bit, it will all be to the good.” (Austin 1962, 5) I’m inclined to think that in this case the simplest explanation is the best, that Austin wrote a series of lectures on perception because he was interested in the philosophy of perception. Warnock says that “Austin was genuinely shocked by what appeared to his eye to be recklessness, hurry, unrealism, and inadequate attention to truth” (Warnock 1989, 154) and suggests this explained not only why Austin wrote the lectures but their harsh edge.\nThere is one larger point one might have wanted to make out of a discussion of direct realism, or that one might have learned from a discussion of direct realism, that seems relevant to what comes later in Soames’s book. If we really see objects, not sense-data, then objects are constituents of intentional states. That suggests that public objects might be constituents of other states, such as beliefs, and hence constituents of assertions. Soames doesn’t give us a discussion of these possible historical links between direct realism and direct reference, and that’s too bad because there could be some fertile ground to work over here. (I’m no expert on the history of the 1960s, so I’m simply guessing as to whether there is a historical link between direct realism and direct reference to go along with the strong philosophical link between the two. But it would be nice if Soames has provided an indication as to whether those guesses were likely to be productive or futile.)\nSoames gives us no inkling of where theories of direct reference came from, save from the brilliant mind of Kripke. Apart from the absence of discussion of any connection between direct realism and direct reference, there’s no discussion of the possible connections between Wittgenstein’s later theories and direct reference, as Howard Wettstein (2004) has claimed exist. And there’s no discussion of the (possibly related) fact that Kripke was developing the work that went into Naming and Necessity at the same time as he was lecturing and writing on Wittgenstein, producing the material that eventually became Wittgenstein on Rules and Private Language. Kripke is presented here as the first of the moderns2, and in many ways he is, but the ways in which he is the last (or the latest) of the ordinary language philosophers could be a very valuable part of a history of philosophy.3\n2 The first of what David Armstrong (2000) has aptly called “The Age of Conferences”.3 Just in case this gets misinterpreted, what I’m suggesting here is that Kripke (and his audiences) might have been influenced in interesting ways by philosophy of the 1950s and 1960s, not that Kripke took his ideas from those philosophers. The latter claim has been occasionally made, but on that ‘debate’ (Soames 1998b, 1998a) I’m 100% on Soames’s side.Matters are somewhat more difficult when it comes to Ryle’s The Concept of Mind. Ryle predicted that he would “be stigmatised as ‘behaviourist’” (Ryle 1949, 327) and Soames obliges, and calls him a verificationist to boot.\n\nIf beliefs and desires were private mental states [says Ryle], then we could never observe the beliefs and desires of others. But if we couldn’t observe them, then we couldn’t know that they exist, [which we can.] … This argument is no stronger than verificationism in general, which by 1949 when The Concept of Mind was published, had been abandoned by its main proponents, the logical positivists, for the simple reason that every precise formulation of it had been decisively refuted (97-8).\n\nBut Ryle’s position here isn’t verificationism at all, it’s abductophobia, or fear of inference to underlying causes. Ryle doesn’t think the claim of ghosts in the machine is meaningless, he thinks it is false. The kind of inference to underlying causes he disparages here is exactly the kind of inference to unobservables that paradigm verificationists, especially Ayer, go out of their way to allow, and in doing so buy all end of trouble.4 And abductophobia is prevalent among many contemporary anti-verificationists, particularly direct realists such as McDowell (1996), Brewer (1999) and Smith (2003) who think that if we don’t directly observe beer mugs we can never be sure that beer mugs exist. I basically agree with Soames that Ryle’s argument here (and the same style of argument recurs repeatedly in The Concept of Mind) is very weak, but it’s wrong to call it verificationist.\n4 It would be particularly poor form of me to use a paradigm case argument without discussing Soames’s very good dissection of Malcolm’s paradigm case argument in chapter 7 of his book. So let me note my gratitude as a Cornellian for all the interesting lines of inquiry Soames finds suggested in Malcolm’s paper – his is a paradigm of charitable interpretation, a masterful discovery of wheat where I’d only ever seen chaff.The issue of behaviourism is trickier. At one level Ryle surely is a behaviourist, because whatever behaviourism means in philosophy, it includes what Ryle says in The Concept of Mind. Ryle is the reference-fixer for at least one disambiguation of behaviourist. However we label Ryle’s views though, it’s hard to square what he says his aims are with the aims Soames attributes to him. In particular, consider Soames’s criticism of Ryle’s attempt to show that we don’t need to posit a ghost in the machine to account for talk of intelligence. (Soames is discussing a long quote from page 47 of The Concept of Mind.)\n\nThe description Ryle gives here is judicious, and more or less accurate. But it is filled with words and phrases that seem to refer to causally efficacious internal mental states—inferring, thinking, interpreting, responding to objections, being on the lookout for this, making sure not to rely on that, and so on. Unless all of these can be shown to be nothing more than behavioral dispositions, Ryle will not have succeeded in establishing that to argue intelligently is simply to manifest a variety of purely behavioral dispositions. (106)\n\nAnd Soames immediately asks\n\nSo what are the prospects of reducing all this talk simply to talk about what behavior would take place in various conditions? (106)\n\nThe answer, unsurprisingly, is that the prospects aren’t good. But why this should bother Ryle is never made clear. For Ryle only says that when we talk of mental properties we talk about people’s dispositions, not that we talk about their purely behavioural dispositions. The latter is Soames’s addition. It is rejected more or less explicitly by Ryle in his discussion of knowing how. “Knowing how, then, is a disposition, but not a single-track disposition like a reflex or a habit … its exercises can be overt or covert, deeds performed or deeds imagined, words spoken aloud or words heard in one’s head, pictures painted on canvas or pictures in the mind’s eye.” (1949, 46–47). Nor should Ryle feel compelled to say that these dispositions are behavioural, given his other theoretical commitments.\nRyle is opposed in general to talk of ‘reduction’ as the discussion of mechanism on pages 76ff shows. To be sure there he is talking about reduction of laws, but he repeatedly makes clear that he regards laws and dispositions as tightly connected (1949, 43, 123ff) and suggests that we use mental concepts to signal that psychological rather than physical laws are applicable to the scenario we’re discussing (167). Moreover, he repeatedly talks about mental events for which it is unclear there is any kind of correlated behavioural disposition, e.g. the discussion of Johnson’s stream of consciousness on page 58 and the extended discussion of imagination in chapter 8. Ryle’s claim that “Silent soliloquy is a form of pregnant non-sayings” (269) hardly looks like the claim of someone who wanted to reduce all mental talk to behavioural dispositions, unless one leans rather hard on ‘pregnant’. But we aren’t told whether Soames leans hard on this word, for he never quite tells us why he thinks all the dispositions that Ryle considers must be behavioural dispositions, rather than (for example) dispositions to produce other dispositions.\nTo be sure, from a modern perspective it is hard to see where the space is that Ryle aims to occupy. He wants to eliminate the ghosts, so what is left for mind to be but physical stuff, and what does physical stuff do but behave? He’s not an eliminativist, so he’s ontologically committed to minds, and he hasn’t left anything for them to be but behavioural dispositions. So we might see it (not unfairly) but that’s not how Ryle sees it.5 Soames sees Ryle as an ancestor of a reductive materialist like David Lewis, and a not very successful one at that. But the Ryle of The Concept of Mind has as much in common with non-reductive materialists, especially when he says that “not all questions are physical questions” (1949, 77), insists that “men are not machines, not even ghost-ridden machines” (1949, 81) and describes Cartesians rather than mechanists as “the better soldiers” (1949, 330) in the war against ignorance. Perhaps a modern anti-dualist should aim for a reduction of the mental to the physical, but Ryle thought no such reduction was needed to give up the ghost, and the historian should record this.\n5 Of course he couldn’t have seen it that way since in 1949 he wouldn’t have had the concept of ontological commitment.\n\n0.4 Conclusion\nAs I said at the top, Soames has written two really valuable books. For anyone who wants to really understand the most important philosophical work written between 1900 and 1970, reading through the classics while constantly referring back to Soames’s books to have the complexities of the philosophy explained will be immensely rewarding. Those who do that might feel that the people who skip reading the classics and just read Soames’s books get an unreasonably large percentage of the benefits they’ve accrued. As noted once or twice above I have some quibbles with some points in Soames’s story, but that shouldn’t let us ignore what a great service Soames has provided by providing these surveys of great philosophical work.\n\n\n\n\n\n\nReferences\n\nArmstrong, D. M. 2000. “Black Swans: The Formative Influences in Australian Philosophy.” In Rationality and Irrationality, edited by Berit Brogaard and Barry Smith, 11–17. Kirchberg: Austrian Ludwig Wittgenstein Society.\n\n\nAustin, J. L. 1962. Sense and Sensibilia. Oxford: Oxford University Press.\n\n\nBrewer, Bill. 1999. Perception and Reason. Oxford: Oxford University Press.\n\n\nGrice, H. Paul. 1989. Studies in the Way of Words. Cambridge, MA.: Harvard University Press.\n\n\nJackson, Frank. 1998. From Metaphysics to Ethics: A Defence of Conceptual Analysis. Clarendon Press: Oxford.\n\n\nKripke, Saul. 1980. Naming and Necessity. Cambridge: Harvard University Press.\n\n\nMcDowell, John. 1996. Mind and World. Cambridge, MA: Harvard University Press.\n\n\nRyle, Gilbert. 1949. The Concept of Mind. New York: Barnes; Noble.\n\n\n———. 1954. Dilemmas. Cambridge: Cambridge University Press.\n\n\nSmith, Michael. 2003. “Rational Capacities.” In Weakness of Will and Varities of Practical Irrationality, edited by Sarah Stroud and Christine Tappolet, 17–38. Oxford: Oxford University Press.\n\n\nSoames, Scott. 1998a. “More Revisionism about Reference.” In The New Theory of Reference, edited by Paul Humphreys and James Fetzer, 65–87. Dordrecht: Kluwer.\n\n\n———. 1998b. “Revisionism about Reference: A Reply to Smith.” In The New Theory of Reference, edited by Paul Humphreys and James Fetzer, 13–35. Dordrecht: Kluwer.\n\n\n———. 2003. Philosophical Analysis in the Twentieth Century. Princeton: Princeton University Press.\n\n\nWarnock, G. J. 1989. J. L. Austin. London: Routledge.\n\n\nWettstein, Howard. 2004. The Magic Prism. Oxford: Oxford University Press.\n\n\nWittgenstein, Ludwig. 1956. Remarks on the Foundations of Mathematics. New York: Macmillan."
  },
  {
    "objectID": "posts/ddd/index.html",
    "href": "posts/ddd/index.html",
    "title": "Deontology and Descartes’s Demon",
    "section": "",
    "text": "0.1 Digesting Evidence\nIn his Principles of Philosophy, Descartes says,\n\nFinally, it is so manifest that we possess a free will, capable of giving or withholding its assent, that this truth must be reckoned among the first and most common notions which are born with us. (Descartes 1644/2003, para. xxxix)\n\nIn this paper, I am going to defend a broadly Cartesian position about doxastic freedom. At least some of our beliefs are freely formed, so we are responsible for them. Moreover, this has consequences for epistemology. But the some here is crucial. Some of our beliefs are not freely formed, and we are not responsible for those. And that has epistemological consequences too. Out of these considerations a concept of doxastic responsibility arises that is useful to the externalist in responding to several challenges. I will say at some length how it supports a familiar style of externalism response to the New Evil Demon problem, and I will note some difficulties in reconciling internalism with the idea that justification is a kind of blamelessness. The internalist, I will argue, has to say that justification is a kind of praiseworthiness, and this idea that praise is more relevant to epistemic concepts than blame will be a recurring theme of the paper.\nWhile the kind of position I am adopting has been gaining supporters in recent years, it is still largely unpopular. The arguments of William Alston (1988) have convinced many that it is a mistake to talk of doxastic freedom, or doxastic responsibility. The short version of this argument is that our beliefs are involuntary, and freedom and responsibility require voluntariness. The longer, and more careful, argument involves drawing some distinctions between ways in which we might come to be in a state. It helps to start with an example where the normative facts are relatively uncontroversial, namely digestion.\nImagine that Emma eats a meat pie, and due to a malfunction in her stomach the pie is not properly digested, leading to some medical complications. Is Emma responsible for her ill-health? Well, that depends on the back-story. If Emma knew that she could not properly digest meat pies, but ate one anyway, she is responsible for the illness via her responsibility for eating the pie. Even if Emma did not know this, she might be responsible for the state of her stomach. If her stomach could not digest the pie because it had been damaged by Emma’s dietary habits, and say Emma knew that her diet could damage her stomach, then Emma is responsible for the state of her stomach and hence for the misdigestion of the pie and hence for her ill-health. But if neither of these conditions obtain, if it just happens that her stomach misdigests the pie, then Emma is not responsible for her ill-health. Even though the cause of her ill-health is something that her stomach does, he is not responsible for that since her stomach is not under her voluntary control. Put another way, her responsibility for maintaining her own health means that she is responsible for the type of digester she is, but he is not responsible for this token digestion.\nSimplifying a little, Alston thinks that the case of belief is similar. Say that Emma has a false belief that p. Is she responsible for this piece of doxastic ill-health? Again, that depends on the back story. If Emma believes that p because she was careless in gathering evidence, and the evidence would have pointed to ~p, then she is responsible for being a bad gatherer of evidence. If Emma has been negligent in maintaining her doxastic health, or worse if she has been doing things she knows endangers doxastic health, then she is responsible for being the type of believer she is. But she is never responsible merely for the token belief that is formed. Her mind simply digests the evidence she has, and Emma’s responsibility only extends to her duty to gather evidence for it, and her duty to keep her mind in good working order. She is not responsible for particular acts of evidential digestion.\nBut these particular acts of evidential digestion are the primary subject matters of epistemology. When we say Emma’s belief is justified or unjustified, we frequently mean that it is a good or bad response to the evidence in the circumstances. (I am obviously here glossing over enormous disputes about what makes for a good response, what is evidence, and what relevance the circumstances have. But most theories of justification can be fit into this broad schema, provided we are liberal enough in interpreting the terms ‘good’, ‘evidence’ and ‘circumstances’.) If Emma is not responsible for her response to the evidence, then either we have to divorce justification from responsibility, or we have to say that the concept of justification being used in these discussions is defective.\nWe can summarise these considerations as a short argument. The following formulation is from Sharon (Ryan 2003, 49).\n\nIf we have any epistemic obligations, then doxastic attitudes must sometimes be under our voluntary control.\nDoxastic attitudes are never under our voluntarily control.\nWe do not have any epistemic obligations.\n\nRyan goes on to reject both premises. (And she does so while interpreting “voluntary control” to mean “direct voluntary control”; the response is not meant to sidestep Alston’s argument.) Matthias Steup (2000, 2008) also rejects both premises of this argument. I am more sympathetic to premise 1, but I (tentatively) agree with them, against what sometimes seems to be orthodoxy, that premise 2 fails. That is, I endorse a kind of doxastic voluntarism. (Just what kind will become clearer as we go along.) There are four questions that anyone who endorses voluntarism, and wants to argue that this matters epistemologically, should I think answer. These are:\n\nWhat is wrong with current arguments against voluntarism?\nWhat does the voluntariness of (some) beliefs consist in?\nWhich kinds of beliefs are voluntary?\nWhat difference does the distinction between these classes make for epistemology?\n\nMy answer to (A) will be similar to Ryan’s, and to Steup’s, but with I think enough differences in emphasis to be worth working through. My answer to (B), however, will be a little more different. I am going to draw on some work on self-control to argue that some beliefs are voluntary because they are the result of exercises of, or failures to exercise, self-control. My answer to (C) is that what I will call inferential beliefs are voluntary, while perceptual beliefs are not. Ryan and Steup sometimes seem to suggest that even perceptual beliefs are voluntary, and I do not think this is true. The consequence for this, I will argue in answering (D), is that inferential beliefs should be judged by how well they respond to the evidence, while perceptual beliefs should be judged by how well they reflect reality. When an agent has misleading evidence, their inferential beliefs might be fully justified, but their perceptual beliefs, being misleading, are not.\nI will detail my answers to those four questions in sections 2, 4, 6 and 7. In between I will discuss recent work on self-control (section 3) and the contrast between my answer to (B) and other voluntarist answers (section 5). In section 8 I will say how my partially voluntarist position gives the externalist a way to avoid the New Evil Demon problem. And in section 9 I will make a direct argument for the idea that justification is a kind of praiseworthiness, not a kind of blamelessness.\nBefore we start, I want to note two ways, other than Ryan’s, of formulating an argument against doxastic responsibility. These are going to seem quite similar to Ryan’s formulation, but I think they hide important differences. The first version uses the idea that some doings (or states) are volitional. That is, we do them (or are in them) because we formed a volition to do so, and this volition causes the doing (or state) in the right kind of way.\n\nIf we have any epistemic obligations, then either the formation or maintenance of doxastic attitudes must sometimes be volitional.\nThe formation or maintenance of doxastic attitudes is never volitional.\nWe do not have any epistemic obligations.\n\nI will not argue against premise 2 of this argument, though Carl Ginet (1985, 2001) (1985, 2001) has done so. But I think there’s little to be said for premise 1. The principle behind it is that we are only responsible for volitional doings. And that principle is very dubious. We could run the kind of regress arguments against it that Gilbert Ryle (1949) offers. But it is simpler to note some everyday counterexamples. Borrowing an example from Angela M A. M. Smith (2005), if I forget a friend’s birthday, that is something I am responsible and blameworthy for, but forgetting a birthday is not volitional. (Below I will offer a Rylean argument that we are sometimes praiseworthy for doings that are not volitional.) So this argument fails. Alternatively, we could run the argument by appeal to freedom.\n\nIf we have any epistemic obligations, then doxastic attitudes must sometimes be free.\nDoxastic attitudes are never free.\nWe do not have any epistemic obligations.\n\nPremise 1 of this argument is more plausible. But, as we’ll see presently, premise 2 is not very plausible. Whether Descartes was right that premise 2 is obviously false, it does seem on reflection very hard to defend. So this argument fails. Ryan’s formulation is interesting because it is not clear just which of the premises fails. As I said, I am going to suggest that premise 2 fails, and that doxastic attitudes are voluntary. But this will turn on some fine judgments about the voluntary/involuntary boundary. If I am wrong about those judgments, then the arguments below will suggest that premise 1, not premise 2, in Ryan’s formulation fails. Either way though, the argument is unsuccessful.\n\n\n0.2 Responding to the Involuntarists\nThere are two kinds of argument against the idea that belief is voluntary. One kind, tracing back to Bernard Williams (1976), holds that the possibility of voluntary belief can be shown to be incoherent by reflection on the concept of belief. This argument is no longer widely endorsed. Nishi Shah (2002) provides an excellent discussion of the problems with Williams’ argument, and I have nothing to add to his work. I will focus on the other kind, that claims we can see that belief is involuntary by observing differences between beliefs and paradigm cases of voluntary actions. I will make three objections to these arguments. First, the argument looks much less plausible once we distinguish between having a belief and forming a belief. Second, the argument seems to rely on inferring from the fact that we do not do something (in particular, believe something that we have excellent evidence is false) to the conclusion that we can not do it. As Sharon Ryan (2003) points out, this little argument overlooks the possibility that we will not do it. Third, the argument relies on too narrow a conception of what is voluntary, and when we get a more accurate grasp on that concept, we’ll give up the argument. Here is a representative version of the argument from William Alston.\n\nCan you, at this moment, start to believe that the United States is still a colony of Great Britain, just by deciding to do so? … [S]uppose that someone offers you $500,000,000 to believe it, and you are much more interested in the money than in believing the truth. Could you do what it takes to get that reward? . . . Can you switch propositional attitudes toward that proposition just by deciding to do so? It seems clear to me that I have no such power. Volitions, decisions, or choosings don’t hook up with anything in the way of propositional attitude inauguration, just as they don’t hook up with the secretion of gastric juices or cell metabolism. (Alston 1988, 122)\n\nNow Alston does note, just one page earlier, that what is really relevant is whether our being in a state of belief is voluntary, not whether the activity of belief formation is voluntary. But he thinks nevertheless that issues about whether we can form beliefs, any old beliefs it seems, voluntarily matters to the question about the voluntariness of belief states.\nIf we think about what it is to be in a state voluntarily, this all seems beside the point. We can see this by considering what it is to be in a political state voluntarily. Consider Shane, who was born into Victoria. His coming to be in Victoria was hence not, in any way, voluntary. Shane is now a grown man, and he has heard many travellers’ tales of far away lands. But the apparent attractions of Sydney and other places have no pull on Shane; he has decided to stay in Victoria. If he has the capacity to leave Victoria, then Shane’s continued presence in Victoria is voluntary. Similarly, we are voluntarily in a belief state if we have the capacity to leave it, but choose not to exercise this capacity. Whether the belief was formed voluntarily is beside the point.\nIf Shane leaves a state, the natural place to leave is for another state, perhaps New South Wales or South Australia. It might be thought that if we leave a belief state, we have to move into another belief state. So to have this capacity to leave, we need the ability to form beliefs voluntarily. Not at all. The capacity to become uncertain, i.e. to not be in any relevant belief state, is capacity enough. (If Shane has a boat, and the capacity to flourish at sea, then perhaps he too can have the capacity to leave Victoria without the capacity to go into another state.)\nBut do we have the capacity to become uncertain? Descartes appeared to think so; arguably the point of the First Meditation is to show us how to exercise this capacity. Moreover, this capacity need not be one that we exercise in any particularly nearby possible worlds. We might exercise our freedom by always doing the right thing. As Descartes goes on to say in the Fourth Meditation.\n\nFor in order to be free, there is no need for me to be capable of going in each of two directions; on the contrary, the more I incline in one direction – either because I clearly understand that reasons of truth and goodness point that way, or because of a divinely produced disposition of my inmost thoughts – the freer is my choice. (Descartes 1641/1996, 40)\n\nThis seems like an important truth. Someone who is so sure of their own interests and values, and so strong-willed as to always aim to promote them, cannot in a certain sense act against their own self-interest and values. But this does not make their actions in defence of those interests and values unfree. If it did, we might well wonder what the value of freedom was. And note that even if there’s a sense that our character could not have done otherwise, this in no way suggests their actions are outside their control. Indeed, a person who systematically promotes the interests and values they have seems an exemplar of an agent in control. The character I am imagining here is in important respects unlike normal humans. We know we can, and do, act against our interests and values. But we can become more or less like them, and it is important to remember, as Descartes does, that in doing so we do not sacrifice freedom for values or interests.\nJohn Cottingham (2002) interprets Descartes here as suggesting that there is a gap between free action and voluntary action, contrasting his “strongly compatibilist notion of human freedom” (350) with the “doxastic involuntarism” (355) suggested by the following lines of the Third Meditation.\n\nYet when I turn to the things themselves which I think I perceive very clearly, I am so convinced by them that I spontaneously declare: let whoever can do so deceive me, he will never bring it about that I am nothing, so long as I continue to think that I am something … (Descartes 1641/1996, 25)\n\nNow there are two questions here. The first is whether Descartes intended to draw this distinction. That is, whether Descartes thought that the kind of free actions that he discusses in the Fourth Meditations, the free action where we are incapable of going in the other directions, are nevertheless involuntary. I do not have any informed opinions about this question. The second is whether this kind of consideration supports the distinction between the free and the voluntary. And it seems to me that it does not. Just as Descartes says the free person will be moved by reasons in the right way, it seems natural to say that a person who acts voluntarily will be responsive to reasons. Voluntary action does require freedom from certain kinds of coercion, but the world does not coerce us when it gives us reason to believe one thing rather than another. If we have voluntary control over our beliefs, then we should be compelled by the sight of rain to believe it is raining.\nIn her discussion of the puzzle of imaginative resistance, Tamar Szabó Gendler (2000) notes that philosophers have a tendency to read too much into intuitions about certain cases. What we can tell from various thought experiments is that in certain circumstances we will not do a certain thing. But getting from what we will not do to what we can not do is a tricky matter, and it is a bad mistake to infer from will not to can not too quickly. Matthias Steup (2000) points out that if you or I try to stick a knife into our hand, we similarly will not do it. (I assume a somewhat restricted readership here.) But this is no evidence that we cannot do it. And Sharon Ryan (2003) notes that we will not bring ourselves to run over pedestrians for no reason. For most of us, our moral sense prevents acting quite this destructively. Yet our continued avoiding of pedestrians is a series of free, even voluntary, actions. We could run over the pedestrians, but we will not. Since forming false beliefs is a form of self-harm, it is not surprising that it has a similar phenomenology, even if it is genuinely possible.\nIt might be argued that we will engage in small forms of self-harm that we can do when the financial rewards are great enough. So we should be able to form this belief about the United States for a large amount sum of money. But I suspect that the only way to exercise the capacity to believe the United States is still a colony is by first suspending my belief that it is no longer a colony. And the only way I can do that is by generally becoming more sceptical of what I have been told over the years. Once I get into such a sceptical mood, I will be sceptical of claims that I will get half a billion dollars should I have this wild political belief. So I will not form the belief in part because the ‘promisor’ lacks the capacity to sufficiently convince me that I will be richly rewarded for doing so. This looks like a lack of capacity on their part, not my part.\nThe final point to make about this argument, and those like it, is that if we are to conclude that belief formation is never voluntary, then we need to compare it to all kinds of voluntary action. And Alston really only ever compares belief formation to volitional action. If this does not exhaust the range of voluntary action, then belief formation might be properly analogous to some other voluntary action. Indeed, this turns out to be the case. To see so, we need to make a small detour through modern work on self-control.\n\n\n0.3 How to Control Your Temper\nTo start, let’s consider three examples of a person failing to keep a commitment they have made about what the good life is. The three ways will be familiar from Gary Watson’s discussion of recklessness, weakness and compulsion Watson (1977), and the discussion of these cases by Jeanette Kennett and Michael Smith Kennett and Smith (1996b, 1996a). My characterisation of the cases will turn out to differ a little from theirs, but the cases are similar. Each of the examples concerns a character Murray, who has decided that he should not swear around his young son Red. He resolves to do this, and has been working on curbing his tendency to swear whenever anything bad happens. But three times over the course of the day he breaks his commitment.1\n1 The cases, especially the second, were inspired by Richard Holton’s discussion of resolutions to prevent ‘automatic’ actions like smoking or sleeping in. See Holton (2003, 2004).The first time comes when Murray puts his hand down on a hot plate that he did not realise was on. The searing pain undermines his self-control, and he is unable to stop himself from swearing loudly through the pain.\nThe second time comes when Murray drops and breaks a wine glass. Murray does not lose his self-control, but he does not exercise the self-control he has. He temporarily forgets his commitment and so, quite literally, curses his misfortune. On doing so he immediately remembers that Red is around, and the commitment he has made, and regrets what he did.\nThe third time comes on the tram home, when Murray gets into a disagreement with a political opponent. Murray can not find the words to express what he feels about the opponent without breaking his commitment. So he decides, without much reason, that his need to express what he feels outweighs his commitment, and starts describing his opponent using language he would, all things considered, not have used around young Red.\nThe first and third cases are close to textbook cases of compulsion and recklessness. Note in the first case that when Murray reflects back on what happened, he might be irritated that his work on reducing his tendency to swear has not been more successful. But he will not be upset that he did not exercise more self-control on that occasion. He did not have, no normal person would have, the amount of self-control he would have needed to stop swearing then. All that would help is having the disposition to say different things when his self-control is defeated. And that is not a disposition he can acquire on the spot.\nI have described the first case as one where Murray’s self-control is undermined. This is a term taken from recent work by Richard Holton and Stephen Shute (2007), who carefully distinguish between self-control being undermined by a provocation, and it being overwhelmed by a provocation. Undermining occurs when the provocation causes the agent to have less self-control than they usually have; overwhelming occurs when the provocation is too much for the agent’s control. The difference is relevant to them, because they are interested in what it is for an agent to lose control. That seems to be what happens here. After all, the things one would naturally do afterwards (jumping around, screaming, swearing if one’s so disposed) do not seem particularly controlled by any measure.\nSimilarly I have accepted Watson’s description of cases like the third as instances of recklessness, but we should not think this necessarily contrasts with weakness. It might be that in this case Murray is both weak and reckless. He is not akratic, if we stipulatively define akrasia as acting against one’s better judgment. But if we accept Richard Holton’s view that weakness of will consists in being “too ready to reconsider their intentions” (Holton 1999, 241), then in this case Murray is weak-willed.2This seems to be the right way to talk about the case to me. With these details in place, we can talk about what’s crucial to this essay, the contrast with the second case.\n2 Whether Murray is akratic is a slightly more complicated question than I have suggested in the text. If akrasia is acting against one’s judgment, then he is not; if akrasia is acting against one’s considered judgment, then he is. ‘Akrasia’ is a technical term, so I do not think a huge amount turns on what we say about this question.\nThere is an interesting historical precedent for Holton’s theory of weakness of will. Ryle hints at a similar position to Holton’s when he says “Strength of will is a propensity the exercise of which consist in sticking to tasks’ that is, in not being deterred or diverted. Weakness of will is having too little of this propensity.” (1949, 73) But the idea is not well developed in Ryle. We’ll return below to the differences between Ryle’s and Holton’s theories.In the second case Murray fails to exercise self-control. He could have prevented himself from swearing in front of his son. Breaking a wine glass is irritating, but it neither undermines nor, necessarily, overwhelms self-control. Murray had the capacity to think about his resolution to not swear in front of Red. And if he had exercised this capacity, he would not have sworn when he did.\nIn the first case, Murray will only regret his lack of prior work at changing his dispositions in cases where his control fails. In the second case he will regret that, but he will also regret what he did on that occasion, for he could have kept his resolution, had only he thought of it. This regret seems appropriate, for in the second case he did something wrong at the time he swore, as well perhaps as having done something wrong earlier. (Namely, not having worked hard enough on his dispositions.) This difference in regret does not constitute the difference between compulsion and a case where self-control fails, but it is pretty good evidence that this is a failure of self-control.\nSo the second case is not one where Murray was compelled. He had the capacity to keep his commitment, and nothing was stopping him exercising this control, but he failed to do so. His failure was a failure of self-control. Murray’s self-control is, in this case, overwhelmed by the provocation. But it need not have been. Within some fairly broad limits, how much self-control we exercise is up to us.3 Murray’s failure of self-control is culpable because anyone with the capacity for self-control Murray has could have avoided breaking his commitment. I am not going to try to offer an analysis of what it is to have a capacity, but I suspect something like the complicated counterfactual analysis Kennett and Smith offer, and that Smith offers elsewhere (M. Smith 1997, 2003), is broadly correct.4\n3 Holton (2003) compares self-control to a muscle that we can exercise. We can make a similar point to the one in the text about physical muscles. If I try to lift a box of books and fail, that does not show I lack the muscular capacity to lift the box; I might not have been trying hard enough.4 (Ryle 1949, 71ff) also offers a counterfactual account of capacities that seems largely accurate.Kennett and Smith stress two things about this capacity that are worth noting here. First, having this kind of capacity is part of what it is to be rational. That is, being rational requires thinking of the right thing at the right time. As Ryle says, “Intelligently reflecting how to act is, among other things, considering what is pertinent and disregarding what is inappropriate.”(Ryle 1949, 31) Second, Kennett and Smith note that exercises of this capacity cannot be volitional. Following Davidson (1963), they say they cannot be actions. I find this terminology somewhat strained. Catching a fast moving ball is an action, I would say, but it does not seem to be volitional. So I will use ‘volitional action’ for this Davidsonian sense of action.\nMany recent philosophers have endorsed the idea that some of the mental states for which we hold people responsible are not voluntary, or at least are not volitional. Adams (1985; Heller 2000; Owens 2000) and Hieronymi (2008) note ways in which we appropriately blame people for being in certain states, where being in that state is not volitional. Something like this idea seems to be behind Ryle’s several regress arguments against the intellectualist legend. It just is not true that what we do divides cleanly into outcomes of conscious thought on the one hand, and mere bodily movements (a la digestion) on the other.5 Rather there is a spectrum of cases from pure ratiocination at one end to pure bodily movement at the other. And some of the things in the middle of this spectrum are proper subjects of reactive attitudes. The focus in this literature has been on blame, but some states in the middle of this spectrum are also praiseworthy.\n5 As I read him, Ryle takes this fact to reveal an important weakness in Descartes’ theory of mind.Consider some action that is strikingly imaginative, e.g. a writer’s apt metaphor or, say, a cricket captain’s imaginative field placements. It seems that, assuming the field settings are successful, the captain deserves praise for being so imaginative. But of course the captain did not, really could not, first intend to imagine such field settings, then carry out that intention. So something for which the captain deserves praise, his act of imagination, is not volitional. So not all praiseworthy things we do are volitional.\nThere are two responses to this argument that I can imagine, neither of them particularly plausible. First, we might think that the captain’s imagination is simply a remarkable feature of nature, as the Great Barrier Reef is. It is God, or Mother Nature, who should be praised, not the captain. Now it seems fair to react to some attributes of a person this way. A person does not deserve praise for having great eyesight, for example. But such a reaction seems grossly inappropriate, almost dehumanising, in this case. To be sure, we might also praise God or Mother Nature for yielding such an imaginative person, but we’ll do that as well as rather than instead of, praising the person. Second, we might praise the captain for his work in studying the game, and thinking about possible ways to dismiss batsmen, rather than this particular action. But if that is what we praise the captain for, we should equally praise the captain’s opponent, a hard working dullard. And that does not seem right. The hard-working dullard deserves praise for his hard work in the lead up, but the hard-working imaginative skipper deserves praise for what he does in the game too. So reactive attitudes, particularly praise, are appropriately directed at things people do even if these things are not volitional.\nThe key point of this section then is that responsibility outruns volition. Some actions are blameworthy because they are failures of self-control. Some actions are praiseworthy because they are wonderful feats of imagination. But neither failing to exercise self-control, nor exercising imagination, needs be volitional is order to be a locus of responsibility. I will argue in the next section that these considerations support the idea of responsibility for beliefs.\n\n\n0.4 Voluntariness about Belief\nHere is a situation that will seem familiar to anyone who has spent time in a student household. Mark is writing out the shopping list for the weekly grocery shop. He goes to the fridge and sees that there is a carton of orange juice in the fridge. He forms the belief that there is orange juice in the fridge, and hence that he does not need to buy orange juice. As it turns out both of these beliefs are false. One of his housemates finishes off the orange juice, but stupidly put the empty carton back in the fridge. When Mark finds this out, he is irritated at his housemate, but he is also irritated at himself. He did not have to draw the conclusion that there was orange juice in the fridge. He was, after all, living in a student house where people do all sorts of dumb things. That his housemate might have returned an empty container to the fridge was well within the range of live possibilities. Indeed had he even considered the possibility he would have thought it was a live possibility, and checked whether the container was empty before forming beliefs about what was needed for the shopping.\nExamples like this can be easily multiplied. There are all sorts of beliefs that we form in haste, where we could have stopped to consider the various realistic hypotheses consistent with the evidence, and doing so would have stopped us forming the belief. Indeed, unless one is a real master of belief formation, it should not be too hard to remember such episodes frequently from one’s everyday life. These conclusions that we leap to are voluntary beliefs; we could have avoided forming them. And not only could we have avoided these formations, but we would have if we had followed the methods for belief formation that we approve of. That seems enough, to me, to say the formation is voluntary. This is not the only way that voluntary doings, like calling a relevant possibility to mind, can matter to belief. The next example will be a little more controversial, but it points at the importance of dismissing irrelevant possibilities.\nLater that evening, Mark is watching his team, Geelong, lose another football game. Geelong are down by eight goals with fifteen minutes to go. His housemates are leaving to go see a movie, and want to know if Mark wants to come along. He says that he is watching the end of the game because Geelong might come back. One of his housemates replies, “I guess it is possible they’ll win. Like it is possible they’ll call you up next week to see if you want a game with them.” Mark replies, “Yeah, you are right. This one’s over. So, which movie?” Mark does nott just give in to his housemates, he forms the belief that Geelong will lose. Later that night, when asked what the result of the game was, he says that he did nott see the final score, but that Geelong lost by a fair bit. (In a recent paper (Weatherson 2005) I go into a lot more detail on the relation between not taking possibilities seriously, and having beliefs. The upshot is that what Mark does can count as belief formation, even if his credence that Geelong will lose does not rise.)\nNow it is tempting, or perhaps I should say that I am tempted, to view the housemate as offering Mark a reason to believe that Geelong will lose. We could view the housemate’s comments as shorthand for the argument that Geelong’s winning is as likely as Mark’s playing for Geelong, and since the latter will not happen, neither will the former. And maybe that is part of what the housemate is doing. But the larger part is that she is mocking Mark for his misplaced confidence. And the point of mocking someone, at least the point of constructive mockery like this, is to get them to change their attitudes. Mark does so, by ceasing to take seriously the possibility that Geelong will come back. In doing so, he exercises a capacity he had for a while, the capacity to cease taking this unserious possibility seriously, but needed to be prompted to use.\nIn both cases I say Mark’s belief formation is voluntary. In the first case he forms the belief because he does not exercise his doxastic self-control. He should have hesitated and not formed a belief until he checked the orange juice. And he would have done so if only he’d thought of the possibility that the container was empty. But he did not. And just as things we do because we do not bring the right thing to mind, like Murray’s swearing in the second case, are voluntary and blameworthy, Mark’s belief is voluntary and blameworthy. In the second case, he forms the belief by ceasing to take an unserious possibility seriously. In most cases of non-perceptual, non-testimonial belief formation, there is a counter-possibility that we could have taken seriously. Skill at being a believer involves not taking extreme possibilities, from Cartesian sceptical scenarios to unlikely footballing heroics, seriously. Exercises of such skill are rarely, if ever, volitional. But just like other mental activities that are not volitional can be voluntary and praiseworthy, not taking an extreme possibility seriously can be voluntary and praiseworthy.6\n6 (Ryle 1949, 29ff) stresses the importance of calling the right things to mind to rational thought and action. I am using a case here where Mark deliberately casts an option from his mind, but the more general point is that what possibilities we call to mind is a crucial part of rational action, and can be praiseworthy or blameworthy, whether or not it is volitional.7 Ryle seems to have taken an intermediate position. He holds, I think, the view that voluntary acts are culpable acts where we had the capacity to do otherwise (71). So Mark’s belief about the orange juice is voluntary because he had the capacity to retain doubt, and nothing prevented him exercising it. But the belief about the football is not voluntary because we should not talk about praiseworthy acts being voluntary or involuntary. The last point is the kind of error that (Grice 1989, Ch.1) showed us how to avoid.I have made two claims for Mark’s beliefs in the above two cases. First, they are instances of voluntary belief formation. In each case he could have done otherwise, either by exercising or failing to exercise his capacity to take various hypotheses seriously. Second, they are appropriate subjects of praise and blame. I imagine some people will agree with the second point but not the first. They will say that only volitional actions are voluntary, even though things we do like bringing relevant considerations to mind are praiseworthy or blameworthy. Such people will agree with most of what I say in this paper. In particularly they’ll agree that the examples involving Mark undermine Alston’s argument against the applicability of deontological concepts in epistemology. So I am not going to die in a ditch over just what we call voluntary. That is, I won’t fuss too much over whether we want to say premise 2 in Ryan’s formulation of the argument is shown to be false by these examples (as I say) or premise 1 is shown to be false (as such an objector will say.) I will just note that it is hard for such people to say intuitive things about the second instance of Murray’s swearing, and this seems like a strong reason to not adopt their position.7\n\n\n0.5 Ryan and Steup\nSharon Ryan has a slightly different view. She thinks that the truth of voluntarism consists in the fact that we hold certain beliefs intentionally. She does not offer an analysis of what it is to do something intentionally, except to say that consciously deciding to do something is not necessary for doing it intentionally, but doing it purposefully is (Ryan 2003, 70–71) In a similar vein, she says “When there’s a car zooming toward me and I believe that there is, I’m believing freely because I’m believing what I mean to believe.” (Ryan 2003, 74) This is said to be an intentional, and I take it a voluntary, belief.\nIt seems to me that there’s a large difference between things we voluntarily do, and things we mean to do, or do purposefully. There are several things we do voluntarily without meaning to do them. Murray’s swearing in the second example above is one instance. When we misspeak, or (as I frequently do) mistype, we do things voluntarily without meaning to do them. I do not mean by mistype cases where we simply hit the wrong key, but such cases as where I write in one more negation than I meant to, or, as I did earlier this evening, write “S is justified in believing that p” when I meant to write “S is justified in believing that she is justified in believing that p.” These are voluntary actions because I had the capacity to get it right, but did not exercise the capacity. But they are not things I meant to do. (I suspect there are also cases where we do things because we mean to do them, but they are not voluntary. These include cases where we train ourselves to produce a reflexive response. But I will not stress such cases here.)\nMatthias Steup (2008) argues that if compatibilism is true about free action, then our beliefs are free. His argument consists in running through the most plausible candidates to be compatibilist notions of freedom, and for each candidate that is plausible, showing that at least some of our beliefs satisfy the purported conditions on free actions. I agree with a lot of what Steup says, indeed this paper has been heavily influenced by what he says. But one crucial analogy fails I think. Steup is concerned to reject the premise that if \\(\\Phi\\)-ing is free, one \\(\\Phi\\)s because one has formed the intention to \\(\\Phi\\). His response centres around ‘automatic’ actions, such as the things we do when starting our drive to work: inserting the key, shifting into reverse, etc.\n\nThe question is whether they are caused by any antecedently formed intentions. I don’t think they are. … I didn’t form an intention to … shift into reverse…. I do things like that automatically, without thinking about them, and I assume you do too. But one can’t form an intention to \\(\\Phi\\) without thinking about \\(\\Phi\\)ing … Just one more example: I’d like to see the person who, just before brushing her teeth, forms the intention to unscrew the cap of the toothpaste tube. (Steup 2008, 383)\n\nI suspect that Steup simply has to look in the mirror. It is true that we do not usually form conscious intentions to shift into reverse, or unscrew the cap, but not all intentions are conscious. If we were asked later, perhaps by someone who thought we’d acted wrongly, whether we intended to do these things, the natural answer is yes. The best explanation of this is that we really did have an intention to do them, albeit an unconscious one. (I am indebted here to Ishani Maitra.)\nSteup is right that free actions do not require a prior intention, but his examples do not quite work. The examples I have used above are the Rylean regress stoppers, such as acts of imagination, and actions that we do because we did not think, like Murray’s swearing. If asked later whether he intended to say what he said, Murray would say yes in the third example, but (I think) no in the first and second. Intuitively, I think, he did not have such an intention.8\n8 If so, Murray is not weak-willed according to Holton’s theory of will, but, since he does not keep his resolution, he is weak-willed according to Ryle’s otherwise similar theory. This seems to be an advantage of Holton’s theory over Ryle’s. Murray’s problem is not that his will was weak, it is that it was not called on. More generally, Ryle’s identification of weakness of will with irresoluteness seems to fail for people who frequently forget their resolutions. These people are surely irresolute, but (in agreement with Holton’s theory) I think they are not weak-willed.\n\n0.6 Involuntarism about Perceptual Beliefs\nIn some early 1990s papers, Daniel Gilbert and colleagues defended a rather startling thesis concerning the relation of comprehension and belief (Gilbert, Krull, and Malone 1990; Gilbert 1991; Gilbert, Tafarodi, and Malone 1993) Casual introspection suggests that when one reads or hears something, one first comprehends it and then, if it is backed by sufficient reasons, believes it. Gilbert (1991) argues against this seeming separation of comprehension and belief, and in favour of a view said to derive from Spinoza. When we comprehend a sentence, we add it to our stock of beliefs. If the new belief is implausible given our old beliefs, then we “unbelieve” it.9\n9 The evidence for this view is set out in Gilbert, Krull, and Malone (1990; Gilbert, Tafarodi, and Malone 1993).We may picturesquely compare the two models of belief and comprehension to two models for security. The way security works at a nightclub is that anyone can turn up at the door, but only those cleared by the guards are allowed in. On the other hand, the way security works at a shopping mall is that anyone is allowed in, but security might remove those it regards as undesirable. Intuitively, our minds work on the nightclub model. A hypothesis can turn up and ask for admission, but it has to be approved by our cognitive security before we adopt it as a belief. Gilbert’s position is that we work on the shopping mall model. Any hypothesis put in front of us is allowed in, as a belief, and the role of security is to remove troublemakers once they have been brought inside.\nNow I do not want to insist Gilbert’s theory is correct. The experimental evidence for it is challenged in a recent paper (Hasson, Simmons, and Todorov 2005). But I do want to argue that if it is correct, then there is a kind of belief that is clearly involuntary. We do not have much control over what claims pass in front of our eyes, or to our ears. (We have some indirect control over this – we could wear eye shades and ear plugs – but no direct control, which is what’s relevant.) If all such claims are believed, these are involuntary beliefs. To be sure, nothing Gilbert says implies that we can not quickly regain voluntary control over our beliefs as we unbelieve the unwanted inputs. But in the time it takes to do this, our beliefs are out of our control.\nGilbert’s theory is rather contentious, but there are other kinds of mental representations that it seems clear we can not help forming. In The Modularity of Mind, Jerry Fodor (1983) has a long discussion of how the various input modules that he believes to exist are not under our voluntary control.10 If I am sitting on a train opposite some people who are chatting away, I can not help but hear what they say. (Unless, perhaps, I put my fingers in my ear.) This is true not just in the sense that I can not help receive the sound waves generated by their vocalisations. I also can not help interpreting and comprehending what they are saying. Much as I might like to not be bothered with the details of their lives, I can not help but hear what they say as a string of English sentences. Not just hearing, but hearing as happens automatically.\n10 As he says, they have a mandatory operation. See pages 52-55 in particular, but the theme is central to the book.This automatic ‘hearing as’ is not under my voluntary control. I do not do it because I want to do it, or as part of a general plan that I endorse or have chosen to undertake. It does not reflect any deep features of my character. (Frankly I would much rather that I just heard most of these conversations as meaningless noise, like the train’s sound.) But I do it, involuntarily, nonetheless. This involuntariness is reflected in some of our practices. A friend tells me not to listen to X, because X is so often wrong about everything. Next I see the friend I say that I now believe that p, and when the friend asks why, I say it is because X said that p. The friend might admonish me. They will not admonish me for being within hearing range of X; that might have been unavoidable. And, crucially, they will not admonish me for interpreting X’s utterances. Taken literally, that might be what they were asking me not to do. But they’ll know it was unavoidable. What they were really asking me not to do was the one relevant thing that I had control over, namely believe what X said.\nAs Fodor points out at length, both seeing as and hearing as are generally outside voluntary control. Our perceptual systems, and by this I am including verbal processing systems, quickly produce representations that are outside voluntary control in any sense. If any of these representations amount to beliefs, then there are some involuntary beliefs that we have. So we might think that in the case above, although it was up to me to believe that p, it was not up to me to believe that, say, X said that p, because this belief was produced by a modular system over which I have no control.\nThis is not the position that Fodor takes. He thinks that beliefs are not produced by input modules. Rather, the non-modular part of the mind, the central processor, is solely responsible for forming and fixing beliefs. And the operation of this central processor is generally not mandatory, at least not in the sense that the operation of the modules is mandatory. Whether this is right seems to turn (in part) on a hard question to do with the analysis of belief.\nLet us quickly review Fodor’s views on the behaviour of input modules. The purpose of each module is to, within a specified domain, quickly and automatically produce representations of the world. These are, as on the nightclub model, then presented to cognition to be allowed in as beliefs or not. Here is how Fodor puts it.\n\nI am supposing that input systems offer central processes hypotheses about the world, such hypotheses being responsive to the current, local distribution of proximal stimulations. The evaluation of these hypotheses in light of the rest of what one knows is one of the things that central processes are for; indeed, it is the fixation of perceptual belief.(Fodor 1983, 136)\n\nBut these representations do not just offer hypotheses. They can also guide action prior to being ‘approved’ by the central processes. That, at least, seems to be the point of Fodor’s discussion of the evolutionary advantages of having fast modules (Fodor 1983, 70–71). The core idea is that when one is at risk of being eaten by a panther, there is much to be said for a quick, automatic, panther recognition device. But there is just as much to be said for acting immediately on one’s panther recognition capacities rather than, say, searching for possible reasons why this panther appearance might be deceptive. And browsing reason space for such evidence of deceptions is just what central processes, in Fodor’s sense, do. So it seems the natural reaction to seeing a panther should be, and is, guided more-or-less directly by the input modules not central processes.\nSo these ‘hypotheses’ are representations with belief-like direction of fit, i.e. they are responsive to the world, that guide action in the way that beliefs do. These are starting to sound a lot like beliefs. Perhaps we should take a Gilbert-style line and say that we automatically believe what we perceive, and the role of Fodorian central processes is not to accept or reject mere hypotheses, but to unbelieve undesirable inputs.11 There are a number of considerations that can be raised for and against this idea, and perhaps our concept of belief is not fine enough to settle the matter. But let’s first look at three reasons for thinking these inputs are not beliefs.\n11 To be clear, the position being considered here is not that we automatically believe p when someone says p to us, but that we automatically believe that they said that p.First, if they are beliefs then we are often led into inconsistency. If we are looking at a scene we know to be illusory, then we might see something as an F when we know it is not an F. If the outputs of visual modules are beliefs, then we inconsistently believe both that it is and is not F. Perhaps this inconsistency is not troubling, however. After all, one of the two inconsistent beliefs is involuntary, so we are not responsible for it. So this inconsistency is not a sign of irrationality, just a sign of defective perception. And that is not something we should be surprised by; the case by definition is one where perception misfires.\nSecond, the inputs do not, qua inputs, interact with other beliefs in the right kind of way. Even if we believe that if p then q, and perceive that p, we will not even be disposed to infer that q unless and until p gets processed centrally. On this point, see Stich (1978) and (Fodor 1983, 83–86). The above considerations in favour of treating inputs as beliefs turned heavily on the idea that they have the same functional characteristics as paradigm beliefs. But as David Braddon-Mitchell and Frank Jackson (2007, 114–23) stress, functionalism can only be saved from counterexamples if we include these inferential connections between belief states in the functional charactisation of belief. So from a functionalist point of view, the encapsulation of input states counts heavily against their being beliefs.\nFinally, if Fodor is right, then the belief-like representation of the central processes form something like a natural kind. On the other hand, the class consisting of these representations plus the representations of the input modules looks much more like a disjunctive kind. Even if all members of the class play the characteristic role of beliefs, we might think it is central to our concept of belief that belief is a natural kind. So these inputs should not count as beliefs.\nOn the other hand, we should not overestimate the role of central processes, even if Fodor is right that central processes are quite different to input systems. There are two related features of the way we process inputs that point towards counting some inputs as beliefs, and hence as involuntary beliefs. The first feature is that we do not have to put any effort into believing what we see. On the contrary, as both Descartes and Hume were well aware, we believe what we see by default, and have to put effort into being sceptical. The second feature is that, dramatic efforts aside, we can only be so sceptical. Perhaps sustained reflection on the possibility of an evil demon can make us doubt all of our perceptions at once. But in all probability, at least most of the time, we can not doubt everything we see and hear.12 We can perhaps doubt any perceptual input we receive, but we can not doubt them all.\n12 As noted in the last footnote, when I talk here about what we hear, I mean to include propositions of the form S said that p, not necessarily the p that S says.In the picturesque terms from above, we might think our security system is less like a nightclub and more like the way customs appears to work at many airports. (Heathrow Airport is especially like this, but I think it is not that unusual.) Everyone gets a cursory glance from the customs officials, but most people walk through the customs hall without even being held up for an instant, and there are not enough officials to stop everyone even if they wanted to. Our central processes, faced with the overwhelming stream of perceptual inputs, are less the all-powerful nightclub bouncer and more the overworked customs official, looking for the occasional smuggler who should not be getting through.\nThe fact that inputs turn into fully fledged beliefs by default is some reason to say that they are beliefs as they stand. It is noteworthy that what Gilbert et al’s experiments primarily tested was whether sentences presented to subjects under cognitive load ended up as beliefs of the subjects. Now this could be because comprehending a sentence implies, at least temporarily, believing it. But perhaps a more natural reading in the first instance is that inputted sentences turn into beliefs unless we do something about it. Gilbert et al are happy inferring that in this case, the inputs are beliefs until and unless we do that something. This seems to be evidence that the concept of belief philosophers and psychologists use include states that need to be actively rejected if they are not to acquire all the paradigm features of belief. And that includes the inputs from Fodorian modules.\nThat argument is fairly speculative, but we can make more of the fact that subjects can not stop everything coming through. This implies that there will be some long disjunctions of perceptual inputs that they will end up believing no matter how hard they try. Any given input can be rejected, but subjects only have so much capacity to block the flow of perceptual inputs. So some long disjunctions will turn up in their beliefs no matter how hard they try to keep them out. I think these are involuntary beliefs.\nSo I conclude tentatively that perceptual inputs are involuntary beliefs, at least for the time it would take the central processes to evaluate them were it disposed to do so. And I conclude less tentatively that subjects involuntarily believe long disjunctions of perceptual inputs. So some beliefs are involuntary.\nSpace considerations prevent a full investigation of this, but there is an interesting connection here to some late medieval ideas about evidence. In a discussion of how Descartes differed from his medieval influences, Matthew L. Jones writes “For Descartes, the realignment of one’s life came about by training oneself to assent only to the evident; for the scholastics, assenting to the evident required no exercise, as it was automatic.” [Jones (2006) 84]13 There is much contemporary interest in the analysis of evidence, with Timothy Williamson’s proposal that our evidence is all of our knowledge being a central focus (Williamson 2000 Ch. 9). I think there’s much to be said for using Fodor’s work on automatic input systems to revive the medieval idea that the evident is that which we believe automatically, or perhaps it is those pieces of knowledge that we came to believe automatically. As I said though, space prevents a full investigation of these interesting issues.\n13 Jones attributes this view to Scotus and Ockham, and quotes Pedro Fonseca as saying almost explicitly this in his commentary on Aristotle’s Metaphysics.\n\n0.7 Epistemological Consequences\nSo some of our beliefs, loosely speaking the perceptual beliefs, are spontaneous and involuntary, while other beliefs, the inferential beliefs, are voluntary in that we have the capacity to check them by paying greater heed to counter-possibilities. (In what follows it will not matter much whether we take the spontaneous beliefs to include all the perceptual inputs, or just the long disjunctions of perceptual inputs that are beyond our capacity to reject. I will note the few points where it matters significantly.) This has some epistemological consequences, for the appropriate standards for spontaneous, involuntary beliefs are different to the appropriate standards for considered, reflective beliefs. I include in the latter category beliefs that were formed when considered reflection was possible, but was not undertaken.\nTo think about the standards for spontaneous beliefs, start by considering the criteria we could use to say that one kind of animal has a better visual system than another. One dimension along which we could compare the two animals concerns discriminatory capacity – can one animal distinguish between two things that the other cannot distinguish? But we would also distinguish between two animals with equally fine-grained visual representations, and the way we would distinguish is in terms of the accuracy of those representations. Some broadly externalist, indeed broadly reliabilist, approach has to be right when it comes to evaluating the visual systems of different animals.\nThings are a little more complicated when it comes to evaluating individual visual beliefs of different animals, but it is still clear that we will use externalist considerations. So imagine we are looking for standards for evaluating particular visual beliefs of again fairly basic animals. One very crude externalist standard we might use is that a belief is good iff it is true. Alternatively, we might say that the belief is good iff the process that produces it satisfied some externalist standard, e.g. it is generally reliable. Or we might, in a way, combine these and say that the belief is good iff it amounts to knowledge, incorporating both the truth and reliability standards. It is not clear which of these is best. Nor is it even clear which, if any, animals without sophisticated cognitive systems can be properly said to have perceptual beliefs. (I will not pretend to be able to evaluate the conceptual and empirical considerations that have been brought to bear on this question.) But what is implausible is to say that these animals have beliefs, and the relevant epistemic standards for evaluating these beliefs are broadly internal.\nThis matters to debates about the justificatory standards for our beliefs because we too have perceptual beliefs. And the way we form perceptual beliefs is not that different from the way simple animals do. (If the representations of input processes are beliefs, then it does not differ in any significant way.) When we form beliefs in ways that resemble those simple believers, most notably when we form perceptual beliefs, we too are best evaluated using externalist standards. The quality of our visual beliefs, that is, seems to directly track the quality of our visual systems. And the quality of our visual system is sensitive to external matters. So the quality of our visual beliefs is sensitive to external matters.\nOn the other hand, when we reason, we are doing something quite different to what a simple animal can do. A belief that is the product of considered reflection should be assessed, inter alia, by assessing the standards of the reflection that produced it. To a first approximation, such a belief seems to be justified if it is well supported by reasons. Some reasoners will be in reasonable worlds, and their beliefs will be mostly true. Some reasoners will be in deceptive worlds, and many of their beliefs will be false. But this does not seem to change what we say about the quality of their reasoning. This, I take it, is the core intuition behind the New Evil Demon problem, that we’ll address much more below.\nSo we’re naturally led to a view where epistemic justification has a bifurcated structure. A belief that is the product of perception is justified iff the perception is reliable; a belief that is (or could have been) the product of reflection is justified iff it is well-supported by reasons.14 This position will remind many of Ernest Sosa’s view that there is animal knowledge, and higher knowledge, or scientia (Sosa 1991, 1997). And the position is intentionally similar to Sosa’s. But there is one crucial difference. On my view, there is just one kind of knowledge, and the two types of justification kick in depending on the kind of knower, or the kind of knowing, that is in question. If we simply form perceptual beliefs, without the possibility of reconsidering them (in a timely manner), then if all goes well, our beliefs are knowledge. Not some lesser grade of animal knowledge, but simply knowledge. To put it more bluntly, if you’re an animal, knowledge just is animal knowledge. On the other hand, someone who has the capacity (and time) to reflect on their perceptions, and fails to do so even though they had good evidence that their perceptions were unreliable, does not have knowledge. Their indolence defeats their knowledge. Put more prosaically, the more you are capable of doing, the more that is expected of you.\n14 There is a delicate matter here about individuating beliefs. If I look up, see, and hence believe it is raining outside, that is a perceptual belief. I could have recalled that it was raining hard a couple of minutes ago, and around here that kind of rain does not stop quickly, and formed an inferential belief that it was raining outside. I want to say that that would have been a different belief, although it has the same content. If I do not say that, it is hard to defend the position suggested here when it comes to the justificatory status of perceptual beliefs whose contents I could have otherwise inferred.\n\n0.8 The New Evil Demon Problem\nThe primary virtue of the above account, apart from its intuitive plausibility, is that it offers a satisfactory response to the New Evil Demon argument. The response in question is not new; it follows fairly closely the recent response due to Clayton Littlejohn (2009), who in turn builds on responses due to Kent Bach (1985) and Mylan Engel (1992). But I think it is an attractive feature of the view defended in this paper that it coheres so nicely with a familiar and attractive response to the argument.\nThe New Evil Demon argument concerns victims of deception who satisfy all the internal standards we can imagine for being a good epistemic agent. So they are always careful to avoid making fallacious inferences, they respect the canons of good inductive and statistical practice, they do not engage in wishful thinking, and so on. The core intuition of the New Evil Demon argument is that although these victims do not have knowledge (because their beliefs are false), they do have justified beliefs. Since the beliefs do not satisfy any plausible externalist criteria of justification, we conclude that no externalist criteria can be correct. The argument is set out by Stewart Cohen (1984).\nA fairly common response is to note that even according to externalist epistemology there will be some favourable epistemic property that the victim’s beliefs have, and this can explain our intuition that there is something epistemically praiseworthy about the victim’s beliefs. My approach is a version of this, one that is invulnerable to recent criticisms of the move. For both this response and the criticism to it, see James Pryor (2001). I am going to call my approach the agency approach, because the core idea is that the victim of the demon is in some sense a good doxastic agent, in that all their exercises of doxastic agency are appropriate, although their perception is quite poor and this undermines their beliefs.\nAs was noted above, the quality of our visual beliefs is sensitive to external matters. This is true even for the clear-thinking victim of massive deception. Denying that the victim’s visual beliefs are as good as ours is not at all implausible; indeed intuition strongly supports the idea that they are not as good. What they are as good at as we are is exercising their epistemic agency. That is to say, they are excellent epistemic agents. But since there is more to being a good believer than being a good epistemic agent, there is also for example the matter of being a good perceiver, they are not as good at believing as we are.\nSo the short version of my response to the New Evil Demon problem is this. There are two things we assess when evaluating someone’s beliefs. We evaluate how good an epistemic agent they are. And we evaluate how good they are at getting evidence from the world. Even shorter, we evaluate both their collection and processing of evidence. Externalist standards for evidence collection are very plausible, as is made clear when we consider creatures that do little more than collect evidence. The intuitions that the New Evil Demon argument draws on come from considering how we process evidence. When we consider beliefs that are the products of agency, such as beliefs that can only be arrived at by extensive reflection, we naturally consider the quality of the agency that led to those beliefs. In that respect a victim might do as well as we do, or even better. But that is no threat to the externalist conclusion that they are not, all things considered, as good at believing as we are.\nAs I mentioned earlier, this is similar to a familiar response to the argument that James Pryor considers and rejects. He considers someone who says that what is in common to us and the clear-thinking victim is that we are both epistemically blameless. The objection he considers says that the intuitions behind the argument come from confusing this notion of being blameless with the more general notion of being justified. This is similar to my idea that the victim might be a good epistemic agent while still arriving at unjustified beliefs because they are so bad at evidence collection. But Pryor argues that this kind of deontological approach cannot capture all of the intuitions around the problem.\nPryor considers three victims of massive deception. Victim A uses all sorts of faulty reasoning practices to form beliefs, practices that A could, if they were more careful, could see were faulty. Victim B was badly ‘brought up’, so although they use methods that are subtly fallacious, there is no way we could expect B to notice these mistakes. Victim C is our paradigm of good reasoning, though of course C still has mostly false beliefs because all of their apparent perceptions are misleading. Pryor says that both B and C are epistemically blameless; C because they are a perfect reasoner and B because they cannot be blamed for their epistemic flaws. But we intuit that C is better, in some epistemic respects, than B. So there is some internalist friendly kind of evaluation that is stronger than being blameless. Pryor suggests that it might be being justified, which he takes to be an internalist but non-deontological concept.\nThe agency approach has several resources that might be brought to bear on this case. For one thing, even sticking to deontological concepts we can make some distinctions between B and C. We can, in particular, say that C is epistemically praiseworthy in ways that B is not. Even if B cannot be blamed for their flaws, C can be praised for not exemplifying those flaws. It is consistent with the agency approach to say that C can be praised for many of their epistemic practices while saying that, sadly, most of C’s beliefs are unjustified because they are based on faulty evidence, or on merely apparent evidence.\nThe merits of this kind of approach can be brought out by considering how we judge agents who are misled about the nature of the good. Many philosophers think that it is far from obvious which character traits are virtues and which are vices. Any particular example is bound to be controversial, but I think it should be uncontroversial that there are some such examples. So I will assume that, as Simon Keller (2005) suggests, it is true but unobvious that patriotism is not a virtue but a vice.\nNow consider three agents D, E and F. D takes patriotism to extremes, developing a quite hostile strand of nationalism, which leads to unprovoked attacks on non-compatriots. E is brought up to be patriotic, and lives this way without acting with any particular hostility to foreigners. F is brought up the same way, but comes to realise that patriotism is not at all virtuous, and comes to live according to purely cosmopolitan norms. Now it is natural to say that D is blameworthy in a way that E and F are not. As long as it seems implausible to blame E for not working through the careful philosophical arguments that tell against following patriotic norms, we should not blame E for being somewhat patriotic. But it is also natural to say that F is a better agent than either D or E. That is because F exemplifies a virtue, cosmopolitanism, that D and E do not, and does not exemplify a vice, patriotism, that D and E do exemplify. F is in this way praiseworthy, while D and E are not.\nThis rather strongly suggests that when agents are misled about norms, a gap will open up between blamelessness and praiseworthiness. We can say that Pryor’s victim C is a better epistemic agent than A or B, because they are praiseworthy in a way that A and B are not. And we can say this even though we do not say that B is blameworthy and we do not say that being a good epistemic agent is all there is to being a good believer.\nAt this point the internalist might respond with a new form of the argument. A victim of deception is, they might intuit, just as praiseworthy as a regular person, if they perform the same inferential moves. I think at this point the externalist can simply deny the intuitions. In general, praiseworthiness is subject to a degree of luck. (Arguably blameworthiness is as well, but saying so sounds somewhat more counterintuitive than saying praiseworthiness is a matter of luck.) For example, imagine two people dive into ponds in which they believe there are drowning children. The first saves two children. The second was mistaken; there are no children to be rescued in the pond they dive into. Both are praiseworthy for their efforts, but they are not equally praiseworthy. The first, in particular, is praiseworthy for rescuing two children. As we saw in the examples of the writer and the good cricket captain above, praiseworthiness depends on outputs as well as inputs, and if the victim of deception produces beliefs that are defective, i.e. false, then through no fault of their own they are less praiseworthy.\n\n\n0.9 Praise and Blame\nAs Pryor notes, many philosophers have thought that a deontological conception of justification supports an internalist theory of justification. I rather think that is mistaken, and that at least one common deontological understanding of what justification is entails a very strong kind of externalism. This is probably a reason to not adopt that deontological understanding.\nAssume, for reductio, that S’s belief that p is justified iff S is blameless in believing that p. I will call this principle J=B to note the close connection it posits between justification and blamelessness. Alston (1988) seems to identify the deontological conception of justification with J=B, or at least to slide between the two when offering critiques. But one of Alston’s own examples, the ‘culturally isolated tribesman’, suggests a principle that can be used to pull these two ideas apart. The example, along with Pryor’s three brains case, suggests that A1 is true.\n\nA1\n\nIt is possible for S to have a justified but false belief that her belief in p is justified.\n\n\nA1 is a special instance of the principle that justification does not entail truth. Some externalists about justification will want to reject the general principle, but all internalists (and indeed most externalists) will accept it. Now some may think that the general principle is right, but that beliefs about what we are justified in believing are special, and if they are justified they are true. But such an exception seems intolerably ad hoc. If we can have false but justified beliefs about some things, then presumably we can have false but justified beliefs about our evidence, since in principle our evidence could be practically anything. So the following situation seems possible; indeed it seems likely that something of this form happens frequently in real life. S has a false but justified belief that e is part of her evidence. S knows both that anyone with evidence e is justified in believing p in the absence of defeaters, and that there are no defeaters present. So S comes to believe, quite reasonably, that she is justified in believing that p. But S does not have this evidence, and in fact all of her evidence points towards ~p.15 So it is false that she is justified in believing p.\n15 I am assuming here that evidence of evidence need not be evidence. This seems likely to be true. In Bayesian terms, something can raise the probability of e, while lowering the probability of p, even though the probability of p given e is greater than the probability of p. Bayesian models are not fully general, but usually things that are possible in Bayesian models are possible in real life.The following principle seems to be a reasonable principle concerning blameless inference.\n\nA2\n\nIf S blamelessly believes that she is justified in believing that p, and on the basis of that belief comes to believe that p, then she is blameless in believing that p.\n\n\nThis is just a principle of transfer of blameworthiness. The quite natural thought is that you do not become blameworthy by inferring from I am justified in believing p to p. This inference is clearly not necessarily truth-preserving, but that is not a constraint on inferences that transfer blameworthiness, since not all ampliative inferences are blameworthy. (Indeed, many are praiseworthy.) And it is hard to imagine a less blameworthy ampliative inference schema than this one.\nWe can see this more clearly with an example of A2. Suzy sees a lot of Fs and observes they are all Gs. She infers that it is justified for her to conclude that all Fs are Gs. Now it turns out this is a bad inference. In fact, G is a gruesome predicate in her world, so that is not a justified inference. But Suzy, like many people, does not have the concept of gruesomeness, and without it had no reason to suspect that this would be a bad inference. So she is blameless. If all that is correct, it is hard to imagine that she becomes blameworthy by actually inferring from what she has so far that all Fs are in fact Gs. Perhaps you might think her original inference, that it is justified to believe all Fs are Gs, was blameworthy, but blame can not kick in for the first time when she moves to the first order belief.\nI am now going to derive a contradiction from A1, A2 and J=B, and a clearly consistent set of assumptions about a possible case of belief.\n\nS justifiedly, but falsely, believes that she is justified in believing p. (Assumption - A1)\nOn the basis of this belief, S comes to believe that p. (Assumption)\nS blamelessly believes that she is justified in believing that p. (1, J=B)\nS blamelessly believes that p. (2, 3, A2)\nS is justified in believing that p. (4, J=B)\nIt is false that S is justified in believing that p. (1)\n\nOne of A1, A2 and J=B has to go. If you accept J=B, I think it has got to be A1, since A2 is extremely plausible. But A1 only fails if we accept quite a strong externalist principle of justification, namely that justification entails truth. More precisely, we’re led to the view that justification entails truth when it comes to propositions about our own justification. But as we saw above, that pretty directly implies that justification entails truth when it comes to propositions about our own evidence. And, on the plausible assumption that evidence can be practically anything, that leads to there being a very wide range of cases where justification entails truth. So J=B entails this strong form of externalism.\nThis does not mean that internalists cannot accept a deontological conception of justification. But the kind of deontological conception of justification that is left standing by this argument is quite different to J=B, and I think to existing deontological conceptions of justification. Here’s what it would look like. First, we say that a belief’s being justified is not a matter of it being blameless, but a matter of it being in a certain way praiseworthy. Second, we say that the inference from I am justified in believing that p to p is not praiseworthy if the premise is false. So if we tried to run the above argument against J=P (the premise that justified beliefs are praiseworthy) it would fail at step 4. So anyone who wants to hold that justification is (even in large part) deontological, and wants to accept that justification can come apart from truth, should hold that justification is a kind of praiseworthiness, not a kind of blamelessness.\n\n\n\n\n\n\nReferences\n\nAdams, Robert Merrihew. 1985. “Involuntary Sins.” Philosophical Review 94 (1): 3–31. https://doi.org/10.2307/2184713.\n\n\nAlston, William. 1988. “The Deontological Conception of Epistemic Justification.” Philosophical Perspectives 2: 257–99. https://doi.org/10.2307/2214077.\n\n\nBach, Kent. 1985. “A Rationale for Reliabilism.” Monist 68 (2): 246–63. https://doi.org/10.5840/monist198568224.\n\n\nBraddon-Mitchell, David, and Frank Jackson. 2007. The Philosophy of Mind and Cognition, Second Edition. Malden, MA: Blackwell.\n\n\nCohen, Stewart. 1984. “Justification and Truth.” Philosophical Studies 46 (3): 279–95. https://doi.org/10.1007/bf00372907.\n\n\nCottingham, John. 2002. “Descartes and the Voluntariness of Belief.” Monist 85 (3): 343–60. https://doi.org/10.5840/monist200285323.\n\n\nDavidson, Donald. 1963. “Actions, Reasons and Causes.” Journal of Philosophy 60 (23): 685–700. https://doi.org/10.2307/2023177.\n\n\nDescartes, René. 1641/1996. Meditations on First Philosophy, Tr. John Cottingham. Cambridge: Cambridge University Press.\n\n\n———. 1644/2003. The Principles of Philosophy, Tr. John Veitch. Champaign, IL: Project Gutenberg.\n\n\nEngel, Mylan. 1992. “Personal and Doxastic Justification in Epistemology.” Philosophical Studies 67 (2): 133–50. https://doi.org/10.1007/bf00373694.\n\n\nFodor, Jerry A. 1983. The Modularity of Mind. Cambridge, MA: MIT Press.\n\n\nGendler, Tamar Szabó. 2000. “The Puzzle of Imaginative Resistance.” Journal of Philosophy 97 (2): 55–81. https://doi.org/10.2307/2678446.\n\n\nGilbert, Daniel T. 1991. “How Mental Systems Believe.” American Psychologist 46 (2): 107–19. https://doi.org/10.1037//0003-066x.46.2.107.\n\n\nGilbert, Daniel T., Douglas S. Krull, and Patrick S. Malone. 1990. “Unbelieving the Unbelievable: Some Problems in the Rejection of False Information.” Journal of Personality and Social Psychology 59 (4): 601–13. https://doi.org/10.1037//0022-3514.59.4.601.\n\n\nGilbert, Daniel T., Romin W. Tafarodi, and Patrick S. Malone. 1993. “You Can’t Not Believe Everything You Read.” Journal of Personality and Social Psychology 65 (2): 221–33. https://doi.org/10.1037//0022-3514.65.2.221.\n\n\nGinet, Carl. 1985. “Contra Reliabilism.” Monist 68 (2): 175–87. https://doi.org/10.5840/monist198568218.\n\n\n———. 2001. “Deciding to Believe.” In Knowledge, Truth and Duty, edited by Matthias Steup, 63–76. Oxford: Oxford University Press.\n\n\nGrice, H. Paul. 1989. Studies in the Way of Words. Cambridge, MA.: Harvard University Press.\n\n\nHasson, Uri, Joseph P. Simmons, and Alexander Todorov. 2005. “Believe It or Not: On the Possibility of Suspending Belief.” Psychological Science 16 (7): 566–71. https://doi.org/10.1111/j.0956-7976.2005.01576.x.\n\n\nHeller, Mark. 2000. “Hobartian Voluntarism: Grounding a Deontological Conception of Epistemological Justification.” Pacific Philosophical Quarterly 81 (2): 130–41. https://doi.org/10.1111/1468-0114.00099.\n\n\nHieronymi, Pamela. 2008. “Responsibility for Believing.” Synthese 161 (3): 357–73. https://doi.org/10.1007/s11229-006-9089-x.\n\n\nHolton, Richard. 1999. “Intention and Weakness of Will.” The Journal of Philosophy 96 (5): 241–62. https://doi.org/10.2307/2564667.\n\n\n———. 2003. “How Is Strength of Will Possible?” In Weakness of Will and Varities of Practical Irrationality, edited by Sarah Stroud and Christine Tappolet, 39–67. Oxford: Oxford University Press.\n\n\n———. 2004. “Rational Resolve.” Philosophical Review 113 (4): 507–35. https://doi.org/10.1215/00318108-113-4-507.\n\n\nHolton, Richard, and Stephen Shute. 2007. “Self-Control in the Modern Provocation Defence.” Oxford Journal of Legal Studies 27 (1): 49–73. https://doi.org/10.1093/ojls/gql034.\n\n\nJones, Matthew L. 2006. The Good Life in the Scientific Revolution: Descartes, Pascal, Leibniz and the Cultivation of Virtue. Chicago: University of Chicago Press.\n\n\nKeller, Simon. 2005. “Patriotism as Bad Faith.” Ethics 115 (3): 563–92. https://doi.org/10.1086/428458.\n\n\nKennett, Jeanette, and Michael Smith. 1996a. “Frog and Toad Lose Control.” Analysis 56 (2): 63–73. https://doi.org/10.1111/j.0003-2638.1996.00063.x.\n\n\n———. 1996b. “Philosophy and Commonsense: The Case of Weakness of Will.” In The Place of Philosophy in the Study of Mind, edited by Michaelis Michael and John O’Leary-Hawthorne, 141–57. Norwell, MA: Kluwer. https://doi.org/10.1017/CBO9780511606977.005.\n\n\nLittlejohn, Clayton. 2009. “The Externalist’s Demon.” Canadian Journal of Philosophy 39 (3): 399–434. https://doi.org/10.1353/cjp.0.0054.\n\n\nOwens, David. 2000. Reason Without Freedom: The Problem of Epistemic Responsibility. New York: Routledge.\n\n\nPryor, James. 2001. “Highlights of Recent Epistemology.” British Journal for the Philosophy of Science 52 (1): 95–124. https://doi.org/10.1093/bjps/52.1.95.\n\n\nRyan, Sharon. 2003. “Doxastic Compatibilism and the Ethics of Belief.” Philosophical Studies 114 (1-2): 47–79. https://doi.org/10.1023/A:1024409201289.\n\n\nRyle, Gilbert. 1949. The Concept of Mind. New York: Barnes; Noble.\n\n\nShah, Nishi. 2002. “Clearing Space for Doxastic Voluntarism.” The Monist 85 (3): 436–45. https://doi.org/10.5840/monist200285326.\n\n\nSmith, Angela M. 2005. “Responsibility for Attitudes: Activity and Passivity in Mental Life.” Ethics 115 (2): 236–71. https://doi.org/10.1086/426957.\n\n\nSmith, Michael. 1997. “A Theory of Freedom and Responsibility.” In Ethics and Practical Reason, edited by Garrett Cullity and Berys Gaut, 293–317. Oxford: Oxford University Press.\n\n\n———. 2003. “Rational Capacities.” In Weakness of Will and Varities of Practical Irrationality, edited by Sarah Stroud and Christine Tappolet, 17–38. Oxford: Oxford University Press.\n\n\nSosa, Ernest. 1991. Knowledge in Perspective. New York: Cambridge University Press.\n\n\n———. 1997. “Reflective Knowledge in the Best Circles.” Journal of Philosophy 94 (8): 410–30. https://doi.org/10.2307/2564607.\n\n\nSteup, Matthias. 2000. “Doxastic Voluntarism and Epistemic Deontology.” Acta Analytica 15 (1): 25–56.\n\n\n———. 2008. “Doxastic Freedom.” Synthese 161 (3): 375–92. https://doi.org/10.1007/s11229-006-9090-4.\n\n\nStich, Stephen. 1978. “Beliefs and Subdoxastic States.” Philosophy of Science 45 (4): 499–518. https://doi.org/10.1086/288832.\n\n\nWatson, Gary. 1977. “Skepticism about Weakness of Will.” Philosophical Review 86 (3): 316–39. https://doi.org/10.2307/2183785.\n\n\nWeatherson, Brian. 2005. “Can We Do Without Pragmatic Encroachment?” Philosophical Perspectives 19 (1): 417–43. https://doi.org/10.1111/j.1520-8583.2005.00068.x.\n\n\nWilliams, Bernard. 1976. “Deciding to Believe.” In Problems of the Self, 136–51. Cambridge: Cambridge University Press.\n\n\nWilliamson, Timothy. 2000. Knowledge and its Limits. Oxford University Press."
  },
  {
    "objectID": "posts/lummarg/index.html",
    "href": "posts/lummarg/index.html",
    "title": "Luminous Margins",
    "section": "",
    "text": "0.1 Luminosity\nIn Knowledge and Its Limits Timothy Williamson argues that few conditions are luminous. 1 A condition is luminous iff we know we are in it whenever we are. Slightly more formally, Williamson defines\n1 Williamson (2000) Ch. 4; all references to this book unless otherwise specified.\nPublished in 83: 373-383.\nThanks to Tamar Szabó Gendler, John Hawthorne, Chris Hill, Ernest Sosa and the ’s referees.\n\n\nA condition C is defined to be luminous if and only if (L) holds:\n\n(L)\n\nFor every case \\({\\alpha}\\), if in \\({\\alpha}\\) C obtains, then in \\({\\alpha}\\) one is in a position to know that C obtains (95).\n\n\n\nIntuitively, the argument against this is as follows. The following three conditions are incompatible.\n\nGradual Change\n\nThere is a series of cases, each very similar to adjacent cases, that starts with a case where C clearly obtains, and ends with a case where C clearly doesn’t obtain.\n\nLuminosity\n\nWhenever C obtains you can know it does.\n\nSafety\n\nOnly safe beliefs count as knowledge, so whenever you can know that C obtains, C obtains in all very similar cases.\n\n\nLuminosity and Safety entail\n\nTolerance\n\nWhenever C obtains, it obtains in all very similar cases.\n\n\nBut Tolerance is incompatible with Gradual Change, since Tolerance entails that if the first member of the series is a case where C obtains, then every successive member is also a case where C obtains. Williamson argues that for any interesting epistemic condition, Gradual Change is a clear possibility. And he argues that Safety is a general principle about knowledge. So Luminosity must be scrapped. The counterexamples to Luminosity we get from following this proof through are always borderline cases of C obtaining. In these cases Luminosity fails because any belief that C did obtain would be unsafe, and hence not knowledge.\nI will argue, following Sainsbury (1995), that Williamson has misinterpreted the requirement that knowledge be safe. The most plausible safety condition might be compatible with Gradual Change and Luminosity, if we make certain plausible assumptions about the structure of phenomenal beliefs.\nOne consequence of the failure of Luminosity is that a certain historically important kind foundationalist analysis of knowledge fails. This kind of foundationalist takes the foundations to be luminous. Although I think Williamson’s argument against Luminosity does not work, my objections are no help to the foundationalist. As I said, my objection to Williamson rests on certain assumptions about the structure of phenomenal beliefs. It is a wide open empirical and philosophical question whether these assumptions are true. If this kind of foundationalism provided a plausible analysis of knowledge, then it would be a wide open question whether our purported knowledge rested on any foundations, and hence a wide open question whether we really had any knowledge. But this is a closed question. It is a Moorean fact that we know many things. So while I object to Williamson’s claim that we have no luminous mental states, I do not object to the weaker claim that we might not have any luminous mental states, and this claim is enough to do much of the philosophical work to which Williamson puts Luminosity.\n\n\n0.2 Williamson’s Example\nWilliamson suggests that (L), the formal rendition of Luminosity, fails for all interesting conditions even if we restrict the quantifier to those that are ‘physically and psychologically feasible’ [94], and I will assume that is what we are quantifying over. To argue that (L) fails for any interesting C, Williamson first argues that it fails in a special case, when C is the condition feeling cold, and then argues that the conditions that lead to failure here are met for any other interesting C. So I will also focus on the special case.\nMr Davis’s apartment faces southwest, so while it is often cold in the mornings it always warms up as the midday and afternoon sun streams in. This morning Mr Davis felt cold when he awoke, but now at noon he is quite warm, almost hot. But the change from wake-up time to the present is rather gradual. Mr Davis does not take a hot bath that morning, nor cook a hot breakfast, but sits reading by the window until the sun does its daily magic. Assume, for the sake of the argument, that feeling cold is luminous, so whenever Mr Davis feels cold, he knows he feels cold. Williamson argues this leads to a contradiction as follows. (I’ve changed names and pronouns to conform with my example.)\n\nLet t0, t1, …, tn be a series of times at one millisecond intervals from dawn to noon. Let \\({\\alpha}\\)i be the case at ti (0 \\({\\leq}\\) i \\({\\leq}\\) n). Consider a time ti between t0 and tn, and suppose that at tn Mr Davis knows that he feels cold. … Now at ti+1 he is almost equally confident that he feels cold, by the description of the case. So if he does not feel cold at ti+1, then his confidence at ti that he feels cold is not reliably based, for his almost equal confidence on a similar basis one millisecond earlier that he felt cold was misplaced … His confidence at ti was reliably based in the way required for knowledge only if he feels cold at ti+1. In the terminology of cases…:\n(ii) If in \\({\\alpha}\\)i he knows that he feels cold, then in \\({\\alpha}\\)i+1 he feels cold. (97)\n\nGiven (L), all instances of (ii), and the fact that Mr Davis feels cold when he awakes, we get the false conclusion that he now feels cold. So if we accept all instances of (ii), we must conclude that (L) is false when C is feeling cold and ‘one’ denotes Mr Davis. Why, then, accept (ii)? One move Williamson makes here is purely defensive. He notes that (ii) is different from the conditionals that lead to paradox in the Sorites argument. The antecedent of (ii) contains the modal operator knows that absent from its consequent, so we cannot chain together instances of (ii) to produce an implausible conditional claim. If that operator were absent then from all the instances of (ii) it would follow that if Mr Davis feels cold at dawn he feels cold at noon, which is false. But by strengthening the antecedent, Williamson weakens (ii) to avoid that conclusion. But the fact that (ii) is not paradoxical is not sufficient reason to accept it.\n\n\n0.3 Reliability\nIt is useful to separate out two distinct strands in Williamson’s argument for (ii). One strand sees Williamson arguing for (ii) by resting on the principle that beliefs constitute knowledge only if they are reliably based. The idea is that if Mr Davis’s belief that he feels cold is a bit of knowledge, it is reliable, and if it is reliable it is true in all similar situations, and hence it is true in \\({\\alpha}\\)i+1. The other strand sees him appealing to a vague but undoubtedly real requirement that beliefs must be safely true in order to be knowledge. Neither argument is successful, though the second kind of argument is better than the first.\nWilliamson acknowledges Conee and Feldman’s arguments that no reliabilist epistemologist has yet solved the generality problem (100). But he takes this to be reason to abandon not the concept of reliability, but the hope of providing a reductive analysis of it. Williamson thinks we can get a long way by just resting on the intuitive concept of reliability. This seems to be a mistake. There are two ordinary ways of using ‘reliable’ in the context of discussing beliefs, and neither provides support for (ii).\nFirst, and this is clearly not what is needed, sometimes ‘reliable’ just means true. This is the sense of the word in which we can consistently say, “It turned out the information that old Ronnie provided us about where the gov’nor was eating tonight was reliable, which was plenty surprising since Ronnie hadn’t been right about anything since the Nixon administration.” This is the sense in which reliable means just what the etymology suggests it means, something that can be relied upon. And that means, in practice, true. But that won’t help at all, for if ‘reliable’ just means true, then nothing follows from the fact that knowledge is reliable that does not follow from the fact that it is factive.\nSecond, there is a distinctively philosophical sense in which reliable means something more like true in a wide range of circumstances. This is the sense in which a stopped clock is not even reliable twice a day. At first, this might look to help Williamson a little more. But if philosophical usage is to be key, the second look is more discouraging. For in its philosophical usage, reliability does not even entail truth. And if reliability does not entail truth in the actual situation, it surely does not entail truth in nearby situations. But Williamson’s argument for (ii) requires that reliability in \\({\\alpha}\\)i entails truth in \\({\\alpha}\\)i+1. So on neither of its natural readings does the concept of reliability seal the argument here, and since we have no unnatural reading to fall back upon, the argument from reliability for (ii) fails. To be fair, by chapter 5 of Williamson’s book the concept of reliability that seems to be employed is little distinguishable from the concept of safety. So let us turn to those arguments.\n\n\n0.4 Safety\nWilliamson at times suggests that the core argument for (ii) is a straight appeal to intuition. “[E]ven when we can appeal to rigorous rules, they only postpone the moment at which we must apply concepts in particular cases on the basis of good judgement. … The argument for (ii) appeals to such judgement.” (101) The appeal to intuition is the royal road to scepticism, so we would be justified in being a little wary of it. Weinberg, Stich, and Nichols (2001) discovered that undergraduates from the same social class as Williamson, Mr Davis and I would frequently judge that a subject could not know that mule was a mule unless he could tell it apart from a cleverly painted zebra. The judgements of that class are not obviously the basis for a sane epistemology.\nWilliamson undersells his argument by making it an appeal to judgement. For there is a principle here, if not a rigorous rule, that grounds the judgement. The principle is something like Ernest Sosa’s safety principle. The idea is that a belief does not constitute knowledge if it is false in similar situations. “[N]ot easily would S believe that p without it being the case that p.” (Sosa 1999, 142) There is much to be said here about what is a similar situation. (David Lewis (1996) discusses a concept of similarity in the context of saying that worlds can be salient, in his sense, in virtue of being similar to salient worlds.) It might turn out that there is no account of similarity that makes it plausible that this is a constraint on knowledge. But for present purposes I am prepared to grant (a) that only safe beliefs count as knowledge, and (b) that \\({\\alpha}\\)i+1 is a similar situation to \\({\\alpha}\\)i.\nThis might seem like too much of a concession to Williamson, for it already conflicts with some platitudes about knowledge. Consider a case that satisfies the following three conditions. Some light reflects off a leopard some distance away and strikes our eyes. The impact of that light causes, by the normal processes, a belief that a leopard is nearby to appear in our belief box. Beliefs, including leopard-related beliefs, that we form by this kind of process are on the whole very reliable. You might think these conditions are sufficient for our belief to count as knowledge that a tiger is present. The proponent of Safety denies this. She says that if, for example, there are several cheetahs with a particularly rare mutation that make the look much like leopards around, and if we saw them at similar distance we would have mistaken them for leopards. Since we could easily have had the belief that a leopard is nearby while there were no leopards, only cheetahs, nearby, the belief is not safe and so does not count as knowledge.\nThere are two reasons to think that safety is too strong here, neither of which strike me as completely compelling. (I’m still conceding things to Williamson here. If there’s a general objection to Safety then his argument against Luminosity does not get off the ground. That’s not my position. As I’ll soon argue, I think Williamson has misinterpreted Safety.) The first reason is a worry that if we deny knowledge in a case of reliable veridical perception, we are conceding too much to the sceptic. But the proponent of Safety has a very good reason to distinguish this case from my current veridical perception of a table - my perception is safe and the perception of a leopard is not. So there is no slippery slope to scepticism here. The second is that the allegedly similar case is not really that similar, because in that case the belief is caused by a cheetah, not a leopard. But to regard cases where the evidence is different in this way as being dissimilar is to make the safety condition impotent, and Sosa has shown that we need some version of Safety to account for our intuitions about different cases.2\n2 I assume here a relatively conservative epistemological methodology, one that says we should place a high priority on having our theories agree with our intuitive judgments. I’m in favour of a more radical methodology that makes theoretical virtues as important as agreement with particular intuitions Weatherson (2003). On the radical view Safety might well be abandoned. But on that view knowledge might be merely true belief, or merely justified true belief, so the argument for Luminosity will be a non-starter. But the argument of this paper does not rest on these radical methodological principles. The position I’m defending is that, supposing a standard methodological approach, we should accept a Safety principle. But as I’ll argue, the version of Safety Williamson adopts is not appropriate, and the appropriate version does not necessarily support the argument against Luminosity.So I think some version of Safety should be adopted. I don’t think this gives us (ii), for reasons related to some concerns first raised by Mark Sainsbury (1995). The role for Safety condition in a theory of knowledge is to rule out knowledge by lucky guesses. This includes lucky guesses in mathematics. If Mr Davis guesses that 193 plus 245 is 438, he does not thereby know what 193 plus 245 is. Can Safety show why this is so? Yes, but only if we phrase it in a certain way. Assume that we have a certain belief B with content p. (As it might be, Mr Davis’s belief with content 193 + 245 = 438.) Then the following two conditions both have claims to being the correct analysis of ‘safe’ as it appears in Safety.\n\nContent-safety\n\nB is safe iff p is true in all similar worlds.\n\nBelief-safety\n\nB is safe iff B is true in all similar worlds.\n\n\nIf we rest with content-safety, then we cannot explain why Mr Davis’s lucky guess does not count as knowledge. For in all nearby worlds, the content of the belief he actually has is true. If we use belief-safety as our condition though, I think we can show why Mr Davis has not just got some mathematical knowledge. The story requires following Marian David’s good advice for token physicalists and rejecting content essentialism about belief (David (2002); see also Gibbons (1993). The part of Mr Davis’s brain that currently instantiates a belief that 193 plus 245 is 438 could easily have instantiated a belief that 193 plus 245 is 338, for Mr Davis is not very good at carrying hundreds while guessing. If, as good physicalists, we identify his belief with the part of the brain that instantiates it, we get the conclusion that this very belief could have had the false content that 193 plus 245 is 338. So the belief is not safe, and hence it is not knowledge.\nThis lends some credence to the idea that it’s belief-safety, not content-safety, that’s the important safety criteria. When talking about Mr Davis’s mathematical hunches, belief-safety is a stronger condition than content-safety. But when talking about his feelings, things may be reversed.\nLet me tell you a little story about how Mr Davis’s mind is instantiated. Mr Davis’s phenomenal beliefs do not arise from one part of his brain, his belief box or mind’s eye, tracking another part, the part whose states constitute his feeling cold. Rather, when he is in some phenomenal state, the very same brain states constitute both the phenomena and a belief about the phenomena. Mr Davis’s brain is so wired that he could not have any sensation of radiant heat (or lack thereof) without his thereby believing that he is having just that sensation, because he could not have felt cold without that feeling itself being a belief that he felt cold. In that case, belief-safety will not entail (ii). Imagine that at \\({\\alpha}\\)i Mr Davis feels cold, but at \\({\\alpha}\\)i+1 he does not. (I assume here, with Williamson, that there is such an i.) At \\({\\alpha}\\)i he thereby believes that he feels cold. The content of that belief is a de se proposition that is false at \\({\\alpha}\\)i+1, so it violates content-safety. But in \\({\\alpha}\\)t+1 that part of his brain does not constitute his feeling cold (for he does not feel cold), and thereby does not constitute his believing that he feels cold. By hypothesis, by that time no part of his brain constitutes feeling cold. So the belief in \\({\\alpha}\\)i that he feels cold is not false in \\({\\alpha}\\)i+1; it either no longer exists, or now has the true content that Mr Davis does not feel cold. So belief-safety does not prevent this belief of Mr Davis’s from being knowledge. And indeed, it seems rather plausible that it is knowledge, for he could not have had just this belief without it being true. This belief violates content-safety but not belief-safety, and since we have no reason to think that content-safety rather than belief-safety is the right form of the safety constraint, we have no reason to reject the intuition that this belief, this more or less infallible belief, counts as a bit of knowledge.\nThis story about Mr Davis’s psychology might seem unbelievable, so let me clear up some details. Mr Davis has both phenomenal and judgemental beliefs about his phenomenal states. The phenomenal beliefs are present when and only when the phenomenal states are present. The judgemental beliefs are much more flexible, they are nomically independent of the phenomena they describe. The judgemental beliefs are grounded in ‘inner perceptions’ of his phenomenal states. The phenomenal beliefs are not, they just are the phenomenal states. The judgemental beliefs can be complex, as in a belief that I feel cold iff it is Monday, while the phenomenal beliefs are always simple. It is logically possible that Mr Davis be wired so that he feel cold without believing he feels cold, but it is not an accident that he is so wired. Most of his conspecifics are similarly set up. It is possible that at a particular time Mr Davis has both a phenomenal belief and a judgemental belief that he feels cold, with the beliefs being instantiated in different parts of his brain. If he has both of these beliefs in \\({\\alpha}\\)i, then Williamson’s argument may well show that the judgemental belief does not count as knowledge, for it could be false in \\({\\alpha}\\)i+1. If he has the judgemental belief that he is not cold in \\({\\alpha}\\)i, then the phenomenal belief that he is cold may not be knowledge, for it is plausible that the existence of a contrary belief defeats a particular belief’s claim to knowledge. But that does not mean that he is not in a position to know that he is cold in \\({\\alpha}\\)i.\nSome may object that it is conceptually impossible that a brain state that instantiates a phenomenal feel should also instantiate a belief. And it is true that Mr Davis’s phenomenal states do not have some of the features that we typically associate with beliefs. These states are relatively unstructured, for example. Anyone who thinks that it is a conceptual truth that mental representations are structured like linguistic representations will think that Mr Davis could not have the phenomenal beliefs I have ascribed to him. But it is very implausible that this is a conceptual truth. The best arguments for the language of thought hypothesis rest on empirical facts about believers, especially the facts that mental representation is typically productive and systematic. If there are limits to how productive and systematic Mr Davis’s phenomenal representations are, then it is possible that his phenomenal states are beliefs. Certainly those states are correlated with inputs (external states of affairs) and outputs (bodily movements, if not actions) to count as beliefs on some functionalist conceptions of belief.\nA referee noted that we don’t need the strong assumption that phenomenal states can be beliefs to make the argument here, though it probably is the most illumination example. Either of the following stories about Mr Davis’s mind could have done. First, Mr Davis’s phenomenal belief may be of the form “I feel \\({\\phi}\\)”, where “I” and “feel” are words in Mr Davis’s language of thought, and \\({\\phi}\\) is the phenomenal state, functioning as a name for itself. As long as the belief arises whenever Mr Davis is \\({\\phi}\\), and it has the phenomenal state as a constituent, it can satisfy belief-safety even when content-safety fails. The second option involves some more contentious assumptions. The phenomenal belief may be of the form “I feel thus”, where the demonstrative picks out the phenomenal state. As long as it is essential to the belief that it includes a demonstrative reference to that phenomenal state, it will satisfy belief-safety. This is more contentious because it might seem plausible that a particular demonstrative belief could have picked out a different state. What won’t work, of course, is if the phenomenal belief is “I feel F”, where F is an attempted description of the phenomenal state. That certainly violates every kind of safety requirement. I think it is plausible that phenomenal states could be belief states, but if you do not believe that it is worth noting the argument could possibly go through without it, as illustrated in this paragraph.\nMr Davis is an interesting case because he shows just how strong a safety assumption we need to ground (ii). For Mr Davis is a counterexample to (ii), but his coldness beliefs satisfy many plausible safety-like constraints. For example, his beliefs about whether he feels cold are sensitive to whether he feels cold. Williamson (Ch. 7) shows fairly conclusively that knowledge does not entail sensitivity, so one might have thought that in interesting cases sensitivity would be too strong for what is needed, not too weak as it is here. From this it follows that any safety condition that is strictly weaker than sensitivity, such as the condition that the subject could not easily believe p and be wrong, is not sufficient to support (ii). Williamson slides over this point by assuming that the subject will be almost as confident that he feels cold at \\({\\alpha}\\)i+1 as he is at \\({\\alpha}\\)i. This is no part of the description of the case, as Mr Davis shows.\nMy argument above rests on the denial of content essentialism, which might look like a relatively unsafe premise. So to conclude this section, let’s see how far the argument can go without that assumption. Sainsbury responds to his example, the lucky arithmetic guess, by proposing a different version of safety: mechanism-safety.\n\nMechanism-safety\n\nB is safe iff the mechanism that produced B produces true beliefs in all similar worlds.\n\n\nI didn’t want to rest on this too much because I think it’s rather hard to say exactly what the mechanism is that produces Mr Davis’s belief that he feels cold. But if it’s just his sensory system, then I think it is clear that even at \\({\\alpha}\\)i, Mr Davis’s belief that he feels cold satisfies mechanism-safety. The bigger point here is that content-safety is a very distinctive kind of safety claim, but it’s the only kind that justifies (ii).\n\n\n0.5 Retractions\nTo close, let me stress how limited my criticisms of Williamson here are. Very briefly, the argument is that there can be some self-presenting mental states, states that are either token identical with the belief that they exist or are constituents of (the contents of) beliefs that they exist, and these beliefs will satisfy all the safety requirements we should want, even in borderline cases. If some conditions are invariably instantiated by self-presenting states, then those conditions will be luminous. And I think it is a live possibility, relative at least to the assumptions Williamson makes, that there are such self-presenting states. But there aren’t very many of them. There is a reason I picked feels cold as my illustration. It’s not laughable that it is self-presenting.\nOn the other hand, it is quite implausible that, say, knowing where to buy the best Guinness is self-presenting. And for states that are not self-presenting, I think Williamson’s anti-luminosity argument works. That’s because it is very plausible (a) that for a belief to be knowledge it must satisfy either belief-safety or mechanism-safety, (b) a non-self-presenting state satisfies belief-safety or mechanism-safety only if it satisfies content-safety, and (c) as Williamson showed, if beliefs about a state must satisfy content-safety to count as knowledge, then that state is not luminous. So epistemic states, like the state of knowing where to buy the best Guinness, are not luminous. That is to say, one can know where to buy the best Guinness without knowing that one knows this. And saying that (for these reasons) is to just endorse Williamson’s arguments against the KK principle. Those arguments are an important special case of the argument against luminosity, and I don’t see how any of my criticisms of the general argument touch the special case.\nWilliamson describes his attacks on luminosity as an argument for cognitive homelessness. If a state was luminous, that state would be a cognitive home. Williamson thinks we are homeless. I think we may have a small home in our phenomenal states. This home is not a mansion, perhaps just a small apartment with some afternoon sun, but it may be a home.\nDon’t be fooled into thinking this supports any kind of foundationalism about knowledge, however. It is true that if we have the kind of self-presenting states that Mr Davis has (under one of the three descriptions I’ve offered), then we have the self-justifying beliefs that foundationalism needs to get started. But it is at best a wide-open philosophical and scientific question whether we have any such states, while it is not a wide-open question whether we have any knowledge, or any justified beliefs. If these states are the only things that could serve as foundations, it would be at least conceptually possible that we could have knowledge without self-justifying foundations. So the kind of possibility exemplified by Mr Davis cannot, on its own, prop up foundationalism.\n\n\n\n\n\n\nReferences\n\nDavid, Marian. 2002. “Content Essentialism.” Acta Analytica 17: 103–14. https://doi.org/10.1007/bf03177510.\n\n\nGibbons, John. 1993. “Identity Without Supervenience.” Philosophical Studies 70 (1): 59–79. https://doi.org/10.1007/bf00989662.\n\n\nLewis, David. 1996. “Elusive Knowledge.” Australasian Journal of Philosophy 74 (4): 549–67. https://doi.org/10.1080/00048409612347521.\n\n\nSainsbury, Mark. 1995. “Vagueness, Ignorance and Margin for Error.” British Journal for the Philosophy of Science 46: 589–601. https://doi.org/10.1093/bjps/46.4.589.\n\n\nSosa, Ernest. 1999. “How to Defeat Opposition to Moore.” Philosophical Perspectives 13: 141–53. https://doi.org/10.1111/0029-4624.33.s13.7.\n\n\nWeatherson, Brian. 2003. “What Good Are Counterexamples?” Philosophical Studies 115 (1): 1–31. https://doi.org/10.1023/A:1024961917413.\n\n\nWeinberg, Jonathan, Stephen Stich, and Shaun Nichols. 2001. “Normativity and Epistemic Intuitions.” Philosophical Topics 29 (1): 429–60. https://doi.org/10.5840/philtopics2001291/217.\n\n\nWilliamson, Timothy. 2000. Knowledge and its Limits. Oxford University Press."
  },
  {
    "objectID": "posts/ieg/index.html",
    "href": "posts/ieg/index.html",
    "title": "Interests, Evidence and Games",
    "section": "",
    "text": "Pragmatic encroachment theories have a problem with evidence. On the one hand, the arguments that knowledge is interest-relative look like they will generalise to show that evidence too is interest-relative. On the other hand, our best story of how interests affect knowledge presupposes an interest-invariant notion of evidence.\n\nPublished in Episteme 15: 329-344.\nImage by Paul Wordingham via Creative Commons.\n\nThe aim of this paper is to sketch a theory of evidence that is interest-relative, but which allows that ‘best story’ to go through with minimal changes. The core idea is that the evidence someone has is just what evidence a radical interpreter says they have. And a radical interpreter is playing a kind of game with the person they are interpreting. The cases that pose problems for pragmatic encroachment theorists generate fascinating games between the interpreter and the interpretee. They are games with multiple equilibria. To resolve them we need to detour into the theory of equilibrium selection. I’ll argue that the theory we need is the theory of risk-dominant equilibria. That theory will tell us how the interpreter will play the game, which in turn will tell us what evidence the person has. The evidence will be interest-relative, because what the equilibrium of the game is will be interest-relative. But it will not undermine the story we tell about how interests usually affect knowledge.\n\n0.1 Encroachment, Reduction and Explanation\nI will start with an argument for a familiar disjunctive conclusion: either knowledge is interest-relative, or scepticism is true. The argument will resemble arguments to the same disjunctive conclusion in Hawthorne (2004) and Fantl and McGrath (2009). Indeed, it is inspired by those discussions. But it uses less controversial premises than previous versions.\nThe argument starts by considering a game, one I’ll call the red-blue game. Here are the rules of the game.\n\nTwo sentences will be written on the board, one in red, one in blue.\nThe player will make two choices.\nFirst, they will pick a colour, red or blue.\nSecond, they say whether the sentence in that colour is true or false.\nIf they are right, they win. If not, they lose.\nIf they win, they get $50, and if they lose, they get nothing.\n\nOur player is Parveen. She is an epistemologist who works on pragmatic encroachment, and (as will become important in a minute), she has frequently cited both Knowledge and Lotteries  (Hawthorne 2004), and Knowledge and Practical Interests  (Stanley 2005). She knows the rules of the game, and no other relevant facts about the game. When the game starts, the following two sentences are written on the board, the first in red, the second in blue.\n\nTwo plus two equals four.\nKnowledge and Lotteries was published before Knowledge and Practical Interests.\n\nIntuitively, there is a unique rational play in this game: Red-True. That is, Parveen announces that she will evaluate the truth value of the red sentence, and then announce that it’s true. That’s a sure $50.\nOn the other hand, in normal circumstances, we would say that Parveen does know that Knowledge and Lotteries was published before Knowledge and Practical Interests. After all, she has looked up their publication dates many times in checking over her papers.\nThere is a puzzle in reconciling these intuitions. The pragmatic encroachment theorist has a solution to these puzzles. In normal circumstances, Parveen does know that Knowledge and Lotteries was published before Knowledge and Practical Interests. But these are not normal circumstances. Right now, it matters whether her reason to believe that Knowledge and Lotteries was published before Knowledge and Practical Interests is as strong as her reason to believe that two plus two equals four. And (unless something very weird is happening), that isn’t true for Parveen. So she knows that red-true will win, she doesn’t know any other play will win, so she should play Red-True.\nIf we reject pragmatic encroachment, and we are not sceptics, we should say that Parveen does know that Knowledge and Lotteries was published before Knowledge and Practical Interests. And then it is a mystery why playing Red-True is more rational than playing Blue-True. After all, Parveen knows the rules of the game, and she knows (by hypothesis) the blue sentence is true, so if she can do even basic logical reasoning in a knowledge preserving way, she knows she will get as good a result as possible by playing Blue-True. So it is a bit of a mystery why it would be anything other than maximally rational to play Blue-True.\nOne way we might try to resolve this mystery is by saying that although Parveen knows that Blue-True will win $50, she super-knows that Red-True will win $50. What do we mean here by super knowledge? Think of this as a placeholder for certainty, or knowledge that one knows, or anything other epistemic state that you think might be relevant to her practical decision making. Perhaps the fact that she super-knows what two plus two is, but doesn’t super-know when the epistemology books were published, could be the explanation for why Red-True is the unique rational play.1\n1 That we need some kind of super-knowledge for action, and not mere knowledge, is a popular, and natural, explanation of the case. For versions of this explanation, obviously with more details than I’ve given here, see for example Jessica Brown (2008) and Jennifer Lackey (2010).But no such explanation can work, because Parveen doesn’t super-know that playing Red-True will win $50. She super-knows that two plus two is four. But we have not assumed that she super-knows the rules of the game. So she doesn’t super-know that Red-True will win, she just knows it. And she also, by hypothesis, knows that Blue-True will win. So looking at any kind of super-knowledge can’t break the intuitive asymmetry between Red-True and Blue-True.\nPut another way, if Parveen knows that Knowledge and Lotteries was published before Knowledge and Practical Interests, then she knows that she is playing the following game.\n\nTwo sentences will be written on the board, one in red, one in blue.\nThe player chooses to play either Blue-True, Blue-False, Red-True, or Red-False.\nIf they play Blue-True, they win $50.\nIf they play Blue-False, they win nothing.\nIf they play Red-True, they win $50 if the red sentence is true, and nothing otherwise.\nIf they play Red-False, they win $50 if the red sentence is false, and nothing otherwise.\n\nAnd is is rational to play Blue-True in that game. (It might also be rational to pay Red-True depending on what the red sentence is, but it is always rational to play Blue-True.) Yet it is not rational to play Blue-True in the original game. So Parveen does not know, when she plays the original game, that Knowledge and Lotteries was published before Knowledge and Practical Interests.\nSo to avoid pragmatic encroachment here we must deny that Parveen ever knew that Knowledge and Lotteries was published before Knowledge and Practical Interests. On its own, that’s not a sceptical conclusion: lots of people don’t know that. But once we go down that path, it looks like not much knowledge will be left. After all, we can repeat the game with any number of different things in the place of the blue sentence. If we adopt the constraint that Parveen only knows p, right now, if it is rationally permissible for her to play Blue-True when p is the blue sentence, no matter what the red sentence is, then either we have to say very unintuitive things about rational plays of the game, or we have to say she knows very little.\nSo we’ve got the conclusion that either pragmatic encroachment is true, or scepticism is true. Since I’m not a sceptic, I’m happy to conclude that pragmatic encroachment is true. But note that we’ve done this without any reference to high stakes situations. The stakes in Parveen’s game are just $50. That’s not nothing, but it’s not ‘high stakes’ in the way that phrase is normally used.\nThe version of pragmatic encroachment we get is that what matters for knowledge are not the stakes involved in any bet on p, but the odds.2 Parveen loses knowledge because she is being asked, in effect, to make a super long odds bet on a fact about publication schedules. She is in no position to rationally make a bet at those odds. So she doesn’t know the fact about publication schedules.\n2 Jessica Brown (2008, 176) shows that pragmatic encroachment theories that rely just on the stakes involved are subject to serious counterexample. Katherine Rubin (2015) argues that if we have a ‘global’ version of pragmatic encroachment, where all our epistemic notions are interest-relative, then it is implausible that it is the stakes the subject faces that matter for knowledge. Since I’m defending such a global version of pragmatic encroachment, Rubin’s arguments show that it is important that I’m relying on odds, not stakes. Baron Reed (2014) argues that if it is stakes alone that matter to pragmatic encroachment, then agents who the pragmatic encroachment theorist takes to be perfectly rational would be subject to a Dutch Book.And that’s the general principle: agents only know a proposition if they are in a position to rationally bet on that proposition at the odds currently being offered to them. In practice, high stakes situations tend to feature bets at long odds, so in practice much knowledge dissipates in high stakes cases. But the explanation of the dissipation is the odds the agent faces, not the stakes.\nMore precisely, I endorse these principles as constraints on knowledge:\n\nIf the agent knows that p, then for any question they have an interest in, the answer to that question is identical to the answer to that question conditional on p.\nWhen an agent is considering the choice between two options, the question of which option has a higher expected utility given their evidence is a question they have an interest in.\n\nThose principles are meant to not merely be extensionally adequate. They are meant to explain why agents lose knowledge when considering some sets of options, like in the Red-Blue game. In some sense, they are meant to be part of reductive explanations. These reductive explanations take as primitive inputs facts about the agent’s evidence, and facts about evidential probability. I’m going to set aside worries about the metaphysics of evidential probability, and just focus on evidence. Because it turns out that there is a real problem in getting a plausible theory of evidence that can function as an input to that reductive explanation.\n\n\n0.2 The Problems with Evidence\nGo back to the red-blue game. Consider a version of the game where:\n\nThe red sentence is that two plus two equals four.\nThe blue sentence is something that, if known, would be part of the agent’s evidence.\n\nI’m going to argue that there are cases where the only rational play is Red-True, but the blue sentence is something we want to say that, ordinarily, the subject knows. And I’ll argue that this is a problem for the kind of reductive explanation I just sketched. If pragmatic effects matter to what the evidence is, we can’t take the evidence as a fixed input into an explanation of how and when pragmatic effects matter.\nLet’s have Parveen play the game again. She’s going to be playing the game in a restaurant, one in Ann Arbor where she lives. Just before the game starts, she notices an old friend, Rahul, across the room. Rahul is someone she knows well, and can ordinarily recognise, but she had no idea he was in town. She thought Rahul was living in Italy. Still, we would ordinarily say that she now knows Rahul is in the restaurant; indeed that he is in the restaurant. It would be perfectly acceptable for her to say to someone else, “I saw Rahul here”, for example. Now the game starts.\n\nThe red sentence is Two plus two equals four.\nThe blue sentence is Rahul is in this restaurant.\n\nNow we have a problem. On the one hand, there is only one rational play here: Red-True. If you haven’t seen someone for a long time, then you can’t be completely certain it’s them when you spot them across a restaurant. It would be foolish to be as confident that it’s Rahul as that two and two make four. It looks like this is a case where pragmatic effects defeat knowledge.\nOn the other hand, our story for why Parveen loses knowledge here has run into problems. I wanted to tell a story roughly like the following. She can’t play Blue-True when the probability of the blue sentence, given her evidence, is less than the probability of the red sentence, given her evidence. That explanation can only go through if the blue sentence is itself not part of her evidence, since the probability of anything given itself is one. So we need a story about how it is that it is not part of Parveen’s evidence that Rahul is not in the restaurant.\nThat story can’t be the one that presupposes facts about what is in Parveen’s evidence. So it can’t use facts about the probability of some proposition given her evidence; at least not in any simple way. If we can independently identify Parveen’s evidence, then we can go back to using evidential probability. But until we’ve done that, we’re stuck.\nThere are two options here that seem possible for the pragmatic encroachment theorist, but not particularly attractive.\nOne is to say that propositions like Rahul is in this restaurant are never part of Parveen’s evidence. Perhaps her evidence just consists of things like I am being appeared to Rahul-like. Such an approach is problematic for two reasons. The first is that it is subject to all the usual objections to psychological theories of evidence  (Williamson 2007). The second is that we can re-run the argument with the blue sentence being some claim about Parveen’s psychological state, and still get the result that the only rational play is Red-True. A retreat to a psychological conception of evidence will only help with this problem if agents are infallible judges of their own psychological states, and that is not in general true  (Schwitzgebel 2008).\nAnother option is to deny that a reductive explanation is needed here. Perhaps pragmatic effects, like the particular sentences that are chosen for this instance of the Red-Blue game, mean that Parveen’s evidence no longer includes facts about Rahul, but this isn’t something we can give a reductive account of. We shouldn’t assume that everything will have a simple reductive explanation, so this isn’t so bad in theory. The problem in practice is that without a reductive explanation, we don’t have a predictive theory of when pragmatic effects matter. And that seems to be a bad thing. For instance, the following theory is completely consistent with Parveen’s case as described.\n\nE=K; i.e., one’s evidence is all and only what one knows.\nSomeone does not know p if the evidential probability of p is not close enough to one for current purposes.\nSince it is part of Parveen’s evidence that Rahul is in the restaurant, the probability that he is there is one, so it is close enough to one for current purposes.\nSo this is not a case where pragmatic effects change what she knows.\n\nThat theory seems to me to be badly mistaken, since it goes on to predict that it is rationally permissible to play Blue-True. But we need a pragmatic account that says that it is mistaken, and says something about which alternative situations would not threaten Parveen’s knowledge. We don’t yet, as far as I can see, have such an account. The aim of the rest of this paper is to provide one.3\n3 You can read this paper as a reply to the challenge posed by Ichikawa, Jarvis, and Rubin (2012). They note that there are challenges facing the pragmatic encroachment theorist whether they make evidence interest-relative, or interest-invariant. I’m going to show how to have an interest-relative theory of evidence, and keep what was desirable about pragmatic encroachment theories.\n\n0.3 A Simple, but Unsatisfying, Solution\nLet’s take a step back and look at the puzzle more abstractly. We have an agent S, who has some option O, and it really matters whether or not the value of O, i.e., \\(V(O)\\) is at least \\(x\\). It is uncontroversial that the agent’s evidence includes some background \\(K\\), and controversial whether it includes some contested proposition \\(p\\). It is also uncontroversial that \\(V(O | p) \\geq x\\), and we’re assuming that for any proposition \\(q\\) that is in the agent’s evidence, \\(V(O | q) = V(O)\\). That is, we’re assuming the relevant values are conditional on evidence. We can capture that last assumption with one big assumption that probably isn’t true, but is a harmless idealisation for these purposes. Say there is a prior value function \\(V^-\\), with a similar metaphysical status to the mythical, mystical prior probability function. Then for any choice \\(C\\), \\(V(C) = V^-(C | E)\\), where \\(E\\) is the evidence the agent has.\nNow we’re in a position to state a simple, but unsatisfying, solution. Let \\(p\\) be the proposition that the agent might or might not know, and the question of whether \\(V(O) \\geq x\\) be the only salient one that \\(p\\) is relevant to. Then the agent knows \\(p\\) only if the following is true:\n\n\\(\\frac{V^-(O | K) + V^-(O | K \\wedge p)}{2} \\geq x\\)\n\nThat is, we work out the value of \\(O\\) with and without the evidence \\(p\\), and if the average is greater than \\(x\\), good enough!\nThat solves the problem of Parveen and Rahul. Parveen’s evidence may or may not include that Rahul is in the restaurant. If it does, then Blue-True has a value of $50. If it does not, then Blue-True’s value is somewhat lower. Even if the evidence includes that someone who looks a lot like Rahul is in the restaurant, the value of Blue-True might only be $45. Averaging them out, the value is less than $50. But you’d only play Blue-True if it was worthwhile it play it instead of Red-True, which is worth $50. So you shouldn’t play Blue-True.\nGreat! Well, great except for two monumental problems. The first problem is that what we’ve said here really only helps with very simple cases, where there is a single decision problem that a single contested proposition is relevant to. We need some way to generalise the case to less constrained situations. The second (and bigger) problem is that the solution is completely ad hoc. Why should we use the arithmetic mean of these two things rather than any other formula that would have implied the intuitively correct result in the Parveen-Rahul case? Pragmatic encroachment starts with a very elegant, very intuitive, principle: you only know the things you can reasonable take to be settled for the purposes of current deliberation. And that deliberation should be driven by the aim of maximising expected utility. It does not look like any such elegant, intuitive, principles will lead to some theorem about averaging out the value of an option with and without new evidence.\nHappily, the two problems have a common solution. But the solution requires a detour into some technical work. It’s time for some game theory.\n\n\n0.4 Gamifying the Problem\nWe can usefully think of some philosophical problems as games, and hence subjects for study using game theoretic techniques. This is especially when the problems involve interactions of rational agents. Here, for example, is the game table for Newcomb’s problem, with the human who is usually the focus of the problem as Row, and the demon as Column.4\n4 In these games, Row chooses a row, and Column chooses a column, and that determines the cell that is the outcome of the game. The cells include two numbers. The first is Row’s payout, and the second is Column’s. The games are non-competitive; the players are simply trying to maximise their own returns, not maximise the difference between their return and the other player’s return.\n\n\n\n\nPredict 1 Box\nPredict 2 Boxes\n\n\n\n\nChoose 1 Box\n1000, 1\n0,0\n\n\nChoose 2 Boxes\n1001, 0\n1, 1\n\n\n\n\nThis game has a unique Nash equilbrium; the bottom right corner.5 And that’s one way of motivating the view that (a) the game is possible, and (b) the rational move for the human is to choose two boxes.\n5 A Nash equilibrium is an outcome of the game where every player does as well as they can given the moves of the other players. Equivalently, it is an outcome where no player can improve their payout by unilaterally defecting from the equilibrium.6 The Radical Interpreter feels like they should be a humanesque character in Alice in Wonderland or The Phantom Tollbooth, but for now they are resolutely abstract.Let’s look at a more complicated game. I’ll call it The Interpretation Game. The game has two players. Just like in Newcomb’s problem, one of them is a human, the other is a philosophical invention. But in this case the invention is not a demon, but The Radical Interpreter.6 To know the payouts for the players, we need to know their value function. More colloquially, we need to know their goals.\n\nThe Radical Interpreter assigns mental states to Human in such a way as to predict Human’s actions given Human rationality. We’ll assume here that evidence is a mental state, so saying what evidence Human has is among Radical Interpreter’s tasks. (Indeed, in the game play to come, it will be their primary task.)\nHuman acts so as to maximise the expected utility of their action, conditional on the evidence that they have. Human doesn’t always know what evidence they have; it depends on what The Radical Interpreter says.\n\nThe result is that the game is a coordination game. The Radical Interpreter wants to assign evidence in a way that predicts rational Human action, and Human wants to do what’s rational given that assignment of evidence. Coordination games typically have multiple equilibria, and this one is no exception.\nLet’s make all that (marginally) more concrete. Human is offered a bet on p. If the bet wins, it wins 1 util; if the bet loses, it loses 100 utils. Human’s only choice is to Take or Decline the bet. The proposition p, the subject of the bet, is like the claim that Rahul is in the restaurant. It is something that is arguably part of Human’s evidence. Unfortunately, it is also arguable that it is not part of Human’s evidence. We will let \\(K\\) be the rest of Human’s evidence (apart from \\(p\\), and things entailed by \\(K \\cup \\{p\\}\\)), and stipulate that \\(\\Pr(p | K) = 0.9\\). Each party now faces a choice.\n\nThe Radical Interpreter has to choose whether p is part of Human’s evidence or not.\nHuman has to decide whether to Take or Decline the bet.\n\nThe Radical Interpreter achieves their goal if human takes the bet iff p is part of their evidence. If p is part of the evidence, then The Radical Interpreter thinks that the bet has positive expected utility, so Human will take it. And if p is not part of the evidence, then The Radical Interpreter thinks that the bet has negative expected utility, so Human will decline it. Either way, The Radical Interpreter wants Human’s action to coordinate with theirs. And Human, of course, wants to maximise expected utility. So we get the following table for the game.\n\n\n\n\n\n\\(p \\in E\\)\n\\(p \\notin E\\)\n\n\n\n\nTake the bet\n1, 1\n-9.1, 0\n\n\nDecline the bet\n0, 0\n0, 1\n\n\n\n\nWe have, in effect, already covered The Radical Interpreter’s payouts. They win in the top-left and lower-right quadrants, and lose otherwise. Human’s payouts are only a little trickier. In the bottom row, they are guaranteed 0, since the bet is declined. In the top-left, the bet is a sure winner; their evidence entails it wins. So they get a payout of 1. In the top-right, the bet wins with probability 0.9, so the expected return7 of taking it is \\(1 \\times 0.9 - 100 \\times 0.1 = -9.1\\).\n7 I am making a large, if orthodox, assumption here: that the payouts that we use for equilibrium analysis should be expected returns, not actual returns. I think that’s the right thing to do, since it is usually impossible to say what the actual return of a game is. Even when we say that the payout is a certain number of dollars, we are really saying that the return is a certain kind of gamble. Maybe the value of the currency will deprecate quickly, and the dollars are not that valuable. Maybe the revolution will come and wealth will be a liability. Almost all games have probabilistic payouts, and this game is no different.There are two Nash equilibria for the game - I’ve bolded them below.\n\n\n\n\n\n\\(p \\in E\\)\n\\(p \\notin E\\)\n\n\n\n\nTake the bet\n1, 1\n-9.1, 0\n\n\nDecline the bet\n0, 0\n0, 1\n\n\n\n\nThe mathematical result that there are two equilibria to this game should not come as a surprise. In discussing games like this earlier, we said that general principles connecting evidence, knowledge and action are not predictive; they are consistent both with p being part of the evidence, and with it not being part of the evidence. The general principles we had stated rule out, in effect, non-equilibrium solutions to games like this one. But they are not predictive in cases where there are multiple equilibria.\nTo make more progress, we need to turn to more contested areas of game theory. In particular, we need to look at some work on equilibrium choice. We’ll introduce this material via a game that is inspired by an example of Rousseau’s.\n\n\n0.5 Equilibrium Selection Principles\nAt an almost maximal level of abstraction, a two player, two option each game looks like this.\n\n\n\n\n\n\\(a\\)\n\\(b\\)\n\n\n\n\n\\(A\\)\n\\(r_{11}\\), \\(c_{11}\\)\n\\(r_{12}\\), \\(c_{12}\\)\n\n\n\\(B\\)\n\\(r_{21}\\), \\(c_{21}\\)\n\\(r_{22}\\), \\(c_{22}\\)\n\n\n\n\nWe’re going to focus on games that have the following eight properties:\n\n\\(r_{11} &gt; r_{21}\\)\n\\(r_{22} &gt; r_{12}\\)\n\\(c_{11} &gt; c_{12}\\)\n\\(c_{22} &gt; c_{21}\\)\n\\(r_{11} &gt; r_{22}\\)\n\\(c_{11} \\geq c_{22}\\)\n\\(\\frac{r_{21}+r_{22}}{2} &gt; \\frac{r_{11}+r_{12}}{2}\\)\n\\(\\frac{c_{12}+c_{22}}{2} \\geq \\frac{c_{11}+c_{21}}{2}\\)\n\nThe first four clauses say that the game has two (strict) Nash equilibria: \\(Aa\\) and \\(Bb\\). The fifth and sixth clauses say that the \\(Aa\\) equilibria is Pareto-optimal: no one prefers the other equilibria to it. In fact it says something a bit stronger: one of the players strictly prefers the \\(Aa\\) equilibria, and the other player does not prefer \\(Bb\\). The seventh and eighth clauses say that the \\(Bb\\) equilibria is risk-optimal. Risk-optimality is a somewhat complicated notion in general; see Harsanyi and Selten (1988) for more details. But for our purposes, we can focus on a simple characterisation of it. Neither player would prefer playing \\(A\\)/\\(a\\) to playing \\(B\\)/\\(b\\) if they thought it was a coin flip which equilibrium the other player was aiming for.\nI’m going to offer an argument from Hans Carlsson and Eric van Damme (1993) for the idea that in these games, rational players will end up at \\(Bb\\). The game that Human and The Radical Interpreter are playing fits these eight conditions, and The Radical Interpreter is perfectly rational, so this will imply that in that game, The Radical Interpreter will say that \\(p \\notin E\\), which is what we aimed to show.\nGames satisfying these eight inequalities are sometimes called Stag Hunt games. There is some flexibility, and some vagueness, in which of the eight inequalities need to be strict, but that level of detail isn’t important here. The name comes from a thought experiment in Rousseau’s Discourse on Inequality.\n\n[T]hey were perfect strangers to foresight, and were so far from troubling themselves about the distant future, that they hardly thought of the morrow. If a deer was to be taken, every one saw that, in order to succeed, he must abide faithfully by his post: but if a hare happened to come within the reach of any one of them, it is not to be doubted that he pursued it without scruple, and, having seized his prey, cared very little, if by so doing he caused his companions to miss theirs.  (Rousseau 1913, 209–10)\n\nIt is rather interesting to think through which real-life situations are best modeled as Stag Hunts, especially in situations where people have thought that the right model was a version of Prisoners’ Dilemma. This kind of thought is one way in to appreciating the virtues of Rousseau’s political outlook, and especially the idea that social coordination might not require anything like the heavy regulatory presence that, say, Hobbes thought was needed. But that’s a story for another day. What we’re going to be interested in is why Rousseau was right to think that a ‘stranger to foresight’, who is just focussing on this game, should take the rabbit.\nTo make matters a little easier, we’ll focus on a very particular instance of Stag Hunt, as shown here. (From here I’m following Carlsson and van Damme very closely; this is their example, with just the labelling slightly altered.)\n\n\n\n\n\n\\(a\\)\n\\(b\\)\n\n\n\n\n\\(A\\)\n4, 4\n0, 3\n\n\n\\(B\\)\n3, 0\n3, 3\n\n\n\n\nAt first glance it might seem like \\(Aa\\) is the right choice; it produces the best outcome. This isn’t like Prisoners Dilemma, where the best collective outcome is dominated. In fact \\(Aa\\) is the best outcome for each individual. But it is risky, and Carlsson and van Damme show how to turn that risk into an argument for choosing \\(Bb\\).\nEmbed this game in what they call a global game. We’ll start the game with each player knowing just that they will play a game with the following payout table, with \\(x\\) to be selected at random from a flat distribution over \\([-1, 5]\\).\n\n\n\n\n\n\\(a\\)\n\\(b\\)\n\n\n\n\n\\(A\\)\n4, 4\n0, x\n\n\n\\(B\\)\nx, 0\nx, x\n\n\n\n\nBefore they play the game, each player will get a noisy signal about the value of \\(x\\). There will be signals \\(s_R\\) and \\(s_C\\) chosen (independently) from a flat distribution over \\([x - 0.25, x + 0.25]\\), and shown to Row and Column respectively. So each player will know the value of \\(x\\) to within \\(\\frac{1}{4}\\), and know that the other player knows it to within \\(\\frac{1}{4}\\) as well. But this is a margin of error model, and in those models there is very little that is common knowledge. That, they argue, makes a huge difference.\nIn particular, they prove that iterated deletion of strictly dominated strategies (almost) removes all but one strategy pair.8 Each player will play \\(A\\)/\\(a\\) if the signal is greater than 2, and \\(B\\)/\\(b\\) otherwise.9 Surprisingly, this shows that players should play the risk-optimal strategy even when they know the other strategy is Pareto-optimal. When a player gets a signal in \\((2, 3.75)\\), then they know that \\(x &lt; 4\\), so \\(Bb\\) is the Pareto-optimal equilibrium. But the logic of the global game suggests the risk-dominant equilibrium is what to play.\n8 A sketch of the proof is in Appendix One.9 Strictly speaking, we can’t rule out various mixed strategies when the signal is precisely 2, but this makes little difference, since that occurs with probability 0.Carlsson and van Damme go on to show that many of the details of this case don’t matter. As long as (a) there is a margin of error in each side’s estimation of the payoffs, and (b) every choice is a dominant option in some version of the global game, then iterated deletion of strongly dominant strategies will lead to each player making the risk-dominant choice.\nI conclude from that that risk-dominant choices are rational in these games. There is a limit assumption involved here; what’s true for games with arbitrarily small margins of error is true for games with no margin of error. (We’ll come back to that assumption below.) And since The Radical Interpreter is rational, they will play the strategy that is not eliminated by deleting dominant strategies. That is, they will play the risk-dominant strategy.\nIn game with Human, the rational (i.e., risk-dominant) strategy for The Radical Interpreter is to say that \\(p \\notin E\\). And in the case of Parveen and Rahul, rational (i.e., risk-dominant) strategy for The Radical Interpreter is to say that it is not part of Parveen’s evidence that Rahul is in the restaurant. And this is an interest-relative theory of evidence; had Parveen been playing a different game, The Radical Interpreter would have said that it is part of Parveen’s evidence that Rahul was in the restaurant.\nAnd from this point we can say all the things we wanted to say about the case. If it is part of Parveen’s evidence that Rahul is in the restaurant, then she knows this. Conversely, if she knows it, then The Radical Interpreter would have said it is part of her evidence, so it is part of her evidence. Parveen will perform the action that maximises expected utility given her evidence. And she will lose knowledge when that disposition makes her do things that would be known to be sub-optimal if she didn’t lose knowledge.\nIn short, this model gives us a way to keep what was good about the pragmatic encroachment theory, while also allowing that evidence can be interest-relative. It does require a slightly more complex theory of rationality than we had previously used. Rather than just say that agents maximise evidential expected utility, we have to say that they play risk-dominant strategies in coordination games. But it turns out that this is little more than saying that they maximise evidential expected utility, and they expect others (at least perfectly rational abstract others) to do the same, and they expect those others to expect they will maximise expected utility, and so on.\n\n\n0.6 Objections and Replies\nWe’ll end the body of the paper with some objections that might be raised to this model. And then the appendix will contain proofs of a couple of the formal claims.\nObjection: The formal result of the previous section only goes through if we assume that the agents do not know precisely what the payoffs are in the game. We shouldn’t assume that what holds for arbitrarily small margins of error will hold in the limit, i.e., when they do know the payoffs.\nReply: If pushed, I would defend the use limit assumptions like this to resolve hard cases like Stag Hunt. But I don’t need that assumption here, What we really need is that Parveen doesn’t know precisely the probability of Rahul being in the restaurant given the rest of her evidence. Given that evidence is not luminous, as Williamson (2000) shows, this is a reasonable assumption. So the margin of error assumption that Carlsson and van Damme make is not, in our case, an assumption that merely makes the math easier; it is built into the case.\nObjection: Even if Parveen doesn’t know the payoffs precisely, The Radical Interpreter does. They are an idealisation, so they can be taken to be ideal.\nReply: It turns out that Carlsson and van Damme’s result doesn’t require that both parties are ignorant of the precise values of the payoffs. As long as one party doesn’t know the exact value of the payoff, the argument goes through. I prove this in Appendix Two.\nObjection: The formal argument requires that in the ‘global game’ there are values for \\(x\\) that make \\(A\\) the dominant choice. These cases serve as a base step for an inductive argument that follows. But in Parveen’s case, there is no such setting for \\(x\\), so the inductive argument can’t get going.\nReply: What matters is that there are values of \\(x\\) such that \\(A\\) is the strictly dominant choice, and Human (or Parveen) doesn’t know that they know that they know, etc., that those values are not actual. And that’s true in our case. For all Human (or Parveen) knows that they know that they know that they know…, the proposition in question is not part of their evidence under a maximally expansive verdict on The Radical Interpreter’s part. So the relevant cases are there in the model, even if for some high value of \\(n\\) they are known\\(^n\\) not to obtain.\nObjection: This model is much more complex than the simple motivation for pragmatic encroachment.\nReply: Sadly, this is true. I would like to have a simpler model, but I don’t know how to create one. The argument I gave earlier that our simple principles underdetermine what to say in cases like Parveen and Rahul’s seems fairly compelling. So more complexity will be needed, one way or another. I think paying this price in complexity is worth it overall, but I can see how some people might think otherwise.\nObjection: Change the case involving Human so that the bet loses 15 utils if p is false, rather than 100. Now the risk-dominant equilibrium is that Human takes the bet, and The Radical Interpreter says that p is part of Human’s evidence. But note that if it was clearly true that p was not part of Human’s evidence, then this would still be too risky a situation for them to know p. So whether it is possible that p is part of Human’s evidence matters.\nReply: This is all true, and it shows that the view I’m putting forward is incompatible with some programs in epistemology. In particular, it is incompatible with E=K, since the what it takes to be evidence on this story is slightly different from what it takes to be knowledge. I don’t think E=K is so intuitively obvious that this refutes the theory, but it is potentially a cost that I have to give it up.\nObjection: Carlsson and van Damme discuss one kind of global game. But there are other global games that have different equilibria. For instance, changing the method by which the noisy signal is selected would change the equilibrium of the global game. So this kind of argument can’t show that the risk-dominant equilibrium is the one true solution.\nReply: This is somewhat true. There are other ways of embedding the game involving Human and The Radical Interpreter in global games that lead to different outcomes. They are usually somewhat artificial; e.g., by having the signal be systematically biased in one way. But what really matters is the game where the error in Human’s knowledge of the payoffs is determined by their actual epistemic limitations. I think that will lead to something like the model we have here. But it is possible that the final result will differ a bit from what I have here, or (more likely) have some indeterminacy about just how interests interact with evidence and knowledge. The precise details are ultimately less important to me than whether we can provide a motivated story of how interests affect knowledge and evidence that does not presuppose we know what the agent’s evidence is. And the method I’ve outlined here shows that we can do that, even if we end up tinkering a bit with the details.\n\n\nAppendix One: Carlsson and van Damme’s Game\nTwo players, Row (or R) and Column (or C) will a version of the following game.\n\n\n\n\n\n\\(a\\)\n\\(b\\)\n\n\n\n\n\\(A\\)\n4, 4\n0, x\n\n\n\\(B\\)\nx, 0\nx, x\n\n\n\n\nThey won’t be told what \\(x\\) is, but they will get a noisy signal of \\(x\\), drawn from an even distribution over \\([x - 0.25, x + 0.25]\\). Call these signals \\(s_R\\) and \\(s_C\\). Each player must then choose \\(A\\), getting either 4 or 0 depending on the other player’s choice, or choose \\(B\\), getting \\(x\\) for sure.\nBefore getting the signal, the players must choose a strategy. A strategy is a function from signals to choices. Since the higher the signal is, the better it is to play \\(B\\), we can equate strategies with ‘tipping points’, where the player plays \\(B\\) if the signal is above the tipping point, and \\(A\\) below the tipping point. Strictly speaking, a tipping point will pick out not a strategy but an equivalence class of strategies, which differ in how they act if the signal is the tipping point. But since that happens with probability 0, the strategies in the equivalence class have the same expected return, and so we won’t aim to distinguish them.\nAlso, strictly speaking, there are strategies that are not tipping points, because they map signals onto probabilities of playing \\(A\\), where the probability decreases as \\(A\\) rises. I won’t discuss these directly, but it isn’t too hard to see how these are shown to be suboptimal using the argument that is about to come. It eases exposition to focus on the pure strategies, and to equate these with tipping points. And since my primary aim here is to explain why the result holds, not to simply repeat an already existing proof, I’ll mostly ignore these mixed strategies.\nCall the tipping points for Row and Column respectively \\(T_R\\) and \\(T_C\\). Since the game is symmetric, we’ll just have to show that in conditions of common knowledge of rationality, \\(T_R = 2\\). It follows by symmetry that \\(T_C = 2\\) as well. And the only rule we’ll use is iterated deletion of strictly dominated strategies. That is, we’ll assume players won’t play strategies where another strategy does better no matter what the opponent chooses, and they won’t play strategies where another strategy does better provided the other player does not play a dominated strategy, and they won’t play strategies where another strategy does better provided the other player does not play a strategy ruled out by these first two conditions, and so on.\nThe return to a strategy is uncertain, even given the other player’s strategy. But given the strategies of each player, we can work out an expected return for each player. And that’s what we’ll assume is the return to a strategy pair.\nNote first that \\(T_R = 4.25\\) strictly dominates any strategy where \\(T_R = y &gt; 4.25\\). If \\(s_R \\in (4.25, y)\\), then \\(T_R\\) is guaranteed to return above 4, and the alternative strategy is guaranteed to return 4. In all other cases, the strategies have the same return. And there is some chance that \\(s_R \\in (4.25, y)\\). So we can delete all strategies \\(T_R = y &gt; 4.25\\), and similarly all strategies \\(T_C = y &gt; 4.25\\). By similar reasoning, we can rule out \\(T_R &lt; -0.25\\) and \\(T_C &lt; -0.25\\).\nIf \\(s_R \\in [-0.75, 4.75]\\), then it is equally likely that \\(x\\) is above \\(s_R\\) as it is below it. Indeed, the posterior distribution of \\(x\\) is flat over \\([s_R - 0.25, s_R + 0.25]\\). From this it follows that the expected return of playing \\(B\\) after seeing signal \\(s_R\\) is just \\(s_R\\).\nNow comes the important step. Assume that we know that \\(T_C \\leq y &gt; 2\\). Now consider the expected return of playing \\(A\\) given various values for \\(s_R &gt; 2\\). Given that the lower \\(T_C\\) is, the higher the expected return is of playing \\(A\\), we’ll just work on the simple case where \\(T_C = y\\), realizing that this is an upper bound on the expected return of \\(A\\) given \\(T_C \\leq y\\). The expected return of \\(A\\) is 4 times the probability that Column will play \\(a\\), i.e., 4 times the probability that \\(s_C &lt; T_C\\). Given all the symmetries that have been built into the puzzle, we know that the probability that \\(s_C &lt; s_R\\) is 0.5. So the expected return of playing \\(A\\) is at most 2 if \\(s_R \\geq y\\). But the expected return of playing \\(B\\) is, as we showed in the last paragraph, \\(s_R\\), which is greater than 2. So it is better to play \\(B\\) than \\(A\\) if \\(s_R \\geq y\\). And the difference is substantial, so even if \\(s_R\\) is epsilon less than that \\(y\\), it will still be better to play \\(B\\). (This is hand-wavy of course, but we’ll make it rigorous in just a second.)\nSo if \\(T_C \\leq y &gt; 2\\) we can prove that \\(T_R\\) should be lower still, because given that assumption it is better to play \\(B\\) even if the signal is just less than \\(y\\). Repeating this reasoning over and over again pushes us to it being better to play \\(B\\) than \\(A\\) as long as \\(s_R &gt; 2\\). And the same kind of reasoning from the opposite end pushes us to it being better to play \\(A\\) than \\(B\\) as long as \\(s_R &lt; 2\\). So we get \\(s_R = 2\\) as the uniquely rational solution to the game.\nLet’s make that a touch more rigorous. Assume that \\(T_C = y\\), and \\(s_r\\) is slightly less than \\(y\\). In particular, we’ll assume that \\(z = y - s_R\\) is in \\((0, 0.5)\\). Then the probability that \\(s_C &lt; y\\) is \\(0.5 + 2z - 2z^2\\). So the expected return of playing \\(A\\) is \\(2 + 8z - 8z^2\\). And the expected return of playing \\(B\\) is, again, \\(s_R\\). These will be equal when the following is true. (The working out is a tedious but trivial application of the quadratic formula, plus some rearranging.)\n\\[s_R = y + \\frac{\\sqrt{145-32y} - 9}{16}\\] So if we know that \\(T_C \\geq y\\), we know that \\(T_R \\geq y + \\frac{\\sqrt{145-32y} - 9}{16}\\), which will be less than \\(y\\) if \\(y &gt; 2\\). And then by symmetry, we know that \\(T_C\\) must be at most as large as that as well. And then we can use that fact to derive a further upper bound on \\(T_R\\) and hence on \\(T_C\\), and so on. And this will continue until we push both down to 2. It does require quite a number of steps of iterated deletion. Here is the upper bound on the threshold after \\(n\\) rounds of deletion of dominated strategies. (These numbers are precise for the first two rounds, then just to three significant figures after that.)\n\n\n\n\nRound\nUpper Bound on Threshold\n\n\n\n\n1\n4.250\n\n\n2\n3.875\n\n\n3\n3.599\n\n\n4\n3.378\n\n\n5\n3.195\n\n\n6\n3.041\n\n\n7\n2.910\n\n\n8\n2.798\n\n\n9\n2.701\n\n\n10\n2.617\n\n\n\n\nThat is, \\(T_R = 4.25\\) dominates any strategy with a tipping point above 4.25. And \\(T_R = 3.875\\) dominates any strategy with a higher tipping point than that, assuming \\(T_C \\leq 4.25\\). And \\(T_R \\approx 3.599\\) dominates any strategy with a higher tipping point than that, assuming \\(T_C \\leq 3.875\\). And so on.\nAnd similar reasoning shows that at each stage not only are all strategies with higher tipping points dominated, but so are strategies that assign positive probability (whether it is 1 or less than 1), to playing \\(A\\) when the signal is above the ‘tipping point’. So this kind of reasoning rules out all mixed strategies (except those that respond probabilistically to \\(s_R = 2\\)).\nSo we’ve shown what was intended, namely that iterated deletion of dominated strategies will rule out all strategies except the risk-optimal equilibrium. We needed the possibility that \\(x\\) is greater than the maximal return for \\(A\\) to get the iterated dominance going. And we needed the signal to have an error bar to it, so that each round of iteration removes more strategies. But that’s all we needed; the particular values we chose are irrelevant to the proof.\n\n\nAppendix Two: The Modified Game\nThe aim of this section is to prove something that Carllson and van Damme did not prove, namely that the analysis of the previous appendix goes through with very little change if one party gets a perfect signal, while the other gets a noisy signal. That is, we’re going to consider the game that is just like the game of appendix one, but it is common knowledge that the signal Column gets, \\(s_C\\), equals \\(x\\).\nSince the game is no longer symmetric, we can’t appeal to the symmetry of the game as we frequently did in the previous appendix. But this only slows the proof down, it doesn’t stop it.\nWe can actually rule out slightly more at the first step in this game than in the previous game. Since Column could not be wrong about \\(x\\), Column knows that if \\(s_C &gt; 4\\) then playing \\(b\\) dominates playing \\(a\\). So one round of deleting dominated strategies rules out \\(T_C &gt; 4\\), as well as ruling out \\(T_R &gt; 4.25\\).\nAt any stage, if we know \\(T_C \\leq y &gt; 2\\), then \\(T_R = y\\) dominates \\(T_R &gt; y\\). That’s because if \\(s_R \\geq y\\), and \\(T_C \\leq y\\), then the probability that Column will play \\(a\\) (given Row’s signal) is less than 0.5. After all, the signal is just as likely to be above \\(x\\) as below it (as long as the signal isn’t too close to the extremes). So if \\(s_R\\) is at or above \\(T_C\\), then it is at least 0.5 likely that \\(s_C = x\\) is at or above \\(T_C\\). So the expected return of playing \\(A\\) is at most 2. But the expected return of playing \\(B\\) equals the signal, which is greater than 2. So if Row knows \\(T_C \\leq y &gt; 2\\), Row also knows it is better to play \\(B\\) if \\(s_R \\geq y\\). And that just means that \\(T_R \\leq y\\).\nAssume now that it is common knowledge that \\(T_R \\leq y\\), for some \\(y &gt; 2\\). And assume that \\(x = s_C\\) is just a little less than \\(y\\). In particular, define \\(z = y -x\\), and assume \\(z \\in (0, 0.25)\\). We want to work out the upper bound on the expected return to Column of playing \\(a\\). (The return of playing \\(b\\) is known, it is \\(x\\).) The will be highest when \\(T_R\\) is lowest, so assume \\(T_R \\leq y\\). Then the probability that Row plays \\(A\\) is \\((1 + 2z)/2\\). So the expected return of playing \\(a\\) is \\(2 + 4z\\), i.e., \\(2 + 4(y - x)\\). That will be greater than \\(x\\) only when\n\\[x &lt; \\frac{2 + 4y}{5}\\] And so if it is common knowledge that \\(T_R \\leq y\\), then it is best for Column to play \\(b\\) unless \\(x &lt; \\frac{2 + 4y}{5}\\). That is, if it is common knowledge that \\(T_R \\leq y\\), then \\(T_C\\) must be at most \\(\\frac{2 + 4y}{5}\\).\nSo now we proceed in a zig-zag fashion. At one stage, we show that \\(T_R\\) must be as low as \\(T_C\\). At the next, we show that if it has been proven that \\(T_R\\) takes a particular value greater than 2, then \\(T_C\\) must be lower still. And this process will eventually rule out all values for \\(T_R\\) and \\(T_C\\) greater than 2.\nThis case is crucial to the story of the paper because The Radical Interpreter probably does not have an error bar in their estimation of the game they are playing. But it turns out the argument for risk-dominant equilibria being the unique solution to interpretation games is consistent with that. As long as one player has a margin of error, each player should play the risk-dominant equilibria.\n\n\n\n\n\n\nReferences\n\nBrown, Jessica. 2008. “Subject-Sensitive Invariantism and the Knowledge Norm for Practical Reasoning.” Noûs 42 (2): 167–89. https://doi.org/10.1111/j.1468-0068.2008.00677.x.\n\n\nCarlsson, Hans, and Eric van Damme. 1993. “Global Games and Equilibrium Selection.” Econometrica 61 (5): 989–1018. https://doi.org/10.2307/2951491.\n\n\nFantl, Jeremy, and Matthew McGrath. 2009. Knowledge in an Uncertain World. Oxford: Oxford University Press.\n\n\nHarsanyi, John C., and Reinhard Selten. 1988. A General Theory of Equilibrium Selection in Games. Cambridge, MA: MIT Press.\n\n\nHawthorne, John. 2004. Knowledge and Lotteries. Oxford: Oxford University Press.\n\n\nIchikawa, Jonathan Jenkins, Benjamin Jarvis, and Katherine Rubin. 2012. “Pragmatic Encroachment and Belief-Desire Psychology.” Analytic Philosophy 53 (4): 327–43. https://doi.org/10.1111/j.2153-960X.2012.00564.x.\n\n\nLackey, Jennifer. 2010. “Acting on Knowledge.” Philosophical Perspectives 24: 361–82. https://doi.org/10.1111/j.1520-8583.2010.00196.x.\n\n\nReed, Baron. 2014. “Practical Matters Do Not Affect Whether You Know.” In Contemporary Debates in Epistemology, edited by Matthias Steup, John Turri, and Ernest Sosa, 2nd ed., 95–106. Chicester: Wiley-Blackwell.\n\n\nRousseau, Jean-Jacques. 1913. Social Contract & Discourses. Translated by G. D. H. Cole. New York: J. M. Dent & Sons.\n\n\nRubin, Katherine. 2015. “Total Pragmatic Encroachment and Epistemic Permissiveness.” Pacific Philosophical Quarterly 96: 12–38. https://doi.org/10.1111/papq.12060.\n\n\nSchwitzgebel, Eric. 2008. “The Unreliability of Naive Introspection.” Philosophical Review 117 (2): 245–73. https://doi.org/10.1215/00318108-2007-037.\n\n\nStanley, Jason. 2005. Knowledge and Practical Interests. Oxford University Press.\n\n\nWilliamson, Timothy. 2000. Knowledge and its Limits. Oxford University Press.\n\n\n———. 2007. The Philosophy of Philosophy. Blackwell."
  },
  {
    "objectID": "posts/prank/index.html",
    "href": "posts/prank/index.html",
    "title": "Prankster’s Ethics",
    "section": "",
    "text": "0.1 A Quick Argument for Boorishness\nDiversity is a good thing. Some of its value is instrumental. Having people around with diverse beliefs, or customs, or tastes, can expand our horizons and potentially raise to salience some potential true beliefs, useful customs or apt tastes. Even diversity of error can be useful. Seeing other people fall away from the true and the useful in distinctive ways can immunise us against similar errors. And there are a variety of pleasant interactions, not least philosophical exchange, that wouldn’t be possible unless some kinds of diversity existed. Diversity may also have intrinsic value. It may be that a society with diverse views, customs and tastes is simply thereby a better society. But we will mostly focus on diversity’s instrumental value here.\n\nPublished in Philosophical Perspectives 18: 45-52.\n\nWe think that what is true of these common types of diversity is also true of moral diversity. By moral diversity we mean not only diversity of moral views, though that is no doubt valuable, but diversity of moral behaviour. In a morally diverse society, at least some people will not conform as tightly to moral norms as others. In short, there will be some wrongdoers. To be sure, moral diversity has some costs, and too much of it is undoubtedly a bad thing. Having rapists and murderers adds to moral diversity (assuming, as we do, that most people are basically moral) but not in a way that is particularly valuable. Still, smaller amounts of moral diversity may be valuable, all things considered. It seems particularly clear that moral diversity within a subgroup has value, but sometimes society as a whole is better off for being morally diverse. Let us consider some examples.\nMany violations of etiquette are not moral transgressions. Eating asparagus spears with one’s fork is not sinful, just poor form. But more extreme violations may be sinful. Hurtful use of racial epithets, for example, is clearly immoral as well as a breach of etiquette. Even use of language that causes not hurt, but strong discomfort, may be morally wrong. Someone who uses an offensive term in polite company, say at a dinner party or in a professional philosophical forum, may be doing the wrong thing. But having the wrongdoer around may have valuable consequences. For example, they generate stories that can be told, to great amusement, at subsequent dinner parties. They also prompt us to reconsider the basis for the standards we ourselves adopt in such matters. The reconsideration may cause us to abandon useless practices, and it may reinforce useful practices. These benefits seem to outweigh the disutility of the discomfort felt by those in attendance when the fateful word drops from the speaker’s lips. These side benefits do not make the original action morally permissible. Indeed, it is precisely because the action is not morally permissible that the benefits accrue.\nWhile we think that case is one of valuable moral diversity, some may question the immorality of the act in question. So let us try a more clearly immoral case: the mostly harmless prankster. Sam is a pie-thrower. Sam doesn’t just throw pies at the rich and infamous. No, Sam’s pies land on common folk like you and I, often for no reason beyond Sam’s amusement. Causing gratuitous harm for one’s own amusement is immoral. And a pie in the face, while better than a poke in the eye with a burnt stick, is harmful. But it may, in some circumstances, have side benefits. There will be the (guilty) pleasure occasioned in the unharmed bystanders, though it would be wrong to put too much weight on that. Other more significant benefits may accrue if Sam’s society is otherwise saintly. Sam’s existence will prompt people to take some simple, and worthwhile, precautions against perpetrators of such attacks. Even if society currently contains no malfeasants, such precautions will be useful against future wrongdoers. This benefit will increase if Sam graduates from pie-throwing to more varied pranks. (As may the entertainment value of Sam’s pranks.) Many computer hackers perform just this function in the present world. Malicious hackers on the whole cause more harm than good. But other hackers, who hack without gratuitously harming, provide a protective benefit by informing us of our weaknesses. These are the pie-throwers of the virtual world. Sam’s actions have other benefits. If Sam’s pranks are harmless enough, some will mistakenly think that they are morally acceptable, and we can have enjoyable, valuable, philosophical discussions with them. (Note that this benefit also increases if Sam varies the pranks.) The upshot is that Sam’s pranks can make the world a better place, all things considered, despite being immoral. Indeed, in some ways they make the world a better place because they are immoral.\nThe philosophical point, or points, here may be familiar. One point certainly is familiar: we have here an example of a Moorean organic unity. The goodness of the whole is no simple function of the goodness of the parts. It might be thought that this follows simply from the familiar counterexamples to utilitarianism, and that our examples have no more philosophical interest than those old counterexamples. Both of these thoughts would be mistaken.\nThe familiar counterexamples we have in mind include, for example, the case of the doctor who kills a healthy patient to harvest her organs, or the judge who executes an innocent man to prevent a riot. Importantly, those examples do not refute consequentialism in general, but only a version of consequentialism that adopts a particular kind of reductive analysis of the good. The details of the analysis won’t matter here, but it may be an analysis of goodness in terms on happiness, or preference satisfaction. If we give up the reductive analysis of goodness, we can say that the doctor and the judge do not make for a better society. A familiar heuristic supports that claim. (We take no stand here on whether this heuristic can be turned into an analysis.) Behind the Rawlsian veil of ignorance, we would prefer that there not be such doctors or judges in society. We think that most of us would agree, even in full appreciation of the possibility that we will be saved by the doctor, or possibly the judge. On the other hand, we think we’d prefer a society with the occasional boorish dinner guest, or a rare pie-thrower, to a society of moral saints. We say this in full appreciation of the possibility that we may get a pie in the face for our troubles. Possibly if we knew we would be the pie-throwee we would change our minds, but fortunately pies cannot penetrate the veil of ignorance.\nAlthough it isn’t much discussed in the literature, we think this form of consequentialism is interesting for several reasons beyond its capacity to avoid counterexamples. For one thing, it is not easy to say whether this counts as an agent-neutral ethical theory. On the one hand, we can say what everyone should do in neutral terms: for each person it is better if they do things that create a better world from the perspective of those behind the veil of ignorance. On the other hand this rule leads to obligations on agents that do not seem at all neutral. From behind the veil of ignorance we’d prefer that parents love their children and hence privilege their interests, and that they love them because they are their children not because this creates a better world, so parents end up with a special obligation to their children. Having this much (or more importantly this little) neutrality in a moral theory sounds quite plausible to us, and although we won’t develop the point here there is possibly an attractive answer to the ‘nearest and dearest’ objection to consequentialism (Jackson 1991). More generally, because we have preferences from behind the veil of ignorance about why people act and not just about how they act – we prefer for instance that people visit sick friends in hospital because they are friends not because of an abstract sense of duty – this form of consequentialism is not particularly vulnerable to objections that claim consequentialists pay too little attention to motives.\nSo we think a consequentialist can avoid the standard objections to utilitarianism by being less ambitious and not trying to provide a reductive analysis of goodness. The most natural retreat is to behind the veil of ignorance, but our examples can reach even there. This is far from the only interesting consequence of the examples.\n\n\n0.2 The Good, the Right, and the Saintly\nWe think that the cases of the curser and the pie-thrower are examples of situations in which (a) an agent ought not to \\(\\varphi\\), and (b) it’s best that the agent does \\(\\varphi\\). Our judgements about the cases are not based on any theoretical analysis of the right and the good. They’re simply intuitions about cases—it just seems to us that the right thing to say about the pie thrower is that she ought not to do what she does, but that it’s still best if she does it. To the extent that these intuitions are puzzling or theoretically problematic (and we think that they are at least a little bit puzzling, and at least potentially problematic), it’s open to us to reject one or the other intuition about the cases, and either deny that the curser and the pie thrower ought not to curse or throw pies, or deny that it’s best that they do curse and throw pies. This is an option, but we think it’s not a very attractive one. Suppose that instead we take the intuitions at face value, and accept our judgements about the cases. What follows?\nOur analysis of the examples is incompatible with two attractive views about the connection between goodness (that is, the property of things—in particular worlds—in virtue of which some of them stand in the better than relation to others) and rightness, and between goodness and good character:\n\nIt’s better if everyone does what’s right.\nIt’s better if everyone has good character.1\n\n1 Proposition (2) is quite a natural position to hold if one is trying to capture the insights of virtue ethics in a consequentialist framework, as in Driver (2001) or Hurka (2001). But if we take ‘better’ in a more neutral way, so (2) does not mean that there are better consequences if everyone has good character, but simply that the world is a better place if this is so, even if this has few consequences, or even negative consequences, then it will be a position common to most virtue ethicists.Now, neither of these will do as a philosophical thesis. But it’s probably not worth spending the time and effort on patching them up, since even the patched-up versions will be false.\nIf the pie-thrower ought not to throw her pies, but it’s nonetheless best that she does, no patched-up version of (1) that captures the intuition behind it can be right. Any patched-up version of (1) will still be claiming that there’s a very tight connection between what it would be right for us to do (what we ought to do) and what it would be best for us to do. Any plausible elaboration on (1) will include a commitment to the thesis that, if we ought not to do something, then it’s best if we don’t do it. But if our analyses of the cases of the curser and the pie-thrower are right, then these are counterexamples.\nWhat about (2)? Well, it’s not better if the cursing dinner guest has good character. What happens if we suppose that the curser does have good character? One of two things: (i) He’ll no longer curse at dinner parties, and we’ll lose the benefits that come from his cursing. This would be bad. (ii) He’ll still curse at dinner parties, but he’ll be cursing in a studied way. He’ll be cursing because he’s seen that things will be better if somebody uses foul language in inappropriate circumstances, and he’s taken it upon himself to fill the unfilled functional role. This would also be bad. This sort of studied bad conduct doesn’t have the same value as bad conduct that springs from bad character. Here is some evidence for this: We value the curser’s breaching of societal norms, even though he ought not to do it. Were we to find out that every expletive had been studied, produced either to produce these important social goods, or to create a familiar bad-boy image, we would stop valuing his breachings of the moral order. They would, instead, become merely tiresome and annoying. Since we value spontaneous cursings which are products of less-than-optimal character, but we do not value studied cursings which are products of exemplary character, it’s very plausible to conclude (though admittedly not quite mandatory) that the spontaneous curses are much more valuable than the studied ones. We’re inclined to say, in fact, that while having a few spontaneous cursers around makes things better, having studied cursers around makes things worse. Since you have to have less-than-perfect character in order to be a spontaneous curser, it follows that you can’t get the benefits of having cursers around without having some people with less-than-perfect character around. And since it’s better to have the cursers than not, it’s better to have some people with less-than-perfect character around than not. This will be incompatible with almost any plausible way of cashing out (2).2\n2 Specifically, it will be incompatible with any maximizing version of (2). There are ‘threshold’ versions of (2) that don’t fall afoul of this kind of problem because they don’t claim it would be best for everyone to have perfect character, but only that it would be best for everyone to have pretty good character, or at least for nobody to have really bad character.\n\n0.3 A Problem about Quantifier Scope?\nBut isn’t there a sense in which (for example) the pie-thrower ought to throw his pies? After all, if nobody was throwing pies, we might think to ourselves, “gosh, it would be better if there were a few—not many, but a few—pie throwers around”. Then it would be natural to conclude, “somebody ought to start throwing pies at strangers”. And then it would be natural to infer that at least the first person to start throwing pies at strangers would be doing what they ought. It would be natural, but it would be wrong. The plausible reading of “someone ought to start throwing pies at strangers” is, “it ought to be that somebody starts throwing pies at strangers”, not, “there’s somebody out there such that they ought to start throwing pies at strangers”. So we haven’t gotten anybody a moral license to throw pies yet. And in fact it’s very plausible that we ought to understand assertions that it ought to be that P as claiming that it would be better if it were the case that P; that is, as making claims about what would be good, not about what would be right.\nThere’s a puzzle about what to make of cases where we’re inclined to say that it ought to be that somebody \\(\\varphi\\)s—that is, that somebody ought to \\(\\varphi\\); but also that there’s nobody such that they ought to \\(\\varphi\\)—in fact, that everybody is such that they ought not to \\(\\varphi\\).3 Maybe the fact that our intuitions about the examples give rise to these kinds of puzzling cases is evidence that one or the other of our intuitions ought to be rejected. The move we suggested above is that the reason this seems so puzzling is that we’ve been punning on “ought”. The “ought” in “somebody ought to start throwing pies” doesn’t have anything much to do with what moral obligations anybody has—doesn’t have anything much to do with what’s right—but has a great deal to do with what’s good. And if that’s the case, then all we have is more evidence against the tight connection between the right and the good: it would be better if somebody started throwing pies, but everybody has a moral obligation not to. So it would be better if somebody did what they oughtn’t.\n3 It’s actually the second part that makes it puzzling. Compare the familiar and unproblematic situation in which we ought to give you a horse, but there’s no horse such that we ought to give you that one, and the more troubling situation in which we ought to give you a horse, but every horse is such that we ought not to give you that one.\n\n0.4 Value, Desire and Advice\nAlthough the “ought” in “somebody ought to throw pies” has little to do with what’s right, it might have a lot to do with what we find desirable. And this will cause problems for some familiar meta-ethical theories. Quite naturally, Jack does not desire to throw pies at strangers for amusement in the actual world. Jack’s a very civic minded fellow in that respect. In fact, his concern for others goes deeper than that. He’d be quite prepared to risk his body for the sake of his fellow citizens. As it turns out, he’s been a volunteer fire fighter for years now. And Jack likes to think that if need be, he would be prepared, to use an old fashioned phrase, to risk his soul for the community. He hopes he would be morally depraved if what the society needed was depravity. Jack agrees with the discussion of character in section 2, so he hopes that when society needs a pie-thrower, he will step up with the plate, and do so directly because he wants to throw pies at innocent bystanders. Letting C stand for the circumstances described above, where it would be good for there to be more wrongdoing, Jack’s position can be summarised by saying that he desires that in C he desires that he throws pies at innocents.\nDoes this all mean Jack values his throwing pies at innocents in C? Not necessarily. Does it mean that if we were all like Jack, and we are subjectivists about what is right, it would be right to throw pies at innocents in C? Definitely not. David Lewis (1989) equates what we value with what we desire to desire.4 And he equates what is valuable with what we value. The text is not transparent, but it seems Lewis wants valuable to subsume both what we call the ‘right’ and the ‘good’. And this he cannot have. Assume that everyone in Jack’s community desires to (de se) desire that (s)he throw pies at innocents in C. That does not make it right that pies are thrown at innocents. We take no stand here on whether the flaw is in the equation of personal value with second-order desire, or in the reduction of both rightness and goodness to personal value, but there is a problem for Lewis’s dispositional theory of value.5\n4 More precisely, with what we desire to desire in circumstances of appropriate imaginative acquaintance. We can suppose that Jack, and everyone else under discussion in this paragraph, is suitably imaginatively acquainted with the salient situations. Jack knows full well what it is like to get a pie in the face.5 Someone might think it obvious that Lewisian value can’t be used in an analysis of both rightness and goodness, since it is one concept and we are analysing two concepts. But Lewisian value bifurcates in a way that one might think it is suitable for analysing both rightness and goodness. Since there are both de dicto and de se desires, one can easily draw out both de dicto and de se values. And it is prima facie plausible that the de dicto values correspond to what is good, and the de se values to what is right. Indeed, given a weak version of consequentialism where these two can be guaranteed to not directly conflict, this correspondence may well hold. But we think the pie-thrower threatens even those consequentialists. The net philosophical conclusion is that the pie-thrower is a problem for Lewis’s meta-ethics, but only because (a) she is a problem for Lewis’s consequentialism, and, surprisingly, (b) Lewis’s meta-ethics depends on his consequentialism being at least roughly right.6 We have glossed over a technical point here that is irrelevant to the current discussion. What matters is not whether our perfectly rational selves are motivated to \\(\\varphi\\), it matters whether they desire that we \\(\\varphi\\), and hence whether they are motivated to advise us to \\(\\varphi\\). Keeping this point clear matters for all sorts of purposes, but not we think the present one.This point generalises to cause difficulties for several dispositional theories of value. For example, Michael Smith (1994) holds that right actions are what our perfectly rational selves would advise us to do. This assumes that when the good and the right come apart, our perfectly rational selves would choose the right over the good. And it’s far from clear that Smith has the resources to argue for this assumption. Smith’s argument that our perfectly rational selves will advise us to do what is right relies on his earlier argument that anyone who does not do what she judges to be right is practically irrational, unlike presumably our perfectly rational selves. And the main argument for that principle is that it is the best explanation of why actually good people are motivated to do what they judge to be right, even when they change their judgements about what is right. But now we should be able to see that there’s an alternative explanation available. Actually good people might be motivated to do what they judge to be good rather than right. We have seen no reason to believe that the right and the good actually come radically apart, so this is just as good an explanation of the behaviour actual moral agents as Smith’s explanation. So for all Smith has argued, one might judge \\(\\varphi\\)ing to be right, also judge it not to be good, hence be not motivated to \\(\\varphi\\), and not be practically irrational. Indeed, our perfectly rational self might be just like this.6 Hence we cannot rely on our perfectly rational self to be a barometer of what is right, as opposed to what is good.\n\n\n\n\n\n\nReferences\n\nDriver, Julia. 2001. Uneasy Virtues. Cambridge: Cambridge University Press.\n\n\nHurka, Thomas. 2001. “Vices as Higher-Level Evils.” Utilitas 13 (2): 195–212. https://doi.org/10.1017/s0953820800003137.\n\n\nJackson, Frank. 1991. “Decision Theoretic Consequentialism and the Nearest and Dearest Objection.” Ethics 101 (3): 461–82. https://doi.org/10.1086/293312.\n\n\nLewis, David. 1989. “Dispositional Theories of Value.” Aristotelian Society Supplementary Volume 63 (1): 113–37. https://doi.org/10.1093/aristoteliansupp/63.1.89.\n\n\nSmith, Michael. 1994. The Moral Problem. Oxford: Blackwell."
  },
  {
    "objectID": "posts/review-realm/index.html",
    "href": "posts/review-realm/index.html",
    "title": "Review of “The Realm of Reason”",
    "section": "",
    "text": "Some of what we know we know by experience and some by reason. It’s experience not reason that teaches that Arsenal ended last season with 90 points and Chelsea with 79, it’s reason not experience that teaches 90 is greater than 79, and, arguably, it’s the two together that teach that Arsenal ended with more points than Chelsea. One useful classification of philosophers is by the relative importance they assign to experience and reason in grounding what we know. Empiricists (on one reading of that term) play down reason, sometimes going so far as to declare that anything known by a means other than experience must be a mere matter of definition. Rationalists play reason up.\n\nPublished in the Times Literary Supplement\n\nChristopher Peacocke is firmly in the rationalist camp, and The Realm of Reason is an attempt to lay out what he takes rationalism to be. It gives his preferred version of rationalism and some arguments in its favour. It’s much too much to attempt in a short book and it isn’t entirely persuasive on any of the applications, but it is a grand vision for what a global rationalism might look like, one that might prove attractive even if the details need work. Given the length of the book a surprising amount of time is spent on relatively abstruse details. Peacocke provides a particularly careful account of what distinguishes rationalists from empiricists and does a lot of work classifying and adjudicating between rationalisms of various strengths. These are the best parts of the book, but also the least accessible.\nPeacocke’s preferred version of rationalism has two distinctive components. First, he focuses not on beliefs, as is usual, but on the “transitions” between representational states that occur in thought, as when we move to a new belief on the basis of one we already have. Mental representational states are often beliefs, but they also include things, like perceptions, that have representational content without necessarily being believed. Peacocke’s rationalist claim is that for any justified transition, there’s an a priori explanation of why it is justified. Second, he insists that this explanation rely crucially on the contents of the states involved in the transition.\nSo we get a quite strong “foundationalist” epistemology. Experience provides the foundations for empirical knowledge, but how we get from there to what we know is entirely in the domain of reason. It is famously difficult to justify many steps by reason alone, and the most pressing is the very first: How do we justify the transition from appearances to reality, such as the transition from That looks crooked to That is crooked? Some philosophers have thought that we need to link appearance and reality so closely that the link is infallible. Peacocke doesn’t take that line, so he has to justify the transition some other way.\nDescartes faced a similar problem when trying to get over his radical doubt about the existence of the material world, and solved it by appeal to God. We can tell a priori, he thought, that a benevolent God exists, and a benevolent God will not let us be deceived about this matter, at least when we are careful enough to rely on clear and distinct perceptions. Now Descartes had to be careful here to only appeal to a priori reasons for belief in God. He couldn’t, for instance, argue from the apparent design of the universe to the existence of a designer, because we can’t tell at this stage whether the apparent design is merely an artifact of our defective perceptual faculties. Indeed, we can’t rely on any apparent fact about the external world until we’ve determined that appearances are a good guide to reality. So we need to argue for the existence of God without appeal to perception, and then use God’s existence to justify future reliance on perception.\nIn keeping with the spirit of the age, Peacocke updates Descartes’s strategy by replacing God with Darwin. Very roughly, Peacocke argues that the best explanation of our having representative capacities at all is that we are the products of a long process of natural selection. And if we are the products of a long process of selection, then we probably have accurate representations. If those two claims can be justified a priori we have an a priori argument to the (prima facie, probable) accuracy of our representations.\nLess roughly, Peacocke argues for a “Complexity Reduction Principle”. We are entitled, on a priori grounds, to believe that complex phenomena have explanations, and we are entitled to regard simpler explanations as more probably true than more complex ones. That we have representations at all is a complex matter. How might it be explained? One explanation is via Divine creation. Another is that we are “brains-in-vats” living in a virtual reality world dreamt up by some quirky scientist (cf The Matrix). But neither of these explanations really reduces the complexity, since in each case we need to appeal to a thing (God, the scientist) that already has representational capacities. A simpler explanation, allegedly, is that we are the product of natural selection and having accurate representations is selected for. This is certainly a novel argument for Darwinism. It isn’t why they teach natural selection to biology students. And of course it has flaws. Peacocke does little to show that there are no better explanations of our having representations. Nor does he address the question of how complicated hereditary mechanisms must be if they are to support natural selection. Arguably they are much more complicated than is needed for representation, so Darwin doesn’t help reduce complexity here.\nSo it’s not clear Peacocke’s rationalism can get past step one; but let’s see what would happen next. To go beyond particular perceptions, in acquiring knowledge, we need induction. Peacocke takes the basic form of enumerative induction to be the (defeasible) inference from All the (many and varied) observed Fs have been Gs to All Fs are Gs. The observation of only Gs, and no non-Gs, amongst these many and varied Fs is a complex fact, and its best (ie simplest) explanation is sometimes that all the Fs are Gs. Peacocke argues that in these cases this explanation is the a priori justification of the transition, and in only these cases is the transition justified; he concludes that induction is acceptable by rationalist lights.\nThe chapter on induction is only fifteen pages long, and it really needs to be much longer. Peacocke sets out the position just outlined, and compares it in some detail to a similar position advocated by Gilbert Harman, and that’s it. There is no discussion of what we do when most, rather than all, the observed Fs have been Gs, even though that’s surely the more important practical case. There’s no discussion of the case that’s frequently central to modern discussions on induction—the case in which a certain (stable) ratio of the Fs are Gs. Peacocke only talks about the special case when all Fs are Gs, and it isn’t obvious that the discussion generalizes. There is no discussion of rationalist alternatives, such as Keynes’s justification of enumerative induction in terms of analogical inference, or D. C. Williams’s probabilistic defence of induction. And there’s no discussion of empiricist attempts to justify induction a posteriori, or to do without it. Even if Peacocke’s suggested justification works, and it is at least a serious contender, a persuasive treatment of induction should have dealt with at least some of these points.\nThe final two chapters discuss moral beliefs. Again, Peacocke thinks that all the inferences we make in order to get from our perceptual beliefs to our moral beliefs can be justified a priori. His view is that we can come to know a priori some moral principles. And we can know contingent moral facts, such as that someone’s giving £1000 to Oxfam is morally praiseworthy, by carrying out the following inference. The person, say Joe, helped other people in need. (We learn this by experience.) Helping those in need is morally praiseworthy. (We learn this moral principle by deploying our reason.) Hence what Joe did is morally praiseworthy. But there’s a problem here, and Peacocke never fully addresses it. It’s only prima facie true that helping those in need is morally praiseworthy. There are always exceptions to the principle. If Joe’s children starved to death because that donation was the last money Joe had to buy them food, the donation wasn’t morally praiseworthy. Moreover, it is just about impossible to state the exceptions without using moral language. So it is far from clear how we are meant to come to know that this case is not one of the exceptions, because knowing this requires both empirical knowledge and moral sensitivity. From a “principleist” position like Peacocke’s, knowing this is not one of the exceptions seems just as hard as the original problem of coming to know that the action was praiseworthy. So it seems the rationalist still has work to do here.\nOne can easily get the feeling from this book that rationalism runs into problems as soon as we try to apply it to real-world cases. But it isn’t obvious these are deep problems with rationalism, and in particular it isn’t clear that the problems can’t be fixed with relatively minor adjustments. Even if there are difficulties in application throughout The Realm of Reason, there is a lot of important philosophical work going on beneath the surface. Peacocke’s best work is done in classifying the various types of rationalist position that are available, and motivating the kind of view he wants to defend. This material remains valuable, highly valuable to anyone wanting to draw a plausible rationalist picture, even if his real-world applications are not yet perfect."
  },
  {
    "objectID": "posts/aka/index.html",
    "href": "posts/aka/index.html",
    "title": "Assertion, Knowledge and Action",
    "section": "",
    "text": "It is widely believed that the mere truth of p is insufficient for p to be properly assertable, even if p is relevant to current conversation. If a speaker simply guessed that p is true, then she shouldn’t say p, for example. There is some dissent from this view (e.g., Weiner (2005)), but it is something close to orthodoxy in the current literature on assertion that something further is needed. The most common ‘something else’ is knowledge: a speaker shouldn’t say p unless they know p. This view is nowadays commonly associated with Timothy Williamson (1996, 2000), but it has historical antecedents tracing back at least to Max Black’s (1952) paper “Saying and Disbelieving”.1 Call Williamson’s position The Knowledge Rule.\nThis paper aims to raise trouble for The Knowledge Rule, and several related positions, by focussing on a particular kind of assertion. We’ll be looking at assertions about what is to be done. The boldest statement of our position is that if an agent should do X, then that agent is in a position to say that they should do X. (We’ll qualify this a little below, but it’s helpful to start with the bold position.) We argue, following Williamson’s ‘anti-luminosity’ arguments, that its being true that X is the thing to do for an agent doesn’t entail that that agent knows it’s the thing to do.2 If both these claims are true, then there will be cases where it is fine to assert that X is what to do, even though the agent doesn’t know this. So, The Knowledge Rule is mistaken. Slightly more formally, we’ll be interested in arguments of this structure.\nIn section 1, we’ll motivate premise 1 with a couple of vignettes. In section 2, we’ll qualify that premise and make it more plausible. In section 3, we’ll motivate premise 2. In section 4, we’ll look at one of the positive arguments for The Knowledge Rule, the argument from Moore’s paradox, and conclude that it is of no help. In section 5, we’ll look at what could be put in place of The Knowledge Rule, and suggest two alternatives.\nWe’re not going to argue for these rules in detail; that would take a much longer paper. Nor are we going to decide between them. What we are going to suggest is that these rules have the virtues that are commonly claimed for The Knowledge Rule, but lack The Knowledge Rule’s problematic consequences when it comes to assertions about what to do."
  },
  {
    "objectID": "posts/aka/index.html#speaking-about-what-to-do",
    "href": "posts/aka/index.html#speaking-about-what-to-do",
    "title": "Assertion, Knowledge and Action",
    "section": "1 Speaking about What to Do",
    "text": "1 Speaking about What to Do\nWe start by motivating premise 1 of the Master Argument with a couple of examples. Both cases are direct counterexamples to The Knowledge Rule, but we’re interested in the first instance in what the cases have in common. After presenting the vignettes, we offer three distinct arguments to show that, in such cases, it is proper for the speakers to assert what they do assert, even though they don’t know it to be true.\n\nGoing to War\nImagine that a country, Indalia, finds itself in a situation in which the thing for it to do, given the evidence available to its leaders, is to go to war against an enemy. (Those pacifists who think it is never right to go to war won’t like this example, but we think war can at least sometimes be justified.) But it is a close call. Had the evidence been a bit weaker, had the enemy been a little less murderous, or the risk of excessive civilian casualties a little higher, it would have been preferable to wait for more evidence, or use non-military measures to persuade the enemy to change its ways. So, while going to war is the thing to do, the leaders of Indalia can’t know this. We’ll come back to this in section 2, but the crucial point here is that knowledge has a safety constraint, and any putative knowledge here would violate this constraint.\nOur leaders are thus in a delicate position here. The Prime Minister of Indalia decides to launch the war, and gives a speech in the House of Commons setting out her reasons. All the things she says in the speech are true, and up to her conclusion they are all things that she knows. She concludes with (1).\nNow (1) is also true, and the Prime Minister believes it, but it is not something she knows. So, the Prime Minister violates The Knowledge Rule when she asserts (1). But it seems to us that she doesn’t violate any norms in making this assertion. We’ll have a lot more to say about why this is so in a few paragraphs. But first, here’s a less dramatic case that is also a counterexample to The Knowledge Rule, one that involves prudential judgments rather than moral judgments.\n\n\nBuying Flood Insurance\nRaj and Nik are starting a small business. The business is near a river that hasn’t flooded in recent memory, but around which there isn’t much flood protection. They could buy flood insurance which would be useful in a flood, naturally, but would be costly in the much more likely event that there is not a flood. Raj has done the calculations of the likelihood of a flood, the amount this would damage the business, the utility loss of not having this damage insured, and the utility loss of paying flood insurance premiums. He has concluded that buying flood insurance is the thing to do. As it happens, this was a good conclusion to draw: it does, in fact, maximise his (and Nik’s) expected utility over time. (It doesn’t maximise their actual utility, as there actually won’t be a flood over the next twelve months. So, the insurance premium is an expense they could have avoided. But that doesn’t seem particularly relevant for prudential evaluation. Prudential buyers of insurance should maximise expected utility, not actual utility. Or so we must say unless we want to be committed to the view that everyone who buys an insurance policy and doesn’t make a claim on it is imprudent.)\nBut again, it’s a close call. If there had been a little less evidence that a flood was a realistic possibility, or the opportunity cost of using those dollars on insurance premiums had been a little higher, or the utility function over different outcomes a little different, it would have been better to forego flood insurance. That suggests that safety considerations make it the case that Raj doesn’t know that buying flood insurance is the thing to do, though in fact it is.\nLet’s now assume Raj has done everything he should do to investigate the costs and benefits of flood insurance. We can imagine a conversation between him and Nik going as follows.\n\nNik: Should we get flood insurance?\nRaj: I don’t know. Hold on; I’m on the phone.\nNik: Who are you calling?\nRaj: The insurance agent. I’m buying flood insurance.\n\nThere is clearly a pragmatic tension in Raj’s actions here. But given The Knowledge Rule, there’s little else he can do. It would be a serious norm violation to say nothing in response to Nik’s question. And given that he can’t say “Yes” without violating The Knowledge Rule, he has to say “I don’t know”. Moreover, since by hypothesis buying flood insurance is the thing to do in his situation, he can’t not buy the insurance without doing the wrong thing. So, given The Knowledge Rule, he’s doing the best he can. But it’s crazy to think that this is the best he can do.\nWe think that these cases are problems for The Knowledge Rule. In particular, we think that in each case, there is a non-defective assertion of something that is not known. It seems to us intuitively clear that those assertions are non-defective, but for those who don’t share this intuition, we have three independent arguments. The arguments focus on Going to War, but they generalize easily enough to Buying Flood Insurance.\n\n\nArgument One: “That was your first mistake”\nImagine that the Prime Minister has a philosophical advisor. And the advisor’s job is to inform the Prime Minister whenever she violates a norm, and stay silent otherwise. If The Knowledge Rule is correct, then the advisor should stay silent as the Prime Minister orders the invasion, silent as the Prime Minister sets out the reasons for the invasion, then speak up at the very last line of the speech. That strikes us as absurd. It’s particularly absurd when you consider that the last line of the speech is supported by what came earlier in the speech, and the Prime Minister believes it, and asserts it, because it is well supported by what came earlier in the speech. Since we think this couldn’t be the right behaviour for the advisor, we conclude that there’s no norm violation in the Prime Minister asserting (1).\nWe’ve heard two replies to this kind of argument. According to one sort of reply, The Knowledge Rule is not meant to be an ‘all-things-considered’ norm. The defender of The Knowledge Rule can say that the Prime Minister’s assertion is defective because it violates that rule, but allow that it is nevertheless all-things-considered proper, because some other norm outweighs The Knowledge Rule on this occasion. We agree that The Knowledge Rule is not intended to be an all-things-considered norm. But even keeping clearly in mind the distinction between being defective in some respect and being defective all-things-considered, it is still deeply unintuitive to say that the Prime Minister’s assertion is defective in a respect. That is, we don’t think the philosophical advisor should speak up just at the very end of the Prime Minister’s speech even if she’s meant to observe all the norm violations (rather than just the all-things-considered norm violations).\nPerhaps the defender of The Knowledge Rule needn’t just appeal to an intuition here. Another reply we’ve heard starts from the premise that the Prime Minister’s assertion would be better, in a certain respect, if she knew that it was true. Therefore, there is a respect in which that assertion is defective, just as The Knowledge Rule requires. To this second reply, our response is that the premise is true, but the reasoning is invalid. Saying why requires reflecting a bit on the nature of norms.\nThere are lots of ways for assertions to be better. It is better, ceteris paribus, for assertions to be funny rather than unfunny. It is better for assertions to be sensitive rather than insensitive. (We mean this both in the Nozickian sense, i.e., an assertion is sensitive iff it wouldn’t have been made if it weren’t true, and in the Hallmark greeting card sense.) It is better for speakers to be certain of the truth of their assertions than for them to be uncertain. But these facts don’t imply that humour, sensitivity, or certainty are norms of assertion, for it doesn’t follow that assertions that lack humour (or sensitivity or certainty) are always defective. Similarly, the fact that it is better to know what you say than not doesn’t imply that asserting what you don’t know is always defective. In slogan form: Not every absence of virtue is a vice. We think knowledge is a virtue of assertions. (In fact, we think that pretty much every norm of assertion that has been proposed in the literature picks out a virtue of assertion.) What we deny is that the absence of knowledge is (always) a vice. Since not every absence of virtue is a vice, one can’t argue that the Prime Minister’s assertion is defective by arguing it could have been better. And that’s why the argument being considered is invalid.\n\n\nArgument Two: “Actions speak louder than words”\nIt’s a bit of folk wisdom that actions speak louder than words. It isn’t crystal clear just what this wisdom amounts to, but we think one aspect of it is that an agent incurs more normative commitments by doing X than by talking about X. But if The Knowledge Rule is right, then this piece of wisdom is in this aspect back-to-front. According to that rule, an agent incurs a greater normative commitment by saying that X is what to do than they do by just doing X. If they do X, and X is indeed what to do, then they’ve satisfied all of their normative commitments. If, by contrast, they say that X is what to do, then not only must X be what to do, but they must know this fact as well. This strikes us as completely back-to-front. We conclude that there is nothing improper about asserting that X is what to do (as the Prime Minister does), when X is in fact what to do.\n\n\nArgument Three: “What else could I do?”\nHere’s a quite different argument that Going to War is a counterexample to The Knowledge Rule.\n\nIf ending the speech the way she did was a norm violation, there is a better way for the Prime Minister to end her speech.\nThere is no better way for the Prime Minister to end the speech without saying something that she does not know to be true.\nSo, ending the speech the way she did was not a norm violation.\nSo, The Knowledge Rule is subject to counterexample.\n\nPremise 1 is a kind of ‘ought-implies-can’ principle, and as such, it isn’t completely obvious that it is true. But when we’ve presented this argument to various groups, the focus has always been on premise two. The common complaint has been that the Prime Minister could have ended the speech in one of the following ways, thereby complying with The Knowledge Rule.\n\nI’ve decided that going to war is the thing to do in the circumstances.\nI believe that going to war is the thing to do in the circumstances.\nIt seems to me that going to war is the thing to do in the circumstances.\n\nOur first reply to this suggestion is that we’d fire a speechwriter who recommended that a Prime Minister end such a speech in such a weaselly way, so this hardly counts as a criticism of premise 2. Our more serious reply is that even if the Prime Minister ended the speech this way, she’d still violate The Knowledge Rule. To see why this is so, we need to pay a little closer attention to what The Knowledge Rule says.\nNote that The Knowledge Rule is not a rule about what kind of declarative utterance you can properly make. An actor playing Hamlet does not violate The Knowledge Rule if he fails to check, before entering the stage, whether something is indeed rotten in the state of Denmark. The rule is a rule about what one asserts. And just as you can assert less than you declaratively utter (e.g., on stage), you can also assert more than you declaratively utter.3 For instance, someone who utters The F is G in a context in which it is common ground that a is the F typically asserts both that the F is G, and that a is G. Similarly, someone who utters I think that S typically asserts both asserts that they have a certain thought, and asserts the content of that thought. We can see this is so by noting that we can properly challenge an utterance of I think that S by providing reasons that S is false, even if these are not reasons that show that the speaker does not (or at least did not) have such a thought. In the context of her speech of the House of Commons, even if the Prime Minister were to end with one of the options above, she would still assert the same thing she would assert by uttering (1) in the circumstances, and she’d still be right to make such an assertion.\n3 The points we’re about to make are fairly familiar by now, but for more detail, see Cappelen and Lepore (2005), which played an important role in reminding the philosophy of language community of their significance."
  },
  {
    "objectID": "posts/aka/index.html#bases-for-action-and-assertion",
    "href": "posts/aka/index.html#bases-for-action-and-assertion",
    "title": "Assertion, Knowledge and Action",
    "section": "2 Bases for Action and Assertion",
    "text": "2 Bases for Action and Assertion\nOne might worry that premise 1 in our master argument is mistaken, in the following way. We said that if X is the thing to do for S, then S can say that X is what to do. But one might worry about cases where S makes a lucky guess about what is to be done. Above we imagined that Raj had taken all of the factors relevant to buying flood insurance into account. But imagine a different case, one involving Raj*, Raj’s twin in a similar possible world. Raj* decides to buy flood insurance because he consults his Magic 8-Ball. Then, even if buying flood insurance would still maximize his expected utility, it doesn’t seem right for Raj* to say that buying flood insurance is what to do.\nHere is a defence of premise 1 that seems initially attractive, though not, we think, ultimately successful. The Magic 8-ball case isn’t a clear counterexample to premise 1, it might be argued, because it isn’t clear that buying flood insurance for these reasons is the thing for Raj* to do. On one hand, we do have the concept of doing the right thing for the wrong reasons, and maybe that is the right way to describe what Raj* does if he follows the ball’s advice. But it isn’t clearly a correct way to describe Raj*. It’s not true, after all, that he’s maximising actual utility. (Remember that there will be no claims on the policy he buys.) And it isn’t clear how to think about expected utility maximisation when the entrepreneur in question relies on the old Magic 8-Ball for decision making. And we certainly want to say that there’s something wrong about this very decision when made using the Magic 8-Ball. So, perhaps we could say that buying flood insurance isn’t what to do for Raj* in this variant example, because he has bad reasons.\nBut this seems like a tendentious defence of the first premise. Worse still, it is an unnecessary defence. What we really want to focus on are cases where people do the right thing for the right reasons. Borrowing a leaf from modern epistemology, we’ll talk about actions having a basis. As well as there being a thing to do in the circumstances (or, more plausibly, a range of things to do), there is also a correct basis for doing that thing (or, more plausibly, a range of correct bases). What we care about is when S does X on basis B, and doing X on basis B is the thing to do in S’s situation. Using this notion of a basis for action, we can restate the main argument.\n\nMaster Argument (Corrected)\n\nIf doing X on basis B is what to do for agent S, then S can properly, on basis B, assert that X is what to do (assuming this is relevant to the conversation).\nIt is possible that doing X on basis B is what to do for S, even though S is not in a position to know, and certainly not in a position to know on basis B, that X is what to do.\nSo, it is possible that S properly can assert that X is what to do, even though she does not know, and is not even in a position to know, that X is what to do.\n\n\nWe endorse this version of the master argument. Since its conclusion is the denial of The Knowledge Rule, we conclude that The Knowledge Rule is mistaken. But we perhaps haven’t said enough about premise 2 to seal the argument. The next section addresses that issue."
  },
  {
    "objectID": "posts/aka/index.html#marginal-wars",
    "href": "posts/aka/index.html#marginal-wars",
    "title": "Assertion, Knowledge and Action",
    "section": "3 Marginal Wars",
    "text": "3 Marginal Wars\nThe argument for premise 2 is just a simple application of Williamson’s anti-luminosity reasoning. (The canonical statement of this reasoning is in (Williamson 2000 Ch. 4)).) Williamson essentially argues as follows, for many different values of p. There are many ways for p to be true, and many ways for it to be false. Some of the ways in which p can be true are extremely similar to ways in which it can be false. If one of those ways is the actual way in which p is true, then to know that p we have to know that situations very similar to the actual situation do not obtain. But in general we can’t know that. So, some of the ways in which p can be true are not compatible with our knowing that p is true. In Williamson’s nice phrase, p isn’t luminous, where a luminous proposition is one that can be known (by a salient agent) whenever it is true. The argument of this paragraph is called ‘an anti-luminosity argument’, and we think that many instances of it are sound.\nThere is a crucial epistemic premise in the middle of that argument: that we can’t know something if it is false in similar situations. There are two ways that we could try to motivate this premise. First, we could try to motivate it with the help of conceptual considerations about the nature of knowledge. That’s the approach that Williamson takes. But his approach is controversial. It is criticised by Sainsbury (1995) and Weatherson (2004) on the grounds that his safety principle goes awry in some special cases. Sainsbury focuses on mathematical knowledge, Weatherson on introspective knowledge. But the cases in which we’re most interested in this paper – Indalia going to war, Raj and Nik buying flood insurance – don’t seem to fall into either of these problem categories. Nevertheless, rather than pursue this line, we’ll consider a different approach to motivating this premise.\nThe second motivation for the epistemic premise comes from details of the particular cases. In the two cases on which we’re focusing, the agents simply lack fine discriminatory capacities. They can’t tell some possibilities apart from nearby possibilities. That is, they can’t know whether they’re in one world or in some nearby world. That’s not because it’s conceptually impossible to know something that fine, but simply an unfortunate fact about their setup. If they can’t know that they’re not in a particular nearby world in which \\(\\neg\\)p, they can’t know p. Using variants of Going to War, we’ll describe a few ways this could come about.\nThe simplest way for this to come about is if war-making is the thing to do given what we know, but some of the crucial evidence consists of facts that we know, but don’t know that we know. Imagine that a crucial piece of Indalia’s case for war comes from information from an Indalian spy working behind enemy lines. As it turns out, the spy is reliable, so the leaders of Indalia can acquire knowledge from her testimony. But she could easily enough have been unreliable. She could, for instance, have been bought off by the enemy’s agents. As it happens, the amount of money that would have taken was outside the budget the enemy has available for counterintelligence. But had the spy been a little less loyal, or the enemy a little less frugal with the counterintelligence budget, she could easily have been supplying misinformation to Indalia. So, while the spy is a safe knowledge source, the Indalian leaders don’t know that she is safe. They don’t, for instance, know the size of the enemy’s counterintelligence budget, or how much it would take to buy off their spy, so for all they know, she is very much at risk of being bought off.\nIn this case, if the spy tells the Indalian leaders that p, they come to know that p, and they can discriminate p worlds from \\(\\neg\\)p worlds. But they don’t know that they know that p, so for all they know, they don’t know p. And for some p that they learn from the spy, if they don’t know p, then going to war isn’t the thing for them to do in the circumstances. So, given that they don’t know the spy is reliable, they don’t know that going to war is the thing for them to do. But the spy really is reliable, so they do know p, so going to war is indeed the thing for them to do.\nOr consider a slightly less fanciful case, involving statistical sampling. Part of the Prime Minister’s case for starting the war was that the enemy was killing his own citizens. Presumably she meant that he was killing them in large numbers. (Every country with capital punishment kills its own citizens, but arguably that isn’t a sufficient reason to invade.) In practice, our knowledge of the scope of this kind of governmental killing comes from statistical sampling. And this sampling has a margin of error. Now imagine that the Indalian leaders know that a sample has been taken, and that it shows that the enemy has killed n of his citizens, with a margin of error of m. So, assuming there really are n killings, they know that the enemy has killed between n - m and n + m of his citizens. Since knowing that he’s killed n - m people is sufficient to make going to war the thing to do, the war can be properly started.\nBut now let’s think about what the Indalian leaders know that they know in this case. The world where the enemy has killed n - m people is consistent with their knowledge. And their margin of error on estimates of how many the enemy has killed is m. So, if that world is actual, they don’t know the enemy has killed more than n - 2m of his citizens. And that knowledge might not be enough to make going to war the thing to do, especially if m is large. (Think about the case where m = n/2, for instance.) So, there’s a world consistent with their knowledge (the n - m killings world), in which they don’t know enough about what the enemy is doing to make going to war the thing to do. In general, if there’s a world consistent with your knowledge where p is false, you don’t know p. Letting p be Going to war is what to do, it follows then that they don’t know that going to war is what to do, even though it actually is the thing to do.\nAnother way we could have a borderline war is a little more controversial. Imagine a case where the leaders of Indalia know all the salient descriptive facts about the war. They know, at least well enough for present purposes, what the costs and benefits of the war might be. But it is a close call whether the war is the thing to do given those costs and benefits. Perhaps different plausible moral theories lead to different conclusions. Or perhaps the leaders know what the true moral theory is, but that theory offers ambiguous advice. We can imagine a continuum of cases where the true theory says war is clearly what to do at one end, clearly not what to do at another, and a lot of murky space between. Unless we are willing to give up on classical logic, we must think that somewhere there is a boundary between the cases where it is and isn’t what to do, and it seems in cases near the boundary even a true belief about what to do will be unsafe. That is, even a true belief will be based on capacities that can’t reliably discriminate situations where going to war is what to do from cases where it isn’t.\nWe’ve found, when discussing this case with others, that some people find this outcome quite intolerable. They think that there must be some epistemic constraints on war-making. And we agree. They go on to think that these constraints will be incompatible with the kind of cases we have in mind that make premise 2 true. And here we disagree. It’s worth going through the details here, because they tell us quite a bit about the nature of epistemic constraints on action.\nConsider all principles of the form\n\n(KW)\n\nGoing to war is N1 only if the war-maker knows that going to war is N2.\n\n\nwhere N1 and N2 are normative statuses, such as being the thing to do, being right, being good, being just, being utility increasing, and so on. All such principles look like epistemic constraints on war-making, broadly construed. One principle of this form would be that going to war is right only if the war-maker knows that going to war is just. That would be an epistemic constraint on war-making, and a plausible one. Another principle of this form would be that going to war is the thing to do only if the war-maker knows that going to war increases actual utility. That would be a very strong epistemic constraint on war-making, one that would rule out pretty much every actual war, and one that is consistent with the anti-luminosity argument with which we started this section. So, the anti-luminosity argument is consistent with there being quite strong epistemic constraints on war-making.\nWhat the anti-luminosity argument is not consistent with is there being any true principle of the form (KW) where N1 equals N2. In particular, it isn’t consistent with the principle that going to war is the thing to do only if the war maker knows that it is the thing to do. But that principle seems quite implausible, because of cases where going to war is, but only barely, the thing to do. More generally, the following luminosity of action principle seems wrong for just about every value of X.\n\n(LA)\n\nX is the thing for S to do only if S knows that X is the thing for her to do.\n\n\nNot only is (LA) implausible, things look bad for The Knowledge Rule if it has to rely on (LA) being true. None of the defenders of The Knowledge Rule has given us an argument that (LA) is true. One of them has given us all we need to show that (LA) is false! It doesn’t look like the kind of principle that The Knowledge Rule should have to depend upon. So, defending The Knowledge Rule here looks hopeless.\nNote that given premise 1 of the Master Argument, as corrected, every instance of (LA) has to be true for The Knowledge Rule to be universally true. Let’s say that you thought (LA) was true when X is starting a war, but not when X is buying flood insurance. Then we can use the case of Raj and Nik to show that The Knowledge Rule fails, since Raj can say that buying flood insurance is what to do in a case where it is what to do, but he doesn’t know this.\nOne final observation about the anti-luminosity argument. Given the way Williamson presents the anti-luminosity argument, it can appear that in all but a few cases, if p, the salient agent can know that p. After all, the only examples Williamson gives are cases that are only picked out by something like the Least Number Theorem. So, one might think that while luminosity principles are false, they are approximately true. More precisely, one might think that in all but a few weird cases near the borderline, if p, then a salient agent is in a position to know p. If so, then the failures of luminosity aren’t of much practical interest, and hence the failures of The Knowledge Rule we’ve pointed out aren’t of much practical interest.\nWe think this is all mistaken. Luminosity failures arise because agents have less than infinite discriminatory capacities. The worse the discriminatory capacities, the greater the scope for luminosity failures. When agents have very poor discriminatory capacities, there will be very many luminosity failures. This is especially marked in decision-making concerning war. The fog of war is thick. There is very much that we don’t know, and what we do know is based on evidence that is murky and ephemeral. There is very little empirical information that we know that we know. If there are certain actions (such as starting a war) that are proper only if we know a lot of empirical information, the general case will be that we cannot know that these actions are correct, even when they are. This suggests that luminosity failures, where an action is correct but not known to be correct, or a fact is known but not known to be known, are not philosophical curiosities. In epistemically challenging environments, like a war zone, they are everyday facts of life."
  },
  {
    "objectID": "posts/aka/index.html#moores-paradox",
    "href": "posts/aka/index.html#moores-paradox",
    "title": "Assertion, Knowledge and Action",
    "section": "4 Moore’s Paradox",
    "text": "4 Moore’s Paradox\nThere is a standard argument for The Knowledge Rule that goes as follows. First, if the Knowledge Rule did not hold, then certain Moore paradoxical assertions would be acceptable. In particular, it would be acceptable to assert q, but I don’t know that q.4 But second, Moore paradoxical assertions are never acceptable. Hence, The Knowledge Rule holds. We reject both premises of this argument.\n4 (Williamson 2000), for instance, shows the strength of this argument.To reject the first premise, it suffices to show that some rule other than The Knowledge Rule can explain the unacceptability of Moore paradoxical assertions. Consider, for example, The Undefeated Reason rule.\n\nThe Undefeated Reason Rule\n\nAssert that p only if you have an undefeated reason to believe that p.\n\n\nThe Undefeated Reason Rule says that q but I don’t know that q can be asserted only if the speaker has an undefeated reason to believe it. That means the speaker has an undefeated reason to believe each conjunct. That means that the speaker has an undefeated reason to believe that they don’t know q. But in every case where it is unacceptable to both assert q and assert that you don’t know q, the speaker’s undefeated reason to believe they don’t know q will be a defeater for her belief that q. If you have that much evidence that you don’t know q, that will in general defeat whatever reason you have to believe q.\nWe don’t claim that The Undefeated Reason Rule is correct. (In fact, we prefer the rules we’ll discuss in section 5.) We do claim that it provides an alternative explanation of the unacceptability of instances of q but I don’t know that q. So, we claim that it undermines the first premise of Williamson’s argument from that unacceptability to The Knowledge Rule.\nWe also think that Williamson’s explanation of Moore paradoxicality over-generates. There is generally something odd about saying q but I don’t know that q. We suspect that the best explanation for why this is odd will be part of a broader explanation that also explains, for instance, why saying I promise to do X, but I’m not actually doing to do X is also defective. Williamson’s explanation isn’t of this general form. He argues that saying q but I don’t know that q is defective because it is defective in every context to both assert q and assert that you don’t know that q. But we don’t think that it is always defective to make both of these assertions.5 In particular, if a speaker is asked whether q is true, and whether they know that q, it can be acceptable to reply affirmatively to the first question, but negatively to the second one. If so, then the second premise of Williamson’s argument from Moore paradoxicality is also false.\n5 This is why we hedged a little two paragraphs ago about what precisely The Undefeated Reason Rule explains. We suspect that many in the literature have misidentified the explicandum.Imagine that the Indalian Prime Minister is a philosopher in her spare time. After the big speech to Parliament she goes to her Peninsula Reading Group. It turns out Michael Walzer and Tim Williamson are there, and have questions about the speech.\n\nTW: Do you agree that knowledge requires safety?\nPM: Yes, yes I do.\nTW: And do you agree that your belief that going to war is the thing to do is not safe?\nPM: Right again.\nTW: So, you don’t know that going to war is the thing to do?\nPM: You’re right, I don’t.\nMW: But is it the thing to do?\nPM: Yes.\n\nThe Prime Minister’s answers in this dialogue seem non-defective to us. But if Williamson’s explanation of why Moore paradoxical utterances are defective is correct, her answers should seem defective. So, Williamson’s explanation over-generates. Whether or not it is true that all assertions of sentences of the form q but I don’t know that q are defective, it isn’t true that there is a defect in any performance that includes both an assertion of q and an assertion of the speaker’s ignorance as to whether q. The Prime Minister’s performance in her reading group is one such performance. So, the explanation of Moore paradoxicality cannot be that any such performance would violate a norm governing assertion.\nTo sum up, then, we’ve argued that The Knowledge Rule (a) fails to be the only explanation of Moore paradoxicality, and (b) misclassifies certain performances that are a little more complex than simple conjunctive assertions as defective. So, there’s no good argument from Moore paradoxicality to The Knowledge Rule."
  },
  {
    "objectID": "posts/aka/index.html#action-and-assertion",
    "href": "posts/aka/index.html#action-and-assertion",
    "title": "Assertion, Knowledge and Action",
    "section": "5 Action and Assertion",
    "text": "5 Action and Assertion\nIf we’re right, there’s a striking asymmetry between certain kinds of assertions. In the war example, early in her speech, the Prime Minister says (2).\nThat’s not the kind of thing she could properly say if it could easily have been false given her evidence. And like many assertions, this is not an assertion whose appropriateness is guaranteed by its truth. Asserting (2) accuses someone of murder, and you can’t properly make such accusations without compelling reasons, even if they happen to be true. On the other hand, we say, the truth of (1) does (at least when it is accepted on the right basis) suffice to make it properly assertable.\nThere’s a similar asymmetry in the flood insurance example. In that example, (3) is true, but neither Raj nor Nik knows it.\nAgain, in these circumstances, this isn’t the kind of thing Raj can properly say. Even though (3) is true, it would be foolhardy for Raj to make such a claim without very good reasons. By contrast, again, we say that Raj can properly assert that the thing to do, in their circumstances, is to buy flood insurance, even though he does not know this.\nThere are two directions one could go at this point. If we’re right, any proposed theory of the norms governing assertion must explain the asymmetry. Theories that cannot explain it, like The Knowledge Rule, or the Certainty Rule proposed by Jason Stanley (2008), or the Rational Credibility Rule proposed by Igor Douven (2006), are thereby refuted.\n\nThe Certainty Rule\n\nAssert only what is certain.\n\nThe Rational Credibility Rule\n\nAssert only what is rationally credible.\n\n\nThe Certainty Rule fails since the Prime Minister is not certain of (1). And the Prime Minister can’t be certain of (1), since certainty requires safety just as much as knowledge does.\nIt’s a little harder to show our example refutes The Rational Credibility Rule. Unlike knowledge, a safety constraint is not built into the concept of rational credibility. (Since rational credibility does not entail truth, in Douven’s theory, it can hardly entail truth in nearby worlds.) But we think that safety constraints may still apply to rational credibility in some particular cases. If you aren’t very good at judging building heights of tall buildings to a finer grain than 10 meters, then merely looking at a building that is 84 meters tall does not make it rationally credible for you that the building is more than 80 meters tall. In general, if your evidence does not give you much reason to think you are not in some particular world where p is false, and you didn’t have prior reason to rule that world out, then p isn’t rationally credible. So, when evidence doesn’t discriminate between nearby possibilities, and p is false in nearby possibilities, p isn’t rationally credible.\nAnd that, we think, is what happens in our two examples. Just as someone looking at an 84 meter building can’t rationally credit that it is more than 80 meters tall, unless they are abnormally good at judging heights, agents for whom X is just barely the thing to do can’t rationally credit that X is the thing to do. By The Rational Credibility Rule, they can’t say X is the thing to do. But they can say that; that’s what our examples show. So, The Rational Credibility Rule must be wrong.\nBut we can imagine someone pushing in the other direction, perhaps with the help of this abductive argument.\n\nA speaker can only assert things like (2) or (3) if they know them to be true.\nThe best explanation of premise 1 of this argument is The Knowledge Rule.\nSo, The Knowledge Rule is correct.\n\nThis isn’t a crazy argument. Indeed, it seems to us that it is implicit in some of the better arguments for The Knowledge Rule. But we think it fails. And it fails because there are alternative explanations of the first premise, explanations that don’t make mistaken predictions about the Prime Minister’s speech. For instance, we might have some kind of Evidence Responsiveness Rule.\n\nThe Evidence Responsiveness Rule\n\nAssert that p only if your attitude towards p is properly responsive to the evidence you have that bears on p.\n\n\nGiven how much can be covered by ‘properly’, this is more of a schema than a rule. Indeed, it is a schema that has The Knowledge Rule as one of its precisifications. In Knowledge and Its Limits, Williamson first argues that assertion is “governed by a non-derivative evidential rule” (249), and then goes on to argue that the proper form of that rule is The Knowledge Rule. We agree with the first argument, and disagree with the second one.6\n6 Actually, our agreement with Williamson here is a bit more extensive than the text suggests. Williamson holds that part of what makes a speech act an assertion as opposed to some other kind of act is that it is governed by The Knowledge Rule. Although many philosophers agree with Williamson that The Knowledge Rule is true, this fascinating claim about the metaphysics of speech acts has been largely ignored. Translating Williamson’s work into the terminology of this paper, we’re inclined to agree that a speech act is an assertion partly in virtue of being responsive to evidence in the right way. But filling in the details on this part of the story would take us too far from the main storyline of this paper.Note that even a fairly weak version of The Evidence Responsiveness Rule would explain what is going on with cases like (1) and (2). Starting a war is a serious business. You can’t properly do it unless your views about the war are evidence responsive in the right way. You can’t, that is, correctly guess that starting the war is the thing to do. You can correctly guess that starting the war will be utility maximizing. And you can correctly guess that starting the war would be what to choose if you reflected properly on the evidence you have, and the moral significance of the choices in front of you. But you simply can’t guess that starting the war is what to do, and be right. If you’re merely guessing that starting a war is thing to do, then you’re wrong to start that war. So, if (1) is true, and the Prime Minister believes it, her belief simply must be evidence responsive. Then, by The Evidence Responsiveness Rule, she can assert it.\nFor most assertions, however, this isn’t the case. Even if it’s true that it will rain tomorrow, the Prime Minister’s could believe that without her belief being evidence responsive. In general, p does not entail that S even believes that p, let alone that this belief of S’s is evidence responsive. But in cases like (1), this entailment does hold, and that’s what explains the apparent asymmetry that we started this section with.\nThe Evidence Responsiveness Rule also handles so called ‘lottery propositions’ nicely. If you know that the objective chance of p being true is c, where c is less than 1, it will seem odd in a lot of contexts to simply assert p. In his arguments for The Knowledge Rule, Williamson makes a lot of this fact. In particular, he claims that the best explanation for this is that we can’t know that p on purely probabilistic grounds. This has proven to be one of the most influential arguments for The Knowledge Rule in the literature. But some kind of Evidence Responsiveness Rule seems to handle lottery cases even more smoothly. In particular, an Evidence Responsiveness Rule that allows for what constitutes ‘proper’ responsiveness to be sensitive to the interests of the conversational participants will explain some odd features concerning lottery propositions and assertability.\nIn the kind of cases that motivate Williamson, we can’t say p where it is objectively chancy whether p, and the chance of p is less than 1. But there’s one good sense in which such an assertion would not be properly responsive to the evidence. After all, in such a case there’s a nearby world, with all the same laws, and with all the same past fatcs, and in which the agent has all the same evidence, in which p is false. And the agent knows all this. That doesn’t look like the agent is being properly responsive to her evidence.\nOn the other hand, we might suspect that Williamson’s arguments concerning lottery propositions overstate the data. Consider this old story from David Lewis (1996).7\n7 We’ve slightly modified the case. Lewis says we can say that we know Bill will never be rich. That seems to us to be a much more controversial than what we’ve included here.\nPity poor Bill! He squanders all his spare cash on the pokies, the races, and the lottery. He will be a wage slave all his days … he will never be rich. (Lewis 1996, 443 in reprint)\n\nThese seem like fine assertions. One explanation of the appropriateness of those assertions combines The Knowledge Rule with contextualism about assertion.8 But contextualism has many weaknesses, as shown in Hawthorne (2004) and Stanley (2005). A less philosophically loaded explanation of Lewis’s example is that proper responsiveness comes in degrees, and for purposes of talking about Bill, knowing that it’s overwhelmingly likely that he’s doomed to wage slavery is evidence enough to assert that he’ll never be rich. The details of this explanation obviously need to be filled in, but putting some of the sensitivity to conversational standards, or practical interests, into the norms of assertion seems to be a simpler explanation of the data than a contextualist explanation. (It would be a priori quite surprising if the norms of proper assertion were not context-sensitive, or interests-sensitive. The norms of appropriateness for most actions are sensitive to context and interests.) So The Evidence Responsiveness Rule seems more promising here than The Knowledge Rule.\n8 The combination is slightly trickier to state than would be ideal. The explanation we have in mind is that S can properly assert p only if S can truly say I know that p, where ‘know’ in this utterance is context sensitive.A harder kind of case for The Knowledge Rule concerns what we might call ‘academic assertions’. This kind of case is discussed in Douven (2006) and in Maitra (2010). In academic papers, we typically make assertions that we do not know. We don’t know that most of the things we’ve said here are true. (Before the last sentence we’re not sure we knew that any of the things we said were true.) But that’s because knowledge is a bad standard for academic discourse. Debate and discussion would atrophy if we had to wait until we had knowledge before we could present a view. So, it seems that assertion can properly outrun knowledge in academic debate.\nAgain, a context-sensitive version of The Evidence Responsiveness Rule explains the data well. Although you don’t need to know things to assert them in philosophy papers, you have to have evidence for them. We couldn’t have just spent this paper insisting louder and louder that The Knowledge Rule is false. We needed to provide evidence, and hopefully we’ve provided a lot of it. In some contexts, such as testifying in court, you probably need more evidence than what we’ve offered to ground assertions. But in dynamic contexts of inquiry, where atrophy is to be feared more than temporary mistakes, the standards are lower. Good evidence, even if not evidence beyond any reasonable doubt, or even if not enough for knowledge, suffices for assertion. That’s the standard we typically hold academic papers to. Like with lotteries, we think the prospects of explaining these apparently variable standards in terms of a norm of assertion that is context-sensitive are greater than the prospects for explaining them in terms of contextually sensitive knowledge ascriptions.\nHere’s a different and somewhat more speculative proposal idea for a rule that also explains the asymmetry we started this section with. We call it the Action Rule.\n\nThe Action Rule\n\nAssert that p only if acting as if p is true is the thing for you to do.\n\n\nWe take the notion of acting as if something is true from Stalnaker (1973). Intuitively, to act as if p is true is to build p into one’s plans, or to take p for granted when acting. This, note, is not the same as using p as a basis for action. When Raj buys flood insurance, he acts as if buying flood insurance is the thing to do. But the fact that buying flood insurance is the thing to do isn’t the basis for his action. (Since he does not know this, one might suspect it wouldn’t be a good basis.) Instead his basis is what he knows about the river, and his business, and its vulnerability to flooding. When an agent is trying to maximise the expected value of some variable (e.g., utility, profit, etc.), then to act as if p is true is simply to maximise the conditional expected value of that variable, in particular, to maximise the expected value of that variable conditional on p. Even when one is not maximising any expected value, we can still use the same idea. To act as if p is to take certain conditional obligations or permissions you have – in particular, those obligations or permissions that are conditional on p – to be actual obligations or permissions.\nTo see how The Action Rule generates the intended asymmetry, we’ll need a bit of formalism. Here are the terms that we will use.\n\nX denotes an action, agent, circumstance triple \\(\\langle\\)XAction, XAgent, XCircumstance\\(\\rangle\\). We take such triples to have a truth value. X is true iff XAgent performs XAction in XCircumstance.\nThingToDo(X) means that X is the thing to do for XAgent in XCircumstance.\nAct(S,p) means that agent S acts as if p is true.\nAssert(S,p) means that agent S can properly assert that p.\n\nSo, The Action Rule is this.\n\nAssert(S,p) \\({\\rightarrow}\\) ThingToDo(Act(S,p))\n\nIn our derivations, the following equivalence will be crucial.\n\nAct(XAgent,ThingToDo(X)) \\({\\leftrightarrow}\\) X\n\nThat is, acting as if X is what to do (in your circumstances) is simply to do X (in those circumstances). And in doing X, you’re acting as if X is what to do (in your circumstances). We take this equivalence to be quite resilient; in particular, it holds under operators like ‘ThingToDo’. So, adding that operator to the previous equivalence, we get another equivalence.\n\nThingToDo(Act(XAgent,ThingToDo(X))) \\({\\leftrightarrow}\\) ThingToDo(X)\n\nIf we substitute ThingToDo(X) for p in The Action Rule, we get this.\n\nAssert(XAgent,ThingToDo(X)) \\({\\rightarrow}\\) ThingToDo(Act(XAgent,ThingToDo(X)))\n\nBut by the equivalence we derived earlier, that’s equivalent to the following.\n\nAssert(XAgent,ThingToDo(X)) \\({\\rightarrow}\\) ThingToDo(X)\n\nSo, we get the nice result that The Action Rule is trivially satisfied for any true claim about what is to be done. That is, for the special case where p is X is the thing for you to do, The Action Rule just reduces to something like the Truth Rule. And so we get a nice explanation of why the Prime Minister and Raj can properly make their assertions about what to do in their respective circumstances.9\n9 The derivation here is deliberately simplified in one way. We haven’t included anything about the bases for action or assertion. We don’t think being sensitive to bases in the formalism would make a material change, but it would obscure the structure of the argument.To explain the other side of the asymmetry with which we began this section, note that these biconditionals do not hold where p is an arbitrary proposition, and S an arbitrary agent.\n\nThingToDo(Act(S,p)) \\({\\leftrightarrow}\\) p\nAct(S,ThingToDo(Act(S,p))) \\({\\leftrightarrow}\\) p\n\nTo see this, let p be the proposition expressed by (4). To act as if this is true is to, inter alia, not buy flood insurance. If there won’t be a flood, buying flood insurance is throwing away money, and when you’re running a business, throwing away money isn’t the thing to do. In symbols, Act(Raj and Nik,p) is equivalent to Raj and Nik don’t buy flood insurance. But not buying flood insurance is not the thing to do. The prudent plan is to buy flood insurance. So, ThingToDo(Act(Raj and Nik,p)) is false, even though p is true. So, the first biconditional fails. Since Raj and Nik do go on to buy flood insurance, i.e., since they don’t act as if ThingToDo(Act(Raj and Nik,p)), the left-hand-side of the second biconditional is also false. But again, the right-hand-side is true. So, that biconditional is false as well. And without those biconditionals, The Action Rule doesn’t collapse into Assert(S,p) \\({\\rightarrow}\\) p.\nWe have thus far argued that The Action Rule can provide an explanation for the asymmetry we noted at the beginning of this section.10 This is not, however, meant to be anything like a complete defence of that rule. That would require a lot more than we’ve provided here. But we do think that the Action Rule can explain a lot of the phenomena that are meant to motivate The Knowledge Rule, as well as some phenomena The Knowledge Rule struggles with.But we do think The Action Rule has some virtues. We’ll close with a discussion of how it explains the two kinds of cases that we argued that The Evidence Responsiveness Rule handles well.\n10 This explanation makes some interestingly different predictions from the explanation in terms of The Evidence Responsiveness Rule. Suppose that for relatively trivial decisions, like where to go for a walk on a nice summer day, one can correctly guess that X is the thing to do. Then the Evidence Responsiveness Rule would suggest that the truth of claims about where to go for a walk is not sufficient grounds for their assertability, while the Action Rule would still imply that truth is sufficient grounds for assertability. We’re not sure that this supposition – that for relatively trivial decisions, one can correctly guess that X is the thing to do – is coherent, nor what to say about assertability judgments in (imagined) cases where the supposition holds. So, we’re not sure we can really use this to discriminate between the two proposed explanations. Nevertheless, it is interesting to note how the explanations come apart. Thanks here to Susanna Schellenberg.To see this, consider first ‘lottery propositions’. If you know that the objective chance of p being true is c, where c is less than 1, it will seem odd in a lot of contexts to simply assert p. In his arguments for The Knowledge Rule, Williamson makes a lot of this fact. In particular, he claims that the best explanation for this is that we can’t know that p on purely probabilistic grounds. This has proven to be one of the most influential arguments for The Knowledge Rule in the literature.\nWe suggest that The Action Rule can offers an alternative a nice explanation for why it’s often defective to assert lottery propositions. Note first that inIn a lot of cases, it isn’t rational for us to act on p when we have only purely probabilistic evidence for it, especially when acting on p amounts to betting on p at sufficiently unfavourable odds. This point is something of a staple of the ‘interest-relative-invariantism’ literature on knowledge.11 To take a mundane case, imagine that you’re cleaning up your desk, and you come across some lottery tickets. Most are for lotteries that have passed, that you know you lost. One ticket, however, is for a future lottery, which you know you have very little chance of winning. In such a case, to act as if the ticket for the future lottery would lose would be to throw it out along with the other tickets. But that would be irrational, and not at all how we’d act in such a case. That is to say, in such a case, we don’t (and shouldn’t, rationally speaking) act as if the ticket for the future lottery will lose, even though we take that outcome to be highly probable.\n11 See, for instance, Fantl and McGrath (2002), Hawthorne (2004), Stanley (2005), and Weatherson (2005).If acting as if a lottery proposition is true isn’t the thing to do, then The Action Rule will say that asserting such a proposition defective. Therefore, we think that The Action Rule can capture why in many cases you can’t in general assert lottery propositions.\nA harder kind of case for The Knowledge Rule concerns what we might call ‘academic assertions’. This kind of case is discussed in Douven (2006) and in Maitra (2010). In academic papers, we typically make assertions that we do not know. We don’t know that most of the things we’ve said here are true. (Before the last sentence we’re not sure we knew that any of the things we said were true.) But that’s because knowledge is a bad standard for academic discourse. Debate and discussion would atrophy if we had to wait until we had knowledge before we could present a view. So, it seems that assertion can properly outrun knowledge in academic debate.\nAcademic assertions raised a problem for The Knowledge Rule because proper assertion in the context of inquiry can outrun knowledge. But note that action in such a context can also properly outrun knowledge. It would slow down learning dramatically if people didn’t engage in various projects that really only make sense if some hypothesis is true. So, academics will study in archives, conduct experiments, write papers, etc. etc., and do so on the basis of reasons they no more know than we know the truth of the speculative claims of this paper. And this is all to the good; the alternative is a vastly inferior alternative to academia as we know it. So, in some fields, action requires much less than knowledge. Happily, in those fields, assertion also requires much less than knowledge. Indeed, the shortfalls in the two cases seem to parallel nicely. And this parallel is neatly captured by The Action Rule.\nAs we said, none of this is a knockdown case for The Action Rule. Our primary purpose is to argue against The Knowledge Rule. As long as the Action Rule is plausible, we have defeated the abductive argument for The Knowledge Rule that was discussed at the start of this section, and we think we’ve done enough to show it is plausible. We also hope we’ve made a successful case for moving the study of assertability away from rules like The Knowledge Rule, and instead have it be more tightly integrated with our best theories about evidence and action."
  },
  {
    "objectID": "posts/misindex/index.html",
    "href": "posts/misindex/index.html",
    "title": "Misleading Indexicals",
    "section": "",
    "text": "In ‘Now the French are invading England’ Komarine Romdenh-Romluc (2002) offers a new theory of the relationship between recorded indexicals and their content. Romdenh-Romluc’s proposes that Kaplan’s basic idea, that reference is determined by applying a rule to a context, is correct, but we have to be careful about what the context is, since it is not always the context of utterance. A few well known examples illustrate this. The ‘here’ and ‘now’ in ‘I am not here now’ on an answering machine do not refer to the time and place of the original utterance, but to the time the message is played back, and the place its attached telephone is located. Any occurrence of ‘today’ in a newspaper or magazine refers not to the day the story in which it appears was written, nor to the day the newspaper or magazine was printed, but to the cover date of that publication.\n\nPublished in Analysis, 62: 308-310.\nPicture by Bernard Spragg via Creative Common.\n\nStill, it is plausible that for each (token of an) indexical there is a salient context, and that ‘today’ refers to the day of its context, ‘here’ to the place of its context, and soon. Romdenh-Romluc takes this to be true, and then makes a proposal about what the salient context is. It is ‘the context that Ac would identify on the basis of cues that she would reasonably take U to be exploiting’. (2002, 39) Ac is the relevant audience, ‘the individual who it is reasonable to take the speaker to be addressing’, and who is assumed to be linguistically competent and attentive. (So Ac might not be the person U intends to address. This will not matter for what follows.) The proposal seems to suggest that it is impossible to trick a reasonably attentive hearer about what the referent of a particular indexical is. Since such trickery does seem possible, Romdenh-Romluc’s theory needs (at least) supplementation. Here are two examples of such tricks.\n\nThanks to Europa Malynicz, Adam Sennet and Ted Sider for helpful comments.\n\n\nExample One\nImagine that at my university, the email servers are down, so all communication from the office staff is by written notes left in our mailboxes. I notice that one of my colleagues, Bruce, has a rather full mailbox, and hence must not have been checking his messages for the last day or two. I also know that Bruce is a forgetful type, and if someone told him that he’d forgotten about a faculty meeting yesterday, he’d probably believe them. In fact he hasn’t forgotten; the meeting is for later today. So I decide to play a little trick on him. I write an official looking note saying ‘There is a faculty meeting today’, leave it undated, and put it in Bruce’s mailbox underneath several other messages, so it looks like it has been there for a day or two. When Bruce sees it he is appropriately tricked, and for an instant panics about the meeting that he has missed.\n\nIt seems to me that what I wrote on the note was true. It was horribly misleading, to be sure, but still true. And as a few people have pointed out over the years, most prominently Bill Clinton I guess, it is possible to mislead people with the truth. But on Romdemh-Romluc’s proposal, what I said was false, since my audience (Bruce) reasonably took the context to be a day earlier in the week.\n\nExample Two\nThis example is closely based on a recent TV commercial. Jack leaves the following message on Jill’s answering machine late one Saturday night. ‘Hi Jill, it’s Jack. I’m at Rick’s. This place is wild. There’s lots of cute girls here, but I’m just thinking about you.’ In the background loud music is playing, as if Jack were at a nightclub, indeed as if Jack were at Rick’s, so Jill reasonably concludes that Jack was at Rick’s when he sent the message, and hence that ‘here’ refers to Rick’s. In fact Jack was home alone, but wanted to hide this fact, so he turned the stereo up to full volume while leaving the message. Despite the fact that a reasonable and attentive member of the target audience inferred on the basis of contextual clues left by Jack that the context was Rick’s, it was not. The context was Jack’s house, and ‘here’ in Jack’s message referred to his house. Jack’s trick may be less morally reprehensible than mine, but at least I managed to avoid lying, something Jack failed to do.\n\nIn Example One I said something true even though what the hearer took me to say was false. In Example Two Jack says something false, though what the hearer takes him to say may well be true, assuming that there are a lot of cute girls at Rick’s. Romdenh-Romluc’s theory predicts that neither of these things is possible, so it does not work as it stands. This, of course, is not to say that anyone else (myself included) has a better theory readily available, so it is unclear whether the right lesson to draw from these examples is that Romdenh-Romluc’s theory needs to have some epicycles added, or that we need to try a rather different approach. One simple epicycle makes the theory extensionally adequate, but philosophically uninteresting. Consider modifying the theory to require Ac to be not just reasonable and attentive, but informed of U’s circumstances. Then the context identified by Ac will be the salient context for determining the referent of U’s indexicals. But saying this is not to offer a theory of content for recorded indexicals, it is merely to say that ideally placed observers have access to all the relevant semantic facts. Even this might be wrong if epistemicism about vagueness is correct, but if that is true then Romdenh-Romluc’s theory is probably radically mistaken, for then there are facts about content that cannot be reasonably believed, even by an attentive and informed observer. We still seem to be a fair distance from having an acceptable theory.\n\n\n\n\nReferences\n\nRomdenh-Romluc, Komarine. 2002. “Now the French Are Invading England.” Analysis 62 (1): 34–41. https://doi.org/10.1093/analys/62.1.34."
  },
  {
    "objectID": "posts/gbc/index.html",
    "href": "posts/gbc/index.html",
    "title": "Games, Beliefs and Credences",
    "section": "",
    "text": "In previous work (Weatherson 2005, 2011, 2012b) I’ve defended an interest-relative theory of belief. This paper continues the defence. I have four aims.\n\nPublished in Philosophy and Phenomenological Research 92: 209-236.\n\n\nTo offer a new kind of reason for being unsatisfied with the simple Lockean reduction of belief to credence.\nTo defend the legitimacy of appealing to credences in a theory of belief.\nTo illustrate the importance of theoretical, as well as practical, interests in an interest-relative account of belief.\nTo have another try at extending my basic account of belief to cover propositions that are practically and theoretically irrelevant to the agent.\n\nYou’re probably familiar with the following dialectic. We want there to be some systematic connection between credences and beliefs. At first blush, saying that a person believes \\(p\\) and has a very low credence in \\(p\\) isn’t just an accusation of irrationality, it is literally incoherent. The simplest such connection would be a reduction of beliefs to credences. But the simplest reductions don’t work.\n\nImage via Meagan via Creative Commons.\n\nIf we identify beliefs with credence 1, and take credences to support betting dispositions, then a rational agent will have very few beliefs. There are lots of things that an agent, we would normally say, believes even though she wouldn’t bet on them at absurd odds. Note that this argument doesn’t rely on reducing credences to betting dispositions; as long as credences support the betting dispositions, the argument goes through.\nA simple retreat is to the so-called Lockean thesis, which holds that to believe that \\(p\\) is to have credence in \\(p\\) greater than some threshold \\(t\\), where \\(t &lt; 1\\). Just how the threshold is determined could be a matter of some discretion. Perhaps it is a function of the agent’s situation, or of the person ascribing beliefs to the agent, or to the person evaluating that ascription. Never mind these complexities; assuming all such things are held fixed, the Lockean thesis says that there is a threshold \\(t\\) such that everything with credence above \\(t\\) is believed.\nThere’s a simple objection to the Lockean thesis. Given some very weak assumptions about the world, it implies that there are plenty of quadruples \\(\\langle S, A, B, A \\wedge B \\rangle\\) such that\n\n\\(S\\) is a rational agent.\n\\(A, B\\) and \\(A \\wedge B\\) are propositions.\n\\(S\\) believes \\(A\\) and believes \\(B\\).\n\\(S\\) does not believe \\(A \\wedge B\\).\n\\(S\\) knows that she has all these states, and consciously reflectively endorses them.\n\nNow one might think, indeed I do think, that such quadruples do not exist at all. But set that objection aside. If the Lockean is correct, these quadruples should be everywhere. That’s because for any \\(t \\in (0, 1)\\) you care to pick, quadruples of the form \\(\\langle S, C, D, C \\wedge D \\rangle\\) are very very common.\n\n\\(S\\) is a rational agent.\n\\(C, D\\) and \\(C \\wedge D\\) are propositions.\n\\(S\\)’s credence in \\(C\\) is greater than \\(t\\), and her credence in \\(D\\) is greater than \\(t\\).\n\\(S\\)’s credence in \\(C \\wedge D\\) is less than \\(t\\).\n\\(S\\) knows that she has all these states, and reflectively endorses them.\n\nThe best arguments for the existence of quadruples \\(\\langle S, A, B, A \\wedge B \\rangle\\) are non-constructive existence proofs. David Christensen (2005) for instance, argues from the existence of the preface paradox to the existence of these quadruples. I’ve expressed some reservations about that argument in the past (Weatherson 2005). But what I want to stress here is that even if these existence proofs work, they don’t really prove what the Lockean needs. They don’t show that quadruples satisfying the constraints we associated with \\(\\langle S, A, B, A \\wedge B \\rangle\\) are just as common as quadruples satisfying the constraints we associated with \\(\\langle S, C, D, C \\wedge D \\rangle\\), for any \\(t\\). But if the Lockean were correct, they should be exactly as common.\nThis kind of consideration pushes some of us, well me in any case, towards an interest-relative account of belief. But I’m going to set that move aside to start by investigating a different objection. This objection holds that the Lockean thesis could not be true, because credence 1 is not sufficient for belief. That is, the Lockean is committed to the thesis known as regularity; that everything left open by belief gets a positive credence. I think regularity is false. That’s hardly news, there are plenty of good arguments against it, though most of these involve cases with some idealisations. Timothy Williamson (2007a) has a compelling argument against regularity turning on reflections about a case involving infinite coin flips.1 I’m going to offer a ‘finite’ argument against regularity, which I hope is of independent interest, and from that conclude the Lockean is mistaken. There is a worry that my argument against the Lockean also undermines my preferred positive view, and I’ll suggest an independently motivated patch. I’ll then turn to Richard Holton’s attack on the very notion of credence, which obviously would have repercussions for attempts to understand beliefs in terms of credences were it to succeed. I think it doesn’t succeed, but it does show there are important and underappreciated constraints on a theory of belief. I’ll conclude with a comparison between my preferred interest-relative account of belief, and a recent account suggested by Jacob Ross and Mark Schroeder. The short version of the comparison is that I think there’s less difference between the views than Ross and Schroeder think, though naturally I think what differences there are favour my view.\n1 If there’s any gap in Williamson’s argument, it is I think at the point where he concludes that any two infinite sequences of coin flips have the same probability of landing all heads. I think that the defender of non-numerical, comparative approaches to probability can deny that with some plausibility. Perhaps the two sequences of coin flips have incomparable probabilities of landing all heads. But this leads us into complications that are irrlevant to this paper, especially since I think it turns out there is a sound Williamsonian argument against the Lockean who lets different sequences have incomparable probabilities. For a more pessimistic take on Williamson’s argument, see Weintraub (2008).\n0.1 Playing Games with a Lockean\nI’m going to raise problems for Lockeans, and for defenders of regularity in general, by discussing a simple game. The game itself is a nice illustration of how a number of distinct solution concepts in game theory come apart. (Indeed, the use I’ll make of it isn’t a million miles from the use that Kohlberg and Mertens (1986) make of it.) To set the problem up, I need to say a few words about how I think of game theory. This won’t be at all original - most of what I say is taken from important works by Robert Stalnaker (1994, 1996, 1998, 1999). But it is different to what I used to think, and perhaps to what some other people think too, so I’ll set it out slowly.2\n2 I’m grateful to the participants in a game theory seminar at Arché in 2011, especially Josh Dever and Levi Spectre, for very helpful discussions that helped me see through my previous confusions.Start with a simple decision problem, where the agent has a choice between two acts \\(A_1\\) and \\(A_2\\), and there are two possible states of the world, \\(S_1\\) and \\(S_2\\), and the agent knows the payouts for each act-state pair are given by the following able.\n\n\n\n\n\n\\(S_1\\)\n\\(S_2\\)\n\n\n\\(A_1\\)\n4\n0\n\n\n\\(A_2\\)\n1\n1\n\n\n\n\nWhat to do? I hope you share the intuition that it is radically underdetermined by the information I’ve given you so far. If \\(S_2\\) is much more probable than \\(S_1\\), then \\(A_2\\) should be chosen; otherwise \\(A_1\\) should be chosen. But I haven’t said anything about the relative probability of those two states. Now compare that to a simple game. Row has two choices, which I’ll call \\(A_1\\) and \\(A_2\\). Column also has two choices, which I’ll call \\(S_1\\) and \\(S_2\\). It is common knowledge that each player is rational, and that the payouts for the pairs of choices are given in the following table. (As always, Row’s payouts are given first.)\n\n\n\n\n\n\\(S_1\\)\n\\(S_2\\)\n\n\n\\(A_1\\)\n4, 0\n0, 1\n\n\n\\(A_2\\)\n1, 0\n1, 1\n\n\n\n\nWhat should Row do? This one is easy. Column gets 1 for sure if she plays \\(S_2\\), and 0 for sure if she plays \\(S_1\\). So she’ll play \\(S_2\\). And given that she’s playing \\(S_2\\), it is best for Row to play \\(A_2\\).\nYou probably noticed that the game is just a version of the decision problem that we discussed a couple of paragraphs ago. The relevant states of the world are choices of Column. But that’s fine; we didn’t say in setting out the decision problem what constituted the states \\(S_1\\) and \\(S_2\\). And note that we solved the problem without explicitly saying anything about probabilities. What we added was some information about Column’s payouts, and the fact that Column is rational. From there we deduced something about Column’s play, namely that she would play \\(S_2\\). And from that we concluded what Row should do.\nThere’s something quite general about this example. What’s distinctive about game theory isn’t that it involves any special kinds of decision making. Once we get the probabilities of each move by the other player, what’s left is (mostly) expected utility maximisation. (We’ll come back to whether the ‘mostly’ qualification is needed below.) The distinctive thing about game theory is that the probabilities aren’t specified in the setup of the game; rather, they are solved for. Apart from special cases, such as where one option strictly dominates another, we can’t say much about a decision problem with unspecified probabilities. But we can and do say a lot about games where the setup of the game doesn’t specify the probabilities, because we can solve for them given the other information we have.\nThis way of thinking about games makes the description of game theory as ‘interactive epistemology’ (Aumann 1999) rather apt. The theorist’s work is to solve for what a rational agent should think other rational agents in the game should do. From this perspective, it isn’t surprising that game theory will make heavy use of equilibrium concepts. In solving a game, we must deploy a theory of rationality, and attribute that theory to rational actors in the game itself. In effect, we are treating rationality as something of an unknown, but one that occurs in every equation we have to work with. Not surprisingly, there are going to be multiple solutions to the puzzles we face.\nThis way of thinking lends itself to an epistemological interpretation of one of the most puzzling concepts in game theory, the mixed strategy. Arguably the core solution concept in game theory is the Nash equilibrium. As you probably know, a set of moves is a Nash equilibrium if no player can improve their outcome by deviating from the equilibrium, conditional on no other player deviating. In many simple games, the only Nash equilibria involve mixed strategies. Here’s one simple example.\n\n\n\n\n\n\\(S_1\\)\n\\(S_2\\)\n\n\n\\(A_1\\)\n0, 1\n10, 0\n\n\n\\(A_2\\)\n9, 0\n-1, 1\n\n\n\n\nThis game is reminiscent of some puzzles that have been much discussed in the decision theory literature, namely asymmetric Death in Damascus puzzles. Here Column wants herself and Row to make the ‘same’ choice, i.e., \\(A_1\\) and \\(S_1\\) or \\(A_2\\) and \\(S_2\\). She gets 1 if they do, 0 otherwise. And Row wants them to make different choices, and gets 10 if they do. Row also dislikes playing \\(A_2\\), and this costs her 1 whatever else happens. It isn’t too hard to prove that the only Nash equilibrium for this game is that Row plays a mixed strategy playing both \\(A_1\\) and \\(A_2\\) with probability , while Column plays the mixed strategy that gives \\(S_1\\) probability , and \\(S_2\\) with probability .\nNow what is a mixed strategy? It is easy enough to take away form the standard game theory textbooks a metaphysical interpretation of what a mixed strategy is. Here, for instance, is the paragraph introducing mixed strategies in Dixit and Skeath’s Games of Strategy.\n\nWhen players choose to act unsystematically, they pick from among their pure strategies in some random way …We call a random mixture between these two pure strategies a mixed strategy. (Dixit and Skeath 2004, 186)\n\nDixit and Skeath are saying that it is definitive of a mixed strategy that players use some kind of randomisation device to pick their plays on any particular run of a game. That is, the probabilities in a mixed strategy must be in the world; they must go into the players’ choice of play. That’s one way, the paradigm way really, that we can think of mixed strategies metaphysically.\nBut the understanding of game theory as interactive epistemology naturally suggests an epistemological interpretation of mixed strategies.\n\nOne could easily …[model players] …turning the choice over to a randomizing device, but while it might be harmless to permit this, players satisfying the cognitive idealizations that game theory and decision theory make could have no motive for playing a mixed strategy. So how are we to understand Nash equilibrium in model theoretic terms as a solution concept? We should follow the suggestion of Bayesian game theorists, interpreting mixed strategy profiles as representations, not of players’ choices, but of their beliefs. (Stalnaker 1994, 57–58)\n\nOne nice advantage of the epistemological interpretation, as noted by Binmore (2007, 185) is that we don’t require players to have \\(n\\)-sided dice in their satchels, for every \\(n\\), every time they play a game.3 But another advantage is that it lets us make sense of the difference between playing a pure strategy and playing a mixed strategy where one of the ‘parts’ of the mixture is played with probability one.\n3 Actually, I guess it is worse than if some games have the only equilibria involving mixed strategies with irrational probabilities. And it might be noted that Binmore’s introduction of mixed strategies, on page 44 of his (2007), sounds much more like the metaphysical interpretation. But I think the later discussion is meant to indicate that this is just a heuristic introduction; the epistemological interpretation is the correct one.With that in mind, consider the below game, which I’ll call Red-Green. I’ve said something different about this game in earlier work (Weatherson 2012a). But I now think that to understand what’s going on, we need to think about mixed strategies where one element of the mixture has probability one.\nInformally, in this game \\(A\\) and \\(B\\) must each play either a green or red card. I will capitalise \\(A\\)’s moves, i.e., \\(A\\) can play GREEN or RED, and italicise \\(B\\)’s moves, i.e., \\(B\\) can play green or red. If two green cards, or one green card and one red card are played, each player gets $1. If two red cards are played, each gets nothing. Each cares just about their own wealth, so getting $1 is worth 1 util. All of this is common knowledge. More formally, here is the game table, with \\(A\\) on the row and \\(B\\) on the column.\n\n\n\n\n\ngreen\nred\n\n\nGREEN\n1, 1\n1, 1\n\n\nRED\n1, 1\n0, 0\n\n\n\n\nWhen I write game tables like this, and I think this is the usual way game tables are to be interpreted (Weatherson 2012b), I mean that the players know that these are the payouts, that the players know the other players to be rational, and these pieces of knowledge are common knowledge to at least as many iterations as needed to solve the game. With that in mind, let’s think about how the agents should approach this game.\nI’m going to make one big simplifying assumption at first. We’ll relax this later, but it will help the discussion to start with this assumption. This assumption is that the doctrine of Uniqueness applies here; there is precisely one rational credence to have in any salient proposition about how the game will play. Some philosophers think that Uniqueness always holds (White 2005). I join with those such as North (2010) and Schoenfield (2013) who don’t. But it does seem like Uniqueness might often hold; there might often be a right answer to a particular problem. Anyway, I’m going to start by assuming that it does hold here.\nThe first thing to note about the game is that it is symmetric. So the probability of \\(A\\) playing GREEN should be the same as the probability of \\(B\\) playing green, since \\(A\\) and \\(B\\) face exactly the same problem. Call this common probability \\(x\\). If \\(x &lt; 1\\), we get a quick contradiction. The expected value, to Row, of GREEN, is 1. Indeed, the known value of GREEN is 1. If the probability of green is \\(x\\), then the expected value of RED is \\(x\\). So if \\(x &lt; 1\\), and Row is rational, she’ll definitely play GREEN. But that’s inconsistent with the claim that \\(x &lt; 1\\), since that means that it isn’t definite that Row will play GREEN.\nSo we can conclude that \\(x = 1\\). Does that mean we can know that Row will play GREEN? No. Assume we could conclude that. Whatever reason we would have for concluding that would be a reason for any rational person to conclude that Column will play green. Since any rational person can conclude this, Row can conclude it. So Row knows that she’ll get 1 whether she plays GREEN or RED. But then she should be indifferent between playing GREEN and RED. And if we know she’s indifferent between playing GREEN and RED, and our only evidence for what she’ll play is that she’s a rational player who’ll maximise her returns, then we can’t be in a position to know she’ll play GREEN.\nI think the arguments of the last two paragraphs are sound. We’ll turn to an objection presently, but let’s note how bizarre is the conclusion we’ve reached. One argument has shown that it could not be more probable that Row will play GREEN. A second argument has shown that we can’t know that Row will play GREEN. It reminds me of examples involving blindspots (Sorensen 1988). Consider this case:\n\nBrian does not know (B).\n\nThat’s true, right? Assume it’s false, so I do know (B). Knowledge is factive, so (B) is true. But that contradicts the assumption that it’s false. So it’s true. But I obviously don’t know that it’s true; that’s what this very true proposition says.4\n4 It’s received wisdom in philosophy that one can never properly say something of the form p, but I don’t know that p. This is used as a data point in views as far removed from each other as those defended in Heal (1994) and Williamson (1996). But I don’t feel the force of this alleged datum at all, and (B) is just one reason. For a different kind of case that makes the same point, see Maitra and Weatherson (2010).5 As an aside, the existence of these cases is why I get so irritated when epistemologists try to theorise about ‘Gettier Cases’ as a class. What does (B) have in common with inferences from a justified false belief, or with otherwise sound reasoning that is ever so close to issuing in a false conclusion due to relatively bad luck? As far as I can tell, the class of justified true beliefs that aren’t knowledge is a disjunctive mess, and this should matter for thinking about the nature of knowledge. For further examples, see Williamson (2013) and Nagel (2013).Now I’m not going to rest anything on this case, because there are so many tricky things one can say about blindspots, and about the paradoxes generally. It does suggest that there are other finite cases where one can properly have maximal credence in a true proposition without knowledge.5 And, assuming that we shouldn’t believe things we know we don’t know, that means we can have maximal credence in things we don’t believe. All I want to point out is that this phenomena of maximal credence without knowledge, and presumably without full belief, isn’t a quirky feature of self-reference, or of games, or of puzzles about infinity; it comes up in a wide range of cases.\nFor the rest of this section I want to reply to one objection, and weaken an assumption I made earlier. The objection is that I’m wrong to assume that agents will only maximise expected utility. They may have tie-breaker rules, and those rules might undermine the arguments I gave above. The assumption is that there’s a uniquely rational credence to have in any given situation.\nI argued that if we knew that \\(A\\) would play GREEN, we could show that \\(A\\) had no reason to play GREEN. But actually what we showed was that the expected utility of playing GREEN would be the same as playing RED. Perhaps \\(A\\) has a reason to play GREEN, namely that GREEN weakly dominates RED. After all, there’s one possibility on the table where GREEN does better than RED, and none where RED does better. And perhaps that’s a reason, even if it isn’t a reason that expected utility considerations are sensitive to.\nNow I don’t want to insist on expected utility maximisation as the only rule for rational decision making. Sometimes, I think some kind of tie-breaker procedure is part of rationality. In the papers by Stalnaker I mentioned above, he often appeals to this kind of weak dominance reasoning to resolve various hard cases. But I don’t think weak dominance provides a reason to play GREEN in this particular case. When Stalnaker says that agents should use weak dominance reasoning, it is always in the context of games where the agents’ attitude towards the game matrix is different to their attitude towards each other. One case that Stalnaker discusses in detail is where the game table is common knowledge, but there is merely common (justified, true) belief in common rationality. Given such a difference in attitudes, it does seem there’s a good sense in which the most salient departure from equilibrium will be one in which the players end up somewhere else on the table. And given that, weak dominance reasoning seems appropriate.\nBut that’s not what we’ve got here. Assuming that rationality requires playing GREEN/green, the players know we’ll end up in the top left corner of the table. There’s no chance that we’ll end up elsewhere. Or, perhaps better, there is just as much chance we’ll end up ‘off the table’, as that we’ll end up in a non-equilibrium point on the table. To make this more vivid, consider the ‘possibility’ that \\(B\\) will play blue, and if \\(B\\) plays blue, \\(A\\) will receive 2 if she plays RED, and -1 if she plays GREEN. Well hold on, you might think, didn’t I say that green and red were the only options, and this was common knowledge? Well, yes, I did, but if the exercise is to consider what would happen if something the agent knows to be true doesn’t obtain, then the possibility that one agent will play blue certainly seems like one worth considering. It is, after all, a metaphysical possibility. And if we take it seriously, then it isn’t true that under any possible play of the game, GREEN does better than RED.\nWe can put this as a dilemma. Assume, for reductio, that GREEN/green is the only rational play. Then if we restrict our attention to possibilities that are epistemically open to \\(A\\), then GREEN does just as well as RED; they both get 1 in every possibility. If we allow possibilities that are epistemically closed to \\(A\\), then the possibility where \\(B\\) plays blue is just as relevant as the possibility that \\(B\\) is irrational. After all, we stipulated that this is a case where rationality is common knowledge. In neither case does the weak dominance reasoning get any purchase.\nWith that in mind, we can see why we don’t need the assumption of Uniqueness. Let’s play through how a failure of Uniqueness could undermine the argument. Assume, again for reductio, that we have credence \\(\\varepsilon &gt; 0\\) that \\(A\\) will play RED. Since \\(A\\) maximises expected utility, that means \\(A\\) must have credence 1 that \\(B\\) will play green. But this is already odd. Even if you think people can have different reactions to the same evidence, it is odd to think that one rational agent could regard a possibility as infinitely less likely than another, given isomorphic evidence. And that’s not all of the problems. Even if \\(A\\) has credence 1 that \\(B\\) will play green, it isn’t obvious that playing RED is rational. After all, relative to the space of epistemic possibilities, GREEN weakly dominates RED. Remember that we’re no longer assuming that it can be known what \\(A\\) or \\(B\\) will play. So even without Uniqueness, there are two reasons to think that it is wrong to have credence \\(\\varepsilon &gt; 0\\) that \\(A\\) will play RED. So we’ve still shown that credence 1 doesn’t imply knowledge, and since the proof is known to us, and full belief is incompatible with knowing that you can’t know, this is a case where credence 1 doesn’t imply full belief. So whether \\(A\\) plays GREEN, like whether the coin will ever land tails, is a case the Lockean cannot get right. No matter where they set the threshold for belief our credence is above that threshold, but we don’t believe.\nSo I think this case is a real problem for a Lockean view about the relationship between credence and belief. If A is rational, she can have credence 1 that B will play green, but won’t believe that B will play green. But now you might worry that my own account of the relationship between belief and credence is in just as much trouble. After all, I said that to believe \\(p\\) is, roughly, to have the same attitudes towards all salient questions as you have conditional on \\(p\\). And it’s hard to identify a question that rational A would answer differently upon conditionalising on the proposition that B plays green.\nI think what went wrong in my earlier view was that I’d too quickly equated updating with conditionalisation. The two can come apart. Here’s an example from Gillies (2010) that makes the point well.6\n6 A similar example is in Kratzer (2012, 94).\nI have lost my marbles. I know that just one of them – Red or Yellow – is in the box. But I don’t know which. I find myself saying things like …“If Yellow isn’t in the box, the Red must be.” (4:13)\n\nAs Gillies goes on to point out, this isn’t really a problem for the Ramsey test view of conditionals.\n\nThe Ramsey test – the schoolyard version, anyway – is a test for when an indicative conditional is acceptable given your beliefs. It says that (if p)(q) is acceptable in belief state B iff q is acceptable in the derived or subordinate state B-plus-the-information-that-p. (4:27)\n\nAnd he notes that this can explain what goes on with the marbles conditional. Add the information that Yellow isn’t in the box, and it isn’t just true, but must be true, that Red is in the box.\nNote though that while we can explain this conditional using the Ramsey test, we can’t explain it using any version of the idea that probabilities of conditionals are conditional probabilities. The probability that Red must be in the box is 0. The probability that Yellow isn’t in the box is not 0. So conditional on Yellow not being in the box, the probability that Red must be in the box is still 0. Yet the conditional is perfectly assertable.\nThere is, and this is Gillies’s key point, something about the behaviour of modals in the consequents of conditionals that we can’t capture using conditional probabilities, or indeed many other standard tools. And what goes for consequents of conditionals goes for updated beliefs too. Learn that Yellow isn’t in the box, and you’ll conclude that Red must be. But that learning can’t go via conditionalisation; just conditionalise on the new information and the probability that Red must be in the box goes from 0 to 0.\nNow it’s a hard problem to say exactly how this alternative to updating by conditionalisation should work. But very roughly, the idea is that at least some of the time, we update by eliminating worlds from the space of possibilities. This affects dramatically the probability of propositions whose truth is sensitive to which worlds are in the space of possibiilties.\nFor example, in the game I’ve been discussing, we should believe that rational B might play red. Indeed, the probability of that is, I think, 1. And whether or not B might play red is highly salient; it matters to the probability of whether A will play GREEN or RED. Conditionalising on something that has probability 1, such as that B will play green, can hardly change that probability. But updating on the proposition that B will play green can make a difference. We can see that by simply noting that the conditional If B plays green, she might play red is incoherent.\nSo I conclude that a theory of belief like mine can handle the puzzle this game poses, as long as it distinguishes between conditionalising and updating, in just the way Gillies suggests. To believe that p is to be disposed to not change any attitude towards a salient question on updating that p. (Plus some bells and whistles to deal with propositions that are not relevant to salient questions. We’ll return to them below.) Updating often goes by conditionalisation, so we can often say that belief means having attitudes that match unconditionally and conditionally on p. But not all updating works that way, and the theory of belief needs to acknowledge this.\n\n\n0.2 Holton on Credence\nWhile I don’t agree with the Lockeans, I do endorse a lot of similar theses to them about the relationship between belief and credence. These theses include that both beliefs and credences exist and that the two are constitutively (as opposed to merely causally) connected. I differ from the Lockeans in holding that both belief and credence have important explanatory roles, and that the connection between the two goes via the interests of the agent. As with most work in this area, my views start off from considerations of cases much like DeRose’s famous bank cases.7 Here’s another contribution to the genre. I know it’s an overcrowded field, but I wanted a case that (a) is pretty realistic, and (b) doesn’t involve the attribution (either to oneself or others) of a propositional attitude. In the example, X and Y are parents of a child, Z.\n7 The idea of using allergies to illustrate the kind of case we’re interested in is due to Ross and Schroeder (2014), and I’m grateful for the idea. It makes the intuitions much more vivid. The kind of cases we’re considering play a big role in, inter alia, DeRose (1992; Cohen 1999) and Fantl and McGrath (2002).\nY: This salad you bought is very good. Does it have nuts in it?\nX: No. The nuttiness you’re tasting is probably from the beans.\nY: Oh, so we could pack it for Z’s lunch tomorrow.\nX: Hang on, I better check about the nuts. Z’s pre-school is very fussy about nuts. One of the children there might have an allergy, and it would be awful to get in trouble over her lunch.\n\nHere’s what I think is going on in that exchange.8 At \\(t_2\\) (I’ll use \\(t_i\\) for the time of the \\(i\\)’th utterance in the exchange), X believes that the salad has no nuts in it. Indeed, the one word sentence “No” expresses that belief. But by \\(t_4\\), X has lost that belief. It would be fine to pack the salad for lunch if it has no nuts, but X isn’t willing to do this for the simple reason that X no longer believes that it has no nuts. Moreover, this change of belief was, or at least could have been for all we’ve said so far, rational on X’s part.\n8 What I say here obviously has some similarities to a view put forward by Jennifer Nagel (2008), but I ultimately end up drawing rather different conclusions to the ones she draws.There’s something a little puzzling about that. Jacob Ross and Mark Schroeder (2014) voice a common intuition when they say that beliefs should only change when new evidence comes in. Indeed, they use this intuition as a key argument against my view of belief. But X doesn’t get any evidence that bears on the nuttiness of the salad. Yet X rationally changes beliefs. So I just conclude that sometimes we can change beliefs without new evidence coming in; sometimes our interests, broadly construed, change, and that is enough to change beliefs.\nWe’ll come back to Ross and Schroeder’s arguments in the next section, because first I want to concede something to the view that only evidence changes beliefs. That view is false, but there might be a true view in the area. And that’s the view that only change in evidence can change credences. But that view only makes sense if there are such things as credences, and that’s something that Richard Holton (2014) has recently launched an intriguing argument against.\nHolton’s broader project is a much more sweeping attack on the Lockean thesis than I have proposed. Actually, it is a pair of more sweeping attacks. One of the pair is that the Lockeans identify something that exists, namely belief, with something that doesn’t, namely high credence. I would not, could not, sign up for that critique. But I am much more sympathetic to the other attack in the pair, namely that credences and beliefs have very different dynamics.\nCredences are, by their nature, exceedingly unstable. Whether an agent’s credence that \\(p\\) is above or below any number x is liable to change according to any number of possible changes in evidence. But, at least if the agent is rational, beliefs are not so susceptible to change. Holton thinks that rational agents, or at least rational humans, frequently instantiate the following pattern. They form a belief that \\(p\\), on excellent grounds. They later get some evidence that \\(\\neg p\\). The evidence is strong enough that, had they had it to begin with, they would have remained uncertain about \\(p\\). But they do not decide to reopen the investigation into whether \\(p\\). They hold on to their belief that \\(p\\), the matter having been previously decided.\nSuch an attitude might look like unprincipled dogmatism. But it need not be, I think, as long as four criteria are met. (I think Holton agrees with these criteria.) One is that the agent’s willingness to reopen the question of whether \\(p\\) must increase. She must be more willing, in the light of yet more evidence against \\(p\\), to consider whether \\(p\\) is really true. A second is that, should the agent (irrationally) reopen the question of whether \\(p\\), she should not use the fact that she previously closed that question as evidence. Once the genie is out of the box, only reasoning about \\(p\\) can get it back in. A third is that the costs of the inquiry must be high enough to warrant putting it off. If simply turning one’s head fifteen degrees to the left will lead to acquiring evidence that definitively settles whether \\(p\\), it is a little dogmatic to refuse to do so in the face of evidence against one’s previously formed opinion that \\(p\\). And finally, the costs of being wrong about \\(p\\) must not be too high. X, in our little dialogue above, would be terribly dogmatic if they didn’t reopen the question of whether the salad had nuts in it, on being informed that this information was being used in a high stakes inquiry.\nSo beliefs should have a kind of resilience. Credences, if they exist, should not have this kind of resilience. So this suggests that a simple reduction of belief to credence, as the Lockeans suggest, cannot be right. You might worry that things are worse, that no reduction of belief to credence can be compatible with the difference in resilience between belief and credence. We’ll return to that point, because first I want to look at Holton’s stronger claim: that there are no such things as credences.\nHolton acknowledges, as of course he must, that we have probabilistic truth-directed attitudes. We can imagine a person, call her Paula, who thinks it’s likely that Richard III murdered his nephews, for instance. But Holton offers several reasons for thinking that in these probabilistic truth-directed attitudes, the probability goes in the content, not in the attitude. That is, we should interpret Paula as believing the probabilistic claim, Richard III probably murdered his nephews, and not as having some graded attitude towards the simple proposition Richard III murdered his nephews. More precisely, Holton thinks we should understand Paula’s explicit attitudes that way, and that independent of having reason to think that agents explicitly have probabilistic attitudes, there’s no good way to make sense of the claim that they implicitly have probabilistic attitudes. So there’s no such thing as credences, as usually understood. Or, at least, there’s no good sense to be made of the claim that there are credences.\nIn response, I want to make six points.\n\nHolton is right about cases like Paula’s, and the possibility of iterating terms like probably provides independent support for this view.\nBeliefs like the one Paula has are odd; they seem to have very strange truth conditions.\nOur theory of mind needs some mechanism for explaining the relationship between confidence and action.\nThe ‘explanatory gap’ here could be filled by positing a binary attitude is more confident that.\nThis binary attitude can do all the work that graded attitudes were posited to do, and in a (historically sensitive) way saves the credences story.\nCredences (or at least confidences) can have a key role within a Holton-like story about graded belief. They can both explain why agents reconsider some beliefs, and provide a standard of correctness for decisions to reconsider.\n\nLet’s take those in order.\nI’m not going to rehearse Holton’s argument for the ‘content view’: that in cases like Paula’s the content of her attitude, and not the attitude itself, is probabilistic. But I do want to offer one extra consideration in its favour. (I’m indebted here to work in progress by my colleague Sarah Moss (2015), though I’m not sure she’d approve of this conclusion.) As well as Paula, we can imagine a person Pip who isn’t sure that Paula is right, but thinks she’s probably right. That is, Pip thinks that Richard III probably probably murdered his nephews. It’s easy to make sense of Pip on the content view. Modalities in propositions iterate smoothly; that’s what they are designed to do. But it’s much harder to iterate attitudes. The possibility of cases like Pip suggests Holton must be right about Paula’s case.\nBut Paula’s case is odd. Beliefs have truth conditions. What are the truth conditions for Paula’s belief? On the one hand, it seems they must be sensitive to her evidence. If she later acquires conclusive evidence that Richard III was framed, she won’t think her earlier self had a false belief. But if we put the evidence into the content of the belief, we get the strange result that her belief can’t be preserved by uttering the same words to herself over again. That is, if the content of Paula’s belief is Given the evidence I have now, Richard III likely murdered his nephews, she can’t have the very same belief tomorrow by retaining the thought Richard III likely murdered his nephews. And she can’t have a belief with the same content as anyone else by the two of them both thinking Richard III likely murdered his nephews. Those seem like unhappy conclusions, especially in the midst of a project that wants to emphasise the resiliency of belief. So perhaps we should say, following Stephenson (2007) or MacFarlane (2011), that the truth conditions of the belief are agent-relative. Or, if we’re unhappy with the MacFarlane story, we might be pushed towards a kind of expressivism (perhaps a la Yalcin (2011)), which isn’t quite like either the content view or the attitude view that Holton discusses. I’m personally partial to the relativist view, but I don’t want to argue for that here, just note that the content view raises some interesting problems, and that natural solutions to them could in a way blur the boundaries between the content and attitude views.\nAs Holton notes in his discussion of Brutus, when our confidence in a proposition changes, our actions will change. Paula gets a little evidence that Richard III was framed, and her actions may change. Of course, not much of what we do in everyday life is sensitive to facts about English royal history, but there may be some effects. Maybe she’ll be less inclined to speak up if the topic of the princes’ murder comes up, or she’ll take a slightly more jaundiced view of Shakespeare’s play (compare Friend (2003).) Holton says that these falling confidences need not have all the precise structure of credences. In particular, they may not have the topology of the interval \\([0, 1]\\). But lots of credence lovers think that’s too demanding. There’s a long tradition of thinking that credences need not all be comparable.9 What’s important is that the relative confidences exist, and that they have a robust relationship to action.\n9 Notable members of the tradition include Levi (1974), Jeffrey (1983) and Fraassen (1989).There’s an old fashioned way of doing this. The idea is implicit in Ramsey (1926), and made central in DeFinetti (1964). Take the binary attitude is more confident that p than q as primitive. As Holton notes, surface structure of our attitude reports suggest that this attitude, unlike the graded attitude of credence, is part of folk psychology. Lay down some constraints on this attitude. To get enough constraints that the binary relation determines a unique probability function, the constraints will have to be very tight. In particular, you’ll need some kind of Archimedean principle, and a principle of universal comparability. Those aren’t very plausible, especially the second. But even weaker constraints will get you something interesting. In particular, it isn’t hard to lay down enough constraints that there is a unique set \\(S\\) of probability functions such that the agent is more confident that \\(p\\) than \\(q\\) just in case \\(\\Pr( p) &gt; \\Pr(q)\\) for all \\(\\Pr \\in S\\). (For much more detail, see for instance Walley (1991).)\nIn that way, we can derive credences from the relative confidences of a reasonably coherent agent. But we can do with even less coherence than that I think. A throwaway remark from Ramsey (1929/1990) provides a key clue. What is it to have credence \\(\\frac{2}{3}\\) in \\(p\\)? Don’t say it’s a betting disposition; mental states and behavioural dispositions aren’t that tightly linked. Here’s Ramsey’s idea. To have credence \\(\\frac{2}{3}\\) in \\(p\\) is to be exactly as confident in \\(p\\) as in \\(q \\vee r\\), where \\(q, r\\) and \\(s\\) are taken to be exclusive and exhaustive, and one has equal confidence in all three. It’s easy to see how to extend that to a definition of credence \\(\\frac{m}{n}\\) for any integer \\(m, n\\). It’s a little trickier to say precisely what, say, credence \\(\\frac{1}{\\pi}\\) is, but rational credences are probably credences enough to explain action. And just like that, we have a way of talking about credences, i.e., graded attitudes, without positing anything more than a binary attitude more confident than.\nPerhaps Holton could argue that we only have unary attitudes, not binary attitudes like more confident than. If Maury is more confident that Oswald shot JFK than that Richard III murdered his nephews, that means he really believes the proposition It is more likely that Oswald shot JFK than that Richard III murdered his nephews. But such a view seems forced at best, and isn’t motivated by Holton’s other arguments for the ‘content view’. This attitude of more confident than isn’t iterable. It isn’t subject to the particular kind of reasoning errors that Holton takes to be evidence for the content view in the probabilistic case. It is an attitude we ordinarily report as a binary attitude in normal speech. In short, it looks like a genuine binary attitude.\nGiven that the binary attitude exists, and that we can define numerical (at least rational) credences in terms of it, I’d say that’s enough to say that credences exist. In a sense, credences will be epiphenomenal. What does the explanatory work is the binary relation more confident that. Maury might stay away from a showing of Richard III because he is less confident that it is historically accurate than he used to be. We can work out from Maury’s other relative confidences what his credence in Richard III’s guilt is and was. Or, at least, we can work out bounds on these. But those numbers aren’t in a fundamental sense explanatory, and neither are the complicated sets of relative confidences that constitute the numbers. What’s really explanatory are relative confidences. But it’s a harmless enough mode of speech to talk as if credences are explanatory; they are easier to talk about than the underlying relative confidences.\n\n\n0.3 The Power of Theoretical Interests\nSo I think we should accept that credences exist. And we can just about reduce beliefs to credences. In previous work I argued that we could do such a reduction. I’m not altogether sure whether the amendments to that view I’m proposing here means it no longer should count as a reductive view; we’ll come back to that question in the conclusion.\nThe view I defended in previous work is that the reduction comes through the relationship between conditional and unconditional attitudes. Very roughly, to believe that p is simply to have the same attitudes, towards all salient questions, unconditionally as you have conditional on p. In a syrupy slogan, belief means never having to say you’ve conditionalised. For reasons I mentioned in section 1, I now think that was inaccurate; I should have said that belief means never having to say you’ve updated, or at least that you’ve updated your view on any salient question.\nThe restriction to salient questions is important. Consider any p that I normally take for granted, but such that I wouldn’t bet on it at insane odds. I prefer declining such a bet to taking it. But conditional on p, I prefer taking the bet. So that means I don’t believe any such p. But just about any p satisfies that description, for at least some ‘insane’ odds. So I believe almost nothing. That would be a reductio of the position. I respond by saying that the choice of whether to take an insane bet is not normally salient.\nBut now there’s a worry that I’ve let in too much. For many p, there is no salient decision that they even bear on. What I would do conditional on p, conditional on \\(\\neg p\\), and unconditionally is exactly the same, over the space of salient choices. (And this isn’t a case where updating and conditionalising come apart; I’ll leave this proviso mostly implicit from now on.) So with the restriction in place, I believe p and \\(\\neg p\\). That seems like a reductio of the view too. I probably do have inconsistent beliefs, but not in virtue of p being irrelevant to me right now. I’ve changed my mind a little about what the right way to avoid this problem is, in part because of some arguments by Jacob Ross and Mark Schroeder.\nThey have what looks like, on the surface, a rather different view to mine. They say that to believe p is to have a default reasoning disposition to use p in reasoning. Here’s how they describe their own view.\n\nWhat we should expect, therefore, is that for some propositions we would have a defeasible or default disposition to treat them as true in our reasoning–a disposition that can be overridden under circumstances where the cost of mistakenly acting as if these propositions are true is particularly salient. And this expectation is confirmed by our experience. We do indeed seem to treat some uncertain propositions as true in our reasoning; we do indeed seem to treat them as true automatically, without first weighing the costs and benefits of so treating them; and yet in contexts such as High where the costs of mistakenly treating them as true is salient, our natural tendency to treat these propositions as true often seems to be overridden, and instead we treat them as merely probable.\nBut if we concede that we have such defeasible dispositions to treat particular propositions as true in our reasoning, then a hypothesis naturally arises, namely, that beliefs consist in or involve such dispositions. More precisely, at least part of the functional role of belief is that believing that p defeasibly disposes the believer to treat p as true in her reasoning. Let us call this hypothesis the reasoning disposition account of belief. (Ross and Schroeder 2014, 9–10)\n\nThere are, relative to what I’m interested in, three striking characteristics of Ross and Schroeder’s view.\n\nWhether you believe p is sensitive to how you reason; that is, your theoretical interests matter.\nHow you would reason about some questions that are not live is relevant to whether you believe p.\nDispositions can be masked, so you can believe p even though you don’t actually use p in reasoning now.\n\nI think they take all three of these points to be reasons to favour their view over mine. As I see it, we agree on point 1 (and I always had the resources to agree with them), I can accommodate point 2 with a modification to my theory, and point 3 is a cost of their theory, not a benefit. Let’s take those points in order.\nThere are lots of reasons to dislike what Ross and Schroeder call Pragmatic Credal Reductionism (PCR). This is, more or less, the view that the salient questions, in the sense relevant above, are just those which are practically relevant to the agent. So to believe \\(p\\) just is to have the same attitude towards all practically relevant questions unconditionally as conditional on \\(p\\). There are at least three reasons to resist this view.\nOne reason comes from the discussions of Ned Block’s example Blockhead  (Block 1978). As Braddon-Mitchell and Jackson point out, the lesson to take from that example is that beliefs are constituted in part by their relations to other mental states  (Braddon-Mitchell and Jackson 2007, 114ff). There’s a quick attempted refutation of PCR via the Blockhead case which doesn’t quite work. We might worry that if all that matters to belief given PCR is how it relates to action, PCR will have the implausible consequence that Blockhead has a rich set of beliefs. That isn’t right; PCR is compatible with the view that Blockhead doesn’t have credences, and hence doesn’t have credences that constitute beliefs. But the Blockhead example’s value isn’t exhausted by its use in quick refutations.10 The lesson is that beliefs are, by their nature, interactive. It seems to me that PCR doesn’t really appreciate that lesson.\n10 The point I’m making here is relevant I think to recent debates about the proper way to formalise counterexamples in philosophy, as in  (Williamson 2007b; Ichikawa and Jarvis 2009; Malmgren 2011). I worry that too much of that debate is focussed on the role that examples play in one-step refutations. But there’s more, much more, to a good example than that.Another reason comes from recent work by Jessica Brown (2014). Compare these two situations.\n\nS is in circumstances C, and has to decide whether to do X.\nS is in completely different circumstances to C, but is seriously engaged in planning for future contingencies. She’s currently trying to decide whether in circumstances C to do X.\n\nIntuitively, S can bring exactly the same evidence, knowledge and beliefs to bear on the two problems. If C is a particularly high stakes situation, say it is a situation where one has to decide what to feed someone with a severe peanut allergy, then a lot of things that can ordinarily be taken for granted cannot, in this case, be taken for granted. And that’s true whether S is actually in C, or she is just planning for the possibility that she finds herself in C.\nSo I conclude that both practical and theoretical interests matter for what we can take for granted in inquiry. The things we can take for granted into a theoretical inquiry into what to do in high stakes contexts as restricted, just as they are when we are in a high stakes context, and must make a practical decision. Since the latter restriction on what we can take for granted is explained by (and possibly constituted by) a restriction on what we actually believe in those contexts, we should similarly conclude that agents simply believe less when they are reasoning about high stakes contexts, whatever their actual context.\nA third reason to dislike PCR comes from the ‘Renzi’ example in Ross and Schroeder’s paper. I’ll run through a somewhat more abstract version of the case, because I don’t think the details are particularly important. Start with a standard decision problem. The agent knows that X is better to do if p, and Y is better to do if \\(\\neg p\\). The agent should then go through calculating the relative gains to doing X or Y in the situations they are better, and the probability of p. But the agent imagined doesn’t do that. Rather, the agent divides the possibility space in four, taking the salient possibilities to be \\(p \\wedge q, p \\wedge \\neg q, \\neg p \\wedge q\\) and \\(\\neg p \\wedge \\neg q\\), and then calculates the expected utility of X and Y accordingly. This is a bad bit of reasoning on the agent’s part. In the cases we are interested in, q is exceedingly likely. Moreover, the expected utility of each act doesn’t change a lot depending on q’s truth value. So it is fairly obvious that we’ll end up making the same decision whether we take the ‘small worlds’ in our decision model to be just the world where p, and the world where \\(\\neg p\\), or the four worlds this agent uses. But the agent does use these four, and the question is what to say about them.\nRoss and Schroeder say that such an agent should not be counted as believing that q. If they are consciously calculating the probability that q, and taking \\(\\neg q\\) possibilities into account when calculating expected utilities, they regard q as an open question. And regarding q as open in this way is incompatible with believing it. I agree with all this.\nThey also think that PCR implies that the agent does believe q. The reason is that conditionalising on q doesn’t change the agent’s beliefs about any practical question. I think that’s right too, at least on a natural understanding of what ‘practical’ is.\nMy response to all these worries is to say that whether someone believes that p depends not just on how conditionalising (or more generally updating) on p would affect someone’s action, but on how it would affect their reasoning. That is, just as we learned from the Blockhead example, to believe that p requires having a mental state that is connected to the rest of one’s cognitive life in roughly the way a belief that p should be connected. Let’s go through both the last two cases to see how this works on my theory.\nOne of the things that happens when the stakes go up is that conditionalising on very probable things can change the outcome of interesting decisions. Make the probability that some nice food is peanut-free be high, but short of one. Conditional on it being peanut-free, it’s a good thing to give to a peanut-allergic guest. But unconditionally, it’s a bad thing to give to such a guest, because the niceness of the food doesn’t outweigh the risk of killing them. And that’s true whether the guest is actually there, or you’re just thinking about what to do should such a guest arrive in the future. In general, the same questions will be relevant whether you’re in C trying to decide whether to do X, or simply trying to decide whether to X in C. In one case they will be practically relevant questions, in the other they will be theoretically relevant questions. But this feels a lot like a distinction without a difference, since the agent should have similar beliefs in the two cases.\nThe same response works for Ross and Schroeder’s case. The agent was trying to work out the expected utility of X and Y by working out the utility of each action in each of four ‘small worlds’, then working out the probability of each of these. Conditional on q, the probability of two of them (\\(p \\wedge \\neg q, \\neg p \\wedge \\neg q\\)), will be 0. Unconditionally, this probability won’t be 0. So the agent has a different view on some question they have taken an interest in unconditionally to their view conditional on q. So they don’t believe q. The agent shouldn’t care about that question, and conditional on each question they should care about, they have the same attitude unconditionally and conditional on q. But they do care about these probabilistic questions, so they don’t believe q.\nSo I think that Ross and Schroeder and I agree on point 1; something beyond practical interests is relevant to belief.\nThey have another case that I think does suggest a needed revision to my theory. I’m going to modify their case a little to change the focus a little, and to avoid puzzles about vagueness. (What follows is a version of their example about Dalı́’s moustache, purged of any worries about vagueness, and without the focus on consistency. I don’t think the problem they true to press on me, that my theory allows excessive inconsistency of belief among rational agents, really sticks. Everyone will have to make qualifications to consistency to deal with the preface paradox, and for reasons I went over in  (Weatherson 2005), I think the qualifications I make are the best ones to make.)\nLet D be the proposition that the number of games the Detroit Tigers won in 1976 (in the MLB regular season) is not a multiple of 3. At most times, D is completely irrelevant to anything I care about, either practically or theoretically. My attitudes towards any relevant question are the same unconditionally as conditional on D. So there’s a worry that I’ll count as believing D, and believing \\(\\neg D\\), by default.\nIn earlier work, I added a clause meant to help with cases like this. I said that for determining whether an agent believes that p, we should treat the question of whether p’s probability is above or below 0.5 as salient, even if the agent doesn’t care about it. Obviously this won’t help with this particular case. The probability of D is around , and is certainly above 0.5. My ‘fix’ avoids the consequence that I implausibly count as believing \\(\\neg D\\). But I still count, almost as implausibly, as believing D. This needs to be fixed.\nHere’s my proposed change. For an agent to count as believing p, it must be possible for p to do some work for them in reasoning. Here’s what I mean by work. Consider a very abstract set up of a decision problem, as follows.\n\n\n\n\n\np\nq\n\n\nX\n4\n1\n\n\nY\n3\n2\n\n\n\n\nThat table encodes a lot of information. It encodes that \\(p \\vee q\\) is true; otherwise there are some columns missing. It encodes that the only live choices are X or Y; otherwise there are rows missing. It encodes that doing X is better than doing Y if p, and worse if q.\nFor any agent, and any decision problem, there is a table like this that they would be disposed to use to resolve that problem. Or, perhaps, there are a series of tables and there is no fact about which of them they would be most disposed to use.\nGiven all that terminology, here’s my extra constraint on belief. To believe that p, there must be some decision problem such that some table the agent would be disposed to use to solve it encodes that p. If there is no such problem, the agent does not believe that p. For anything that I intuitively believe, this is an easy condition to satisfy. Let the problem be whether to take a bet that pays 1 if p, and loses 1 otherwise. Here’s the table I’d be disposed to use to solve the problem.\n\n\n\n\n\np\n\n\nTake bet\n1\n\n\nDecline bet\n0\n\n\n\n\nThis table encodes that p, so it is sufficient to count as believing that p. And it doesn’t matter that this bet isn’t on the table. I’m disposed to use this table, so that’s all that matters.\nBut might there be problems in the other direction. What about an agent who, if offered such a bet on D, would use such a simple table? I simply say that they believe that D. I would not use any such table. I’d use this table.\n\n\n\n\n\nD\n\\(\\neg D\\)\n\n\nTake bet\n1\n–1\n\n\nDecline bet\n0\n0\n\n\n\n\nNow given the probability of D, I’d still end up taking the bet; it has an expected return of . (Well, actually I’d probably decline the bet because being offered the bet would change the probability of D for reasons made clear in  Runyon (1992, 14–15). But that hardly undermines the point I’m making.) But this isn’t some analytic fact about me, or even I think some respect in which I’m obeying the dictates of rationality. It’s simply a fact that I wouldn’t take D for granted in any inquiry. And that’s what my non-belief that D consists in.\nThis way of responding to the Tigers example helps respond to a nice observation that Ross and Schroeder make about correctness. A belief that p is, in some sense, incorrect if \\(\\neg p\\). It isn’t altogether clear how to capture this sense given a simple reduction of beliefs to credences. I propose to capture it using this idea that decision tables encode propositions. A table is incorrect if it encodes something that’s false. To believe something is, inter alia, to be disposed to use a table that encodes it. So if it is false, it involves a disposition to do something incorrect.\nIt also helps capture Holton’s observation that beliefs should be resilient. If someone is disposed to use decision tables that encode that p, that disposition should be fairly resilient. And to the extent that it is resilient, they will satisfy all the other clauses in my preferred account of belief. So anyone who believes p should have a resilient belief that p.\nThe last point is where I think my biggest disagreement with Ross and Schroeder lies. They think it is very important that a theory of belief vindicate a principle they call Stability.\n\nStability: A fully rational agent does not change her beliefs purely in virtue of an evidentially irrelevant change in her credences or preferences. (20)\n\nHere’s the kind of case that is meant to motivate Stability, and show that views like mine are in tension with it.\n\nSuppose Stella is extremely confident that steel is stronger than Styrofoam, but she’s not so confident that she’d bet her life on this proposition for the prospect of winning a penny. PCR implies, implausibly, that if Stella were offered such a bet, she’d cease to believe that steel is stronger than Styrofoam, since her credence would cease to rationalize acting as if this proposition is true. (22)\n\nRoss and Schroeder’s own view is that if Stella has a defeasible disposition to treat as true the proposition that steel is stronger than Styrofoam, that’s enough for her to believe it. And that can be true if the disposition is not only defeasible, but actually defeated in the circumstances Stella is in. This all strikes me as just as implausible as the failure of Stability. Let’s go over its costs.\nThe following propositions are clearly not mutually consistent, so one of them must be given up. We’re assuming that Stella is facing, and knows she is facing, a bet that pays a penny if steel is stronger than Styrofoam, and costs her life if steel is not stronger than Styrofoam.\n\nStella believes that steel is stronger than Styrofoam.\nStella believes that if steel is stronger than Styrofoam, she’ll win a penny and lose nothing by taking the bet.\nIf 1 and 2 are true, and Stella considers the question of whether she’ll win a penny and lose nothing by taking the bet, she’ll believe that she’ll win a penny and lose nothing by taking the bet.\nStella prefers winning a penny and losing nothing to getting nothing.\nIf Stella believes that she’ll win a penny and lose nothing by taking the bet, and prefers winning a penny and losing nothing to getting nothing, she’ll take the bet.\nStella won’t take the bet.\n\nIt’s part of the setup of the problem that 2 and 4 are true. And it’s common ground that 6 is true, at least assuming that Stella is rational. So we’re left with 1, 3 and 5 as the possible candidates for falsehood.\nRoss and Schroeder say that it’s implausible to reject 1. After all, Stella believed it a few minutes ago, and hasn’t received any evidence to the contrary. And I guess rejecting 1 isn’t the most intuitive philosophical conclusion I’ve ever drawn. But compare the alternatives!\nIf we reject 3, we must say that Stella will simply refuse to infer r from p, q and \\((p \\wedge q) \\rightarrow r\\). Now it is notoriously hard to come up with a general principle for closure of beliefs. But it is hard to see why this particular instance would fail. And in any case, it’s hard to see why Stella wouldn’t have a general, defeasible, disposition to conclude r in this case, so by Ross and Schroeder’s own lights, it seems 3 should be acceptable.\nThat leaves 5. It seems on Ross and Schroeder’s view, Stella simply must violate a very basic principle of means-end reasoning. She desires something, she believes that taking the bet will get that thing, and come with no added costs. Yet, she refuses to take the bet. And she’s rational to do so! At this stage, I think I’ve lost what’s meant to be belief-like about their notion of belief. I certainly think attributing this kind of practical incoherence to Stella is much less plausible than attributing a failure of Stability to her.\nPut another way, I don’t think presenting Stability on its own as a desideratum of a theory is exactly playing fair. The salient question isn’t whether we should accept or reject Stability. The salient question is whether giving up Stability is a fair price to pay for saving basic tenets of means-end rationality. And I think that it is. Perhaps there will be some way of understanding cases like Stella’s so that we don’t have to choose between theories of belief that violate Stability constraints, and theories of belief that violate coherence constraints. But I don’t see one on offer, and I’m not sure what such a theory could look like.\nI have one more argument against Stability, but it does rest on somewhat contentious premises. There’s often a difference between the best methodology in an area, and the correct epistemology of that area. When that happens, it’s possible that there is a good methodological rule saying that if such-and-such happens, re-open a certain inquiry. But that rule need not be epistemologically significant. That is, it need not be the case that the happening of such-and-such provides evidence against the conclusion of the inquiry. It just provides a reason that a good researcher will re-open the inquiry. And, as we’ve stated above, an open inquiry is incompatible with belief.\nHere’s one way that might happen. Like other non-conciliationists about disagreement, e.g.,  Kelly (2010), I hold that disagreement by peers with the same evidence as you doesn’t provide evidence that you are wrong. But it might provide an excellent reason to re-open an inquiry. We shouldn’t draw conclusions about the methodological significance of disagreement from the epistemology of disagreement. So learning that your peers all disagree with a conclusion might be a reason to re-open inquiry into that conclusion, and hence lose belief in the conclusion, without providing evidence that the conclusion is false. This example rests on a very contentious claim about the epistemology of disagreement. But any gap that opens up between methodology and epistemology will allow such an example to be constructed, and hence provide an independent reason to reject Stability.\n\n\n0.4 Conclusion\nYou might well worry that the view here is too complex to really be a theory of belief. Belief is a simple state; why all the epicycles? This is a good question, and I’m not sure I have a sufficiently good answer to it.\nAt heart, the theory I’ve offered here is simple. To believe p is to take p for granted, to take it as given, to take it as a settled question. But one doesn’t take a question as settled in a vacuum. I will take some questions as settled in some circumstances and not others. It’s here that the complexities enter in.\nTo believe p, it isn’t necessary that we take it as settled in all contexts. That would mean that anything one believes one would bet on at any odds. But it isn’t sufficient to take it as settled in some context or other. If I’m facing a tricky bet on p, the fact that I’d take p as settled in some other context doesn’t mean that I believe p. After all, I might even decline the bet, although I desire the reward for winning the bet, and believe that if p I will win. And we can’t just focus on the actual circumstances. Five minutes ago, I neither took it as settled or as open that the Cubs haven’t won the World Series for quite a while. I simply wasn’t thinking about that proposition, and didn’t really take it to be one thing or another.\nThis is why things get so complex. To believe p is to hold a fairly simple attitude towards p in some relevant circumstances. But which circumstances? That’s what’s hard to say, and it’s why the theory is so messy. And I think we have an argument that it must be a little hard to say, namely an argument by exhaustion of all the possible simple things to say. The previous paragraph starts such an argument.\nI’d be a little surprised if the account here is the best or last word on the matter though. It does feel a little disjunctive, as if there is a simpler reduction to be had. But I think it’s better than what came before, so I’m putting it forward.\nThe previous version of the theory I put forward was clearly reductive; beliefs were reduced to credences and preferences. This version is not quite as clearly reductive. Which decision tables the agent is disposed to use, and which propositions those tables encode, are not obviously facts about credences and preferences. So it feels like I’ve given up on the reductive project.\nI’m not altogether happy about this; reduction is a good aim to have. But if reduction of belief to other states fails, I’d think this kind of reason is why it is going to fail. Facts about how an agent conceptualises a problem, how she sets up the decision table, are distinct from facts about which values she writes into the table. This is the deepest reason why the Lockean theory is false. Belief is not the difference between one column in the decision table getting probability 0.98 rather than 0.97; it is the difference between one column being excluded rather than included. If that difference can’t be accounted for in terms of actual credences and preferences, the reductionist project will fail.\n\n\n\n\n\n\nReferences\n\nAumann, Robert J. 1999. “Interactive Epistemology i: Knowledge.” International Journal of Game Theory 28 (3): 263–300. https://doi.org/10.1007/s001820050111.\n\n\nBinmore, Ken. 2007. Playing for Real: A Text on Game Theory. Oxford: Oxford University Press.\n\n\nBlock, Ned. 1978. “Troubles with Functionalism.” Minnesota Studies in the Philosophy of Science 9: 261–325.\n\n\nBraddon-Mitchell, David, and Frank Jackson. 2007. The Philosophy of Mind and Cognition, Second Edition. Malden, MA: Blackwell.\n\n\nBrown, Jessica. 2014. “Impurism, Practical Reasoning and the Threshold Problem.” Noûs 48 (1): 179–92. https://doi.org/10.1111/nous.12008.\n\n\nChristensen, David. 2005. Putting Logic in Its Place. Oxford: Oxford University Press.\n\n\nCohen, Stewart. 1999. “Contextualism, Skepticism, and the Structure of Reasons.” Philosophical Perspectives 13: 57–89. https://doi.org/10.1111/0029-4624.33.s13.3.\n\n\nDeFinetti, Bruno. 1964. “Foresight: Its Logical Laws, Its Subjective Sources.” In Studies in Subjective Probability, edited by Henry E. Kyburg and Howard E. Smokler, 93–156. New York: Wiley.\n\n\nDeRose, Keith. 1992. “Contextualism and Knowledge Attributions.” Philosophy and Phenomenological Research 52 (4): 913–29. https://doi.org/10.2307/2107917.\n\n\nDixit, Avinash K., and Susan Skeath. 2004. Games of Strategy. Second. New York: W. W. Norton & Company.\n\n\nFantl, Jeremy, and Matthew McGrath. 2002. “Evidence, Pragmatics, and Justification.” Philosophical Review 111: 67–94. https://doi.org/10.2307/3182570.\n\n\nFraassen, Bas van. 1989. Laws and Symmetry. Oxford: Clarendon Press.\n\n\nFriend, Stacie. 2003. “How i Really Feel about JFK.” In Imagination, Philosophy and the Arts, edited by Matthew Kieran and Dominic McIver Lopes, 35–53. London. Routledge.\n\n\nGillies, Anthony S. 2010. “Iffiness.” Semantics and Pragmatics 3 (4): 1–42. https://doi.org/10.3765/sp.3.4.\n\n\nHeal, Jane. 1994. “Moore’s Paradox: A Wittgensteinian Approach.” Mind 103 (409): 5–24. https://doi.org/10.1093/mind/103.409.5.\n\n\nHolton, Richard. 2014. “Intention as a Model for Belief.” In Rational and Social Agency: Essays on the Philosophy of Michael Bratman, edited by Manuel Vargas and Gideon Yaffe, 12–37. Oxford: Oxford University Press.\n\n\nIchikawa, Jonathan, and Benjamin Jarvis. 2009. “Thought-Experiment Intuitions and Truth in Fiction.” Philosophical Studies 142 (2): 221–46. https://doi.org/10.1007/s11098-007-9184-y.\n\n\nJeffrey, Richard. 1983. “Bayesianism with a Human Face.” In Testing Scientific Theories, edited by J. Earman (ed.). Minneapolis: University of Minnesota Press.\n\n\nKelly, Thomas. 2010. “Peer Disagreement and Higher Order Evidence.” In Disagreement, edited by Ted Warfield and Richard Feldman, 111–74. Oxford: Oxford University Press.\n\n\nKohlberg, Elon, and Jean-Francois Mertens. 1986. “On the Strategic Stability of Equilibria.” Econometrica 54 (5): 1003–37. https://doi.org/10.2307/1912320.\n\n\nKratzer, Angelika. 2012. Modals and Conditionals. Oxford: Oxford University Press.\n\n\nLevi, Isaac. 1974. “On Indeterminate Probabilities.” Journal of Philosophy 71 (13): 391–418. https://doi.org/10.2307/2025161.\n\n\nMacFarlane, John. 2011. “Epistemic Modals Are Assessment-Sensitive.” In Epistemic Modality, edited by Andy Egan and Brian Weatherson, 144–78. Oxford: Oxford University Press.\n\n\nMaitra, Ishani, and Brian Weatherson. 2010. “Assertion, Knowledge and Action.” Philosophical Studies 149 (1): 99–118. https://doi.org/10.1007/s11098-010-9542-z.\n\n\nMalmgren, Anna-Sara. 2011. “Rationalism and the Content of Intuitive Judgements.” Mind 120 (478): 263–327. https://doi.org/10.1093/mind/fzr039.\n\n\nMoss, Sarah. 2015. “On the Semantics and Pragmatics of Epistemic Vocabulary.” Semantics and Pragmatics 8: 1–81. https://doi.org/10.3765/sp.8.5.\n\n\nNagel, Jennifer. 2008. “Knowledge Ascriptions and the Psychological Consequences of Changing Stakes.” Australasian Journal of Philosophy 86 (2): 279–94. https://doi.org/10.1080/00048400801886397.\n\n\n———. 2013. “Motivating Williamson’s Model Gettier Cases.” Inquiry 56 (1): 54–62. https://doi.org/10.1080/0020174X.2013.775014.\n\n\nNorth, Jill. 2010. “An Empirical Approach to Symmetry and Probability.” Studies In History and Philosophy of Science Part B: Studies In History and Philosophy of Modern Physics 41 (1): 27–40. https://doi.org/10.1016/j.shpsb.2009.08.008.\n\n\nRamsey, Frank. 1929/1990. “Probability and Partial Belief.” In Philosophical Papers, edited by D. H. Mellor, 95–96. Cambridge University Press.\n\n\n———. 1926. “Truth and Probability.” In Philosophical Papers, edited by D. H. Mellor, 52–94. Cambridge: Cambridge University Press.\n\n\nRoss, Jacob, and Mark Schroeder. 2014. “Belief, Credence, and Pragmatic Encroachment.” Philosophy and Phenomenological Research 88 (2): 259–88. https://doi.org/10.1111/j.1933-1592.2011.00552.x.\n\n\nRunyon, Damon. 1992. Guys & Dolls: The Stories of Damon Runyon. New York: Penguin.\n\n\nSchoenfield, Miriam. 2013. “Permission to Believe: Why Permissivism Is True and What It Tells Us about Irrelevant Influences on Belief.” Noûs 47 (1): 193–218. https://doi.org/10.1111/nous.12006.\n\n\nSorensen, Roy A. 1988. Blindspots. Oxford: Clarendon Press.\n\n\nStalnaker, Robert. 1994. “On the Evaluation of Solution Concepts.” Theory and Decision 37 (1): 49–73. https://doi.org/10.1007/BF01079205.\n\n\n———. 1996. “Knowledge, Belief and Counterfactual Reasoning in Games.” Economics and Philosophy 12: 133–63. https://doi.org/10.1017/S0266267100004132.\n\n\n———. 1998. “Belief Revision in Games: Forward and Backward Induction.” Mathematical Social Sciences 36 (1): 31–56. https://doi.org/10.1016/S0165-4896(98)00007-9.\n\n\n———. 1999. “Extensive and Strategic Forms: Games and Models for Games.” Research in Economics 53 (3): 293–319. https://doi.org/10.1006/reec.1999.0200.\n\n\nStephenson, Tamina. 2007. “Judge Dependence, Epistemic Modals, and Predicates of Personal Taste.” Linguistics and Philosophy 30 (4): 487–525. https://doi.org/10.1007/s10988-008-9023-4.\n\n\nWalley, Peter. 1991. Statisical Reasoning with Imprecise Probabilities. London: Chapman & Hall.\n\n\nWeatherson, Brian. 2005. “Can We Do Without Pragmatic Encroachment?” Philosophical Perspectives 19 (1): 417–43. https://doi.org/10.1111/j.1520-8583.2005.00068.x.\n\n\n———. 2011. “Defending Interest-Relative Invariantism.” Logos & Episteme 2 (4): 591–609. https://doi.org/10.5840/logos-episteme2011248.\n\n\n———. 2012a. “Games and the Reason-Knowledge Principle.” The Reasoner 6 (1): 6–8.\n\n\n———. 2012b. “Knowledge, Bets and Interests.” In Knowledge Ascriptions, edited by Jessica Brown and Mikkel Gerken, 75–103. Oxford: Oxford University Press.\n\n\nWeintraub, Ruth. 2008. “How Probable Is an Infinite Sequence of Heads? A Reply to Williamson.” Analysis 68 (3): 247–50. https://doi.org/10.1093/analys/68.3.247.\n\n\nWhite, Roger. 2005. “Epistemic Permissiveness.” Philosophical Perspectives 19: 445–59. https://doi.org/10.1111/j.1520-8583.2005.00069.x.\n\n\nWilliamson, Timothy. 1996. “Knowing and Asserting.” Philosophical Review 105 (4): 489–523. https://doi.org/10.2307/2998423.\n\n\n———. 2007a. “How Probable Is an Infinite Sequence of Heads?” Analysis 67 (295): 173–80. https://doi.org/10.1111/j.1467-8284.2007.00671.x.\n\n\n———. 2007b. The Philosophy of Philosophy. Blackwell.\n\n\n———. 2013. “Gettier Cases in Epistemic Logic.” Inquiry 56 (1): 1–14. https://doi.org/10.1080/0020174X.2013.775010.\n\n\nYalcin, Seth. 2011. “Nonfactualism about Epistemic Modality.” In Epistemic Modality, edited by Andy Egan and Brian Weatherson, 295–332. Oxford: Oxford University Press."
  },
  {
    "objectID": "posts/modesty/index.html",
    "href": "posts/modesty/index.html",
    "title": "For Bayesians, Rational Modesty Requires Imprecision",
    "section": "",
    "text": "Gordon Belot (2013) has recently developed a novel argument against Bayesianism. He shows that there is an interesting class of problems that, intuitively, no rational belief forming method is likely to get right. But a Bayesian agent’s credence, before the problem starts, that she will get the problem right has to be 1. This is an implausible kind of immodesty on the part of Bayesians.1 My aim is to show that while this is a good argument against traditional, precise Bayesians, the argument doesn’t neatly extend to imprecise Bayesians. As such, Belot’s argument is a reason to prefer imprecise Bayesianism to precise Bayesianism.\n1 There is another sense of immodesty that is often discussed in the literature, going back to Lewis (1971). This is the idea that some agents think their attitudes are optimal by some standards; these are the immodest ones. And often, it is held that not being self-endorsing in this way is a coherence failure Elga (2010). I don’t think this kind of immodesty is rationally required, for reasons set out by Miriam Schoenfield (2015) and Maria Lasonen-Aarnio (2015), but in any case that’s not the kind of modesty that’s at issue in Belot’s argument.\nPublished in Ergo 2: 20.\n\nFor present purposes, the precise Bayesian agent has just two defining characteristics. First, their credences in all propositions are given by a particular countably additive probability function. Second, those credences are updated by conditionalisation as new information comes in. These commitments are quite strong in some respects. They say that there is a single probability function that supplies the agent’s credences no matter which question is being investigated, and no matter how little evidence the agent has before the investigation is started. The everyday statistician, even one who is sympathetic to Bayesian approaches, may feel no need to sign up for anything this strong. But many philosophers seem to be interested in varieties of Bayesianism that are just this strong. For instance, there has been extensive discussion in recent epistemology of whether various epistemological approaches, such as dogmatism, can be modeled within the Bayesian framework, with the background assumption being that it counts against those approaches if they cannot.2 In these debates, the issue is not whether the Bayesian approach works in the context of a well-defined question and a substantial evidential background, but whether it does so for all questions in all contexts. Indeed, the assumption is that it does, and epistemological theories inconsistent with it are false. So the precise Bayesian is a figure of some interest, at least in epistemology.\n2 For dogmatism, see Pryor (2000). The canonical argument that it is inconsistent with Bayesianism is White (2006).3 Note that this formulation leaves it open which side of the biconditional is explanatorily prior. I’m going to defend a view on which the left hand side, i.e., the comparative confidences, are more explanatorily basic than the facts about what is in the agent’s representor. I say a little more about why I take this stand in footnote 7. For much more detail on varieties of imprecise Bayesianism, see Walley (1991), from whom I take the view that the representor and its members are much less explanatorily important than the comparative judgments the agent makes.The imprecise Bayesian doesn’t have a single probability function for their credences. Rather, they have a representor consisting of a set of probability functions. The agent is more confident in \\(p\\) than \\(q\\) just in case \\(\\Pr(p) &gt; \\Pr(q)\\) for every \\(\\Pr\\) in this representor.3 Just like the precise Bayesian, the imprecise Bayesian updates by conditionalisation; their new representor after an update is the result of conditionalising every member of the old representor with the new information. The added flexibility in imprecise Bayesianism will allow us to develop a suitably modest response to Belot’s puzzle.\n\n0.1 The Puzzle\nThe set up Belot uses is this. An agent, A, will receive a data stream of 0s and 1s. The data stream will go on indefinitely. I will use \\(\\boldsymbol{x}\\) for the (infinite) sequence of data she would (eventually) get, \\(x_k\\) for the \\(k\\)th element of this sequence, and \\(\\boldsymbol{x}_k\\) for the sequence consisting of the first \\(k\\) elements of the stream. These variables are, as usual, rigid designators. I’ll also use the capitalised \\(\\boldsymbol{X}\\) and \\(\\boldsymbol{X}_k\\) as random variables for the sequence itself, and for the first \\(k\\) elements of the sequence, respectively. So \\(\\boldsymbol{X}= \\boldsymbol{x}\\) is the substantive and true claim that the sequence that will be received is actually \\(\\boldsymbol{x}\\). And \\(\\boldsymbol{X}_k = \\boldsymbol{x}_k\\) is the substantive and true claim that the first \\(k\\) elements of that sequence are \\(\\boldsymbol{x}_k\\). Propositions of this form will play a major role below, since they summarise the evidence the agent has after \\(k\\) elements have been revealed. I’ll use \\(+\\) as a sequence concatenation operator, so \\(\\boldsymbol{y}+ \\boldsymbol{z}\\) is the sequence consisting of all of \\(\\boldsymbol{y}\\), followed by all of \\(\\boldsymbol{z}\\).\nBelot is interested in a quite general puzzle, but I’ll focus for most of the paper on a very specific instance of the puzzle. (We’ll return to the more general puzzle in the last section.) We’re going to look at the agent’s evolving credence that \\(\\boldsymbol{X}\\) is periodic. Let \\(p\\) be the proposition that \\(\\boldsymbol{X}\\) is periodic, since we’ll be returning to that proposition a lot. And let’s start by assuming the agent is a precise Bayesian, to see the challenge Belot develops.\nSay that the agent succeeds just in case her credence in \\(p\\) eventually gets on the correct side of \\(\\frac{1}{2}\\), and stays there. (The correct side is obviously the high side if \\(p\\) is true, and the low side otherwise.) That is, if \\(v\\) is the truth value function, it succeeds just in case this is true.4 \\[\\exists n \\forall m \\geq n: |v(p) - \\textit{Cr}(p | \\boldsymbol{X}_m = \\boldsymbol{x}_m)| &lt; \\frac{1}{2}\\] The agent fails otherwise. Given the assumption that the agent is a classical Bayesian, we can step back from evaluating the agent and evaluate her prior probability function directly. So a prior \\(\\Pr\\) succeeds relative to \\(\\boldsymbol{x}\\) just in case this is true. \\[\\exists n \\forall m \\geq n: |v(p) - \\Pr(p | \\boldsymbol{X}_m = \\boldsymbol{x}_m)| &lt; \\frac{1}{2}\\] This is reasonably intuitive; the agent is going to get a lot of data about \\(\\boldsymbol{X}\\), and it is interesting to ask whether that data eventually lets her credence in \\(p\\) get to the right side of \\(\\frac{1}{2}\\).\n4 Belot lets an agent succeed if \\(\\boldsymbol{X}\\) is periodic, and the credence in \\(p\\) never drops below \\(\\frac{1}{2}\\), but I think it’s neater to say that the agent is undecided in this case.Given these notions of success and failure, we can naturally define the success set of a prior (or agent) as the set of sequences it succeeds on, and the failure set as the set of sequences it fails on.\nAbusing notation a little, say that \\(\\boldsymbol{x}_i \\supset \\boldsymbol{x}_k\\) iff \\(\\boldsymbol{x}_i\\) is a sequence that has \\(\\boldsymbol{x}_k\\) as its first \\(k\\) entries. Then we can state the first of Belot’s conditions on a good Bayesian agent/prior. A prior is open-minded just in case this condition holds: \\[\\forall \\boldsymbol{x}_k \\exists \\boldsymbol{x}_i \\supset \\boldsymbol{x}_k, \\boldsymbol{x}_j \\supset \\boldsymbol{x}_k: \\Pr(p | \\boldsymbol{X}_i = \\boldsymbol{x}_i) &lt; \\frac{1}{2} \\wedge \\Pr(p | \\boldsymbol{X}_j = \\boldsymbol{x}_j) &gt; \\frac{1}{2}\\] That is, no matter what happens, it is possible that the probability of \\(p\\) will fall below , and possible it will rise above . To motivate the first, consider any situation where the sequence to date has looked periodic. (If it had not looked periodic to date, presumably the probability of \\(p\\) should already be low.) Now extend that sequence with a large of random noise. At the end of this, it should no longer be probable that the sequence is periodic. On the other hand, assume the sequence has not looked periodic to date. Extend it by repeating \\(\\boldsymbol{x}_k\\) more than \\(k\\) times. At the end of this, it should look probable that the sequence is periodic (at least for large enough \\(k\\)). So open-mindedness looks like a good condition to impose.\nThe second condition we might impose, though not one Belot names, is modesty. Any function might fail. One natural way it might fail is that it might get, to use a term Belot does use, flummoxed. It could change its mind infinitely often about whether the sequence is periodic. By definition, open-mindedness entails the possibility of being flummoxed. Given the definitions of success and failure, \\(\\Pr\\) will fail relative to any \\(\\boldsymbol{x}\\) that flummoxes it. So success is not a priori guaranteed. Now for any function we can work out the set of sequences relative to which it fails. It turns out this will be a rather large set. Indeed, the set of sequences on which any open-minded function succeeds is meagre.5 Say a function is modest if the initial probability it gives to \\(\\boldsymbol{X}\\) being in its success set is less than 1. Given how large the failure set is, modesty also seems like a good requirement.6\n5 A meagre subset of a space is any set built up as a countable union of nowhere dense sets.6 Belot goes into much more detail about why modesty is a good requirement to put on a rational prior, but I’m omitting those details since I have very little to add to what Belot says.The argument for modesty is not that it is an immediate consequence of regularity. It does follow from regularity, but in the case we’re considering, regularity is quite implausible. Some sets, even some quite large sets in some sense, will have to be given probability 0. The surprising thing is that a residual set (i.e., the complement of a meagre set) gets probability 0.\nIt might be thought that modesty here is problematic for the same reason that epistemic modesty is often problematic: it validates Moore-paradoxical thoughts. It’s bad to say p, but there is a probability that not p. It’s even bad, though as Briggs (2009) points out, not quite bad for the same reasons, to say Whether I believe p is true or false tomorrow, there will be a probability I’m false. Perhaps modesty is a requirement that someone say something like that, and hence is an improper requirement.\nBut in fact the requirement of modesty is disanalogous to the ‘requirement’, suggested in the previous paragraph, that agents endorse Moore-paradoxical principles. There isn’t anything wrong with saying Whichever side of one half my credence in p is tomorrow, there is a probability that the truth will be the other side of one half. That’s not Moore-paradoxical. Indeed, unless one is sure that one’s credence in \\(p\\) tomorrow will be 0 or 1, it is something one should endorse.\nOr consider a different example. There will be a sequence of 0s and 1s, but this time there will only be three elements, and the agent will only be shown the first of them tomorrow. Let \\(q\\) be the proposition that there are more 1s than 0s in the three-element sequence. Say the agent succeeds iff tomorrow, after seeing just one element, her credence in \\(q\\) is the same side of one-half as the truth. And say the agent is modest iff, right now, her credence that she succeeds tomorrow is less than one. There is nothing incoherent about being modest. If her credal distribution today is completely flat, giving \\(\\frac{1}{8}\\) credence to each of the eight possible sequences, she will be modest, for example.\nNow this case is somewhat different to the one Belot started with in a couple of respects. On the one hand, we’re asking about modesty at a particular point, i.e., tomorrow, rather than over a long sequence. On the other hand, we’re asking about whether the agent’s credences will be on the right side of one-half after having seen one-third of the data, rather than, as in the original case, after seeing measure zero of the sequence. The first difference makes it easier to be modest, the second difference makes it harder. So the cases are not perfect analogies, but they are similar enough in respect of modesty to make it plausible that if modesty is coherent in this case, as we’ve shown it is, then it should be coherent in Belot’s case as well.\nSo that’s the argument that open-mindedness and modesty are good conditions for priors to satisfy. Here’s the worrying result that Belot proves. There are no open-minded modest priors. If \\(A\\) is a classical Bayesian, she will either have to be closed minded or immodest. Neither seems rational, so it seems that being a classical Bayesian is incompatible with being rational. That is, we can’t be precise Bayesians if we accept the following two constraints.\n\nOpen-Mindedness: For any initial sequence, there is a continuation after which it seems probable that \\(\\boldsymbol{X}\\) is periodic, and a continuation after which it seems probable that \\(\\boldsymbol{X}\\) is not periodic.\nModesty: The initial probability that the agent will succeed, i.e., that their credence in \\(p\\) will eventually get to the right side of \\(\\frac{1}{2}\\) and stay there, is less than 1.\n\nSince both open-mindedness and modesty are very plausible constraints, it follows that there is no good way to be a precise Bayesian in the face of this puzzle.\n\n\n0.2 Making the Puzzle Less Precise\nWhat happens, though, if the agent is an imprecise Bayesian? Is there a parallel version of Belot’s argument that shows this kind of imprecise Bayesian is necessarily irrational? I’m going to argue that the answer is no.\nThe first thing we have to do is work out how to redefine the key terms in Belot’s argument once we drop the assumption that the agent is a classical Bayesian. There are several ways of formulating our definitions which are equivalent given that assumption, but not equivalent given that the agent is an imprecise Bayesian. There are three major choice points here.\n\nWhat is success?\nWhat is open-mindedness?\nWhat is modesty?\n\nAssume our agent’s credal state is represented by set \\(S\\) of probability functions. Then there are two natural ways to think about success. \\[\\begin{aligned}\n\\forall \\Pr \\in S:  \\exists n \\forall m \\geq n: |v(p) - \\Pr(p | \\boldsymbol{X}_m= \\boldsymbol{x}_m)| &lt; \\frac{1}{2} \\\\\n\\exists n \\forall \\Pr \\in S: \\forall m \\geq n: |v(p) - \\Pr(p | \\boldsymbol{X}_m= \\boldsymbol{x}_m)| &lt; \\frac{1}{2}\\end{aligned}\\] The second is obviously stronger than the first, since it involves moving an existential quantifier out in front of a universal quantifier. And there are some natural cases where an agent could succeed on the first definition, and fail on the second. Here’s one such case.\nLet \\(\\Pr_0\\) be the fair-coin measure. Acccording to the fair coin measure, if \\(\\boldsymbol{y}\\) is any \\(k\\) length sequence of 0s and 1s we have \\(\\Pr_0(\\boldsymbol{x}_k = \\boldsymbol{y}) = 2^{-k}\\). Intuitively, it thinks the 0s and 1s are generated by flips of a fair coin, and it won’t change its mind about that no matter what happens.\nSay a probability function \\(\\Pr\\) is regular periodic iff it satisfies these two conditions.\n\n\\(\\Pr(p) = 1\\).\nFor any periodic sequence \\(\\boldsymbol{y}\\), \\(\\Pr(\\boldsymbol{X}= \\boldsymbol{y}) &gt; 0\\).\n\nIntuitively, these functions are certain that \\(X\\) is periodic, and assign positive probability to each possible periodic sequence. Now consider the family of functions we get by taking equal weighted mixtures of \\(\\Pr_0\\) with each regular periodic function. Let that family represent the agent’s credence. And assume for now that \\(\\boldsymbol{X}\\) is the sequence \\(\\langle 0, 0, 0, \\dots \\rangle\\). Does the agent succeed?\nWell, each \\(\\Pr\\) in her representor succeeds. To prove this, it will be helpful to prove a lemma that we’ll again have use for below. For this lemma, let \\(\\Pr_0\\) be the fair-coin measure (as already noted), \\(\\Pr_1\\) be any measure such that \\(\\Pr_1(p) = 1\\), and \\(\\Pr_2\\) be the equal mixture of \\(\\Pr_0\\) and \\(\\Pr_1\\).\nLemma 1: \\(\\Pr_2(p | \\boldsymbol{X}_k = \\boldsymbol{y}_k) &gt; \\frac{1}{2}\\) iff \\(\\Pr_1(\\boldsymbol{X}_k = \\boldsymbol{y}_k) &gt; \\Pr_0(\\boldsymbol{X}_k = \\boldsymbol{y}_k).\\)\n\nProof. Proof. Let \\(\\Pr_i(\\boldsymbol{X}_k = \\boldsymbol{y}_k) = a_i\\) for \\(i \\in {0, 1}\\). Recall that \\(\\Pr_0(p) = 0\\) and \\(\\Pr_1(p) = 1\\). Then we can quickly get that \\(\\Pr_2(p | \\boldsymbol{X}_k = \\boldsymbol{y}_k) = \\frac{a_1}{a_0 + a_1}\\), from which the lemma immediately follows. ◻\n\nFor any \\(\\Pr\\) in the agent’s representor, there is some \\(k\\) such that \\(\\Pr(\\boldsymbol{X}= \\langle 0, 0, 0, \\dots \\rangle)\\) \\(&gt; 2^{-k}\\). So after at most \\(k\\) 0s have appeared, \\(\\Pr(p)\\) will be above \\(\\frac{1}{2}\\), and it isn’t coming back. That means it succeeds. And since \\(\\Pr\\) was arbitrary, it follows that all \\(\\Pr\\) succeed.\nBut the agent in a good sense doesn’t succeed. No matter how much data she gets, there will be \\(\\Pr\\) in her representor according to which \\(\\Pr(p) &lt; \\frac{1}{2}\\). After all, for any \\(k\\), there are regular periodic \\(\\Pr\\) such that the probability of \\(\\boldsymbol{x}_k\\) being \\(k\\) 0s is below \\(\\frac{1}{2^k}\\). So if we mix that function with \\(\\Pr_0\\), we get a function where the most probable continuations of this initial sequence are the random sequences provided by the fair coin measure.\nIn terms of our definitions of success above, the agent satisfies the first, but not the second. Every function in her representor eventually has the probability of \\(p\\) go above \\(\\frac{1}{2}\\). But at any time, there are functions in her representor according to which the probability of \\(p\\) is arbitrarily low.\nHere I think we have to make a distinction between different ways of understanding the formalism of imprecise probabilities. (What follows is indebted to Bradley (2014), especially his section 3.1, but I’m disagreeing somewhat with his conclusions, and following more closely the conclusions of Joyce (2010) and Schoenfield (2012).)\nOne way of thinking about imprecise credences is that each probability function in the representor is something like an advisor, and the agent who is imprecise simply hasn’t settled on which advisor to trust. Call this the pluralist interpretation of the formalism. On this interpretation, it is natural to think that what is true of every function is true of the agent.\nAnother way is to think of the agent’s mind as constituted by, but distinct from, the representors. An analogy to keep in mind here is the way that a parliament is constituted by, but distinct from, its members. Keeping with this analogy, call this the corporate interpretation of the formalism. Note that corporate bodies will typically have their own rules for how the views of the members will be translated into being views of the whole. Even if every member of the parliament believes that the national cricket team will win its upcoming game, it doesn’t follow that the parliament believes that; the parliament only believes what it resolves it has believed.\nNow I only want to defend the imprecise Bayesian model on the corporate interpretation.7 The pluralist interpretation, it seems to me, faces grave difficulties. For one thing, it has a hard time explaining what’s wrong with the existential claim “There is a precise number \\(x\\) such that \\(x\\) is the probability of \\(p\\)”. Every advisor believes that, so on the pluralist model the agent does too. (Compare the criticisms of “fanatical supervaluationism” in Lewis (1993).) More relevant to the discussion here, I am following Belot in thinking we have an argument that each precise Bayesian is unreasonably proud. On the pluralist interpretation, the agent is undecided which of these unreasonable advisors she will follow. But such a state is itself unreasonable; she should have decided not to follow any of them, since they are all provably unreasonable!\n7 I have an independent metaphysical reason for preferring the corporate interpretation. I think that comparative confidences, things like being at least as confident in \\(p\\) as in \\(q\\), are metaphysically prior to numerical credences, or even sets of numerical credences. On such a metaphysics, what it is for \\(\\Pr\\) to be in the representor just is for every \\(p, q, r, s\\), if the agent is at least as confident in \\(p\\) given \\(q\\) as in \\(r\\) given \\(s\\), then \\(\\Pr(p | q) \\geq \\Pr(r | s)\\). And it seems, though I won’t defend this claim here, that the corporate interpetation fits more naturally with the idea that comparative confidences are primitive.A surprising fact about corporate bodies is that they can be immune to problems that beset each of their members. It would be illegitimate for any one parliamentarian to have law-making power; it is (or at least can be) legitimate for them all to have such power. Indeed, it would be unreasonable for any of them to think that they individually should have law-making powers; that would be unreasonably proud. But it is not unreasonable for them to collectively think that they should collectively have law-making powers. If they are a well-constituted parliament, this is a perfectly reasonable thought. Similarly here, the agent, the corporate body, could avoid being unreasonably proud even though each of the representors is over-confident in its own powers.\nNow going back to success and modesty, it seems to me that the first definition of success is appropriate on the pluralist interpretation of the imprecise framework, and the second is appropriate on the corporate interpretation. The first interpretation says that the agent succeeds iff every member succeeds. And the second says that the agent succeeds iff the body of functions, collectively, succeed. Since I’m defending the use of the imprecise framework on the corporate interpretation, it is the second definition of success that is appropriate, and that’s what I will use here.\nThis understanding isn’t without costs. Bradley (2014) argues, in effect, that the best responses to dilation-based arguments against imprecise probabilities (as in White (2010)), are only available on the pluralist interpretation. I’m not going to try to solve those problems here, but I will note that the interpretative choice I’m making generates some extra philosophical work elsewhere. Against that, the corporate interpretation has some benefits. It lets us agree with Peter Walley (1991) that there are rational agents who are represented by sets of merely finitely additive probability functions, though no merely finitely additive probability function on its own could represent a rational agent. So the issues between the two interpretations are extensive. For now, I’ll simply note that I’m interested in defending the imprecise Bayesian from Belot’s argument on the corporate interpretation. And with that I’ll return to translating Belot’s puzzle into the imprecise framework, with the second, corporate-friendly, interpretation of success on board.\nThere are also two natural ways to generalise Belot’s notion of open-mindedness to the imprecise case. We could require that the agent satisfies either the first or second of these conditions. \\[\\begin{aligned}\n\\forall \\boldsymbol{x}_k \\exists \\boldsymbol{x}_i \\supset \\boldsymbol{x}_k, \\boldsymbol{x}_j \\supset \\boldsymbol{x}_k: \\neg(\\Pr(p | \\boldsymbol{X}_i = \\boldsymbol{x}_i) \\geq \\frac{1}{2}) \\wedge \\neg(\\Pr(p | \\boldsymbol{X}_j = \\boldsymbol{x}_j) &lt; \\frac{1}{2}) \\\\\n\\forall \\boldsymbol{x}_k \\exists \\boldsymbol{x}_i \\supset \\boldsymbol{x}_k, \\boldsymbol{x}_j \\supset \\boldsymbol{x}_k: \\Pr(p | \\boldsymbol{X}_i = \\boldsymbol{x}_i) &lt; \\frac{1}{2} \\wedge \\Pr(p | \\boldsymbol{X}_j = \\boldsymbol{x}_j) \\geq \\frac{1}{2}\\end{aligned}\\] The second is just the same symbols as in Belot’s, and it is what I’ll end up arguing is the right constraint to put on the imprecise Bayesian agent. And it is a considerably more demanding constraint than the first. But the first is perhaps the more natural understanding of open-mindedness. It says that no matter what the initial evidence is, the agent is not guaranteed to settle her credence in \\(p\\) on one side of \\(\\frac{1}{2}\\). That’s a way of being open-minded.\nBut if the agent satisfies that constraint, she may be open-minded, but she won’t necessarily be responsive to the evidence. Here’s how I’m using the terms ‘open-minded’ and ‘evidence-responsive’. In both clauses, the quantification is intended to be over a salient class of propositions. (The relevant class in the application we’re most interested in is just \\(\\{X\\) is periodic, \\(X\\) is not periodic\\(\\}\\).) And I’ll say an agent is ‘confident’ in a proposition iff her credence in it is above \\(\\frac{1}{2}\\).\n\nOpen-Minded\n\nAny time an agent is confidence in a proposition, there is some evidence she could get that would make her lose confidence in it.\n\nEvidence-Responsive\n\nFor any proposition, there is some evidence the agent could get that would make her confident in it.\n\n\nOnce we allow imprecise credences, these two notions can come apart. Consider the agent we described above, whose representor consists of equal mixtures of the fair-coin measure and regular periodic functions. They are open-minded; they can always lose confidence that \\(X\\) is periodic or not. But they aren’t evidence-responsive; no matter what the evidence, their credence that \\(X\\) is periodic will never rise above \\(\\frac{1}{2}\\). In fact, their credence that \\(X\\) is periodic will never rise above any positive number.\nThat suggests open-mindedness is too weak a constraint. If the evidence the agent gets is a string of several hundred 0s, she shouldn’t just lose any initial confidence in \\(\\neg p\\), she should become confident in \\(p\\). And arguably (though I could imagine a dissent here), if the initial sequence is a seemingly random sequence, the credence in \\(p\\) should drop well below \\(\\frac{1}{2}\\). (The imagined dissent here is from someone who thinks that the noisier the data, the more imprecise credences should get. That’s an interesting view, but perhaps orthogonal to the issues we’re debating here.)\nAnd when we look back at Belot’s motivations for open-mindedness, we see that they are really motivations for being evidence-responsive. One of the distinctive (and I would say problematic) features of precise Bayesianism is that it doesn’t really have a good way of representing a state of indecisiveness or open-mindedness. In the terms we’ve been using here, there’s no difference for the precise Bayesian between being evidence responsive and open minded. The imprecise Bayesian can distinguish these. And in Belot’s puzzle, we should require that the imprecise Bayesian agent is evidence responsive. So we should impose the second, stronger, condition.\nThe final condition to discuss is modesty. There are three natural candidates here. We could merely require that the agent’s prior probability that \\(\\boldsymbol{x}\\) is in her success set is not equal to 1. Or we could require that it be less than 1. Or, even more strongly, we could require that it be less than some number that is less than 1. If her credence that \\(\\boldsymbol{x}\\) is in her success set is imprecise over some interval \\([k, 1]\\), she satisfies the first condition, but not the second or third. If it is imprecise over some interval \\((k, 1)\\), or \\([k, 1)\\), she satisfies the first and second conditions, but not the third. In the interests of setting the imprecise Bayesian the hardest possible challenge, though, let’s say that modesty requires the third criteria. Her ex ante credence in success should not just be less than 1, it should be less than some number less than 1.\nThe aim of the next section is to describe a representor that satisfies open-mindedness and modesty with respect to the question of whether the sequence is periodic. The representor will not represent a state that it is rational for a person to be in; we’ll come back in the last section to the significance of this. My aim is just to show that for the imprecise Bayesian, unlike the precise Bayesian, open-mindedness and modesty are compatible. And the proof of this will be constructive; I’ll build a representor that is, while flawed in some other ways, open-minded and modest.\n\n\n0.3 Meeting the Challenge, Imprecisely\nRecall that \\(\\Pr_0\\) is the fair-coin measure, according to which, if \\(\\boldsymbol{y}\\) is any \\(k\\) length sequence of 0s and 1s we have \\(\\Pr_0(\\boldsymbol{X}_k = \\boldsymbol{y}) = 2^{-k}\\).\nSay a finite sequence \\(\\boldsymbol{y}_k\\) of length \\(k\\) is repeating iff for some \\(n &gt; 1\\), \\(\\boldsymbol{y}_k\\) consists of \\(n\\) repetitions of a sequence of length \\(k/n\\). For any non-repeating sequence \\(\\boldsymbol{y}_k\\) (of length \\(k\\)) let \\(\\boldsymbol{s}_{\\boldsymbol{y}_k}\\) be the sequence consisting of \\(\\boldsymbol{y}_k\\) repeated infinitely often. Let \\(\\Pr_1\\) be the function such that, \\[\\Pr{}_1(\\boldsymbol{X}= \\boldsymbol{s}_{\\boldsymbol{y}_k}) = \\frac{1}{2^{2k}-1}\\] Intuitively, we can think of \\(\\Pr_1\\) as follows. Consider a measure over representations of periodic sequences. Any periodic sequence can be represented just as a finite sequence, plus the instruction repeat infinitely often, so this is really just a measure over finite sequences. One natural such measure assigns measure \\(\\frac{1}{2^{2k}}\\) to each sequence of length \\(k\\). Of course, several of these representations will be representations of the same sequence. For instance, \\(\\langle 0, 1 \\rangle\\), \\(\\langle 0, 1, 0, 1 \\rangle\\) and \\(\\langle 0, 1, 0, 1, 0, 1 \\rangle\\) repeated infinitely produce the same sequence. Now the probability of a sequence, according to \\(\\Pr_1\\) is just the measure, so defined, of the class of representations of that measure. (It’s a little easier to confirm that the measures sum to 1 than that the probabilities do, which is why I’ve included this little explanation.)\nNow define \\(\\Pr_2\\) as the equal weight mixture of \\(\\Pr_0\\) and \\(\\Pr_1\\), i.e., \\(\\Pr_2(q) = (\\Pr_0(q) + \\Pr_1(q))/2\\). Since \\(\\Pr_0(p) = 0\\), and \\(\\Pr_1(p) = 1\\), \\(\\Pr_2(p) = \\frac{1}{2}\\). There will be several facts about \\(\\Pr_2\\) that are useful to have in place for future reference. (Recall I’m using \\(\\boldsymbol{X}\\) as a random variable for the sequence the agent will see, \\(\\boldsymbol{x}\\) as a rigid designator of that sequence, \\(\\boldsymbol{y}\\) and \\(\\boldsymbol{z}\\) are variables for arbitrary sequences, and the \\(k\\) subscript to restrict sequences to length \\(k\\).) The first of these was proven as Lemma 1.\n\nLemma 1.\n\n\\(\\Pr_2(p | \\boldsymbol{X}_k = \\boldsymbol{y}_k) &gt; \\frac{1}{2} \\text{ iff } \\Pr_1(\\boldsymbol{X}_k = \\boldsymbol{y}_k) &gt; \\Pr_0(\\boldsymbol{X}_k = \\boldsymbol{y}_k).\\)\n\n\nDefine a new predicate \\(N\\) of finite sequences \\(\\boldsymbol{y}_k\\), to hold just in case \\(\\boldsymbol{y}_k\\) could be the initial segment of an infinite sequence of period at most \\(\\frac{k}{2}\\). So \\(\\boldsymbol{y}_k\\) must consist of some sequence repeated twice, and anything else in \\(\\boldsymbol{y}_k\\) must be consistent with that sequence repeating again (and if necessary again, and again, …). Then we get,\n\nLemma 2.\n\nFor \\(k \\geq 2\\), \\(\\Pr_2(p | \\boldsymbol{X}_{2k} = \\boldsymbol{y}_{2k}) &gt; \\frac{1}{2}\\) iff \\(N\\boldsymbol{y}_{2k}\\).\n\n\n\nProof. Proof. By Lemma 1, this reduces to the question of the relationship \\(\\Pr_1(\\boldsymbol{X}_{2k} = \\boldsymbol{y}_{2k}) &gt; \\Pr_0(\\boldsymbol{X}_{2k} = \\boldsymbol{y}_{2k})\\). Moreover, we know that \\(\\Pr_0(\\boldsymbol{X}_{2k} = \\boldsymbol{y}_{2k}) = 2^{-2k}\\). So the question is whether \\(\\Pr_1(\\boldsymbol{X}_{2k} = \\boldsymbol{y}_{2k}) &gt; 2^{-2k}\\).\nIf \\(N\\boldsymbol{y}_{2k}\\), then it is consistent with \\(\\boldsymbol{X}_{2k} = \\boldsymbol{y}_{2k}\\) that \\(\\boldsymbol{x}\\) is a particular periodic sequence with period at most \\(k\\). Since the probability, according to \\(\\Pr_1\\) of any such sequence is greater than \\(2^{-2k}\\), the right-to-left direction follows.\nIf \\(\\neg N\\boldsymbol{y}_{2k}\\), then the possibilities that get positive probability according to \\(\\Pr_1\\) are at most among the following: \\(\\boldsymbol{X}\\) consists of the first \\(k + 1\\) digits of \\(\\boldsymbol{y}_{2k}\\) repeated endlessly; \\(\\boldsymbol{X}\\) consists of the first \\(k + 2\\) digits of \\(\\boldsymbol{y}_{2k}\\) repeated endlessly; …; \\(\\boldsymbol{x}\\) consists of the first \\(2k\\) digits of \\(\\boldsymbol{y}_{2k}\\) repeated endlessly; \\(\\boldsymbol{X}\\) is one of the two sequences of period \\(2k + 1\\) starting with \\(\\boldsymbol{y}_{2k}\\), or one of the four sequences of period \\(2k+2\\) starting with \\(\\boldsymbol{y}_{2k}\\) or …. So we get the following, starting with the probabilities of each of the possibilities listed in the previous sentence, \\[\\begin{aligned}\n\\Pr{}_1(\\boldsymbol{X}_{2k} = \\boldsymbol{y}_{2k})\n    &\\leq \\frac{1}{2^{2k+2}-1}\n    &+ &\\frac{1}{2^{2k+4}-1}\n    &+ \\dots\n    &+ &\\frac{1}{2^{4k}-1}\n    &+ &\\frac{2}{2^{4k+2}-1}\n    &+ \\dots \\\\\n%\n    &&lt; \\frac{1}{2^{2k+1}}\n    &+ &\\frac{1}{2^{2k+3}}\n    &+ \\dots\n    &+ &\\frac{1}{2^{4k-1}}\n    &+ &\\frac{1}{2^{4k}}\n    &+ \\dots \\\\\n%\n    &&lt; \\frac{1}{2^{2k}}\\end{aligned}\\] And from that the left-to-right direction follows. ◻\n\n\nLemma 3\n\n\\(\\Pr_2\\) is open-minded.\n\n\n\nProof. Proof. Since any initial sequence \\(\\boldsymbol{y}_k\\) that is not \\(N\\) can be easily extended into one that is \\(N\\) (by, e.g., repeating \\(\\boldsymbol{y}_k\\)), and one is that is \\(N\\) can be extended into one that is not (by, e.g., having the repeating sequence stop at the very next step), this follows immediately from Lemma 2. ◻\n\nDefine \\(f\\) to be a function from sequences of length \\(k \\geq 2\\) to sequences of length \\(k+1\\) such that \\[f(\\boldsymbol{y}_k) = \\boldsymbol{y}_k +\n    \\begin{cases}\n        \\langle 0 \\rangle &\\text{if } N\\boldsymbol{y}_k \\leftrightarrow \\Pr{}_1(x_{k+1} = 0 | \\boldsymbol{X}_k = \\boldsymbol{y}_k) \\leq \\frac{1}{2} \\\\\n        \\langle 1 \\rangle &\\text{otherwise}\n    \\end{cases}\\] In the normal way, define \\(f^n(\\boldsymbol{y}_k)\\) to be the result of applying \\(f\\) \\(n\\) times to \\(\\boldsymbol{y}_k\\). And define \\(f^\\infty(\\boldsymbol{y}_k)\\) to be the infinite sequence we get by doing this infintely often.\nIntuitively, the way \\(f\\) works is that if \\(\\boldsymbol{y}_k\\) is already somewhat sequential, then we include the less likely digit, and if it isn’t, then we include the more likely digit. (With ties resolved in favour of including 0 rather than 1.) If we define \\(p(\\boldsymbol{y}_k)\\) to be the smallest \\(n\\) such that \\(\\boldsymbol{y}_k\\) could be the initial segment of a periodic sequence of length \\(n\\), then we’ll get that \\(p(f(\\boldsymbol{y}_k)) &gt; p(\\boldsymbol{y}_k) \\leftrightarrow N\\boldsymbol{y}_k\\) in all cases, except for the case where \\(\\Pr{}_1(\\boldsymbol{x}_k = 0 | \\boldsymbol{X}_k = \\boldsymbol{y}_k) = \\frac{1}{2}\\). That is, if \\(N\\boldsymbol{y}_k\\), then extending \\(\\boldsymbol{y}_k\\) in this way will wipe out the possibility of that smallest sequence being extended indefinitely, while if \\(\\neg N\\boldsymbol{y}_k\\), then that possibility will still be on the table.\nFrom this, it follows that \\(f^{\\infty}(\\boldsymbol{y}_k)\\) will flummox \\(\\Pr_2\\), no matter which \\(\\boldsymbol{y}_k\\) we start with.\nWe need one last classification of finite sequences, and then we are done. Say that \\(O\\boldsymbol{y}_k\\) just in case some initial segment of \\(\\boldsymbol{y}_k\\) of length \\(r\\) could be the initial segment of an infinite period sequence of period less than \\(\\frac{r}{2}\\). This contrasts with \\(N\\) in two ways. First, it requires a sequence that repeats twice, and then starts a third repetition. Second, it does not require that the sequence be ‘live’; there might be subsequent parts of \\(\\boldsymbol{y}_k\\) that are not compatible with the sequence repeating. So the sequence \\(\\langle 0, 0, 1, 0, 0, 1\\rangle\\) satisfies \\(N\\) but not \\(O\\), while the sequence \\(\\langle 0, 1, 0, 1, 0, 0\\rangle\\) satisfies \\(O\\) but not \\(N\\).\nThere are a countable infinity of finite sequences \\(\\boldsymbol{y}_k\\) such that \\(\\neg O \\boldsymbol{y}_k\\). Produce some ordering of them, then define \\(\\Pr_i\\), for \\(i \\geq 3\\), to be the probability function such that \\(\\Pr_i(\\boldsymbol{X}= f^\\infty(\\boldsymbol{y}_k)) = 1\\), where \\(\\boldsymbol{y}_k\\) is the \\(i-2\\)’th sequence in this order.\nNow, consider the set \\(R\\) of all probability functions of the form: \\[\\Pr = \\sum_{i = 2}^\\infty a_i\\Pr{}_i\\] where each of the \\(\\Pr_i\\) are defined as above, each \\(a_i\\) is non-negative, \\(a_2\\) is , and the sum of the \\(a_i\\) from 3 to \\(\\infty\\) is also \\(\\frac{1}{2}\\). Intuitively, each function starts by halving the probability \\(\\Pr_2\\) gives to each initial (or completed) sequence, and distributing the remaining probability over the countable infinity of flummoxing sequences of the form \\(f^\\infty(\\boldsymbol{y}_k)\\), where \\(\\neg O\\boldsymbol{y}_k\\).\nI’ll now prove that \\(R\\) is open minded.\n\nLemma 4\n\nIf \\(\\neg O \\boldsymbol{y}_k\\), then \\(\\neg O f(\\boldsymbol{y}_k)\\).\n\n\n\nProof. Proof. Since \\(\\neg O \\boldsymbol{y}_k\\), the only way that \\(O f(\\boldsymbol{y}_k)\\) could be true is if \\(k = 2r +1\\), and \\(f(\\boldsymbol{y}_k)\\) consists of some sequence of length \\(r\\) repeated twice, plus the first digit repeated a third time. But that means that \\(N\\boldsymbol{y}_k\\). And if that’s the case, then the extra digit that is added by \\(f(\\boldsymbol{y}_k)\\) will not be the necessary digit to repeat this sequence. So it is impossible that \\(O f(\\boldsymbol{y}_k)\\). ◻\n\n\nLemma 5\n\nIf \\(\\neg O \\boldsymbol{y}_k\\), then \\(\\neg O f^\\infty(\\boldsymbol{y}_k)\\).\n\n\n\nProof. Proof. This follows trivially from Lemma 4. ◻\n\n\nTheorem 6\n\n\\(R\\) is open-minded.\n\n\n\nProof. Proof. Any initial sequence can be extended to a sequence satisfying \\(O\\). For example, the initial sequence can be repeated in full twice. An immediate consequence of Lemma 5 is that for all \\(i \\geq 3, O\\boldsymbol{y}_k \\rightarrow \\Pr_i(\\boldsymbol{X}_k = \\boldsymbol{y}_k) = 0\\). That means that if \\(O\\boldsymbol{y}_k\\), then for any \\(\\Pr \\in R,{ } \\Pr(p | \\boldsymbol{X}_k = \\boldsymbol{y}_k) = \\Pr_2(p | \\boldsymbol{X}_k = \\boldsymbol{y}_k)\\). And now the theorem is an immediate consequence of Lemma 3. ◻\n\nLet \\(F\\) be the set of all sequences \\(f^\\infty(\\boldsymbol{y}_k)\\), where \\(\\neg O \\boldsymbol{y}_k\\).\n\nLemma 7\n\nIf \\(\\boldsymbol{x}\\in F\\), then \\(R\\) fails.\n\n\n\nProof. Proof. Assume \\(\\boldsymbol{x}\\in F\\), so \\(\\boldsymbol{x}\\) is not periodic. Then proving the lemma requires showing that for any \\(i\\), there is a \\(j \\geq i\\) such that, according to \\(R\\), the probability of \\(p\\) given \\(\\boldsymbol{X}_j =\\boldsymbol{x}_j\\) is not less than \\(\\frac{1}{2}\\). And that requires showing that there is a \\(\\Pr \\in R\\) such that \\(\\Pr(p | \\boldsymbol{X}_j = \\boldsymbol{x}_j) \\geq \\frac{1}{2}\\). This is easy to do. Consider any sequence \\(\\boldsymbol{y}_i\\) of length \\(i\\) not identical to \\(\\boldsymbol{x}_i\\) such that \\(\\neg O \\boldsymbol{y}_i\\). Consider the probability function \\(\\Pr_k \\in R\\) such that \\(\\Pr_k(\\boldsymbol{X}= f^\\infty(\\boldsymbol{y}_i)) = \\frac{1}{2}\\). Once we conditionalise on \\(\\boldsymbol{X}_i = \\boldsymbol{x}_i\\), that function will behave just like \\(\\Pr_2\\). And since \\(\\boldsymbol{X}\\) flummoxes \\(\\Pr_2\\), that means there is a \\(\\boldsymbol{x}_j\\) such that \\(\\Pr(p | \\boldsymbol{X}_j = \\boldsymbol{x}_j) &gt; \\frac{1}{2}\\), and hence \\(\\Pr(p | \\boldsymbol{X}_j = \\boldsymbol{x}_j) \\geq \\frac{1}{2}\\). ◻\n\n\nLemma 8\n\nFor each \\(\\Pr \\in R, \\Pr(\\boldsymbol{x}\\in F) = \\frac{1}{2}.\\)\n\n\n\nProof. Proof. It helps to think of each of the \\(\\Pr \\in R\\) as mixtures of \\(\\Pr_0\\) and \\(\\Pr_1\\), plus a mixture of the \\(\\Pr_i\\) for \\(i \\geq 3\\). Now \\(\\Pr_0(\\boldsymbol{x}\\in F) = 0\\), since for any countable set, \\(\\Pr_0\\) says the probability that \\(\\boldsymbol{x}\\) is in that set is 0. And \\(\\Pr_1(\\boldsymbol{x}\\in F) = 0\\), since \\(\\Pr_1\\) says that the probability of \\(\\boldsymbol{x}\\) being periodic is 1, and none of the members of \\(F\\) are periodic. But for each \\(\\Pr_i\\) for \\(i \\geq 3\\), \\(\\Pr_i(\\boldsymbol{x}\\in F) = 1\\). Indeed, for each such function, there is a particular sequence in \\(F\\) such that the probability that \\(\\boldsymbol{x}\\) is that sequence is 1. So for each \\(\\Pr \\in R, \\Pr(\\boldsymbol{x}\\in F) = \\frac{1}{4} \\times 0 + \\frac{1}{4} \\times 0 + \\frac{1}{2} \\times 1 = \\frac{1}{2}\\). ◻\n\n\nTheorem 9\n\nAccording to \\(R\\), the probability of an agent whose representor is \\(R\\) failing is at least \\(\\frac{1}{2}\\).\n\n\n\nProof. Proof. Immediate from Lemma 7 and Lemma 8. ◻\n\nSo if an agent’s credences are represented by a non-singleton set of probability functions, not a single probability function, it is possible for them to be open-minded and modest. On the other hand, if an agent is represented by a single probability function, as the precise Bayesian desires, then it is impossible to be open-minded and modest. Since being open-minded and modest is desirable, this is a reason to prefer the imprecise Bayesian picture.\n\n\n0.4 Objections and Replies\nI’m going to reply to three objections, but since my replies overlap, I’ll group the objections together.\n\nObjection 1\n\nThe model here only gives you conditional modesty. Once the initial sequence is \\(O\\), the representor becomes the singleton of an open-minded probability function, and Belot showed that to be immodest. Ideally, the agent would have a prior that is in some way resiliently modest, whereas this prior is fragilely modest.\n\nObjection 2\n\nThis representor is open-minded and modest towards one particular problem, namely whether \\(\\boldsymbol{X}\\) is periodic. But Belot was interested in a wider range of problems, indeed in all problems of the form: does \\(\\boldsymbol{x}\\) fall into some set that is measurable, dense, and has a dense complement. Ideally, we’d have a prior which is widely open-minded and modest, in the sense that it had an open-minded and modest attitude towards many problems. But this prior is narrowly modest, in the sense that it is open-minded and modest about only one problem.\n\nObjection 3\n\nThe representor described here is clearly not a representation of a credal state of anyone rational. Look what it does if the data is a 1 followed by thousands of 0s, or is the first few thousand digits of the binary expansion of \\(\\pi\\), or has a frequency of 0s of 0.2 over all large sub-intervals. No one could adopt this prior, so it doesn’t show anything about the advantages of imprecise Bayesianism.\n\n\n\nProof. Reply. My responses are going to be (1) that we should want more resilient modesty, and though this is a hard technical challenge, it’s possible to see a way forward on it, (2) that we should want somewhat wider open-minded modesty, though how much wider is a hard question, and (3) that the third objection should simply be rejected. Let’s go through those in reverse order, since it’s the response to the third that explains part of what I’m doing in response to the other two.\nWhat we have in section three is a consistency proof. For the imprecise Bayesian, unlike the precise Bayesian, being open-minded is consistent with being modest. That’s good, since it shows that we can’t rule out a rational response to problems like Belot’s. It’s obviously true that the prior in question isn’t rational, but that’s not needed for a consistency proof.\nMoreover, we don’t just have a consistency proof, we have a constructive consistency proof - the prior is described in detail. It’s just not going to be possible to do a constructive proof that open-mindedness, modesty and full rationality are consistent. And that’s because to do that would essentially be to solve all of the problems of epistemology ever. Demonstrating a fully rational prior, even for the range of questions Belot considers, is too much to ask.\nIf there’s a reasonable looking argument that imprecise Bayesians are unlikely to be able to satisfy some set of plausible constraints, then the defender of imprecise Bayesianism is, I think, obliged to show how those constraints can be satisfied. But to ask for a demonstration of how all reasonable constraints can be satisfied at once, in the absence of a decent argument that they cannot be, would clearly be asking too much.\nSo I don’t care that the prior I described is irrational; it serves its purpose in proving consistency. Now what would be nice is to show that some slightly stronger constraints can be simultaneously satisfied. But we have to be sure that those constraints are in fact reasonable constraints. Here’s one constraint that I think isn’t reasonable: be open-minded towards any proposition of the form \\({\\boldsymbol{X}\\in S}\\), where \\(S\\) is a dense set of sequences. Let \\(S\\), for example, be the set consisting of all sequences of the form \\(\\boldsymbol{y}_k + \\boldsymbol{z}\\), where \\(\\boldsymbol{y}_k\\) ranges over all finite sequeneces, and \\(\\boldsymbol{z}\\) is a particular arbitrary sequence that lacks finite definition in our current language. That set is dense, and indeed measurable. But there’s no evidence that could make it reasonable to take \\(\\boldsymbol{X}\\in S\\) to be probable. So a prior that wasn’t open-minded towards \\(\\boldsymbol{X}\\in S\\) could still be perfectly reasonable.\nThat said, the prior I demonstrated is closed-minded towards several propositions that should be taken seriously. It will never have positive credence that \\(\\boldsymbol{X}\\) is eventually periodic without being periodic, or that \\(\\boldsymbol{X}\\) is generated by a chance process that gives each data point chance \\(c \\neq \\frac{1}{2}\\) of being 0. It would be good to have a prior whose open-minded modesty was wider. But before we do that technical work, I think there’s a need to figure out which propositions we should be open-minded about.\nI am more worried by the fragility of the modesty of this prior. There’s a reasonable sense in which the prior is open-minded only in virtue of the fact that it has parts which are immodest. At any point where the agent has credence above \\(\\frac{1}{2}\\) that \\(p\\), she has credence 1 that she will succeed.\nWe could try to complicate the prior a bit more to avoid that. Here’s a sketch of how it could go, with application to one particular initial sequence of data. Consider what happens to \\(R\\) if the initial input is \\(\\langle 0, 1, 0, 0, 1, 0, 0, 1\\rangle\\), hereafter \\(\\boldsymbol{y}\\). According to \\(\\Pr_0\\), that initial sequence has probability \\(\\frac{1}{256}\\). According to \\(\\Pr_1\\), it has probability \\(\\frac{1}{63} + \\frac{1}{4095} + \\frac{1}{65535} \\approx \\frac{1}{62}\\). So given that initial sequence, \\(\\Pr_2\\) says the probability of \\(p\\) is about \\(\\frac{4}{5}\\). And since the sequence is \\(O\\), it could be the start of the the sequence \\(\\langle 0, 1, 0\\rangle\\) repeated indefinitely, its probability according to \\(\\Pr_i\\) is 0, for \\(i \\geq 3\\). Now consider the set of all probability functions of the form \\(a\\Pr_{R} + b\\Pr_{New}\\), where \\(a + b = 1\\), \\(b \\in (0, \\frac{1}{256}), \\Pr_{R} \\in R\\) and \\(\\Pr_{New}\\) is the function which gives probability 1 to \\(\\boldsymbol{X}\\) being \\(O(\\boldsymbol{y})\\). That prior is open-minded, and even after conditionalising on \\(\\boldsymbol{y}\\) satisfies the intermediate of the three modesty conditions described on page - the probability of failure is less than one, though it isn’t less than some number less than one. And this trick could be generalised to satisfy more modesty conditions, and even (though it would take some time to prove this) be unconditionally modest.\nBut I’m not going to go through those steps here. That’s mostly because I think we already have shown enough to show that imprecise Bayesianism has an advantage over precise Bayesianism. The imprecise Bayesian can, and the precise Bayesian can’t, have an open-minded modest attitude. It would be good to press home that advantage and show that there are other things the imprecise Bayesian can do that the precise Bayesian can’t do, such as having a widely open-minded and resiliently modest prior. But even before such a demonstration takes place, the advantage has been established. ◻\n\n\n\n\n\n\n\nReferences\n\nBelot, Gordon. 2013. “Bayesian Orgulity.” Philosophy of Science 80 (4): 483–503. https://doi.org/10.1086/673249.\n\n\nBradley, Seamus. 2014. “Imprecise Probabilities.” In The Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta, Winter 2014. http://plato.stanford.edu/archives/win2014/entries/imprecise-probabilities/; Metaphysics Research Lab, Stanford University.\n\n\nBriggs, Rachael. 2009. “Distorted Reflection.” Philosophical Review 118 (1): 59–85. https://doi.org/10.1215/00318108-2008-029.\n\n\nElga, Adam. 2010. “How to Disagree about How to Disagree.” In Disagreement, edited by Ted Warfield and Richard Feldman, 175–87. Oxford: Oxford University Press.\n\n\nJoyce, James M. 2010. “A Defence of Imprecise Credences in Inference and Decision Making.” Philosophical Perspectives 24 (1): 281–323. https://doi.org/10.1111/j.1520-8583.2010.00194.x.\n\n\nLasonen-Aarnio, Maria. 2015. “New Rational Reflection and Internalism about Rationality.” Oxford Studies in Epistemology 5: 145–71. https://doi.org/10.1093/acprof:oso/9780198722762.003.0005.\n\n\nLewis, David. 1971. “Immodest Inductive Methods.” Philosophy of Science 38 (1): 54–63. https://doi.org/10.1086/288339.\n\n\n———. 1993. “Many, but Almost One.” In Ontology, Causality, and Mind: Essays on the Philosophy of D. M. Armstrong, edited by Keith Campbell, John Bacon, and Lloyd Reinhardt, 23–38. Cambridge: Cambridge University Press. https://doi.org/10.1017/CBO9780511625343.010.\n\n\nPryor, James. 2000. “The Sceptic and the Dogmatist.” Noûs 34 (4): 517–49. https://doi.org/10.1111/0029-4624.00277.\n\n\nSchoenfield, Miriam. 2012. “Chilling Out on Epistemic Rationality: A Defense of Imprecise Credences (and Other Imprecise Doxastic Attitudes).” Philosophical Studies 158 (2): 197–219. https://doi.org/10.1007/s11098-012-9886-7.\n\n\n———. 2015. “A Dilemma for Calibrationism.” Philosophy and Phenomenological Research 91 (2): 425–55. https://doi.org/10.1111/phpr.12125.\n\n\nWalley, Peter. 1991. Statisical Reasoning with Imprecise Probabilities. London: Chapman & Hall.\n\n\nWhite, Roger. 2006. “Problems for Dogmatism.” Philosophical Studies 131 (3): 525–57. https://doi.org/10.1007/s11098-004-7487-9.\n\n\n———. 2010. “Evidential Symmetry and Mushy Credence.” Oxford Studies in Epistemology 3: 161–89."
  },
  {
    "objectID": "posts/herman/index.html",
    "href": "posts/herman/index.html",
    "title": "Centrality and Marginalisation",
    "section": "",
    "text": "0.1 Welcome to the History of Late Analytic Philosophy\nIt’s a good time to be doing history of late analytic philosophy. There is flurry of new and exciting work on how philosophy got from the death pangs of positivism and ordinary language philosophy to where it is today. Some may see this as a much needed gap in the literature. Indeed, there are a couple of reasons for scepticism about there being such a field as history of late analytic philosophy, both of which are plausible but wrong.\n\nPhilosophical Studies 171: 517-533. Thanks to Herman Cappelen and Ishani Maitra for many discussions about the material in this paper.\n\nOne reason is that it is too recent. But it can’t be too recent for general historical study; there are courses in history departments on September 11, so it’s not like looking at philosophy from thirty to forty years ago is rushing in where historians fear to tread. And indeed, if logical positivism could be treated historically in the 1960s, and ordinary language philosophy could be treated historically at the turn of the century, it seems a reasonable time to look back at the important works of the 1970s that established the contemporary era in philosophy.\nAnother reason is that we all know it so well. We are still so engaged with the key works by Kripke, Lewis, Burge, Perry, Thomson and so on that we don’t need to also look at them the way we look at Descartes, Locke and Hume. But this, it turns out, is not true. Books by Daniel Nolan (2005) and Wolfgang Schwarz (2009) changed the way that some philosophers, even those who knew the Lewisian corpus fairly well, changed the way they read Lewis. There has also been a minor flurry of work on how important the Gödel/Schmidt case is to the argument of Naming and Necessity (Devitt 2011; Ichikawa, Maitra, and Weatherson 2012; Machery et al. 2012).\nBut that’s nothing compared to the bombshell that is Philosophy Without Intuitions. (Cappelen 2012; all page citations, unless otherwise noted, to this book.) Herman Cappelen shows, extremely convincingly to my eyes at least, that intuitions play a much smaller role in late analytic philosophy than many philosophers thought. Indeed, there is a lot of textual evidence both for the claim that intuitions don’t do much philosophical work, and for the claim that many people have said that they do. The first of these claims is all to the good, says Cappelen, since there isn’t a particularly good epistemological defence of the use of intuitions.\nThe evidence for Cappelen’s claims comes in two parts. The first part, which I won’t discuss much here, is an extended argument that words like ‘intuitively’, or ‘counterintuitive’, as they appear in philosophical discourse, don’t in general function to pick out, or even draw attention to, any distinctive kind of mental state we could call an ‘intuition’. The second part argues that when we look at the actual introduction of thought experiments into late analytic philosophy, we don’t see the appeal to intuitions that many philosophers seem to think go along with thought experiments. Rather, we see a whole host of interesting philosophical moves. Sometimes a thought experiment functions to highlight an explanandum. Sometimes it gives us a prima facie plausible thesis that we then argue for (or against) at great length. Sometimes it just raises a puzzle.\nOne upshot of this historical work, one that Cappelen I think does a good job highlighting, is that contemporary philosophy is much more interesting than its practitioners sometimes take it to be. Philosophy is a way of investigating hard questions about the world, often at great expense in terms of human capital, but with thankfully little in the way of other expenses. It isn’t a matter of tidying up conceptual space. Thinking of philosophy this way should, I think, help us see why so many different kinds of projects are philosophically important.\n\n\n0.2 Centrality and Its Discontents\nThe big goal of Cappelen’s book is to refute the view, which he dubs Centrality, that intuitions (of a certain kind) are central to analytic philosophy, and in particular that they are a primary source of evidence for analytic philosophers. The intuitions that he has in mind have these three characteristics. (The quotes are from pages 112-3, where these features are articulated.)\n\nF1: Phenomenology\n\n“An Intuitive Judgment has a distinctive phenomenology” .\n\nF2: Rock\n\n“An intuitive judgment has a special epistemic status …Intuitive judgments justify, but they need no justification”.\n\nF3: Conceptual\n\nA judgment is an intuition “only if it is justified solely by the subjects’ conceptual competence”.\n\n\nThere’s some more detail on F2, but we’ll get to that in section 6. And there’s a fourth characteristic of intuitions that I want to add.\n\nF4: Speed\n\nIntuitions are rapid reactions..1\n1 My own views about the importance of this, as well as much else in this paper, owe a lot to Jennifer Nagel (2007, 2013).\n\nI’m going to spend much of this paper defending a view that intuitions characterised by F2 and F4 do play a role, though perhaps not a central role, in philosophy. But I do think that intuitions characterised by F1 and F3 are just not important to philosophy. Indeed, I think it’s a very important fact that they are not that important.\nThe claim that intuitions have a distinctive phenomenology is mostly harmless but, it seems to me, false. I certainly don’t find anything in common when I introspect my judgments that, say, no set is a member of itself, or that losing a limb would seriously reduce my happiness, or that the only language I think in is English. It will fall out of the view I’m defending that the best intuitions have no phenomenology, but I don’t think that’s a particularly important fact about them.\nBut the claim that intuitions derive solely from conceptual competencies, plus the claim that these are the central source of evidence in philosophy, is both wrong and dangerous. If that conjunction were true, we’d expect most philosophical conclusions to be conceptual truths (whatever those are). I’m not going to take a stand on whether there are conceptual truths, but I think it is pretty obvious that conceptual truths won’t help much resolve the following debates. (Compare the list E1-E6 on pages 200-201, which I’m basically just extending.)\n\nDo bans on pornography involve trading off speech rights versus welfare considerations, or do they just involve evaluating the free speech interests of different groups?\nIs it permissible to eat whales?\nUnder what circumstances is it permissible to end a terminally ill patient’s life, or to withhold life-saving treatment?\nIs all context dependency in language traceable to the presence of bindable variables?\nDoes belief have a phenomenology?\nWhich animals (and which non-animals) have beliefs?\n\nIf philosophy uses largely conceptual evidence, these aren’t philosophical questions. More generally, if Centrality (in Cappelen’s sense) is true of philosophy, then feminist philosophy, legal philosophy, political philosophy, bioethics, philosophy of language and (most of) philosophy of mind are not part of philosophy. (This list is far from exhaustive; making philosophy Centrality-friendly would involve writing out huge swathes of the discipline.)\nModus tollens obviously beckons. But as Cappelen notes (213), one occasional reaction to this is to identify certain parts of philosophy as the ‘Core’ of the discipline, and say Centrality is true of those. If Centrality is true of the core of philosophy, then feminist philosophy etc., are not part of the core of the field. Maybe now some people would be disposed to use modus ponens not modus tollens.\nThat would be a large mistake. It would have shocked Plato, and Locke, and Hume, and practically every other major figure in the history of philosophy to learn that political philosophy wasn’t central to the field. I do think (contra some of what Cappelen says) that some philosophy involves a priori and conceptual investigation. Indeed, I even do some of it. But it’s not true that when I’m doing that I’m doing work that’s deeper, or more philosophical, or more central to philosophy than the work that, for example, Rae Langton or Susan Moller Okin or Tamar Szabó Gendler or Sarah-Jane Leslie do.\nThis reason alone suffices for me to hope that Cappelen’s book has a very wide readership. Centrality isn’t true, but it is I think widely believed to true of at least some parts of the field. (Cappelen quotes many people endorsing this view.) I suspect that on the basis of this mistake, the parts of philosophy about which Centrality is not obviously false (especially metaphysics and epistemology) have been seen as more central to the discipline than they really ought to be. That’s not a bad state of affairs for metaphysicians and epistemologists, but it’s not good for philosophy, and I hope that Cappelen’s book helps put a stop to it.\n\n\n0.3 Intuitions in Detective Work\nDespite my very broad sympathy with Cappelen’s project, I do think there’s a role for intuitions of some kind in philosophy. Just what this kind is, and what this role is, will take some spelling out to avoid Cappelen’s arguments. So that’s what I’ll do for the next few pages.\nThe intuitions I have in mind are characterised by F2 and F4; they are default justified, and they are fast. Here’s how I think these kinds of intuitions could matter philosophically.\nWhen humans are growing up, they develop a lot of cognitive skills. Some of these skills are grounded in specific bits of propositional knowledge. We learn to count in part by learning that 2 comes after 1, and 3 comes after 2, and so on. But not all of them are. We learn how to tell causation from correlation, at least in simple cases, by developing various heuristics, none of which come close to a full theory of causation. Indeed, none of these heuristics would even be true, if stated as universal generalisations. But this ability to pick out which of the many predecessors of an event is its cause is one we develop very early (Gopnik 2009, 33–44), and it is vital to navigating the world.\nI think we develop a lot of skills like that; skills which either go beyond our propositional knowledge, or at the very least are hard to articulate in terms of propositions. That we have these kinds of skills should hardly be news to philosophers; under the label ‘heuristics’ they have become quite familiar thanks to the work of, among others, Daniel Kahneman. They occasionally get a bad press, because one central way in which psychologists detect them is by seeing where they lead to errors that careful thought would correct. (For instance, our heuristics sometimes say that a conjunction is more probable than one of the conjuncts, and careful thinking would correct this.) But this should not blind us to the fact that these incredibly fast heuristics are often very reliable; reliable enough to be an independent check on our theorising.\nThe use of the term ‘intuition’ to pick out these heuristics isn’t particularly idiosyncratic; Kahneman (2011) himself moves back and forth freely between the two terms. He approvingly cites Herbert Simon’s remark that “intuition is nothing more and nothing less than recognition”, which I think is basically right. We intuit that \\(a\\) is \\(F\\) by recognising that it has the tell-tale signs of \\(F\\)hood. Of course we’re a million miles from conceptual or a priori reasoning here; as I said, I agree entirely with Cappelen that F3 is not a feature of any philosophically significant source of evidence. Here are a couple of cases, one real life and one fictional, that draw out far removed intuitive thinking can be from a priori or conceptual thinking. The first is from Kahneman’s description of a case reported by Gary Klein (1999); the second is from (Norwegian) crime novelist Jo Nesbø (2009). First Kahneman,\n\nA team of firefighters entered a house in which the kitchen was on fire. Soon after they started hosing down the kitchen, the commander heard himself shout “Let’s get out of here!” without realizing why. The floor collapsed almost immediately after the firefighters escaped. Only after the fact did the commander realize that the fire had been unusually quiet and that his ears had been unusually hot ... He had no idea what was wrong, but he knew something was wrong. (Kahneman 2011, 11)\n\nNow Nesbø. In the story, Harry is the hero, Harry Hole, and Beate is a talented forensic detective.\n\n‘Forget what you have or haven’t got,’ Harry said. ‘What was your first impression? Don’t think, speak.’\nBeate smiled. She knew Harry now. First, intuition, then the facts. Because intuition provides facts too; it’s all the information the crime scene gives you, but which the brain cannot articulate straight off. (Nesbø 2009, 126)\n\nThere’s at least a family resemblence between Harry Hole’s instruction here and Lewis’s instruction to his readers at the start of “Elusive Knowledge” (Lewis 1996).\n\nIf you are a contented fallibilist, I implore you to be honest, be naive, hear it afresh. ‘He knows, yet he has not eliminated all possibilities of error.’ Even if you’ve numbed your ears, doesn’t this overt, explicit fallibilism still sound wrong? (Lewis 1996, 550)\n\nReviewers of Nesbø’s books often describe his hero as ‘intuitive’. That’s a little misleading; Harry Hole thinks intuition has a key role to play in detective work, but the adjective suggests that he relies heavily on his own intuition. That’s not right; he’s just as often badgering his colleagues to give him their impressions of a crime scene, or an interview subject. In these scenes he reminds me of no one so much as a colleague constantly wanting to know what one thinks about some thought experiment or variation on a familiar case. (These are often the best kind of colleague - full of inspiring ideas!)\nSo I think a lot of philosophical progress is made by drawing on, and drawing out, these skills. But isn’t this just to say something uncontroversial and uninteresting, namely that philosophy relies on implicit knowledge? As Cappelen puts it,\n\nIt is not controversial that conversations have propositions in the common ground. Nor is it controversial that all arguments start with premises that are not argued for. (155)\n\nWell, there’s something a bit interesting here, namely that the ‘common ground’ and the ‘not argued for’ premises have much greater overlap in philosophy than in other fields. A book starting with observations about the Galápagos Islands starts with premises that are not argued for, but are asserted on the basis of observations. These premises surely weren’t in the common ground before the ‘conversation’ starts. I’ll say more about this in the next section.\nBecause first I want to fuss a little about just what ‘common ground’ is. We’ll start with an observation Cappelen makes about the Ginet/Goldman case of Henry and the fake barns (Goldman 1976). Many philosophers take it to be an interesting fact that in one scenario, Henry knows there’s a barn, while in another he does not. Cappelen says that these facts are “presented as being pre-theoretically in the common ground” (172). That seems false at first blush. Before reading Goldman’s paper, it’s not clear philosophers are in a position to form singular thoughts about Henry. That’s an uncharitable reading though. A more plausible claim is to say that we are pre-theoretically disposed to accept some long sentence that roughly says that an agent in such-and-such scenario knows there is a barn, while an agent in a slightly different scenario does not.\nWe might gloss that last claim as saying that we implicitly knew something about these scenarios. I’m not sure that’s right though. We do surely have lots of implicit knowledge. I know, and so do you, that the Sydney Opera House is south of the Royal Albert Hall, even if you’d never articulated that thought to yourself or another. But do our dispositions to respond to quite finely drawn, and often reasonably long, vignettes count as implicit beliefs, or should they count as things we were in a position to know, but only learned once a philosopher had done the work of drawing the vignette? I can see merit in both positions, and don’t see firm grounds for preferring one.\nLet’s introduce some terminology to avoid taking a stance on this question. Say that a subject has Socratic knowledge that \\(p\\) when the following two conditions are met:\n\nOnce the agent is asked to consider \\(p\\) in the right way, they will come to know \\(p\\).\nThe evidential basis for this knowledge that \\(p\\) is not the asking itself.\n\nThe first clause says that anyone who reacts to a Gettier case with “Oh, of course that’s justified true belief without knowledge” has Socratic knowledge that such a case is a counterexample to the JTB theory of knowledge. And they have this Socratic knowledge before the case is even raised. The second clause says that if the person reacts instead with “Oh, some philosophers use thought experiments that don’t make sense unless you know which cars come from which countries”, that won’t count as Socratic knowledge. They would be expressing some knowledge, to be sure, but the telling of the example would play an evidential role.\nIf you are very liberal about which dispositions count as implicit beliefs, and implicit knowledge, then Socratic knowledge will just be a special kind of implicit knowledge. But if you think considering examples can lead to learning new facts, not just drawing out dispositions, then you will think ‘Socratic’ is like ‘alleged’, a non-factive modifier. As I’ve defined it, once you hear Gettier cases once, that they are counterexamples to the JTB theory ceases to be Socratic knowledge, and becomes regular knowledge. Note also that we can make sense of some implicit states being more or less Socratic than others; some dispositions to assent require very careful work to trigger.\nWhy is the class of propositions that we Socratically know so rich and fertile? It’s because of the central role of heuristics in our cognitive lives. Our interactions with the world don’t just furnish us with a set of truths about the world. They also furnish us with skills that we can apply to generate more truths. I suspect that something like this observation is at the heart of the endorsement of F3, that intuitions reveal conceptual truths. When we intuit that \\(p\\), we don’t always merely recall a prior belief that \\(p\\), or infer \\(p\\) from what we antecedently explicitly knew. But nor do we observe that \\(p\\). So what is it? It must be something internal, but not memory or inference. Conceptual competence isn’t a bad first guess, but Cappelen shows that isn’t the right answer. I think the right answer has to do with cognitive skills, i.e., heuristics.\n\n\n0.4 Philosophy: A Negative Characterisation\nSo intuitions matter because they reveal Socratic knowledge, and Socratic knowledge, when made explicit, is a very good guide to the world. That implies that intuitions should not be confined to philosophy. And, indeed, they are not. If an economic theorist claimed the standard of living among English men was higher in 1915 than in 1935, it would be perfectly reasonable to reply that intuitively that cannot be right, because in 1915 a rather large number of English men were living on the Western Front in catastrophically poor conditions. What is distinctive of philosophy then?\nWe need to clarify this question before we can answer it. Philosophy is both a discipline with a history over many millennia, and an organisational unit inside modern universities. These two things overlap well, but not perfectly. Once we note that they are distinct, we can separate out the following three questions.\n\nWhat questions are philosophical questions?\nWhat questions are, within the academy, primarily addressed by researchers in philosophy departments?\nWhat questions should be, at least within the academy, primarily addressed by researchers in philosophy departments?\n\nThe three questions don’t overlap. When Milton Friedman (1953) writes about economic methodology, I think he’s addressing a philosophical question, but work like this is, and probably should be, carried out in economics departments. Questions about professional ethics are philosophical questions that I think should be researched in philosophy departments, but in the United States at least typically receive more attention in professional schools. Let’s focus on the third question; what should a philosophy department do?\nMy colleagues at Michigan and St Andrews work on an incredibly wide range of questions, from the interpretation of quantum physics through history of logic through moral psychology and so on. And I think philosophy departments should have this range of interests. But what do all these questions have in common?\nIt’s not anything to do with necessity or a priority. Those categories seriously cross cut philosophy, as Cappelen points out. Historical investigations into disputes about the parentage of various might-have-been-royals, or mathematical investigation into the nature of the primes are not philosophical, but have to do with necessity and a priority. Whether there’s a language of thought is contingent, a posteriori, and almost paradigmatically philosophical.\nIt’s not really anything to do with depth, at least on a natural understanding of that. Why pandas have thumbs, and humans have appendices, turn out to be reasonably deep questions, but they are for biologists, not philosophers. Under what circumstances is democracy compatible with a strong executive is, at least to me, an incredibly deep and important question, but it’s a question to be answered, primarily, in history and political science departments.2 On the other hand, whether we can tell a plausible supervaluationist story about belief reports is not particularly deep, but a perfectly good subject for a philosophical inquiry as in Weatherson (2003a).\n2 This is not to say that political philosophers couldn’t help with this question. There are lots of questions that should have as their research centre some other department, but to which philosophers can usefully help. Indeed, the examples from economic methodology and evolutionary explanation I just mentioned are two more such questions.Better, I think, is to say that philosophical questions are those where implicit or Socratic knowledge, including crucially intuitions, can plausibly play a large role in getting to an answer. Philosophy is a little recursive, so it includes investigations into its own investigations, including historical work and metaphilosophical work. (Two fields which, prior to Cappelen’s book, had surprisingly little interaction.) That’s not to say we’re always right that Socratic knowledge can answer the questions philosophy sets. Maybe some questions in mind and language are best answered with the aid of neurological or phonological work that requires powerful measuring devices. But the questions are ones where starting with the knowledge and skills we already have seems like a plausible starting point, or at least not entirely crazy. This makes philosophy distinct from, say, history. We use intuitions in history too, especially intuitions about what explains what. But we need more; intuition won’t help if you want to know how many troops Henry had at Agincourt.\nThis hypothesis explains, I think, one of the historically important facts about philosophy. Philosophy gives birth to disciplines. Physics, economics, psychology and cognitive science were all, at one time, part of philosophy. In some cases, the split was very recent. The economics tripos at Cambridge only split from philosophy in 1903 (Tribe 2002). The Australasian Journal of Philosophy was the Australasian Journal of Psychology and Philosophy until 1946. Why does philosophy give rise to disciplines like these?\nI think having a negative characterisation of philosophy helps explain it. Philosophy has a lot in common, methodologically, with physics, economics, psychology and so on. All those fields use intuitions and other forms of Socratic knowledge. But the other fields use other things too, especially observation. It’s when it becomes clear that armchair methods play too small a role in the research that the field leaves philosophy.\nOf course, philosophers care more about their questions than their methods, so when the need for non-armchair methods becomes pressing, some of the individual philosophers will go along, picking up more and more observational knowledge and experimental skills. Note how much more empirical research informs the recent work by (for example) Gilbert Harman, Kim Sterelny and Peter Carruthers, compared to their earlier work (Harman 1973; Kilkarni and Harman 2011; Devitt and Sterelny 1987; Sterelny 2012; Carruthers 1990, 2011). From the other direction, our armchairs come with more knowledge now than they used to, which is partially why engaging with Laura Ruetsche’s work in philosophy of science requires more empirical knowledge engaging with William Whewell’s (Ruetsche 2011; Whewell 1840). But still I think the general picture holds; a question is fit for philosophy iff it is plausible that the intuitive, armchair methods which are part of every academic’s toolkit can, on their own, generate serious progress on the question.\n\n\n0.5 Letting Go\nI’ve said that Lewis’s instruction at the start of “Elusive Knowledge” is to look to intuitions, not to theoretical beliefs. But that might involve reading more into Lewis than is really there. What he literally asks the reader is to not appeal to their preferred theory of knowledge. Is that the same as an appeal to intuitions?\nIt need not always be. Sometimes, asking people to let go of their prior theory involves asking them to engage in a complex cognitive task. In Meditation One, Descartes has us go through quite a lot of thoughts before we can be pre-theoretical in the way he wants us to be.\nBut I don’t think that’s what’s going on with Lewis. For one thing, he doesn’t guide us back to a pre-theoretic naı̈veté the way Descartes does. But more generally, I think getting snap judgments is a way of letting go of some prior theories.\nThe picture I have here, and it is nothing more than a picture, is that intuitions are judgments delivered by heuristics, heuristics are deployed by Fodorian modules, and Fodorian modules are informationally encapsulated (J. A. Fodor 1983; J. Fodor 2000). That is, when we rely on a heuristic, we don’t use all of the information at our disposal. The classic example of this is eyesight; we may know that there are no elephants on Market Street in St Andrews, but given the right visual stimuli, our eyes will still insist that there is an elephant right there. The background theory about the spatial distribution of elephants isn’t encoded into the visual module. More generally, to rely on a heuristic just is to make a judgment using a part of our mind that doesn’t believe some of the things that we do. And that’s good, because it is a kind of independent check on the beliefs we have.3\n3 Philosophers sometimes understate the importance of independent checks. We can know a scale is working, but if we want to check its reliability we don’t use it, we use something else. I suspect that a certain amount of theory-independence is part of the explanation of the value of intuitions.But isn’t the idea that snap judgments are essential to philosophy inconsistent with the fact that we work very hard on getting our examples just right, and (as Cappelen shows), argue at great length over what to say about various examples? I think it isn’t, because there are two respects in which our practice reveals a sensitivity to snap judgments, and a respect for their use as a check on theorising.\nLet me tell you a small secret. I haven’t heard anything that even sounds like a counterexample to the broadly Stalnakerian theory of indicative conditionals that I like for about a decade. That’s not because there aren’t any intuitive counterexamples. It’s just because my intuitions have been trained to accord with this kind of theory.4 So what do I do? Do I give up on the use of intuitions as a test of theory? No, I ask colleagues for their intuitions. Sometimes I ask them a lot of different questions, and sometimes I work rather hard on refining the question, or (when they sadly disagree with my theory) finding ways to undermine their intuitions. Given the number of similar questions I get from other colleagues, I don’t think my methodology here is distinctive. In short, we can work very hard before and after getting the snap judgments, while giving those judgments a role.\n4 Relatedly, I haven’t seen Liverpool get awarded an undeserved free kick for about that long.This might be more idiosyncratic, but I also do a bunch of things in papers to draw out snap judgments. The main idea is to distract the reader from the fact that they are about to be prompted for an intuition, one that may not accord with their preferred theory. So I’ll use deliberately absurd props (like Vinny the talking vulture), or start an example without flagging that it is an example. My favourite move along these lines is to set up an example in such a way that the example doesn’t make sense unless some theoretical claim I want to argue for is true. Then, after much discussion of the correct verdict on the case, I can announce that the very sensibility of the prior discussion is proof that, at least intuitively, the theory I’m pushing must be true.\nWe’re going to come back to this theme a bit later, because I think it’s rather important. The cases you can remember from papers are probably not the ones where intuition mattered. The big role for intuition in philosophy (and in many other disciplines) is in checking the small steps along the way. That’s why I join Cappelen in opposing the methodological rationalists; I don’t think intuitions are distinctive to philosophy, and these small steps don’t have much of a phenomenology. But that doesn’t mean they are unimportant.\n\n\n0.6 Strength and Fragility\nOne of the big trends in late 20th Century epistemology has been the separation of two senses of strength of evidence. This might mean\n\nHow strong a doxastic state is supported by the evidence.\nHow resilient the force of the evidence is in the face of counterevidence.\n\nOne thing that conservative epistemologies (e.g., Harman (1986)) and dogmatic epistemologies (e.g., Pryor (2000)) have in common is that sources which might be very strong in the first sense might be very weak in the second sense. In particular, there can be sources of evidence that ground knowledge, and hence be rather strong in tthe first sense, but easily overturned by conflicting evidence. I prefer to reserve the terms ‘strong’ and ‘weak’ for the first sense, and use the terms ‘resilient’ or ‘fragile’ for the presence or absence of the second property. In that language, the important insight of the conservatives and dogmatists is that evidence can be strong but fragile.\nThat’s roughly how I think of intuitions – they are strong but rather fragile. So they can be unjustified justifiers, which is how I read Cappelen’s feature F2 (i.e., Rock).5\n5 There’s an ambiguity in Cappelen’s text that I’m not sure I’m interpreting the right way. Let’s that someone intuits that in a particular case, \\(c\\) doesn’t cause \\(e\\). Call the content of that intuition, i.e., what is intuited, \\(p_d\\). And call the proposition that the person has this intuition, i.e., the event of the intuiting, \\(p_g\\). Plausibly both \\(p_d\\) and \\(p_g\\) could be evidence in the right cases, though most of the time the salient evidence will be \\(p_d\\). I think \\(p_d\\) can be an unjustified justifier in the sense that other beliefs, e.g., that a particular theory of causation is false, can be justified on the basis of \\(p_d\\), but no other beliefs the agent has justify \\(p_d\\). But you might want a stronger sense of ‘unjustified’, where it means not just not justified by anything else, but not justified at all. I think in these kinds of cases, \\(p_d\\) is justified, just not justified by anything else. And the justification is, as I’ll get to below, strong but fragile. If when Cappelen says that intuitions, according to Centrality, are unjustified justifiers he means that the belief that \\(p_d\\) is unjustified, then I’m not defending Centrality. I just mean that the agent need not have any other mental states which justify the belief \\(p_d\\), or indeed any access to anything that justifies \\(p_d\\). But for all that it might be that the belief that \\(p_d\\) is justified, and the grounds for the justification include what the agent learned about causation as a child, plus perhaps her competence in distinguishing causes from non-causes.Cappelen notes it is hard to tell whether something is being used as a starting point, or an unjustified justifier, so he gives three diagnostics for this. I mostly agree with one, and disagree with the other two. I agree that intuitions are non-inferential, and they aren’t based on any particular experience, which is his criteria F2.1. (Though they usually are based on experiences taken collectively.) But I would alter the following suggestion, which he gives as a second diagnostic.\n\nF2.2 Evidence Recalcitrance: Intuitions are evidence recalcitrant; i.e., holders of them are not disposed to give them up even when their best arguments for those intuitions are shown to fail. (Compare pg 112)\n\nI would rather offer something normative here. What’s true of intuitions is that they might provide a stronger ground for belief than the best evidence we can offer for them. Compare the case of Gettier. As Cappelen carefully notes (194n3), Gettier doesn’t appeal to a raw intuition. He gives an argument that his subjects don’t know. Unfortunately, it isn’t a compelling argument, since it takes as a premise that we can’t get knowledge from a false belief, and that isn’t quite right (Warfield 2005). But Gettier was, to some extent, justified in believing these subjects didn’t know to a greater degree than he was justified in believing this argument was sound. And that, I think, is not uncommon.\nThis is why I don’t think Cappelen’s ‘Rough Guide to Rock Detection’ (121), the third of the diagnostics, is perfectly reliable. He says that if evidence is given for \\(p\\) in a context, that’s evidence that \\(p\\) isn’t an unjustified justifier in that context. But sometimes we give arguments for judgments that we think could rest without them. Compare this little dialogue.\n\nA: Is ‘John happiness’ a well-formed sentence?\nB: No; it doesn’t have a verb.\n\nHere B gives a judgment, then offers a little argument for it. The argument has a strong premise, namely that all sentences have verbs. That’s debatable; ‘Lo, gavagai!’ may be a counterexample. But B’s judgment isn’t undermined by examples that undermine her argument. As in the Gettier case, we may give an argument that doesn’t capture the full normative force of the judgment.\nTo say that intuitions are unjustified justifiers is not to say they are particularly special. If some conservative or dogmatic epistemology is true, there will be other unjustified justifiers. And if not, then this story about intuitions will be pretty implausible.\nThis picture of intuitions as strong but fragile meshes well, I think, with the picture from section 5. There I said the important intuitions are the ones you barely notice or remember. That’s because the intuitions are fragile; if you remembered them enough to argue about them (or experimentally test them), the fragility conditions had probably been triggered, and the intuition probably wasn’t doing much argumentative work.6\n6 I’m simplifying a little here. My preferred position is that intuiteds provide strong but fragile evidence, while intuitings provide weak but resilient evidence. The reason this is relevant is related to footnote 7.But why not think that intuitions are so fragile that they have no use in any philosophical debate? This question deserves more space than I can give it, but here are three sketches of answers.\n\nIntuitions might be valuable checks on theory, and might be resilient enough to perform a valuable checking role.\nJust like heuristics have characteristic errors, it might be that careful reasoning has characteristic errors, and there are cases where our first impressions are more reliable. See Gladwell (2005) for a summary of some relevant evidence.\nSomewhat surprisingly, there may be cases when it is best to trust the less reliable source. The case for this is a bit detailed, and not original to me, so I’ll just include a brief footnote for those interested.7\n\n7 At one point in Ben Levinstein’s doctoral dissertation, he considers whether there’s a general rule for deciding which of two conflicting sources we can trust. There turns out to be very little in general one can say. In particular, trust the more reliable source turns out not in general to be good advice. If sources have characteristic errors, it might be that given what the two sources have said, it is better on this occasion to trust the less reliable source, because the verdicts the sources deliver provide evidence that we are seeing one of the characteristic errors of the more reliable source. It takes more space than I have here to fill in the details of this argument, and most of the details I’d include would be Levinstein’s not mine. But here’s the big conclusion. Assume that intuitions are often wrong, but rarely dramatically wrong. The reason for that is that heuristics are bad at getting things exactly right, and good at getting in the ballpark. And that careful reasoning is often right, but sometimes dramatically wrong. This is trickier to motivate, but I think true. Then when intuition dramatically diverges from theory, and we don’t have independent reason to think that intuition is mistaken about the kind of case that’s in question, we should trust the intuition more than the theory.\n\n0.7 Some Lewisian Case Studies\nI’ve described one kind of mental state that deserves the name ‘intuition’, and which could play a role in philosophical activity. But, as Cappelen presses, we have to work to convert that ‘could’ to a ‘does’. Do we really rely in intuitive, or heuristic-driven, judgments about cases in analytic philosophy?\nAs Cappelen shows, the answer is “A lot less than you may have guessed.” We argue a lot more than we intuit, especially about the famous cases.8 The bit of analytic philosophy I’m most familiar with is David Lewis’s corpus, and since that doesn’t play much of a role in Cappelen’s story, I’ll illustrate his point with some examples from it.\n8 There is interesting work to be done on the relative role of intuitions and arguments about principles, but I’m going to leave that for another day, and focus here on cases. The principles/cases distinction can be a bit slippery, but paradigm cases are easy to identify, and we’ll be working with fairly paradigmatic cases here.Going from memory, I would have guessed the clearest example of a case refuting a theory was the use of finkish dispositions to refute the conditional analysis of dispositions. But go to the opening pages of “Finkish Dispositions” (Lewis 1997a), and you find not an intuition about a case, but an argument that finks are possible. And even though that argument is followed up with more cases, Lewis rather explicitly argues for his conclusions about each one. See, for example, the glass loving sorcerer on page 147. Lewis doesn’t avert to an intuition that the loved glass is fragile, rather he “wield[s] an assumption that dispositions are an intrinsic matter.” (Lewis 1997a, 147)\nThe discussion of causation turns out to be a little more fertile. From (the longer version of) “Causation as Influence”, I count the following appeals to intuitions about cases.\n\nThe chancy bomb example which shows simple probabilistic analyses of indeterministic causation won’t work (Lewis 2004a, 79).\nThe Merlin and Morgana example which shows that trumping is possible, and matters for what is the cause (Lewis 2004a, 81).\nThe variant on Billy and Suzy that raises problems for quasi-dependence (Lewis 2004a, 83).\nThe crazed President example which shows that causation by double prevention is possible, and that causation is not an intrinsic relation (Lewis 2004a, 84).\nThe Frankfurt example which shows we can have causation without dependence (Lewis 2004a, 95).\n\nThere’s a strong sense, I think, in which none of the judgments in these cases are argued for. Indeed, they arise as problems for theories that are otherwise doing rather well. If there was an argument around, it would be for the negation of the intuited judgment. So I think there’s a role for intuition here.\nBut we should not imagine that this is normal for philosophers, or even for Lewis. Cases, it is true, play a large role in Lewis’s writing. But they are very rarely simple refutations of existing theories. We could perhaps distinguish four roles that cases play, or perhaps four types of philosophical cases.\n\nRefutation of theories, as in these causation cases.\nIllustrations that help explain what’s going on in an argument, as in the examples from “Finkish Dispositions”. For a more extensive version of this, see Lewis’s version of Puzzling Pierre (Lewis 1981).\nTools for showing that we must distinguish various concepts, such as the discussion of Ned Kelly’s proof that there’s no honest cop (Lewis 1988).\nSimplified versions of the real world, on which we can test various explanatory hypotheses, such as the footy and rugby people in “Naming the Colors” (Lewis 1997b).\n\nAnd that list is probably incomplete. The last is fairly fascinating as a case study actually.9 Some of you may have had the following experience when programming, or indeed doing anything that looks like working with code (such as writing in LaTeX). A bug arises. It helps to find a minimal example in which the bug arises, i.e., a smallest program that produces the same bug. This helps you spot what’s going on, and if you still need help, it helps your interlocutors focus on the central problem. It’s important that you haven’t changed the problem; the example must be of the same kind as what you started with. But the example could be much simpler than the case you’re most interested in. Some philosophy examples are, I suspect, like that. Their value lies in revealing that some striking feature of reality would persist even if the world were simpler. So, probably, the explanation of the feature lies in some respect the real messy world shares with the simple example world. (Compare Cappelen’s discussion of Perry’s messy shopper in section 8.1.)\n9 See Sugden (2000, 2009) for much more on this use of thought experiments.It is perhaps no coincidence that the easiest place to find examples of type 1 in Lewis’s work is in the papers on causation. Lewis thinks there is no such thing as causation (Lewis 2004a, 2004b). Whatever our theory of ‘causes’ should be, it shouldn’t match that verb with a binary property. Rather, the aim of philosophical work on causation is to give a reductive analysis of causal thought and talk. In such a project, judgments about how we use ‘causes’ are more likely to be central.\nIt’s also not coincidental that when an example is central to a paper, such as the ‘dishonest’ cop and Puzzled Pierre, they really don’t look like type 1. That’s one big and important lesson from Cappelen’s work. Philosophers do use examples to refute theories, but they are rarely the big famous examples. If an example is central to a philosophy paper, it typically plays one of the other three roles.\n\n\n0.8 Summary\nLet’s take stock. I’ve argued for the following theses:\n\nSocratic knowledge is important to philosophy.\nThe distinctive feature of philosophy is that it addresses questions that can, at least prima facie, be productively worked on while relying primarily on Socratic knowledge.\nIntuitions are manifestations of cognitive skills, and much Socratic knowledge is constituted by the possession of such cognitive skills.\nLike other forms of Socratic knowledge, intuitions are mostly a posteriori, and have roles outside philosophy as well as inside it.\nIntuitions are default justified; that is, they can be unjustified justifiers.\nThis default is very weak; intuitions can easily be overridden by other considerations.\nRelatedly, it is rare for any one intuition to be central to a philosophical work; philosophical intuitions mostly concern the little cases we see along the way to larger projects.\n\nI also hinted at, without developing, an argument for\n\nThe right intuition can stop even a plausible theory dead in its tracks; and we have (thanks to Ben Levinstein) a mathematical model for why this can be so even if intuitions are much less reliable than theories.\n\nI opened with a discussion of why it matters to philosophy’s self-conception that point 4 is correct. Since Cappelen also endorses 4, I probably don’t need to say more about that here. But I think there is more to say about 7.\nThe first thing I want to note is that 7 is of course consistent with Cappelen’s textual research on important work in late analytic philosophy. In just about any thought experiment that you can remember, the intuitions about it don’t carry much philosophical weight in the work in which it is introduced. The intuitions that matter are the little ones, the ones that go by so quickly that no one questions them and are largely forgotten by all but the cognoscenti in that field. Even these intuitions aren’t that common. There are less of them in Lewis than I would have guessed.\nStill, I disagree with Cappelen that philosophy is without these intuitions. And so I disagree that there’s no role for double checking, experimentally if need be, whether these intuitions are really intuitive. If a well run survey showed that most people disagree with Lewis’s judgment about, say, the chancy bombs example, I’d reconsider my views about probabilistic causation. But I’d be really surprised to see this.\nThe second thing to note is that while 7 is true, it’s not the case that intuitions about one case are never central to a philosophical project. There is one big counterexample: the Gettier literature. Like Cappelen (194n3), I think this literature is incredibly unrepresentative of philosophy. And I think that’s in part because it was methodologically flawed. I tried to make this point in an earlier paper (Weatherson 2003b), but I didn’t get it quite right. (What I should have said was more like what Elijah Chudnoff (2011) does say.) When we saw the Gettier example, this should have been an invitation to try and find out what feature of knowledge was driving the fact that the belief in the main examples didn’t amount to knowledge. Gettier suggested it was inference from a false premise, but that doesn’t quite work (Warfield 2005). You might think it is insensitivity, but that doesn’t quite work. At this point there should have been one of two paths taken - attempts to find some other explanation of the data, or a reconsideration of whether our initial judgment about the case was wrong. That’s what the picture of philosophy sketched here would have predicted, and (this is the point I was trying but failing to make in the earlier paper) that’s what reflection on our successes in other areas of philosophy would have recommended. But the first kind of project ended up intertwined with attempts to analyse knowledge, and stalled for decades. And the second project wasn’t seriously undertaken, with some honorable exceptions such as Sartwell (1992) and Hetherington (2001). Now eventually this didn’t matter, because we discovered that safety based explanations of the Gettier case would work, even if there is no safety based analysis of knowledge, and even if there is some work to be done in getting the safety condition just right (Williamson 1994, 2000; Sainsbury 1995; Lewis 1996; Weatherson 2004). So if we strengthened 7 into a universal claim it would be false – thirty years of epistemological struggle attest to this. But it was really when epistemology fell into line with practice in other fields of philosophy that it made progress on the Gettier case.\n\n\n\n\n\n\nReferences\n\nCarruthers, Peter. 1990. The Metaphysics of the Tractatus. Cambridge: Cambridge University Press.\n\n\n———. 2011. The Opacity of Mind: An Integrative Theory of Self-Knowledge. Oxford: Oxford University Press.\n\n\nChudnoff, Elijah. 2011. “What Should a Theory of Knowledge Do?” Dialectica 65 (4): 561–79. https://doi.org/10.1111/j.1746-8361.2011.01285.x.\n\n\nDevitt, Michael. 2011. “Experimental Semantics.” Philosophy and Phenomenological Research 82 (2): 418–35. https://doi.org/ppr201182222.\n\n\nDevitt, Michael, and Kim Sterelny. 1987. Language and Reality: An Introduction to the Philosophy of Language. Cambridge, MA.: MIT Press.\n\n\nFodor, Jerry. 2000. The Mind Doesn’t Work That Way. Cambridge, MA: MIT Press.\n\n\nFodor, Jerry A. 1983. The Modularity of Mind. Cambridge, MA: MIT Press.\n\n\nFriedman, Milton. 1953. “The Methodology of Positive Economics.” In Essays in Positive Economics, 3–43. Chicago: University of Chicago Press.\n\n\nGladwell, Malcolm. 2005. Blink: The Power of Thinking Without Thinking. New York: Little, Brown.\n\n\nGoldman, Alvin I. 1976. “Discrimination and Perceptual Knowledge.” The Journal of Philosophy 73 (20): 771–91. https://doi.org/10.2307/2025679.\n\n\nGopnik, Alison. 2009. The Philosophical Baby: What Children’s Minds Tell Us about Truth, Love, and the Meaning of Life. New York: Farrar, Straus; Giroux.\n\n\nHarman, Gilbert. 1973. Thought. Princeton: Princeton University Press.\n\n\n———. 1986. Change in View. Cambridge, MA: Bradford.\n\n\nHetherington, Stephen. 2001. Good Knowledge, Bad Knowledge: On Two Dogmas of Epistemology. Oxford: Oxford University Press.\n\n\nIchikawa, Jonathan, Ishani Maitra, and Brian Weatherson. 2012. “In Defence of a Kripkean Dogma.” Philosophy and Phenomenological Research 85 (1): 56–68. https://doi.org/10.1111/j.1933-1592.2010.00478.x.\n\n\nKahneman, Daniel. 2011. Thinking Fast and Slow. New York: Farrar, Straus; Giroux.\n\n\nKilkarni, Sanjeev, and Gilbert Harman. 2011. An Elementary Introduction to Statistical Learning Theory. Hoboken, NJ: Wiley.\n\n\nKlein, Gary A. 1999. Sources of Power. Cambridge, MA.: MIT Press.\n\n\nLewis, David. 1981. “What Puzzling Pierre Does Not Believe.” Australasian Journal of Philosophy 59 (3): 283–89. https://doi.org/10.1080/00048408112340241.\n\n\n———. 1988. “The Trap’s Dilemma.” Australasian Journal of Philosophy 66 (2): 220–23. https://doi.org/10.1080/00048408812343301.\n\n\n———. 1996. “Elusive Knowledge.” Australasian Journal of Philosophy 74 (4): 549–67. https://doi.org/10.1080/00048409612347521.\n\n\n———. 1997a. “Finkish Dispositions.” The Philosophical Quarterly 47 (187): 143–58. https://doi.org/10.1111/1467-9213.00052.\n\n\n———. 1997b. “Naming the Colours.” Australasian Journal of Philosophy 75 (3): 325–42. https://doi.org/10.1080/00048409712347931.\n\n\n———. 2004a. “Causation as Influence.” In Causation and Counterfactuals, edited by John Collins, Ned Hall, and L. A. Paul, 75–106. Cambridge: MIT Press.\n\n\n———. 2004b. “Void and Object.” In Causation and Counterfactuals, edited by John Collins, Ned Hall, and L. A. Paul, 277–90. Cambridge: MIT Press.\n\n\nMachery, Eduoard, Ron Mallon, Shaun Nichols, and Stephen Stich. 2012. “If Folk Intuitions Vary, Then What?” Philosophy and Phenomenological Research 86 (3): 618–35. https://doi.org/10.1111/j.1933-1592.2011.00555.x.\n\n\nNagel, Jennifer. 2007. “Epistemic Intuitions.” Philosophy Compass 2 (6): 792–819. https://doi.org/10.1111/j.1747-9991.2007.00104.x.\n\n\n———. 2013. “Defending the Evidential Value of Epistemic Intuitions: A Reply to Stich.” Philosophy and Phenomenological Research 86 (1): 179–99. https://doi.org/10.1111/phpr.12008.\n\n\nNesbø, Jo. 2009. The Redeemer. London: Vintage Books.\n\n\nNolan, Daniel. 2005. David Lewis. Chesham: Acumen Publishing.\n\n\nPryor, James. 2000. “The Sceptic and the Dogmatist.” Noûs 34 (4): 517–49. https://doi.org/10.1111/0029-4624.00277.\n\n\nRuetsche, Laura. 2011. Interpreting Quantum Theories. Oxford: Oxford University Press.\n\n\nSainsbury, Mark. 1995. “Vagueness, Ignorance and Margin for Error.” British Journal for the Philosophy of Science 46: 589–601. https://doi.org/10.1093/bjps/46.4.589.\n\n\nSartwell, Crispin. 1992. “Why Knowledge Is Merely True Belief.” Journal of Philosophy 89 (4): 167–80. https://doi.org/10.2307/2026639.\n\n\nSchwarz, Wolfgang. 2009. David Lewis: Metaphysik Und Analyse. Paderborn: Mentis-Verlag.\n\n\nSterelny, Kim. 2012. The Evolved Apprentice: How Evolution Made Humans Unique. Cambridge, MA.: Bradford.\n\n\nSugden, Robert. 2000. “Credible Worlds: The Status of Theoretical Models in Economics.” Journal of Economic Methodology 7 (1): 1–31. https://doi.org/10.1080/135017800362220.\n\n\n———. 2009. “Credible Worlds, Capacities and Mechanisms.” Erkenntnis 70 (1): 3–27. https://doi.org/10.1007/s10670-008-9134-x.\n\n\nTribe, Kevin. 2002. “The Cambridge Economics Tripos 1903–55 and the Training of Economists.” The Manchester School 68 (2): 222–48. https://doi.org/10.1111/1467-9957.00191.\n\n\nWarfield, Ted A. 2005. “Knowledge from Falsehood.” Philosophical Perspectives 19: 405–16. https://doi.org/10.1111/j.1520-8583.2005.00067.x.\n\n\nWeatherson, Brian. 2003a. “Many Many Problems.” The Philosophical Quarterly 53 (213): 481–501. https://doi.org/10.1111/1467-9213.00327.\n\n\n———. 2003b. “What Good Are Counterexamples?” Philosophical Studies 115 (1): 1–31. https://doi.org/10.1023/A:1024961917413.\n\n\n———. 2004. “Luminous Margins.” Australasian Journal of Philosophy 82 (3): 373–83. https://doi.org/10.1080/713659874.\n\n\nWhewell, William. 1840. The Philosophy of the Inductive Sciences, Founded Upon Their History. London: John W. Parker.\n\n\nWilliamson, Timothy. 1994. Vagueness. Routledge.\n\n\n———. 2000. Knowledge and its Limits. Oxford University Press."
  },
  {
    "objectID": "posts/iri/index.html",
    "href": "posts/iri/index.html",
    "title": "Interest-Relative Invariantism",
    "section": "",
    "text": "0.1 Introduction\nOne of the initial motivations for epistemological contextualism was that the appropriateness of self-ascriptions of knowledge seemed to depend, in some circumstances, on factors that were traditionally thought to be epistemologically irrelevant. So whether our hero S was prepared to say “I know that p” would depend not just on how strong S’s evidence for p was, or how strongly they believed it, but on factors such as how much it mattered whether p was true, or what alternatives to p were salient in their thought or talk.\n\nPublished in Routledge Handbook of Epistemic Contextualism, edited by Jonathan Jenkins Ichikawa, 2017, 240-253.\n\nIt was immediately noted that this data point, even if accepted, is consistent with a number of theories of the truth of knoweldge ascriptions. It might be that things like stakes and salient alternatives affect the assertability conditions of knowledge ascriptions, but not their truth conditions  (Rysiew 2017). But let’s assume that we’ve convinced ourselves that this isn’t right, and that whether S can truly (and not just appropriately) say “I know that p” depends on things like the stakes or salient alternatives.\nIt still doesn’t follow that contextualism is true. It might be that in all contexts, whether an utterance of “S knows that p” is true depends on the stakes for S, or on the salient alternatives for S. That would be true, the idea is, whether S is talking about herself, or someone else is talking about her. The stakes, or salient alternatives, would affect the truth conditions of S’s utterance not because she is the one doing the talking, but the one being talked about. The practical and theoretical situation of the ascribee of the knowledge ascription may be relevant, even if the practical and theoretical situation of the ascribor need not be.\nThis line of thought leads to the idea that knowledge itself is interest-relative. Whether an utterance here and now of “S knows that p” is true, i.e., whether S knows that p, depends on how much it matters to S that p is true, or on which alternative are salient to S. The thesis that knowledge is interest-relative is consistent with contextualism. It could be that whether a knowledge ascription is true depends on the interests of both the ascriber, and the ascribee. In this entry, however, I’m going to largely focus on the view that knowledge is interest-relative, but contextualism is false. On this view, the interests of the ascribee do matter to the truth of a knowledge ascription, but the interests of the ascribee do not.\nThis view is naturally called interest-relative invariantism, since it makes knowledge interest-relative, but it is a form of anti-contextualism, i.e., invariantism. The view is sometimes called subject-sensitive invariantism, since it makes knowledge relevant to the stakes and salient alternatives to the subject. But this is a bad name; of course whether a knowledge ascription is true is sensitive to who the subject of the ascription is. I know what I had for breakfast and you (probably) don’t. What is distinctive is which features of the subject’s situation that interest-relative invariantism says are relevant, and the name interest-relative invariantism makes it clear that it is the subject’s interests. There is one potential downside to this name; it suggests that the practical interests of the subject are relevant to what they know. I intend to use the predicate ‘interest-relative’ to pick out a class of theories, including the theory floated by John Hawthorne (2004), where the options that are salient to the subject matter to what the subject knows. If forced to defend the name, I’d argue that salience is relevant to the theoretical interests of the subject, if not necessarily to their practical interests. But the name is still potentially misleading; my main reason for using it is that ‘subject-sensitive’ is even more misleading. (I’ll shorten ‘interest-relative invariantism’ to IRI in what follows. I’ll return to the question of practical and theoretical interests in section 4.)\nThere are a number of ways to motivate and precisify IRI. I’ll spend most of this entry going over the choice points, starting with the points where I think there is a clearly preferably option, and ending with the choices where I think it’s unclear which way to go. Then I’ll discuss some general objections to IRI, and say how they might be answered.\n\n\n0.2 Motivations\nThere are two primary motivations for IRI. One comes from intuitions about cases, the other from a pair of principles. It turns out the two are connected, but it helps to start seeing them separately.\nJason Stanley (2005) starts with some versions of the ‘bank cases’ due originally to Keith DeRose (1992). These turn on idiosyncratic, archaic details of the US payments system, and I find it hard to have clear intuitions about them. A cleaner pair of examples is provided by Angel Pinillos (2012); here are slightly modified versions of his examples.\n\nAnkita and Bojan each have an essay due. They have, surprisingly, written word for word identical papers, and are now checking the paper for typos. The papers have no typos, and each student has checked their paper twice, with the same dictionary, and not found any typos. They are, in general, equally good at finding typos, and have true beliefs about their proficiency at typo-spotting.\nThe only difference between them concerns the consequence of a typo remaining. If the paper is a borderline A/A- paper, a typo might mean Ankita gets an A- rather than an A. But the grade doesn’t matter to her; she’s already been accepted into a good graduate program next year so long as she gets above a C. But Bojan’s instructor is a stickler for spelling. Any typo and he gets a C on the paper. And he has a very lucrative scholarship that he loses if he doesn’t get at least a B on this paper. (Compare the Typo-Low and Typo-High examples in Pinillos (2012, 199).)\n\nThe intuition that helps IRI is that Ankita knows she has no typos in her paper, and should turn it in, while Bojan does not know this, and should do a third (and perhaps fourth or fifth) check. Contextualists have a hard time explaining this; in this very context I can say “Ankita knows her paper has no typos, but Bojan does not know his paper has no typos”. If the intuition is right, it seems to support interest-relativity, since the difference in practical situation between Ankita and Bojan seems best placed to explain their epistemic difference. Alternatively, if there is a single context within which one can truly say \"Ankita knows her paper has no typos’‘, and’‘Bojan does not know his paper has no typos’’, that’s again something an interest-invariant contextualism can’t explain. Either way, we have an argument from cases for a form of interest-relativity.\nThe argument from principles takes off from the idea that knowledge plays an important role in good deliberation, and that knowledge does not require maximal confidence. It is easiest to introduce with an example, though note that we aren’t going to rely on epistemic intuitions about the example. Chika looked at the baseball scores last night before going to bed and saw that the Red Sox won. She remembers this when she wakes up, though she knows that she does sometimes misremember baseball scores. She is then faced with the following choice: take the red ticket, which she knows pays $1 if the Red Sox won last night, and nothing otherwise or the blue ticket, which she knows pays $1 iff 2+2=4, and nothing otherwise. Now consider the following principle, named by Jessica Brown (2014):\n\nK-Suff\n\nIf S knows that p, then S can rationally take p as given in practical deliberation.\n\n\nThe following trio seems to be inconsistent:\n\nChika knows the Red Sox won last night.\nChika is rationally required to take the blue ticket.\nK-Suff is true.\n\nBy 1 and 3, Chika can take for granted that the Red Sox won last night. So the value of the red ticket, for her, is equal to its value conditional on the Red Sox winning. And that is $1. So it is at least as valuable as the blue ticket. So she can’t be rationally required to take the blue ticket. Hence the three propositions are inconsistent.\nThis is worrying for two reasons. For one thing, it is intuitive that Chika knows that the Red Sox won. For another thing, it seems this form of argument generalises. For almost any proposition at all, if Chika knows the red ticket pays out iff that proposition is true, she should prefer the blue ticket. So she knows very little.\nHow could this argument be resisted? One move, which we’ll return to frequently, is to deny K-Suff. Maybe Chika’s knowledge that the Red Sox won is insufficient; she needs to be certain, or to have some higher order knowledge. But denying K-Suff alone will not explain why Chika should take the blue ticket. After all, if K-Suff is false, the fact that Chika knows the payout terms of the tickets is not in itself a reason for her to choose the blue ticket.\nSo perhaps we could deny that she is rationally required to choose the blue ticket. This does seem extremely unintuitive to me. Intuitions around here do not seem maximally reliable, but this is a strong enough intuition to make it worthwhile to explore other options.\nAnd IRI provides a clever way out of the dilemma. Chika does not know the Red Sox won last night. But she did know that, before the choice was offered. Once she has that choice, her knowledge changes, and now she does not know. The intuition that she knows is explained by the fact that relative to a more normal choice set, she can take the fact that the Red Sox won as a given. And scepticism is averted because Chika does normally know a lot; it’s just in the context of strange choices that she loses knowledge.\nThe plotline here, that principles connecting knowledge and action run up against anti-sceptical principles in contrived choice situations, and that IRI provides a way out of the tangle, is familiar. It is, simplifying greatly, the argumentative structure put forward by Hawthorne (2004), and by Fantl and McGrath (2002, 2009), and by Weatherson (2012). It does rely on intuitions, but they are intuitions about choices (such as that Chika should choose the blue ticket), not about knowledge directly.\nSome discussions of IRI, especially that in Hawthorne and Stanley (2008) use a converse principle. Again following the naming convention suggested by Jessica Brown (2014), we’ll call this K-Nec.\n\nK-Nec\n\nAn agent can properly use p as a reason for action only if she knows that p.\n\n\nI’ll mostly set the discussion of K-Nec aside here, since my preferred argument for IRI, the argument from Chika’s case, merely relies on K-Suff. But it is interesting to work through how K-Nec helps plug a gap in the argument by cases for IRI.\nBuckwalter and Schaffer (2015) argue that the intuitions behind Pinillos’s examples are not as solid as we might like. It’s true that experimental subjects do say that Bojan has to check the paper more times than Ankita does before he knows that the paper contains no typos. But those subjects also say he has to check more times before he believes that the paper has no typos. And, surprisingly, they say that he has to check more time before he guesses the paper has no typos. They suggest that there might be interest-relativity in the modal ‘has’ as much as in the verb ‘knows’. To say someone ‘has’ to X before they Y, typically means that it is improper, in some way, to Y without doing X first. That won’t be a problem for the proponent of IRI as long as at least in some of the cases Pinillos studies, the relevant senses of propriety are connected to knowledge. And that’s plausible for belief; Bojan has to know the paper is typo free before he (properly) believes it. At least, that’s a plausible move given K-Nec.1\n1 I’m suggesting here that in some sense, knowledge is a norm of belief. For more on the normative role of knowledge, see Worsnip (2017).There is one other problem for argument from cases for IRI. Imagine that after two checks of the paper, we tell Bojan that Ankita’s paper is a duplicate of hers, and she has checked her paper in just the same way he has checked his. And we tell him that Ankita does not overly care whether her paper is typo-free, but is confident that it is. We then ask him, does Ankita know her paper is typo free? Many philosophers think Bojan should answer “No” here. And that isn’t something IRI can explain. According to IRI, he should say, “I don’t know.” He can’t say Ankita does know, since he doesn’t know their common paper has no typos. But it’s hard to see why he should deny knowledge. Keith DeRose (2009, 185) thinks this case is particularly hard for IRI to explain, while Brian Kim (2016) offers some possible explanations. This objection doesn’t tell against the claim that knowledge is interest-relative, but it does threaten the invariantism. An interest-relative contextualist should say that everyone should deny Bojan knows his paper is typo free, and Bojan should deny Ankita knows her paper is typo-free.\n\n\n0.3 Odds and Stakes\nInterest-relative invariantism says that the interests of the subject matter to what she knows. This is a fairly vague statement though; there are a number of ways to make it precise. Right now I have interests in practical questions (such as whether I should keep writing or go to lunch) and in theoretical questions (such as whether IRI is true). Do both kinds of interests matter? We’ll return to that question in the next section. For now we want to ask a prior question: when do practical interests matter for whether a subject knows that p? There are two main answers to this question in the literature.\n\nStakes\n\nWhen the agent has a possible bet on p that involves large potential losses, it is harder to know that p.\n\nOdds\n\nWhen the agent has a possible bet on p that involves long odds, it is harder to know that p.\n\n\nThe difference between these two options becomes clear in a simple class of cases. Assume the agent is faced with a choice with the following structure:\n\nThere is a safe option, with payout S.\nAnd there is a risky option, with good payout G if p is true, and bad payout B if p is false.\n\nThese choices need not involve anything like a ‘bet’, in the ordinary folk sense. But they are situations where the agent has to make a choice between a path where the payouts are p-dependent, and one where they are independent of p. And those are quite common situations.\nThe Stakes option says that the relevant number here is the magnitude \\(S-B\\). If that is large, then the agent is in a high-stakes situation, and knowledge is hard. If it is low, then the agent is in a low stakes situation, and knowledge is relatively easy. (Perhaps the magnitude of \\(G-S\\) is relevant as well, though the focus in the literature has been on examples where \\(S-B\\) is high.)\nThe Odds option says that the relevant number is is the ratio:\n\\[\\frac{S-B}{G-S}\\] If that number is high, the agent faces a long odds bet, and knowledge is hard. If that number is low, the agent faces a short odds bet, and knowledge is relatively easy.\nIf our motivation for IRI came from cases, then it is natural to believe Stakes. Both Bojan and Chika face bets on p at long odds, but intuition is more worried about whether Bojan knows that p than whether Chika does. (At least my intuition is worried about whether Bojan knows, and I’ve seen little evidence that Chika’s case is intuitively a case of non-knowledge.)\nBut if our motivation for IRI came from principles, then it is natural to believe Odds. One way to think of the argument from principles for IRI is that it is a way to make all four of the following intuitive claims true:\n\nAgents should maximise evidential expected utility; i.e., they should choose the option whose expected utility is highest if the utilities are the agent’s own, and the probabilities are the evidential probabilities given the agent’s evidence.\nIf an agent knows that p, they can ignore possibilities where p is false; i.e., they can make whatever choice is the rational choice given p.\nChika cannot ignore possibilities where the Red Sox lost; she should consider those possibilities because it is in virtue of them that the evidential expected utility of taking the red ticket is higher.\nAgents with Chika’s evidence, background and dispositions typically know that the Red Sox won.\n\nThe first three principles imply that Chika does not know the Red Sox won. The only way to square that with the anti-sceptical fourth principle is to say that Chika is in some way atypical. And the only way she has been said to be atypical is in the practical choices she faces. But note it is not because she faces a high-stakes choice: precisely one dollar is at stake. It is because she faces a long (indeed infinitely long) odds bet.\nIn the general case we discussed above, agents maximise expected utility by taking the risky choice iff:\n\\[\\frac{S-B}{G-S} &lt; \\frac{Pr(p)}{1-Pr(p)}\\] where \\(Pr(p)\\) is the probability of p given the agent’s evidence. The actual magnitudes at play don’t matter to what choice maximses expected utility, just the odds the agent faces. So if one’s motivation to keep IRI is to square expected utility maxmisation with natural principles about knowledge and action, it seems the relevant feature of practical situations should be the stakes agents face.\nWhy could it seem stakes matter then? I think it is because in high stakes situations, the odds an agent faces are typically long ones. It is much easier to lose large amounts of utility than to gain large amounts of utility. Bojan stands to lose a lot from a typo in his paper; he doesn’t stand to lose much by taking the time to check it over. So a high stakes situation will, at least typically, be a long odds situation. So if we say the odds the agent faces are relevant to what they know, we can explain any intuition that the stakes at play are relevant.\nJessica Brown (2008, 176) also notes that cases where the agent faces long odds but low stakes raise problems for the stakes-based version of IRI.\n\n\n0.4 What Kind of Interests?\nLet’s return to the question of whether theoretical interests are relevant to knowledge, or only practical interests. There is some precedent for the more restrictive answer. Stanley’s book on IRI is called Knowledge and Practical Interests. And he defends a theory on which what an agent knows depends on the practical questions they face. But there are strong reasons to think that theoretical reasons matter as well.\nIn the previous section, I suggested that agents know that p only if they would maximise expected utility by choosing the choice that would be rational given p. That is, agents know that p only if the answer to the question “What choice maximises expected utility?” is the same unconditionally as it is conditional on p. My preferred version of interest-relative invariantism generalises this approach. An agent knows that p only if the rational answer to a question she faces is the same unconditionally as it is conditional on p. What it is for an agent to face a question is dependent on the agent’s interests. If that’s how one thinks of IRI, the question of this section becomes, should we restrict questions the agent faces to just being questions about what choice to make? Or should they include questions that turn on her thoeretical interests, but which are irrelevant to choices before her. There are two primary motivations for allowing theoretical interests as well as practical interests to matter.\nThe first comes from the arguments for what Jeremy Fantl and Matthew McGrath call the Unity Thesis  (Fantl and McGrath 2009, 73–76). They are interested in the thesis that whether or not p is a reason for an agent is independent of whether the agent is engaged in practical or theoretical deliberation. But we don’t have to be so invested in the ideology of reasons to appreciate their argument. Note that if only practical interests matter, then the agent should come up with different answers to the question “What to do in situation S” depending on whether the agent is actually in S, or they are merely musing about how one would deal with that situation. And it is unintuitive that this should matter.\nLet’s make that a little less abstract. Imagine Chika is not actually faced with the choice between the red and blue tickets. In fact, she has no practical decision to make that turns on whether the Red Sox won. But she is idly musing over what she would do if she were offered the red ticket and the blue ticket. If she knows the Red Sox won, then she should be indifferent between the tickets. After all, she knows they will both return $1. But intuitively she should think the red ticket is preferable, even in the abstract setting. And this seems to be the totally general case.\nThe general lesson is that if whether one can take p for granted is relevant to the choice between A and B, it is similarly relevant to the theoretical question of whether one would choose A or B, given a choice. And since those questions should receive the same answer, if p can’t be known while making the practical deliberation between A and B, it can’t be known while musing on whether A or B is more choiceworthy.\nIn Weatherson (2012) I suggest another reason for including theoretical interests in what’s relevant to knowledge. There is something odd about the following reasoning: The probability of p is precisely x, therefore p, in any case where \\(x &lt; 1\\). It is a little hard to say, though, why this is problematic, since we often take ourselves to know things on what we would admit, if pushed, are purely probabilistic grounds. The version of IRI that includes theoretical interests allows for this. If we are consciously thinking about whether the probability of p is x, then that’s a relevant question to us. Conditional on p, the answer to that question is clearly no, since conditional on p, the probability of p is 1. So anyone who is thinking about the precise probability of p, and not thinking it is 1, is not in a position to know p. And that’s why it is wrong, when thinking about p’s probability, to infer p from its high probability.\nPutting the ideas so far together, we get the following picture of how interests matter. An agent knows that p only if the evidential probability of p is close enough to certainty for all the purposes that are relevant, given the agent’s theoretical and practical interests. Assuming the background theory of knowledge is non-sceptical, this will entail that interests matter.\n\n\n0.5 Global or Partial\nSo far I’ve described three ways to refine the defence of IRI.\n\nThe motivation could come from cases or principles.\nThe relevant feature that makes it hard to have knowledge could be that the agent faces a high-stakes choice, or a long-odds choice.\nOnly practical interests may be relevant to knowledge, or theoretical interests may matter as well.\n\nFor better or worse, the version of IRI I’ve defended has fairly clear commitments on all three; in each case, I prefer the latter option. From here on, I’m much less sure of the right way to refine IRI.\nIRI, like contextualism, was introduced as a thesis about knowledge. But it need not be restricted that way. It could be generalised to a number of other epistemically interesting notion. At the extreme, we could argue that every epistemologially interesting notion is interest-relative. Doing so gives us a global version of IRI.\nJason Stanley (2005) comes close to defending a global version. He notes that if one has both IRI, and a ‘knowledge first’ epistemology  (Williamson 2000), then one is a long way to towards globalism. Even if one doesn’t accept the whole knowledge first package, but just accepts the thesis that evidence is all and only what one knows, then one is a long way towards globalism. After all, if evidence is interest-relative, then probability, justification, rationality, and evidential support are interest-relative too.\nKatherine Rubin (2015) objects to globalist versions of IRI. But the objections she gives turn, as she notes, on taking stakes not odds to be relevant.\nIf a non-global version of IRI could be made to work, it would have some theoretical advantages. It’s nice to be able to say that Chika should take the blue ticket because the evidential probability of the Red Sox winning is lower than the evidential probability of two plus two being four. But that won’t be a non-circular explanation if we also say that something is part of Chika’s evidence in virtue of being known.\nOn the other hand, the motivations for interest-relativity of knowledge seem to generalise to all other non-gradable states. In ordinary cases, Chika could use the fact that the Red Sox won as a given in practical or theoretical reasoning. That is, she could properly treat it as evidence. But she can’t treat it as evidence when deciding which ticket to take. So at least what she can properly treat as evidence seems to be interest-relative, and from there it isn’t obvious how to deny that evidence itself is interest-relative too.\nThere remains a question of whether gradable notions, like epistemic probabilities, are also interest-relative. One of the aims of my first paper on IRI  (Weatherson 2005) was to argue that probabilistic notions are interest-invariant while binary notions are interest-relative. But if propositions that are part of one’s evidence have maximal probability (in the relevant sense of probability), and evidence is interest-relative, that combination won’t be sustainable.\nIn short, while the non-global version of IRI allows for some nice reductive explanations of why interests matter, the global version is supported by the very intuitions that motivated IRI. There is a danger here that whatever way the IRI theorist goes, they will run into insuperable difficulties. Ichikawa, Jarvis, and Rubin (2012) argue strongly that this danger is real; there is no plausible way to fill out IRI. I’m not convinced that the prospects are quite so grim, but I think this is one of the more pressing worries for IRI.\n\n\n0.6 Belief, Justification and Interest\nIf we decide that not everything in epistemology is interest-relative, then we face a series of questions about which things are, and are not, interest relative. One of these concerns belief. Should we say that what an agent believes is sensitive to what her interests are?\nNote that the question here concerns whether belief is constitutively related to interests. It is extremely plausible that belief is causally related to interests. As Jennifer Nagel (2008) has shown, many agents will react to being in a high-stakes situation by lowering their confidence in relevant propositions. In this way, being in a high-stakes situation may cause an agent to lose beliefs. This is not the kind of constitutive interest-relativity that’s at issue here, though the fact this happens makes it harder to tell whether there is such a thing as constitutive interest-relativity of belief.\nI find it useful to distinguish three classes of views about beliefs and interests.\n\nBeliefs are not interest-relative. If knowledge is interest-relative, the interest-relativity is in the conditions a belief must satisfy in order to count as knowledge.\nBeliefs are interest-relative, and the interest-relativity of belief fully explains why knowledge is interest-relative.\nBeliefs are interest-relative, but the interest-relativity of belief does not fully explain why knowledge is interest-relative.\n\nIn Weatherson (2005), I suggested an argument for option 2. I now think that argument fails, for reasons given by Jason Stanley (2005). I originally thought option 2 provided the best explanation of cases like Chika’s. Assume Chika does the rational thing, and takes the blue ticket. She believes it is better to take the blue ticket. But that would be incoherent if she believed the Red Sox won. So she doesn’t believe the Red Sox won. But she did believe the Red Sox won before she was offered the bet, and she hasn’t received any new evidence that they did not. So, assuming we can understand an interest-invariant notion of confidence, she is no less confident that the Red Sox won, but she no longer believes it. That’s because belief is interest-relative. And if all cases of interest-relativity are like Chika’s, then they will all be cases where the interest-relativity of belief is what is ultimately explanatory.\nThe problem, as Stanley had in effect already pointed out, is that not all cases are like Chika’s. If agents are mistaken about the choice they face, the explanation I offered for Chika’s case won’t go through. This is especially clear in cases where the mistake is due to irrationality. Let’s look at an example of this. Assume Dian faces the same choice as Chika, and this is clear, but he irrationally believes that the red ticket pays out $2. So he prefers the red ticket to the blue ticket, and there is no reason to deny he believes the Red Sox won. Yet taking the red ticket is irrational; he wouldn’t do it were he rational. Yet it would be rational if he knew the Red Sox won. So Dian doesn’t know the Red Sox won, in virtue of his interests, while believing they did.\nNote this isn’t an argument for option 1. Everything I said about Dian is consistent with the Chika-based argument for thinking that belief is interest-relative. It’s just that there are cases where the interest-relativity of knowledge can’t be explained by the interest-relativity of belief. So I now think option 3 is correct.\nWe can ask similiar questions about whether justified belief is interest-relative, and whether if so this explains the interest-relativity of knowledge. I won’t go into as much detail here, save to note that on my preferred version of IRI, Dian’s belief that the Red Sox won is both justified and rational. (Roughly, this is because I think his belief that the Red Sox won just is his high credence that the Red Sox won, and his high credence the Red Sox won is justified and rational. I defend this picture at more length in [Weatherson2005;]. And while that paper makes some mistaken suggestions about knowledge, I still think what it says about belief and justification is broadly correct.) That is, Dian has a justified true belief that the Red Sox won, but does not know it. This is, to put it mildly, not the most intuitive of verdicts. I suspect the alternative verdicts lead to worse problems elsewhere. But rather than delving deeper into the details of IRI to confirm whether that’s true, let’s turn to some objections to the view.\n\n\n0.7 Debunking Objections\nMany arguments against IRI are, in effect, debunking arguments. The objector’s immediate conclusion is not that IRI is false, but that it is unsupported by the arguments given for it.\nArguments that people do not have the intuition that, for exaple, Bojan lacks knowledge that his paper is typo-free, do not immediately show thtat IRI is false. That’s because the truth of IRI can be made compatible with that intuition in two ways. For one thing, it is possible that people think Bojan knows because they think Bojan betting that his paper is typo free is, in the circumstances, a good bet.2 For another thing, intuitions around here might be unreliable. Remember that one of the original motivations for IRI was that it was the lowest cost solution to the preface paradox and lottery paradox. We shouldn’t expect intuitions to be reliable in the presence of serious paradox. That consideration cuts both ways; it makes debunking objections to arguments for IRI from intuitions about cases look very promising. And I think those objections are promising; but they don’t show IRI is false.\n2 Compare the response to Feltz and Zarpentine (2010) that I make in Weatherson (2011, sec. 1), or the response to Lackey (2010) by Masashi Kasaki (2014, sec. 5).Similarly, objections to the premises of the argument from principles don’t strictly entail that IRI is false. After all, IRI is an existential thesis; it says sometimes interests matter. The principles used to defend it are universal claims; they say (for example) it is always permissible to act on knowledge. Weaker versions of these principles might still be consistent with, or even supporting of, IRI. But this feels a little desperate. If the premises of these arguments fail, then IRI looks implausible.\nBut there are still two methodological points worth remembering. Sometimes it seems that critics of principles like K-Suff reason that K-Suff entails IRI, and IRI is antecedently implausible, so we should start out suspicious of K-Suff. Now why might IRI be antecedently implausible?\nI think to some extent it is because it is thought to be so revolutionary. The denial of interest-relativity is often taken to be a “traditional” view. This phrasing appears, for example, in Boyd (2016), and in Ichikawa, Jarvis, and Rubin (2012), and even in the title of Buckwalter (2014). And if this were correct, that would be a mark against interest-relativity. The “inherited experience and acumen of many generations of men”  (Austin 1956, 11) should not be lightly forsaken. The problem is that it isn’t true that IRI is revolutionary. Indeed, in historical terms there is nothing particularly novel about contemporary IRI. As Stephen R. Grimm (2015) points out, you can see a version of the view in Locke, and in Clifford. What’s really radical, as Descartes acknowledged, is to think the perspective of the Cartesian meditator is the right one for epistemology.\nPerhaps what is unintuitive about IRI is that it makes knowledge depend on factors that are not ‘truth-directed’, or ‘truth-conducive’. There is a stronger and weaker version of the principle that might be being appealed to here. The stronger version is that IRI makes practical matters into one of the factors on which knowledge depends, and this is implausible. But IRI doesn’t do this. It is consistent with IRI to say that only truth-conducive features of beliefs are relevant to whether they amount to knowledge, but how much of each feature one needs depends on practical matters. The weaker principle is that IRI makes knowledge counterfactually sensitive to features irrelevant to the truth, justification or reliability of the belief. This is true, but it isn’t an objection to IRI. Any theory that allows defeaters to knowledge, and defeaters to those defeaters, will make knowledge counterfactually sensitive to non-truth-conducive features in just the same way. And it is independently plausible that there are defeaters to knowledge, and they can be defeated.3\n3 The argument of the last two sentences is expanded on greatly in Weatherson (2014, sec. 3). The idea that knowledge allows for defeaters is criticised by Maria Lasonen-Aarnio (2014b). Eaton and Pickavance (2015) make an objection to IRI that does not take this point into account.These are all reasons to think that IRI is not antecedently implausible. There is one reason to think it is antecedently plausible. On a functionalist theory of mind, belief is a practical notion. And it is plausible that knowledge is a kind of success condition for belief. Now it’s possible to have non-practical success conditions for a state our concept of which is practical. But I don’t find that a natural starting assumption. It’s mucn more intuitive, to me at least, that the norms of belief and the metaphysics of belief would be tightly integrated. And that suggests that IRI is, if anything, a natural default.\nThat’s not an argument for IRI, or of course for K-Suff. And there are important direct objections to K-Suff. Jessica Brown (2008) and Jennifer Lackey (2010) have examples of people in high stakes situations who they say are intuitively described as knowing something, but not being in a position to act on it. I’m sympathetic to the two-part reply that Masashi Kasaki (2014) makes to these examples. The first thing to note is that these are hard cases, in areas where several paradoxes (e.g., lottery, preface, sceptical) are lurking. Intuitions are less reliable than usual around here. But another thing to notice is that it is very hard to say what actions are justified by taking p for granted in various settings. Brown and Lackey both describe cases where doctors have lots of evidence for p, and given p a certain action would maximise patient-welfare, but where intuitively it would be wrong for the doctor to act that way. As it stands, that’s a problem for IRI only if doctors should maximise epistemic expected patient-welfare, and that principle isn’t true. Kasaki argues that there isn’t a way to fill out Lackey’s example to get around this problem, and I suspect the same is true for Brown’s example.\nFinally, note that K-Suff is an extensional claim. Kenneth Boyd (2016) and Baron Reed (2014) object to a principle much stronger than K-Suff: the principle that what an agent knows should explain why some choices are rational for them. Both of them say that if IRI is inconsistent with the stronger principle, that is a serious problem for IRI. (In Boyd’s case this is part of an argument that IRI is unmotivated; in Reed’s case he takes it to be a direct objection to IRI.) Now I think IRI is inconsistent with this principle. Chika doesn’t know the Red Sox won because she can’t rationally choose the red ticket, not the other way around. But I don’t see why the principle is so plausible. It seems plausible to me that something else (e.g., evidence) explains both rational choice and knowledge, and the way it explains both things makes IRI true.\n\n\n0.8 Direct Objections\nLet’s close with direct arguments against IRI. There are two kinds of arguments that I won’t address here. One of these is the argument, developed in Ichikawa, Jarvis, and Rubin (2012) that there isn’t a good way to say how far interest-relativity should extend. As I noted above, I agree this is a deep problem, and don’t think there is a good answer to it in the existing literature. The other kind are objections that only apply to the Stakes version of IRI, not the Odds version. One instance of this kind is the Dutch Book argument deployed by Baron Reed (2014). I think several instances of that kind of argument are successful. But the theory they succeed against is not IRI, but a sub-optimal version of IRI. So I’ll stick to objections that apply to the Odds version.\nIRI does allow knowledge to depend on some unexpected factors. But so do most contemporary theories of knowledge. Most contemporary theories allow for knowledge to be defeated in certain ways, such as by available but unaccessed evidence  (Harman 1973, 75), or by nearby possibilities of error  (Goldman 1976), or by mistakes in the background reasoning. The last category of cases aren’t really contemporary; they trace back at least to Dharmottara  (Nagel 2014, 58). And contemporary theories of knowledge also allow for defeaters to be defeated. Once we work through the details of what can defeat a defeater, it turns out many surprising things can affect knowledge.\nIndeed, for just about any kind of defeater, it is possible to imagine something that in some ways makes the agent’s epistemic position worse, while simultaneously defeating the defeater.4 If interests matter to knowledge because they matter to defeaters, as is true on my version of IRI, we should expect strange events to correlate with gaining knowledge. For example, it isn’t surprising that one can gain knowledge that p at exactly the moment one’s evidential support for p falls. This consequence of IRI is taken to be obviously unacceptable by Eaton and Pickavance (2015), but it’s just a consequence of how defeaters generally work.\n4 The argument of the last two sentences is expanded on greatly in Weatherson (2014, sec. 3), where it is credited to Martin Smith. The idea that knowledge allows for defeaters is criticised by Maria Lasonen-Aarnio (2014a).IRI has been criticised for making knowledge depend on agents not allowing agents to get knowledge by not caring, as in these vivid quotes:\n\nNot giving a damn, however enviable in other respects, should not be knowledge-making.  (Russell and Doris 2009, 433)\n\n\nIf you don’t now whether penguins eat fish, but want to know, you might think … you have to gather evidence. [But if IRI] were correct, though, you have another option: You could take a drink or shoot heroin.  (Cappelen and Lepore 2006, 1044–45)\n\nLet’s walk through Cappelen and Lepore’s case. IRI says that there are people who both have high confidence that penguins eat fish, and they have this confidence for reasons that are appropriately connected to the fact that penguins eat fish. But one of them really worries about sceptical doubts, and so won’t regard the question of what penguins eat as settled. The other brushes off excessive sceptical doubts, and rightly so; they are, after all, excessive. IRI says that the latter knows and the former does not. If the former were to care a little less, in particular if they cared a little less about evil demons and the like, they’d know. Perhaps they could get themselves to care a little less by having a drink. That doesn’t sound like a bad plan; if a sceptical doubt is destroying knowledge, and there is no gain from holding on to it, then just let it go. From this perspective, Cappelen and Lepore’s conclusion does not seem like a reductio. Excessive doubt can destroy knowledge, so people with strong, non-misleading evidence can gain knowledge by setting aside doubts. And drink can set aside doubt. So drink can lead to knowledge.5\n5 Wright (2004) notes that there often is not value in holding on to sceptical doubts, and the considerations of this paragraph are somewhat inspired by his views. That’s not to endorse the idea that using alcohol or heroin is preferable to being gripped by sceptical doubts, especially heroin, but I do endorse the general idea that those doubts are not cost-free.But note that the drink doesn’t generate the knowledge. It blocks, or defeats, something that threatens to block knowledge. We should say the same thing to Russell and Doris’s objection. Not giving a damn, about scepticism for example, is not knowledge-making, but it is knowledge-causing. In general, things that cause by double prevention do not make things happen, although later things are counterfactually dependent on them  (Lewis 2004). And the same is true of not caring.\nFinally, it has been argued that IRI makes knowledge unstable in a certain kind of way  (Lutz 2014; Anderson 2015). Practical circumstances can change quickly; something can become a live choice and cease being one at a moment’s notice. If knowledge is sensitive to what choices are live, then knowledge can change this quickly too. But, say the objectors, it is counterintuitive that knowledge changes this quickly.\nNow I’m not sure this is counterintuitive. I think that part of what it takes to know p is to treat the question of whether p as closed. It sounds incoherent to say, “I know a is the F, but the question of who is the F is still ope”. And whether a question is treated as open or closed does, I think, change quite rapidly. One can treat a question as closed, get some new reason to open it (perhaps new evidence, perhaps an interlocutor who treats it as open), and then quickly dismiss that reason. So I’m not sure this is even a problem.\nBut to the extent that it is, it is only a problem for a somewhat half-hearted version of IRI. The puzzles the objectors raise turn on cases where the relevant practical options change quickly. But even once a practical option has ceased to be available, it can be hard in practice to dismiss it from one’s mind. One may often still think about what to do if it becomes available again, or about exactly how unfortunate it is that the option went away. As long as theoretical as well as practical interests matter to knowledge, it will be unlikely that knowledge will be unstable in just this way. Practical interests may change quickly; theoretical ones typically do not.\n\n\n\n\n\n\nReferences\n\nAnderson, Charity. 2015. “On the Intimate Relationship of Knowledge and Action.” Episteme 12 (3): 343–53. https://doi.org/10.1017/epi.2015.16.\n\n\nAustin, J. L. 1956. “A Plea for Excuses.” Proceedings of the Aristotelian Society 57 (1): 1–30. https://doi.org/10.1093/aristotelian/57.1.1.\n\n\nBoyd, Kenneth. 2016. “Pragmatic Encroachment and Epistemically Responsible Action.” Synthese 193 (9): 2721–45. https://doi.org/10.1007/s11229-015-0878-y.\n\n\nBrown, Jessica. 2008. “Subject-Sensitive Invariantism and the Knowledge Norm for Practical Reasoning.” Noûs 42 (2): 167–89. https://doi.org/10.1111/j.1468-0068.2008.00677.x.\n\n\n———. 2014. “Impurism, Practical Reasoning and the Threshold Problem.” Noûs 48 (1): 179–92. https://doi.org/10.1111/nous.12008.\n\n\nBuckwalter, Wesley. 2014. “Non-Traditional Factors in Judgments about Knowledge.” Philosophy Compass 7 (4): 278–89. https://doi.org/10.1111/j.1747-9991.2011.00466.x.\n\n\nBuckwalter, Wesley, and Jonathan Schaffer. 2015. “Knowledge, Stakes and Mistakes.” Noûs 49 (2): 201–34. https://doi.org/10.1111/nous.12017.\n\n\nCappelen, Herman, and Ernest Lepore. 2006. “Shared Content.” In The Oxford Handbook of Philosophy of Language, edited by Ernest Lepore and Barry C. Smith, 1020–55. Oxford: Oxford University Press.\n\n\nDeRose, Keith. 1992. “Contextualism and Knowledge Attributions.” Philosophy and Phenomenological Research 52 (4): 913–29. https://doi.org/10.2307/2107917.\n\n\n———. 2009. The Case for Contextualism: Knowledge, Skepticism and Context. Oxford: Oxford.\n\n\nEaton, Daniel, and Timothy Pickavance. 2015. “Evidence Against Pragmatic Encroachment.” Philosophical Studies 172: 3135–43. https://doi.org/10.1007/s11098-015-0461-x.\n\n\nFantl, Jeremy, and Matthew McGrath. 2002. “Evidence, Pragmatics, and Justification.” Philosophical Review 111 (1): 67–94. https://doi.org/10.2307/3182570.\n\n\n———. 2009. Knowledge in an Uncertain World. Oxford: Oxford University Press.\n\n\nFeltz, Adam, and Chris Zarpentine. 2010. “Do You Know More When It Matters Less?” Philosophical Psychology 23 (5): 683–706. https://doi.org/10.1080/09515089.2010.514572.\n\n\nGoldman, Alvin I. 1976. “Discrimination and Perceptual Knowledge.” The Journal of Philosophy 73 (20): 771–91. https://doi.org/10.2307/2025679.\n\n\nGrimm, Stephen R. 2015. “Knowledge, Practical Interests and Rising Tides.” In Epistemic Evaluation: Purposeful Epistemology, edited by David K. Henderson and John Greco, 117–37. Oxford: Oxford University Press.\n\n\nHarman, Gilbert. 1973. Thought. Princeton: Princeton University Press.\n\n\nHawthorne, John. 2004. Knowledge and Lotteries. Oxford: Oxford University Press.\n\n\nHawthorne, John, and Jason Stanley. 2008. “Knowledge and Action.” Journal of Philosophy 105 (10): 571–90. https://doi.org/10.5840/jphil20081051022.\n\n\nIchikawa, Jonathan Jenkins, Benjamin Jarvis, and Katherine Rubin. 2012. “Pragmatic Encroachment and Belief-Desire Psychology.” Analytic Philosophy 53 (4): 327–43. https://doi.org/10.1111/j.2153-960X.2012.00564.x.\n\n\nKasaki, Masashi. 2014. “Subject-Sensitive Invariantism and Isolated Secondhand Knowledge.” Acta Analytica 29: 83–98. https://doi.org/10.1007/s12136-013-0215-3.\n\n\nKim, Brian. 2016. “In Defense of Subject-Sensitive Invariantism.” Episteme 13 (2): 233–51. https://doi.org/10.1017/epi.2015.40.\n\n\nLackey, Jennifer. 2010. “Acting on Knowledge.” Philosophical Perspectives 24: 361–82. https://doi.org/10.1111/j.1520-8583.2010.00196.x.\n\n\nLasonen-Aarnio, Maria. 2014a. “Higher-Order Evidence and the Limits of Defeat.” Philosophy and Phenomenological Research 88 (2): 314–45. https://doi.org/10.1111/phpr.12090.\n\n\n———. 2014b. “The Dogmatism Puzzle.” Australasian Journal of Philosophy 92 (3): 417–32. https://doi.org/10.1080/00048402.2013.834949.\n\n\nLewis, David. 2004. “Causation as Influence.” In Causation and Counterfactuals, edited by John Collins, Ned Hall, and L. A. Paul, 75–106. Cambridge: MIT Press.\n\n\nLutz, Matt. 2014. “The Pragmatics of Pragmatic Encroachment.” Synthese 191 (8): 1717–40. https://doi.org/10.1007/s11229-013-0361-6.\n\n\nNagel, Jennifer. 2008. “Knowledge Ascriptions and the Psychological Consequences of Changing Stakes.” Australasian Journal of Philosophy 86 (2): 279–94. https://doi.org/10.1080/00048400801886397.\n\n\n———. 2014. Knowledge: A Very Short Introduction. Oxford: Oxford University Press.\n\n\nPinillos, Ángel. 2012. “Knowledge, Experiments and Practical Interests.” In Knowledge Ascriptions, edited by Jessica Brown and Mikkel Gerken, 192–219. Oxford: Oxford University Press.\n\n\nReed, Baron. 2014. “Practical Matters Do Not Affect Whether You Know.” In Contemporary Debates in Epistemology, edited by Matthias Steup, John Turri, and Ernest Sosa, 2nd ed., 95–106. Chicester: Wiley-Blackwell.\n\n\nRubin, Katherine. 2015. “Total Pragmatic Encroachment and Epistemic Permissiveness.” Pacific Philosophical Quarterly 96: 12–38. https://doi.org/10.1111/papq.12060.\n\n\nRussell, Gillian, and John M. Doris. 2009. “Knowledge by Indifference.” Australasian Journal of Philosophy 86 (3): 429–37. https://doi.org/10.1080/00048400802001996.\n\n\nRysiew, Patrick. 2017. “Warranted Assertability Maneuvers.” In Routledge Handbook of Epistemic Contextualism, edited by Jonathan Jenkins Ichikawa, n/a–a. London: Routledge.\n\n\nStanley, Jason. 2005. Knowledge and Practical Interests. Oxford University Press.\n\n\nWeatherson, Brian. 2005. “Can We Do Without Pragmatic Encroachment?” Philosophical Perspectives 19 (1): 417–43. https://doi.org/10.1111/j.1520-8583.2005.00068.x.\n\n\n———. 2011. “Defending Interest-Relative Invariantism.” Logos & Episteme 2 (4): 591–609. https://doi.org/10.5840/logos-episteme2011248.\n\n\n———. 2012. “Knowledge, Bets and Interests.” In Knowledge Ascriptions, edited by Jessica Brown and Mikkel Gerken, 75–103. Oxford: Oxford University Press.\n\n\n———. 2014. “Probability and Scepticism.” In Scepticism and Perceptual Justification, edited by Dylan Dodd and Elia Zardini, 71–86. Oxford: Oxford University Press.\n\n\nWilliamson, Timothy. 2000. Knowledge and its Limits. Oxford University Press.\n\n\nWorsnip, Alex. 2017. “Knowledge Norms.” In Routledge Handbook of Epistemic Contextualism, edited by Jonathan Jenkins Ichikawa, n/a–a. London: Routledge.\n\n\nWright, Crispin. 2004. “Warrant for Nothing (and Foundations for Free)?” Proceedings of the Aristotelian Society, Supplementary Volume 78 (1): 167–212. https://doi.org/10.1111/j.0309-7013.2004.00121.x."
  },
  {
    "objectID": "posts/review-sorensen/index.html",
    "href": "posts/review-sorensen/index.html",
    "title": "Review of “Vagueness and Contradiction”",
    "section": "",
    "text": "Like all epistemicists, Roy Sorensen holds that vagueness poses no threat to classical logic, and that appearances to the contrary are the result of mistakenly assigning semantic force to certain barriers to inquiry. We may not be able to know whether 932 seconds after noon is still noonish, but there is a fact of the matter about whether it is. Hence the sentence 932 seconds after noon is noonish is either true or false, just as adherents of classical logic presuppose, and the threat from vagueness to classical logic dissolves.\n\nPublished in Australasian Journal of Philosophy 81: 290-292.\n\nBut Sorensen is not an orthodox epistemicist. He does not hold that these barriers to inquiry rise because of our limited powers of discrimination. That would imply that a more discerning observer, say God, could know where the boundary is. Sorensen holds that vagueness is an absolute barrier to inquiry. No one can know whether 932 seconds after noon is noonish, even God. This is because competently using the vague predicate ‘noonish’ requires believing a particular analytic falsehood involving it, and having this belief prevents knowing the truth about a borderline case. Much of this book is dedicated to defending these surprising claims. The first half of the book argues that this is the right thing to say about vague cases, and the second half provides more general arguments that we can and should believe analytic falsehoods.\nIt’s illuminating to compare Sorensen’s epistemicism with that of Timothy Williamson. A core feature of Williamson’s position is neatly summarised in this quote, which Sorensen cites: “for the epistemicist, definiteness is truth under all sharp interpretations of the language indiscriminable from the right one.” (“On the Structure of Higher Order Vagueness” Mind 108 (1999): 127‑43.)  Sorensen disagrees with the Williamson’s position in four ways. Two of these disagreements are immediate, and two are with deeper presuppositions of Williamson’s.\nFirst, Sorensen thinks that Williamson here ignores the need for ‘completeness’. Williamson holds that p is definite iff, roughly, it is true on all interpretations we cannot know to be incorrect. Call these the admissible interpretations. Sorensen claims that is not enough for p to be knowable, and hence definitely true. It must also be knowable that these are all the admissible interpretations.\nSecondly, indiscriminability is always indiscriminability by something, so on Williamson’s account definiteness is only defined relative to a discriminator. Sorensen wants there to be absolute borderline cases, and absolute indefiniteness, so he cannot rest with this definition. Sorensen thinks that unless we accept absolute borderline cases, we do not properly respect the sense in which vagueness is an absolute barrier to inquiry. The two other innovations in Sorensen’s theory guarantee that his theory has place for absolute indefiniteness.\nConsider a normal Sorites conditional, say If 932 seconds after noon is noonish, so is 933 seconds. Sorensen holds that being a competent user of ‘noonish’ requires that one believe every such conditional involving ‘noonish’. Someone who failed to believe it would not be competent in the language. Although Sorensen always puts this in terms of linguistic competence, he also says that one who didn’t believe this couldn’t have beliefs about the extension of our predicates. The most natural conclusion to draw is that from Sorensen’s perspective, one who doesn’t believe the Sorites conditional lacks the concept NOONISH. Sorensen talks about predicates rather than concepts, so he doesn’t put it quite this way, but it succinctly summarises the picture he sketches. Moreover, beliefs in such Sorites conditionals are a priori, despite the fact that one of them is analytically false. These are distinctive views, and they need good arguments.\nA bad argument would be, “It is always irrational to deny a Sorites conditional, so it is always rational to believe it.” This ignores the possibility that agnosticism about the conditional is always possible, and sometimes desirable. Sorensen does not endorse this argument, though he does note it shows that Sorites conditionals satisfy a ‘negative conception’ of the a priori: no empirical evidence can make us believe they are false.\nSorensen’s argument seems to be that believing every Sorites conditional gives us many true beliefs at the cost of only one false belief. He thinks that cost is worth the benefit. But this is at best a reason why we should believe Sorites conditionals, not why God should. And it doesn’t imply much about why God needs to believe this falsehood if He is to have the concept NOONISH. If we think subjectivism about language implies that God can’t know more about our language than we do, that may draw God into our dilemma. But it should seem very implausible, especially to an epistemicist, that God can’t know more about our language than we do. So even if it is good advice to believe every Sorites conditional, it does not follow that those who spurn this advice lack any concepts, or lack linguistic competence.\nIn any case, there are other costs to adopting Sorensen’s advice and believing a bunch of Sorites conditionals that we know includes a falsehood. For example, we can no longer safely believe the logical consequences of some things we believe. Sorensen happily accepts that consequence. He holds p and q can both be a priori even though their conjunction is not a priori. In chapter 6 Sorensen replies to several arguments against this, including a purported proof that a priority agglomerates across conjunction. The proof assumes that all logical truths are a priori. Sorensen says this is false because there are logical truths that are too complex for us to believe, a priori or otherwise. Since the only logical truth needed in the proof was p → (q → (p & q)), this is not obviously a sound response.\nSorensen has a more speculative reason for thinking there is absolute vagueness. (This is the final way in which Sorensen’s position differs from Williamson.) Consider a card that has The sentence on the other side of this card is false written on each side. If the sentences have truth values, then one is true and the other false. Whichever is true is a truth without a truthmaker, for any truthmaker would do just as well at making the other true. So Sorensen concludes that here we have a truth without a truthmaker, and the truthmaker principle is false. If there are some truths without truthmakers, there could be several. Sorensen holds that a is F is such a truth whenever a is an F which is a borderline F. Assume further that only truths with truthmakers are knowable, because knowability goes via knowing truthmakers, and we conclude that no one could know of a borderline F whether it is F. This is quite an interesting line of thought, and it deserves further attention. (Sorensen is quite upfront about how speculative it is.) Two immediate issues spring to mind. First, it is not clear how this is still a version of epistemicism, for vagueness is now at base a metaphysical phenomenon. There are epistemic consequences, but vagueness is constituted by the fact that there are truths without truthmakes, not by the unknowability of these. Secondly, and relatedly, it is no longer clear how higher order vagueness will be incorporated into the model. The most obvious thought is that there will be no truthmaker for the claim that some particular truth has a truthmaker. But whether some object is a truthmaker for some truth is not contingent, and it is notoriously difficult to apply truthmaker theory to necessary truths. Since every proposition entails any necessary truth, it is plausible that any object is a truthmaker for a necessary truth.\nSorensen argues that we should believe all Sorites conditionals, including ones that are analytically false. He notes this requires an argument that we can, and should, believe some analytic falsehoods. (He calls these impossibilities ‘contradictions’, a term some may think should be reserved for sentences of the form p & ¬p.) His argument that we can is fairly quick. Assume, for reductio, the philosophical thesis that we cannot believe analytic falsehoods. As a philosophical thesis, this is analytically true if true at all. But Sorensen believes its negation. So it is possible for someone to believe an analytic falsehood. The weakest premise here is that if we cannot believe analytic falsehoods, then it is analytic that we cannot. If it turns out that only creatures with a language of thought can believe analytic falsehoods, and it is a contingent feature of us that we lack a language of thought, Sorensen’s premise is false.\nThe argument that we should believe some analytic falsehoods uses a version of the preface paradox. If we can believe analytic falsehoods, we should take apparent occurrences of this (as when we make arithmetic errors) at face value. That is, reason demands we believe that we believe an analytic falsehood. But this implies it is provable that our beliefs are not collectively true. So if we follow the dictates of reason, it is provable we believe something provably false. This argument is obviously useful for removing a particular barrier to accepting Sorensen’s account of vagueness, that it seems absurd that reason could require we believe an analytic falsehood. But even if we reject Sorensen’s theory of vagueness, they are independently interesting contributions to the theory of belief.\nSorensen makes two distinctive contributions to the theory of vagueness here. First, he argues that linguistic competence demands that we believe Sorites conditionals. Secondly, he links the existence of vagueness to the failure of the truthmaker principle. As those familiar with Sorensen’s work will suspect, he makes these contributions in a lively and entertaining way. Anyone working on vagueness, and especially anyone interested in investigating the range of theories of vagueness that preserve classical logic, should pay it close attention."
  },
  {
    "objectID": "posts/review-real-cond/index.html",
    "href": "posts/review-real-cond/index.html",
    "title": "Review of “Real Conditionals”",
    "section": "",
    "text": "Over the last two decades, William Lycan’s work on the semantics of conditionals has been distinguished by his careful attention to the connection between syntax and semantics, and more generally by his impeccible methodology. Lycan takes compositionality seriously, so in his theory the meaning of ‘even if’, for example, should be a combination of the meaning of ‘even’ and the meaning of ‘if’. After reading his work, it’s hard to take seriously work which does not share this methodology.\nLycan’s semantics for conditionals makes central use of what he calls ‘events’. An event is not a possible world, for it need not be complete or consistent. It is more like what Barwise and Perry call a ‘situation’. Conditionals are quantifiers over events, as follows:\n\nP if Q = P in any event in which Q\nP only if Q = P in no event other than one in which Q\nP even if Q = P in any event including any in which Q (17)\n\nThe quantifiers here are contextually restricted. Lycan includes in the semantic analysis a predicate of events R, whose role is to restrict the quantifiers over events. An event satisfies R only if it is ‘envisaged’, which is similar to saying it is a ‘real’ or ‘relevant’ possibility. The value of R changes frequently; sometimes it even changes mid-sentence. This fact is appealed to frequently in explaining some surprising behaviour of conditionals. For example, the invalidity of antecedent-strengthening: if p then r, so if p and q then r, is explained by saying the class of events relevant to the truth of the conclusion may be larger than the class of events relevant to the truth of the premise. In particular, at least one event in which p and q is relevant to the conclusion, but no such event need be relevant to the premise. A similar explanation is given for the failure of transitivity and contraposition.\nThe quantifier domain must include some non-actual events or conditionals will turn into material implications. Surprisingly, Lycan says that sometimes the quantifier includes only non-actual events. In these cases, it is possible that all (relevant) p-events can be q-events, even though p is true but not q. That is, in these cases modus ponens is invalid. Lycan argues persuasively that the case against modus ponens is at least as strong as the case against antecedent-strengthening, contraposition and modus tollens.\nThere is an extended discussion of ‘even’, which is necessary for providing a theory of ‘even if’. Lycan first suggests that Even Grannie was sober means Everyone, including Grannie, was sober. The quantifier domain includes everyone no less likely than Grannie to be sober. After discussing some counterexamples, Lycan suggests that instead it means Everyone plus Grannie was sober, where the quantifer ranges over everyone whom you would expect to be sober. Lycan is committed to ‘even’ being a quantifier because of its syntactic similarity to ‘only’, and because of the “initial plausibility of … universally quantified paraphrases” (121) of sentences involving ‘even’. The discussion here is fascinating, but not conclusive. It isn’t clear, for example, that ‘even’ and ‘only’ have the same syntactic role. Compare Even supposing Jack were here, he wouldn’t help with *Only supposing Jack were here, he wouldn’t help.\nLycan also includes a helpful discussion of how his theory handles Allan Gibbard’s ‘Riverboat Puzzle’ and related cases. It is troubling, for those who don’t analyse conditionals as material implications, that sometimes one speaker can say If p, q, another can say If p, not q, and both seem to be speaking truly. Lycan argues we should accept this troubling consequence, but explain it by making R sensitive to epistemic considerations.\nAs well as these points, Lycan raises some powerful objections to ‘No Truth Value’ theories of conditionals, and against the extensive use of probability theory in semantics. The book concludes with two appendicies on ‘non-conditional’ conditionals, such as If you’re hungry, there’s biscuits on the sideboard.\nThere’s a lot to like about this book, not least it’s witty, even charming, style. Lycan considers more examples, from more diverse sources, than most writers. The theory he presents is innovative and at least aims to be comprehensive. And of course there are some good arguments for it. Despite this there are, as always, occasional grounds for complaint.\nAlthough Lycan is very careful to get the syntax of ‘if’ right, and proves that unlike ‘and’ and ‘or’ it is not a co-ordinating conjunction, it is not so clear that the syntactic evidence provides distinctive support for his semantic theory. If it’s consistent with the syntax to say p if q means All relevant q-events are p-events, it’s consistent with the syntax to say that it means All nearby q-worlds are p-worlds. So the syntactic argument for preferring Lycan’s theory, to, say, Stalnaker’s, is not obviously overpowering. Lycan suggests that we can naturally paraphrase conditionals as quantifications over events, but since he is using event ‘in a slightly uncommon way’ (17) it is not obvious what support this gives for his theory.\nThere are few reasons to favour the use of events rather than worlds in the analysis. The fact that events can be incomplete seems to only cause complications for the theory. The fact that they can be inconsistent is used to rescue some intuitions about conditionals with impossible antecedents, but many would argue those intuitions should be discarded.\nBut the main worry is that Lycan needs to say more about some key notions, particularly about his R and about validity. In the discussion of the Riverboat Puzzle, Lycan says, “I do not have a good enough intuitive handle on my own notion of ‘relevance’ to provide a crushing answer [to a question about why certain events are not covered by R].” (173)  Lycan says that for an event to be R, “the utterer must have it at least tacitly in mind as a live prospect.” (19) All events in R are ‘envisaged’, to use the term he lands on. But “there is somethig slightly artificial or stylized about ‘envisaging’ … ‘Envisaging’ is not a purely de facto cognitive or other psychological state.” (30) The upshot is that the envisaged possibilities are some, but not always all, of those that are (possibly tacitly) regarded as live. Just which possibilities then? We are never given a specific account. Any account we do get is, as in the above quote, almost immediately qualified. Since R does so much work, the reader is probably owed a little more here. (This point is made at greater length in Ken Turner’s excellent review of Real Conditionals in the Journal of Pragmatics forthcoming.)\nWe are also never specifically given an account of validity. We are told that several argument forms, from antecedent-strengthening to modus ponens, are invalid. This seems to mean that one could assert their premises then reject, or a least decline to assert, their conclusion. It’s important that this process of assertion and rejection take place in real time, because the value of R needs to change for the arguments to be invalid. Lycan has some arguments that this conception of validity is the philosophically interesting one, but this deserves more treatment. The logical reforms it draws in go well beyond the logic of conditionals. On Lycan’s approach, All swans are white, so all Australian swans are white is, presumably, invalid, since the scope of the quantifier could change from premise to conclusion. And contraposition fails for valid arguments. Contraposed modus ponens: p, not q, so not if p, q is valid, but modus ponens is not.\nNone of this is to deny that Real Conditionals is a great contribution to the literature, and if it causes more theorists to pay serious attention to Lycan’s Event Theory, that would be an excellent consequence."
  },
  {
    "objectID": "posts/sre/index.html",
    "href": "posts/sre/index.html",
    "title": "Scepticism, Rationalism, and Externalism",
    "section": "",
    "text": "This paper is about three of the most prominent debates in modern epistemology. The conclusion is that three prima facie appealing positions in these debates cannot be held simultaneously.\n\nPublished in Oxford Studies in Epistemology 1: 311-31.\n\nThe first debate is scepticism vs anti-scepticism. My conclusions apply to most kinds of debates between sceptics and their opponents, but I will focus on the inductive sceptic, who claims we cannot come to know what will happen in the future by induction. This is a fairly weak kind of scepticism, and I suspect many philosophers who are generally anti-sceptical are attracted by this kind of scepticism. Still, even this kind of scepticism is quite unintuitive. I’m pretty sure I know (1) on the basis of induction.\n\nThis paper has been presented at Cornell University and the Inland Northwest Philosophy Conference, and each time I received valuable feedback.\n\n\nIt will snow in Ithaca next winter.\n\nAlthough I am taking a very strong version of anti-scepticism to be intuitively true here, the points I make will generalise to most other versions of scepticism. (Focussing on the inductive sceptic avoids some potential complications that I will note as they arise.)\n\nThanks also to David Chalmers, Harold Hodes, Nicholas Sturgeon and, especially, Tamar Szabó Gendler for very helpful comments on various drafts of the paper.\n\nThe second debate is a version of rationalism vs empiricism. The kind of rationalist I have in mind accepts that some deeply contingent propositions can be known a priori, and the empiricist I have in mind denies this. Kripke showed that there are contingent propositions that can be known a priori. One example is Water is the watery stuff of our acquaintance. (‘Watery’ is David Chalmers’s nice term for the properties of water by which folk identify it.) All the examples Kripke gave are of propositions that are, to use Gareth Evans’s term, deeply necessary (Evans 1979). It is a matter of controversy presently just how to analyse Evans’s concepts of deep necessity and contingency, but most of the controversies are over details that are not important right here. I’ll simply adopt Stephen Yablo’s recent suggestion: a proposition is deeply contingent if it could have turned out to be true, and could have turned out to be false [Yablo (2002)]1. Kripke did not provide examples of any deeply contingent propositions knowable a priori, though nothing he showed rules out their existence.\n1 If you prefer the ‘two-dimensional’ way of talking, a deeply contingent proposition is one that is true in some possible world ‘considered as actual’. See Chalmers (2006) for a thorough discussion of ways to interpret this phrase, and the broader notion of so-called ‘deep’ contingency. Nothing that goes on here will turn on any of the fine distinctions made in that debate - the relevant propositions will be deeply contingent in every plausible sense.2 That a property is introspective does not mean that whenever a subject instantiates it she is in a position to form a not too badly mistaken belief about it. Even if the subject instantiates the property she may not possess sufficient concepts in order to have beliefs about it. And even if she has the concept she may simply have more pressing cognitive needs than forming certain kinds of belief. Many agents have no beliefs about the smell in their ordinary environment much of the time, for example, and this does not show that phenomenal smell properties are not introspective. All that is required is that if she has any beliefs at all about which determinate she instantiates, the beliefs are immune to massive error.The final debate is a version of internalism vs externalism about epistemic justification. The internalist I have in mind endorses a very weak kind of access internalism. Say that a class of properties (intuitively, a determinable) is introspective iff any beliefs an agent has about which property in the class (which determinate) she instantiates are guaranteed to not be too badly mistaken.2 (Since ‘too badly’ is vague, ‘introspective’ will be vague too, but as we’ll see this won’t matter to the main argument.) My internalist believes the following two claims:\n\nWhich propositions an agent can justifiably believe supervenes in which introspective properties she instantiates, and this is knowable a priori.3\nThere exist some introspective properties and some deeply contingent propositions about the future such that it’s a priori that whoever instantiates those properties can justifiably believe those propositions.\n\n3 There is a delicate ambiguity in this expression to which a referee drew my attention. The intended meaning is that for any two agents who instantiate the same introspective properties, belief in the same propositions is justified. What’s not intended is that if there’s an agent who justifiably believes p, and the introspective properties they instantiate are F1, …, Fn, then any agent who instantiates F1, …, Fn is justified in believing p. For there might be some other introspective property Fn+1 they instantiate that justifies belief in q, and q might be a defeater for p. The ‘unintended’ claim would be a very strong, and very implausible, claim about the subvenient basis for justification.My externalist denies one or other of these claims. Typically, she holds that no matter what introspective properties you have, unless some external condition is satisfied (such as the reliability of the connection between instantiating those properties and the world being the way you believe it is) you lack justification. Alternatively, she holds that the connection between introspective properties and justification is always a posteriori. (Or, of course, she might deny both.)\nMy argument will be that the combination of anti-scepticism, empiricism and internalism is untenable. Since there’s quite a bit to be said for each of these claims individually, that their combination is untenable means we are stuck with a fairly hard choice: accept scepticism, or rationalism, or externalism. Of the three, it may seem that externalism is the best, but given how weak the version of internalism is that I’m using, I think we should take the rationalist option seriously.4 In this paper I’ll just argue against the combination of anti-scepticism, empiricism and internalism, and leave it to the reader to judge which of the three to reject.\n4 Rationalism is supported by BonJour (1997) and Hawthorne (2002), and my argument owes a lot to each of their discussions.Very roughly, the argument for the trilemma will be as follows. There are some propositions q such that these three claims are true.\n\nIf anti-scepticism is true, then I either know q a priori or a posteriori.\nIf internalism and empiricism is true, I do not know q a priori.5\nIf internalism is true, I do not know q a posteriori.\n\n5 Aesthetically it would be preferable to have the antecedent of this claim be just that empiricism is true, but unfortunately this does not seem to be possible.6 I.e. I am not a brain-in-a-vat* in the sense of Cohen (1999)Much of the paper will be spent giving us the resources to find, and state, such a q, but to a first approximation, think of q as being a proposition like I am not a brain-in-a-vat whose experiences are as if they were a normal person.6 The important features of q are that (a) it is entailed by propositions we take ourselves to know, (b) it is possibly false and (c) if something is evidence for it, then any evidence is evidence for it. I will claim that by looking at propositions like this, propositions that say in effect that I am not being misled in a certain way, it is possible to find a value for q such that (2), (3) and (4) are all true. From that it follows that\nFor most of the paper I will assume that internalism and anti-scepticism are true, and use those hypotheses to derive rationalism. The paper will conclude with a detailed look at the role internalism plays in the argument, and this will give us some sense of what an anti-sceptical empiricist externalism may look like.\n\n0.1 A Sceptical Argument\nAmong the many things I know about future, one of the firmest is (1).\n\nIt will snow in Ithaca next winter.\n\nI know this on the basis of inductive evidence about the length of meteorological cycles and the recent history of Ithaca in winter. The inductive sceptic now raises the spectre of Winter Wonderland, a kind of world that usually has the same meteorological cycles as ours, and has the same history, but in which it is sunny every day in Ithaca next winter.7 She says that to know (1) we must know that (5) is false, and we do not.\n7 If she is convinced that there is no possible world with the same history as ours and no snow in Ithaca next winter, the sceptic will change her story so Winter Wonderland’s past differs imperceptibly from the past in our world. She doesn’t think this issue is particularly relevant to the epistemological debate, no matter how interesting the scientific and metaphysical issues may be, and I agree with her.\nI am living in Winter Wonderland.\n\nJust how does reflection (5) affect my confidence that I know (1)? The sceptic might just appeal to the intuition that I don’t know that (5) is false. But I don’t think I have that intuition, and if I do it is much weaker than my intuition that I know (1) and that I can infer (5) from (1). James Pryor (2000, 527–29) has suggested the sceptic is better off using (5) in the following interesting argument.8\n8 Pryor is discussing the external world sceptic, not the inductive sceptic, so the premises here are a little different to those he provides.\nEither you don’t know you’re not living in Winter Wonderland; or, if you do know that, it’s because that knowledge rests in part on your inductive knowledge that it will snow in Ithaca next winter.\nIf you’re to know (1) on the basis of certain experiences or grounds e, then for every q which is “bad” relative to e and (1), you have to be in a position to know q to be false in a non-question-begging way—i.e., you have to be in a position to know q to be false antecedently to knowing that it will snow next winter on the basis of e.\n(5) is “bad” relative to any course of experience e and (1).\nYou can’t know (1), that it will snow next winter on the basis of your current experiences.\n\nAn alternative hypothesis q is “bad” in the sense used here iff (to quote Pryor) “it has the special features that characterise the sceptic’s scenarios—whatever those features turn out to be.” (527) To a first approximation, q is bad relative to p and e iff you’re meant to be able to know p on the basis of e, but q is apparently compatible with e, even though it is not compatible with p.\nPryor argues that the best response to the external world sceptic is dogmatism. On this theory you can know p on the basis of e even though you have no prior reason to rule out alternatives to p compatible with e. Pryor only defends the dogmatic response to the external world sceptic, but it’s worth considering the dogmatist response to inductive scepticism. According to this response, I can come to know I’m not in Winter Wonderland on the basis of my experiences to date, even though I didn’t know this a priori. So dogmatism is a version of empiricism, and it endorses (6).9 The false premise in this argument, according to the dogmatist, is (7). We can know it will snow even though the Winter Wonderland hypothesis is bad relative to this conclusion and our actual evidence, and we have no prior way to exclude it.\n9 It is a version of the kind of internalism discussed in footnote 2, since according to the dogmatist seeming to see that p can be sufficient justification for belief in p. Pryor’s preferred version of dogmatism is also internalist in the slightly stronger sense described in the text, but it seems possible that one could be a dogmatist without accepting that internalist thesis. One could accept, for instance, that seeming to see that p justifies a belief that p, but also think that seeming to see that q justifies a belief that p iff there is a known reliable connection between q and p. As I said, even the weaker version of internalism is sufficient to generate a conflict with anti-scepticism and empiricism, provided we just focus on the propositions that can be justifiably believed on the basis of introspective properties.Pryor notes that the sceptic could offer a similar argument concerning justification, and the dogmatist offers a similar response.\n\nEither you’re not justified in believing that you’re not in Winter Wonderland; or, if you are justified in believing this, it’s because that justification rests in part on your justified belief that it will snow in Ithaca next winter.\nIf you’re to have justification for believing (1) on the basis of certain experiences or grounds e, then for every q which is “bad” relative to e and (1), you have to have antecedent justification for believing q to be false—justification which doesn’t rest on or presuppose any e-based justification you may have for believing (1).\n(5) is “bad” relative to any course of experience e you could have and (1).\nYou can’t justifiably believe it will snow in Ithaca next winter on the basis of past experiences.\n\nThe dogmatist rejects (10), just as she rejects (7). I shall spend most of my time in the next two sections arguing for (10), returning to (7) only at the end. For it seems there are compelling reasons to accept (10), and hold that the problem with this argument is either with (9) or (11).10\n10 Just which is wrong then? That depends on how “bad” is defined. On our final definition (8) will fail, but there are other sceptical arguments, using other sceptical hypotheses, on which (6) fails.\n\n0.2 Dominance Arguments\nThe primary argument for (10) will turn on a dominance principle: if you will be in a position to justifiably believe p whatever evidence you get, and you know this, then you are now justified in believing p. This kind of reasoning is perfectly familiar in decision theory: if you know that one of n states obtains, and you know that in each of those states you should do X rather than Y, then you know now (or at least you should know) that you should do X rather than Y. This is a very plausible principle, and equivalent epistemic principles are just as viable. Dominance reasoning can directly support (10) and hence indirectly support (7). (As Vann McGee (1999) showed, the dominance principle in decision theory has to be qualified for certain kinds of agents with unbounded utility functions who are faced with a decision tree with infinitely many branches. Such qualifications do not seem at all relevant here.)\nIt will be useful to start with an unsound argument for (10), because although this argument is unsound, it fails in an instructive way. Before I can present the argument I need to make an attempt at formalising Pryor’s concept of badness.\n\nq is bad relative to e and p =df q is deeply contingent, you know p entails \\(\\neg\\)q, and for any possible evidence e\\(^\\prime\\) (that you could have had at the time your total evidence is actually e) there exists a p\\(^\\prime\\) such that you know p\\(^\\prime\\) entails \\(\\neg\\)q and you are justified in believing p\\(^\\prime\\) on the basis of e\\(^\\prime\\) if e\\(^\\prime\\) is your total evidence.\n\nRoughly, the idea is that a bad proposition is one that would be justifiably ruled out by any evidence, despite the fact that it could turn out to be true.11 Using this definition we can present an argument for rationalism. The argument will use some fairly general premises connecting justification, evidence and badness. If we were just interested in this case we could replace q with (5), r with the proposition that (5) is false, e with my current evidence, and e\\(^\\prime\\) with some evidence that would undermine my belief that (5) is false, if such evidence could exist. The intuitions behind the argument may be clearer if you make those substitutions when reading through the argument. But because the premises are interesting beyond their application to this case, I will present the argument in its more general form.\n11 Note that there’s a subtle shift here in our conception of badness. Previously we said that bad propositions are those you allegedly know on the basis of your actual evidence (if you know p) even though they are logically consistent with that evidence. Now we say that they are propositions you could rule out on any evidence, even though they are consistent with your actual total evidence. This is a somewhat narrower class of proposition, but focussing on it strengthens the sceptic’s case appreciably.\nIf you are justified in believing (1) on the basis of e, and you know (1) entails \\(\\neg\\)(5), then you are justified in believing \\(\\neg\\)(5) when your evidence is e.\nIf you are justified in believing r (at time t) on the basis of e, then there is some other possible evidence e\\(^\\prime\\) (that you could have at t) such that you would not be justified in believing r were your total evidence e\\(^\\prime\\).\nIf you are justified in believing r, and there is no evidence e such that e is part of your evidence and you are justified in believing r on the basis of e, then you are justified in believing r a priori.12\nBy definition, q is bad relative to e and p iff q is deeply contingent, you know p entails \\(\\neg\\)q, and for any possible evidence e\\(^\\prime\\) (that you could have when your evidence is e) there exists a p\\(^\\prime\\) such that you know p\\(^\\prime\\) entails \\(\\neg\\)q and you are justified in believing p\\(^\\prime\\) on the basis of e\\(^\\prime\\) if e\\(^\\prime\\) is your total evidence.\nSo, if q is bad relative to e and (1), and you are justified in believing (1) on the basis of e, then you are justified in believing \\(\\neg\\)q a priori.\n\n12 {#fnt:ftn13 label=“fnt:ftn13”} David Chalmers noted that (10) and (11) entail that I exist is a priori. He thought this was a bad result, and a sufficient reason to modify these premises. I’m perfectly happy with saying, following Kaplan, that I exist is a priori. I don’t think this proves rationalism, because I think it’s also deeply necessary that I exist. (It’s not deeply necessary that Brian exists, but that’s no objection to what I just claimed, because it’s not deeply necessary that I’m Brian.)\nThis position is controversial though, so I don’t want to rest too much weight on it. If you don’t think that I exist should be a priori, rewrite (11) so that it’s conclusion is that you would be justified in believing the material conditional I exist \\({\\supset}\\) r a priori. (Note that since I’m presupposing in the dominance argument that all the salient possibilities are ones in which I have some evidence, and hence exist, it’s not surprising that I exist has a special status within the theory.)\nOn a separate point, note that I make no assumptions whatsoever here about what relationship must obtain between a justified belief and the evidence on which it is based. Depending on what the right theory of justification is, that relationship might be entailment or constitution or causation or association or reliable connection or something else or some combination of these. I do assume that a posteriori beliefs are somehow connected to evidence, and if the beliefs are justified this relation is properly called basing.(The references to times in (13) and (15) is just to emphasise that we are talking about your current evidence, and ways it could be. That you could observe Winter Wonderland next winter doesn’t count as a relevant alternative kind of evidence now.)\nOur conclusion (16) entails (10), since (10) merely required that for every bad proposition relative to e and (1), you have ‘antecedent’ justification for believing that proposition to be false, while (16) says this justification is a priori. (‘Antecedent’ justification need not be a priori as long as it arrives before the particular evidence you have for (1). This is why (16) is strictly stronger than (10).) So if (10) is false then one of these premises must be false. I take (15) to define “bad”, so it cannot be false. Note that given this definition we cannot be certain that (5) is bad. We will return to this point a few times.\nWhich premise should the dogmatist reject? (12) states a fairly mundane closure principle for justified belief. And (13) follows almost automatically from the notion of ‘basing’. A belief can hardly be based in some particular evidence if any other evidence would support it just as well. This does not mean that such a belief cannot be rationally caused by the particular evidence that you have, just that the evidence cannot be the rational basis for that belief. The dogmatist objects to (14). There is a prima facie argument for (14), but as soon as we set it out we see why the dogmatist is correct to stop us here.\nConsider the following argument for (14), which does little more than lay out the intuition (14) is trying to express. Assume r is such that for any possible evidence e, one would be justified in believing r with that evidence. Here’s a way to reason a priori to r. Whatever evidence I get, I will be justified in believing that q. So I’m now justified in believing that r, before I get the evidence. Compare a simple decision problem where there is one unknown variable, and it can one of two values, but whichever value it takes it is better for one to choose X rather than Y. That is sufficient to make it true now that one should choose X rather than Y. Put this way, the argument for (14) is just a familiar dominance argument.\nTwo flaws with this argument for (14) stand out, each of them arising because of disanalogies with the decision theoretic case.\nFirst, when we apply dominance reasoning in decision theory, we look at cases where it would be better to take X rather than Y in every possible case, and this is known. This point is usually not stressed, because it’s usually just assumed in decision theory problems that the players know the consequences of their actions given the value of certain unknown variables. It’s not obviously a good idea to assume this without comment in applications of decision theory, and it’s clearly a bad idea to make the same kind of assumption in epistemology. Nothing in the antecedent of (14) specifies that we can know, let alone know a priori, that if our evidence is e then we are justified in believing r. Even if this is true, even if it is necessarily true, it may not be knowable.\nSecond, in the decision theory case we presupposed it is known that the variable can take only one of two values. Again, there in nothing in the antecedent of (14) to guarantee the parallel. Even if an agent knows of every possible piece of evidence that if she gets that evidence she will be justified in believing r, she may not be in a position to justifiably conclude r now because she may not know that these are all the possible pieces of evidence. In other words, she can only use dominance reasoning to conclude r if she knows de dicto, and not merely de re, of every possible body of evidence that it justifies r.\nSo the quick argument for (14) fails. Still, it only failed because (14) left out two qualifications. If we include those qualifications, and adjust the other premises to preserve validity, the argument will work. To make this adjustment, we need a new definition of badness.\n\nq is bad relative to e and p =df\n\nq is deeply contingent;\np is known to entail \\(\\neg\\)q; and\nit is knowable a priori that for any possible evidence e\\(^\\prime\\) there exists a p\\(^\\prime\\) such that p\\(^\\prime\\) is known to entail \\(\\neg\\)q, and one is justified in believing p\\(^\\prime\\) on the basis of e\\(^\\prime\\).\n\n\nThe aim still is to find an argument for some claim stronger than (10) in sceptical argument 2. If we can do that, and if as the sceptic suggests (5) really is bad, then the only anti-sceptical response to sceptical argument 2 will be rationalism. So the fact that this looks like a sound argument for a slightly stronger conclusion than (10) is a large step in our argument that anti-scepticism plus internalism entails rationalism. (I omit the references to times from here on.)\n\nIf you are justified in believing (1) on the basis of e, and you know (1) entails \\(\\neg\\)(5), then you are justified in believing \\(\\neg\\)(5) when your evidence is e.\nIf you are justified in believing r on the basis of e, then there is some other possible evidence e\\(^\\prime\\) such that you would not be justified in believing r were your total evidence e\\(^\\prime\\).\nIf you know you are justified in believing r, and you know a priori that there is no evidence e you have such that you are justified in believing r on the basis of e, then you are justified in believing r a priori.13\nBy definition, q is bad relative to e and p iff q is deeply contingent, p is known to entail \\(\\neg\\)q, and it is knowable a priori that for any possible evidence e\\(^\\prime\\) there exists a p\\(^\\prime\\) such that p\\(^\\prime\\) is known to entail \\(\\neg\\)q, and one is justified in believing p\\(^\\prime\\) on the basis of e\\(^\\prime\\).\nSo, if q is bad relative to e and (1), and you are justified in believing (1) on the basis of e, then you are justified in believing \\(\\neg\\)q a priori.\n\n13 Again, if you don’t think I exist should be a priori, the conclusion should be that I exist \\({\\supset}\\) r is a priori.This is a sound argument for (19), and hence for (10), but as noted on this definition of “bad” (11) may be false. If the Winter Wonderland hypothesis is to be bad it must be a priori knowable that on any evidence whatsoever, you’d be justified in believing it to be false. But as we will now see, although no evidence could justify you in believing the Winter Wonderland hypothesis to be true, it is not at all obvious that you are always justified in believing it is false.\n\n\n0.3 Hunting the Bad Proposition\nA proposition is bad if it is deeply contingent but if you could justifiably believe it to be false on the basis of your current evidence, you could justifiably believe it to be false a priori. If a bad proposition exists, then we are forced to choose between rationalism and scepticism. To the extent that rationalism is unattractive, scepticism starts to look attractive. I think Pryor is right that this kind of argument tacitly underlies many sceptical arguments. The importance of propositions like (5) is not that it’s too hard to know them to be false. The arguments of those who deny closure principles for knowledge notwithstanding, it’s very intuitive that it’s easier to know (5) is false than to know (1) is true. So why does reflection on (5) provide more comfort to the inductive sceptic than reflection on (1)? The contextualist has one answer, that thinking about (5) moves the context to one where sceptical doubts are salient. Pryor’s work suggests a more subtle answer. Reflecting on (5) causes us to think about how we could come to know it is false, and prima facie it might seem we could not know that a priori or a posteriori. It’s that dilemma, and not the mere salience of the Winter Wonderland possibility, that drives the best sceptical argument. But this argument assumes that (5) could not be known to be false on the basis of empirical evidence, i.e. that it is bad. If it is not bad, and nor is any similar proposition, then we can easily deflect the sceptical argument. However, if we assume internalism, we can construct a bad proposition.\nThe prima facie case that (5) is bad (relative to (1) and our current evidence e – I omit these relativisations from now on) looks strong. The negation of (5) is (20), where H is a proposition that summarises the relevant parts of the history of the world.14\n14 I assume H includes a ‘that’s all that’s relevant clause’ to rule out defeaters. That is, it summaries the relevant history of the world as such.\nEither \\(\\neg\\)H or it will snow in Ithaca next winter.\n\nNow one may argue that (5) is bad as follows. Either our evidence justifies believing \\(\\neg\\)H or it doesn’t. If it does, then it clearly justifies believing (20), for \\(\\neg\\)H trivially entails it. If it does not, then we are justified in believing H, and whenever we are justified believing the world’s history is H, we can inductively infer that it will snow in Ithaca next winter. The problem with this argument, however, is fairly clear: the step from the assumption that we are not justified in believing \\(\\neg\\)H to the conclusion we are justified in believing H is a modal fallacy. We might be justified in believing neither H nor its negation. In such a situation, it’s not obvious we could justifiably infer (20). So (5) may not be bad.\nA suggestion John Hawthorne (2002) makes seems to point to a proposition that is more plausibly bad. Hawthorne argues that disjunctions like (21) are knowable a priori, and this suggests that (22), its negation, is bad.\n\nEither my evidence is not e or it will snow in Ithaca next winter.\nMy evidence is e and it will not snow in Ithaca next winter.\n\nHawthorne does not provide a dominance argument that (21) is knowable a priori. Instead he makes a direct appeal to the idea that whatever kinds of inference we can draw now the basis of our evidence we could have drawn prior to getting e as conditional conclusions, conditional on getting e. So if I can now know it will snow in Ithaca next winter, prior to getting e I cold have known the material conditional If my evidence is e, it will snow in Ithaca, which is equivalent to (21). It’s not clear this analogy works, since when we do such hypothetical reasoning we take someone to know that our evidence is e, and this may cause some complications. Could we find a dominance argument to use instead? One might be tempted by the following argument.\n\nI know a priori that if my evidence is e, then I am justified in believing the second disjunct of (21).\nI know a priori that if my evidence is not e, then I am justified in believing the first disjunct of (21)\nI know a priori that if I am justified in believing a disjunct of (21) I am justified in believing the disjunction (21).\nI know a priori that my evidence is either e or not e.\nSo, I’m justified a priori in believing (21).\n\nThe problem here is the second premise, (24). It’s true that if my evidence is not e then the first disjunct of (21) is true. But there’s no reason to suppose I am justified in believing any true proposition about my evidence. Timothy (Williamson 2000 ch. 8) has argued that the problem with many sceptical arguments is that they assume agents know what their evidence is. I doubt that’s really the flaw in sceptical arguments, but it certainly is the flaw in the argument that (22) is bad.\nThe problem with using (22) is that the argument for its badness relied on quite a strong privileged access thesis: whenever my evidence is not e I am justified in believing it is not. If we can find a weaker privileged access thesis that is true, we will be able to find a proposition similar to (22) that is bad. And the very argument Williamson gives against the thesis that we always know what our evidence is will show us how to find such a thesis.\nWilliamson proposes a margin-of-error model for certain kinds of knowledge. On this model, X knows that p iff (roughly) p is true in all situations within X’s margin-of-error.15 The intuitive idea is that all of the possibilities are arranged in some metric space, with the distance between any two worlds being the measure of their similarity with respect to X. Then X knows all the things that are true in all worlds within some sphere centred on the actual world, where the radius of that sphere is given by how accurate she is at forming beliefs.\n15 There’s a considerable amount of idealisation here. What’s really true is that X is in a position to know anything true in all situations within her margin-of-error. Since we’re working out what is a priori knowable, I’ll assume agents are idealised so they know what they are in a position to know. This avoids needless complications we get from multiplying the modalities that are in play.One might think this would lead to the principle B: p \\({\\rightarrow}\\) K\\(\\neg\\)K\\(\\neg\\)p, that is, if p is true then X knows that she does not know \\(\\neg\\)p. Or, slightly more colloquially, if p is true then X knows that for all she knows p is true. (I use K here as a modal operator. KA means that X, the salient subject, knows that A.) On a margin-of-error model p \\({\\rightarrow}\\) K\\(\\neg\\)K\\(\\neg\\)p is false only if p is actually true and there is a nearby (i.e. within the margin-of-error) situation where the agent knows \\(\\neg\\)p. But if nearby is symmetric this is impossible, because the truth of p in this situation will rule out the knowability of \\(\\neg\\)p in that situation.\nAs Williamson points out, that quick argument is fallacious, since it relies on a too simplistic margin-of-error model. He proposes a more complicated account: p is known at s iff there is a distance d greater than the margin-of-error and for any situation s\\(^\\prime\\) such that the distance between s and s\\(^\\prime\\) is less than d, p is true at s\\(^\\prime\\). Given this model, we cannot infer p \\({\\rightarrow}\\) K\\(\\neg\\)K\\(\\neg\\)p. Indeed, the only distinctive modal principle we can conclude is Kp \\({\\rightarrow}\\) p. However, as Delia Graff Fara (2002) has shown, if we make certain density assumptions on the space of available situations, we can recover the principle (27) within this account.16\n16 If we translate K as \\(\\square\\) and \\(\\neg\\)K\\(\\neg\\) as \\(\\diamond\\), (24) can be expressed as the modal formula p \\({\\rightarrow}\\) \\(\\square\\)\\(\\diamond\\)\\(\\diamond\\)p.\np \\({\\rightarrow}\\) K\\(\\neg\\)KK\\(\\neg\\)p\n\nTo express the density assumption, let d(s1, s2) be the ‘distance’ between s1 and s2, and m the margin-of-error. The assumption then is that there is a k &gt; 1 such that for any s1, s2 such that d(s1, s2) &lt; km, there is an s3 such that d(s1, s3) &lt; m and d(s3, s2) &lt; m. And this will be made true if there is some epistemic situation roughly ‘half-way’ between s1 and s2.17 That is, all we have to assume to recover (27) within the margin-of-error model is that the space of possible epistemic situations is suitably dense. Since the margin-of-error model, and Fara’s density assumption, are both appropriate for introspective knowledge, (27) is true when p is a proposition about the agent’s own knowledge.\n17 Fara actually gives a slightly stronger principle than this, but this principle is sufficient for her purposes, and since it is weaker than Fara’s, it is a little more plausible. But the underlying idea here, that we can get strong modal principles out of margin-of-error models by making plausible assumptions about density, is taken without amendment from her paper.18 If you preferred the amended version of (11) discussed in footnote 12, the bad proposition is I don’t exist or (28) is true.To build the bad proposition now, let G be a quite general property of evidence, one that is satisfied by everyone with a reasonable acquaintance with Ithaca’s weather patterns, but still precise enough that it is a priori that everyone whose evidence is G is justified in believing it will snow in Ithaca next winter. The internalist, remember, is committed to such a G existing and it being an introspective property. Now consider the following proposition, which I shall argue is bad.18\n\nI know that I know my evidence is G, and it will not snow in Ithaca next winter.\n\nThe negation of (28) is (29).\n\nIt will snow in Ithaca next winter, or I don’t know that I know my evidence is G.\n\nIt might be more intuitive to read (29) as the material conditional (29a), though since English conditionals aren’t material conditionals this seems potentially misleading.\n\nIf I know that I know that my evidence is G, then it will snow in Ithaca next winter.\n\nTo avoid confusions due to the behaviour of conditionals, I’ll focus on the disjunction (29). Assume for now that the margin-of-error model is appropriate for propositions about my own evidence. I will return below to the plausibility of this assumption. This assumption implies that principle (27) is always correct when p is a proposition about my evidence. Given this, we can prove (28) is bad. Note that all my possible evidential states either are, or are not, G. If they are G then by hypothesis I am justified in believing that it will snow in Ithaca next winter and hence I am justified in believing (29). If they are not, then by the principle (27) I know that I don’t know that I know my evidence is G, so I can come to know (29), so I am justified in believing (29). So either way I am justified in believing (29). It’s worth noting that at no point here did I assume that I knew whether my evidence was G, though I do assume that I know that having evidence that is G justifies belief in snow next winter.\nAll of this assumes the margin-of-error model looks appropriate for introspective properties. If it isn’t, then we can’t assume that (27) is true when p is a proposition about the introspective properties I satisfy, and hence the argument that (29) is knowable a priori fails. There’s one striking problem with assuming a priori that we can use the margin-of-error model in all situations. It is assumed (roughly) that anything that is true in all possibilities within a certain sphere with the subject’s beliefs at the centre is known. This sphere must include the actual situation, or some propositions that are actually false may be true throughout the sphere. Since for propositions concerning non-introspective properties there is no limit to how badly wrong the subject can be, we cannot set any limits a priori to the size of the sphere. So a priori the only margin-of-error model we can safely use is the sceptical model that says the subject knows that p iff p is true in all situations. For introspective properties the margin-of-error can be limited, because it is constitutive of introspective properties that the speakers beliefs about whether they possess these properties are not too far from actuality. So there seems to be no problem with using Williamson’s nice model as long as we restrict our attention to introspective properties.\nIf belief in (29) can be justified a priori, and it is true, does that mean it is knowable a priori? If we want to respect Gettier intuitions, then we must not argue directly that since our belief in (29) is justified, and it is true, then we know it. Still, being justified and true is not irrelevant to being known. I assume here, far from originally, that it is a reasonable presumption that any justified true belief is an item of knowledge. This presumption can be defeated, if the belief is inferred from a false premise, or if the justification would vanish should the subject acquire some evidence she should have acquired, or if there is a very similar situation in which the belief is false, but it is a reasonable presumption. Unless we really are in some sceptical scenario, there is no “defeater” that prevents our belief in (29) being an item of knowledge. We certainly did not infer it from a false premise, there is no evidence we could get that would undermine it, and situations in which it is false are very far from actuality.\nSince there are no such defeaters, it is reasonable to infer we can know (29) a priori. The important premises grounding this inference are an anti-sceptical premise, that we can know (1) on the basis of our current evidence, and the internalist premise that we used several times in the above argument. This completes the argument that the combination of empiricism, internalism and anti-scepticism is untenable.\n\n\n0.4 How Externalism Helps\nIt should be obvious how the rationalist can respond to the above argument - by simply accepting the conclusion. Ultimately I think that’s the best response to this argument. As Hawthorne notes, rationalism is the natural position for fallibilists about knowledge to take, for it is just the view that we can know something a priori even though we could turn out to be wrong. In other words, it’s just fallibilism about a priori knowledge. Since fallibilism about a posteriori knowledge seems true, and there’s little reason to think fallibilism about the a priori would be false if fallibilism about the a posteriori is true, the rationalist’s position is much stronger than many have assumed.19 The inductive sceptic also has an easy response - reject the initial premise that in my current situation I know that it will snow in Ithaca next winter. There are other responses that deserve closer attention: first, the inductive sceptic who is not a universal sceptic, and in particular is not a sceptic about perception, and second the externalist.\n19 As BonJour points out, rationalism has fallen into such disrepute that many authors leave it out even of surveys of the options. This seems unwarranted given the close connection between rationalism and the very plausible thesis of fallibilism.I said at the start that the argument generalises to most kinds of scepticism. One kind of theorist, the inductive sceptic who thinks we can nonetheless acquire knowledge through perception, may think that the argument does not touch the kind of anti-sceptical, internalist, empiricist position she adopts. The kind of theorist I have in mind says that the objects and facts we perceive are constitutive of the evidence we receive. So given we are getting the evidence we are actually getting, these objects must exist and those facts must be true. She says that if I’d started with (30), instead of (1), my argument would have ended up claiming that (31) is bad for some G.\n\nA hand exists.\nA hand exists, or I don’t know that I know that I’m perceiving a hand.\n\nShe then says that (31) is not deeply contingent, since in any situation where the first disjunct is false the second is true, so it cannot be bad. This response is correct as far as it goes, but it does not go far enough to deserve the name anti-sceptical. For it did not matter to the above argument, or to this response that (1) is about the future. All that mattered was that (1) was not entailed by our evidence. So had (1) been a proposition about the present that we cannot directly perceive, such as that it is not snowing in Sydney right now, the rest of the argument would have been unaffected. The summary here is that if one is suitably externalist about perception, so one thinks the existence of perceptual states entail the existence of the things being perceived, one can accept this argument, accept internalism, accept empiricism, and not be an external world sceptic. For it is consistent with such a position that one know the existence of the things one perceives. But on this picture one can know very little beyond that, so for most practical purposes, the position is still a sceptical one.\nThe externalist response is more interesting. Or, to be more precise, the externalist reponses are more interesting. Although I have appealed to internalism a couple of times in the above argument, it might not be so clear how the externalist can respond. Indeed, it may be worried that by exercising a little more care in various places I could have shown that everyone must accept either rationalism or scepticism. That is the conclusion Hawthorne derives in his paper on deeply contingent a priori knowledge, though as noted above he uses somewhat more contentious reasoning than I do in order to get there. To conclude, I will argue that the internalism is crucial to the argument I have presented, and I will spell out how the externalist can get out of the trap I’ve set above.\nOne easy move that’s available to an externalist is to deny that any facts about justification are a priori. That blocks the move that says we can find a G such that it’s a priori that anyone whose evidence is G can know that it will snow in Ithaca next year. This is not an essential feature of externalism. One can be an externalist about justification and still think it is a priori that if one’s evidence has the property is reliably correlated with snow in the near future then it justifies belief that it will shortly snow. But the position that all facts about justification are a posteriori fits well with a certain kind of naturalist attitude, and people with that attitude will find it easy to block the sceptical argument I’ve presented.\nCan, however, we use an argument like mine to argue against an anti-sceptic empiricist externalist who thinks some of the facts about justification can be discovered a priori? The strategy I’ve used to build the argument is fairly transparent: find a disjunctive a priori knowable proposition by partitioning the possible evidence states into a small class, and adding a disjunct for every cell of the partition. In every case, the disjunct that is added is one that is known to be known given that evidence. If one of the items of knowledge is ampliative, if it goes beyond the evidence, then it is possible the disjunction will be deeply contingent. But the disjunction is known no matter what.\nIf internalism is true, then the partition can divide up evidential states according to the introspective properties of the subject. If externalism is true, then such a partition may not be that useful, because we cannot infer much about what the subject is justified in believing from the introspective properties she instantiates. Consider, for example, the above partition of subjects into the G and the not-G, where G is some introspective property, intuitively one somewhat connected with it snowing in Ithaca next year. The subjects that are not-G know that they don’t know they know they are G, because they aren’t. Externalists need not object to this stage of the argument. They can, and should, accept that a margin-of-error model is appropriate for introspective properties. Since it’s part of the nature of introspective properties that we can’t be too badly wrong about which ones we instantiate, we’re guaranteed to satisfy some reliability clause, so there’s no ground there to deny the privileged access principle I defended above.\nThe problem is what to say about the cases where the subject is G. Externalists should say that some such subjects are justified in believing it will snow in Ithaca next winter, and some are not. For simplicity, I’ll call the first group the reliable ones and the others the unreliable ones. If I’m G and reliable, then I’m justified in believing it will snow, and hence in believing (29). But if I’m G and unreliable, then I’m not justified in believing this. Indeed, if I’m G and unreliable, there is no obvious argument that I’m justified in believing either of the disjuncts of (29). Since this is a possible evidential state, externalists should think there is no dominance argument that (29) is a priori knowable.\nCould we solve this by adding another disjunct, one that is guaranteed to be known if I’m G and unreliable? There is no reason to believe we could. If we’re unreliable, there is no guarantee that we will know we are unreliable. Indeed, we may well believe we are reliable. So there’s no proposition we can add to our long disjunction while saying to ourselves, “In the case where the subject is G and unreliable, she can justifiably believe this disjunct.” If the subject is unreliable, she may not have any justified beliefs about the external world. But this is just to say the above recipe for constructing bad propositions breaks down. Externalists should have no fear that anything like this approach could be used to construct a proposition they should find bad. This is obviously not a positive argument that anti-sceptical empiricist externalism is tenable, but it does suggest that such a position is immune to the kind of argument I have presented here.\n\n\n\n\n\n\nReferences\n\nBonJour, Laurence. 1997. In Defense of Pure Reason. Cambridge: Cambridge University Press.\n\n\nChalmers, David. 2006. “Foundations of Two-Dimensional Semantics.” In Two-Dimensional Semantics, edited by Manuel Garcia-Carpintero and Josep Macià, 55–140. Oxford: Oxford University Press.\n\n\nEvans, Gareth. 1979. “Reference and Contingency.” Monist 62: 161–89.\n\n\nFara, Delia Graff. 2002. “An Anti-Epistemicist Consequence of Margin for Error Semantics for Knowledge.” Philosophy and Phenomenological Research 64 (1): 127–42. https://doi.org/10.1111/j.1933-1592.2002.tb00146.x.\n\n\nHawthorne, John. 2002. “Deeply Contingent a Priori Knowledge.” Philosophy and Phenomenological Research 65 (2): 247–69. https://doi.org/10.1111/j.1933-1592.2002.tb00201.x.\n\n\nMcGee, Vann. 1999. “An Airtight Dutch Book.” Analysis 59 (4): 257–65. https://doi.org/10.1093/analys/59.4.257.\n\n\nPryor, James. 2000. “The Sceptic and the Dogmatist.” Noûs 34 (4): 517–49. https://doi.org/10.1111/0029-4624.00277.\n\n\nWilliamson, Timothy. 2000. Knowledge and its Limits. Oxford University Press.\n\n\nYablo, Stephen. 2002. “Coulda, Woulda, Shoulda.” In Conceivability and Possibility, edited by Tamar Szabó Gendler and John Hawthorne, 441–92. Oxford: Oxford University Press."
  },
  {
    "objectID": "posts/sims/index.html",
    "href": "posts/sims/index.html",
    "title": "Are You a Sim?",
    "section": "",
    "text": "In Will Wright’s delightful game The Sims, the player controls a neighbourhood full of people, affectionately called sims. The game has no scoring system, or winning conditions. It just allows players to create, and to some extent participate in, an interesting mini-world. Right now the sims have fairly primitive psychologies, but we can imagine this will be improved as the game evolves. The game is very popular now, and it seems plausible that it, and the inevitable imitators, will become even more popular as its psychological engine becomes more realistic. Since each human player creates a neighbourhood with many, many sims in it, in time the number of sims in the world will vastly outstrip the number of humans.\n\nPublished in Philosophical Quarterly 53: 425-431.\nPicture by Elven*Nicky via Creative Commons\n\nLet’s assume that as the sims become more and more complex, they will eventually acquire conscious states much like yours or mine. I do not want to argue for or against this assumption, but it seems plausible enough for discussion purposes. I’ll reserve the term Sim, with a capital S, for a sim that is conscious. By similar reasoning to the above, it seems in time the number of Sims in the world will far outstrip the number of humans, unless humanity either (a) stops existing, or (b) runs into unexpected barriers to computing power or (c) loses interest in these kinds of simulators. I think none of these is likely, so I think that over time the ratio of Sims to humans will far exceed 1:1.\nNick Bostrom (2003) argues that given all that, we should believe that we are probably Sims. Roughly, the argument is that we know that most agents with conscious states somewhat like ours are Sims. And we don’t have any specific evidence that tells on whether we are a Sim or a human. So the credence we each assign to I’m a Sim should equal our best guess as to the percentage of human-like agents that are Sims, which is far above \\(\\frac{1}{2}\\). As Glenn Reynolds put it, “Is it live, or is it Memorex? Statistically, it’s probably Memorex. Er, and so are you, actually.”1 (Is it worrying that we used the assumption that we are human to generate this statistical argument? Not necessarily; if we are Sims then the Sims:humans ratio is probably even higher, so what we know is a lower bound on the proportion of human-like agents that are Sims.) Less roughly, the argument appeals crucially to the following principle:\n1 Link. Reynolds’s comment wasn’t directly about Bostrom, but it bore the ancestral of the relation refers to Bostrom’s paper.\n(#)\n\nCr(Sim  fSim = x) = x\n\n\nHere Cr is a rational credence function. I will adopt David Lewis’s theory of de se belief, and assume that the credence function is defined over properties, rather than propositions Lewis (1979). Whenever I use a term that normally stands for a proposition inside the scope of Cr, it stands for the property of being in a world where that proposition is true. So fSim = x stands for the property of being in a world where 100x% of the human-like agents are Sims.\nAs Bostrom notes, the main reason for believing (#) is that it is an instance of a plausible general principle, which I’ll call (##).\n\n(##)\n\n\\({\\forall}{\\Phi}\\): Cr(\\({\\Phi}\\)  f\\({\\Phi}\\) = x) = x\n\n\nBostrom does not formulate this more general principle, but it is clear that he intends something like it to be behind his argument, for many of the defences of (#) involve substituting some other property in place of Sim in statements like (#). So I will focus here on whether anything like (##) is plausibly true, and whether it supports (#). There are many ways we could interpret (##), depending on whether we take Cr to be a rational agent’s current credences, or in some sense the prior credences before they are affected by some particular evidence, and on whether we take the quantifier to be restricted or unrestricted. Five particular interpretations stand out as being worth considering. None of these, however, provides much reason to believe (#), at least on the reading Bostrom wants to give it. In that reading (#) the credence function represents the current credences of an agent much like you or me. If (#) isn’t interpreted that way, it can’t play the dialectical role Bostrom wants it to play. On two of the interpretations, (##) is false, on two others it may be true but clearly does not entail (#), and on the fifth it only entails (#) if we make an auxiliary assumption which is far from obviously true.\nFor ease of exposition, I will assume that Cr describes in some way the credences at some time of a particular rational human-like agent, Rat, who is much like you or me, except that she is perfectly rational.\n\n0.1 First Interpretation\nCr in (##) measures Rat’s current credences, and the quantifier in (##) is unrestricted. On this interpretation, (##) is clearly false, as Bostrom notes. Rat may well know that the proportion of human-like agents that are like spaghetti westerns is rather low, while rationally being quite confident that she likes spaghetti westerns. For any property \\({\\Phi}\\) where Rat has some particular information about whether he is one of the \\({\\Phi}\\)s or not, that information, and not general facts about the proportion of human-like agents that are \\({\\Phi}\\), can (indeed should) guide Rat’s credences. So those substitution instances of (##) are false.\n\n\n0.2 Second Interpretation\nJust like the first interpretation, except that we restrict the quantifier range so that it only ranges over properties such that Rat does not know whether she possesses them. This interpretation seems to be hinted at by Bostrom when he says, “the bland indifference principle expressed by (#) prescribes indifference only between hypotheses about which observer you are, when you have no information about which of these observers you are.” Even given this restriction, (##) is still false, as the following example shows.\nAssume that Rat knows that fSim &gt; 0.9, which Bostrom clearly takes to be consistent with rationality. And assume also that Rat, being a normal human-like agent, knows some fairly specific, and fairly distinctive facts about her conscious life. If Rat is anything like you or me, she will have experiences that he can be fairly sure are unique to her. Last night, for instance, while Rat was listening to Go-Betweens bootlegs, watching baseball, drinking beer, rocking in his rocking chair and thinking about Bostrom’s simulation argument, she stubbed her toe in a moderately, but not excessively, painful way. Few people will have done all these things at once, and none in quite that way. Let C be the property of ever having had an experience almost just like that. Rat knows he is a C. She is very confident, though not certain, that she is the only human-like C. Let a suman be the property of being C and human, or not-C and a Sim. For much of the paper we’re going to be concerned with the following two properties.\n\n\\(x\\) is a suman =df \\(x\\) is a human \\(C\\) or a Sim who is not a \\(C\\).\n\\(x\\) is a him =df \\(x\\) is a Sim \\(C\\) or a human who is not a \\(C\\).\n\nWe are following Bostrom in assuming that Rat does not know whether she is a Sim so she does not know whether she is a suman. But given that almost no one is C, it follows that fsuman \\({\\approx}\\) fSim. Hence fsuman &gt; 0.85, for if it is less than fSim, it is not much less. But if Cr(a suman) &gt; 0.85, and Cr(Sim) &gt; 0.9, and Rat is coherent, it follows that Cr(C) &lt; 0.25. But we assumed that Rat knew that she was a C, and however knowledge and credence are to be connected, it is inconceivable that one could know something while one’s credence in it is less than \\(\\frac{1}{4}\\). Hence it must be false that Cr(C) &lt; \\(\\frac{1}{4}\\), but we inferred that from given facts about the story and (##), as interpreted here. Hence (##), as interpreted here, is false.\n\n\n0.3 Third Interpretation\nOne natural response ot the previous objection is that there shoul dbe some way of restricting (##) so that it does not apply to properties like being a suman. Intuitively, the response is that even though Rat doesn’t know whether she is a suman, she knows something that is relevant to whether she is a suman, namely that she is a \\(C\\). The problem with this response is that any formal restriction on (##) that implements this intuition ends up giving us a version so weak that it doesn’t entail (#).\nThe idea is that what went wrong in the previous case is that even though Rat does not know whether she is a suman, she knows something relevant to this. In particular, she knows that if she is a suman, she is one of the sumans that is human, rather than one of the ones that is a Sim. Our third interpretation avoids the difficulties this raises by restricting the quantifier in (##) even further. Say that a property \\({\\Phi}\\) is in the domain of the quantifier iff (a) Rat does not know whether she is \\({\\Phi}\\), and (b) there is no more specific property \\({\\Phi}\\)\\(^\\prime\\) such that Rat knows that if she is \\({\\Phi}\\), then she is \\({\\Phi}\\)\\(^\\prime\\).2 This will rule out the applicability of (##) to properties like a suman. Unfortunately, it will also rule out the applicability of (##) to properties like being a Sim. For Rat knows that if she is a Sim, then she is a Sim that is also a C. So now (##) doesn’t entail (#).\n2 I think it is this interpretation of (##) that Adam Elga implicitly appeals to in his solution to the Sleeping Beauty problem Elga (2000).This kind of problem will arise for any attempt to put a purely formal restriction on (##). The problem is that, as Goodman noted in a quite different context (Goodman 1955), there is no formal distinction between the ‘normal’ properties, being a human and being a sim, and the ‘deviant’ properties, being a suman and being a him. The following four biconditionals are all conceptual truths, and hence must all receive credence 1.\nIf the obvious truth of (1a) implies that Rat cannot apply (##) to the property o being a suman once she knows that she is a \\(C\\), for (1a) makes that evidence look clrarly relevant to the issue of whether she is suman, then similar reasoning suggests that the obvious truth of (2a) implies that Rat cannot apply (##) to the properties of being a human once she knows that she is a \\(C\\), for (2a) makes that evidence look clearly relevant to the issue of whether she is human. The point is that a restriction on (##) that is to deliver (#) must fine some epistemologically salient distinction between the property of being human and the property of being suman if it is to rule out one application of (##) without ruling out the other, and if we only consider formal constraints, we won’t find such a restriction. Our final attempt to justify (#) from something like (##) attempts to avoid this problem by appealing directly to the nature of Rat’s evidence.\n\n\n0.4 Fourth Interpretation\nThe problems with the three interpretations of (##) so far have been that they applied after Rat found out something distinctive about herself, that she was a C. Perhaps (##) is really a constraint on prior credence functions. A priori, Rat’s credences should be governed by an unrestricted version of (##). We then have the following argument for (#). (As noted above, (#) is a constraint on current credences, so it is not immediately entailed by a constraint on prior credences such as (##) under its current interpretation.)\n\nP1\n\nA priori, Rat’s conditional credence in her being a Sim given that fSim is x is x.\n\nP2\n\nAll of Rat’s evidence is probabilistically independent of the property of being a Sim.\n\nC\n\nRat’s current conditional credence in her being a Sim given that fSim is x is x.\n\n\nThis interpretation may be reasonably faithful to what Bostrom had in mind. The argument just sketched looks similar enough to what he hints at in the following quote: “More generally, if we knew that a fraction x of all observers with human-type experiences live in simulations, and we don’t have any information that indicate that our own particular experiences are any more or less likely than other human-type experiences to have been implemented in vivo rather than in machina, then our credence that we are in a simulation should equal x.” So it’s not unreasonable to conclude that he is committed to P2, and intends it to be used in the argument that you should give high credence to being a Sim.3 Further, this version of (##), where it is restricted to prior credences, does not look unreasonable. So if P2 is true, an argument for (#) might just succeed. So the issue now is just whether P2 is true.\n3 Jamie Dreier pointed out to me that what Bostrom says here is slightly more complicated than what I, hopefully charitably, attribute to him. A literal reading of Bostrom’s passage suggests he intends the following principle.\n  \\({\\forall}\\)e: Cr(e  Human) - Cr(e  Sim) = Cr(e  Human) - Cr(e  Sim)      (B)\nThe quantifier here ranges over possible experiences e, e is the actual experience Rat has, and Cr is the credence function at the ‘time’ when Rat merely knows that he is human-like and fSim is greater than 0.9. I suggested a simpler assumption:\n  Cr(Human  e) = Cr(Sim  e)            (I)\nBostrom needs something a little stronger than (I) to get his desired conclusion, for he needs this to hold not just for Rat’s experience e, but for your experience and mine as well. But we will not press that point. Given that point, though, (I) is all he needs. And presumably the reason he adopts (B) is because it looks like it entails (I). And indeed it does entail (I) given some fairly innocuous background assumptions.Why might we reject P2? Any of the following three reasons might do. First, Rat’s evidence might be constituted by more than her conscious phenomenal states. This reply has an externalist and an internalist version. On the externalist version, Rat’s perceptual evidence is constituted in part by the objects she is perceiving. Just as seeing a dagger and hallucinating a dagger provide different evidence, so does seeing a dagger and sim-seeing a sim-dagger. For reasns Williamson notes, a Sim may not know that she has different evidence to someone seeing a dagger when she sim-sees a sim-dagger, but that does not imply that she does not have different evidence unless one also assumes, implausibly, that agents know exactly what their evidence is Williamson (2000). On the internalist version, our evidence is constituted by our sensory irritations, just as Quine said it is (Quine 1973). If Rat’s evidence includes the fact that her eyes are being irritated thus-and-so, his credence conditional on that that she is human should be 1, for if she were a Sim she could not have this evidence because she would not have eyes. She may, depending on the kind of Sim she is, have sim-eyes, but sim-eyes are not eyes. So Bostrom needs an argument that evidence supervenes on conscious experiences, and he doesn’t clearly have one. This is not to say that no such argument could exist. For example, Laurence BonJour provides some intriguing grounds for thinking that our fundamental evidence does consist in certain kinds of conscious states, namely occurrent beliefs (BonJour 1999), but we’re a long way from knowing that the supervenience claims holds. And if the supervenience claim does not hold, then even if Sims and humans have the same kind of experiences, they may not have the same kind of evidence. And if that is true, it is open to us to hold that Rat’s non-experiential evidence entails that she is not a Sim (as both Williamson and Quine suggest), so her evidence will not be independent of the question of whether she is a Sim.\nSecondly, even if every one of Rat’s experiences is probabilistically independent of the hypothesis that she is a Sim, that doesn’t give us a sufficient reason to believe that her total evidence is so independent. Just because e1 and e2 are both probabilistically independent of H, the conjunction e1 \\({\\wedge}\\) e2 might not be independent of H. So possibly our reasons for accepting P2 involve a tacit scope confusion.4\n4 Thanks to Jamie Dreier for reminding me of this point.Finally, we might wonder just why we’d even think that Rat’s evidence is probabilistically independent of the hypothesis that she is human. To be sure, her evidence does not entail that she is human. But that cannot be enough to show that it is probabilistically independent. For the evidence also does not entail that she is suman. And if P2 is true, then the evidence must have quite a bit of bearing on whether she is suman. For Rat’s prior credence in being suman is above 0.9 but apparently her posterior credence in it should be below 0.15. So the mere fact that the evidence does not entail that she is human cannot show that it is probabilistically independent of her being human, for the same reasoning would show it is probabilistically independent of his being suman.\nMore generally, we still need a distinction here between the property of being human and the property of being suman that shows why ordinary evidence should be independent of the first property but not the second. One might think the distinction can reside in the fact that being human is a natural property, while being suman is gruesome. The lesson of Goodman’s riddle of induction is that we have to give a privileged position in our epistemic framework to natural properties like being human, and this explains the distinction. This response gets the status of privileged and gruesome properties back-to-front. The real lesson of Goodman’s riddle is that credences in hypotheses involving natural properties should be distinctively sensitive to new evidence. Our evidence should make us quite confident that all emeralds are green, while giving us little reason to think that all emeralds are grue. What P2 says is that a rather natural hypothesis, that Rat is human, is insensitive to all the evidence Rat has, while a rather gruesome hypothesis, that Rat is suman, is sensitive to this evidence. The riddle of induction gives us no reason to believe that should happen.\nIt seems, though this is a little speculative, that the only reason for accepting P2 involves a simple fallacy. It is true that we have no reason to think that some evidence, say C, is more or less likely given that Rat is human rather than a Sim. But from this we should not conclude that we have a reason to think it is not more or less likely given that Rat is human rather than a Sim, which is what P2 requires. Indeed, drawing this kind of conclusion will quickly lead to a contradiction, for we can use the same ‘reasoning’ to conclude that we have a reason to think her evidence is not more or less likely given that Rat is a suman rather than a him.\n\n\n0.5 Conclusion\nNothing I have said here implies that Rat should have a high credence in her being human. But it does make one argument that she should not have a high credence in this look rather tenuous. Further, it is quite plausible that if there is no good reason not to give high credence to a hypothesis, then it is rationally permissible to give it such a high credence. It may not be rationally mandatory to give it such a high credence, but it is permissible. If Rat is very confident that she is human, even while knowing that most human-like beings are Sims, she has not violated any norms of reasoning, and hence is not thereby irrational. In that respect she is a bit like you and me.\n\n\n\n\n\n\nReferences\n\nBonJour, Laurence. 1999. “Foundationalism and the External World.” Philosophical Perspectives 13: 229–49. https://doi.org/10.1111/0029-4624.33.s13.11.\n\n\nBostrom, Nick. 2003. “Are You Living in a Computer Simulation?” The Philosophical Quarterly 53 (211): 243–55. https://doi.org/10.1111/1467-9213.00309.\n\n\nElga, Adam. 2000. “Self-Locating Belief and the Sleeping Beauty Problem.” Analysis 60 (2): 143–47. https://doi.org/10.1093/analys/60.2.143.\n\n\nGoodman, Nelson. 1955. Fact, Fiction and Forecast. Cambridge: Harvard University Press.\n\n\nLewis, David. 1979. “Attitudes de Dicto and de Se.” Philosophical Review 88 (4): 513–43. https://doi.org/10.2307/2184646.\n\n\nQuine, W. V. O. 1973. The Roots of Reference. La Salle: Open Court.\n\n\nWilliamson, Timothy. 2000. “Scepticism and Evidence.” Philosophy and Phenomenological Research 60 (3): 613–28. https://doi.org/10.2307/2653819."
  },
  {
    "objectID": "posts/conprob/index.html",
    "href": "posts/conprob/index.html",
    "title": "From Classical to Intuitionistic Probability",
    "section": "",
    "text": "It is a standard claim of modern Bayesian epistemology that reasonable epistemic states should be representable by probability functions. There have been a number of authors who have opposed this claim. For example, it has been claimed that epistemic states should be representable by Zadeh’s fuzzy sets, Dempster and Shafer’s evidence functions, Shackle’s potential surprise functions, Cohen’s inductive probabilities or Schmeidler’s non-additive probabilities.1 A major motivation of these theorists has been that in cases where we have little or no evidence for or against \\(p\\), it should be reasonable to have low degrees of belief in each of \\(p\\) and \\({\\lnot}\\)\\(p\\), something apparently incompatible with the Bayesian approach. There are two broad types of response to this situation, the second of which shows the incompatibility just mentioned is more apparent than real. The first of these – much in evidence in the work of the writers just cited – is to replace or radically reconstrue the notion of probability taken by that approach to represent degrees of belief. The second – to be defended here – seeks to maintain the core of standard probability theory but to generalize the notion of a probability function to accommodate variation in the background logic of the account; this allows us to respond to such issues as the low degree of belief in a proposition and its negation by simply weakening the background logic from classical to intuitionistic logic. Thus if Bayesianism is construed as in our opening sentence, one way to respond to the objections of the heterodox writers listed above is to trade in classical Bayesianism for intuitionistic Bayesianism. Since for many theorists at least the motivation for their opposition to Bayesianism is grounded in either verificationism or anti-realism, a move to a intuitionistic theory of probability seems appropriate. Indeed, as Harman (1983) notes, the standard analysis of degrees of belief as dispositions to bet leads naturally to a intuitionistic theory of probability. We give a Dutch Book argument in defence of constructive Bayesianism in Section 4 below.\n1 For more details, see Zadeh (1978), Dempster (1967), Shafer (1976), Shackle (1949), Cohen (1977), Schmeidler (1989).The appropriate generalization of the notion of a probability function makes explicit allowance for a sensitivity to the background logic. The latter we identify with a consequence relation, such as, in particular, the consequence relation \\(\\vdash_{CL}\\) associated with classical logic or the consequence relation \\(\\vdash_{IL}\\) associated with intuitionistic logic. To keep things general, we assume only that the languages under discussion have two binary connectives: \\({\\vee}\\) and \\({\\wedge}\\). No assumptions are made about how a consequence relation on such a language treats compounds formed using these connectives, though of course in the cases in which we are especially interested, \\(\\vdash_{CL}\\) and \\(\\vdash_{IL}\\), such compounds have the expected logical properties. We take the language of these two consequences relations to be the same, assuming in particular that negation (\\({\\lnot}\\)) is present for both. Finally, if \\(A\\) belongs to the language of a consequence relation \\(\\vdash\\), then we say that \\(A\\) is a \\(\\vdash\\)-thesis of \\(\\vdash\\) \\(A\\) and that \\(A\\) is a \\(\\vdash\\)-antithesis if for all \\(B\\) in that language \\(A\\) \\(\\vdash\\) \\(B\\). (Thus the \\(\\vdash\\)-theses and antitheses represent the logical truths and logical falsehoods as seen from the perspective of \\(\\vdash\\).) We are now in a position to give the key definition.\nIf \\(\\vdash\\) is a consequence relation, then a function Pr mapping the language of \\(\\vdash\\) to the real interval [0,1] is a \\(\\vdash\\)-probability function if and only if the following conditions are satisfied:\n\n(P0)\n\nPr(\\(A\\)) = 0 if \\(A\\) is a \\(\\vdash\\)-antithesis.\n\n(P1)\n\nPr(\\(A\\)) = 1 if \\(A\\) is a \\(\\vdash\\)-thesis\n\n(P2)\n\nIf \\(A\\) \\(\\vdash\\) \\(B\\) then Pr(\\(A\\)) \\({\\leq}\\) Pr(\\(B\\))\n\n(P3)\n\nPr(\\(A\\)) + Pr(\\(B\\)) = Pr(\\(A\\) \\({\\vee}\\) \\(B\\)) + Pr(\\(A\\) \\({\\wedge}\\) \\(B\\))\n\n\nIf \\(\\vdash\\) is \\(\\vdash_{CL}\\), then we call a \\(\\vdash\\)-probability function a classical probability function; if \\(\\vdash\\) is \\(\\vdash_{IL}\\) we call a \\(\\vdash\\)-probability function an intuitionistic probability function. The position described above as constructive Bayesianism would replace classical probability functions by intuitionistic probability functions as candidate representations of reasonable epistemic states. Note that classical probability functions in this sense are exactly those obeying the standard probability calculus axioms. In paricular, the familiar negation axiom dictating that Pr(\\({\\lnot}\\)\\(A\\)) = 1 – Pr(\\(A\\)) emerges as a by-product of the interaction between the general (i.e., logic-independent) condition (P3) and, via (P0) and (P1), the logic-specific facts that \\(A\\) \\({\\wedge}\\) \\({\\lnot}\\)\\(A\\) is a \\(\\vdash_{CL}\\)-antithesis and \\(A\\) \\({\\vee}\\) \\({\\lnot}\\)\\(A\\) is a \\(\\vdash_{CL}\\)-thesis for any \\(A\\).\nAlthough it is these two kinds – intuitionistic and classical – of probability functions we shall be dealing with specifically in what follows, we emphasize the generality of the above definition of a \\(\\vdash\\)-probability function, and invite the reader to consider what effect further varying the choice of \\(\\vdash\\) has on the behaviour of such functions. Our attention will be on the comparative merits of \\(\\vdash_{CL}\\) and \\(\\vdash_{IL}\\) in this regard. (It may have occurred to the reader in connection with (P3) above that we might naturally have considered a generalized version of (P3) for ‘countable additivity’. Whether such a condition ought be adopted will turn on some rather difficult questions concerning the use of infinities in constructive reasoning; let us leave it as a question for further research. We have stated (P3) in its finitary form so as not to require that intuitionistic probability functions satisfy the more contentious general condition.)\nIn the following section we shall review some of the motivations for intuitionistic Bayesianism. The arguments are rather piecemeal; they are designed to show that given the philosophical commitments various writers in the field have expressed they would be better off taking this route, i.e., focussing on the class of intuitionistic probability functions, than – as many of them have suggested –abandoning Bayesianism in our broad sense. In particular, we shall urge that moves in the latter direction which involve abandoning (what we shall call) the Principle of Addition are seriously undermotivated.\nOne aspect of the Bayesian perspective which we have not considered concerns the dynamics rather than the statics of epistemic states: in particular the idea that changes in such states are governed for rational agents by the principle of conditionalizing on new information. This requires that we have a dyadic functor available for expressing conditional probabilities. Accordingly, where Pr is for some consequence relation \\(\\vdash\\) a \\(\\vdash\\)-probability function, we favour the standard account and take the associated conditional \\(\\vdash\\)-probability function Pr( , ) to be given by Pr(\\(A\\),\\(B\\)) = Pr(\\(A\\) \\({\\wedge}\\) \\(B\\))/Pr(\\(B\\)) when Pr(\\(B\\)) \\({\\neq}\\) 0, with Pr(\\(A\\),\\(B\\)) undefined when Pr(\\(B\\)) = 0. The intention, of course, is that Pr(\\(A\\),\\(B\\)) represents the conditional probability of \\(A\\) given \\(B\\). We defer further consideration of conditional probability until the Appendix."
  },
  {
    "objectID": "posts/aka/index.html#going-to-war",
    "href": "posts/aka/index.html#going-to-war",
    "title": "Assertion, Knowledge and Action",
    "section": "Going to War",
    "text": "Going to War\nImagine that a country, Indalia, finds itself in a situation in which the thing for it to do, given the evidence available to its leaders, is to go to war against an enemy. (Those pacifists who think it is never right to go to war won’t like this example, but we think war can at least sometimes be justified.) But it is a close call. Had the evidence been a bit weaker, had the enemy been a little less murderous, or the risk of excessive civilian casualties a little higher, it would have been preferable to wait for more evidence, or use non-military measures to persuade the enemy to change its ways. So, while going to war is the thing to do, the leaders of Indalia can’t know this. We’ll come back to this in section 2, but the crucial point here is that knowledge has a safety constraint, and any putative knowledge here would violate this constraint.\nOur leaders are thus in a delicate position here. The Prime Minister of Indalia decides to launch the war, and gives a speech in the House of Commons setting out her reasons. All the things she says in the speech are true, and up to her conclusion they are all things that she knows. She concludes with (1).\nNow (1) is also true, and the Prime Minister believes it, but it is not something she knows. So, the Prime Minister violates The Knowledge Rule when she asserts (1). But it seems to us that she doesn’t violate any norms in making this assertion. We’ll have a lot more to say about why this is so in a few paragraphs. But first, here’s a less dramatic case that is also a counterexample to The Knowledge Rule, one that involves prudential judgments rather than moral judgments."
  },
  {
    "objectID": "posts/aka/index.html#buying-flood-insurance",
    "href": "posts/aka/index.html#buying-flood-insurance",
    "title": "Assertion, Knowledge and Action",
    "section": "Buying Flood Insurance",
    "text": "Buying Flood Insurance\nRaj and Nik are starting a small business. The business is near a river that hasn’t flooded in recent memory, but around which there isn’t much flood protection. They could buy flood insurance which would be useful in a flood, naturally, but would be costly in the much more likely event that there is not a flood. Raj has done the calculations of the likelihood of a flood, the amount this would damage the business, the utility loss of not having this damage insured, and the utility loss of paying flood insurance premiums. He has concluded that buying flood insurance is the thing to do. As it happens, this was a good conclusion to draw: it does, in fact, maximise his (and Nik’s) expected utility over time. (It doesn’t maximise their actual utility, as there actually won’t be a flood over the next twelve months. So, the insurance premium is an expense they could have avoided. But that doesn’t seem particularly relevant for prudential evaluation. Prudential buyers of insurance should maximise expected utility, not actual utility. Or so we must say unless we want to be committed to the view that everyone who buys an insurance policy and doesn’t make a claim on it is imprudent.)\nBut again, it’s a close call. If there had been a little less evidence that a flood was a realistic possibility, or the opportunity cost of using those dollars on insurance premiums had been a little higher, or the utility function over different outcomes a little different, it would have been better to forego flood insurance. That suggests that safety considerations make it the case that Raj doesn’t know that buying flood insurance is the thing to do, though in fact it is.\nLet’s now assume Raj has done everything he should do to investigate the costs and benefits of flood insurance. We can imagine a conversation between him and Nik going as follows.\n\nNik: Should we get flood insurance?\nRaj: I don’t know. Hold on; I’m on the phone.\nNik: Who are you calling?\nRaj: The insurance agent. I’m buying flood insurance.\n\nThere is clearly a pragmatic tension in Raj’s actions here. But given The Knowledge Rule, there’s little else he can do. It would be a serious norm violation to say nothing in response to Nik’s question. And given that he can’t say “Yes” without violating The Knowledge Rule, he has to say “I don’t know”. Moreover, since by hypothesis buying flood insurance is the thing to do in his situation, he can’t not buy the insurance without doing the wrong thing. So, given The Knowledge Rule, he’s doing the best he can. But it’s crazy to think that this is the best he can do.\nWe think that these cases are problems for The Knowledge Rule. In particular, we think that in each case, there is a non-defective assertion of something that is not known. It seems to us intuitively clear that those assertions are non-defective, but for those who don’t share this intuition, we have three independent arguments. The arguments focus on Going to War, but they generalize easily enough to Buying Flood Insurance."
  },
  {
    "objectID": "posts/aka/index.html#argument-one-that-was-your-first-mistake",
    "href": "posts/aka/index.html#argument-one-that-was-your-first-mistake",
    "title": "Assertion, Knowledge and Action",
    "section": "Argument One: “That was your first mistake”",
    "text": "Argument One: “That was your first mistake”\nImagine that the Prime Minister has a philosophical advisor. And the advisor’s job is to inform the Prime Minister whenever she violates a norm, and stay silent otherwise. If The Knowledge Rule is correct, then the advisor should stay silent as the Prime Minister orders the invasion, silent as the Prime Minister sets out the reasons for the invasion, then speak up at the very last line of the speech. That strikes us as absurd. It’s particularly absurd when you consider that the last line of the speech is supported by what came earlier in the speech, and the Prime Minister believes it, and asserts it, because it is well supported by what came earlier in the speech. Since we think this couldn’t be the right behaviour for the advisor, we conclude that there’s no norm violation in the Prime Minister asserting (1).\nWe’ve heard two replies to this kind of argument. According to one sort of reply, The Knowledge Rule is not meant to be an ‘all-things-considered’ norm. The defender of The Knowledge Rule can say that the Prime Minister’s assertion is defective because it violates that rule, but allow that it is nevertheless all-things-considered proper, because some other norm outweighs The Knowledge Rule on this occasion. We agree that The Knowledge Rule is not intended to be an all-things-considered norm. But even keeping clearly in mind the distinction between being defective in some respect and being defective all-things-considered, it is still deeply unintuitive to say that the Prime Minister’s assertion is defective in a respect. That is, we don’t think the philosophical advisor should speak up just at the very end of the Prime Minister’s speech even if she’s meant to observe all the norm violations (rather than just the all-things-considered norm violations).\nPerhaps the defender of The Knowledge Rule needn’t just appeal to an intuition here. Another reply we’ve heard starts from the premise that the Prime Minister’s assertion would be better, in a certain respect, if she knew that it was true. Therefore, there is a respect in which that assertion is defective, just as The Knowledge Rule requires. To this second reply, our response is that the premise is true, but the reasoning is invalid. Saying why requires reflecting a bit on the nature of norms.\nThere are lots of ways for assertions to be better. It is better, ceteris paribus, for assertions to be funny rather than unfunny. It is better for assertions to be sensitive rather than insensitive. (We mean this both in the Nozickian sense, i.e., an assertion is sensitive iff it wouldn’t have been made if it weren’t true, and in the Hallmark greeting card sense.) It is better for speakers to be certain of the truth of their assertions than for them to be uncertain. But these facts don’t imply that humour, sensitivity, or certainty are norms of assertion, for it doesn’t follow that assertions that lack humour (or sensitivity or certainty) are always defective. Similarly, the fact that it is better to know what you say than not doesn’t imply that asserting what you don’t know is always defective. In slogan form: Not every absence of virtue is a vice. We think knowledge is a virtue of assertions. (In fact, we think that pretty much every norm of assertion that has been proposed in the literature picks out a virtue of assertion.) What we deny is that the absence of knowledge is (always) a vice. Since not every absence of virtue is a vice, one can’t argue that the Prime Minister’s assertion is defective by arguing it could have been better. And that’s why the argument being considered is invalid."
  },
  {
    "objectID": "posts/aka/index.html#argument-two-actions-speak-louder-than-words",
    "href": "posts/aka/index.html#argument-two-actions-speak-louder-than-words",
    "title": "Assertion, Knowledge and Action",
    "section": "Argument Two: “Actions speak louder than words”",
    "text": "Argument Two: “Actions speak louder than words”\nIt’s a bit of folk wisdom that actions speak louder than words. It isn’t crystal clear just what this wisdom amounts to, but we think one aspect of it is that an agent incurs more normative commitments by doing X than by talking about X. But if The Knowledge Rule is right, then this piece of wisdom is in this aspect back-to-front. According to that rule, an agent incurs a greater normative commitment by saying that X is what to do than they do by just doing X. If they do X, and X is indeed what to do, then they’ve satisfied all of their normative commitments. If, by contrast, they say that X is what to do, then not only must X be what to do, but they must know this fact as well. This strikes us as completely back-to-front. We conclude that there is nothing improper about asserting that X is what to do (as the Prime Minister does), when X is in fact what to do."
  },
  {
    "objectID": "posts/aka/index.html#argument-three-what-else-could-i-do",
    "href": "posts/aka/index.html#argument-three-what-else-could-i-do",
    "title": "Assertion, Knowledge and Action",
    "section": "Argument Three: “What else could I do?”",
    "text": "Argument Three: “What else could I do?”\nHere’s a quite different argument that Going to War is a counterexample to The Knowledge Rule.\n\nIf ending the speech the way she did was a norm violation, there is a better way for the Prime Minister to end her speech.\nThere is no better way for the Prime Minister to end the speech without saying something that she does not know to be true.\nSo, ending the speech the way she did was not a norm violation.\nSo, The Knowledge Rule is subject to counterexample.\n\nPremise 1 is a kind of ‘ought-implies-can’ principle, and as such, it isn’t completely obvious that it is true. But when we’ve presented this argument to various groups, the focus has always been on premise two. The common complaint has been that the Prime Minister could have ended the speech in one of the following ways, thereby complying with The Knowledge Rule.\n\nI’ve decided that going to war is the thing to do in the circumstances.\nI believe that going to war is the thing to do in the circumstances.\nIt seems to me that going to war is the thing to do in the circumstances.\n\nOur first reply to this suggestion is that we’d fire a speechwriter who recommended that a Prime Minister end such a speech in such a weaselly way, so this hardly counts as a criticism of premise 2. Our more serious reply is that even if the Prime Minister ended the speech this way, she’d still violate The Knowledge Rule. To see why this is so, we need to pay a little closer attention to what The Knowledge Rule says.\nNote that The Knowledge Rule is not a rule about what kind of declarative utterance you can properly make. An actor playing Hamlet does not violate The Knowledge Rule if he fails to check, before entering the stage, whether something is indeed rotten in the state of Denmark. The rule is a rule about what one asserts. And just as you can assert less than you declaratively utter (e.g., on stage), you can also assert more than you declaratively utter.3 For instance, someone who utters The F is G in a context in which it is common ground that a is the F typically asserts both that the F is G, and that a is G. Similarly, someone who utters I think that S typically asserts both asserts that they have a certain thought, and asserts the content of that thought. We can see this is so by noting that we can properly challenge an utterance of I think that S by providing reasons that S is false, even if these are not reasons that show that the speaker does not (or at least did not) have such a thought. In the context of her speech of the House of Commons, even if the Prime Minister were to end with one of the options above, she would still assert the same thing she would assert by uttering (1) in the circumstances, and she’d still be right to make such an assertion.\n3 The points we’re about to make are fairly familiar by now, but for more detail, see Cappelen and Lepore (2005), which played an important role in reminding the philosophy of language community of their significance."
  },
  {
    "objectID": "posts/bayesdog/index.html#the-dogmatist-and-the-keynesian",
    "href": "posts/bayesdog/index.html#the-dogmatist-and-the-keynesian",
    "title": "The Bayesian and the Dogmatist",
    "section": "4.1 The Dogmatist and the Keynesian",
    "text": "4.1 The Dogmatist and the Keynesian\nThe first advantage of the dynamic Keynesian model is that because it does not verify Lower, it is consistent with dogmatism. Now if you think that dogmatism is obviously false, you won’t think this is much of an advantage. But I tend to think that dogmatism is one of the small number of not absurd solutions to a very hard epistemological problem with no obvious solution, so we should not rule it out pre-emptively. Hence I think our formal models should be consistent with it. What is tricky is proving that the dynamic Keynesian model is indeed consistent with it.\nTo see whether this is true on the dynamic Keynesian model, we need to say what it is to lower the credence of some proposition. Since representors map propositions onto intervals rather than numbers, we can’t simply talk about one ‘probability’ being a smaller number than another.5 On the static Keynesian model, the most natural move is to say that conditionalisation on E lowers the credence of p iff for all Pr in the representor, Pr(p) &gt; Pr(p  E). This implies that if every function in the representor says that E is negatively relevant to p, then conditionalising on E makes p less probable. Importantly, it allows this even if the values that Pr(p) takes across the representor before and after conditionalisation overlap. So what should we say on the dynamic Keynesian model? The weakest approach that seems viable, and not coincidentally the most plausible approach, is to say that updating on E lowers the credence of p iff the following conditions are met:\n5 Strictly speaking, the story I’ve told so far does not guarantee that for any proposition p, the values that Pr(p) takes (for Pr in the representor) form an interval. But it is usual in more detailed presentations of the model to put constraints on the representor to guarantee that happens, and I’ll assume we’ve done that.\nFor all Pr in U(R, E), Pr(p E) &lt; Pr(p)\nFor all Pr in R but not in U(R, E), there is a Pr\\(^\\prime\\) in U(R, E) such that Pr\\(^\\prime\\)(p  E) &lt; Pr(p)\n\nIt isn’t too hard to show that for some models, updating on E does not lower the credence of E \\({\\supset}\\) H, if lowering is understood this way. The following is an extreme example, but it suffices to make the logical point. Let R be the minimal representor, the set of all probability functions that assign probability 1 to a priori certainties. And let U(R, E) be the singleton of the following probability function, defined only over Boolean combinations of E and H: Pr(E \\({\\wedge}\\) H) = Pr(E \\({\\wedge}\\) \\({\\lnot}\\)H) = Pr(\\({\\lnot}\\)E \\({\\wedge}\\) H) = Pr(\\({\\lnot}\\)E \\({\\wedge}\\) \\({\\lnot}\\)H) = \\(\\frac{1}{4}\\). Then the probability of E \\({\\supset}\\) H after updating is \\(\\frac{3}{4}\\). (More precisely, according to all Pr in U(R, E), Pr(E \\({\\supset}\\) H) = \\(\\frac{3}{4}\\).) Since before updating there were Pr in R such that Pr(E \\({\\supset}\\) H) &lt; \\(\\frac{3}{4}\\), in fact there were Pr in R such that Pr(E \\({\\supset}\\) H) = 0, updating on E did not lower the credence of E \\({\\supset}\\) H. So the dynamic Keynesian model does not, in general, have as a consequence that updating on E lowers the credence of E \\({\\supset}\\) H. This suggests that Lower in general is not true.\nIt might be objected that if evidence E supports our knowledge that E \\({\\supset}\\) H, then updating on E should raise the credence of E \\({\\supset}\\) H. And if we define credence raising the same way we just defined credence lowering, updating on E never raises the credence of E \\({\\supset}\\) H. From a Keynesian perspective, we should simply deny that evidence has to raise the credence of the propositions known on the basis of that evidence. It might be sufficient that getting this evidence removes the uncertainty associated with those propositions. Even on the static Keynesian model, it is possible for evidence to remove uncertainty related to propositions without raising the probability of that proposition. A little informally, we might note that whether an agent with representor R is sufficiently confident in p to know that p depends on the lowest value that Pr(p) takes for Pr \\({\\in}\\) R, and updating can raise the value of this ‘lower bound’ without raising the value of Pr(p) according to all functions in R, and hence without strictly speaking raising the credence of p.\nThe above illustration is obviously unrealistic, in part because U could not behave that way. It’s tempting at this stage to ask just how U does behave so we can work out if there are more realistic examples. Indeed, it’s tempting to try to attempt to provide a formal description of U. This temptation should be resisted. The whole point of the model is that we can only learn which hypotheses are supported by certain evidence by actually getting that evidence. If we could say just what U is, we would be able to know what was supported by any kind of evidence without getting that evidence. The best we can do with respect to U is to discover some of its contours with respect to evidence much like our own. And the way to make those discoveries will be to do scientific and epistemological research. It isn’t obvious that, say, looking for nice formal properties of U will help at all."
  },
  {
    "objectID": "posts/bayesdog/index.html#the-problem-of-the-priors",
    "href": "posts/bayesdog/index.html#the-problem-of-the-priors",
    "title": "The Bayesian and the Dogmatist",
    "section": "4.2 The Problem of the Priors",
    "text": "4.2 The Problem of the Priors\nOne really nice consequence of the dynamic Keynesian approach is that it lets us say what the representor of an agent with no empirical information should be. Say a proposition is a priori certain iff it is a priori that all rational agents assign credence 1 to that proposition. Then the representor of the agent with no empirical evidence is {Pr: \\({\\forall}\\)p: If p is a priori certain, then Pr(p) = 1}. This is the minimal representor I mentioned above. Apart from assigning probability 1 to the a priori certainties, the representor is silent. Hence it treats all propositions that are not a priori certain in exactly the same way. This kind of symmetric treatment of propositions is not possible on the traditional Bayesian conception for logical reasons. (The reasons are set out in the various discussions of the paradoxes of indifference, going back to Bertrand (1888).) Such a prior representor is consistent with the static Keynesian approach, but it yields implausible results, since conditionalising on E has no effect on the distribution of values of Pr(p) among functions in the representor for any p not made a priori certain by E. (We’ll say p is made a priori certain by E iff E \\({\\supset}\\) p is a priori certain.) So if this is our starting representor, we can’t even get probabilistic evidence for things that are not made certain by our evidence.6 So on the static Keynesian model, this attractively symmetric prior representor is not available.\n6 The argument in the text goes by a little quickly, because I’ve defined representors in terms on unconditional probabilities and this leads to complications to do with conditionalising on propositions of zero probability. A better thing to do, as suggested by Hájek (2003), is to take conditional probability as primitive. If we do this we’ll define representors as sets of conditional probability functions, and the a priori representor will be {Pr: If p \\({\\supset}\\) q is a priori certain, then Pr(q p) = 1}. Then the claim in the text will follow.I think one of the motivations of anti-dogmatist thinking is the thought that we should be able to tell a priori what is evidence for what. If it looking like there is a cow in front of us is a reason to think there is a cow in front of us, that should be knowable a priori. I think the motivation for this kind of position shrinks a little when we realise that an a priori prior that represented all the connections between evidence and hypotheses would have to give us a lot of guidance as to what to do (epistemically speaking) in worlds quite unlike our own. Moreover, there is no reason we should have lots that information. So consider, for a minute, a soul in a world with no spatial dimensions and three temporal dimensions, where the primary source of evidence for souls is empathic connection with other souls from which they get a (fallible) guide to those souls’ mental states. When such a soul conditionalises on the evidence “A soul seems to love me” (that’s the kind of evidence they get) what should their posterior probability be that there is indeed a soul that loves them? What if the souls have a very alien mental life, so they instantiate mental concepts very unlike our own, and souls get fallible evidence of these alien concepts being instantiated through empathy? I think it’s pretty clear we don’t know the answers to these questions. (Note that to answer this question we’d have to know which of these concepts were grue-like, and which were projectable, and there is no reason to believe we are in a position to know that.) Now those souls are presumably just as ignorant about the epistemologically appropriate reaction to the kinds of evidence we get, like seeing a cow or hearing a doorbell, as we are about their evidence. The dynamic Keynesian model can allow for this, especially if we use the very weak prior representor described above. When we get the kind of evidence we actually get, the effect of U is to shrink our representors to sets of probability functions which are broadly speaking epistemically appropriate for the kind of world we are in. Before we got that evidence, we didn’t know how we should respond to it, just like the spaceless empathic souls don’t know how to respond to it, just like we don’t know how to respond to their evidence.\nIt is a commonplace observation that (a) prior probabilities are really crucial in Bayesian epistemology, but (b) we have next to no idea what they look like. I call this the problem of the priors, and note with some satisfaction that the dynamic Keynesian model avoids it. Now a cynic might note that all I’ve done is replace a hand-wavy story about priors with a hand-wavy story about updating. That’s true, but nevertheless I think this is progress. The things I’m being deliberately unclear about, such as what U should look like for E such as “Some other non-spatial tri-temporal soul seems to love me” are things that (a) my theory says are not a priori knowable, and (b) I don’t have any evidence concerning. So it isn’t surprising that I don’t have much to say about them. It isn’t clear that the traditional Bayesian can offer any story, even by their own lights, as to why they are less clear about the structure of the prior probability conditional on such an E."
  },
  {
    "objectID": "posts/bayesdog/index.html#the-problem-of-old-evidence",
    "href": "posts/bayesdog/index.html#the-problem-of-old-evidence",
    "title": "The Bayesian and the Dogmatist",
    "section": "4.3 The Problem of Old Evidence",
    "text": "4.3 The Problem of Old Evidence\nWhen we get evidence E, the dynamic Keynesian model says that we should do two things. First, we should throw out some probability functions in our representor. Second, we should conditionalise those that remain. But this is a normative condition, not a description of what actually happens. Sometimes, when we get evidence E, we may not realise that it is evidence that supports some theory T. That is, we won’t sufficiently cull the representor of those probability functions where the probability of T given E is not high. Housecleaning like this is hard, and sometimes we only do it when it becomes essential. In this case, that means we only do it when we start paying serious attention to T. In that case we may find that evidence E, evidence we’ve already incorporated, in the sense of having used in conditionalisation, gives us reason to be more confident than we were in T. In such a case we’ll simply cull those functions where probability of T given E is not high, and we will be more confident in T. That’s how old evidence can be relevant on the dynamic Keynesian model. Since we have a story about how old evidence can be relevant, there is no problem of old evidence for the dynamic Keynesian.\nFamously, there is a problem of old evidence for traditional Bayesians. Now I’m not going to rehearse all the arguments concerning this problem to convince you that this problem hasn’t been solved. That’s in part because it would take too long and in part because I’m not sure myself that it hasn’t been solved. But I will note that if you think the problem of old evidence is a live problem for traditional Bayesians, then you have a strong reason for taking the dynamic Keynesian model seriously."
  },
  {
    "objectID": "posts/bayesdog/index.html#why-should-we-care",
    "href": "posts/bayesdog/index.html#why-should-we-care",
    "title": "The Bayesian and the Dogmatist",
    "section": "4.4 Why Should We Care?",
    "text": "4.4 Why Should We Care?\nThe sceptic’s opening move was to appeal to our intuition that propositions like E \\({\\supset}\\) H are unknowable. We then asked what reasons we could be given for accepting this claim, because the sceptic seems to want to derive quite a lot from a raw intuition. The sceptic can respond with a wide range of arguments, four of which are mentioned above. Here we focussed on the sceptic’s argument from exhaustion. E \\({\\supset}\\) H isn’t knowable a priori, because it could be false, and it isn’t knowable a posteriori, because, on standard models of learning, our evidence lowers its credibility. My response is to say that this is an artefact of the model the sceptic (along with everyone else) is using. There’s nothing wrong with using simplified models, in fact it is usually the only way to make progress, but we must be always wary that our conclusions transfer from the model to the real world. One way to argue that a conclusion is a mere artefact of the model is to come up with a model that is sensitive to more features of reality in which the conclusion does not hold. That’s what I’ve done here. The dynamic Keynesian model is sensitive to the facts that (a) there is a distinction between risk and uncertainty and (b) we can learn about fundamental evidential connections. In the dynamic Keynesian model, it isn’t true that our evidence lowers the probability of E \\({\\supset}\\) H. So the anti-sceptic who says that E \\({\\supset}\\) H is knowable a posteriori, the person I’ve called the dogmatist, has a defence against this Bayesian argument. If the response is successful, then there may well be other applications of the dynamic Keynesian model, but for now I’m content to show how the model can be used to defend the dogmatic response to scepticism.[^7]"
  }
]