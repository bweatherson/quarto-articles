[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Online Articles",
    "section": "",
    "text": "Intellectual Skill and the Rylean Regress\n\n\n\n\n\n\nepistemology\n\n\nskill\n\n\n\nIntelligent activity requires the use of various intellectual skills. While these skills are connected to knowledge, they should not be identified with knowledge. There are realistic examples where the skills in question come apart from knowledge. That is, there are realistic cases of knowledge without skill, and of skill without knowledge. Whether a person is intelligent depends, in part, on whether they have these skills. Whether a particular action is intelligent depends, in part, on whether it was produced by an exercise of skill. These claims promote a picture of intelligence that is in tension with a strongly intellectualist picture, though they are not in tension with a number of prominent claims recently made by intellectualists. \n\n\n\n\n\nApr 2, 2017\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nHumean Supervenience\n\n\n\n\n\n\nDavid Lewis\n\n\nmetaphysics\n\n\nHumeanism\n\n\n\nHumean supervenience is the conjunction of three theses: Truth supervenes on being, Anti‐haecceitism, and Spatiotemporalism. The first clause is a core part of Lewis’s metaphysics. The second clause is related to Lewis’s counterpart theory. The third clause says there are no fundamental relations beyond the spatiotemporal, or fundamental properties of extended objects. This paper sets out why Humean Supervenience was so central to Lewis’s metaphysics, and why we should care about it even if there are empirical arguments against Spatiotemporalism. The project of defending Humean Supervenience was part of a larger project of philosophical compatibilism, of showing how the folk picture of the world and the scientific picture could be made to cohere with relatively little damage to the former and none to the latter. And Lewis’s contributions to that project are independent of whether the scientific picture of the world ultimately includes Spatiotemporalism. \n\n\n\n\n\nMar 6, 2015\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nExplanation, Idealisation and the Goldilocks Problem\n\n\n\n\n\n\nexplanation\n\n\nphilosophy of economics\n\n\nbook symposium\n\n\non books\n\n\n\nA contribution to a symposium on Michael Strevens’s book Depth. \n\n\n\n\n\nMar 21, 2012\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nDefending Interest Relative Invariantism\n\n\n\n\n\n\nepistemology\n\n\ninterest-relativity\n\n\n\nSince interest-relative invariantism (hereafter, IRI) was introduced into contemporary epistemology in the early 2000s, it has been criticised on a number of fronts. This paper responds to six different criticisms of IRI launched by five different authors. And it does so by noting that the best version of IRI is immune to the criticisms they have launched. The ‘best version’ in question notes three things about IRI. First, what matters for knowledge is not strictly the stakes the agent faces in any decision-problem, but really the odds at which she has to bet. Second, IRI is a relatively weak theory; it just says interests sometimes matter. Defenders of IRI have often derived it from much stronger principles about reasoning, and critics have attacked those principles, but much weaker principles would do. Third, and most importantly, interests matter because generate certain kinds of defeaters. It isn’t part of this version of IRI that an agent can know something in virtue of their interests. Rather, the theory says that whether a certain kind of consideration is a defeater to an agent’s putative knowledge that p depends on their interests. This matters for the intuitive plausibility of IRI. Critics have argued, rightly, that interests don’t behave in ways distinctive of grounds of knowledge. But interests do behave like other kinds of defeaters, and this undermines the criticisms of IRI. \n\n\n\n\n\nJan 1, 2011\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Good are Counterexamples?\n\n\n\n\n\n\ngames and decisions\n\n\nepistemology\n\n\nmethodology\n\n\n\nIntuitively, Gettier cases are instances of justified true beliefs that are not cases of knowledge. Should we therefore conclude that knowledge is not justified true belief? Only if we have reason to trust intuition here. But intuitions are unreliable in a wide range of cases. And it can be argued that the Gettier intuitions have a greater resemblance to unreliable intuitions than to reliable intuitions. What’s distinctive about the faulty intuitions, I argue, is that respecting them would mean abandoning a simple, systematic and largely successful theory in favour of a complicated, disjunctive and idiosyncratic theory. So maybe respecting the Gettier intuitions was the wrong reaction, we should instead have been explaining why we are all so easily misled by these kinds of cases. \n\n\n\n\n\nJul 1, 2003\n\n\nBrian Weatherson\n\n\n\n\n\n\n\n\n\n\n\n\nReview of “Moral Uncertainty and Its Consequences”\n\n\n\n\n\n\nbook review\n\n\non books\n\n\nethics\n\n\nmoral uncertainty\n\n\n\nReview of Ted Lockhart, “Moral Uncertainty and Its Consequences”. Oxford: Oxford University Press, 2000. \n\n\n\n\n\nJul 1, 2002\n\n\nBrian Weatherson\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/wgac/index.html",
    "href": "posts/wgac/index.html",
    "title": "What Good are Counterexamples?",
    "section": "",
    "text": "The following kind of scenario is familiar throughout analytic philosophy. A bold philosopher proposes that all Fs are Gs. Another philosopher proposes a particular case that is, intuitively, an F but not a G. If intuition is right, then the bold philosopher is mistaken. Alternatively, if the bold philosopher is right, then intuition is mistaken, and we have learned something from philosophy. Can this alternative ever be realised, and if so, is there a way to tell when it is? In this paper, I will argue that the answer to the first question is yes, and that recognising the right answer to the second question should lead to a change in some of our philosophical practices.\n\nPublished in Philosophical Studies 115 (2003): 1-31.\n\nThe problem is pressing because there is no agreement across the sub-disciplines of philosophy about what to do when theory and intuition clash. In epistemology, particularly in the theory of knowledge, and in parts of metaphysics, particularly in the theory of causation, it is almost universally assumed that intuition trumps theory. Shope’s The Analysis of Knowledge contains literally dozens of cases where an interesting account of knowledge was jettisoned because it clashed with intuition about a particular case. In the literature on knowledge and lotteries it is not as widely assumed that intuitions about cases are inevitably correct, but this still seems to be the working hypothesis.1 And recent work of causation by a variety of authors, with a wide variety of opinions, generally takes the same line: if a theory disagrees with intuition about a case, the theory is wrong.2 In this area exceptions to the rule are a little more frequent, particularly on the issues of whether causation is transitive and whether omissions can be causes, but in most cases the intuitions are taken to override the theories. Matters are quite different in ethics. It is certainly not a good thing for utilitarian theories that we very often feel that the action that maximises utility is not the right thing to do. But the existence of such cases is rarely taken to be obviously and immediately fatal for utilitarian theories in the way that, say, Gettier cases are taken to be obviously and immediately fatal for theories of knowledge that proclaim those cases to be cases of knowledge. Either there is some important difference here between the anti-utilitarian cases and the Gettier cases, a difference that justifies our differing reactions, or someone is making a mistake. I claim that it is (usually) the epistemologists and the metaphysicians who are wrong. In more cases than we usually imagine, a good philosophical theory can teach us that our intuitions are mistaken. Indeed, I think it is possible (although perhaps not likely) that the justified true belief (hereafter, JTB) theory of knowledge is so plausible that we should hold onto it in preference to keeping our intuition that Gettier cases are not cases of knowledge.\n1 See, for example, DeRose (1996) and Nelkin (2000)2 See, for example, Menzies (1996), or any of the papers in the special Journal of Philosophy issue on causation, April 2000.My main interests here are methodological, not epistemological. Until the last section I will be arguing for the JTB theory of knowledge, but my main interest is in showing that one particular argument against the JTB theory, the one that turns on the fact that it issues in some rather unintuitive pronouncements about Gettier cases, is not in itself decisive. Still, the epistemological issues are important, which is one reason I chose to focus on the JTB theory, and at the end I will discuss how the methodological conclusions drawn here may impact on them in an unexpected way.\n\n1 Intuitions\nLet us say that a counterexample to the theory that all Fs are Gs is a possible situation such that most people have an intuition that some particular thing in the story is an F but not a G. The kinds of intuition I have in mind are what George Bealer (1998) calls intellectual “seemings”. Bealer distinguishes intellectual seemings, such as the intuition that Hume’s Principle is true, or that punishing a person for a crime they did not commit is unjust, from physical seemings, such as the ‘intuition’ that objects fall if released, or perhaps that the sun rotates around the earth. We shall be primarily concerned here with intellectual seemings, and indeed I shall only call these intuitions in what follows.\nAs Bealer notes, whether something seems to be true can be independent of whether we believe it to be true. Bealer himself notes that Frege’s Axiom V seems to be true, though we know it is false. It does not seem to be the case, in the relevant sense, that 643 x 721 = 463603. Unless one is rather good at mental arithmetic, there is nothing that 643 x 721 seems to be; it is out of the reach of intuition. These are not the only ways that seemings and belief can come apart. One can judge that something seems to be the case while neither believing nor disbelieving it. This is a sensible attitude to take towards the view that one cannot know that a particular ticket will lose in a fair lottery. This is despite the fact that it certainly seems one cannot know this. If one’s intuitions are running rampant, one may even have an intuition about something that one believes to be strictly indeterminate. For example, some people may have the intuition that the continuum hypothesis is true, even though they believe on reflection that it is indeterminate whether it is true.\nThe distinction between intuitions and belief is important because it helps reduce the violence that revisionary philosophical views do to our pre-existing positions. When I say that Gettier cases may be cases of knowledge, I am not denying that there is a strong intuition that they are not cases of knowledge. I am not denying that a Gettier case does not seem to be a case of knowledge. The same thing occurs in ethics. Utilitarians rarely deny that it seems that punishing innocents is the wrong thing to do. They urge that in certain, rare, cases this might be one of those things that seems to be true despite being false. The case that knowledge is justified true belief is meant to be made in full awareness of the fact that certain cases of justified true beliefs seem to not be cases of knowledge.\nActually, although we will not make much of it here, this last claim is not true as a general statement about all people. Jonathan Weinberg, Stephen Stich and Shaun Nichols have reported Weinberg, Stich, and Nichols (2001) that the intuition that Gettier cases are not cases of knowledge is not universally shared. It is not entirely clear what the philosophical relevance of these discoveries is. It might show that we who have Gettier intuitions speak a different language from those who do not. It might show (though as Stich and Nichols point out it is rather hard to see how) that philosophers know a lot more about knowledge than other folk. I think it is rather unlikely that this is true, but we shall bracket such concerns for now, and continue on the assumption that all parties have the Gettier intuitions. Since I shall want to argue that knowledge may still be justified belief in any case, I am hardly tilting the playing field in my direction by making this assumption.\nGiven that intuitions are what Bealer calls intellectual seemings, and given that the example of Axiom V shows that seemings can be mistaken, what evidence have we that they are not mistaken in the cases we consider here? Arguably, we have very little indeed. Robert Cummins (1998) argues that in general intuition should not be trusted as an evidential source because it cannot be calibrated. We wouldn’t have trusted the evidence Galileo’s telescope gave us about the moon without an independent reason for thinking his telescope reliable. Fortunately, this can be done; we can point the telescope at far away terrestrial mountains, and compare its findings with the findings of examining the mountains up close and personal. There is no comparable way of calibrating intuitions. Clearly we should suspicious of any method that has been tested and found unreliable, but there are tricky questions about the appropriate level of trust in methods that have not been tested. Ernest Sosa (1998) argues in response to Cummins that this kind of reasoning leads to an untenable kind of scepticism. Sosa notes that one can make the same point about perception as Cummins makes about intuition: we have no independent way of calibrating perception as a whole. There is a distinction to be drawn here, since perception divides into natural kinds, visual perception, tactile perception, etc, and we can use each of these to calibrate the others. It is hard to see how intuitions can be so divided in ways that permit us to check some kinds of intuitions against the others. In any case, the situation is probably worse than Cummins suggests, since we know that several intuitions are just false. It is interesting to note the many ways in which intuition does, by broad agreement, go wrong.\nMany people are prone to many kinds of systematic logical mistakes. Most famously, the error rates on the Wason Selection Task are disturbingly large. Although this test directly measures beliefs rather than intuitions, it seems very likely that many of the false beliefs are generated by mistaken intuitions. As has been shown in a variety of experiments, the most famous of which were conducted by Kahneman and Tversky, most people are quite incompetent at probabilistic reasoning. In the worst cases, subjects held that a conjunction was more probable than one of its conjuncts. Again, this only directly implicates subjects’ beliefs, but it is very likely that the false beliefs are grounded in false intuitions. (The examples in this paragraph are discussed in detail in Stich (1988, 1992).)\nAs noted above, most philosophers would agree that many, if not most, people have mistaken moral intuitions. We need not agree with those consequentialists who think that vast swathes of our moral views are in error to think that (a) people make systematic moral mistakes and (b) some of these mistakes can be traced to mistaken intuitions. To take the most dramatic example, for thousands of years it seemed to many people that slavery was morally acceptable. On a more mundane level, many of us find that our intuitive judgements about a variety of cases cannot be all acceptable, for it is impossible to find a plausible theory that covers them all.3 Whenever we make a judgement inconsistent with such an intuition, we are agreeing that some of our original intuitions were mistaken.\n3 The myriad examples in Unger (1996) are rather useful for reminding us just how unreliable our moral intuitions are, and how necessary it is to employ reflection and considered judgement in regimenting such intuitions.From a rather different direction, there are many mistaken conceptual intuitions, with the error traceable to the way Gricean considerations are internalised in the process of learning a language. Having learned that it would be improper to use t to describe a particular case, we can develop the intuition that this case is not an F, where F is the property denoted by t. For example, if one is careless, one can find oneself sharing the intuition expressed by Ryle in The Concept of Mind that morally neutral actions, like scratching one’s head, are neither voluntary nor involuntary (Ryle 1949). The source of this intuition is the simple fact that it would be odd to describe an action as voluntary or involuntary unless there was some reason to do so, with the most likely such reason being that the action was in some way morally suspect. The fact that the intuition has a natural explanation does not stop it being plainly false. We can get errors in conceptual intuitions from another source. At one stage it was thought that whales are fish, that the Mars is a star, the sun isn’t. These are beliefs, not intuitions, but there are clearly related intuitions. Anyone who had these beliefs would have had the intuition that in a situation like this (here demonstrating the world) the object in the Mars position was a star, and the objects in the whale position were fish. The empirical errors in the person’s belief will correlate to conceptual errors in their intuition. To note further that the kind of error being made here is conceptual not empirical, and hence the kind of error that occurs in intuition, note that we need not have learned anything new about whales, the sun or Mars to come to our modern beliefs. (In fact we did, but that’s a different matter.) Rather, we need only have learned something about the vast bulk of the objects that are fish, or stars, to realise that these objects had been wrongly categorised. The factor we had thought to be the most salient similarity to the cases grouped under the term, being a heavenly body visible in the night sky for ‘star’, living in water for ‘fish’, turned out not to be the most important similarity between most things grouped under that term. So there is an important sense in which saying whales are fish, or that the sun is not a star, may reveal a conceptual (rather than an empirical) error.\nThere seems to be a link between these two kinds of conceptual error. The reason we say that the Rylean intuitions, or more generally the intuitions of what Grice (1989, Ch. 1) called the Type-A philosophers, are mistaken is that the rival, Gricean, theory attaches to each word a relatively natural property. There is no natural property that actions satisfy when, and only when, we ordinarily describe them as voluntary. There is a natural property that covers all these cases, and other more mundane actions like scratching one’s head, and that is the property we now think is denoted by ‘voluntary’. This notion of naturalness, and the associated drive for systematicity in our philosophical and semantic theories, will play an important role in what follows.\n\n\n2 Correcting Mistakes\nThe following would be a bad defence of the JTB theory against counterexamples. We can tell that all counterexamples to the JTB theory are based on mistaken intuitions, because the JTB theory is true, so all counterexamples to it are false. Unless we have some support for the crucial premise that the JTB theory is true, this argument is rather weak. And that support should be enough to not only make the theory prima facie plausible, but so convincing that we are prepared to trust it rather than our judgements about Gettier cases.\nIn short, the true theory of knowledge is the one that does best at (a) accounting for as many as possible of our intuitions about knowledge while (b) remaining systematic. A ‘theory’ that simply lists our intuitions is no theory at all, so condition (b) is vital. And it is condition (b), when fully expressed, that will do most of the work in justifying the preservation of the JTB theory in the face of the counterexamples.\nThe idea that our theory should be systematic is accepted across a wide range of philosophical disciplines. This idea seems to be behind the following plausible claims by Michael Smith: “Not only is it a platitude that rightness is a property that we can discover to be instantiated by engaging in rational argument, it is also a platitude that such arguments have a characteristic coherentist form.” (1994: 40) The second so-called platitude just points out that it is a standard way of arguing in ethics to say, you think we should do X in circumstances C1, circumstances C2 are just like C1, so we should do X in C1. The first points out that not only is this standard, it can yield surprising ethical knowledge. But this is only plausible if it is more important that final ethics is systematic than that first ethics, the ethical view delivered by intuition, is correct. In other words, it is only plausible if ethical intuitions are classified as mistaken to the extent that they conflict with the most systematic plausible theory. So, for example, it would be good news for utilitarianism if there was no plausible rival with any reasonable degree of systematicity.\nThis idea also seems to do important work in logic. If we just listed intuitions about entailment, we would have a theory on which disjunctive syllogism (A and ~A \\({\\vee}\\) B entail B) is valid, while ex falso quadlibet (A and ~A entail B) is not. Such a theory is unsystematic because no concept of entailment that satisfies these two intuitions will satisfy a generalised transitivity requirement: that if C and D entail E, and F entails D then C and F entail E. (This last step assumes that ~A entails ~A \\({\\vee}\\) B, but that is rarely denied.) Now one can claim that a theory of entailment that gives up this kind of transitivity can still be systematic enough, and Neil Tennant (1992) does exactly this, but it is clear that we have a serious cost of the theory here, and many people think avoiding this cost is more important than preserving all intuitions.\nIn more detail, there are four criteria by which we can judge a philosophical theory. First, counterexamples to a theory count against it. While a theory can be reformist, it cannot be revolutionary. A theory that disagreed with virtually all intuitions about possible cases is, for that reason, false. The theory: X knows that p iff X exists and p is true is systematic, but hardly plausible. As a corollary, while intuitions about any particular possible case can be mistaken, not too many of them could be. Counterexamples are problematic for a theory, the fewer reforms needed the better, it’s just not that they are not fatal. Importantly, not all counterexamples are as damaging to a theory as others. Intuitions come in various degrees of strength, and theories that violate weaker intuitions are not as badly off as those that violate stronger intuitions. Many people accept that the more obscure or fantastic a counterexample is, the less damaging it is to a theory. This seems to be behind the occasional claim that certain cases are “spoils to the victor” – the idea is that the case is so obscure or fantastic that we should let theory rather than intuition be our guide. Finally, if we can explain why we have the mistaken intuition, that counts for a lot in reducing the damage the counterexample does. Grice did not just assert that the theory on which an ordinary head scratch was voluntary was more systematic than the theory of voluntariness Ryle proposed, he provided an explanation of why it might seem that his theory was wrong in certain cases.\nSecondly, the analyses must not have too many theoretical consequences which are unacceptable. Consider Kahneman and Tversky’s account of how agents actually make decisions, prospect theory, as an analysis of ‘good decision’. (Disclaimer: This is not how Kahneman and Tversky intend it.) So the analysis of ‘good decision’ is ‘decision authorised by prospect theory’. It is a consequence of prospect theory that which decision is “best” depends on which outcome is considered to be the neutral point. In practice this is determined by contextual factors. Redescribing a story to make different points neutral, which can be done by changing the context, licences different decisions. I take it this would be unacceptable in an analysis of ‘good decision’, even though it means the theory gives intuitively correct results in more possible cases than its Bayesian rivals4. In general, we want our normative theories to eliminate arbitrariness as much as possible, and this is usually taken to be more important than agreeing with our pre-theoretic intuitions about particular cases. Unger uses a similar argument in Living High and Letting Die to argue against the reliance on intuitions about particular cases in ethics. We have differing ethical intuitions towards particular cases that differ only in the conspicuousness of the suffering caused (or not prevented), we know that conspicuousness is not a morally salient difference, so we should stop trusting the particular intuitions. (Presumably this is part of the reason that we find Tennant’s theory of entailment so incredible, prima facie. It is not just that violating transitivity seems unsystematic, it is that we have a theoretical intuition that transitivity should be maintained.)\n4 A point very similar to this is made in Horowitz (1998).Thirdly, the concept so analysed should be theoretically significant, and should be analysed in other theoretically significant terms. This is why we now analyse ‘fish’ in such a way that whales aren’t fish, and ‘star’ in such a way that the sun is a star. This is not just an empirical fact about our language. Adopting such a constraint on categories is a precondition of building a serious classificatory scheme, so it is a constraint on languages, which are classificatory schemes par excellance. Even if I’m wrong about this, the fact that we do reform our language with the advance of science to make our predicates refer to theoretically more significant properties shows that we have a commitment to this restriction.\nFinally, the analysis must be simple. This is an important part of why we don’t accept Ryle’s analysis of ‘voluntary’. His analysis can explain all the intuitive data, even without recourse to Gricean implicature, and arguably it doesn’t do much worse than the Gricean explanation on the second and third tests. But Grice’s theory can explain away the intuitions that it violates, and importantly it does so merely with the aid of theories of pragmatics that should be accepted for independent reasons, and it is simpler, so it trumps Ryle’s theory.\nMy main claim is that even once we have accepted that the JTB theory seems to say the wrong thing about Gettier cases, we should still keep an open mind to the question of whether it is true. The right theory of knowledge, the one that attributes the correct meaning to the word ‘knows’, will do best on balance at these four tests. Granted that the JTB theory does badly on test one, it seems to do better than its rivals on tests two, three and four, and this may be enough to make it correct.\n\n\n3 Naturalness in a theory of meaning\nLet’s say I have convinced you that it would be better to use ‘knows’ in such a way that we all now assent to “She knows” whenever the subject of that pronoun truly, justifiably, believes. You may have been convinced that only by doing this will our term pick out a natural relation, and there is evident utility in having our words pick out relations that carve nature at something like its joints. Only in that way, you may concede, will our language be a decent classificatory scheme of the kind described above, and it is a very good thing to have one’s language be a decent classificatory scheme. I have implicitly claimed above that if you concede this you should agree that I will have thereby corrected a mistake in your usage. But, an objector may argue, it is much more plausible to say that in doing so I simply changed the meaning of ‘knows’ and its cognates in your idiolect. The meaning of your words is constituted by your responses to cases like Gettier cases, so when I convince you to change your response, I change the meaning of your words.\nThis objection relies on a faulty theory of meaning, one that equates meaning with use in a way which is quite implausible. If this objection were right, it would imply infallibilism about knowledge ascriptions. Still, the objection does point to a rather important point. There is an implicit folk theory of the meaning of ‘knows’, one according to which it does not denote justified true belief. I claim this folk theory is mistaken. It is odd to say that we can all be mistaken about the meanings of our words; it is odd to say that we can’t make errors in word usage. I think the latter is the greater oddity, largely because I have a theory which explains how we can all make mistakes about meanings in our own language.\nHow can we make such mistakes? The short answer is that meanings ain’t in the head. The long answer turns on the kind of tests on analyses I discussed in section two. The meaning of a predicate is a property in the sense described by Lewis (1983)5: a set, or class, or plurality of possibilia. (That is, in general the meaning of a predicate is its intension.6) The interesting question is determining which property it is. In assigning a property to a predicate, there are two criteria we would like to follow. The first is that it validates as many as possible of our pre-theoretic beliefs. The second is that it is, in some sense, simple and theoretically important. How to make sense of this notion of simplicity is a rather complex matter. Lewis canvasses the idea that there is a primitive ‘naturalness’ of properties which measures simplicity and theoretical significance7, and I will adopt this idea. Space restrictions prevent me going into greater detail concerning ‘naturalness’, but if something more definite is wanted, for the record I mean by it here just what Lewis means by it in the works previously cited.8\n5 The theory of meaning outlined here is deeply indebted to Lewis (1983, 1984, 1992).6 There are tricky questions concerning cointensional predicates, but these have fairly familiar solutions, which I accept. For ease of expression here I will ignore the distinction between properties and relations – presumably ‘knows’ denotes a relation, that is a set of ordered pairs.7 ‘Measures’ may be inappropriate here. Plausibly a property is simple because it is natural.8 For more recent applications of naturalness in Lewis’s work, see Langton and Lewis (1998, 2001) and Lewis (2001).So, recapitulating what I said in section two, for any predicate t and property F, we want F meet two requirements before we say it is the meaning of t. We want this meaning assignment to validate many of our pre-theoretic intuitions (this is what we test for in tests one and two) and we want F to be reasonably natural (this is what we test for in tests three and four). In hard cases, these requirements pull in opposite directions; the meaning of t is the property which on balance does best. Saying ‘knows’ means ‘justifiably truly believes’ does not do particularly well on the first requirement. Gettier isolated a large class of cases where it goes wrong. But it does very well on the second, as it analyses knowledge in terms of a short list of simple and significant features. I claim that all its rivals don’t do considerably better on the first, and arguably do much worse on the second. (There are considerations pulling either way here, as I note in section seven, but it is prima facie plausible that it does very well on the second, which is all that we consider for now.) That the JTB theory is the best trade-off is still a live possibility, even considering Gettier cases.\nThis little argument will be perfectly useless this theory of meaning (owing in all its essential features to Lewis) is roughly right. There are several reasons for believing it. First, it can account for the possibility of mistaken intuitions, while still denying the possibility that intuitions about meaning can be systematically and radically mistaken. This alone is a nice consequence, and not one which is shared by every theory of meaning on the market. Secondly, as was shown in sections one and two, it seems to make the right kinds of predictions about when meaning will diverge from intuitions about meaning.\nThirdly, it can account for the fact that some, but not all, disagreements about the acceptability of assertions are disputes about matters of fact, not matters of meaning. This example is from Cummins: “If a child, asked to use ‘fair’ in a sentence, says,”It isn’t fair for girls to get as much as boys,” we should suspect the child’s politics, not his language” (1998, 120). This seems right; but if the child had said “It is fair that dreams are purple”, we would suspect his language. Perhaps by ‘fair’ he means ‘nonsensical’ or something similar. A theory of meaning needs to account for this divergence, and for the fact that it is a vague matter when we say the problem is with the child’s language, and when with his politics. In short, saying which disputes are disputes about facts (or values or whatever), and which about meanings, is a compulsory question for a theory of meaning.\nThe balance theory of meaning I am promoting can do this, as the following demonstration shows. This theory of meaning is determinedly individualistic. Every person has an idiolect determined by her dispositions to apply terms; a shared language is a collection of closely-enough overlapping idiolects. So the child’s idiolect might differ from ours, especially if he uses ‘fair’ to mean ‘nonsensical’. But if the idiolect differs in just how a few sentences are used, it is likely that the meaning postulate which does best at capturing his dispositions to use according to our two criteria, is the same as the meaning postulate which does best at capturing our dispositions to use. The reason is that highly natural properties are pretty thin on the ground; one’s dispositions to use a term have to change quite a lot before they get into the orbit of a distinct natural property. So despite the fact that I allow for nothing more than overlapping idiolects, in practice the overlap is much closer to being exact than on most ‘overlapping idiolect’ theories.\nWith this, I can now distinguish which disputes are disputes about facts, and which are disputes about meaning. Given that there is a dispute, the parties must have different dispositions to use some important term. In some disputes, the same meaning postulate does best on balance at capturing the dispositions of each party. I say that here the parties mean the same thing by their words, and the dispute is a dispute about facts. In others, the difference will be so great that different meaning postulates do best at capturing the dispositions of the competing parties. In these cases, I say the dispute is a dispute about meaning.\nNow, I can explain the intuition that the JTB theorist means something different to the rest of us by ‘knows. That is, I can explain this intuition away. It seems a fair assumption that the reasonably natural properties will be evenly distributed throughout the space of possible linguistic dispositions. If this is right, then any change of usage beyond a certain magnitude will, on my theory, count as a change of meaning. And it is plausible to suppose the change I am urging to our usage, affirming rather than denying sentences like, “Smith knows Jones owns a Ford” is beyond that certain magnitude. But the assumption of even distribution of the reasonably natural properties is false. That, I claim, is what the failure of the ’analysis of knowledge’ merry-go-round to stop shows us. There are just no reasonably natural properties in the neighbourhood of our disposition to use ‘knows’. If this is right, then even some quite significant changes to usage will not be changes in meaning, because they will not change which is the closest reasonably natural property to our usage pattern. The assumption that the reasonably natural properties are reasonably evenly distributed is plausible, but false. Hence the hunch that I am trying to change the meaning of ‘knows’ is plausible, but false.\nThe hypothesis that when we alter intuitions because of a theory we always change meanings, on the other hand, is not even plausible. When the ancients said “Whales are fish”, or “The sun is not a star”, they simply said false sentences. That is, they said that whales are fish, and believed that the sun is not a star. This seems platitudinous, but the ‘use-change implies meaning-change’ hypothesis would deny it.\nIt has sometimes been suggested to me that conceptual intuitions should be given greater privilege than other intuitions; that I am wrong to generalise from the massive fallibility of logical, ethical or semantic intuitions to the massive fallibility of conceptual intuitions. Since I am on much firmer ground when talking about these non-conceptual cases, if such an attack were justified it would severely weaken my argument. Given what has been said so far we should be able to see what is wrong with this suggestion. Consider a group of people who systematically assent to “If A then B implies if B then A.” On this view these people are expressing a mistaken logical intuition, but a correct conceptual intuition. So their concept of ‘implication’ doesn’t pick out implication, or at the very least doesn’t pick out our concept of ‘implication’. Now if we are in that group, this summary becomes incoherent, so this position immediately implies that we can’t be mistaken about our logical intuitions. Further, we are no longer able to say that when these people say “If A then B implies if B then A,” they are saying something false, because given the reference of ‘implies’ in their idiolect, this sentence expresses a true proposition. This is odd, but odder is to come. Assuming again we are in this group, it turns out to be vitally important in debates concerning philosophical logic to decide whether we are engaging in logical analysis or conceptual analysis. It might turn out a correct piece of conceptual analysis of ‘implication’ picks out a different relation to the correct implication relation we derive from purely logical considerations. If logical intuitions are less reliable than conceptual intuitions, as proposed, and assent to sentences like “If A then B implies if B then A” reveals simultaneously a logical and a conceptual intuition, this untenable conclusion seems forced. I conclude that conceptual intuitions are continuous with other intuitions, and should be treated in a similar way.\n\n\n4 Keeping Conceptual Analysis\nThe following would be a bad way to respond to the worry that the JTB theory amounts to a change in the meaning of the word ‘knows’. For the worry to have any bite, facts about the meaning of ‘knows’ will have to be explicable in terms of facts about the use of ’knows. But facts about use can only tell us about the beliefs of this community about knowledge, not what knowledge really is. Since different communities adopt different standards for knowledge, we should only trust ours over theirs if (a) we have special evidence that our is correct or (b) we are so xenophobic that we trust ours simply because it is ours. “Many of us care very much whether or cognitive processes lead to beliefs that are true, or give us power over nature, or lead to happiness. But only those with a deep and free-floating conservatism in matters epistemic will care whether their cognitive processes are sanctioned by the evaluative standards that happen to be woven into our language” (Stich (1988), 109). “The intuitions and tacit knowledge of the man or woman in the street are quite irrelevant. The theory seeks to say what knowledge really is, not what folk epistemology takes it to be” (Stich (1992), 252).9 Facts about use can only give us the latter, so they are not what are relevant to my inquiry.\n9 The paper from which this quote is drawn is about the content of mental states, so originally it had ‘mental representation’ for ‘knowledge’ and ‘psychology’ for ‘epistemology’. But I take it that (a) this isn’t an unfair representation of Stich’s views and (b) even if it is, it is an admirably clear statement of the way many people feel about the use of intuitions about possible cases, and worth considering for that reason alone.Stich takes this to be a general reason for abandoning conceptual analysis. Now while I think, and have argued above, that conceptual analysis need not slavishly follow intuition, I do not think that we should abandon it altogether. Stich’s worry seems to be conceptual analysis can only tell us about our words, not about our world. But is this kind of worry coherent? Can we say what will be found when we get to this real knowledge about the world? Will we be saying, “This belief of Smith’s shouldn’t be called knowledge, but really it is”? We need to attend to facts about the meaning of ‘knows’ in order to define the target of our search. If not, we have no way to avoid incoherencies like this one.\nTo put the same point another way, when someone claims to find this deep truth about knowledge, why should anyone else care? She will say, “Smith really knows that Jones owns a Ford, but I don’t mean what everyone else means by ‘knows’.” Why is this any more interesting than saying, “Smith really is a grapefruit, but I don’t mean what everyone else means by ‘grapefruit’”? If she doesn’t use words in the way that we do, we can ignore what she says about our common word usage. Or at least we can ignore it until she (or one of her colleagues) provides us with a translation manual. But to produce a translation manual, or to use words the way we do, she needs to attend to facts about our meanings. Again, incoherence threatens if she doesn’t attend to these facts but claims nevertheless to be participating in a debate with us. These points are all to be found in Chapter 2 of Jackson (1998).\nAn underlying assumption of the first reply is that there is a hard division between facts about meaning and facts about the world at large; that a principle like: No ‘is’ from a ‘means’ holds. This principle is, however, mistaken. All instances of the following argument pattern, where t ranges over tokenings of referring terms, are valid.\n\nP1.\n\nt refers unequivocally to \\({\\alpha}\\).\n\nP2.\n\nt refers unequivocally to \\({\\beta}\\).\n\nC.\n\n\\({\\alpha}\\) = \\({\\beta}\\)\n\n\nFor example, from the premise that ‘POTUS’ refers unequivocally to the President of the United States, and the premise that ‘POTUS’ refers unequivocally to Bush, we can validly infer that Bush is President of the United States. Since P1 and P2 are facts about meaning, and C is a fact about the world, any principle like No ‘is’ from a ‘means’ must be mistaken. So this worry about how much we can learn from conceptual analysis, from considerations of meaning, is mistaken.\nI call this inference pattern the R-inference. That the R-inference is valid doesn’t just show Stich’s critique rests on the false assumption No ‘is’ from a ‘means’. It can be used to provide a direct response to his critique. The problem is meant to be that conceptual analysis, the method of counterexamples, can at best provide us with claims like: ‘knows’ refers to the relation justifiably truly believes. We want to know facts about knowledge, not about the term ‘knows’, so the conceptual analyst seems to have been looking in the wrong place. But it is a platitude that ‘knows’ refers to the relation knows. I call such platitudes, that ‘t’ refers to t, instances of the R-schema10. We can use the R-schema together with the R-inference to get the kind of conclusion our opponents are looking for.\n10 Horwich (1999, 115–30) discusses similar schema, noting that instances involving words in foreign languages, or indexical expressions, will not be platitudinous. He also notes a way to remove the presumption that there is such a thing as knowledge, by stating the schema as \\({\\forall}\\)x (‘knowledge’ refers to x iff knowledge = x). For ease of expression I will stick with the simpler formulation in the text.\nP1.\n\n‘Knowledge’ refers unequivocally to the relation justifiably truly believes.\n\nP2.\n\n‘Knowledge’ refers unequivocally to the relation knows.\n\nC.\n\nThe relation knows is the relation justifiably truly believes.\n\n\nMore colloquially, the conclusion says that knowledge is justified true belief. Everyone agrees (I take it) that conceptual analysis could, in principle, give us knowledge of facts of the form of P1. So the opponents of conceptual analysis must either deny P2, or deny that C follows from P1 and P2. In other words, for any such argument they must deny that the R-schema is true, or that the R-inference is valid. I hope the reader will agree that neither option looks promising.\n\n\n5 Against the Psychologists\nSomeone excessively impressed by various results in the psychological study of concepts may make the following objection to the theory of meaning here proffered. “Why think that we should prefer short lists of necessary and sufficient conditions? This seems like another one of those cases where philosophers take their aesthetic preferences to be truth-indicative, much like the ‘taste for desert landscapes’ argument. Besides, haven’t psychologists like Eleanor Rosch shown that our concepts don’t have simple necessary and sufficient conditions? If that’s right, your argument falls down in several different places.”\nStrictly speaking, my preference is not just for short lists of necessary and sufficient conditions. But it is, for reasons set out more fully in the next section, for short theories that fit the meaning of some term into a network of other properties. And my argument would fall down if there was no reason to prefer such short theories. And, of course, short lists of necessary and sufficient conditions are paradigmatically short theories. One reason I prefer the JTB analysis to its modern rivals is its brevity. Some of the reasons for preferring short lists are brought out by considering the objections to this approach developed by psychologists. I’ll just focus on one of the experiments performed by Rosch and Mervis, the points I make can be generalised.\nRosch and Mervis (1975) claim that “subjects rate superordinate semantic categories as having few, if any, attributes common to all members.” (p. 20) (A superordinate semantic category is one, like ‘fruit’, which has other categories, like ‘apple’, ‘pear’ and ‘banana’, as sub-categories.) Here’s the experiment they ran to show this. For each of six superordinate categories (‘furniture’, ‘fruit’, ‘weapon’, ‘vegetable’, ‘vehicle’ and ‘clothing’) they selected twenty category members. So for ‘fruit’ the members ranged from ‘orange’ and ‘apple’ to ‘tomato’ and ‘olive’. They then asked a range of subjects to list the attributes they associated with some of these 120 category members. Each subject was presented with six members, one from each category, and for each member had a minute and a half to write down its salient attributes.\n\n[F]ew attributes were given that were true of all twenty members of the category – for four of the categories there was only one such item; for two of the categories, none. Furthermore, the single attribute that did apply to all members, in three cases was true of many items besides those within that superordinate (for example, “you eat it” for fruit). Rosch and Mervis (1975)\n\nThey go on to conclude that the superordinate is not defined by necessary and sufficient conditions, but by a ‘family resemblance’ between members. This particular experiment was taken to confirm that the number of attributes a member has with other members of the category is correlated with a previously defined measure of prototypicality.11 They claim that the intuition, commonly held amongst philosophers, that there must be some attribute in common to all the members, is explicable by the fact that the highly prototypical members of the category all do share quite a few attributes in common, ranging from 3 attributes in common to the highly prototypical vegetables, to 36 for the highly prototypical vehicles.\n11 In previous work they had done some nice experiments aimed at getting a grip on our intuition that apples are more prototypical exemplars of fruit than olives are.One occasionally hears people deride the assumption that there are necessary and sufficient conditions for the application of a term, as if this was the most preposterous piece of philosophy possible. Really, this assumption is no more than the assumption that dictionaries can be written, and without any reason to think otherwise, seems perfectly harmless. Perhaps, though, the Rosch and Mervis experiments provide a reason to think otherwise, a reason for thinking that the conditions of applicability for terms like ‘fruit’, ‘weapon’, and perhaps ‘knowledge’ are Wittgensteinian family resemblance conditions, rather than short lists of necessary and sufficient conditions, the kinds of conditions that fill traditional dictionaries.\nWhen we look closely, we see that the experiments do not show this at all. One could try and knock any such argument away by claiming the proposal is incoherent. The psychologists claim that there are no necessary and sufficient conditions for being a weapon, but something is a weapon iff it bears a suitable resemblance to paradigmatic weapons. In one sense, bearing a suitable resemblance to a paradigmatic weapon is a condition, so it looks like we just have a very short list of necessary and sufficient conditions, a list of length one. Jackson (1998, 61) makes a similar point in response to Stich’s invocation of Rosch’s experiments. This feels like it’s cheating, so I’ll move onto other objections. I’ll explain below just why it feels like cheating.\nPhilosophers aren’t particularly interested in terms like ‘weapon’, so these experiments only have philosophical interest if the results can be shown to generalise to terms philosophers care about. In other words, if can be shown that terms like ‘property’, ‘justice’, ‘cause’ and particularly ‘knows’ are cluster concepts, or family resemblance terms. But there is a good reason to think this is false. As William Ramsey (1998) notes, if F refers to a cluster concept, then for any proposed list of necessary and sufficient properties for F-hood, it should be easy to find an individual which is an F but which lacks some of these properties. To generate such an example, just find an individual which lacks one of the proposed properties, but which has several other properties from the cluster. It should be harder to find an individual which has the properties without being an F. If the proposed analysis is even close to being right, then having these conditions will entail having enough of the cluster of properties that are constitutive of F-hood to be an F. Note, for example, that all of the counterexamples Wittgenstein (1953) lists to purported analyses of ‘game’ are cases where something is, intuitively, a game but which does not satisfy the analysis. If game is really a cluster concept, this is how things should be. But it is not how things are with knowledge; virtually all counterexamples, from Gettier on, are cases which are intuitively not cases of knowledge, but which satisfy the proposed analysis. This is good evidence that even if some terms in English refer to cluster concepts, ‘knows’ is not one of them.\nSecondly, Rosch and Mervis’s conclusions about the nature of the superordinate categories makes some rather mundane facts quite inexplicable. In this experiment the subjects weren’t told which category each member was in, but for other categories they were. Imagine, as seems plausible, one of the subjects objected to putting the member in that category. Many people, even undergraduates, don’t regard olives and tomatoes as fruit. (“Fruit on pasta? How absurd!”) When the student asks why is this thing called a fruit, other speakers can provide a response. It is not a brute fact of language that tomatoes are fruit. It is not just by magic that we happened to come to a shared meaning for fruit that includes tomatoes, and that if faced with a new kind of object, we would generally agree about whether it is a fruit. It is because we know how to answer such questions. This answer to the Why is it called ‘fruit’? question had better be a sufficient condition for fruitness. If not, the subject is entitled to ask why having that property makes it a fruit. And unless there are very many possible distinct answers to this question, which seems very improbable, there will be a short list of necessary and sufficient conditions for being a fruit. But for this example, at least, ‘fruit’ was relatively arbitrary, so there will be a short list of necessary and sufficient conditions for being an F, for pretty much any F.\nThirdly, returning to ‘fruit’, we can see that Rosch and Mervis’s experiments could not possibly show that many superordinate predicates in English are cluster concepts. For they would, if successful, show that ‘fruit’ is a cluster concept, and it quite plainly is not. So by modus tollens, there is something wrong with their methodology. Some of the other categories they investigate, particularly ‘weapon’ and ‘furniture’ might be relatively cluster-ish, in a sense to be explained soon, but not ‘fruit’. As the OED says, a fruit is “the edible product of a tree, shrub or other plant, consisting of the seed and its envelope.” If nothing like this is right, then we couldn’t explain to the sceptical why we call tomatoes, olives and so on fruit.\nSo the conclusion that philosophically significant terms are likely to be cluster concepts is mistaken. To close, I note one way the cluster concept view could at least be coherent. Many predicates do have necessary and sufficient conditions for their applicability, just as traditional conceptual analysis assumed. In other words, they have analyses. However, any analysis must be in words, and sometimes the words needed will refer to quite recherche properties. The properties in the analysans may, that is, be significantly less natural than the analysandum.\nIn some contexts, we only consider properties that are above a certain level of naturalness. If I claim two things say my carpet and the Battle of Agincourt, have nothing in common, I will not feel threatened by an objector who points out that they share some gruesome, gerrymandered property, like being elements of {my carpet, the Battle of Agincourt}. Say that the best analysis of F-hood requires us to use predicates denoting properties which are below the contextually defined border between the ‘natural enough’ and ‘too gruesome to use’. Then there will be a sense in which there is no analysis of F into necessary and sufficient conditions; just the sense in which my carpet and the Battle of Avignon have nothing in common. Jackson’s argument feels like a cheat because he just shows that there will be necessary and sufficient conditions for any concept provided we are allowed to use gruesome properties, but he makes it sound like this proviso is unnecessary. If Rosch and Mervis’s experiments show anything at all, it is that this is true of some common terms in some everyday-ish contexts. In particular, if we restrict our attention to the predicates that might occur to us within ninety seconds (which plausibly correlates well with some level of naturalness), very few terms have analyses. Thus far, Rosch and Mervis are correct. They go wrong by projecting truths of a particular context to all contexts.\n\n\n6 In defence of analysis\nIn the previous section I argued that various empirical arguments gave us no reason to doubt that ‘knows’ will have a short analysis. In this section we look at various philosophical arguments to this conclusion. One might easily imagine the following objection to what has been claimed so far. At best, the above reasoning shows that if ‘knows’ has a short analysis, then the JTB analysis is correct, notwithstanding the intuitions provoked by Gettier cases. But there is little reason to think English terms have analyses, as evidenced by the failure of philosophers to analyse even one interesting term, and particular reasons to think that ‘knows’ does not have an analysis. These reasons are set out by Williamson (2000 Ch. 3), who argues, by appeal to intuitions about a particular kind of case, that there can be no analysis of ‘knows’ into independent clauses, one of which describes an internal state of the agent and the other of which describes an external state of the agent. This does not necessarily refute the JTB analysis, since the concepts of justification and belief in use may be neither internal nor external in Williamson’s sense. And if we are going to revise intuitions about the Gettier cases, we may wish to revise intuitions about Williamson’s cases as well, though here it is probably safest to not do this, because it is unclear just what philosophical benefit is derived from this revision. In response to these arguments I will make two moves: one defensive and one offensive. The defensive move is to distinguish the assumptions made here about the structure of the meaning of ‘knows’, and show how these assumptions do not have some of the dreadful consequences suggested by various authors. The offensive move, with which we begin, is to point out the rather unattractive consequences of not making these assumptions about the structure of the meaning of ‘knows’.\nIn terms of the concept of naturalness used above, the relation denoted by ‘knows’ might fall into one of three broad camps:\n\nIt might be rather unnatural;\nIt might be fairly natural in virtue of its relation to other, more natural, properties; or\nIt might be a primitive natural property, one that does not derive its naturalness from anything else.\n\nMy preferred position is (b). I think that the word ‘knows’, like every other denoting term in English, denotes something fairly natural. And I don’t think there are any primitively natural properties or relations in the vicinity of the denotation of this word, so it must derive its naturalness from its relation to other properties or relations. If this is so, we can recover some of the structure of its meaning by elucidating those relationships. If it is correct, that is exactly what I think the JTB theory does. This is not to say that justification, truth or belief are themselves primitively natural properties, but rather that we can make some progress towards recovering the source of the naturalness of knowledge via its decomposition into justification, truth and belief. But before investigating the costs of (b), let us look at the costs of (a) and (c).\nI think we can dispense with (c) rather quickly. It would be surprising, to say the least, if knowledge was a primitive relation. That X knows that p can hardly be one of the foundational facts that make up the universe. If X knows that p, this fact obtains in virtue of the obtaining of other facts. We may not be able to tell exactly what these facts are in general, but we have fairly strong opinions about whether they obtain or not in a particular case. This is why we are prepared to say whether or not a character knows something in a story, perhaps a philosophical story, without being told exactly that. We see the facts in virtue of which the character does, or does not, know this. This does not conclusively show that knowledge is not a primitively natural property. Electrical charge presumably is a primitively natural property, yet sometimes we can figure out the charge of an object by the behaviour of other objects. For example, if we know it is repulsed by several different negatively charged things, it is probably negatively charged. But in these cases it is clear our inference is from some facts to other facts that are inductively implied, not to facts that are constituted by the facts we know. (Only a rather unreformed positivist would say that charge is constituted by repulsive behaviour.) And it does not at all feel that in philosophical examples we are inductively (or abductively) inferring whether the character knows that p.\nThe more interesting question is whether (a) might be correct. This is, perhaps surprisingly, consistent with the theory of meaning advanced above. I held, following Lewis, that the meaning of a denoting term is the most natural object, property or relation that satisfies most of our usage dispositions. It is possible that the winner of this contest will itself be quite unnatural. This is what happens all the time with vague terms, and indeed it is what causes, or perhaps constitutes, their vagueness. None of the properties (or relations) that we may pick out by ‘blue’ is much more natural than several other properties (or relations) that would do roughly as well at capturing our usage dispositions, were they the denotation of ‘blue’.12 And indeed none of these properties (or relations) are particularly natural; they are all rather arbitrary divisions of the spectrum. The situation is possibly worse when we consider what Theodore Sider (2001) calls maximal properties. A property F is maximal iff things that massively overlap an F are not themselves an F. So being a coin is maximal, since large parts of a coin, or large parts of a coin fused with some nearby atoms outside the coin, are not themselves coins. Sider adopts the following useful notation: something is an F* iff it is suitable to be an F in every respect save that it may massively overlap an F. So a coin* is a piece of metal (or suitable substance) that is (roughly) coin-shaped and is (more or less) the deliberate outcome of a process designed to produce legal tender. Assuming that any collection of atoms has a fusion, in the vicinity of any coin there will be literally trillions of coin*s. At most one of these will be a coin, since coins do not, in general, overlap. That is, the property being a coin must pick out exactly one of these coin*s. Since the selection will be ultimately arbitrary, this property is not very natural. There are just no natural properties in the area, so the denotation of ‘coin’ is just not natural.\n12 I include the parenthetical comments here so as not to prejudge the question of whether colours are properties or relations. It seems unlikely to me that colours are relations, either the viewers or environments, but it is not worth quibbling over this here.These kind of considerations show that option (a) is a live possibility. But they do not show that it actually obtains. And there are several contrasts between ‘knows’, on the one hand, and ‘blue’ and ‘coin’ on the other, which suggest that it does not obtain. First, we do not take our word ‘knows’ to be as indeterminate as ‘blue’ or ‘coin’, despite the existence of some rather strong grounds for indeterminacy in it. Secondly, we take apparent disputes between different users of the word ‘knows’ to be genuine disputes, ones in which at most one side is correct, which we do not necessarily do with ‘blue’ and ‘coin’. Finally, we are prepared to use the relation denoted by ‘knows’ in inductive arguments in ways that seem a little suspect with genuinely unnatural relations, as arguably evidenced by our attitudes towards ‘coin’ and ‘blue’. Let’s look at these in more detail.\nIf we insisted that the meaning of ‘knows’ must validate all of our dispositions to use the term, we would find that the word has no meaning. If we just look at intuitions, we will find that our intuitions about ‘knows’ are inconsistent with some simple known facts. (Beliefs, being regimented by reflection, might not be inconsistent, depending on how systematic the regimentation has been.) For example, the following all seem true to many people.\n\nKnowledge supervenes on evidence: if two people (not necessarily in the same possible world) have the same evidence, they know the same things.\nWe know many things about the external world.\nWe have the same evidence as some people who are the victims of massive deception, and who have few true beliefs about their external world.\nWhatever is known is true.\n\nThese are inconsistent, so they cannot all be true. We could take any three of these as an argument for the negation of the fourth, though probably the argument from (1) (2) and (3) to the negation of (4) is less persuasive than the other three such arguments. I don’t want to adjudicate here which such argument is sound. All I want to claim here is that there is a fact of the matter about which of these arguments is sound, and hence about which of these four claims is false. If two people are disagreeing about which of these is false, at most one of them is right, and the other is wrong. If ‘knows’ denoted a rather unnatural relation, there would be little reason to believe these things to be true. Perhaps by more carefully consulting intuitions we could determine that one of them is false by seeing that it had the weakest intuitive pull. If we couldn’t do this, it would follow that in general there was no fact of the matter about which is false, and if someone wanted to use ‘know’ in their idiolect so that one particular one of these is false, there would be no way we could argue that they were wrong. It is quite implausible that this is what should happen in such a situation. It is more plausible that the dispute should be decided by figuring out which group of three can be satisfied by a fairly natural relation. This, recall, is just how we resolve disputes in many other areas of philosophy, from logic to ethics. If there is no natural relation eligible to be the meaning of ‘knows’, then probably this dispute has no resolution, just like the dispute about what ‘mass’ means in Newtonian mechanics.13\n13 Note that in that dispute the rivals are quite natural properties, but seem to be matched in their naturalness. In the dispute envisaged here, the rivals are quite unnatural, but still seem to be matched. For more on ‘mass’, see Field (1973).The above case generalises quite widely. If one speaker says that a Gettier case is a case of knowledge and another denies this (as Stich assures us actually happens if we cast our linguistic net wide enough) we normally assume that one of them is making a mistake. But if ‘knows’ denotes something quite unnatural, then probably each is saying something true in her own idiolect. Each party may make other mistaken claims, that for example what they say is also true in the language of all their compatriots, but in just making these claims about knowledge they would not be making a mistake. Perhaps there really is no fact of the matter here about who is right, but thinking so would be a major change to our common way of viewing matters, and hence would be a rather costly consequence of accepting option (a). Note here the contrast with ‘blue’ and ‘coin’. If one person adopts an idiosyncratic usage of ‘blue’ and ‘coin’, one on which there are determinate facts about matters where, we say, there are none, the most natural thing to say is that they are using the terms differently to us. If they insist that it is part of their intention in using the terms to speak the same way as their fellows we may (but only may) revise this judgement. But in general there is much more inclination to say that a dispute over whether, say, a patch is blue is merely verbal than to say this about a dispute over whether X knows that p.\nFinally, if knowledge was a completely unnatural relation, we would no more expect it to play a role in inductive or analogical arguments than does grue, but it seems it can play such a role. One might worry here that blueness also plays a role in inductive arguments, as in: The sky has been blue the last n days, so probably it will be blue tomorrow. If blueness is not natural, this might show that unnatural properties can play a role in inductive arguments. But what is really happening here is that there is, implicitly, an inductive argument based on a much narrow colour spectrum, and hence a much more natural property. To see this, note that we would be just as surprised tomorrow if the sky was navy blue, or perhaps of the dominant blue in Picasso’s blue period paintings, as if it were not blue at all.\nSo there are substantial costs to (a) and (c). Are there similar costs to (b)? If we take (b) to mean that there is a decomposition of the meaning of ‘knows’ into conditions, expressible in English, which we can tell a priori are individually necessary and jointly sufficient for knowledge, and such that it is also a priori that they represent natural properties, then (b) would be wildly implausible. To take just one part of this, Williamson (2000) notes it is clear that there are some languages in which such conditions cannot be expressed, so perhaps English is such a language too. And if this argument for ‘knows’ works it presumably works for other terms, like ‘pain’, but it is hard to find such an a priori decomposition of ‘pain’ into more natural properties. Really, all (b) requires is that there be some connection, perhaps only discoverable a posteriori, perhaps not even humanly comprehensible, between knowledge and other more primitively natural properties. These properties need not be denoted by any terms of English, or any other known language.\nMost importantly, this connection need not be a decomposition. If knowledge is the most general factive mental state, as Williamson proposes, and being factive and being a mental state are natural properties, then condition (b) will be thereby satisfied. If knowledge is the norm of assertion, as Williamson also proposes, then that could do as the means by which knowledge is linked into the network of natural properties. This last assumes that being an assertion is a natural property, and more dangerously that norms as natural, but these are relatively plausible assumptions in general. In neither case do we have a factorisation, in any sense, of knowledge into constituent properties, but we do have, as (b) requires, a means by which knowledge is linked into the network of natural properties. It is quite plausible that for every term which, unlike ‘blue’ and ‘coin’ are not excessively vague and do not denote maximal properties, something like (b) is correct. Given the clarifications made here to (b), this is consistent with most positions normally taken to be anti-reductionist about those terms, or their denotata.\n\n\n7 Naturalness and the JTB theory\nI have argued here that the following argument against the JTB theory is unsound.\n\nP1.\n\nThe JTB theory says that Gettier cases are cases of knowledge.\n\nP2.\n\nIntuition says that Gettier cases are not cases of knowledge.\n\nP3.\n\nIntuition is trustworthy in these cases.\n\nC.\n\nThe JTB theory is false.\n\n\nThe objection has been that P3 is false in those cases where following intuition slavishly would mean concluding that some common term denoted a rather unnatural property while accepting deviations from intuition would allow us to hold that it denoted a rather natural property. Peter Klein (in conversation) has suggested that there is a more sophisticated argument against the JTB theory that we can draw out of the Gettier cases. Since this argument is a good illustration of the way counterexamples should be used in philosophy, I’ll close with it.\nKlein’s idea, in effect, is that we can use Gettier cases to argue that being a justified true belief is not a natural property, and hence that P3 is after all true. Remember that P3 only fails when following intuition too closely would lead too far away from naturalness. If being a justified true belief is not a natural property to start with, there is no great danger of this happening. What the Gettier cases show us, goes the argument, is that there are two ways to be a justified true belief. The first way is where the belief is justified in some sense because it is true. The second way is where it is quite coincidental that the belief is both justified and true. These two ways of being a justified true belief may be natural enough, but the property being a justified true belief is just the disjunction of these two not especially related properties.\nI think this is, at least, a prima facie compelling argument. There are, at least, three important points to note about it. First, this kind of reasoning does not obviously generalise. Few of the examples described in Shope (1983) could be used to show that some target theory in fact made knowledge into a disjunctive kind. The second point is that accepting this argument is perfectly consistent with accepting everything I said above against the (widespread) uncritical use of appeal to intuition. Indeed, if what I said above is broadly correct then this is just the kind of reasoning we should be attempting to use when looking at fascinating counterexamples. Thirdly, if the argument works it shows something much more interesting than just that the JTB theory is false. It shows that naturalness is not always transferred to a conjunctive property by its conjuncts.\nI assume here that being a justified belief and being a true belief are themselves natural properties, and being a justified true belief is the conjunction of these. The only point here that seems possibly contentious is that being a true belief is not natural. On some forms of minimalism about truth this may be false, but those forms seem quite implausibly strong. Remember that saying being a true belief is natural does not imply that has an analysis – truth might be a primitively natural component of this property. And remember also that naturalness is intensional rather than hyperintensional. If all true beliefs correspond with reality in a suitable way, and corresponding with reality in that way is a natural property, then so is being a true belief, even if truth of belief cannot be explained in terms of correspondence.\nThis is a surprising result, because the way naturalness was originally set up by Lewis suggested that it would be transferred to a conjunctive property by its conjuncts. Lewis gave three accounts of naturalness. The first is that properties are perfectly natural in virtue of being co-intensive with a genuine universal. The third is that properties are natural in virtue of the mutual resemblance of their members, where resemblance is taken to be a primitive. On either account, it seems that whenever being F is natural, and so is being G, then being F and G will be natural.14 The second account, if it can be called that, is that naturalness is just primitive. If the Gettier cases really do show that being a justified true belief is not natural, then they will have shown that we have to fall back on just this account of naturalness.\n\n\n\n14 I follow Armstrong (1978) here in assuming that there are conjunctive universals.\n\n\nReferences\n\nArmstrong, D. M. 1978. Universals and Scientific Realism. Cambridge: Cambridge University Press.\n\n\nBealer, George. 1998. “Intuition and the Autonomy of Philosophy.” In Rethinking Intuition, edited by Michael DePaul and William Ramsey, 201–40. Lanham: Rowman & Littlefield.\n\n\nCummins, Robert. 1998. “Reflection on Reflective Equilibrium.” In Rethinking Intuition, edited by Michael DePaul and William Ramsey, 113–28. Lanham: Rowman & Littlefield.\n\n\nDeRose, Keith. 1996. “Knowledge, Assertion and Lotteries.” Australasian Journal of Philosophy 74 (4): 568–79. https://doi.org/10.1080/00048409612347531.\n\n\nField, Hartry. 1973. “Theory Change and the Indeterminacy of Reference.” Journal of Philosophy 70 (14): 462–81. https://doi.org/10.2307/2025110.\n\n\nGrice, H. Paul. 1989. Studies in the Way of Words. Cambridge, MA.: Harvard University Press.\n\n\nHorowitz, Tamara. 1998. “Philosophical Intuitions and Psychological Theory.” Ethics 108 (2): 367–85. https://doi.org/10.1086/233809.\n\n\nHorwich, Paul. 1999. Meaning. Oxford: Oxford University Press.\n\n\nJackson, Frank. 1998. From Metaphysics to Ethics: A Defence of Conceptual Analysis. Clarendon Press: Oxford.\n\n\nLangton, Rae, and David Lewis. 1998. “Defining ‘Intrinsic’.” Philosophy and Phenomenological Research 58 (2): 333–45. https://doi.org/10.2307/2653512.\n\n\n———. 2001. “Marshall and Parsons on ‘Intrinsic’.” Philosophy and Phenomenological Research 63 (2): 353–55. https://doi.org/10.2307/3071068.\n\n\nLewis, David. 1983. “New Work for a Theory of Universals.” Australasian Journal of Philosophy 61 (4): 343–77. https://doi.org/10.1080/00048408312341131.\n\n\n———. 1984. “Putnam’s Paradox.” Australasian Journal of Philosophy 62 (3): 221–36. https://doi.org/10.1080/00048408412340013.\n\n\n———. 1992. “Meaning Without Use: Reply to Hawthorne.” Australasian Journal of Philosophy 70 (1): 106–10. https://doi.org/10.1080/00048408112340093.\n\n\n———. 2001. “Redefining ’Intrinsic’.” Philosophy and Phenomenological Research 63 (2): 381–98. https://doi.org/10.2307/3071071.\n\n\nMenzies, Peter. 1996. “Probabilistic Causation and the Pre-Emption Problem.” Mind 105 (417): 85–117. https://doi.org/10.1093/mind/105.417.85.\n\n\nNelkin, Dana. 2000. “The Lottery Paradox, Knowledge, and Rationality.” Philosophical Review 109 (3): 373–409. https://doi.org/10.2307/2693695.\n\n\nRamsey, William. 1998. “Prototypes and Conceptual Analysis.” In Rethinking Intuition, edited by Michael DePaul and William Ramsey, 161–77. Lanham: Rowman & Littlefield.\n\n\nRosch, Eleanor, and Carolyn Mervis. 1975. “Family Resemblances: Studies in the Internal Structure of Categories.” Cognitive Science 7 (4): 573–605. https://doi.org/10.1016/0010-0285(75)90024-9.\n\n\nRyle, Gilbert. 1949. The Concept of Mind. New York: Barnes; Noble.\n\n\nShope, Robert. 1983. The Analysis of Knowledge. Princeton: Princeton University Press.\n\n\nSider, Theodore. 2001. “Maximality and Intrinsic Properties.” Philosophy and Phenomenological Research 63 (2): 357–64. https://doi.org/10.1111/j.1933-1592.2001.tb00109.x.\n\n\nSosa, Ernest. 1998. “Minimal Intuition.” In Rethinking Intuition, edited by Michael DePaul and William Ramsey, 257–69. Lanham: Rowman & Littlefield.\n\n\nStich, Stephen. 1988. “Reflective Equilibrium, Analytic Epistemology and the Problem of Cognitive Diversity.” Synthese 74 (3): 391–413. https://doi.org/10.1007/bf00869637.\n\n\n———. 1992. “What Is a Theory of Mental Representation?” Mind 101 (402): 243–63. https://doi.org/10.1093/mind/101.402.243.\n\n\nTennant, Neil. 1992. Autologic. Edinburgh: Edinburgh University Press.\n\n\nUnger, Peter. 1996. Living High and Letting Die. Oxford: Oxford University Press.\n\n\nWeinberg, Jonathan, Stephen Stich, and Shaun Nichols. 2001. “Normativity and Epistemic Intuitions.” Philosophical Topics 29 (1): 429–60. https://doi.org/10.5840/philtopics2001291/217.\n\n\nWilliamson, Timothy. 2000. Knowledge and its Limits. Oxford University Press.\n\n\nWittgenstein, Ludwig. 1953. Philosophical Investigations. London: Macmillan.\n\nCitationBibTeX citation:@article{weatherson2003,\n  author = {Weatherson, Brian},\n  title = {What {Good} Are {Counterexamples?}},\n  journal = {Philosophical Studies},\n  volume = {115},\n  number = {1},\n  pages = {1-31},\n  date = {2003-07},\n  doi = {10.1023/A:1024961917413},\n  langid = {en}\n}"
  },
  {
    "objectID": "posts/diri/index.html",
    "href": "posts/diri/index.html",
    "title": "Defending Interest Relative Invariantism",
    "section": "",
    "text": "In recent years a number of authors have defended the interest-relativity of knowledge and justification. Views of this form are floated by John Hawthorne (2004), and endorsed by Jeremy Fantl and Matthew McGrath (2002, 2009), Jason Stanley (2005) and Brian Weatherson (2005). The various authors differ quite a lot in how much interest-relativity they allow, but what is common is the defence of interest-relativity.\n\nPublished in Logos and Episteme 2 (2011): 591-609.\nImage from Wikimedia Commons.\n\nThese views have, quite naturally, drawn a range of criticisms. The primary purpose of this paper is to respond to these criticisms and, as it says on the tin, defend interest-relative invariantism, or IRI for short. But I don’t plan to defend every possible version of IRI, only a particular one. Most of the critics of IRI have assumed that it must have some or all of the following features.\n\nIt is harder to know things in high-stakes situations than in low-stakes situations.\nThere is an interest-sensitive constituent of knowledge.\nIRI stands and falls with some principles connecting knowledge and action, such as the principles found in Hawthorne and Stanley (2008).\n\nMy preferred version of IRI has none of these three features.1\n1 It is a tricky exegetical question how many of the three features here must be read into defences of IRI in the literature. My reading is that they do not have to be read in, so it is not overly original of me to defend a version of IRI that does away with all three. But I know many people disagree with that. If they’re right, this paper is more original than I think it is, and so I’m rather happy to be wrong. But I’m going to mostly set these exegetical issues aside, and compare different theories without taking a stand on who originally promulgated them.First, it says that knowledge changes when the odds an agent faces change, not when the stakes change. More precisely, interests affect belief because whether someone believes \\(p\\) depends inter alia on whether their credence in \\(p\\) is high enough that any bet on \\(p\\) they actually face is a good bet. And interests affect knowledge largely because they affect belief. Raising the stakes of any bet on \\(p\\) does not directly change whether an agent believes \\(p\\), but changing the odds of the bets on \\(p\\) they face does change it. In practice raising the stakes changes the odds due to the declining marginal utility of material goods. So in practice high-stakes situations are typically long-odds situations. But knowledge is hard in those situations because they are long-odds situations, not because they are high-stakes situations.\nSo my version of IRI says that knowledge differs between these two cases.\n\nHigh Cost Map:\n\nZeno is walking to the Mysterious Bookshop in lower Manhattan. He’s pretty confident that it’s on the corner of Warren Street and West Broadway. But he’s been confused about this in the past, forgetting whether the east-west street is Warren or Murray, and whether the north-south street is Greenwich, West Broadway or Church. In fact he’s right about the location this time, but he isn’t justified in having a credence in his being correct greater than about 0.95. While he’s walking there, he has two options. He could walk to where he thinks the shop is, and if it’s not there walk around for a few minutes to the nearby corners to find where it is. Or he could call up directory assistance, pay $1, and be told where the shop is. Since he’s confident he knows where the shop is, and there’s little cost to spending a few minutes walking around if he’s wrong, he doesn’t do this, and walks directly to the shop.\n\nLow Cost Map:\n\nJust like the previous case, except that Zeno has a new phone with more options. In particular, his new phone has a searchable map, so with a few clicks on the phone he can find where the store is. Using the phone has some very small costs. For example, it distracts him a little, which marginally raises the likelihood of bumping into another pedestrian. But the cost is very small compared to the cost of getting the location wrong. So even though he is very confident about where the shop is, he double checks while walking there.\n\n\nI think the Map Cases are like the various cases that have been used to motivate interest-relativity2 in all important respects. I think Zeno knows where the shop is in High Cost Map, and doesn’t know in Low Cost Map. And he doesn’t know in Low Cost Map because the location of the shop has suddenly become the subject matter of a bet at very long odds. You should think of Zeno’s not checking the location of the shop on his phone-map as a bet on the location of the shop. If he wins the bet, he wins a few seconds of undistracted strolling. If he loses, he has to walk around a few blocks looking for a store. The disutility of the loss seems easily twenty times greater than the utility of the gain, and by hypothesis the probability of winning the bet is no greater than 0.95. So he shouldn’t take the bet. Yet if he knew where the store was, he would be justified in taking the bet. So he doesn’t know where the store is. Now this is not a case where higher stakes defeat knowledge. If anything, the stakes are lower in Low Cost Map. But the relevant odds are longer, and that’s what matters to knowledge.\n2 Such as the Bank Cases in Stanley (2005), or the Train Cases in Fantl and McGrath (2002).Second, on this version of IRI, interests matter because there are interest-sensitive defeaters, not because interests form any kind of new condition on knowledge, alongside truth, justification, belief and so on. In particular, interests matter because there are interest-relative coherence constraints on knowledge. Some coherence constraints, I claim, are not interest-relative. If an agent believes \\(\\neg p\\), that belief defeats her purported knowledge that \\(p\\), even if the belief that \\(p\\) is true, justified, safe, sensitive and so on. It is tempting to try to posit a further coherence condition.\n\nPractical Coherence\n\nAn agent does not know that \\(p\\) if she prefers \\(\\varphi\\) to \\(\\psi\\) unconditionally, but prefers \\(\\psi\\) to \\(\\varphi\\) conditional on \\(p\\).\n\n\nBut that is too strong. For reasons similar to those gone over at the start of Hawthorne (2004), it would mean we know nearly nothing. A more plausible condition is:\n\nRelevant Practical Coherence\n\nAn agent does not know that \\(p\\) if she prefers \\(\\varphi\\) to \\(\\psi\\) unconditionally, but prefers \\(\\psi\\) to \\(\\varphi\\) conditional on \\(p\\), for any \\(\\varphi, \\psi\\) that are relevant given her interests.\n\n\nWhen this condition is violated, the agent’s claim to knowledge is defeated. As we’ll see below, defeaters behave rather differently to constituents of knowledge. Some things which could not plausibly be grounds for knowledge could be defeaters to defeaters for knowledge.\nRelevant Practical Coherence suffices, at least among agents who are trying to maximise expected value, to generate an interest-relativity to knowledge. The general structure of the case should be familiar from the existing literature. Let \\(p\\) be a proposition that is true, believed by the agent, and strongly but not quite conclusively supported by their evidence. Let \\(B\\) be a bet that has a small positive return if \\(p\\), and a huge negative return if \\(\\neg p\\). Assume the agent is now offered the bet, and let \\(\\varphi\\) be declining the bet, and \\(\\psi\\) be accepting the bet. Conditional on \\(p\\), the bet wins, so the agent prefers the small positive payout, so prefers \\(\\psi\\) to \\(\\varphi\\) conditional on \\(p\\). But the bet has a massively negative expected return, so unconditionally the agent does not want it. That is, unconditionally she prefers \\(\\varphi\\) to \\(\\psi\\). Once the bet is offered, the actions \\(\\varphi\\) and \\(\\psi\\) become relevant given her interests, so by Relevant Practical Coherence she no longer knows \\(p\\). So for such an agent, knowledge is interest-relative.\nCases where knowledge is defeated because if the agent did know \\(p\\), that would lead to problems elsewhere in their cognitive system, have a few quirky features. In particular, whether the agent knows \\(p\\) can depend on very distant features. Consider the following kind of case.\n\nConfused Student\nCon is systematically disposed to affirm the consequent. That is, if he notices that he believes both \\(p\\) and \\(q \\rightarrow p\\), he’s disposed to either infer \\(q\\), or if that’s impermissible given his evidence, to ditch his belief in the conjunction of \\(p\\) and \\(q \\rightarrow p\\). Con has completely compelling evidence for both \\(q \\rightarrow p\\) and \\(\\neg q\\). He has good but less compelling evidence for \\(p\\). And this evidence tracks the truth of \\(p\\) in just the right way for knowledge. On the basis of this evidence, Con believes \\(p\\). Con has not noticed that he believes both \\(p\\) and \\(q \\rightarrow p\\). If he did, he’s unhesitatingly drop his belief that \\(p\\), since he’d realise the alternatives (given his dispositions) involved dropping belief in a compelling proposition. Two questions:\n\nDoes Con know that \\(p\\)?\nIf Con were to think about the logic of conditionals, and reason himself out of the disposition to affirm the consequent, would he know that \\(p\\)?\n\n\nI think the answer to the first question is No, and the answer to the second question is Yes. As it stands, Con’s disposition to affirm the consequent is a doxastic defeater of his putative knowledge that \\(p\\). Put another way, \\(p\\) doesn’t cohere well enough with the rest of Con’s views for his belief that \\(p\\) to count as knowledge. To be sure, \\(p\\) coheres well enough with those beliefs by objective standards, but it doesn’t cohere at all by Con’s lights. Until he changes those lights, it doesn’t cohere well enough to be knowledge. Moreover (as a referee pointed out), Con’s belief is not safe. Since he could easily have ‘reasoned’ himself out of his belief that \\(p\\), the belief isn’t safe in the way that knowledge is safe.\nI think that beliefs which violate Relevant Practical Coherence fail to be knowledge for the same reason that Con’s belief that \\(p\\) fails to be knowledge. In what follows, I’ll make frequent use of this analogy; many of the objections to IRI turn out to be equally strong objections to the view that there are ever defeaters of the type Con suffers from.\nThis suggests our third point. This version of IRI does not take IRI to be a consequence of more general principles about knowledge and action. It simply says that there exist at least one pair of cases where the only relevant difference between agents in the two cases concerns their interests, but one knows that \\(p\\) and the other does not.3 I happen to think that most of the general principles that philosophers have used to try to derive IRI are false. But since IRI is much weaker than those principles, that is no reason to conclude IRI is false.4\n3 And this is true even though \\(p\\) is not a proposition about their interests, or something that is supported by propositions about their interests, and so on.4 I will consider, and tentatively support, one principle stronger than IRI in the final section. But the key point is that these general principles are not needed to defend IRI.The existence of interest-relativity is then quite a weak claim. There are plenty of stronger claims in the area we could make. I prefer, for instance, a version of IRI where being offered bets like \\(B\\) defeats knowledge that \\(p\\) even if the agent does not have the preferences I ascribed above. (That could be because she isn’t trying to maximise expected value, or because she’s messed up the expected value calculations.) But knowledge could be interest-relative even if I’m wrong about those cases.\nSo I’ve set out a version of IRI that lacks three features often attributed to IRI. I haven’t argued for that theory here - I do that at much greater length in (Author Paper 1). But I hope I’ve done enough to convince you that the theory is both a version of IRI, and not obviously false. In what follows, I’ll argue that the theory is immune to the various challenges to IRI that have been put forward in the literature. This immunity is, I think, a strong reason to prefer this version of IRI.\n\n1 Experimental Objections\nI don’t place as much weight as some philosophers do on the correlation between the verdicts of an epistemological theory and the gut reactions that non-experts have to tricky cases. And I don’t think the best cases for IRI relies on such a correlation holding. The best case for IRI is that it integrates nicely with an independently supported theory of belief, and that it lets us keep a number of plausible principles without drifting into skepticism.5 But still, it is nice to not have one’s theory saying exorbitantly counterintuitive things. Various experimental results, such as the results in May et al. (2010) and Feltz and Zarpentine (2010), might be thought to suggest that IRI does have consequences which are counterintuitive, or which at least run counter to the intuitions of some experimental subjects. I’m going to concentrate on the latter set of results here, though I think that what I say will generalise to related experimental work. In fact, I think the experiments don’t really tell against IRI, because IRI, at least in my preferred version, doesn’t make any unambiguous predictions about the cases at the centre of the experiments. The reason for this is related to my insistence that we concentrate on the odds an agent faces, not the stakes she faces.\n5 This points are expanded upon greatly in (Author Paper 1).Feltz and Zarpentine gave subjects related vignettes, such as the following pair. (Each subject only received one of the pair.)\n\nHigh Stakes Bridge\n\nJohn is driving a truck along a dirt road in a caravan of trucks. He comes across what looks like a rickety wooden bridge over a yawning thousand foot drop. He radios ahead to find out whether other trucks have made it safely over. He is told that all 15 trucks in the caravan made it over without a problem. John reasons that if they made it over, he will make it over as well. So, he thinks to himself, ‘I know that my truck will make it across the bridge.’\n\nLow Stakes Bridge\n\nJohn is driving a truck along a dirt road in a caravan of trucks. He comes across what looks like a rickety wooden bridge over a three foot ditch. He radios ahead to find out whether other trucks have made it safely over. He is told that all 15 trucks in the caravan made it over without a problem. John reasons that if they made it over, he will make it over as well. So, he thinks to himself, ‘I know that my truck will make it across the bridge.’ (Feltz and Zarpentine 2010, 696)\n\n\nSubjects were asked to evaluate John’s thought. And the result was that 27% of the participants said that John does not know that the truck will make it across in Low Stakes Bridge, while 36% said he did not know this in High Stakes Bridge. Feltz and Zarpentine say that these results should be bad for interest-relativity views. But it is hard to see just why this is so.\nNote that the change in the judgments between the cases goes in the direction that IRI seems to predict. The change isn’t trivial, even if due to the smallish sample size it isn’t statistically significant in this sample. But should a view like IRI have predicted a larger change? To figure this out, we need to ask three questions.\n\nWhat are the costs of the bridge collapsing in the two cases?\nWhat are the costs of not taking the bet, i.e., not driving across the bridge?\nWhat is the rational credence to have in the bridge’s sturdiness given the evidence John has?\n\nConditional on the bridge not collapsing, the drivers presumably prefer taking the bridge to not taking it. And the actions of taking the bridge or going around the long way are relevant. So by Relevant Practical Coherence, the drivers know the bridge will not collapse in Low Stakes Bridge but not High Stakes Bridge if the following equation is true. (I assume all the other conditions for knowledge are met, and that there are no other salient instances of Relevant Practical Coherence to consider.)\n\\[\\frac{C_H}{G + C_H} &gt; x &gt; \\frac{C_L}{G + C_L}\\]\nwhere \\(G\\) is the gain the driver gets from taking a non-collapsing bridge rather than driving around (or whatever the alternative is), \\(C_H\\) is the cost of being on a collapsing bridge in High Stakes Bridge, \\(C_L\\) is the cost of being on a collapsing bridge in Low Stakes Bridge, and \\(x\\) is the probability that the bridge will collapse. I assume \\(x\\) is constant between the two cases. If that equation holds, then taking the bridge, i.e., acting as if the bridge won’t collapse, maximises expected utility in Low Stakes Bridge but not High Stakes Bridge. So in High Stakes Bridge, adding the proposition that the bridge won’t collapse to the agent’s cognitive system produces incoherence, since the agent won’t (at least rationally) act as if the bridge won’t collapse. So if the equation holds, the agent’s interests in avoiding \\(C_H\\) creates a doxastic defeater in High Stakes Bridge.\nBut does the equation hold? Or, more relevantly, did the subjects of the experiment believe that the equation hold? None of the four variables has their values clearly entailed by the story, so we have to guess a little as to what the subjects’ views would be.\nFeltz and Zarpentine say that the costs in “High Stakes Bridge are very costly—certain death—whereas the costs in Low Stakes Bridge are likely some minor injuries and embarrassment.” (Feltz and Zarpentine 2010, 702) I suspect both of those claims are wrong, or at least not universally believed. A lot more people survive bridge collapses than you may expect, even collapses from a great height.6 And once the road below a truck collapses, all sorts of things can go wrong, even if the next bit of ground is only 3 feet away. (For instance, if the bridge collapses unevenly, the truck could roll, and the driver would probably suffer more than minor injuries.)\n6 In the West Gate bridge collapse in Melbourne in 1971, a large number of the victims were underneath the bridge; the people on top of the bridge had a non-trivial chance of survival. That bridge was 200 feet above the water, not 1000, but I’m not sure the extra height would matter greatly. Again from a slightly lower height, over 90% of people on the bridge survived the I-35W collapse in Minneapolis in 2007.We aren’t given any information as to the costs of not crossing the bridge. But given that 15 other trucks, with less evidence than John, have decided to cross the bridge, it seems plausible to think they are substantial. If there was an easy way to avoid the bridge, presumably the first truck would have taken it. If \\(G\\) is large enough, and \\(C_H\\) small enough, then the only way for this equation to hold will be for \\(x\\) to be low enough that we’d have independent reason to say that the driver doesn’t know the bridge will hold.\nBut what is the value of \\(x\\)? John has a lot of information that the bridge will support his truck. If I’ve tested something for sturdiness two or three times, and it has worked, I won’t even think about testing it again. Consider what evidence you need before you’ll happily stand on a particular chair to reach something in the kitchen, or put a heavy television on a stand. Supporting a weight is the kind of thing that either fails the first time, or works fairly reliably. Obviously there could be some strain-induced effects that cause a subsequent failure7, but John really has a lot of evidence that the bridge will support him.\n7 As I believe was the case in the I-35W collapse.Given those three answers, it seems to me that it is a reasonable bet to cross the bridge. At the very least, it’s no more of an unreasonable bet than the bet I make every day crossing a busy highway by foot. So I’m not surprised that 64% of the subjects agreed that John knew the bridge would hold him. At the very least, that result is perfectly consistent with IRI, if we make plausible assumptions about how the subjects would answer the three numbered questions above.\nAnd as I’ve stressed, these experiments are only a problem for IRI if the subjects are reliable. I can think of two reasons why they might not be. First, subjects tend to massively discount the costs and likelihoods of traffic related injuries. In most of the country, the risk of death or serious injury through motor vehicle accident is much higher than the risk of death or serious injury through some kind of crime or other attack, yet most people do much less to prevent vehicles harming them than they do to prevent criminals or other attackers harming them.8 Second, only 73% of these subjects in this very experiment said that John knows the bridge will support him in Low Stakes Bridge. This is rather striking. Unless the subjects endorse an implausible kind of scepticism, something has gone wrong with the experimental design. But if the subjects are implausibly sceptical, then we shouldn’t require our epistemological theory to track their gut reactions. (And if something has gone wrong with the experimental design, then obviously can’t be used as the basis for any objection.) So given the fact that the experiment points broadly in the direction of IRI, and that with some plausible assumptions it is perfectly consistent with that theory, and that the subjects seem unreasonably sceptical to the point of unreliability about epistemology, I don’t think this kind of experimental work threatens IRI.\n8 See the massive drop in the numbers of students walking or biking to school, reported in Ham, Martin, and Kohl III (2008), for a sense of how big an issue this is.\n\n2 Knowledge By Indifference and By Wealth\nGillian Russell and John Doris (2009) argue that Jason Stanley’s account of knowledge leads to some implausible attributions of knowledge, and if successful their objections would generalise to other forms of IRI. I’m going to argue that Russell and Doris’s objections turn on principles that are prima facie rather plausible, but which ultimately we can reject for independent reasons.9\n9 I think the objections I make here are similar in spirit to those Stanley made in a comments thread on Certain Doubts, though the details are new. The thread is at http://el-prod.baylor.edu/certain_doubts/?p=616.Their objection relies on variants of the kind of case Stanley uses heavily in his (2005) to motivate a pragmatic constraint on knowledge. Stanley considers the kinds of cases we used to derive IRI from Relevant Practical Coherence. So imagine an agent who faces a choice between accepting the status quo, call that \\(\\varphi\\), and taking some giant risk, call that \\(\\psi\\). The giant risk in this case will involve a huge monetary loss if \\(\\neg p\\), and a small non-monetary gain if \\(p\\). Stanley says, and I agree, that in such a case the agent doesn’t know \\(p\\), even if their belief in \\(p\\) is true, well supported by evidence, and so on. Moreover, he says, had \\(\\psi\\) not been a relevant option, the agent could have known \\(p\\). I agree, and I think Relevant Practical Coherence explains these intuitions well.\nRussell and Doris imagine two kinds of variants on Stanley’s case. In one variant the agent doesn’t care about the material loss associated with \\(\\psi \\wedge \\neg p\\). As I would put it, although their material wealth would decline precipitously in that case, their utility would not, because their utility is not tightly correlated with material wellbeing. Given that, the agent may well prefer \\(\\psi\\) to \\(\\varphi\\) unconditionally, and so would still know \\(p\\). Russell and Doris don’t claim this is a problem in itself, but they do think the conjunction of this with the previous paragraph is a problem. As they put it, “you should have reservations ... about what makes the knowledge claim true: not giving a damn, however enviable in other respects, should not be knowledge-making.” (Russell and Doris 2009, 432).\nTheir other variant involves an agent with so much money that the material loss is trifling to them. Since the difference in utility between having, say, eight billion dollars and seven billion dollars is not that high, perhaps they will again prefer \\(\\psi\\) to \\(\\varphi\\) unconditionally, so still know \\(p\\). But it is, allegedly, counterintuitive to have the knowledge that \\(p\\) turn on the agent’s wealth. As Russell and Doris say, “matters are now even dodgier for practical interest accounts, because money turns out to be knowledge making.” (Russell and Doris 2009, 433) And this isn’t just because wealth can purchase knowledge. As they say, “money may buy the instruments of knowledge ... but here the connection between money and knowledge seems rather too direct.” (Russell and Doris 2009, 433)\nThe first thing to note about this case is that indifference and wealth aren’t really producing knowledge. What they are doing is more like defeating a defeater. Remember that the agent in question had enough evidence, and enough confidence, that they would know \\(p\\) were it not for the practical circumstances. As I said in the introduction, practical considerations enter debates about knowledge in part because they are distinctive kinds of defeaters. It seems that’s what is going on here. And we have, somewhat surprisingly, independent evidence to think that indifference and wealth do matter to defeaters.\nConsider two variants on Gilbert Harman’s ‘dead dictator’ example (Harman 1973, 75). In the original example, an agent reads that the dictator has died through an actually reliable source. But there are many other news sources around, such that if the agent read them, she would lose her belief. Even if the agent doesn’t read those sources, their presence can constitute defeaters to her putative knowledge that the dictator died.\nIn our first variant on Harman’s example, the agent simply does not care about politics. It’s true that there are many other news sources around that are ready to mislead her about the dictator’s demise. But she has no interest in looking them up, nor is she at all likely to look them up. She mostly cares about literature, and will spend her day reading old novels. In this case, the misleading news sources are too distant, in a sense, to be defeaters. So she still knows the dictator has died. Her indifference towards politics doesn’t generate knowledge - the original reliable report is the knowledge generator - but her indifference means that a would-be defeater doesn’t gain traction.\nIt might be objected here that the agent doesn’t know the dictator has died because there are misleading reports around saying the dictator is alive, and she is in no position to rebut them. But this is too high a standard for knowledge. There are millions of people in Australia who know that humans are contributing to global warming on purely testimonial grounds. Many, perhaps even most, of these people would not be able to answer a carefully put together argument that humans are not contributing to global warming, such as an argument that picked various outlying statistics to mislead the reader. And such arguments certainly exist; the conservative parts of the media do as much as they can to play them up. But the mere existence of such arguments doesn’t defeat the average person’s testimonial knowledge about anthropogenic global warming. Similarly, the mere existence of misleading reports does not defeat our agent’s knowledge of the dictator’s death, as long as there is no nearby world where she is exposed to the reports. (Thanks here to an anonymous referee.)\nIn the second variant, the agent cares deeply about politics, and has masses of wealth at hand to ensure that she knows a lot about it. Were she to read the misleading reports that the dictator has survived, then she would simply use some of the very expensive sources she has to get more reliable reports. Again this suffices for the misleading reports not to be defeaters. Even before the rich agent exercises her wealth, the fact that her wealth gives her access to reports that will correct for misleading reports means that the misleading reports are not actually defeaters. So with her wealth she knows things she wouldn’t otherwise know, even before her money goes to work. Again, her money doesn’t generate knowledge – the original reliable report is the knowledge generator – but her wealth means that a would-be defeater doesn’t gain traction.\nThe same thing is true in Russell and Doris’s examples. The agent has quite a bit of evidence that \\(p\\). That’s why she knows \\(p\\). There’s a potential practical defeater for \\(p\\). But due to either indifference or wealth, the defeater is immunised. Surprisingly perhaps, indifference and/or wealth can be the difference between knowledge and ignorance. But that’s not because they can be in any interesting sense ‘knowledge makers’, any more than I can make a bowl of soup by preventing someone from tossing it out. Rather, they can be things that block defeaters, both when the defeaters are the kind Stanley talks about, and when they are more familiar kinds of defeaters.\n\n\n3 Temporal Embeddings\nMichael Blome-Tillmann (2009) has argued that tense-shifted knowledge ascriptions can be used to show that his version of Lewisian contextualism is preferable to IRI. Like Russell and Doris, his argument uses a variant of Stanley’s Bank Cases.10 Let \\(O\\) be that the bank is open Saturday morning. If Hannah has a large debt, she is in a high-stakes situation with respect to \\(O\\). In Blome-Tillmann’s version of the example, Hannah had in fact incurred a large debt, but on Friday morning the creditor waived this debt. Hannah had no way of anticipating this on Thursday. She has some evidence for \\(O\\), but not enough for knowledge if she’s in a high-stakes situation. Blome-Tillmann says that this means after Hannah discovers the debt waiver, she could say\n10 In the interests of space, I won’t repeat those cases yet again here.\nI didn’t know \\(O\\) on Thursday, but on Friday I did.\n\nBut I’m not sure why this case should be problematic for any version of IRI, and very unsure why it should even look like a reductio of IRI. As Blome-Tillmann notes, it isn’t really a situation where Hannah’s stakes change. She was never actually in a high stakes situation. At most her perception of her stakes change; she thought she was in a high-stakes situation, then realised that she wasn’t. Blome-Tillmann argues that even this change in perceived stakes can be enough to make (1) true if IRI is true. Now actually I agree that this change in perception could be enough to make (1) true, but when we work through the reason that’s so, we’ll see that it isn’t because of anything distinctive, let alone controversial, about IRI.\nIf Hannah is rational, then given her interests she won’t be ignoring \\(\\neg O\\) possibilities on Thursday. She’ll be taking them into account in her plans. Someone who is anticipating \\(\\neg O\\) possibilities, and making plans for them, doesn’t know \\(O\\). That’s not a distinctive claim of IRI. Any theory should say that if a person is worrying about \\(\\neg O\\) possibilities, and planning around them, they don’t know \\(O\\). And that’s simply because knowledge requires a level of confidence that such a person simply does not show. If Hannah is rational, that will describe her on Thursday, but not on Friday. So (1) is true not because Hannah’s practical situation changes between Thursday and Friday, but because her psychological state changes, and psychological states are relevant to knowledge.\nWhat if Hannah is, on Thursday, irrationally ignoring \\(\\neg O\\) possibilities, and not planning for them even though her rational self wishes she were planning for them? In that case, it seems she still believes \\(O\\). After all, she makes the same decisions as she would as if \\(O\\) were sure to be true. But it’s worth remembering that if Hannah does irrationally ignore \\(\\neg O\\) possibilities, she is being irrational with respect to \\(O\\). And it’s very plausible that this irrationality defeats knowledge. That is, you can’t be irrational with respect to a proposition and know it. Irrationality excludes knowledge. In any case, I doubt this is the natural way to read Blome-Tillmann’s example. We naturally read Hannah as being rational, and if she is rational she won’t have the right kind of confidence to count as knowing \\(O\\) on Thursday.\nThere’s a methodological point here worth stressing. Doing epistemology with imperfect agents often results in facing tough choices, where any way to describe a case feels a little counterintuitive. If we simply hew to intuitions, we risk being led astray by just focussing on the first way a puzzle case is described to us. But once we think through Hannah’s case, we see perfectly good reasons, independent of IRI, to endorse IRI’s prediction about the case.\n\n\n4 Problematic Conjunctions\nBlome-Tillmann offers another argument against IRI, that makes heavy use of the notion of having enough evidence to know something. Here is how he puts the argument. (Again I’ve changed the numbering and some terminology for consistency with this paper.)\n\nSuppose that John and Paul have exactly the same evidence, while John is in a low-stakes situation towards \\(p\\) and Paul in a high-stakes situation towards \\(p\\). Bearing in mind that IRI is the view that whether one knows \\(p\\) depends on one’s practical situation, IRI entails that one can truly assert:\n\nJohn and Paul have exactly the same evidence for \\(p\\), but only John has enough evidence to know \\(p\\), Paul doesn’t.\n\n(Blome-Tillmann 2009, 328–29)\n\nAnd this is meant to be a problem, because (2) is intuitively false.\nBut IRI doesn’t entail any such thing. We can see this by looking at a simpler example that illustrates the way ‘enough’ works.\nGeorge and Ringo both have $6000 in their bank accounts. They both are thinking about buying a new computer, which would cost $2000. Both of them also have rent due tomorrow, and they won’t get any more money before then. George lives in New York, so his rent is $5000. Ringo lives in Syracuse, so his rent is $1000. Clearly, (REC) and (RAC) are true.\n\nREC\n\nRingo has enough money to buy the computer.\n\nRAC\n\nRingo can afford the computer.\n\n\nAnd (GEC) is true as well, though there’s at least a reading of (GAC) where it is false.\n\nGEC\n\nGeorge has enough money to buy the computer.\n\nGAC\n\nGeorge can afford the computer.\n\n\nFocus for now on (GEC). It is a bad idea for George to buy the computer; he won’t be able to pay his rent. But he has enough money to do so; the computer costs $2000, and he has $6000 in the bank. So (GEC) is true. Admittedly there are things close to (GEC) that aren’t true. He hasn’t got enough money to buy the computer and pay his rent. You might say that he hasn’t got enough money to buy the computer given his other financial obligations. But none of this undermines (GEC).\nNow just like George has enough money to buy the computer, Paul has enough evidence to know that \\(p\\). Paul can’t know that \\(p\\), just like George can’t buy the computer, because of his practical situation. But that doesn’t mean he doesn’t have enough evidence to know it. He clearly does have enough evidence, since he has the same evidence John has, and John knows that \\(p\\). So, contra Blome-Tillmann, IRI doesn’t entail this problematic conjunction.\nIn a footnote attached to this, Blome-Tillmann offers a reformulation of the argument.\n\nI take it that having enough evidence to ‘know \\(p\\)’ in \\(C\\) just means having evidence such that one is in a position to ‘know \\(p\\)’ in \\(C\\), rather than having evidence such that one ‘knows \\(p\\)’. Thus, another way to formulate (2) would be as follows: ‘John and Paul have exactly the same evidence for \\(p\\), but only John is in a position to know \\(p\\), Paul isn’t.’ (Blome-Tillmann 2009, 329n23)\n\nNow having enough evidence to know \\(p\\) isn’t the same as being in a position to know it, any more than having enough money to buy the computer puts George in a position to buy it. So I think this is more of a new objection than a reformulation of the previous point. But might it be a stronger objection? Might it be that IRI entails (PosK), which is false?\n\nPosK\n\nJohn and Paul have exactly the same evidence for \\(p\\), but only John is in a position to know \\(p\\), Paul isn’t.\n\n\nActually, it isn’t a problem that IRI says that (PosK) is true. In fact, almost any epistemological theory will imply that conjunctions like that are true. In particular, any epistemological theory that allows for the existence of defeaters which do not supervene on the possession of evidence will imply that conjunctions like (PosK) are true. For example, anyone who thinks that whether you can know that a barn-like structure is really a barn depends on whether there are non-barns in the neighbourhood that look like the structure you’re looking at will think that conjunctions like (PosK) are true. Again, it matters a lot that IRI is suggesting that traditional epistemologists did not notice that there are distinctively pragmatic defeaters. Once we see that, we’ll see that conjunctions like (PosK) are not surprising at all.\nConsider again Con, and his friend Mod who is disposed to reason by modus ponens and not by affirming the consequent. We could say that Con and Mod have the same evidence for \\(p\\), but only Mod is in a position to know \\(p\\). There are only two ways to deny that conjunction. One is to interpret ‘position to know’ so broadly that Con is in a position to know \\(p\\) because he could change his inferential dispositions. But then we might as well say that Paul is in a position to know \\(p\\) because he could get into a different ‘stakes’ situation. Alternatively, we could say that Con’s inferential dispositions count as a kind of evidence against \\(p\\). But that stretches the notion of evidence beyond a breaking point. Note that we didn’t say Con had any reason to affirm the consequent, just that he does. Someone might adopt, or change, a poor inferential habit because they get new evidence. But they need not do so, and we shouldn’t count their inferential habits as evidence they have.\nIf that case is not convincing, we can make the same point with a simple Gettier-style case.\n\nGetting the Job\nIn world 1, at a particular workplace, someone is about to be promoted. Agnetha knows that Benny is the management’s favourite choice for the promotion. And she also knows that Benny is Swedish. So she comes to believe that the promotion will go to someone Swedish. Unsurprisingly, management does choose Benny, so Agnetha’s belief is true.\nWorld 2 is similar, except there it is Anni-Frid who knows that Benny is the management’s favourite choice for the promotion, that Benny is Swedish. So she comes to believe that the promotion will go to someone Swedish. But in this world Benny quits the workplace just before the promotion is announced, and the management unexpectedly passes over a lot of Danish workers to promote another Swede, namely Björn. So Anni-Frid’s belief that the promotion will go to someone Swedish is true, but not in a way that she could have expected.\n\nIn that story, I think it is clear that Agnetha and Anni-Frid have exactly the same evidence that the job will go to someone Swedish, but only Agnetha is in a position to know this, Anni-Frid is not. The fact that an intermediate step is false in Anni-Frid’s reasoning, but not Agnetha’s, means that Anni-Frid’s putative knowledge is defeated, but Agnetha’s is not. And when that happens, we can have differences in knowledge without differences in evidence. So it isn’t an argument against IRI that it allows differences in knowledge without differences in evidence.\n\n\n5 Holism and Defeaters\nThe big lesson of the last few sections is that interests create defeaters. Sometimes an agent can’t know \\(p\\) because adding \\(p\\) to her stock of beliefs would introduce either incoherence or irrationality. The reason is normally that the agent faces some decision where it is, say, bad to do \\(\\varphi\\), but good to do \\(\\varphi\\) given \\(p\\). In that situation, if she adds \\(p\\), she’ll either incoherently think that it’s bad to do \\(\\varphi\\) although it’s good to do it given what is (by her lights) true. Moreover, the IRI theorist says, being incoherent in this way blocks knowledge, so the agent doesn’t know \\(p\\).\nBut there are other, more roundabout, ways in which interests can mean that believing \\(p\\) would entail incoherence. One of these is illustrated by an example alleged by Ram Neta to be hard for interest-relative theorists to accommodate.\n\nKate needs to get to Main Street by noon: her life depends upon it. She is desperately searching for Main Street when she comes to an intersection and looks up at the perpendicular street signs at that intersection. One street sign says “State Street” and the perpendicular street sign says “Main Street.” Now, it is a matter of complete indifference to Kate whether she is on State Street–nothing whatsoever depends upon it. (Neta 2007, 182)\n\nLet’s assume for now that Kate is rational; dropping this assumption introduces mostly irrelevant complications. That is, we will assume Kate is an expected utility maximiser. Kate will not believe she’s on Main Street. She would only have that belief if she took it to be settled that she’s on Main, and hence not worthy of spending further effort investigating. But presumably she won’t do that. The rational thing for her to do is to get confirming (or, if relevant, confounding) evidence for the appearance that she’s on Main. If it were settled that she was on Main, the rational thing to do would be to try to relax, and be grateful that she had found Main Street. Since she has different attitudes about what to do simpliciter and conditional on being on Main Street, she doesn’t believe she’s on Main Street.\nSo far so good, but what about her attitude towards the proposition that she’s on State Street? She has enough evidence for that proposition that her credence in it should be rather high. And no practical issues turn on whether she is on State. So she believes she is on State, right?\nNot so fast! Believing that she’s on State has more connections to her cognitive system than just producing actions. Note in particular that street signs are hardly basic epistemic sources. They are the kind of evidence we should be ‘conservative’ about in the sense of Pryor (2004). We should only use them if we antecedently believe they are correct. So for Kate to believe she’s on State, she’d have to believe the street signs she can see are correct. If not, she’d incoherently be relying on a source she doesn’t trust, even though it is not a basic source.11 But if she believes the street signs are correct, she’d believe she was on Main, and that would lead to practical incoherence. So there’s no way to coherently add the belief that she’s on State Street to her stock of beliefs. So she doesn’t know, and can’t know, that she’s either on State or on Main. This is, in a roundabout way, due to the high stakes Kate faces.\n11 The caveats here about basic sources are to cancel any suggestion that Kate has to antecedently believe that any source is reliable before she uses it. As Pryor (2000) notes, that view is problematic. The view that we only get knowledge from a street sign if we antecedently have reason to trust it is not so implausible.Neta thinks that the best way for the interest-relative theorist to handle this case is to say that the high stakes associated with the proposition that Kate is on Main Street imply that certain methods of belief formation do not produce knowledge. And he argues, plausibly, that such a restriction will lead to implausibly sceptical results. But that’s not the only way for the interest-relative theorist to go. What they could, and I think should, say is that Kate can’t know she’s on State Street because the only grounds for that belief are intimately connected to a proposition that, in virtue of her interests, she needs very large amounts of evidence to believe.\n\n\n6 Non-Consequentialist Cases\nNone of the replies yet have leaned heavily on the last of the three points from the introduction, the fact that IRI is an existential claim. This reply will make heavy use of that fact.\nIf an agent is merely trying to get the best outcome for themselves, then it makes sense to represent them as a utility maximiser. But when agents have to make decisions that might involve them causing harm to others if certain propositions turn out to be true, then I think it is not so clear that orthodox decision theory is the appropriate way to model the agents. That’s relevant to cases like this one, which Jessica Brown has argued are problematic for the epistemological theories John Hawthorne and Jason Stanley have recently been defending.12\n12 The target here is not directly the interest-relativity of their theories, but more general principles about the role of knowledge in action and assertion. But it’s important to see how IRI handles the cases that Brown discusses, since these cases are among the strongest challenges that have been raised to IRI.\nA student is spending the day shadowing a surgeon. In the morning he observes her in clinic examining patient A who has a diseased left kidney. The decision is taken to remove it that afternoon. Later, the student observes the surgeon in theatre where patient A is lying anaesthetised on the operating table. The operation hasn’t started as the surgeon is consulting the patient’s notes. The student is puzzled and asks one of the nurses what’s going on:\nStudent: I don’t understand. Why is she looking at the patient’s records? She was in clinic with the patient this morning. Doesn’t she even know which kidney it is?\nNurse: Of course, she knows which kidney it is. But, imagine what it would be like if she removed the wrong kidney. She shouldn’t operate before checking the patient’s records. (Brown 2008, 1144–45)\n\nIt is tempting, but I think mistaken, to represent the payoff table associated with the surgeon’s choice as follows. Let Left mean the left kidney is diseased, and Right mean the right kidney is diseased.\n\n\n\n\n\nLeft\nRight\n\n\nRemove left kidney\n\\(1\\)\n\\(-1\\)\n\n\nRemove right kidney\n\\(-1\\)\n\\(1\\)\n\n\nCheck notes\n\\(1-\\varepsilon\\)\n\\(1-\\varepsilon\\)\n\n\n\n\nHere \\(\\varepsilon\\) is the trivial but non-zero cost of checking the chart. Given this table, we might reason that since the surgeon knows that she’s in the left column, and removing the left kidney is the best option in that column, she should remove the left kidney rather than checking the notes.\nBut that reasoning assumes that the surgeon does not have any obligations over and above her duty to maximise expected utility. And that’s very implausible, since consequentialism is a fairly implausible theory of medical ethics.13\n13 I’m not saying that consequentialism is wrong as a theory of medical ethics. But if it is right, so many intuitions about medical ethics are going to be mistaken that such intuitions have no evidential force. And Brown’s argument relies on intuitions about this case having evidential value. So I think for her argument to work, we have to suppose non-consequentialism about medical ethics.It’s not clear exactly what obligation the surgeon has. Perhaps it is an obligation to not just know which kidney to remove, but to know this on the basis of evidence she has obtained while in the operating theatre. Or perhaps it is an obligation to make her belief about which kidney to remove as sensitive as possible to various possible scenarios. Before she checked the chart, this counterfactual was false: Had she misremembered which kidney was to be removed, she would have a true belief about which kidney was to be removed. Checking the chart makes that counterfactual true, and so makes her belief that the left kidney is to be removed a little more sensitive to counterfactual possibilities.\nHowever we spell out the obligation, it is plausible given what the nurse says that the surgeon has some such obligation. And it is plausible that the ‘cost’ of violating this obligation, call it \\(\\delta\\), is greater than the cost of checking the notes. So here is the decision table the surgeon faces.\n\n\n\n\n\nLeft\nRight\n\n\nRemove left kidney\n\\(1-\\delta\\)\n\\(-1-\\delta\\)\n\n\nRemove right kidney\n\\(-1-\\delta\\)\n\\(1-\\delta\\)\n\n\nCheck notes\n\\(1-\\varepsilon\\)\n\\(1-\\varepsilon\\)\n\n\n\n\nAnd it isn’t surprising, or a problem for an interest-relative theory of knowledge, that the surgeon should check the notes, even if she believes and knows that the left kidney is the diseased one. This is not to say that the surgeon does know that the left kidney is diseased, just that the version of IRI being defended here is neutral on that question.\nThere is a very general point here. It suffices to derive IRI that we defend principles like the following:\n\nWhenever maximising expected value is called for, one should maximise expected value conditional on everything one knows.\nMaximising expected value is called for often enough that there exist the kinds of pairs of cases IRI claims exist. That’s because in some cases, changing the options facing an agent will make it the case that which live option is best differs from which live option is best given \\(p\\), even though the agent antecedently knew \\(p\\).\n\nBut that doesn’t imply that maximising expected value is always called for. Especially in a medical case, it is hard to square an injunction like “Do No Harm!” with a view that one should maximise expected value, since maximising expected value requires treating harms and benefits symmetrically. What would be a problem for the version of IRI defended here was a case with the following four characteristics.\n\nMaximising expected value is called for in the case.\nConditional on \\(p\\), the action with the highest expected value is \\(\\varphi\\).\nIt would be wrong to do \\(\\varphi\\).\nThe agent knows \\(p\\).\n\nIt is tempting for the proponent of IRI to resist any attempted counterexample by claiming it is not really a case of knowledge. That might be the right thing to say in Brown’s case. But IRI defenders should remember that it is often a good move to deny that the first condition holds. Consequentialism is not an obviously correct theory of decision making in morally fraught situations; purported counterexamples that rely on it can therefore be resisted.\n\n\n\n\n\n\nReferences\n\nBlome-Tillmann, Michael. 2009. “Contextualism, Subject-Sensitive Invariantism, and the Interaction of ‘Knowledge’-Ascriptions with Modal and Temporal Operators.” Philosophy and Phenomenological Research 79 (2): 315–31. https://doi.org/10.1111/j.1933-1592.2009.00280.x.\n\n\nBrown, Jessica. 2008. “Knowledge and Practical Reason.” Philosophy Compass 3 (6): 1135–52. https://doi.org/10.1111/j.1747-9991.2008.00176.x.\n\n\nFantl, Jeremy, and Matthew McGrath. 2002. “Evidence, Pragmatics, and Justification.” Philosophical Review 111: 67–94. https://doi.org/10.2307/3182570.\n\n\n———. 2009. Knowledge in an Uncertain World. Oxford: Oxford University Press.\n\n\nFeltz, Adam, and Chris Zarpentine. 2010. “Do You Know More When It Matters Less?” Philosophical Psychology 23 (5): 683–706. https://doi.org/10.1080/09515089.2010.514572.\n\n\nHam, Sandra A., Sarah Martin, and Harold W. Kohl III. 2008. “Changes in the Percentage of Students Who Walk or Bike to School-United States, 1969 and 2001.” Journal of Physical Activity and Health 5 (2): 205–15. https://doi.org/10.1123/jpah.5.2.205.\n\n\nHarman, Gilbert. 1973. Thought. Princeton: Princeton University Press.\n\n\nHawthorne, John. 2004. Knowledge and Lotteries. Oxford: Oxford University Press.\n\n\nHawthorne, John, and Jason Stanley. 2008. “Knowledge and Action.” Journal of Philosophy 105 (10): 571–90. https://doi.org/10.5840/jphil20081051022.\n\n\nMay, Joshua, Walter Sinnott-Armstrong, Jay G. Hull, and Aaron Zimmerman. 2010. “Practical Interests, Relevant Alternatives, and Knowledge Attributions: An Empirical Study.” Review of Philosophy and Psychology 1 (2): 265–73. https://doi.org/10.1007/s13164-009-0014-3.\n\n\nNeta, Ram. 2007. “Anti-Intellectualism and the Knowledge-Action Principle.” Philosophy and Phenomenological Research 75 (1): 180–87. https://doi.org/10.1111/j.1933-1592.2007.00069.x.\n\n\nPryor, James. 2000. “The Skeptic and the Dogmatist.” Noûs 34 (4): 517–49. https://doi.org/10.1111/0029-4624.00277.\n\n\n———. 2004. “What’s Wrong with Moore’s Argument?” Philosophical Issues 14 (1): 349–78. https://doi.org/10.1111/j.1533-6077.2004.00034.x.\n\n\nRussell, Gillian, and John M. Doris. 2009. “Knowledge by Indifference.” Australasian Journal of Philosophy 86 (3): 429–37. https://doi.org/10.1080/00048400802001996.\n\n\nStanley, Jason. 2005. Knowledge and Practical Interests. Oxford University Press.\n\n\nWeatherson, Brian. 2005. “Can We Do Without Pragmatic Encroachment?” Philosophical Perspectives 19 (1): 417–43. https://doi.org/10.1111/j.1520-8583.2005.00068.x.\n\nCitationBibTeX citation:@article{weatherson2011,\n  author = {Weatherson, Brian},\n  title = {Defending {Interest} {Relative} {Invariantism}},\n  journal = {Logos and Episteme},\n  volume = {2},\n  pages = {591-609},\n  date = {2011},\n  doi = {10.5840/logos-episteme2011248},\n  langid = {en}\n}"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/eigp/index.html",
    "href": "posts/eigp/index.html",
    "title": "Explanation, Idealisation and the Goldilocks Problem",
    "section": "",
    "text": "Michael Strevens’s book Depth is a great achievement.1 To say anything interesting, useful and true about explanation requires taking on fundamental issues in the metaphysics and epistemology of science. So this book not only tells us a lot about scientific explanation, it has a lot to say about causation, lawhood, probability and the relation between the physical and the special sciences. It should be read by anyone interested in any of those questions, which includes presumably the vast majority of readers of this journal.\n1 All page references, unless otherwise noted, are to Strevens (2008).\nImage from Creative Commons.\n\nOne of its many virtues is that it lets us see more clearly what questions about explanation, causation, lawhood and so on need answering, and frames those questions in perspicuous ways. I’m going to focus on one of these questions, what I’ll call the Goldilocks problem. As it turns out, I’m not going to agree with all the details of Strevens’s answer to this problem, though I suspect that something like his answer is right. At least, I hope something like his answer is right; if it isn’t, I’m not sure where else we can look.\n\n1 The Goldilocks Problem\nSam has engaged in some unhealthy activity, and is now profusely vomiting in the bathroom. Here are three things that are true of the buildup to this unfortunate turn of events.\n\nSam either ate a carton of raw eggs, or drank a bottle of vodka.\nSam ate a carton of raw eggs.\nSam ate a carton of raw eggs that were bought at midday.\n\nAll three of these claims are interesting things to know about the buildup to the vomiting. But intuitively, or at least according to my intuitions, (2) is the best explanation of the lot. That’s because intuitively, (1) is too weak, and (3) is too strong, while (2) is just right.\nLet’s assume for now these intuitions are correct. We then have the puzzle of explaining why explanations of moderate strength, like (2), are strictly better than either weaker explanations, like (1), or stronger explanations, like (3). Put another way, we have to explain what makes (2) ‘just right’. Call this the Goldilocks problem.2\n2 Strevens calls the problem of how to explain why (2) is a better explanation than (1) ‘the disjunction problem’. Given that the problem arises in the context of a theory that aims to explain why (2) is better than (3), I think the disjunction problem and the Goldilocks problem are not particularly distinct.If the Goldilocks problem was merely a matter of first-pass intuitions, then perhaps the right way to solve it would be to explain why we have quirky intuitons about explanations. But I think we can see that it turns on deeper features than that.\nOn the one hand, we want explanations, particularly of single events, to locate those events in the causal structure of the world. That’s why we’re pushed towards saying that (3) is the best explanation of Sam’s current activity. Indeed, in his defence of a causal theory of explanation, David Lewis (1986) says that (3) is really the best explanation, though we might prefer to use, or to offer, (2) for pragmatic reasons.\nOn the other hand, we want explanations that unify disparate phenomena. If we see that an event is just one instance of the right kind of pattern, it feels more explicable. That pushes us towards explanations that encompass more and more actual and possible outcomes. This pushes us away from (3) as an explanation, and towards (2), but also away from (2) and towards (1). After all, if we accepted (1) as the best explanation for what’s going on, we would have an explanation that encompasses even more events.3\n3 For more on explanation as unification, see Friedman (1974) and, especially, Kitcher (1989).We can also get pushed towards (1) as being the ideal explanation by considering ways in which (2) is a better explanation than (3). There is a sense in which some of the information in (3) is redundant. No matter when Sam bought the eggs, the vomiting would have resulted given that they were eaten. Here is one principle we might draw from that. If \\(E^\\prime\\) is logically weaker than \\(E\\), and the outcome \\(O\\) would have happened even if \\(E^\\prime\\) had happened but \\(E\\) had not, then \\(E^\\prime\\) is a better explanation than \\(E\\). This will get the right result that (2) is a better explanation than (3). But it will get the wrong result that (1) is a better explanation than (2).\nTo some extent, the observations of the last three paragraphs point to a solution to the Goldilocks problem. There are virtues that (2) has over (3), in not being too specific, and over (1), in being specific enough for the task at hand. But as a moment’s reflection will show, attempting to turn these ideas into a theory is not exactly trivial. It’s much too easy to come up with principles that end up implying that (2) has all the vices of (1) and (3), and is really worse than each, rather than better. (The attempt to use counterfactuals to give a sufficient condition for superiority of explanation in the last paragraph is illustrative of how we might end up theorising this way.) Having a theory of explanation that avoids these traps is both desirable, and difficult.\n\n\n2 Idealisations in Explanation\nMuch more familiar than the Goldilocks problem is the problem of accounting for the role of idealisations in explanation. Explanations seem, after all, factive. The sentence p because q just entails both \\(p\\) and \\(q\\). And yet explanations involving idealisations seem to be false. Here’s an illustrative example.\nOn a busy suburban corner, there are four gas stations.4 Although the price for which they offer gas fluctuates a lot from day to day, the four usually have the same price, even to the nearest tenth of a cent. Why might that be? One might suspect collusion, but we’ll stipulate that this is a real free market, and the stations are actually competing, not colluding. Another might be that the stations are using ‘cost-plus’ pricing. But in fact, given the many and varied ways in which the stations (or their corporate parents) have used derivatives to hedge their costs, the four actually face very different input costs. And in any case, a ‘cost-plus’ theory can’t explain the fluctuation of prices.\n4 ‘Petrol stations’ if that fits your dialect better.The real explanation is relatively simple. If any station charges a higher price than its rivals, then no one will come to that station. And that’s something the station desparately wants to avoid. So no station charges a higher price than the others. And that means they all charge the same price.\nNow why, might we ask, is it that if any station charges a higher price than its rivals, then no one will come to that station? There’s a simple explanation here too. First, customers know the prices at each of the four stations, or at least if they don’t the cost of getting those prices is zero. Second, the customers are each utility-maximisers who prefer having more money to less. And third, the goods that the stations are offering are perfect substitutes. Those three premises entail that a station with a higher price than the others will have zero customers.\nBut just wait! Precisely none of those three premises are perfectly true. There is some cost in figuring out the prices at each. If there weren’t, we couldn’t explain why stations put up such big signs advertising their prices. The point of those signs is to reduce the cost of acquiring price information. And, as philosophers of economics never tire of pointing out, customers aren’t perfect utility maximisers. And, finally, the goods aren’t perfect substitutes. The stations might have different queue lengths, or reputations for quality, or associations with firms that pollute the Gulf of Mexico, and so on.5\n5 Given the last point, we’d expect that after the BP disaster in the Gulf of Mexico, stations weren’t too worried about being undercut on price by a nearby BP station.Strevens has a nice story to tell here about what we should say about the explanations like the one I just offered. When the explainer says that, for instance, the cost of acquiring price information is zero, we should interpret them charitably, and loosely. We should apply the same principles as we apply when interpreting someone’s claim that Brazil is triangular. The truth-conditional content of the claim is not that the cost of acquiring price information is precisely zero. Rather, it is that the cost is in a not-too-large range that includes zero. How large is ‘not-too-large’? That depends on what the person is trying to explain? If they are trying to explain the size of gas station signage, it will be a small range; if they are trying to explain the dynamics of gas station pricing, it will be somewhat larger.\nStrevens’s theory here is hermeneutic, not revolutionary. He doesn’t say that we should replace the explanations that economists give, which are full of freely available information, perfectly substitutable goods, utility maximising agents and so on, with explanations that involve low cost information, highly substitutable goods, and agents who usually choose high utility outcomes. Rather, he is saying that the explanations those economists give already involve low cost (but not necessarily free) information, highly (but not necessarily perfectly) substitutable goods, and so on. This seems entirely right to me. Well known results showing the limitations of human rationality simply don’t undermine the stories like the one I told explaining the correlation between prices at nearby gas stations, even though a cursory glance at those explanations might appear to involve appeal to perfectly rational buyers.\nNow what happens when we interpret an explanation as saying not that some value is zero, but that it is near zero? Well, we get an instance of the Goldilocks problem back. We could imagine an explanation of the gas station prices that includes the exact value of the cost of acquiring information about each station’s price. That explanation would be more precise than the explanation that merely says the cost of acquiring price information is low. But despite that increase in precision, it would be a worse explanation, and it would be worse for just the same reason that (3) is a worse explanation than (2). (Of course, we haven’t yet said just what that reason is!)\nSo puzzles about idealisations in explanation reduce, given Strevens’s nice hermeneutic suggestion, to the Goldilocks problem. That raises the interest in solving the Goldilocks problem, so let’s turn to Strevens’s own solution to it.\n\n\n3 The Kairetic Theory of Explanation\nI’m going to have to simplify a lot in sketching Strevens’s theory of explanation, but I hope the following offers a not-too-inaccurate picture. For Strevens, explanations of individual events are causal models. (Explanations of regularities are basically explanations of the events that make up the regularity.) A causal model is a valid argument, whose premises are all true, and whose conclusion is the event to be explained, such that the conclusion can be derived from the premises using (more-or-less) nothing but modus ponens, with every such step, from \\(C\\) and \\(C \\rightarrow E\\) to \\(E\\), being such that in reality \\(C\\) caused \\(E\\). When an argument has this property, Strevens says that the premises causally entail the conclusion. In practice, these models typically have three (kinds of) premises: a specification of initial conditions, a law (or set of laws) linking those conditions to the eventual result, and a ‘no defeaters’ condition, since the laws in question will usually not guarantee any outcome.6\n6 For instance, the gravitational law says that there is a downward force on my coffee cup, but it doesn’t guarantee that it moves downwards. And, indeed, there are currently sufficiently many forces acting on it that it remains suspended 80 feet above the ground. The ‘no defeaters’ clause is intended to rule out such mischief.There will usually be many such explanations. For instance, we could start with either (1), (2) or (3), add an appropriate law and a no defeaters condition, and causally derive that Sam is nauseous. Strevens then puts two extra conditions on causal models, one of which provides a ranking of explanations, the other of which is a necessary condition for an explanation being satisfactory.\nThe ranking condition is that the weaker the set of initial conditions are, the better the explanation is. If we weaken the initial conditions, but can still causally derive the explanandum, then the stronger set of initial conditions contained redundant information and better explanations excise redundant information. The condition that some information is necessary for the causal entailment to go through is what Strevens calls ‘the kairetic condition’ on explanatory relevance, and that in turn is why the theory is called a kairetic theory of explanation.\nOnce we loosen the specification of the initial conditions, a range of different possible causal pathways are compatible with the argument being a causal entailment. The necessary condition Strevens adds is that these possible pathways must be coherent. And he defines cohesion as “dynamic contiguity” (105). That is, if we situate all the possible causal chains in a possible space, an argument satisfies the cohesion condition if the set of chains consistent with the argument’s premises causally entailing the conclusion form a contiguous set.\nNote that contiguity is not that closely related to a similarity condition. The set of all possible causal pathways is perfectly contiguous, although its members are severely dissimilar. On the other hand, some small sets of causal pathways are not contiguous. So consider (4) and (5) below. Arguably the set of worlds in which (4) is true is not contiguous – there is a disconnect between the worlds where Suzy throws and the worlds where Billy throws – while the set of worlds in which (5) is true is contiguous.\n\nEither Billy or Suzy threw a brick at the window at exactly \\(2\\pi\\) mph.\nSuzy threw a brick at the window at between 5 and 30 mph.\n\nAlthough the worlds where Suzy throws hard are very dissimilar from the worlds where Suzy throws softly, there is a chain of worlds connecting the two. And each member of the chain is very similar to the next member. That suffices for contiguity.\nIt’s important to what follows that Strevens takes contiguity here to be physical contiguity. That is, two worlds (or causal pathways) are contiguous iff they are contiguous from the perspective of fundamental physics. Contiguity is not meant to be something defined in terms of explanations, and nor is it meant to be contiguity in terms of properties of interest to the special sciences. This will be important for what follows.\nWe’re now in a position to see Strevens’s solution to the Goldilocks problem. The detail about when Sam bought the eggs is irrelevant to the conclusion that Sam is nauseous. As long as the eggs were bought, and eaten, Sam’s nausea will exist. Indeed, its existence will be guaranteed by a causal law, given the appropriate ‘no defeaters’ condition. So the kairetic condition says we improve the explanation of Sam’s nausea by dropping the time at which the eggs were bought.7 Now if we start with (1), there will still be a causal law that lets us derive Sam’s nausea. But the space of causal pathways consistent with the argument we generate will not be contiguous. It will contain the worlds where the eggs cause nausea, and the worlds where the vodka causes nausea, and nothing in between. So it isn’t an eligible explanation. So the kairetic account predicts, correctly, that the best explanation of Sam’s nausea starts with (2). QED.\n7 Of course, if we wanted to explain the time of Sam’s nausea, and not just its existence, the extra details in (3) might matter.\n\n4 Equilibrium Explanations in Economics\nBut there’s a difficulty looming for this nice theory. It isn’t at all clear how we’re going to generalise it to cover explanations in the social sciences. It’s perhaps easiest to see this if we look at an example. This example is originally from Hendricks and Porter (1988), though much of my discussion of it leans heavily on the exposition in Sutton (2000, 47–56).\nThe fact to be explained concerns the amount that oil exploration firms pay for, and eventually earn from, licences to drill in various tracts of the Gulf of Mexico. At various times, the government opens up the rights to drill on new tracts of sea bed. Firms are allowed to make a single bid for the rights to these tracts, and the highest bid wins. Some firms that bid have, prior to the opening of the new tract, drilling rights to some adjacent tract, and some do not. Having drilling rights to an adjacted tract is useful, because oil deposits tend not to follow the sharp lines on government surveyors’ maps. If you have already been working on an area adjacent to the one being auctioned, you have a pretty good idea how much oil that tract contains. If you don’t, then you have to make a guess based on more general features of that region of the Gulf. The stylised fact to be explained is that firms that bid on tracts adjacent to their existing tracts made a large profit, on average, while firms that bid on non-adjacent tracts made no net profit. (In fact they averaged a small loss, but the amount is close enough to zero that it’s worth treating their net returns as zero.) Why might this be?\nThe explanation that Hendricks and Porter offer starts with the following game, from Wilson (1967). Assume that two players, \\(A\\) and \\(B\\), are bidding on a good of some value in \\([0, 1]\\). \\(A\\) knows exactly how valuable the good is - call this value \\(x\\). \\(B\\) has no idea how valuable the good is; her credences about its possible value are distributed evenly over \\([0, 1]\\). Both \\(A\\) and \\(B\\) know these facts about each other. What should each of them do?\nStandard game theory has an answer. The game has a single Nash equilibrium. \\(A\\) bids \\(\\frac{x}{2}\\), and \\(B\\) plays a mixed strategy, randomly choosing a bid from \\([0, \\frac{1}{2}]\\). If each of them play these strategies, then \\(A\\) has an expected return of \\(\\frac{x^2}{2}\\), and \\(B\\) has an expected return of 0. Moreover, given each of them is playing those strategies, the other party cannot do better by changing their strategy. (That’s just what it means for the strategies to form a Nash equilibrium.)\nNow Hendricks and Porter go on to suggest that the drilling rights auctions are more or less like these games, with \\(A\\)’s role being filled by the firm with an adjacent tract, and \\(B\\)’s role by the firm with no adjacent tract.8 If we apply that model, we get plausible results for how much profit the two kinds of firms should earn, including a nice story about why the non-adjacent firms earn no profit. Indeed, we even get a satisfactory (at least to economists) story about why firms without adjacent tracts continue to bid even though they earn no net profit by doing so. If they didn’t bid, then firms with adjacent tracts could win the bidding by bidding a penny, and then it would be valuable to bid. In other words, the only equilibrium solution requires them to bid, even though they get no gain from it.\n8 There are a lot of technical details I’m suppressing here, many of which Hendricks and Porter take into account, and many of which they rightly suppress. Sutton characterises Hendricks and Porter’s model as having considerably fewer added complications to the simple game Wilson develops than Hendricks and Porter themselves do. For instance, Sutton suppreses, while Hendricks and Porter explicitly consider, the possible efficiency gains derivable from owning adjacent tracts, but this only makes a small difference to the final result. On the kairetic theory of explanation, these simplifications actually improve the explanation considerably.There is obviously a bit of work to do to show that this game provides a good model of Gulf of Mexico auctions. For one thing, we have to show that we can treat the auction as having effectively two players. Hendricks and Porter suggest that the behaviour of firms with adjacent tracts is sufficiently cooperative that this is a legitimate idealisation. There are other idealisations too, all of which I think can be fit nicely into Strevens’s kairetic story. We have to treat the firms with adjacent tracts as knowing the value of the tract, when really they’ll only know the approximate value. But it is plausible that treating their ignorance as being zero-valued, i.e., treating their knowledge as being perfect, makes no difference to what we need to explain. Similarly, it is not really true that the other firms have no idea how valuable the tracts are. But their knowledge levels are close enough to being represented by a flat probability distribution over the possible values of the tract that it doesn’t make a difference to this story to model their knowledge more precisely.\n(There is an interesting technical point here. Strevens focuses on cases where the idealisations involve giving some variable a “zero, infinite or some other extreme or default value” (318). In social sciences, one useful ‘default’ value is that the variable is represented by a flat probability function over some interval. This will rarely be exactly right; whether we interpret the probability function metaphysically or epistemically the ‘right’ function will presumably have some bumps or kinks in it. But it is an acceptable idealisation.)\nSo far so good. We started with an interesting set of facts, we found a nice mathematical model that has the facts as a consequence, and we argued (or at least hinted at how one could argue) that the deviation between the model and the facts was irrelevant to the outcome to be explained. So we’ve arguably fit a widely accepted economic explanation into the kairetic framework.\nBut once we start looking at the details, some problems start to emerge. Remember that on the kairetic account, explanations must be causal derivations. It doesn’t look at first like we’ve got any causation in the economic explanation. But I think that’s wrong. After all, there’s a reason why the two types of firms bid they way they do. The structure of the auction, along with other facts, causes them to make these bids. It isn’t something you’ll see highlighted in Hendricks and Porter, but it’s arguable their story is a causal story.\nThe problem is the ‘other facts’ you need to cite to complete this causal explanation. Those don’t seem to be sufficiently ‘cohesive’ for Strevens’s story to hold up. What we know is that if the actors follow equilibrium strategies, then we’ll get the results that are actually observed. But why should we think that actors will do just that? There are several possible reasons; too many reasons it might seem for the kairetic theory to work.\nPossibly the actors are perfectly rational, and perfectly rational beings play Nash equilibrium strategies.9 Possibly the actors are worried about their strategies leaking out, and are maximising expected utility relative to that assumption.10 Possibly there are a number of actors playing other strategies, but they don’t tend to survive economically, and so the statistics are dominated by firms that do survive, and the survivors generally play equilibrium strategies.11 Possibly the firms are run by a lot of game theorists, and “game theory is an excellent way of predicting the behaviour of professional game theorists.”12 More likely, some combination of these four reasons, and even some others, is causally relevant to the establishment and maintenance of this equilibrium.\n9 The normative claim here, that perfectly rational beings play Nash equilibrium strategies, seems implausible to me for reasons similar to those set out by Stalnaker (1996, 1998, 1999).10 Note that maximising expected utility does not entail playing equilibrium strategies without some extra assumption about strategies leaking, since a mixed strategy can be part of a unique equilibrium, but can never be uniquely utility maximising.11 Philosophers tend to overstate how much economists rely on rationality assumptions. One of the attractions of game-theoretic explanations is that they don’t require all the agents to be perfectly rational. After all, game-theoretic explanations work well in evolutionary biology, and the players there are certainly not perfectly rational. For more on this point, and especially on how much work economists do to weaken rationality postulates, see Hahn (1996).12 The quote is from a blog post by Daniel Davies on October 8, 2010. See http://d-squareddigest.blogspot.com/2010/10/on-not-being-obliged-to-vote-for.html.And that is something that’s hard to fit into the kairetic framework. We can show how the background facts about the case (i.e., the risks and rewards facing the competing oil firms), and a general causal law (i.e., that firms tend to end up playing equilibrium strategies) entail the conclusions that various firms bid on newly released tracts despite having zero expected profit. The problem is that many distinct causal pathways are compatible with this loosely described causal structure, and these pathways are not ‘cohesive’. So the kairetic theory of explanation predicts that the explanation offered in Hendricks and Porter (1988) is not a good explanation of the observed behaviour in the auctions. That should worry anyone who either finds it intuitively plausible that it is a good explanation, or thinks that we should defer somewhat to the salient experts on what is a good explanation.\n\n\n5 Possible Responses\nI think these equilibrium explanations are a challenge to Strevens’s solution to the Goldilocks problem, and I think that’s a problem given the importance of solving the Goldilocks problem to the broader aims of the kairetic theory of explanation. But there are a number of ways Strevens could respond to this challenge. Indeed, we can see three responses already made in Depth. So I’ll end by noting why I don’t think those three responses work.\nFirst, it is true that some equilibrium explanations are cohesive in Strevens’s sense. Strevens discusses an example proposed by Elliot Sober (1983). Here is how Strevens describes the case.\n\nConsider a ball released at the inside lip of a basin. The ball rolls down into, then back and forth inside, the basin, eventually coming to rest at its lowest point. This will happen no matter what the ball’s release point. … Sober claims, quite rightly, that an equilibrium explanation … is the best explanation of the ball’s final resting place. (267-8)\n\nNow there are many ways in which the ball might have reached its equilibrium state. But note that these ways are all fairly similar to one another. The ways are, collectively, cohesive in just the sense needed for the kairetic theory.13 But this is surely an accident of the example. The ways in which agents reach a game-theoretic equilibrium are very different from one another, which makes that case rather unlike the case of a ball descending to the bottom of a basin. In short, while some equilibrium explanations will be suitably cohesive many, perhaps even most, will not.\n13 Actually, this sentence isn’t as obviously true as it seems. Strevens’s discussion of the case brings out some unexpected difficulties in accommodating Sober’s claim in the kairetic theory. But this doesn’t affect my point, which is that the case is relatively easy for the kairetic theory to accommodate.14 This might be reading too much into Strevens’s discussion. What he says about a related example is that the existence of communicative channels within firms is part of the ‘framework’ when making economic explanations. I don’t know whether he would extend this story to cover all means by which firms get to equilibrium.Second, sometimes we don’t want to fully explain why \\(p\\) is true, but merely why \\(p\\) is true rather than \\(q\\), or why \\(p\\) is true given that \\(r\\) is true. In these cases, Strevens says that we exploit ‘explanatory frameworks’ (149) which fix certain facts as given for the purposes of explanation. So we might take \\(p \\vee q\\), or \\(r\\), to simply be fixed background facts; part of the framework relative to which explanations are made. When a proposition is part of the framework, its presence in the derivation of the intended outcome does not contribute to incohesiveness (163). So if we say that, for instance, the fact that games like the tract auction end up at equilibrium is part of the framework, then the orthodox explanation of, say, why firms bid despite a zero expected profit, can work. In short, the story about why firms bid is incohesive, but the story about why firms bid given that firms play equilibrium strategies is cohesive, and it is the latter that economists are trying to explain.14\nNow perhaps that’s true of what some economists are doing some of the time. But it seems too defeatist to me. Part of the appeal of game theoretic explanations is that they are supposed to explain why we get to, and stay at, equilibrium. I don’t think a practicing economist would say that they are merely presupposing that players in a game reach equilibrium, as opposed to offering a theory where that fact falls out as a nice explanandum. It’s true that economists do leave some things in the framework. They generally assume that economic actors are agents, while leaving the story about how agency might be physically realised to other disciplines. But it seems wrong to me to say that all the facts about how equilibrium is established and preserved are simply framework questions.\nFinally, Strevens notes that we can often refer to causal processes in explanations without being able to fully describe them. If someone asks why the temperature in this room stays so even while the temperature in other rooms fluctuates, I can explain the stability by saying that a thermostat regulates the temperature. Now at first this might look like a very incohesive explanation. There are many ways that a thermostat might work, and they don’t form anything like a coherent set. But perhaps that’s the wrong way to take my explanation. We could take the explanation as referring to the particular thermostat that is present, and the particular way in which it regulates the temperature. That explanation will be very cohesive; indeed, the real worry is that it is too precise. Of course, I might not be able to describe the process by which the thermostat regulates temperature. But this is no barrier to my being able to refer to it, any more than ignorance of chemistry is a barrier to my being able to refer to H\\(_2\\)O.\nCould this help with the tract auction we are discussing? At first glance it seems like it might. Perhaps the explanation can simply refer to the means by which a particular firm ends up playing an equilibrium strategy, even if it cannot describe that means. But the second glance is more troubling. Remember that what we’re trying to explain here is an average, not a particular firm’s behaviour. And it is meant to be consistent with the explanations that different firms get to equilibrium in very different ways. So we can’t really just refer to those different methods; we can only describe what they have in common. And that leaves us back with an incohesive explanation. Indeed, Strevens notes this point in a similar context when he says that “in aggregative and regularity explanation … there is a real risk” that we won’t pick out a cohesive causal mechanism. (154)\nSo I’m left thinking that we need somehow to supplement the story Strevens offers to make it plausible as an account of explanation in the special sciences. The kind of equilibrium explanations game theorists offer of economic outcomes are at least sometimes good explanations. But what makes them good is not the cohesiveness of their underlying physical mechanisms. It is, at least intuitively, the cohesiveness of the explanations from the perspective of the special science in question. If that intuition is right, we theorists still have work to do in characterising this notion of cohesiveness.\n\n\n\n\n\n\nReferences\n\nFriedman, Michael. 1974. “Explanation and Scientific Understanding.” Journal of Philosophy 71 (1): 5–19. https://doi.org/10.2307/2024924.\n\n\nHahn, Frank. 1996. “Rerum Cognoscere Causas.” Economics and Philosophy 12 (2): 183–95. https://doi.org/10.1017/S0266267100004156.\n\n\nHendricks, Kenneth, and Robert H. Porter. 1988. “An Empirical Study of an Auction with Asymmetric Information.” The American Economic Review 78 (5): 865–83.\n\n\nKitcher, Philip. 1989. “Explanatory Unification and the Causal Structure of the World.” In Scientific Explanation, edited by Philip Kitcher and Wesley Salmon, 13:410–505. Minnesota Studies in Philosophy of Science. Minneapolis: University of Minnesota Press.\n\n\nLewis, David. 1986. “Causal Explanation.” In Philosophical Papers, II:214–40. Oxford: Oxford University Press.\n\n\nSober, Elliot. 1983. “Equilibrium Explanation.” Philosophical Studies 43 (2): 201–10. https://doi.org/10.1007/BF00372383.\n\n\nStalnaker, Robert. 1996. “Knowledge, Belief and Counterfactual Reasoning in Games.” Economics and Philosophy 12: 133–63. https://doi.org/10.1017/S0266267100004132.\n\n\n———. 1998. “Belief Revision in Games: Forward and Backward Induction.” Mathematical Social Sciences 36 (1): 31–56. https://doi.org/10.1016/S0165-4896(98)00007-9.\n\n\n———. 1999. “Extensive and Strategic Forms: Games and Models for Games.” Research in Economics 53 (3): 293–319. https://doi.org/10.1006/reec.1999.0200.\n\n\nStrevens, Michael. 2008. Depth: An Account of Scientific Explanations. Cambridge, MA: Harvard University Press.\n\n\nSutton, John. 2000. Marshall’s Tendencies: What Can Economists Know? Cambridge, MA: MIT Press.\n\n\nWilson, Robert B. 1967. “Competitive Bidding with Asymmetric Information.” Management Science 13 (11): 816–20. https://doi.org/10.1287/mnsc.13.11.816.\n\nCitationBibTeX citation:@article{weatherson2012,\n  author = {Weatherson, Brian},\n  title = {Explanation, {Idealisation} and the {Goldilocks} {Problem}},\n  journal = {Philosophy and Phenomenological Research},\n  volume = {84},\n  number = {2},\n  pages = {461-473},\n  date = {2012-03},\n  doi = {10.1111/j.1933-1592.2011.00574.x},\n  langid = {en}\n}"
  },
  {
    "objectID": "posts/humsup/index.html",
    "href": "posts/humsup/index.html",
    "title": "Humean Supervenience",
    "section": "",
    "text": "1 What is Humean Supervenience?\nAs with many aspects of David Lewis’s work, it is hard to provide a better summary of his views than he provided himself. So the following introduction to what the Humean Supervenience view is will follow the opening pages of Lewis (1994a) extremely closely. But for those readers who haven’t read that paper, here’s the nickel version.\nHumean Supervenience is the conjunction of three theses.\n\nTruth supervenes on being (Bigelow 1988). That is, all the facts about a world supervene on facts about which individuals instantiate which fundamental properties and relations.\nAnti-haeccaetism. All the facts about a world supervene on the distribution of qualitative properties and relations; rearranging which properties hang on which ‘hooks’ doesn’t change any facts.\nSpatio-temporalism. The only fundamental relations that are actually instantiated are spatio-temporal, and all fundamental properties are properties of points or point-sized occupants of points.\n\nThe first clause is a core part of Lewis’s metaphysics. It is part of what it is for some properties and relations to be fundamental that they characterize the world. Indeed, Lewis thinks something stronger, namely that the fundamental properties and relations characterize the world without redundancy (Lewis 1986a, 60). This probably isn’t true, for a reason noted in Sider (1993). Consider the relations earlier than and later than. If these are both fundamental, then there is some redundancy in the characterisation of the world in terms of fundamental properties and relations. But there is no reason to believe that one is fundamental and the other isn’t. And it is hard to see how we could give a complete characterisation of the world without either of these relations. So we’ll drop the claim that the fundamental properties relations characterise the world without redundancy, and stick to the weaker claim, namely that the fundamental properties and relations characterize the world completely.\nThe second clause is related to Lewis’s counterpart theory. Consider what it would be like for anti-haeccaetism to fail. There would have to be two worlds, with the same distribution of qualitative properties, but with different facts obtaining in each. These facts would have to be non-qualitative facts, presumably facts about which individual plays which role. So perhaps, to use a well-known example, there could be a world in which everything is qualitatively as it is in this world, but in which Barack Obama plays the Julius Caeser role, and vice versa. So Obama conquers Gaul and crosses the Rubicon, Caeser is born in Hawai’i and becomes President of the United States. But what could make it the case that the Gaul-conqueror in that world is really Obama’s counterpart, and not Caeser’s? Nothing qualitative, and nothing else it seems is available. So this pseudo-possibility is not really a possibility. And so on for all other counterexamples to anti-haeccaetism.\nThe third clause is the most striking. It says there are no fundamental relations beyond the spatio-temporal, or fundamental properties of extended objects. If we assume that ‘properties’ of objects with parts are really relations between the parts, and anything extended has proper parts, then the second clause reduces to the first. I think it isn’t unfair to read Lewis as holding both those theses.\nSince for Lewis the fundamental qualities are all intrinsic, the upshot is that the world is characterized by a spatio-temporal distribution of intrinsic qualities. As Lewis acknowledged, this was considerably more plausible given older views about the nature of physics than it is now. We’ll return to this point at great length below. But for now the key point to see the kind of picture Humean Supervenience offers. The world is like a giant video monitor. The facts about a monitor’s appearance supervene, plausibly, on intrinsic qualities of the pixels, plus facts about the spatial arrangement of the pixels. The world is 4-dimensional, not 2-dimensional like the monitor, but the underlying picture is the same.\n\n\n2 Supervenience\nGiven the name Humean Supervenience  you might expect it to be possible to state Humean Supervenience as a supervenience thesis. But this turns out to be hard to do. Here is one attempt at stating Humean Supervenience as a supervenience thesis that is happily clear, and unhappily false.\n\nStrong Modal Humean Supervenience\n\nFor any two worlds where the spatio-temporal distribution of fundamental qualities is the same, the contingent facts are the same.\n\n\nBut Humean Supervenience does not make a claim this strong. It is consistent with Humean Supervenience that there could be fundamental non-spatio-temporal relations. The only thing Humean Supervenience claims is that no such relations are instantiated. In a pair of possible worlds where there are such relations, and the relations vary but the arrangement of qualities is the same, Strong Modal Humean Supervenience will fail. In the Introduction to Lewis (1986b), he suggested the following weaker version.\n\nLocal Modal Humean Supervenience\n\nFor any two worlds at which no alien properties or relations are instantiated, if the spatio-temporal distribution of fundamental qualities is the same at each world, the contingent facts are also the same.\n\n\nAn alien property(/relation) is a fundamental property(/relation) that is not actually instantiated. So this version of Humean Supervenience says that to get a difference between two worlds, you have to either have a change in the spatio-temporal arrangement of qualities, or the instantiation of actually uninstantiated fundamental properties or relations.\nBut Lewis eventually decided that wouldn’t do either. In response to Haslanger (1994), he conceded that enduring objects would generate counterexamples to Local Modal Humean Supervenience even if there were no alien properties or relations. So he fell back to the following, somewhat vaguely stated, thesis. (See Lewis (1994a) for the concession, and Hall (2010) for an argument that he should not have conceded this to Haslanger.)\n\nFamiliar Modal Humean Supervenience\n\nIn any two “worlds like ours”, if the spatio-temporal distribution of fundamental qualities is the same at each world, the contingent facts are also the same (Lewis 1994a, 475).\n\n\nWhat’s a “world like ours’? It isn’t, I fear, entirely clear. But this doesn’t matter for the precise statement of Humean Supervenience. The three theses in section 1 are clear enough, and state what Humean Supervenience is. The only difficulty is in stating it as a supervenience thesis.\n\n\n3 What is Perfect Naturalness?\nThat definintion does, however, require that we understand what it is for some properties and relations to be fundamental, or, as Lewis put it following his discussion in Lewis (1983), perfectly natural. The perfectly natural properties and relations play a number of interconnected roles in Lewis’s metaphysics and his broader philosophy.\nMost generally, they characterise the difference between real change and ‘Cambridge change’, and the related difference between real similarity, and mere sharing of grue-like attributes. This somewhat loose idea is turned, in Plurality, into a definition of duplication.\n\n…two things are duplicates iff (1) they have exactly the same perfectly natural properties, and (2) their parts can be put into correspondence in such a way that corresponding parts have exactly the same perfectly natural properties, and stand in the same perfectly natural relations. (Lewis 1986a, 61)\n\nThe intrinsic properties are then defined as those that are shared between any two (possible) duplicates. So, as noted above, Humean Supervenience says that the spatio-temporal distribution of intrinsic features of points characterises worlds like ours.\nI’ve gone back and forth between describing these properties as fundamental and describing them as perfectly natural. And that’s because for Lewis, the perfectly natural properties are in a key sense fundamental. For reasons to do with the nature of vectorial properties, I think this is probably wrong (Weatherson 2006). That is, we need to hold that some derivative properties are perfectly natural in order to get the definition of intrinsicness terms of perfect naturalness to work. But for Lewis, the perfectly natural properties and relations are all fundamental.\nPart of what Lewis means by saying that some properties are fundamental is that all the facts about the world supervene on the distribution. (This is Bigelow’s thesis that truth supervenes on being.) But I think he also means something stronger. The non-fundamental facts don’t merely supervene on the fundamental facts; those non-fundamental facts are true because the fundamental facts are true, and in virtue of the truth of the fundamental facts.\nThe perfectly natural properties play many other roles in Lewis’s philosophy besides these two. They play a key role in the theory of laws, for instance. They are a key part of Lewis’s solution to the New Riddle of Induction (Goodman 1955). And they play an important role in Lewis’s theory of content, though just exactly what that role is is a matter of some dispute. (See Sider (2001) and Weatherson (2003) for one interpretation, and Schwarz (2009) for a conflicting interpretation.)\nNow it is a pretty open question whether any one division of properties can do all these roles. One way to solve the New Riddle (arguably Lewis’s way, though this is a delicate question of interpretation) is to be a dogmatist (in the sense of Pryor (2000)) about inductive projections involving a privileged class of properties. Lewis’s discussion of the New Riddle at the end of Lewis (1983) sounds like he endorses this view, with the privileged class being the very same class as fundamentally determines the structure of the world, and makes for objective similarity and difference. But why should these classes be the same? It might make more sense to, for instance, endorse dogmatism about inductive projections of observational properties, rather than about microphysical properties.\nLewis doesn’t attempt to give a theoretically neutral definition of the perfectly natural properties. Rather, the notion of a perfectly natural property is introduced by the theoretical role it serves. But that theoretical role is very ambitious, covering many areas in metaphysics, epistemology and the theory of content. We might wonder whether claims like Humean Supervenience have any content if it turns out nothing quite plays that theoretical role. I think there is still a clear thesis we can extract, relying on the connection between intrinsicness and naturalness. It consists of the following claims:\n\nThere is a small class of properties and relations such that the contingent facts at any world supervene on the distribution of these properties and relations.\nEach of these properties is an intrinsic property.\nAt the actual world, the only relations among these which are instantiated are spatio-temporal, and all the contingent facts supervene not merely on the distribution of fundamental qualities and relations, but also on the distribution of fundamental qualities and relations over points and point-sized occupants of points.\n\nThose theses are distinctively Lewisian, they are clearly entailed by Humean Supervenience as Lewis’s conceives of them, they are opposed in one way or another by those who take themselves to reject Humean Supervenience, but they are free of any commitment to there being a single class of properties and relations that plays all the roles Lewis wants the perfectly natural properties and relations to play. So from now on, when I discuss the viability of Humean Supervenience, I’ll be discussing the viability of this package of views.\n\n\n4 Humean Supervenience and other Humean Theses\nLewis endorsed many views that we might broadly describe as ‘Humean’. Of particular interest here are the following three.\n\nHumean Supervenience.\nNomological Reductionism. Nomological properties and relations (including lawhood, chance and causation) are not among the fundamental properties and relations.\nModal Combinatorialism. Roughly, anything can co-exist with anything else.\n\nWe’ve stated Modal Combinatorialism extremely roughly, and will persist with using a fairly informal version of it throughout. For an excellent study of more careful versions of it, see Nolan (1996). But those details aren’t as important to this debate. What is important for now is that all three of these theses are associated with what are known as Humean approaches to metaphysics in the contemporary literature. But how closely connected are they to each other, or for that matter to Hume.\nOne question about Humean Supervenience is just how it connects to the work of the historical Hume. This would be a little easier to answer if there was a broad scholarly consensus that Hume actually believed the kind of simple regularity thesis of causation that Lewis attributes to him at the start of Lewis (1973). But it isn’t clear that this is Hume’s view (Strawson 2000). What is true is that Hume was sceptical that we could know more about causation than that it was manifested in certain distinctive kinds of correlations. But it is a further step to say that Hume inferred that causation just consists of these distinctive kinds of correlations.\nA second question is how Humean Supervenience, which perhaps should be referred to as so-called “Humean Supervenience”, or perhaps even better as “Lewisian Supervenience”, relates to the kind of regularity theory that Lewis attributes to Hume, or to the prohibition on necessary connections between distinct existences that underlies Modal Combinatorialism. Lewis seemed to see the three theses as related. Here he is explaining how he chose to name Humean Supervenience (and recall that this isn’t backed up by any detailed exegesis of Hume).\n\nHumean Supervenience is named in honour of the great denier of necessary connections. It is the doctrine that all there is to the world is a vast mosaic of local matters of particular fact just one little thing and then another. (Lewis 1986b ix)\n\nThis is a slightly confusing passage, since it isn’t clear why a violation of Humean Supervenience would constitute a necessary connection of any kind. We will return to this point below. But it does seem to make clear that Lewis thought that Humean Supervenience and Modal Combinatorialism were connected, since Modal Combinatorialism is much more closely connected to the denial that they can be necessary connections between distinct existences.\nCompare how Lewis introduces Humean Supervenience when discussing the role of possible worlds in formulating trans-world supervenience theses in Plurality.\n\nAre the laws, chances, and causal relationships nothing but patterns which supervene on this point-by-point distribution of properties? Could two worlds differ in their wars without differing, somehow, somewhere, in local qualitative character? (I discuss this question of ‘Humean Supervenience’, inconclusively, in the Introduction to my Philosophical Papers, volume II.) (Lewis 1986a, 14)\n\nThis seems to connect Humean Supervenience closely to Nomological Reductionism, since it makes the reducibility of the nomological properties and relations central to the question of whether Humean Supervenience is true. We can also, I think, see Lewis connecting Modal Combinatorialism and Nomological Reductionism in a later passage in Plurality where he discusses why he doesn’t believe that laws are necessary truths.\n\nAnother use of Modal Combinatorialism is to settle – or as opponents might say, to beg – the question whether the laws of nature are strictly necessary. They are not … Episodes of bread-eating are possible because actual; as are episodes of starvation. Juxtaposed duplicates of the two, on the grounds that anything can follow anything; here is a possible world to violate the law bread nourishes. … It is no surprise that Modal Combinatorialism prohibited strictly necessary connections between distinct existences. What I have done is to take a Humean view about laws and causation, and use it instead as a thesis about possibility. Same thesis, different emphasis. (Lewis 1986a, 91)\n\nSo for Lewis, these three theses are meant to be closely connected. And it is true that in the contemporary literature all three of them are frequently described as ‘Humean’ theses. (Or at least they are so described in metaphysics and philosophy of science; again, we’re bracketing questions of historical interpretation here.) But on second glance, it isn’t as clear what the connection between the three theses could amount to. One immediate puzzle is that Humean Supervenience is for Lewis a contingent thesis, while the other two theses are necessary truths. The accounts of causation, lawhood and chance that he gives in defending Nomological Reductionism are clearly meant to hold in all kinds of worlds, not just worlds like ours. (Consider the amount of effort that is spent in Lewis (2004a) at defending the theory of causation from examples involving wizards, action at a distance and so on.) And the formulation of Modal Combinatorialism in Plurality leaves little doubt that it is meant to be necessarily true.\nThis difference in modal status means that the theses can’t be in any way equivalent. But you might think that they are in some way reinforcing. Even that isn’t so clear. Consider the most dedicated kind of denier of Modal Combinatorialism, namely the fatalist who thinks that every truth is a necessary truth. She will endorse Humean Supervenience. After all, she thinks that all the truths about the world supervene on any category of truths whatsoever, so they’ll supervene on intrinsic properties of point-sized objects.\nIn the other direction, failures of Humean Supervenience don’t motivate compromising Modal Combinatorialism. Imagine a world where occasionally there are pairs of people who can know what each other is thinking, even though there is no independent informational chain between the two of them. It is just that a telepathic connection exists. Moreover, there is no rhyme or reason to when a pair of people will be telepathic; it is simply the case that some pairs of people are. In such a world, it is plausible that being a telepathic pair will be a fundamental relation. That’s not a problem for Humean Supervenience, since there aren’t any such pairs in this world. But it does mean Humean Supervenience is false in that world.\nAssume that Daniels and O’Leary are a telepathic pair. Any duplication of the pair of them will also be telepathic, since by Lewis’s preferred definition of duplication, duplication preserves all fundamental properties and relations. Does that mean there’s a necessary connection between Daniels and O’Leary? Not really. The spirit of Modal Combinatorialism is that you can duplicate any parts of any worlds, and combine them. One part of our world is Daniels. A duplicate of him need not include any telepathic connection to O’Leary; indeed, he has duplicates in worlds in which O’Leary is absent. Another part of the world is O’Leary; duplicates of him need not include a connection to Daniels. Putting the two together, there is a world where there are duplicates of Daniels and O’Leary, but no telepathic connection between the two. So Modal Combinatorialism suggests that even when Humean Supervenience fails, there won’t be a necessary connection between distinct objects. So Humean Supervenience really isn’t that important to the idea that there are no necessary connection between distinct existences.\nWhat’s closer to the truth, I think, is that Humean Supervenience is interesting because of Modal Combinatorialism. If Modal Combinatorialism fails, then Humean Supervenience doesn’t capture anything important. In particular, it doesn’t capture the idea that the nomic is somehow less fundamental than (some features of) the non-nomic. It is only given Modal Combinatorialism that we can make these kinds of priority claims in modal terms. Think about the philosopher who denies Modal Combinatorialism on the grounds that laws of nature are necessarily true. That philosopher will say that the laws supervene on the distribution of intrinsic properties of points, because the laws supervene on any set of facts that you like. But they will deny that this makes the distribution of intrinsic properties of points more fundamental than the laws. It is only given Modal Combinatorialism that we can claim that supervenience theses are any guide whatsoever to fundamentality.\nWhat about the connection between Nomological Reductionism and Humean Supervenience? It can’t be equivalence, since Lewis agrees that Humean Supervenience fails in worlds in which Nomological Reductionism is true. For the same reason, it can’t be that failures of Humean Supervenience entail failures of Nomological Reductionism. What about the other direction? Could we imagine Nomological Reductionism failing while Humean Supervenience holds? I think this is a coherent possibility, but not at all an attractive one. (Compare, in this respect, the discussion of theories that “qualify technically as Humean” at (Lewis 1994a, 485).) It requires that some of the irreducible, nomological properties be intrinsic properties of point-sized objects. Well, we could imagine two worlds where \\(F\\) and \\(G\\) are co-extensive, intrinsic properties of points, and in one of them it is a law that all \\(F\\)s are \\(G\\)s, and in the other it is a law that all \\(G\\)s are \\(F\\)s, and there are further intrinsic properties of all the points which are \\(F\\) and \\(G\\) which underlie these laws without making a difference to any of the other facts. So we imagine that the property being F in virtue of being G is held by all these things in one world but not in the other, and this is a fundamental perfectly natural property. I don’t think any of this is literally inconsistent, and I think filling out the details could give us a way for Nomological Reductionism to fail while the letter of Humean Supervenience holds. But it would clearly violate the spirit of Humean Supervenience  and it isn’t clear why we should believe in such ‘possibilities’ anyway.\nSo in practice, I think that any philosopher who rejects Nomological Reductionism is probably going to want to reject Humean Supervenience. And I think that Lewis saw some of the deepest challenges to Humean Supervenience as coming from threats to Nomological Reductionism. In particular, Lewis thought that the biggest challenges to Humean Supervenience came from the difficulties in providing a reductive account of chance, and the appeal of non-reductive series of causation.\nThe difficulties in providing a reductive account of chance are discussed at length in the introduction to Lewis (1986b), and in the only paper that has ‘Humean Supervenience’ in its title, i.e., Lewis (1994a). Here is a quick version of the problem. Chances are not fundamental, so they must supervene on the distribution of qualities. At least in the very early stages of the universe, there aren’t enough facts about the distribution of qualities in the past and present to form a suitable subvenient base for the chances. So whether the chance of \\(p\\) is \\(x\\) or \\(y\\) will, at least some of the time, depend on how the future of the world turns out. Now let \\(p\\) the proposition that tells the full story about the future of the world. And assume that \\(p\\) is a proposition such that what its chance is depends on how that future goes. If it goes the way \\(p\\) says it will go, the chance of \\(p\\) is \\(x\\); if it goes some other way, the chance of \\(p\\) is \\(y\\). Given a Humean theory of chance, Lewis says that this is going to be possible.\nBut now there’s a problem. What Lewis calls the Principal Principle says that if we know the chance of \\(p\\) is \\(y\\), and have no further information, then our credence in \\(p\\) should be \\(y\\). But in this case, if we knew the chance of \\(p\\) was \\(y\\), we could be sure that \\(p\\) would not obtain. So our credence in \\(p\\) should be 0. Here we seem to have reached a contradiction, and it is a contradiction to Lewis for a long time feared undermined the prospect of giving a reductive account of chance. The solution he eventually settled on in Lewis (1994a) was to slightly modify the Principal Principle, with the modification being designed to make very little difference in regular cases, but avoid this contradiction.\nLewis discusses the appeal of non-reductive theories of causation in several places, most notably for our purposes Lewis (2004a) and Lewis (2004c). Much of his attention is focused on the theory developed by Peter Menzies (1996). Menzies suggests that causation is the intrinsic relation that does the best job of satisfying folk platitudes about causation. A consequence of Menzies’s view is that there is something that makes a difference to the intrinsic properties of pairs of causes and effects which doesn’t supervene on either the intrinsic properties of the two ends of the causal chain, or on the spatio-temporal relations that hold between them. This something will either be causation or will be something on which causation depends. Either way there is a problem for Humean Supervenience, since there will have to be a perfectly natural relation that is not spatio-temporal.\nLewis’s response is to raise problems for the idea that causation could be an intrinsic relation. One class of worries concerns the very idea that causation could be a relation. Lewis says that absences can be causes and effects, but absences can’t stand in any relations, so causation must not be a relation. Another class of worries concerns the idea that causation could be intrinsic. Causation by double prevention, says Lewis, doesn’t look like it could be intrinsic. But intuitively there could be causation by double prevention. Yet another class of worries concerns the idea that causation could be a natural relation, or that there could be any one thing that satisfies all the platitudes about causation. The vast array of different ways in which causes can bring about their effects in the actual world, he says, undermines this possibility.\nNote that in both cases Lewis defends Humean Supervenience simply by defending Nomological Reductionism. So I think it is fair to say that there’s a close connection between the two in Lewis’s overall theory.\n\n\n5 Why Care about Humean Supervenience\nAs is well-known, some surprising results in quantum mechanics suggest that entanglement relations are somehow fundamental (Maudlin 1994). This suggests that Humean Supervenience is actually false. If that’s right, why should we care about philosophical arguments for Humean Supervenience? Lewis’s response to this challenge is somewhat disconcerting.\n\nReally, what I uphold is not so much the truth of Humean Supervenience as the tenability of it. If physics itself were to teach me that it is false, I wouldn’t grieve.\nThat might happen: maybe the lesson of Bell’s Theorem is exactly that … But I am not ready to take lessons in ontology from quantum physics as it now is. … If, after quantum theory has been cleaned up, it still teaches non-locality, I shall submit willingly to the best of authority.\nWhat I want to fight are philosophical arguments against Humean Supervenience. When philosophers claim that one or another commonplace feature of the world cannot supervene on the arrangement of qualities, I make it my business to resist. Being a commonsensical fellow (except where unactualised possible worlds are concerned) I will seldom deny that the features in question exist. I grant their existence, and do my best to show how they can, after all, supervene on the arrangement of qualities. (Lewis 1986b xi)\n\nWe can, I think, dismiss the point about quantum physics as it was in 1986. The theory has been cleaned up in just the way Lewis wanted, and the claims about non-locality remain. Indeed, by the end of his life Lewis was willing to take lessons in ontology from quantum physics. See, for example, Lewis (2004b). So what is at issue here is whether or not there are philosophical arguments against Humean Supervenience.\nBut at this point we might wonder why we should care. If a theory is false, what does it matter whether its falsehood is shown by philosophy or by physics? We might compare the dismissive attitude Lewis takes towards Plantinga’s attempts to show that reconstructions of the problem of evil as an argument do not rely solely on things provable in first-order logic (Lewis 1993).\nThe answer I offered in Weatherson (2009) was that the philosophical defence of Humean Supervenience was connected to the point of the last paragraph quoted above. Lewis wanted to save various features of our commonsensical picture of the world. And he wanted to do this without saying that philosophical reflection showed us that the picture of the world given to us by signs of somehow incomplete. He wanted to defend what I called ‘compatibilism’, something that I contrasted with eliminativism and expansionism. The eliminativists want to say that science shows us that some commonsensical feature of reality doesn’t really exist. (See, for example, Churchland (1981) for eliminativism about folk psychological states.) The expansionists want to say that since science (or at least physics) doesn’t recognise certain features of reality, but they obviously exist, we need to posit that science (or at least physics) is incomplete. There are many stripes of philosophical expansionists, from theists to dualists to believers in agent causation.\nLewis wasn’t averse in principle to either eliminativism or expansionism. One could, depending on exactly how one interpreted folk theory and science, classify him as an eliminativist about gods, and an expansionist about unactualised possible worlds. But his first tendency was always to support compatibilism. Compatibilists face what Frank Jackson (1998) called the ‘location problem’. They have to show where the commonsensical features are located in the scientific picture. That is, they have to show how to reduce (in at least some sense of ‘reduce’) or commonsensical concepts to scientific concepts. (Many compatibilists may bristle at the idea that they have to be reductionists; in recent decades the world has abounded with ‘non-reductive physicalists’, who are precisely compatibilists in my sense, but who reject what they call ‘reductionism’. But as Lewis (1994b) argued, these rejections often turn on reading too much into the notion of reduction. For that reason, Lewis would not have objected to being described as a reductionist about many everyday concepts.)\nOne way to perform such a reduction would be to wait until the best scientific theory is developed, and show where within it we find minds, meanings, morals and all the other exciting features of our ordinary worldview. But that could take a while, and philosophers could use something to do while waiting. In the meantime we could look for a recipe that should work no matter what physical theory the scientists settle on, or at least should work in a very wide range of cases. I think we can see Lewis’s defence of Humean Supervenience as providing such a recipe.\nIt is important to note here that Lewis’s defence of Humean Supervenience was largely constructive. He didn’t try to give a proof that there couldn’t be more to the world than the arrangement of local qualities. At least, he didn’t rest a huge amount of weight on such arguments. The arguments we will look at below for a functional construal of the nomological are, perhaps, hints at arguments of this type. But, in general, Lewis defended Humean Supervenience by explicitly showing where the ordinary concepts fitted in to a sparse physical picture of reality, under the assumption that physics tells us that the world consists of nothing but a spatio-temporal arrangement of intrinsic qualities.\nNow physics tells us no such thing. But it shouldn’t matter. If the recipe Lewis provides works in the case of the ‘Humean’ world, it should also work in the world physics tells us we actually live in. The reduction of laws to facts about the distribution of fundamental qualities, and the reduction of chances and counterfactual dependencies to facts about laws, and the reduction of causation to facts about chances and counterfactual dependencies, and the reduction of mind to facts about causation and the distribution of qualities, and the reduction of value to facts about minds, and so on are all independent of whether physics tells us that we have to recognise relationships like entanglement as fundamental. In other words, if we can solve the location problem for the Humean world, we can solve it for the actual world. And solving the location problem is crucial to defending compatibilism. And whether it is possible to defend compatibilism is a central concern of metaphysics.\nI quoted above a passage from 1986 in which Lewis links Humean Supervenience to compatibilism. It’s worth noting that he returns to the point in 1994.\n\nThe point of defending Humean Supervenience is not to support reactionary physics, but rather to resist philosophical arguments that there are more things in heaven and earth in physics has dreamt of. Therefore if I defend the philosophical tenability of Humean Supervenience, that defence can doubtless be adapted to whatever better supervenience thesis may emerge from better physics. (Lewis 1994a, 474)\n\nThat is, the defence of Humean Supervenience just is part of the argument against expansionism, and hence for compatibilism. That was the defence I offered in Weatherson (2009) for the interest of Lewis’s defence of Humean Supervenience, even if it were to turn out that Humean Supervenience was refuted by physics. I still think much of it is correct. In particular, I still think that Lewis wanted to defend compatibilism, and that the defence of Humean Supervenience is key to the defence of Humean Supervenience. Indeed, I think there is pretty strong textual evidence that it was a major part of Lewis’s motivation for defending Humean Supervenience. But this explanation of why the defence of Humean Supervenience is significant can’t explain why Lewis was so worried about the failures of Humean theories of chance. After all, if all we are trying to do is show that science and commonsense are compatible, we could just take chances to be one of the fundamental features of reality given to us by science. There isn’t any need, from the perspective of trying to reconcile science and common sense, to give a reductive account of chance. Yet Lewis clearly thought that giving a reductive account of chance was crucial to the defence of Humean Supervenience. As he said,\n\nThere is one big bad bug: chance. It is here, and here alone, that I fear defeat. But if I’m beaten here, then the entire campaign goes kaput. (Lewis 1986b xiv)\n\nI now think that attitude is very hard to explain if my earlier views about the significance of Humean Supervenience are entirely correct. The natural conclusion is that there is something more that the defence of Humean Supervenience is supposed to accomplish. One plausible interpretation is that what it is supposed to accomplish is a vindication of the idea that the key nomological concepts are, in a sense, descriptive. It’s easiest to say what this sense is by contrasting it with the kind of view that Lewis rejected.\nWe’re all familiar with the standard story about ‘water’. Our ordinary usage of the term latches onto some stuff in the physical world. That stuff is H\\(_2\\)O. Some people think that’s because our ordinary usage determines a property which H\\(_2\\)O satisfies, others because we demonstratively pick out H\\(_2\\)O in ordinary demonstrations of what it is we’re talking about when we use the term ‘water’. Either way, we get to be talking about H\\(_2\\)O when we use the word ‘water’, even if we are so ignorant of chemistry that we can’t tell hydrogen and oxygen apart. Moreover, our term continues to pick out ‘water’ even in worlds that are completely free of hydrogen and oxygen, and even if such worlds have other stuff that plays a very similar functional role to the role water plays in the actual world.\nLewis was somewhat sceptical of this standard story about ‘water’ (Lewis 2002). He thought that the ordinary term was ambiguous between our usage on which it picked out H\\(_2\\)O, and usage on which it picked out a role, a role that happens to be played by H\\(_2\\)O in the actual world but which could be played by other substances in other worlds. But if he thought the standard story about ‘water’ was at best, part right, he thought applying a similar story to ‘law’, ‘cause’ and ‘chance’ was wildly implausible.\nIf such a story were right, then we would expect to find worlds where there was some relation other than causation which played the causal role. Since the actual world is physical, any world in which nonphysical things stand in the kind of relations that causes and effects typically stand in should do. So, for instance, if we have a world where the castings of spells are frequently followed by transformations from human to toad form, we should have a world where spells don’t cause such transformations but rather the spellcasting and the transformation stand in a kind of fool’s cause relationship. But we see no such thing. In such magical worlds, spells cause transformations.\nSo whatever causation is, it doesn’t look to be the kind of thing whose essence can be discovered by physics. Physics couldn’t tell us anything about the essence of the relationship between the spell and the transformation into a toad. But, we think, physics can tell us a lot about the fundamental properties and relations are instantiated in the actual world. So causation must not be one of them.\nLewis has a number of other arguments against anti-descriptivist views about individual nomological concepts. These arguments strike me as rather strong in the case of lawhood and causation, and less strong in the case of chance.\nIf being F and being F in virtue of a law are both fundamental properties, then a plausible principle of modal recombination would suggest they could come apart. But they cannot; or at least they cannot in one direction. We want being F in virtue of a law to entail being F. That’s easy if lawhood is defined in terms of fundamental properties of things; but it’s hard to see how it could be if lawhood itself is fundamental (Lewis 1986b xii).\nA similar argument goes for causation. Assume that causation is a fundamental intrinsic relation that holds between things at different times. Consider, for instance, the causal relationship which holds between a throw of a rock (call it \\(t\\)) and the shattering of the window (call it \\(s\\)). As we noted above in the case of Daniels and O’Leary, several applications of Modal Combinatorialism suggest that there will be a world just like this one in which \\(t\\) is followed by \\(s\\), but in which \\(t\\) does not cause \\(s\\). But such a world seems to be impossible. As we also noted above, such a view runs into trouble with causation by double prevention, which does not look to be intrinsic.\nThe last two paragraphs have been extremely quick arguments, but in both cases it seems to me that they can be tightened up so as to provide good arguments for some kind of descriptivist stance towards laws and causation. Chance is another matter.\nThe first problem is that recombination arguments if anything point away from descriptivism about chance. Any such account will imply that chances can’t, in general, point too far away from frequencies. But recombination arguments suggest that chances and frequencies can come arbitrarily far apart. Consider some particular event type \\(e\\) that has a one-half chance of occurring in circumstances \\(c\\). Start with a world where \\(c\\) occurs frequently, and about half the time it is followed by \\(e\\). Now use recombination to generate a world where all the \\(c \\wedge \\neg e\\) events are deleted, so \\(c\\) is always followed by \\(e\\). Unless we add a lot of bells and whistles to our theory of chance, it will no longer be the case that the chance of \\(e\\) given \\(c\\) is one-half. That is odd; we can’t simply take the first circumstance where \\(c\\) occurred and at that moment there was a one-half chance of it being followed by \\(e\\), and patch it into an arbitrary world. Bigelow, Collins, and Pargetter (1993) turn this idea into a more careful argument against descriptivism about chance. They say that chances should satisfy the following principle. (In this principle, \\(Ch\\) is the chance function, and various subscripts relativise it to times and worlds.)\n\nSuppose \\(x &gt; 0\\) and \\(Ch_{tw}(A) = x\\). Then \\(A\\) is true in at least one of those worlds \\(w^{\\prime}\\) that matches \\(w\\) up to time \\(t\\) and for which \\(Ch_t(A) = x\\). (Bigelow, Collins, and Pargetter 1993, 459)\n\nThat is, if the chance of \\(A\\) at \\(t\\) is \\(x\\), and \\(x &gt; 0\\), then \\(A\\) could occur without changing the history prior to \\(t\\), and without changing the chance of \\(A\\) at \\(t\\). This seems like a plausible principle of chance, but it entails the not-so-Humean view that chances at \\(t\\) supervene on history to \\(t\\), not on the full state of the world.\nNow as it turns out Lewis doesn’t rest on recombination arguments against rival views of chance, and in my view he is wise to do so. Instead he rests on epistemological arguments. He takes the following two things to be data points.\n\nSomething like the Principal Principle is true. The original Principal Principle said that if you knew the chance of \\(p\\) at \\(t\\) was \\(x\\), and didn’t have any ‘inadmissible’ information (roughly, information about how the world developed after \\(t\\)), then your credence in \\(p\\) should be \\(x\\). Lewis tinkered with this slightly, as we noted above, but he took it to be a requirement on a theory of chance that the Principal Principle turn out at least roughly right.\nThe correct theory of chance will explain the Principal Principle.\n\nLewis frequently wielded this second requirement against rival theories of chance. Here’s one example.\n\nI can see, dimly, how it might be rational to conform my credences about outcomes to my credencs about history, symmetries and frequencies. I haven’t the faintest notion how it might be rational to conform my credences about outcomes to my credences about some mysterious unHumean magnitude. Don’t try to take away the mystery my saying that this unHumean magnitude is none other than chance! (Lewis 1986b xv)\n\nBut this also seems like a weak argument. For one thing, chances are actually correlated very well with frequencies, and this correlation does not look at all accidental. It seems very plausible to me that we should line up our credences with things that are actually correlated well with frequencies. But, you might protest, shouldn’t we have an explanation of why the Principal Principle is an a priori principle of rationality? I think that before we ask for such an explanation, we should check how confident we are that the Principal Principle, or anything else, is part of an a priori theory of rationality. I’m not so confident that we’ll be able to do this (Weatherson 2005, 2007).\nThere are other replies too that we might make. It seems plausible that we should minimise the expected inaccuracy of our credences (Joyce 1998). This is true when we consider not just the subjective expected inaccuracy of our credences, but the objective expected inaccuracy of our credences. That is, when we calculate the expected inaccuracy of someone’s credences, using chances as the probabilities for generating the expectations, it is good if this expected inaccuracy is as low as possible. But, assuming that we are using a proper scoring rule for measuring the accuracy of credences, this means that we must have credences match chances.\nMore generally, I’m very sceptical of theories that insist our metaphysics be designed to have complicated epistemological theses fall out as immediate consequences. Rationality requires that we be inductivists. Why is that? Here’s a bad way to go about answering it: find a theory of persistence that makes induction obviously rational, and then require our metaphysics to conform to that theory. I don’t think you’ll get a very good theory of persistence that way, and, relatedly, you won’t get a very Lewisian theory of persistence that way. The demand that the theory of chance play a central role in an explanation of the Principal Principle strikes me as equally mistaken.\nIf what I’ve been saying so far is correct, then chance interacts with the motivation for Humean Supervenience in very different ways to how laws and causation interact. Neither of the two kinds of motivations for defending Humean Supervenience against philosophical attacks provides us with good reason to leave chances out of the subvenient base on which we say all contingent facts supervene. This is not to yet offer anything like a positive argument for chances to be part of the fundamental furniture of reality. Rather, what I’ve argued here is that a metaphysics that takes chances as primitives would not be as far removed from a recognisably Lewisian metaphysics as a metaphysics that takes laws or causes as primitive, let alone one that takes mind, meanings or morals as primitive.\n\n\n6 Points, Vectors and Lewis\nThe other main point from the discussion of the previous section is that the fact that quantum mechanics raises problems for Humean Supervenience does not undercut the philosophical significance of Lewis’s defence of Humean Supervenience. But is Humean Supervenience even compatible with classical physics? Perhaps not.\n\nEven classical electromagnetism raises a question for Humean Supervenience as I stated it. Denis Robinson (1989) has asked: is a vector field an arrangement of local qualities? I said qualities were intrinsic; that means they can never differ between duplicates; and I would have said offhand that two things can be duplicates even if they point in different directions. May be this last opinion should be reconsidered, so that vector-valued magnitudes may count as intrinsic properties. What else could they be? Any attempt to reconstruct with them as relational properties seems seriously artificial. (Lewis 1994a, 474)\n\nThe opinion that the Lewis proposes to discard here seems more than an offhand judgement. It seems to follow from the very way that we introduce the notion of duplication. Here is Lewis’s own attempt to introduce the notion.\n\nWe are familiar with cases of approximate duplication, e.g., when we use copying machines. And we understand that if these machines were more perfect than they are, the copies they made would be perfect duplicates of the original. Copy and original would be alike in size and shape and chemical composition of the ink marks and the paper, alike in temperature and magnetic alignment and electrostatic charge, alike even in the exact arrangement of their electrons and quarks. Such duplicates would be exactly alike we say. They would match perfectly, they would be qualitatively identical, they would be indiscernible. (Lewis 1983, 355)\n\nIf Lewis is right that vector-valued magnitudes may count as intrinsic properties, then there is yet another condition that the perfect copying machine must satisfy. The original and the duplicate must be parallel. This isn’t the case in most actual copying machines. Usually, the original is laid flat, while the duplicate is a small angle to make it easier to collect. This is a feature, not a bug. It is not a way in which the machine falls short of perfect copying. But if vector-valued magnitudes are intrinsic qualities, and duplicates share their intrinsic qualities, it would be. So Lewis is wrong to think that these vector-valued magnitudes may be intrinsic.\nMoreover, the little argument that Lewis gives seems to rest on a category mistake. What matters here is the division of properties into intrinsic and extrinsic. But the properties on the kind of things that can be relational or non-relational. As Humberstone (1996) shows, concepts and not properties of the things that can be relational and non-relational. For instance the concept being the same shape as David Lewis actually was at noon on January 1, 1970, is a relational concept that presumably picks out an intrinsic property, namely a shape property. Whether they are valued magnitudes are intrinsic or extrinsic properties, is somewhat orthogonal question of whether it is best to pick them out by means of relational or non-relational concepts.\nThere is a further issue about the compatibility of Humean Supervenience with classical physics. This is a point that has been made well by Jeremy Butterfield (2006), and we can see the problem by looking at the different ways in which Lewis introduces Humean Supervenience.\n\nHumean Supervenience says that in a world like ours, the fundamental properties are local qualities: perfectly natural intrinsic properties of points, or of point-sized occupants of points. (Lewis 1994a, 474)\n\nLewis goes back and forth between local properties and intrinsic properties of points here. These aren’t the same thing. As Butterfield notes, ‘local’ is used in a few different ways throughout physics. One simple usage identifies local properties of a point with properties that supervene on intrinsic features of arbitrarily small regions around the point. To take an important example, the slope of a curve at a point may be a local property of the curve at that point without being intrinsic property of the point.\nThis raises a question: can we do classical physics with only intrinsic properties of points, and not even these further local properties? Butterfield argues, persuasively, that the answer is no. He notes, however, that there are some very mild weakenings of Humean Supervenience that avoid this difficulty. Here is a very simple one.\nCall Local Supervenience the following thesis. For any length \\(\\varepsilon\\) greater than 0, there is a length \\(d\\) less than \\(\\varepsilon\\) with the following feature. All the facts about the world supervene on intrinsic features of objects and regions with diameter at most \\(d\\), plus facts about the spatio-temporal arrangement of these objects and regions. This will mean that we can include all local qualities in the subvenient base, without assuming that these are intrinsic qualities of points. If the theory of intrinsicness in Weatherson (2006) is correct, we’ll also be able to include vector-valued magnitudes in the subvenient base without assuming that these are intrinsic properties of points. (On my view, they will end up being intrinsic properties of asymmetrically shaped regions.) We still won’t be able to accommodate entanglement relationships, but we will be able to capture classical physics. And, for the reasons discussed in the previous section, it would still be worthwhile to ask whether there are philosophical objections to Local Supervenience. A negative answer would greatly assist the arguments for compatibilism, and for nomological descriptivism.\nButterfield offers from theses like Local Supervenience to Lewis as friendly suggestions. But he thinks Lewis’s focus on points and their properties would have led him to reject it. I don’t want to get into the business of making counterfactual speculation about what Lewis would or would not have accepted. But I think he should have been happy to weaken Humean Supervenience to something like Local Supervenience. If the point of defending Humean Supervenience is not to defend its truth, but rather to assist in larger arguments for compatibilism, and for nomological descriptivism, then the big question to ask is whether a defence of Local Supervenience (against distinctively philosophical objections) would have served those causes just as well. And I think it’s pretty clear that it would have. Showing that we have no philosophical reason to posit fundamental non-local features of reality would be enough to let us “resist philosophical arguments that there are more things in heaven and earth in physics has dreamt of” (Lewis 1994a, 474). Lewis’s work in defending Humean Supervenience has been invaluable to those of us who want to join this resistance. It wouldn’t have been undermined if he’d allowed some local properties into the mix.\n\n\n\n\n\nReferences\n\nBigelow, John. 1988. The Reality of Numbers: A Physicalist’s Philosophy of Mathematics. Oxford: Oxford.\n\n\nBigelow, John, John Collins, and Robert Pargetter. 1993. “The Big Bad Bug: What Are the Humean’s Chances?” The British Journal for the Philosophy of Science 44 (3): 443–62. https://doi.org/10.1093/bjps/44.3.443.\n\n\nButterfield, Jeremy. 2006. “Against Pointillisme about Mechanics.” British Journal for the Philosophy of Science 57 (4): 709–53. https://doi.org/10.1093/bjps/axl026.\n\n\nChurchland, Paul. 1981. “Eliminative Materialism and the Propositional Attitudes.” Journal of Philosophy 78 (2): 67–90. https://doi.org/10.2307/2025900.\n\n\nGoodman, Nelson. 1955. Fact, Fiction and Forecast. Cambridge: Harvard University Press.\n\n\nHall, Ned. 2010. “David Lewisś Metaphysics.” In The Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta, Fall 2010. http://plato.stanford.edu/archives/fall2010/entries/lewis-metaphysics/; Metaphysics Research Lab, Stanford University.\n\n\nHaslanger, Sally. 1994. “Humean Supervenience and Enduring Things.” Australasian Journal of Philosophy 72 (3): 339–59. https://doi.org/10.1080/00048409412346141.\n\n\nHumberstone, I. L. 1996. “Intrinsic/Extrinsic.” Synthese 108 (2): 205–67. https://doi.org/10.1007/bf00413498.\n\n\nJackson, Frank. 1998. From Metaphysics to Ethics: A Defence of Conceptual Analysis. Clarendon Press: Oxford.\n\n\nJoyce, James M. 1998. “A Non-Pragmatic Vindication of Probabilism.” Philosophy of Science 65 (4): 575–603. https://doi.org/10.1086/392661.\n\n\nLewis, David. 1973. “Causation.” Journal of Philosophy 70 (17): 556–67. https://doi.org/10.2307/2025310.\n\n\n———. 1983. “New Work for a Theory of Universals.” Australasian Journal of Philosophy 61 (4): 343–77. https://doi.org/10.1080/00048408312341131.\n\n\n———. 1986a. On the Plurality of Worlds. Oxford: Blackwell Publishers.\n\n\n———. 1986b. Philosophical Papers. Vol. II. Oxford: Oxford University Press.\n\n\n———. 1993. “Evil for Freedom’s Sake?” Philosophical Papers 22 (3): 149–72. https://doi.org/10.1080/05568649309506401.\n\n\n———. 1994a. “Humean Supervenience Debugged.” Mind 103 (412): 473–90. https://doi.org/10.1093/mind/103.412.473.\n\n\n———. 1994b. “Reduction of Mind.” In A Companion to the Philosophy of Mind, edited by Samuel Guttenplan, 412–31. Oxford: Blackwell. https://doi.org/10.1017/CBO9780511625343.019.\n\n\n———. 2002. “Tharp’s Third Theorem.” Analysis 62 (2): 95–97. https://doi.org/10.1093/analys/62.2.95.\n\n\n———. 2004a. “Causation as Influence.” In Causation and Counterfactuals, edited by John Collins, Ned Hall, and L. A. Paul, 75–106. Cambridge: MIT Press.\n\n\n———. 2004b. “How Many Lives Has Schrödinger’s Cat?” Australasian Journal of Philosophy 82 (1): 3–22. https://doi.org/10.1080/713659799.\n\n\n———. 2004c. “Void and Object.” In Causation and Counterfactuals, edited by John Collins, Ned Hall, and L. A. Paul, 277–90. Cambridge: MIT Press.\n\n\nMaudlin, Tim. 1994. Quantum Non-Locality and Relativity: Metaphysical Intimations of Modern Physics. Oxford: Blackwell.\n\n\nMenzies, Peter. 1996. “Probabilistic Causation and the Pre-Emption Problem.” Mind 105 (417): 85–117. https://doi.org/10.1093/mind/105.417.85.\n\n\nNolan, Daniel. 1996. “Recombination Unbound.” Philosophical Studies 84 (2-3): 239–62. https://doi.org/10.1007/BF00354489.\n\n\nPryor, James. 2000. “The Sceptic and the Dogmatist.” Noûs 34 (4): 517–49. https://doi.org/10.1111/0029-4624.00277.\n\n\nRobinson, Denis. 1989. “Matter, Motion and Humean Supervenience.” Australasian Journal of Philosophy 67 (4): 394–409. https://doi.org/10.1080/00048408912343921.\n\n\nSchwarz, Wolfgang. 2009. David Lewis: Metaphysik Und Analyse. Paderborn: Mentis-Verlag.\n\n\nSider, Theodore. 1993. “Naturalness, Intrinsicality and Duplication.” PhD thesis, University of Massachusetts - Amherst.\n\n\n———. 2001. “Criteria of Personal Identity and the Limits of Conceptual Analysis.” Philosophical Perspectives 15: 189–209. https://doi.org/10.1111/0029-4624.35.s15.10.\n\n\nStrawson, Galen. 2000. “David Hume: Objects and Power.” In The New Hume Debate, edited by Rupert Read and Kenneth A. Richman, 31–51. London: Routledge.\n\n\nWeatherson, Brian. 2003. “What Good Are Counterexamples?” Philosophical Studies 115 (1): 1–31. https://doi.org/10.1023/A:1024961917413.\n\n\n———. 2005. “Scepticism, Rationalism and Externalism.” Oxford Studies in Epistemology 1: 311–31.\n\n\n———. 2006. “The Asymmetric Magnets Problem.” Philosophical Perspectives 20: 479–92. https://doi.org/10.1111/j.1520-8583.2006.00116.x.\n\n\n———. 2007. “The Bayesian and the Dogmatist.” Proceedings of the Aristotelian Society 107: 169–85. https://doi.org/10.1111/j.1467-9264.2007.00217.x.\n\n\n———. 2009. “David Lewis.” In Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta. Metaphysics Research Lab, Stanford University.\n\nCitationBibTeX citation:@incollection{weatherson2015,\n  author = {Weatherson, Brian},\n  editor = {Loewer, Barry and Schaffer, Jonathan},\n  publisher = {Blackwell},\n  title = {Humean {Supervenience}},\n  booktitle = {A Companion to David Lewis},\n  pages = {99-105},\n  date = {2015},\n  doi = {10.1002/9781118398593.ch8},\n  langid = {en}\n}"
  },
  {
    "objectID": "posts/ryle-regress/index.html",
    "href": "posts/ryle-regress/index.html",
    "title": "Intellectual Skill and the Rylean Regress",
    "section": "",
    "text": "In recent work about know how, Rylean regress arguments have largely dropped out of focus. They play little role in the anti-intellectualist arguments of various kinds in the papers collected in Bengson and Moffett (2011). They are used as something like target practice by intellectualists like Jason Stanley (2011), who uses the first chapter of his book to dispose of them before getting onto the real business. And even Yuri Cath, who in other work has launched sharp critiques of intellectualism, has argued that the regress arguments for anti-intellectualism don’t work (Cath 2011, 2013). The majority view seems to be that Carl Ginet (1975) basically showed these arguments didn’t work, and it’s time to move onto other considerations for or against intellectualism.\n\nImage from Wikipedia. It is Rex Whistler’s portrait of Ryle.\n\nI think this isn’t exactly right. In particular, I think regress arguments can be used to show a few different things. For one, they can be used to refute a precisification of this thesis, which plays a key role in some intellectualist arguments.\n\nOnly volitional actions are normatively assessable.\n\nOnce we have seen that thesis is false, we need a new picture of how action can be at once intelligent and non-volitional. Some considerations similar to those adduced by Ryle (1949) concerning agents who either concentrate on irrelevant considerations, or ignore relevant ones, show there is a role for intellectual skill that cannot be identified with any piece of knowledge that. And some further considerations, similar to those adduced by Cath (2011), suggest that this intellectual skill can’t even be constituted by a piece of knowledge that. So regress arguments, I’ll argue, can do quite a lot to motivate the thought that there was a lot wrong with the intellectual picture Ryle tried to attack.\nThe position I’m going to be defending is a long way from the strongest kinds of Rylean position that contemporary intellectualists such as Stanley are focussed on arguing against. My focus is primarily on intellectual skill. This has some relevance for debates about know how, though less relevance for debates about the semantics of know how ascriptions. This focus on skill rather than know how ascriptions is hardly novel; it is continuing a trend that we see exemplified in recent work by, inter alia, Carlotta Pavese (2013), Ellen Fridland (2014) and Cheng-Hung Tsai (2014). And in fact that conclusions I’ll draw here are, I think, similar to the ones that Fridland draws.\nOnce we move towards thinking about skill, we can get varieties of anti-intellectualism that are very different from those that were the focus of most philosophical discussion until very recently. For example, the anti-intellectualist view I’m defending is consistent with the following four theses.\n\nInstances of intellectual skill are usually, and perhaps always, not happily reported using know how ascriptions.\nKnow how ascriptions are rarely, if ever, reports of intellectual skill, and are frequently reports of propositional knowledge.\nIntellectual skill is guided by, and dependent on, propositional knowledge.\nPropositional knowledge is not behaviourally inert.\n\nNot just is the view consistent with these four, I’m fairly confident that the last three at least are true. But that’s all consistent with the view that intellectual skill is not itself propositional knowledge. And it’s all consistent with the view that we can learn philosophically significant conclusions from Ryle’s regress arguments.\nOne disclaimer before I start. Although this paper is heavily influenced by (Ryle 1945, 1949), and sympathetic interpreters of Ryle such as Jennifer Hornsby (2011), I make no attempt at Ryle exegesis here. I think there’s a decent case to be made that Ryle was sympathetic to the position defended here, but I’m going to leave that debate for another day.\n\n1 The Volitional Regress\nDefine a volitional action to be one that is preceeded by a volition to perform that very action. And say an action is normatively assessable if it can properly be assessed using terms like praiseworthy, blameworthy, intelligent or stupid. Note that I’m ruling out assessments as good or bad as versions of normative assessment, in the relevant sense. Someone who has a good digestive system is not, thereby, normatively assessable in the stipulative sense I’m using. Both of these definitions are to an extent stipulative; the terms ‘volitional’ and ‘normative’ can sensibly receive many other definitions. Still, I will stick to these definitions here. In light of those stipulations, consider the following set of propositions.\n\nOnly volitional actions are normatively assessable.\nThe action of forming a volition is normatively assessable.\nSome public actions, such as making a move in a chess game, are normatively assessable.\n\nIt should be obvious that this leads to a regress. Whether the kind of regress in question is impossible, or even impractical, is a tricky question. (See Robert K. Meyer (1987) for some of the complications that arise when trying to reason about regresses.) But it is commonly assumed in this literature that the kind of regress that these three premises lead to is problematic.\nSince the third premise is obviously true, the issue is whether the first or second is false. But it seems that second is true as well. Just as we can assess a person’s actions as praise or blameworthy, intelligent or stupid, we can assess the process by which she decided to perform those actions in the same way. Consider two people who make the same, as it turns out great, chess move in the same situation. The first notices an initially appealing counter to her move, and sees after careful thought that it won’t work. The second simply doesn’t notice the counter, and is stumped when her opponent makes it. It seems the first has engaged in a more intelligent practice of volition formation than the second. Or imagine a third player, whose initial analysis of the move starts by considering a recipe for arroz con leche. Unless there turns out to be an unnoticed connection here, this looks even less intelligent than the second player.\nOn the other hand, the first premise is rather unintuitive. To borrow an example from Angela Smith (2005), it is blameworthy to forget a friend’s birthday, although forgettings are rarely volitional. So we must reject 1 or 2, and while 1 is subject to independent counterexample, 2 seems independently plausible. So 1 must be false.1\n1 This argument is obviously rather quick, and I doubt will persuade someone already convinced of 1. For much more extensive arguments against 1, see the Smith, Ryan and Steup articles cited in the text, plus Adams (1985).That’s already a substantial conclusion. Something like 1 is behind William Alston’s famous, and influential, arguments against deontological approaches to epistemology (Alston 1988). But the negation of 1 is not a novel claim; I’m saying nothing here that Smith didn’t say in her rejection of the “volitional view of responsibility” (Smith 2005, 238). And similar views have been put forward by other critics of Alston such as Sharon Ryan (2003) and Matthias Steup (2008).\nBut still, the fact that 1 is false seems not to have been sufficiently appreciated in the recent literature on intellectualism. To see one place where it is relevant, consider this set of propositions, which also seem to trigger a regress.\n\nIntelligent action requires the triggering of a prior representation of knowledge relevant to the action.\nThe triggering of a representation, when done well, is an intelligent action.\nSome public actions, such as making a move in a chess game, are intelligent.\n\nAgain, these propositions obviously trigger a regress, and that seems like good evidence to take one of them to be false. This is very similar to one of the regresses Jason Stanley considers in chapter 2 of his (2011). And Stanley thinks the false proposition is 5. He writes “Triggering a representation can be done poorly or well. But this does not show it can be done intelligently or stupidly.” (Stanley 2011, 16) Indeed, he writes that since “triggering representations is something we do automatically” (Stanley 2011, 16) a statement like 5 is a “manifest implausibility” (Stanley 2011, 16). But the argument here relies on 1. If you think things done non-volitionally can be intelligent or stupid, it isn’t too much of a stretch to think that things done automatically can be intelligent or stupid. Indeed, Smith’s birthday example is already enough to undermine Stanley’s point; forgetting a friend’s birthday seems automatic in the sense he has in mind, but is also stupid.\nMore generally, it seems very intuitive to describe everyday cases in such a way that 5 must be true. For example, Billy asks Suzy whether she thinks Jill’s party will be a success. There are a lot of things that are common knowledge between the two of them. One is that Jill is a proficient party host. Another is that Jill has invited all of their colleagues, including Jack. Another is that parties which Jack attends are rarely successes. But Suzy thinks for a minute, remembers that Jack is away in Ohio, and says that it will be a success.\nIt was smart of Suzy to think about Jack’s whereabouts. It wasn’t, perhaps, necessary. If she’d just reasoned from Jill’s general proficiency to the success of the party, she would have got to the right conclusion. But it was better to note a possible complication, and check that it wouldn’t actually get in the way.\nIt would have been stupid to perform the same activity for many other kinds of possible complications. If Suzy had thought to herself, “The party will be a disaster if there’s an alien invasion in the middle of it, but there’s no reason to think the aliens will invade just now, so I’ll keep on thinking it will be a success,” that would have been stupid. Other possible complications are not stupid to consider, but they are intellectual mistakes. The party won’t be a success if there’s a police raid in the middle, based on a mistaken view the police have about where a particular drug dealer lives. Police do make mistakes, so even if Jill isn’t a drug dealer, this could be a genuine concern, depending on how nearby the mistakes are. But if the nearest mistake was a botched raid in a neighbouring state in the previous year, it’s wrong for Suzy to worry about this before answering Billy’s question.\nStanley’s view has to be that I’ve been misusing adjectives systematically through the last two paragraphs. I shouldn’t have said that it was smart of Suzy to consider Jack’s whereabouts, or that it would have been stupid to consider the alien invasion. Rather, it was just her cognitive system working well when she considered Jack, and would have been working poorly had she considered the aliens, and sub-optimally had she considered the police. This doesn’t seem at all the natural way to describe the case to me, in part because I’m not sure I see the difference Stanley is hinting at. Intelligence just is the good operation of the cognitive system, and stupidity its poor operation.\nSo these two regresses lead to two interesting conclusions. First, some non-volitional actions are normatively assessable. Second, intelligent action does not always require the prior triggering of a representation of relevant knowledge. Both of these are interesting. Both of these are negations of part of what you might consider “the intellectualist picture”. (Cath (2013) notes that Ryle often refers to the regresses as arguments against this picture, not against any particular thesis.) But neither of them get us very close to a distinction between know how and know that, or between intellectual skill and know that. The next section addresses some ways we might move closer to arguments against more central intellectualist claims.\n\n\n2 Picturing Intelligent Action\nAs noted in the introduction, my plan is not to offer an argument with regress like premises, and the conclusion that intellectual skill is distinct from propositional knowledge, or that know how is distinct from propositional knowledge. What I do want to do is sketch a picture of human intelligence (at a very high level of generality) that presupposes that intellectual skill is not identical to propositional knowledge, and suggest some considerations to the effect that no similarly plausible picture exists in which intellectual skill and propositional knowledge are identified. The thought here is not that the only way out of the regress involves distinguishing skill and knowledge – and perhaps distinguishing know how from know that – but rather that the best way out does.\nStart with a well known, if not obviously authentic, exchange.2\n2 I thought this example was purely fictional, coming from the Monty Python sketch reproduced in Dempsey (2012, 741). But Ben Wolfson pointed out to me that it’s recorded as a true story in Hadley (1903, 255).\nIt’s actually striking how few really good off-the-cuff quips there are in recorded history. The famous one attributed to Wilde, “I have nothing to declare but my genius”, is probably apocryphal, and in any case sounds prepared. Lists of famous come-backs and ripostes are usually crowded with written responses. Word play is hard.\nOscar Wilde: I wish I’d said that.\nJames McNeill Whistler: You will Oscar; you will.\n\nAssuming this really happened, that’s a clever response. It’s an occupational hazard of philosophers to think that the ability to come up with quick, clever responses is somehow central to intelligence. But we can reject that wildly implausible view without thinking that it’s wrong to think of these quips as a manifestation of a kind of intelligence.\nNow let’s think of how someone could have come up with this response. Even before we start researching the neural patterns behind quips like this, we can be pretty sure the following is not what happened in Whistler’s brain. He first made an exhaustive list of all possible responses, from “Green ideas sleep furiously” to what he actually said, then figured out which would be best, then produced the best one. On this wildly implausible model, the reply would be intelligent because it would reflect the speaker’s ability to properly evaluate this list of responses. That’s implausible because the list is simply too big. Indeed, it is in principle infinitely large. The list is too big to survey not just consciously, but subconsciously.\nComing up with a response like this requires first coming up with a narrower list of possible responses, and then evaluating which is best from that list.3 There’s a romantic model of intellect where the list in question consists of just the reply actually issued. On this model the perfect reply appears fully and perfectly formed in the mind of the intelligent person. Now such a model may often fit the phenomenology, but I don’t think we should give that much credit. It’s an empirical question how many possible replies are represented in the mind in a situation like this, before the chosen reply is issued. What’s not an empirical issue is whether the list of possible replies that is represented in the mind is finite or infinite. It simply must be finite, which means that there must be better and worse lists to consider. And that suggests that there is some skill involved in coming up with the list.\n3 Or, perhaps even more plausibly, coming up with a short list of possible openings, choosing the best, and doing what one can to figure out how to complete the response while uttering the start of it. Thanks here to Ben Wolfson.One could reject this last conclusion. One could try saying that the coming up with a list of possible replies is no manifestation of skill, but the skill is only involved in the evaluation and selection of replies. But this seems to generate a bizarre explanation about why the less skilled interlocutor comes up with worse replies. The model, presumably, is that the lack of skill does not explain having the wrong list of replies to choose between. Rather, what explains their less skilled reply must simply be that they misevaluated the possible replies. But that doesn’t fit the observed data. It’s much easier to see of someone else’s reply that it was clever than it is to come up with a clever reply.\nIt could also be objected that the model I’ve suggested is much too simple. It isn’t just that the mind issues a list of options, then evaluates them, and then selects the best. A more plausible model involves more recursive steps. The mind first generates a list of options, selects the best, then generates a list of refinements of that best option, selects the best of those, and so on. Perhaps when we consider superficial forms of intelligence, such as quips, it makes sense to consider a ‘one-step’ model, where a list is generated and evaluated, followed by a speech. But when one is choosing one’s words carefully, as in say Wilde’s writing, the simple model I’ve described feels much too simple.\nBut although the simple model is too simple for considered writing, the general structure must be right. Even a writer working at a leisurely pace, such as Joyce taking decades to write Finnegans Wake, doesn’t have time to consider, even subconsciously, all possible constructions. There are still too many. And nor is it true that the difference between Joyce’s skill and ours is that he realises the value of the sentences we all represent. The rest of us didn’t simply misjudge the value of “Nobirdy aviar soar anywing to eagle it” (Joyce 1939/2012, 505); we simply didn’t token it. The ability to token mental representations like that is part of what Joyce’s genius consists in.\nI’ve focussed so far on cases where it is a priori implausible that human thinkers start by surveying the range of possible things they could do. It is also interesting to look at cases where this is in principle possible, but doesn’t seem to happen in practice. There have been, traditionally, major differences in the style of play between human and computer chess players. (Since so many young players learn from machines these days, Kasparov (2010) suggests these differences are diminishing.4) This isn’t necessarily because humans can’t consider all options on the chess board. Usually there will be fewer than a hundred available moves, and a human could consider each. But that isn’t, it seems, how humans think. They don’t allocate equal resources to working through each of the possible options. As a result, computers often come up with surprising kinds of moves. Now computers are actually very good at chess, so these pre-deliberative allocations of cognitive resources may not have been optimal. Perhaps it would have been better for traditional chess players to spend more time thinking through unlikely progressions of the game. But it is evidence that even when we could use an unintelligent method for beginning inquiry, namely recursively generating the possible options, we prefer to use intelligent methods.\n4 Thanks to Bernard Kobes and John Collins for helpful discussions about the chess examples.So intelligent action, at least in humans in the kinds of situations humans normally find themselves in, consists in part of making intelligent choices about where to start inquiry. Given that intelligent action need not be volitional, as we established above, it isn’t surprising that being intelligent consists in part in starting in the right places. But perhaps this intelligence is just itself a kind of knowledge. It is, we might suspect, just the knowledge of what a good starting point will be. Or, since we will want to start with all and only the considerations relevant to a given inquiry, it is just knowledge of what is relevant.\nThe resulting picture is both perfectly intellectualist, and immune to the regresses considered above. The intelligent person knows what is relevant to what inquiry. Her choice of starting points is guided by this knowledge. (The ‘guidance’ metaphor recurs frequently in Stanley’s work.) This isn’t because it leads to a volition to start just here. Such a volition would be self-defeating, since in the relevant sense of ‘start’, by the time this volition is formed, one has already started, and indeed started elsewhere. Nor can she be guided by even a triggered representation of this knowledge of relevance. Again, if that happens, she is in the relevant sense starting elsewhere. But perhaps propositional knowledge can guide directly; not by generating volitions, and without even being represented anew.\nNow I don’t think this picture is right. But it isn’t incoherent either, and it takes work to see why it isn’t right.\nOne bad argument against this picture starts with the idea that skills are active, while knowledge is passive. The thought is that the person who knows a lot is like the Tortoise in Louis Carroll’s dialogue (Carroll 1895), only able to add more premises but never to reach a conclusion. It is only with skill that we can get to the conclusion. Stanley rightly objects to this argument on the grounds that it just isn’t true that knowledge is passive in the relevant sense. We should not, as Stanley puts it, “over-intellectualize knowing that”. (Stanley 2012, 773). (A similar point is made in Stalnaker (2012).) Knowing that p is not just a matter of having p written in a knowledge box somewhere in the brain; it can in part be constituted by active dispositions.\nA better argument looks at the very different modal profiles of intellectual skill and knowledge of relevance. Someone can know that something is irrelevant and yet lack the skill to ignore it; or they can know that something is relevant and yet lack the skill to consider it in a timely manner. Examples from the other direction, where there is skill without knowledge, are a little more contentious, but we’ll look at some possible cases of those too. But first we’ll run through two examples to show how easy it is to have knowledge without skill.\nAlice has spent a lot of money on video-conferencing equipment. But it isn’t working at all well, and she now has to decide whether to try and patch it into something better, or buy a whole new system. She knows the sunk cost fallacy is a fallacy; that buying a new system would make the previous purchases a waste is no reason to not buy a new system, especially if doing so is good value compared to the cost of buying a ‘patch’. But she can’t bring herself to ignore this fact when deliberating. Even though she eventually makes the right decision and buys new equipment, she takes much longer about this than she would have if, say, the existing equipment was old enough that she could easily conceptualise it as obsolete.\nBob is trying to solve a puzzle about the properties of functions from rationals to rationals. He knows that it is often helpful, when solving such puzzles, to transform the puzzle into one about functions from ordered pairs of integers to ordered pairs of integers. He knows that in the sense that if you asked him whether it could be useful to consider that transformation of the puzzle, he would immediately say yes, and this answer would come with the phenemenology of recollection, not of new insight. But no one does ask him that question, and the transformation in question simply never occurs to Bob. Since the untransformed puzzle is very hard, while the transformed puzzle is manageable, Bob never solves the problem.\nIt seems to me that what’s happened in both cases is that the agent has some knowledge, but is incapable of using it. What they lack is a skill. In particular, they lack what Fridland (2014, 2746) calls ‘selective, top-down, automatic attention’. Alice keeps attending to something she should not, even though she knows she should not. Bob fails to attend to something he should, although in some sense he knows that is what he should attend to. Bob’s case is one of the reasons I find the picture of skill presented by Stanley and Williamson (2017) unhelpful. They say skill is a disposition to form knowledge. But Bob has the important knowledge. The disposition he lacks is the disposition to activate that knowledge, and let it guide deliberation. That’s what constitutes his lack of skill.\nIt’s true that knowledge isn’t completely passive. If Alice never appealed to the fact that the sunk cost fallacy is a fallacy in her reasoning, we wouldn’t say that she knows it. If none of Bob’s answers were guided by the existence of natural and useful transformations between rational numbers and ordered pairs of integers, we wouldn’t say he knows such transformations are natural and useful. I’m here agreeing with Stanley and Stalnaker that knowledge is itself a kind of disposition. And intellectual skill is a kind of disposition too. But they are very different dispositions. In particular, they have very different triggering conditions. Bob lacks some skill because he does not call to mind this fact about rational numbers right now. He has the salient knowledge about rational numbers because he is disposed to use the facts in question often enough.\nSo intellectual skill and knowledge of relevance have different manifestation conditions, and so they are not identical. But we can say something stronger than that. The cases of Alice and Bob are not in any way unusual. Examples where we forget the salience of some consideration, or can’t get an irrelevant point out of our heads, are frequent. In principle, one could respond to the arguments I’ve made so far by saying that while knowledge of relevance is not identical to skill, nevertheless the two are as closely linked as, say, a material object and the matter that constitutes it. And if I had to resort to bizarre cases of the kind we torture introductory students with to make my point, I’d say that would be the right response. But given how normal Alice and Bob’s cases are, this seems like the wrong move. Skill and knowledge don’t just come apart in theory, they come apart in practice, frequently.\n\n\n3 Four Objections\nSo far I’ve defended three theses that are in tension with some forms of intellectualism. They are:\n\nSome non-volitional actions are normatively assessable.\nNot all intelligent action is preceded by the triggering of representations of relevant knowledge.\nIntellectual skill, in particular the intellectual skill associated with starting inquiry in the right place, is not identical to any piece of propositional knowledge.\n\nWhile this doesn’t show that, for instance, know how and know that are distinct, and is completely silent on what we should say about know how ascriptions, it does undermine some intellectualist programs. I’ll conclude with some objections either to the arguments I’ve put forward, or to their significance.\nObjection: Even if all of this is true, there may still be a sense in which intellectualism is true. After all, it could still be that knowledge guides action in a suitable way. (Compare (Stanley 2011, 2).)\nReply: This could be true. Whether it is a win for intellectualism depends a bit on the boring question of how we settle the term ‘intellectualism’, and a bit on more interesting questions about priority. Let’s start by distinguishing five theories we might call intellectualist.\n\nIdentity Intellectualism\n\nThe possession of an intellectual skill just is the possession of a piece of knowledge.\n\nConstitution Intellectualism\n\nThe possession of an intellectual skill is, always, constituted by a piece of knowledge.\n\nWeak Constitution Intellectualism\n\nThe possession of an intellectual skill is, often, constituted by a piece of knowledge.\n\nCausal Intellectualism\n\nThe possession of an intellectual skill is, always, caused by the possession of a piece of knowledge.\n\nWeak Causal Intellectualism\n\nThe possession of an intellectual skill is, often, caused by the possession of a piece of knowledge.\n\n\nThis paper has been arguing against Identity Intellectualism. I think the falsity of this is as much as we could reasonably hope to prove using regress arguments. (I think I’m here agreeing with Wiggins (2009) and Hornsby (2011).) And the considerations behind the regress argument do, I think, show it to be false. If someone wants to insist that by intellectualism, they mean something weaker than this, I’m not going to quarrel over terminology. I’ll just note that Identity Intellectualism is an interesting, and false, thesis.\nThe arguments here are clearly not arguments against either form of Weak Intellectualism. Indeed, they are naturally understood as the kind of cases that confirm Weak Intellectualism. Mathematics students, like Bob, train by learning a lot of mathematical facts. And it’s hard to see how they could develop the relevant skills without knowing some important facts. This is, I suspect, the general case. Skillfully bringing the right considerations to bear on a problem requires, and is probably the causal consequence of, knowing a lot of relevant facts. (Tsai (2014) makes clear how one can simultaneously hold that skills are in part constituted by knowledge of facts without having an intellectualist picture of skill.)\nBut what of the other two intellectualist theories? Do we have reason to think that there are some skills that are not constituted by, or not caused by, the possession of factual knowledge? One way to quickly show that would be to show that there can be skills without the related knowledge. Perhaps that’s not just sufficient for rejecting Constitutive/Causal Intellectualism, but necessary. If knowledge without skills is possible, as in Alice and Bob’s cases, and skills without knowledge were impossible, that asymmetry would call out for explanation. And something in the vicinity of Constitutive or Causal Intellectualism would be a very good candidate explanation.\nThere are (at least) two promising routes to showing that there can be skills without knowledge. One is due to Imogen Dickie (2012). She argues that since there are so many different routes to skill than there are to knowledge, we should expect that there will be cases of skill that are causally prior to knowledge. Jason Stanley (2012) replies that Dickie’s argument assumes an overly narrow conception of propositional knowledge. This is a fascinating debate, but I don’t have anything useful to add to it, so I’ll just note the existence of this route, and move on.\nThe other route is due to Yuri Cath (2011). He suggests that facts in virtue of which a person might lose propositional knowledge do not always bring about a loss of knowledge that. I’m going to sketch a Cath-style argument that we can have intellectual skills without knowledge. I think the argument has some force, though there are more ways to resist it than there are to resist the argument against Identity Intellectualism.\nRoss and Rachel are economics students taking an exam. They are given a hard question asking about the likely effects of an exogenous shock, say an earthquake affecting an area the supplies crucial raw materials, on some related markets. The question is hard, with the relevant causal pathways being interconnected and often opposing. The only plausible way forward is to use a model and search for equilibrium points in the model. That’s what Ross and Rachel have both been taught to do. And in fact both of them quickly select the right kind of model, with just the right amount of complexity in it to answer the question without being overburdened, and set out on the difficult algebra involved in solving the question.\nSo far it looks like both Ross and Rachel have shown intellectual skill. Now it turns out Ross and Rachel have very different views about the role of models in economic thinking. (My own thinking about models has been heavily influenced by Strevens (2008 ch. 8) and Davey (2011), and I rely on their insights in what follows.) These models involve, as all models do, some serious idealisation. Most notably, they assume that all the relevant actors are perfectly rational utility maximisers. Rachel hasn’t given much thought to this assumption, though she knows it to be literally false. But if pressed, she would say some reasonably sensible things about why she was using the model. For one thing, the familiar failures of human rationality aren’t obviously relevant to the puzzle being presented. For another, they’ve been taught that using these models is a good way to solve problems, and that testimonial evidence carries some weight. And for another, it’s an exam, and it is likely that questions have been selected to test how well students can use the models they have been taught. If those are her background, implicit, views, I think it is plausible to say that Rachel knows that the model is relevant to the exam question, even if she couldn’t produce a theory of idealisations in economics of the standards of the best philosophers.\nRoss’s views about models are rather different. He thinks the familiar models in economics work, when they do, because the background assumptions are strictly and literally true. He thinks economic agents are utility maximisers, and the apparent evidence to the contrary is due to sloppy experimental design. He thinks markets are always in general equilibrium. And so he thinks that the only sources of error in predictions we can make about markets are from errors about things like the costs of extracting raw materials after the earthquake. This perspective is, of course, grossly mistaken. Moreover, Ross thinks that if the assumptions were not correct, there would be no point in using the models. This too is a mistake, though perhaps not as dramatic as his other mistakes.\nNow even if Ross and Rachel aren’t thinking about these philosophical views about the nature of models, I think they are relevant to whether each of them know that the models are relevant to the puzzle. In particular, I think Rachel does know that the models are relevant, while Ross’s belief that they are relevant is more like a lucky guess than a piece of knowledge. Still, I think we should say that Ross showed skill in using this model rather than a more or less complex model, or a different kind of model, or no model at all. So he is a case of intellectual skill without knowledge of relevance.\nI don’t think this case is conclusive. I can think of at least four ways someone might reasonably object to the case.\n\nIt might be argued that despite his false views about why the models are relevant, he really does know that they are relevant. In other words, we would have another counterexample, to be added to those discussed by Warfield (2005) and Luzzi (2010), to the theory that false beliefs cannot generate knowledge.\nIt might be argued that Ross is not really skilled, since it is a matter of luck that the falsity of his beliefs does not lead him to false conclusions here.\nIt might be argued that although Ross doesn’t know that this model is relevant, his skill is constituted by, or caused by, some other knowledge he has.\nIt might be argued that the broad picture of the role of idealisations in scientific reasoning that I’m adopting from Strevens and Davey is mistaken, and this fatally undermines my use of the case to argue against intellectualism.\n\nI don’t think these arguments are going to ultimately work. But it’s clear we are a long way from Rylean regress arguments here. And that’s where I think the debate about regress arguments should end. We have a good argument against Identity Intellectualism. And we have some suggestive considerations that seem to tell against Constitutive and Causal Intellectualism, but whether these arguments ultimately work will depend on considerations independent of the regress.\nObjection: Stanley and Williamson (2017) have recently defended the idea that skill is a disposition to form knowledge. And they back this up with empirical analysis of intelligent motor skills, especially drawing on the survey by Yarrow, Brown, and Krakauer (2009). Is this kind of intellectualism subject to the regress worries?\nReply: Once we are taking the dispositions themselves to be the skills, not the underlying knowledge, it feels that we are a long way from traditional intellectualism. But the view is independently interesting, and it is a useful segue to thinking about the relationship between intellectual skills, as conceived of in this paper, and motor skills.\nI’ve already mentioned that the Bob example does not seem to fit well with Stanley and Williamson’s paradigm. And there is something suspicious about a theory of physical skill that divorces it so strongly from the physical. To be a skilled batsman requires more than dispositions to get knowledge, one might suspect. Stanley and Williamson have a reply to this suspicion. They write,\n\nConsider the difference between someone who can bench-press a maximum of 100 pounds and someone who can bench press 150 pounds. We may suppose that both employ the same technique; only brute strength makes the difference between them. Both are equally skilled ...Any view of skill must account for such cases. In particular, it must explain why strength, speed, and stamina are not themselves skills.(Stanley and Williamson 2017, 9, page references to preprint)\n\nBut even if strength is not a skill, it might be a prerequisite for a skill. A batsman whose degenerative back condition means he lacks the flexibility to deploy his trademark pull shot has lost a skill, even if he hasn’t lost any dispositions to form knowledge. There is a puzzle as to why qualitative physical differences matter so much to skill attributions why quantitative ones do not. If you can’t turn to pull the ball, you’ve lost a skill, but if a muscle strength decline reduces the power of your pull shot, your skills haven’t declined. But that difference doesn’t justify making skills entirely cognitive.\nStill, there is a cognitive angle. One central point of this paper is completely consistent with Stanley and Williamson’s picture; motor skills often require forming the right knowledge. The skilled batsman doesn’t just pick up many characteristics of the bowler’s delivery, they pick up the ones that are most relevant to the trajectory of the ball. As the Bob example shows, they also have to activate that knowledge for it really to be a skill, but that’s not a new objection.\nThere is one other cognitive aspect of motor skill that Yarrow, Brown, and Krakauer (2009) draw attention to, and which fits very nicely with the theme of this paper. It’s a specific instance of a much more wide-ranging skill. Sometimes an agent knows that in some time some evidence, drawn from a large space, will come in. She will shortly thereafter have to act in response to the evidence. She has some time to plan now. What should she do? In many such cases, backwards induction is impossible; there are too many possible pieces of evidence that could come in, and planning for each of them is a waste of resources. On the other hand, not planning at all is also a waste of the time she now has, and will lack once the evidence comes in. The solution is to do some planning. And there is a real skill involved in getting the resource allocation right, and neither wasting effort planning for unlikely scenarios, nor wasting the ability to be prepared before one needs to act.\nYarrow, Brown, and Krakauer (2009, 590–91) suggest the same thing happens at a very low level. Highly skilled athletes are making many places in advance of knowing exactly how they will act. Part of the skill involved is allocating the right resources to each of these planning activities. Many of them will ultimately be wasteful, since they are plans for eventualities that do not arise. And one failure condition is that a single plan is not selected, and the agent performs some combination of multiple plans that are worse than either one plan. That failure state is part of the evidence that there is this low-level planning going on before actions. But it is a real skill, and part of the skill is focussing on just the right things.\nSo motor skills often have as a constituent part intellectual skills. Some of those skills are closely tied to knowledge; for instance, having priors that track frequencies. Sometimes the skill involved is in focussing on the evidence that the posterior probability is maximally sensitive to, and reacting to that evidence. Sometimes the skill is not attending to evidence that is just going to be unhelpful noise in the activity in question (Yarrow, Brown, and Krakauer 2009, 589). And sometimes it is in allocating just the right resources to forward planning. All of these seem like intellectual skills, and parts of motor skills. We could try to squeeze all of them into a framework of being dispositions to form knowledge, but it seems more perspicuous to just present the plurality of ways in which the intellect and the body interact, rather than trying to find a single framework.\nObjection: Appeal to skill does not stop the regress. If we need to posit something, say a skill, that comes between the possession of knowledge and the use of knowledge in reasoning or action, then we also to posit something that comes between the possession of a skill, and the use of that skill in reasoning or action. (Compare Stanley (2011, 26)).\nReply: What I’m going to say here is similar to what Jeremy Fantl (2011) said in a response to an earlier version of Stanley’s argument, so I’ll be brief. Skills are dispositions. We don’t need to posit anything that comes between the disposition and its triggering. If a string is disposed to produce a middle C when struck, and it is struck, we don’t need to posit an extra intermediary between the striking and the note. Dispositions stop regresses.\nBut, you might insist, couldn’t the same be true of knowledge? After all, on a broadly functionalist construal of the mental, knowledge is a kind of disposition. My reply is in theory knowledge could stop such a regress, but in practice it is unlikely. An agent could be facing a problem where the possible considerations and options can be enumerated without using any particular skill, and the options are few enough that they can be each considered in turn. That is the situation an agent playing a relatively simple game might face. But it isn’t the general human condition. In practice, we face problems every moment where it requires skill to bring the right considerations to bear, at least given the processing capacities we have available.\nObjection: There are semantic arguments that attributions of know how are attributions of propositional knowledge. This shows that Ryle was wrong to draw a broad distinction between know how and know that.\nReply: I’m not making any claims about either know how or about ‘know how’. I am making some claims about skill, and those imply some claims about ‘skill’. But I’m sympathetic to the idea that reports of know how are often reports of some kind of practical propositional knowledge. I certainly haven’t offered any arguments, nor I think any considerations in the direction of an argument, against this view.\nIndeed, there are a lot of intellectualst positions that I’m not arguing against here. Anti-intellectualism is often tied up with the view that there is an important distinction between theoretical and practical fields. The arguments I’ve developed here suggest that if there is such a distinction, then proving mathematical theorems is on the ‘practical’ side. I think that’s a strange enough conclusion that it is time to change our terminology. That’s why I’ve talked about the distinction between intellectual skills and knowledge, not the distinction (if such there is) between know how and know that, or between praxis and theory.\n\n\n\n\n\n\nReferences\n\nAdams, Robert Merrihew. 1985. “Involuntary Sins.” Philosophical Review 94 (1): 3–31. https://doi.org/10.2307/2184713.\n\n\nAlston, William. 1988. “The Deontological Conception of Epistemic Justification.” Philosophical Perspectives 2: 257–99. https://doi.org/10.2307/2214077.\n\n\nBengson, John, and Marc Moffett, eds. 2011. Knowing How. Oxford: Oxford University Press.\n\n\nCarroll, Lewis. 1895. “What the Tortoise Said to Achilles.” Mind 4 (14): 278–80. https://doi.org/10.1093/mind/iv.14.278.\n\n\nCath, Yuri. 2011. “Knowing How Without Knowing That.” In Knowing How, edited by John Bengson and Marc Moffett, 113–35. Oxford: Oxford University Press.\n\n\n———. 2013. “Regarding a Regress.” Pacific Philosophical Quarterly 94 (3): 358–88. https://doi.org/10.1111/papq.12004.\n\n\nDavey, Kevin. 2011. “Idealizations and Contextualism in Physics.” Philosophy of Science 78 (1): 16–38. https://doi.org/10.1086/658093.\n\n\nDempsey, Luke, ed. 2012. Monty Python’s Flying Circus: Complete and Annotated...all the Bits. New York: Black Dog & Leventhal Publishers.\n\n\nDickie, Imogen. 2012. “Skill Before Knowledge.” Philosophy and Phenomenological Research 85 (3): 737–45. https://doi.org/10.1111/j.1933-1592.2012.00638.x.\n\n\nFantl, Jeremy. 2011. “Ryle’s Regress Defended.” Philosophical Studies 156 (1): 121–30. https://doi.org/10.1007/s11098-011-9800-8.\n\n\nFridland, Ellen. 2014. “They’ve Lost Control: Reflections on Skill.” Synthese 191 (12): 2729–50. https://doi.org/10.1007/s11229-014-0411-8.\n\n\nGinet, Carl. 1975. Knowledge, Perception and Memory. Dordrecht: Riedel.\n\n\nHadley, Frank A. 1903. “Whistler, the Man, as Told in Anecdote.” Brush & Pencil 12 (5): 334–59. https://doi.org/10.2307/25505918.\n\n\nHornsby, Jennifer. 2011. “Ryle’s Knowing How, and Knowing How to Act.” In Knowing How, edited by John Bengson and Marc Moffett, 80–98. Oxford: Oxford University Press.\n\n\nJoyce, James. 1939/2012. Finnegans Wake. Oxford World’s Classics. Oxford: Oxford University Press.\n\n\nKasparov, Garry. 2010. “The Chess Master and the Computer.” The New York Review of Books. The New York Review of Books. http://www.nybooks.com/articles/archives/2010/feb/11/the-chess-master-and-the-computer/.\n\n\nLuzzi, Federico. 2010. “Counter-Closure.” Australasian Journal of Philosophy 88 (4): 673–83. https://doi.org/10.1080/00048400903341770.\n\n\nMeyer, Robert K. 1987. “God Exists!” Noûs 21 (3): 345–61. https://doi.org/10.2307/2215186.\n\n\nPavese, Carlotta. 2013. “The Unity and Scope of Knowledge.” PhD thesis, Rutgers University, New Brunswick.\n\n\nRyan, Sharon. 2003. “Doxastic Compatibilism and the Ethics of Belief.” Philosophical Studies 114 (1-2): 47–79. https://doi.org/10.1023/A:1024409201289.\n\n\nRyle, Gilbert. 1945. “Knowing How and Knowing That.” Proceedings of the Aristotelian Society 46 (1): 1–16. https://doi.org/10.1093/aristotelian/46.1.1.\n\n\n———. 1949. The Concept of Mind. New York: Barnes; Noble.\n\n\nSmith, Angela M. 2005. “Responsibility for Attitudes: Activity and Passivity in Mental Life.” Ethics 115 (2): 236–71. https://doi.org/10.1086/426957.\n\n\nStalnaker, Robert. 2012. “Intellectualism and the Objects of Knowledge.” Philosophy and Phenomenological Research 85 (3): 754–61. https://doi.org/10.1111/j.1933-1592.2012.00640.x.\n\n\nStanley, Jason. 2011. Know How. Oxford: Oxford University Press.\n\n\n———. 2012. “Replies to Dickie, Schroeder and Stalnaker.” Philosophy and Phenomenological Research 85 (3): 762–78. https://doi.org/10.1111/j.1933-1592.2012.00641.x.\n\n\nStanley, Jason, and Timothy Williamson. 2017. “Skill.” Noûs 51 (4): 713–26. https://doi.org/10.1111/nous.12144.\n\n\nSteup, Matthias. 2008. “Doxastic Freedom.” Synthese 161 (3): 375–92. https://doi.org/10.1007/s11229-006-9090-4.\n\n\nStrevens, Michael. 2008. Depth: An Account of Scientific Explanations. Cambridge, MA: Harvard University Press.\n\n\nTsai, Cheng-hung. 2014. “The Structure of Practical Expertise.” Philosophia 42 (2): 539–54. https://doi.org/10.1007/s11406-013-9513-7.\n\n\nWarfield, Ted A. 2005. “Knowledge from Falsehood.” Philosophical Perspectives 19: 405–16. https://doi.org/10.1111/j.1520-8583.2005.00067.x.\n\n\nWiggins, David. 2009. “Knowing How to and Knowing That.” In Wittgenstein and Analytic Philosophy: Essays for p. M. S. Hacker, edited by Hans-Johann Glock and John Hyman, 263–77. Oxford: Oxford University Press.\n\n\nYarrow, Kielan, Peter Brown, and John W. Krakauer. 2009. “Inside the Brain of an Elite Athlete: The Neural Processes That Support High Achievement in Sports.” Nature Reviews Neuroscience 10 (8): 585–96. https://doi.org/10.1038/nrn2672.\n\nCitationBibTeX citation:@article{weatherson2017,\n  author = {Weatherson, Brian},\n  title = {Intellectual {Skill} and the {Rylean} {Regress}},\n  journal = {Philosophical Quarterly},\n  volume = {67},\n  number = {267},\n  pages = {370-386},\n  date = {2017-04},\n  doi = {10.1093/pq/pqw051},\n  langid = {en}\n}"
  },
  {
    "objectID": "posts/review-moral-uncertainty/index.html",
    "href": "posts/review-moral-uncertainty/index.html",
    "title": "Review of “Moral Uncertainty and Its Consequences”",
    "section": "",
    "text": "For many years now, Peter Singer has been arguing that we should not eat meat, and that we should give more money to famine relief. Many have been convinced, but many more remain sceptical. However, on one point most of us would agree: the actions that Singer recommends here are certainly morally permissible. One rarely feels a twang of moral doubt when eating tofu curry or writing cheques to Oxfam. Even if we do not find Singer totally convincing, we may still feel this moral doubt when eating sirloin, or spending frivolously rather than charitably. If we accept the main principle in Ted Lockhart’s book Moral Uncertainty and Its Consequences, these twangs of moral doubt should be sufficient to make us amend our behaviour.\nThe main principle Lockhart endorses is that we should perform actions that we are maximally confident are morally permissible. We might be quite confident that having the sirloin is morally permissible, but if we are not certain, and we are certain the tofu is permissible, we should stick to tofu. Similarly, if we are certain that large donations to famine relief are permissible, and not certain that not making these donations is permissible, the chequebook should come out. The principle is not just for left-wingers. As Lockhart notes, approvingly, it can also be used in anti-abortion arguments. In most cases, not having an abortion is almost certainly permissible. Perhaps there is an exception for cases of extreme fetal deformity, but not in everyday cases. So if the woman considering an abortion wants to do the action that is most probably morally permissible, and has any doubts about the permissibility of the procedure, she should decline the abortion.\nThe bulk of Lockhart’s book is devoted to case studies where this principle is deployed, and amendments to the principle generated by considerations of these cases are adopted. The cases include abortion, patient confidentiality, Roe v Wade and, briefly, charitable giving. The theme behind the studies is that even if people cannot come to agreement on what is morally right, they can come to agreement on what should be done according to the principle, at least as variously amended, and this should be sufficient to provide recommendations for action. Lockhart stresses that if this line of reasoning is correct, then applied ethicists can provide good advice on practical action without conclusively resolving apparently intractable ethical problems.\nThere are three main amendments Lockhart suggests to the principle. First, he suggests that if moral rightness comes in degrees, we should maximise the expected moral rightness of our actions, rather than the probability that we are doing the right thing. Secondly, in situations where we cannot work out which action maximises expected rightness, because perhaps we do not have perfect access to the relevant subjective probabilities, we should choose the action which most probably maximises expected rightness, or more generally has the highest expected expected degree of moral rightness. And thirdly, he says that we should maximise the expected rightness of courses of action, rather than of individual actions. One might quibble with these amendments, particularly I think with the second, but they do not seem to affect the core philosophical issues.\nThe principle has some rather striking consequences, so striking we might fear for its refutation by a quick modus tollens. Lockhart, of course, does not think this is so. He does not discuss the vegetarianism issue, and endorses the anti-abortion implications, but argues that the principle need not have such striking implications concerning charitable giving. He notes that for some people, those who think it probable enough that substantial charitable giving is a very bad thing to do, because we have such strong obligations to ourselves and those nearest and dearest, his principle does not recommend such giving (109).\nThere is a more direct reason for thinking the principle stands in need of some further clarification and defence. It is rather unclear what kind of norm the principle is stating, and hence what force the should in it is has. Lockhart says it is a norm of rational action, but it seems in practice to be neither that, nor a moral norm. To see this, consider the following case where someone clearly does not follow the principle. While on her way to visit a sick friend in hospital, Jane is convinced by a fellow subway rider that morality requires an impersonal concern for the whole world. She is convinced that morality requires that she not visit her friend, but instead find the patient most in need of a visitor, and see them. But when she gets to the hospital, her new moral belief is not strong enough to overcome her desire to visit her friend in need, which, feeling a little guilty, she does.\nAssuming that Jane’s newfound moral beliefs are wrong, and that in fact she did the right thing, what criticisms can we make of her action? Not that it was immoral, because she did the right thing, visiting her sick friend, and she acted for the right reason, acting out of care for her friend. Nor, it seems, that it was prudentially irrational, for she did what she believed would best satisfy her desires. Perhaps the fact that her new moral beliefs were not sufficiently motivating indicates a lack of resolve, or even a weakness of will, but alternatively one might think that Jane displayed commendable, and virtuous, common sense in not abandoning her friend precipitously. In any case, I doubt Jane’s action cannot be criticised, even if her resolve can be. Since Jane clearly violated Lockhart’s principle, she did not act in the way she thought most likely to be morally permissible, but her action seems immune from criticism, that suggests the principle should not be an action guiding norm.\nOne might argue that Jane has a moral responsibility to desire to do the right thing, and if she had this desire, she would have been rationally required to not visit her friend. If one believes in such a responsibility, then one will think that Jane acted against a desire she should have, that she was, at best, lucky that she did the right thing, and hence she was irrational. Lockhart compares such agents, who do the right thing against their better judgement, to gamblers who bet their life savings on unlikely, but ultimately successful, outcomes. (34)\nThis line of reasoning, however, ultimately does not provide grounds for criticising Jane. A moral agent may well have a moral responsibility to desire to do the things that happen to be the right things to do. For example, she may well have a responsibility to want to visit her sick friends, and to help those in need, and not cause harm to others. But she does not have a responsibility to want to do the right thing, whatever it turns out to be. Indeed, she would be a worse moral agent if many of her actions were motivated by such a desire. She should want to visit her friend because she cares about her friend, not because it is, in the abstract, the right thing to do. Michael Smith has described the desire to do the right thing, whatever it turns out to be, as a moral fetish, and this often seems appropriate. (The Moral Problem, Oxford: Blackwell, 1994, p. 76)\nIt is no discredit to Jane that she lacks this general desire, and in some cases it may be a virtue. If Jane has the general desire, if in Smith’s terminology she is a moral fetishist, then she may be prudentially required to follow Lockhart’s principle, but not otherwise, and she is not required, by any normative standard, to be a moral fetishist. If Jane (virtuously) does not have that general desire to do the right thing, whatever it turns out to be, then she is importantly dissimilar to the gambler, who does (and should) desire to bet on the successful outcome, whatever it turns out to be.\nWhatever the merits of Lockhart’s main principle, his approach raises several fascinating theoretical questions. For example, there is a substantial literature on what the motivational effects of coming to hold a new moral view are, and what they should be. But what is, and what should be, the motivational effects of coming to hold, say, that it is more probable than not that meat eating is permissible? From a different angle, if moral attitudes are more like desires than like beliefs, as some expressivists suggest, then can we even have the attitude that it is more probable than not that meat eating is permissible? Although in general Lockhart says little directly on these theoretical questions, it is a great service to show how they arise.\nIf Lockhart’s main principle is correct, it has rather radical implications for how applied ethics is practiced. Even if it is not, consideration of the issues Lockhart raises may provide a novel and valuable outlook on some familiar theoretical questions.\n\n\n\nCitationBibTeX citation:@misc{weatherson2002,\n  author = {Weatherson, Brian},\n  title = {Review of “{Moral} {Uncertainty} and {Its} {Consequences}”},\n  volume = {111},\n  number = {443},\n  pages = {693-696},\n  date = {2002-07},\n  doi = {10.1093/mind/111.443.693},\n  langid = {en}\n}"
  }
]