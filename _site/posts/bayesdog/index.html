<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.479">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Brian Weatherson">
<meta name="dcterms.date" content="2007-08-01">
<meta name="description" content="It has been argued recently that dogmatism in epistemology is incompatible with Bayesianism. That is, it has been argued that dogmatism cannot be modelled using traditional techniques for Bayesian modelling. I argue that our response to this should not be to throw out dogmatism, but to develop better modelling techniques. I sketch a model for formal learning in which an agent can discover a posteriori fundamental epistemic connections. In this model, there is no formal objection to dogmatism.">

<title>Online Articles - Brian Weatherson - The Bayesian and the Dogmatist</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" href="https://use.typekit.net/uzz2drx.css">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Online Articles - Brian Weatherson</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://brian.weatherson.org"> <i class="bi bi-mortarboard" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://bsky.app/profile/bweatherson.bsky.social"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">The Bayesian and the Dogmatist</h1>
                  <div>
        <div class="description">
          <p>It has been argued recently that dogmatism in epistemology is incompatible with Bayesianism. That is, it has been argued that dogmatism cannot be modelled using traditional techniques for Bayesian modelling. I argue that our response to this should not be to throw out dogmatism, but to develop better modelling techniques. I sketch a model for formal learning in which an agent can discover a posteriori fundamental epistemic connections. In this model, there is no formal objection to dogmatism.</p>
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">epistemology</div>
                <div class="quarto-category">scepticism</div>
              </div>
                  </div>
  </div>
    
  <div class="quarto-title-meta-author">
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-heading">Affiliation</div>
    
      <div class="quarto-title-meta-contents">
      <p class="author"><a href="http://brian.weatherson.org">Brian Weatherson</a> </p>
    </div>
      <div class="quarto-title-meta-contents">
          <p class="affiliation">
              University of Michigan
            </p>
        </div>
      </div>

  <div class="quarto-title-meta">

        
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 1, 2007</p>
      </div>
    </div>
    
      
      <div>
      <div class="quarto-title-meta-heading">Doi</div>
      <div class="quarto-title-meta-contents">
        <p class="doi">
          <a href="https://doi.org/10.1111/j.1467-9264.2007.00217.x">10.1111/j.1467-9264.2007.00217.x</a>
        </p>
      </div>
    </div>
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Sections</h2>
   
  <ul>
  <li><a href="#sceptical-arguments" id="toc-sceptical-arguments" class="nav-link active" data-scroll-target="#sceptical-arguments"><span class="header-section-number">1</span> Sceptical Arguments</a></li>
  <li><a href="#dogmatism-and-a-bayesian-objection" id="toc-dogmatism-and-a-bayesian-objection" class="nav-link" data-scroll-target="#dogmatism-and-a-bayesian-objection"><span class="header-section-number">2</span> Dogmatism and a Bayesian Objection</a></li>
  <li><a href="#bayes-and-keynes" id="toc-bayes-and-keynes" class="nav-link" data-scroll-target="#bayes-and-keynes"><span class="header-section-number">3</span> Bayes and Keynes</a></li>
  <li><a href="#in-defence-of-dynamism" id="toc-in-defence-of-dynamism" class="nav-link" data-scroll-target="#in-defence-of-dynamism"><span class="header-section-number">4</span> In Defence of Dynamism</a>
  <ul class="collapse">
  <li><a href="#the-dogmatist-and-the-keynesian" id="toc-the-dogmatist-and-the-keynesian" class="nav-link" data-scroll-target="#the-dogmatist-and-the-keynesian"><span class="header-section-number">4.1</span> The Dogmatist and the Keynesian</a></li>
  <li><a href="#the-problem-of-the-priors" id="toc-the-problem-of-the-priors" class="nav-link" data-scroll-target="#the-problem-of-the-priors"><span class="header-section-number">4.2</span> The Problem of the Priors</a></li>
  <li><a href="#the-problem-of-old-evidence" id="toc-the-problem-of-old-evidence" class="nav-link" data-scroll-target="#the-problem-of-old-evidence"><span class="header-section-number">4.3</span> The Problem of Old Evidence</a></li>
  <li><a href="#why-should-we-care" id="toc-why-should-we-care" class="nav-link" data-scroll-target="#why-should-we-care"><span class="header-section-number">4.4</span> Why Should We Care?</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="The Bayesian and the Dogmatist.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<p>There is a lot of philosophically interesting work being done in the borderlands between traditional and formal epistemology. It is easy to think that this would all be one-way traffic. When we try to formalise a traditional theory, we see that its hidden assumptions are inconsistent or otherwise untenable. Or we see that the proponents of the theory had been conflating two concepts that careful formal work lets us distinguish. Either way, the formalist teaches the traditionalist a lesson about what the live epistemological options are. I want to argue, more or less by example, that the traffic here should be two-way. By thinking carefully about considerations that move traditional epistemologists, we can find grounds for questioning some presuppositions that many formal epistemologists make.</p>
<p>To make this more concrete, I’m going to be looking at a Bayesian objection to a certain kind of dogmatism about justification. Several writers have urged that the incompatibility of dogmatism with a kind of Bayesianism is a reason to reject dogmatism. I rather think that it is reason to question the Bayesianism. To put the point slightly more carefully, there is a simple proof that dogmatism (of the kind I envisage) can’t be modelled using standard Bayesian modelling tools. Rather than conclude that dogmatism is therefore flawed, I conclude that we need better modelling tools. I’ll spend a fair bit of this paper on outlining a kind of model that (a) allows us to model dogmatic reasoning, (b) is motivated by the epistemological considerations that motivate dogmatism, and (c) helps with a familiar problem besetting the Bayesian.</p>
<p>I’m going to work up to that problem somewhat indirectly. I’ll start with looking at the kind of sceptical argument that motivates dogmatism. I’ll then briefly rehearse the argument that shows dogmatism and Bayesianism are incompatible. Then in the bulk of the paper I’ll suggest a way of making Bayesian models more flexible so they are no longer incompatible with dogmatism. I’ll call these new models <em>dynamic Keynesian</em> models of uncertainty. I’ll end with a brief guide to the virtues of my new kind of model.</p>
<section id="sceptical-arguments" class="level1 page-columns page-full" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Sceptical Arguments</h1>
<p>Let <em>H</em> be some relatively speculative piece of knowledge that we have, say that G. E. Moore had hands, or that it will snow in Alaska sometime next year. And let <em>E</em> be all of our evidence about the external world. I’m not going to make many assumptions about what <em>E</em> contains, but for now <em>E</em> will stay fairly schematic. Now a fairly standard sceptical argument goes something like this. Consider a situation <em>S</em> in which our evidence is unchanged, but in which <em>H</em> is false, such as a brain-in-vat scenario, or a zombie scenario, or a scenario where the future does not resemble the past. Now a fairly standard sceptical argument goes something like this.</p>
<ol type="1">
<li><p>To know <em>H</em> we have to be in a position to know we aren’t in <em>S</em></p></li>
<li><p>We aren’t in a position to know that we aren’t in <em>S</em></p></li>
<li><p>So, we don’t know <em>H</em></p></li>
</ol>
<p>There are a few immediate responses one could make, but which I’m going to dismiss without argument <em>here</em>. These include claiming the setup is incoherent (as in, e.g., <span class="citation" data-cites="Williamson2000-WILKAI">Williamson (<a href="#ref-Williamson2000-WILKAI" role="doc-biblioref">2000</a>)</span>), rejecting the closure principle behind premise 1 (as in, e.g., <span class="citation" data-cites="Dretske1971">Dretske (<a href="#ref-Dretske1971" role="doc-biblioref">1971</a>)</span>, accepting the conclusion (the sceptical response), or saying that in different sceptical arguments, one or other of these positions is correct. Instead I want to look at responses that question premise 2. In particular, I want to look at responses that offer us reasons to accept premise 2, since it seems here that the sceptic is at her strongest. (If the sceptic merely insists that premise 2 is reasonable, we can reply either that it isn’t, as I’m inclined to think, or that here is a case where intuition should be revised.)</p>
<p>Many epistemologists will write papers responding to ‘the sceptic’. I think this is a mistake, since there are so many different possible sceptics, each with different arguments for premise 2. (And, of course, some sceptics do not argue from sceptical scenarios like this one.) Here are, for instance, three arguments that sceptics might give for premise 2.</p>
<ol type="1">
<li><p>Someone in <em>S</em> can’t discriminate her situation from yours.</p></li>
<li><p>Indiscriminability is symmetric.</p></li>
<li><p>If you can’t discriminate our situation from <em>S</em>, you can’t know you’re not in <em>S</em>.</p></li>
<li><p>So you can’t know you’re not in <em>S</em>.</p></li>
</ol>
<!-- -->
<ol type="1">
<li><p>Someone in <em>S</em> has the same evidence as you do.</p></li>
<li><p>What you can know supervenes on what your evidence is.</p></li>
<li><p>So, you can’t know you are not in <em>S</em>.</p></li>
</ol>
<!-- -->
<ol type="1">
<li><p>There is no non-circular argument to the conclusion that you aren’t in <em>S</em>.</p></li>
<li><p>If you were able to know you’re not in <em>S</em>, you would be able to produce a non-circular argument that concluded that you aren’t in <em>S</em>.</p></li>
<li><p>So you can’t know that you aren’t in <em>S</em>.</p></li>
</ol>
<p>I won’t say much about these arguments, save that I think in each case the second premise is very implausible. I suspect that most non-philosophers who are moved by sceptical arguments are tacitly relying on one or other of these arguments, but confirming that would require a more careful psychological study than I could do. But set those aside, because there’s a fourth argument that is more troubling. This argument takes its inspiration from what we might call Hume’s exhaustive argument for inductive scepticism. Hume said that we can’t justify induction inductively, and we can’t justify it deductively, and that <em>exhausts</em> the justifications, so we can’t justify induction. A similar kind of argument helps out the general sceptic.</p>
<ol type="1">
<li><p>If you know you aren’t in <em>S</em>, you know this a priori, or a posteriori</p></li>
<li><p>You can’t know you aren’t in <em>S</em> a posteriori</p></li>
<li><p>You can’t know you aren’t in <em>S</em> a priori</p></li>
<li><p>So, you can’t know you aren’t in <em>S</em></p></li>
</ol>
<p>This seems to be a really interesting argument to me. To make things simpler, I’ll stipulate that by a posteriori knowledge, I just mean knowledge that isn’t a priori. That makes the first premise pretty secure, as long as we’re assuming classical logic.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Lots of philosophers take its third premise for granted. They assume that since it is metaphysically possible that you could be in <em>S</em>, this can’t be something you can rule out a priori. That strikes me as a rather odd capitulation to infallibilism. But I won’t push that here. Instead I’ll look at denials of the second premise.</p>
<div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;Perhaps not a wise assumption around here, but one that I’ll make throughout in what follows.</p></li></div></section>
<section id="dogmatism-and-a-bayesian-objection" class="level1 page-columns page-full" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Dogmatism and a Bayesian Objection</h1>
<p>Someone who denies the second premise says that your empirical evidence can provide the basis for knowing that you aren’t in <em>S</em>, even though you didn’t know this a priori. I’m going to call such a person a <em>dogmatist</em>, for reasons that will become clear shortly. The dogmatist is not a sceptic, so the dogmatist believes that you can know <em>H</em>. The dogmatist also believes a closure principle, so the dogmatist also believes you can know <em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em>. If the dogmatist thought you could know <em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em> a priori, they’d think that you could know a priori that you weren’t in <em>S</em>. (This follows by another application of closure.) But they think that isn’t possible, so knowing <em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em> a priori isn’t possible. Hence you know <em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em> a posteriori.</p>
<p>If we reflect on the fact that <em>E</em> is your total evidence, then we can draw two conclusions. The first is that the dogmatist thinks that you can come to know <em>H</em> on the basis of <em>E</em> even though you didn’t know in advance that if <em>E</em> is true, then <em>H</em> is true. You don’t, that is, need <em>antecedent</em> knowledge of the conditional in order to be able to learn <em>H</em> from <em>E</em>. That’s why I’m calling them a dogmatist. The second point is that the dogmatist is now running head on into a piece of Bayesian orthodoxy.</p>
<p>To see the problem, note that we can easily prove (A), for arbitrary <em>E</em>, <em>H</em> and <em>K</em>.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;Again, the proof uses distinctively classical principles, in particular the equivalence of A with (A <span class="math inline">\({\wedge}\)</span> B) <span class="math inline">\({\vee}\)</span> (A <span class="math inline">\({\wedge}\)</span> <span class="math inline">\({\lnot}\)</span>B.) But I will take classical logic for granted throughout. David Jehle pointed out to me that the proof fails without this classical assumption.</p></li></div><dl>
<dt>(A)</dt>
<dd>
<p><em>Pr</em>(<em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em> <em>E</em>&nbsp;<span class="math inline">\({\wedge}\)</span>&nbsp;<em>K</em>)&nbsp;<span class="math inline">\({\leq}\)</span> <em>Pr</em>(<em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em> <em>K</em>), with equality iff <em>Pr</em>(<em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em> <em>E</em>&nbsp;<span class="math inline">\({\wedge}\)</span>&nbsp;<em>K</em>) = 1</p>
</dd>
</dl>
<p>Proof:</p>
<div class="column-page">
<p><span class="math display">\[
\begin{aligned}
1. &amp; \Pr(E \supset H | K) = \Pr(E \supset H | E \wedge K)\Pr(E | K) + \Pr(E \supset H | \neg E \wedge K)\Pr(\neg E | K) &amp;&amp;  \text{Prob theorem} \\
2. &amp; \Pr(E \supset H | \neg E \wedge K) = 1 &amp;&amp; \text{Logic} \\
3. &amp; \Pr(E \supset H | E \wedge K) \leq 1  &amp;&amp; \text{Prob theorem} \\
4. &amp; \Pr(E \supset H | K)  \geq \Pr(E \supset H | E \wedge K)\Pr(E | K) + \Pr(E \supset H | E \wedge K)\Pr(\neg E | K)  &amp;&amp; \text{1, 2, 3} \\
5. &amp; \Pr(E | K) + \Pr(\neg E | K) = 1  &amp;&amp; \text{Prob theorem} \\
6. &amp; \Pr(E \supset H | K) \geq \Pr(E \supset H | E \wedge K) &amp;&amp; \text{4, 5}
\end{aligned}
\]</span></p>
</div>
<p>It is clear enough from the proof that line 6 is an equality iff line 3 is an equality, so we have proven (A). Now some authors have inferred from this something like (B) from (A).<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div class="no-row-height column-margin column-container"><li id="fn3"><p><sup>3</sup>&nbsp;Roger <span class="citation" data-cites="White2006">White (<a href="#ref-White2006" role="doc-biblioref">2006</a>)</span> and Stewart <span class="citation" data-cites="Cohen2005">Cohen (<a href="#ref-Cohen2005" role="doc-biblioref">2005</a>)</span> endorse probabilistic arguments against people who are, in my sense, dogmatists. John <span class="citation" data-cites="Hawthorne2002">Hawthorne (<a href="#ref-Hawthorne2002" role="doc-biblioref">2002</a>)</span> also makes a similar argument when arguing that certain conditionals, much like E <span class="math inline">\({\supset}\)</span> H, are a priori.</p></li></div><dl>
<dt>(B)</dt>
<dd>
<p>It is impossible to go from not being in a position to know <em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em> to being in a position to know it just by receiving evidence <em>E</em>.</p>
</dd>
</dl>
<p>The transition here should raise an eyebrow or two. (A) is a principle of probability statics. (B) is a principle of epistemological kinematics. To get from (A) to (B) we need a principle linking probability and epistemology, and a principle linking statics and kinematics. Fortunately, orthodox Bayesian confirmation theory offers us suggestions for both principles. We’ll write <em>Cr</em>(<em>A</em>) for the agent’s credence in <em>A</em>, and <em>Cr<sub>E</sub></em>(<em>A</em>) for the agent’s credence in <em>A</em> when updated by receiving evidence <em>E</em>.</p>
<p><span class="smallcaps"><strong>Learning</strong></span><br>
If <em>Cr<sub>E</sub></em>(<em>A</em>) <span class="math inline">\({\leq}\)</span> <em>Cr</em>(<em>A</em>), then it is impossible to go from not being in a position to know <em>A</em> to being in a position to know it just by receiving evidence <em>E</em>.</p>
<p><span class="smallcaps"><strong>Bayes</strong></span><br>
<em>Cr<sub>E</sub></em>(<em>A</em>) = <em>Cr</em>(<em>A</em>&nbsp;|&nbsp;<em>E</em>). That is, learning goes by conditionalisation.</p>
<p>A quick browse at any of the literature on Bayesian confirmation theory will show that these principles are both widely accepted by Bayesians. Philosophers, even Bayesians, make false assumptions, so neither of these principles is obviously true. Nevertheless, I’m going to accept <span class="smallcaps">Learning</span> at least for the sake of argument. I’m going to argue instead that the inference from (A) to (B) fails because <span class="smallcaps">Bayes</span> fails. That is, I’m going to accept that if we could prove a principle I’ll call <span class="smallcaps">Lower</span> is true, then dogmatism in the sense I’m defending it fails.</p>
<p><span class="smallcaps"><strong>Lower</strong></span><br>
<em>Cr<sub>E</sub></em>(<em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em>) is less than or equal to <em>Cr</em>(<em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em>).</p>
<p>Now there is a bad argument around here that the dogmatist might make. It might be argued that since the Bayesian approach (including <span class="smallcaps">Bayes</span>) involves so much idealisation it could not be applicable to real agents. That’s a bad argument because the Bayesian approach might provide us with a good model for real agents, and models can be useful without being scale models. As long as the Bayesian model is the most appropriate model in the circumstances, then we can draw conclusions for the real world from facts about the model. The problem arises if there are alternative models which seem to fit just as well, but in which principles like <span class="smallcaps">Lower</span> are not true. If there are alternative models that seem better suited (or at least just as well suited) to modelling the situation of initial evidence acquisition, and those models do not make <span class="smallcaps">Lower</span> true, then we might think the derivation of <span class="smallcaps">Lower</span> in the Bayesian model is a mere consequence of the arbitrary choice of model. In the next section I will develop just such a model. I won’t argue that it is the best model, let alone the only alternative to the Bayesian model. But I will argue that it is as good for these purposes as the Bayesian model, and it does not imply <span class="smallcaps">Lower</span>.</p>
</section>
<section id="bayes-and-keynes" class="level1 page-columns page-full" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Bayes and Keynes</h1>
<p>The traditional Bayesian model of a rational agent starts with the following two principles.</p>
<ul>
<li><p>At any moment, the agent’s credal states are represented by a probability function.</p></li>
<li><p>From moment to moment, the agent’s credal states are updated by conditionalisation on the evidence received.</p></li>
</ul>
<p>Over recent decades many philosophers have been interested in models that relax those assumptions. One particular model that has got a lot of attention (from e.g.&nbsp;Isaac Levi <span class="citation" data-cites="Levi1974 Levi1980">(<a href="#ref-Levi1974" role="doc-biblioref">Levi 1974</a>, <a href="#ref-Levi1980" role="doc-biblioref">1980</a>)</span>, Richard <span class="citation" data-cites="Jeffrey1983">Jeffrey (<a href="#ref-Jeffrey1983" role="doc-biblioref">1983</a>)</span>, Bas <span class="citation" data-cites="vanFraassen1990">Fraassen (<a href="#ref-vanFraassen1990" role="doc-biblioref">1990</a>)</span>, Alan Hajek <span class="citation" data-cites="Hajek2000 Hajek2003">(<a href="#ref-Hajek2000" role="doc-biblioref">2000</a>, <a href="#ref-Hajek2003" role="doc-biblioref">2003</a>)</span> and many others) is what I’ll call the <em>static Keynesian model</em>. This model has the following features.</p>
<ul>
<li><p>At any moment, the agent’s credal states are represented by a set of probability functions, called their representor.</p></li>
<li><p>The agent holds that <em>p</em> is more probable than <em>q</em> iff the probability of <em>p</em> is greater than the probability of <em>q</em> according to all probability functions in their representor. The agent holds that <em>p</em> and <em>q</em> are equally probable iff the probability of <em>p</em> is equal to the probability of <em>q</em> according to all probability functions in their representor.</p></li>
<li><p>From moment to moment, the agent’s credal states are updated by conditionalising each of the functions in the representor on the evidence received.</p></li>
</ul>
<p>The second point is the big attraction. It allows that the agent need not hold that <em>p</em> is more probable than <em>q</em>, or <em>q</em> more probable than <em>p</em>, or that <em>p</em> and <em>q</em> are equally probable, for arbitrary <em>p</em> and <em>q</em>. And that’s good because it isn’t a rationality requirement that agents make pairwise probability judgments about all pairs of propositions. Largely because of this feature, I argued in an earlier paper that this model could be use to formalise the key philosophical ideas in Keynes’s <em>Treatise on Probability</em>. That’s the reason I call this a ‘Keynesian’ model.</p>
<p>The modifier ‘static’ might seem a little strange, because the agent’s representor does change when she receives new evidence. But the change is always of a certain kind. Her ‘hypothetical priors’ do not change. If at <em>t</em><sub>1</sub> her evidence is <em>E</em><sub>1</sub> and her representor <em>R</em><sub>1</sub>, and at <em>t</em><sub>2</sub> her evidence is <em>E</em><sub>2</sub> and her representor <em>R</em><sub>2</sub>, then there is a ‘prior’ representor <em>R</em><sub>0</sub> such that the following two claims are true for all probability functions <em>Pr</em>.</p>
<ul>
<li><p><em>Pr</em> <span class="math inline">\({\in}\)</span> <em>R</em><sub>1</sub> <span class="math inline">\({\leftrightarrow}\)</span> [<span class="math inline">\({\exists}\)</span>Pr<sub>0</sub> <span class="math inline">\({\in}\)</span> <em>R</em><sub>0</sub>: <span class="math inline">\({\forall}\)</span><em>p</em> (<em>Pr</em>(<em>p</em>) = Pr<sub>0</sub>(<em>p</em> <em>E</em><sub>1</sub>)]</p></li>
<li><p><em>Pr</em> <span class="math inline">\({\in}\)</span> <em>R</em><sub>2</sub> <span class="math inline">\({\leftrightarrow}\)</span> [<span class="math inline">\({\exists}\)</span>Pr<sub>0</sub> <span class="math inline">\({\in}\)</span> <em>R</em><sub>0</sub>: <span class="math inline">\({\forall}\)</span><em>p</em> (<em>Pr</em>(<em>p</em>) = Pr<sub>0</sub>(<em>p</em> <em>E</em><sub>2</sub>)]</p></li>
</ul>
<p>That is, there is a set of probability functions such that the agent’s representor at any time is the result of conditionalising each of those functions on her evidence. I’ll call any model with this property a static model, so the model described above is the static Keynesian model.</p>
<p>Now there is a lot to like about the static Keynesian model, and I have made extensive use of it previous work. It is a particularly useful model to use when we need to distinguish between risk and uncertainty in the sense that these terms are used in Keynes’s 1937 article “The General Theory of Employment”.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> The traditional Bayesian model assumes that all propositions are risky, but in real life some propositions are uncertain as well, and in positions of radical doubt, where we have little or no empirical evidence, presumably most propositions are extremely uncertain. And using the static Keynesian model does not mean we have to abandon the great work done in Bayesian epistemology and philosophy of science. Since a Bayesian model is a (degenerate) static Keynesian model, we can say that in many circumstances (namely circumstances where <em>uncertainty</em> can be properly ignored) the Bayesian model will be appropriate. Indeed, these days it is something like a consensus among probabilists or Bayesians that the static Keynesian model is a useful generalisation of the Bayesian model. For example in <span class="citation" data-cites="Christensen2005">Christensen (<a href="#ref-Christensen2005" role="doc-biblioref">2005</a>)</span> it is noted, almost as an afterthought, that the static Keynesian model will be more realistic, and hence potentially more useful, than the traditional Bayesian model. Christensen doesn’t appear to take this as any kind of <em>objection</em> to Bayesianism, and I think this is just the right attitude.</p>
<div class="no-row-height column-margin column-container"><li id="fn4"><p><sup>4</sup>&nbsp;The clearest statement of the distinction that I know is from that paper.</p>
<blockquote class="blockquote">
<p>By ‘uncertain’ knowledge, let me explain, I do not mean merely to distinguish what is known for certain from what is only probable. The game of roulette is not subject, in this sense, to uncertainty; nor is the prospect of a Victory bond being drawn. Or, again, the expectation of life is only slightly uncertain. Even the weather is only moderately uncertain. The sense in which I am using the term is that in which the prospect of a European war is uncertain, or the price of copper and the rate of interest twenty years hence, or the obsolescence of a new invention, or the position of private wealth owners in the social system in 1970. About these matters there is no scientific basis on which to form any calculable probability whatever. We simply do not know. Nevertheless, the necessity for action and decision compels us as practical men to do our best to overlook this awkward fact and to behave exactly as we should if we had behind us a good Benthamite calculation of a series of prospective advantages and disadvantages, each multiplied by its appropriate probability, waiting to be summed. <span class="citation" data-cites="Keynes1937">(<a href="#ref-Keynes1937" role="doc-biblioref">Keynes 1937, 114–15</a>)</span></p>
</blockquote>
</li></div><p>But just as the static Keynesian is more general than the Bayesian model, there are bound to be interesting models that are more general than the static Keynesian model. One such model is what I call the <em>dynamic</em> Keynesian model. This model has been used by Seth Yalcin to explicate some interesting semantic theories, but to the best of my knowledge it has not been used for epistemological purposes before. That should change. The model is like the static Keynesian model in its use of representors, but it changes the way updating is modelled. When an agent with representor <em>R</em> receives evidence <em>E</em>, she should update her representor by a two step process.</p>
<ul>
<li><p>Replace <em>R</em> with U(<em>R</em>, <em>E</em>)</p></li>
<li><p>Conditionalise U(<em>R</em>, <em>E</em>), i.e.&nbsp;replace it with {<em>Pr</em>( <em>E</em>): <em>Pr</em> is in U(<em>R</em>, <em>E</em>)}</p></li>
</ul>
<p>In this story, U is a function that takes two inputs: a representor and a piece of evidence, and returns a representor that is a subset of the original representor. Intuitively, this models the effect of learning, via getting evidence <em>E</em>, what evidential relationships obtain. In the static Keynesian model, it is assumed that before the agent receives evidence <em>E</em>, she could already say which propositions would receive probabilistic support from <em>E</em>. All of the relations of evidential support were encoded in her conditional probabilities. There is no place in the model for learning about fundamental evidential relationships. In the dynamic Keynesian model, this is possible. When the agent receives evidence <em>E</em>, she might learn that certain functions that were previously in her representor misrepresented the relationship between evidence and hypotheses, particularly between evidence <em>E</em> and other hypotheses. In those cases, U(<em>R</em>, <em>E</em>) will be her old representor <em>R</em>, minus the functions that <em>E</em> teaches her misrepresent these evidential relationships.</p>
<p>The dynamic Keynesian model seems well suited to the dogmatist, indeed to any epistemological theory that allows for fundamental evidential relationships to be only knowable a posteriori. As we’ll see below, this is a reason to stop here in the presentation of the model and not try and say something systematic about the behaviour of U. Instead of developing the model by saying more about <em>U</em>, we should assess it, which is what I’ll do next.</p>
</section>
<section id="in-defence-of-dynamism" class="level1 page-columns page-full" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> In Defence of Dynamism</h1>
<p>In this section I want go over three benefits of the dynamic Keynesian model, and then say a little about how it relates to the discussion of scepticism with which we opened. I’m not going to say much about possible objections to the use of the model. That’s partially for space reasons, partially because what I have to say about the objections I know of is fairly predictable, and partially because the model is new enough that I don’t really know what the strongest objections might be. So here we’ll stick to arguments for the view.</p>
<section id="the-dogmatist-and-the-keynesian" class="level2 page-columns page-full" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="the-dogmatist-and-the-keynesian"><span class="header-section-number">4.1</span> The Dogmatist and the Keynesian</h2>
<p>The first advantage of the dynamic Keynesian model is that because it does not verify <span class="smallcaps">Lower</span>, it is consistent with dogmatism. Now if you think that dogmatism is obviously false, you won’t think this is much of an advantage. But I tend to think that dogmatism is one of the small number of not absurd solutions to a very hard epistemological problem with no obvious solution, so we should not rule it out pre-emptively. Hence I think our formal models should be consistent with it. What is tricky is proving that the dynamic Keynesian model is indeed consistent with it.</p>
<p>To see whether this is true on the dynamic Keynesian model, we need to say what it is to <em>lower</em> the credence of some proposition. Since representors map propositions onto intervals rather than numbers, we can’t simply talk about one ‘probability’ being a smaller number than another.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> On the static Keynesian model, the most natural move is to say that conditionalisation on <em>E</em> <em>lowers</em> the credence of <em>p</em> iff for all <em>Pr</em> in the representor, <em>Pr</em>(<em>p</em>)&nbsp;&gt;&nbsp;<em>Pr</em>(<em>p</em>&nbsp;&nbsp;<em>E</em>). This implies that if every function in the representor says that <em>E</em> is negatively relevant to <em>p</em>, then conditionalising on <em>E</em> makes <em>p</em> less probable. Importantly, it allows this even if the values that <em>Pr</em>(<em>p</em>) takes across the representor before and after conditionalisation overlap. So what should we say on the dynamic Keynesian model? The weakest approach that seems viable, and not coincidentally the most plausible approach, is to say that updating on <em>E</em> lowers the credence of <em>p</em> iff the following conditions are met:</p>
<div class="no-row-height column-margin column-container"><li id="fn5"><p><sup>5</sup>&nbsp;Strictly speaking, the story I’ve told so far does not guarantee that for any proposition <em>p</em>, the values that Pr(<em>p</em>) takes (for Pr in the representor) form an interval. But it is usual in more detailed presentations of the model to put constraints on the representor to guarantee that happens, and I’ll assume we’ve done that.</p></li></div><ul>
<li><p>For all <em>Pr</em> in U(<em>R</em>, <em>E</em>), <em>Pr</em>(<em>p</em> <em>E</em>) &lt; <em>Pr</em>(<em>p</em>)</p></li>
<li><p>For all <em>Pr</em> in <em>R</em> but not in U(<em>R</em>, <em>E</em>), there is a <em>Pr</em><span class="math inline">\(^\prime\)</span> in U(<em>R</em>, <em>E</em>) such that <em>Pr</em><span class="math inline">\(^\prime\)</span>(<em>p</em>&nbsp;&nbsp;<em>E</em>) &lt; <em>Pr</em>(<em>p</em>)</p></li>
</ul>
<p>It isn’t too hard to show that for some models, updating on <em>E</em> does not lower the credence of <em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em>, if lowering is understood this way. The following is an extreme example, but it suffices to make the logical point. Let <em>R</em> be the minimal representor, the set of all probability functions that assign probability 1 to a priori certainties. And let U(<em>R</em>, <em>E</em>) be the singleton of the following probability function, defined only over Boolean combinations of <em>E</em> and <em>H</em>: <em>Pr</em>(<em>E</em>&nbsp;<span class="math inline">\({\wedge}\)</span>&nbsp;<em>H</em>) = <em>Pr</em>(<em>E</em>&nbsp;<span class="math inline">\({\wedge}\)</span>&nbsp;<span class="math inline">\({\lnot}\)</span><em>H</em>) = <em>Pr</em>(<span class="math inline">\({\lnot}\)</span><em>E</em>&nbsp;<span class="math inline">\({\wedge}\)</span>&nbsp;<em>H</em>) = <em>Pr</em>(<span class="math inline">\({\lnot}\)</span><em>E</em>&nbsp;<span class="math inline">\({\wedge}\)</span>&nbsp;<span class="math inline">\({\lnot}\)</span><em>H</em>) = <span class="math inline">\(\frac{1}{4}\)</span>. Then the probability of <em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em> after updating is <span class="math inline">\(\frac{3}{4}\)</span>. (More precisely, according to all <em>Pr</em> in U(<em>R</em>, <em>E</em>), <em>Pr</em>(<em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em>)&nbsp;=&nbsp;<span class="math inline">\(\frac{3}{4}\)</span>.) Since before updating there were <em>Pr</em> in <em>R</em> such that <em>Pr</em>(<em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em>) &lt; <span class="math inline">\(\frac{3}{4}\)</span>, in fact there were <em>Pr</em> in <em>R</em> such that <em>Pr</em>(<em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em>)&nbsp;=&nbsp;0, updating on <em>E</em> did not <em>lower</em> the credence of <em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em>. So the dynamic Keynesian model does not, in general, have as a consequence that updating on <em>E</em> lowers the credence of <em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em>. This suggests that <span class="smallcaps">Lower</span> in general is not true.</p>
<p>It might be objected that if evidence <em>E</em> supports our knowledge that <em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em>, then updating on <em>E</em> should <em>raise</em> the credence of <em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em>. And if we define credence raising the same way we just defined credence lowering, updating on <em>E</em> <em>never</em> raises the credence of <em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em>. From a Keynesian perspective, we should simply deny that evidence has to raise the credence of the propositions known on the basis of that evidence. It might be sufficient that getting this evidence removes the uncertainty associated with those propositions. Even on the static Keynesian model, it is possible for evidence to remove uncertainty related to propositions without raising the probability of that proposition. A little informally, we might note that whether an agent with representor <em>R</em> is sufficiently confident in <em>p</em> to know that <em>p</em> depends on the lowest value that <em>Pr</em>(<em>p</em>) takes for <em>Pr</em> <span class="math inline">\({\in}\)</span> <em>R</em>, and updating can raise the value of this ‘lower bound’ without raising the value of <em>Pr</em>(<em>p</em>) according to all functions in <em>R</em>, and hence without strictly speaking <em>raising</em> the credence of <em>p</em>.</p>
<p>The above illustration is obviously unrealistic, in part because U could not behave that way. It’s tempting at this stage to ask just how U does behave so we can work out if there are more realistic examples. Indeed, it’s tempting to try to attempt to provide a formal description of U. This temptation should be resisted. The whole point of the model is that we can only learn which hypotheses are supported by certain evidence by actually getting that evidence. If we could say just what U is, we would be able to know what was supported by any kind of evidence without getting that evidence. The best we can do with respect to U is to discover some of its contours with respect to evidence much like our own. And the way to make those discoveries will be to do scientific and epistemological research. It isn’t obvious that, say, looking for nice formal properties of U will help at all.</p>
</section>
<section id="the-problem-of-the-priors" class="level2 page-columns page-full" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="the-problem-of-the-priors"><span class="header-section-number">4.2</span> The Problem of the Priors</h2>
<p>One really nice consequence of the dynamic Keynesian approach is that it lets us say what the representor of an agent with no empirical information should be. Say a proposition is <em>a priori certain</em> iff it is a priori that all rational agents assign credence 1 to that proposition. Then the representor of the agent with no empirical evidence is {<em>Pr</em>: <span class="math inline">\({\forall}\)</span><em>p</em>: If <em>p</em> is a priori certain, then <em>Pr</em>(<em>p</em>) = 1}. This is the minimal representor I mentioned above. Apart from assigning probability 1 to the a priori certainties, the representor is silent. Hence it treats all propositions that are not a priori certain in exactly the same way. This kind of symmetric treatment of propositions is not possible on the traditional Bayesian conception for logical reasons. (The reasons are set out in the various discussions of the paradoxes of indifference, going back to <span class="citation" data-cites="Bertrand1888">Bertrand (<a href="#ref-Bertrand1888" role="doc-biblioref">1888</a>)</span>.) Such a prior representor is consistent with the static Keynesian approach, but it yields implausible results, since conditionalising on <em>E</em> has no effect on the distribution of values of Pr(<em>p</em>) among functions in the representor for any <em>p</em> not made a priori certain by <em>E</em>. (We’ll say <em>p</em> is made a priori certain by <em>E</em> iff <em>E</em> <span class="math inline">\({\supset}\)</span> <em>p</em> is a priori certain.) So if this is our starting representor, we can’t even get probabilistic evidence for things that are not made certain by our evidence.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> So on the static Keynesian model, this attractively symmetric prior representor is not available.</p>
<div class="no-row-height column-margin column-container"><li id="fn6"><p><sup>6</sup>&nbsp;The argument in the text goes by a little quickly, because I’ve defined representors in terms on unconditional probabilities and this leads to complications to do with conditionalising on propositions of zero probability. A better thing to do, as suggested by <span class="citation" data-cites="Hajek2003">Hájek (<a href="#ref-Hajek2003" role="doc-biblioref">2003</a>)</span>, is to take conditional probability as primitive. If we do this we’ll define representors as sets of conditional probability functions, and the a priori representor will be {Pr: If <em>p</em> <span class="math inline">\({\supset}\)</span> <em>q</em> is a priori certain, then Pr(<em>q</em> <em>p</em>) = 1}. Then the claim in the text will follow.</p></li></div><p>I think one of the motivations of anti-dogmatist thinking is the thought that we <em>should</em> be able to tell a priori what is evidence for what. If it looking like there is a cow in front of us is a reason to think there is a cow in front of us, that should be knowable a priori. I think the motivation for this kind of position shrinks a little when we realise that an a priori prior that represented all the connections between evidence and hypotheses would have to give us a lot of guidance as to what to do (epistemically speaking) in worlds quite unlike our own. Moreover, there is no reason we should have lots that information. So consider, for a minute, a soul in a world with no spatial dimensions and three temporal dimensions, where the primary source of evidence for souls is empathic connection with other souls from which they get a (fallible) guide to those souls’ mental states. When such a soul conditionalises on the evidence “A soul seems to love me” (that’s the kind of evidence they get) what should their posterior probability be that there is indeed a soul that loves them? What if the souls have a very alien mental life, so they instantiate mental concepts very unlike our own, and souls get fallible evidence of these alien concepts being instantiated through empathy? I think it’s pretty clear we <em>don’t</em> know the answers to these questions. (Note that to answer this question we’d have to know which of these concepts were grue-like, and which were projectable, and there is no reason to believe we are in a position to know that.) Now those souls are presumably just as ignorant about the epistemologically appropriate reaction to the kinds of evidence we get, like seeing a cow or hearing a doorbell, as we are about their evidence. The dynamic Keynesian model can allow for this, especially if we use the very weak prior representor described above. When we get the kind of evidence we actually get, the effect of U is to shrink our representors to sets of probability functions which are broadly speaking epistemically appropriate for the kind of world we are in. Before we got that evidence, we didn’t know how we should respond to it, just like the spaceless empathic souls don’t know how to respond to it, just like we don’t know how to respond to their evidence.</p>
<p>It is a commonplace observation that (a) prior probabilities are really crucial in Bayesian epistemology, but (b) we have next to no idea what they look like. I call this the problem of the priors, and note with some satisfaction that the dynamic Keynesian model avoids it. Now a cynic might note that all I’ve done is replace a hand-wavy story about priors with a hand-wavy story about updating. That’s true, but nevertheless I think this is progress. The things I’m being deliberately unclear about, such as what U should look like for <em>E</em> such as “Some other non-spatial tri-temporal soul seems to love me” are things that (a) my theory says are not a priori knowable, and (b) I don’t have any evidence concerning. So it isn’t surprising that I don’t have much to say about them. It isn’t clear that the traditional Bayesian can offer any story, even by their own lights, as to why they are less clear about the structure of the prior probability conditional on such an <em>E</em>.</p>
</section>
<section id="the-problem-of-old-evidence" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="the-problem-of-old-evidence"><span class="header-section-number">4.3</span> The Problem of Old Evidence</h2>
<p>When we get evidence <em>E</em>, the dynamic Keynesian model says that we should do two things. First, we should throw out some probability functions in our representor. Second, we should conditionalise those that remain. But this is a normative condition, not a description of what actually happens. Sometimes, when we get evidence <em>E</em>, we may not realise that it is evidence that supports some theory <em>T</em>. That is, we won’t sufficiently cull the representor of those probability functions where the probability of <em>T</em> given <em>E</em> is not high. Housecleaning like this is hard, and sometimes we only do it when it becomes essential. In this case, that means we only do it when we start paying serious attention to <em>T</em>. In that case we may find that evidence <em>E</em>, evidence we’ve already incorporated, in the sense of having used in conditionalisation, gives us reason to be more confident than we were in <em>T</em>. In such a case we’ll simply cull those functions where probability of <em>T</em> given <em>E</em> is not high, and we will be more confident in <em>T</em>. That’s how old evidence can be relevant on the dynamic Keynesian model. Since we have a story about how old evidence can be relevant, there is no problem of old evidence for the dynamic Keynesian.</p>
<p>Famously, there <em>is</em> a problem of old evidence for traditional Bayesians. Now I’m not going to rehearse all the arguments concerning this problem to convince you that this problem hasn’t been solved. That’s in part because it would take too long and in part because I’m not sure myself that it hasn’t been solved. But I will note that if you think the problem of old evidence <em>is</em> a live problem for traditional Bayesians, then you have a strong reason for taking the dynamic Keynesian model seriously.</p>
</section>
<section id="why-should-we-care" class="level2 page-columns page-full" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="why-should-we-care"><span class="header-section-number">4.4</span> Why Should We Care?</h2>
<p>The sceptic’s opening move was to appeal to our intuition that propositions like <em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em> are unknowable. We then asked what reasons we could be given for accepting this claim, because the sceptic seems to want to derive quite a lot from a raw intuition. The sceptic can respond with a wide range of arguments, four of which are mentioned above. Here we focussed on the sceptic’s argument from exhaustion. <em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em> isn’t knowable a priori, because it could be false, and it isn’t knowable a posteriori, because, on standard models of learning, our evidence <em>lowers</em> its credibility. My response is to say that this is an artefact of the model the sceptic (along with everyone else) is using. There’s nothing wrong with using simplified models, in fact it is usually the only way to make progress, but we must be always wary that our conclusions transfer from the model to the real world. One way to argue that a conclusion is a mere artefact of the model is to come up with a model that is sensitive to more features of reality in which the conclusion does not hold. That’s what I’ve done here. The dynamic Keynesian model is sensitive to the facts that (a) there is a distinction between risk and uncertainty and (b) we can learn about fundamental evidential connections. In the dynamic Keynesian model, it isn’t true that our evidence lowers the probability of <em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em>. So the anti-sceptic who says that <em>E</em>&nbsp;<span class="math inline">\({\supset}\)</span>&nbsp;<em>H</em> is knowable a posteriori, the person I’ve called the dogmatist, has a defence against this Bayesian argument. If the response is successful, then there may well be other applications of the dynamic Keynesian model, but for now I’m content to show how the model can be used to defend the dogmatic response to scepticism.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<div class="no-row-height column-margin column-container"><li id="fn7"><p><sup>7</sup>&nbsp;Image on website <a href="https://www.flickr.com/photos/102148845@N07">hiwhataboutyou</a> via <a href="https://search.creativecommons.org/photos/2490c26c-ce0e-46ce-b4cd-16dfb3fe063b">Creative Commons</a>.</p></li></div></section>
<section id="references" class="level2 unnumbered">




</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Bertrand1888" class="csl-entry" role="listitem">
Bertrand, Joseph Louis François. 1888. <em>Calcul Des Probabilités</em>. Paris: Gauthier-Villars et fils.
</div>
<div id="ref-Christensen2005" class="csl-entry" role="listitem">
Christensen, David. 2005. <em>Putting Logic in Its Place</em>. Oxford: Oxford University Press.
</div>
<div id="ref-Cohen2005" class="csl-entry" role="listitem">
Cohen, Stewart. 2005. <span>“Why Basic Knowledge Is Easy Knowledge.”</span> <em>Philosophy and Phenomenological Research</em> 70 (2): 417–30. <a href="https://doi.org/10.1111/j.1933-1592.2005.tb00536.x">https://doi.org/10.1111/j.1933-1592.2005.tb00536.x</a>.
</div>
<div id="ref-Dretske1971" class="csl-entry" role="listitem">
Dretske, Fred. 1971. <span>“Conclusive Reasons.”</span> <em>Australasian Journal of Philosophy</em> 49 (1): 1–22. <a href="https://doi.org/10.1080/00048407112341001">https://doi.org/10.1080/00048407112341001</a>.
</div>
<div id="ref-vanFraassen1990" class="csl-entry" role="listitem">
Fraassen, Bas van. 1990. <span>“Figures in a Probability Landscape.”</span> In <em>Truth or Consequences</em>, edited by J. M. Dunn and A. Gupta, 345–56. Amsterdam: Kluwer.
</div>
<div id="ref-Hajek2000" class="csl-entry" role="listitem">
Hájek, Alan. 2000. <span>“Objecting Vaguely to Pascal’s Wager.”</span> <em>Philosophical Studies</em> 98: 1–16. <a href="https://doi.org/10.1023/A:1018329005240">https://doi.org/10.1023/A:1018329005240</a>.
</div>
<div id="ref-Hajek2003" class="csl-entry" role="listitem">
———. 2003. <span>“What Conditional Probability Could Not Be.”</span> <em>Synthese</em> 137 (3): 273–323. <a href="https://doi.org/10.1023/B:SYNT.0000004904.91112.16">https://doi.org/10.1023/B:SYNT.0000004904.91112.16</a>.
</div>
<div id="ref-Hawthorne2002" class="csl-entry" role="listitem">
Hawthorne, John. 2002. <span>“Deeply Contingent a Priori Knowledge.”</span> <em>Philosophy and Phenomenological Research</em> 65 (2): 247–69. <a href="https://doi.org/10.1111/j.1933-1592.2002.tb00201.x">https://doi.org/10.1111/j.1933-1592.2002.tb00201.x</a>.
</div>
<div id="ref-Jeffrey1983" class="csl-entry" role="listitem">
Jeffrey, Richard. 1983. <span>“Bayesianism with a Human Face.”</span> In <em>Testing Scientific Theories</em>, edited by J. Earman (ed.). Minneapolis: University of Minnesota Press.
</div>
<div id="ref-Keynes1937" class="csl-entry" role="listitem">
Keynes, John Maynard. 1937. <span>“The General Theory of Employment.”</span> <em>Quarterly Journal of Economics</em> 51 (2): 209–23. <a href="https://doi.org/10.2307/1882087">https://doi.org/10.2307/1882087</a>.
</div>
<div id="ref-Levi1974" class="csl-entry" role="listitem">
Levi, Isaac. 1974. <span>“On Indeterminate Probabilities.”</span> <em>Journal of Philosophy</em> 71 (13): 391–418. <a href="https://doi.org/10.2307/2025161">https://doi.org/10.2307/2025161</a>.
</div>
<div id="ref-Levi1980" class="csl-entry" role="listitem">
———. 1980. <em>The Enterprise of Knowledge</em>. Cambridge, MA.: MIT Press.
</div>
<div id="ref-White2006" class="csl-entry" role="listitem">
White, Roger. 2006. <span>“Problems for Dogmatism.”</span> <em>Philosophical Studies</em> 131 (3): 525–57. <a href="https://doi.org/10.1007/s11098-004-7487-9">https://doi.org/10.1007/s11098-004-7487-9</a>.
</div>
<div id="ref-Williamson2000-WILKAI" class="csl-entry" role="listitem">
Williamson, Timothy. 2000. <em><span class="nocase">Knowledge and its Limits</span></em>. Oxford University Press.
</div>
</div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@article{weatherson2007,
  author = {Weatherson, Brian},
  title = {The {Bayesian} and the {Dogmatist}},
  journal = {Proceedings of the Aristotelian Society},
  volume = {107},
  number = {2},
  pages = {169-185},
  date = {2007-08},
  doi = {10.1111/j.1467-9264.2007.00217.x},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>