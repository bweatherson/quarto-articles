<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.479">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="James Joyce">
<meta name="author" content="Brian Weatherson">
<meta name="dcterms.date" content="2019-01-01">
<meta name="description" content="Recently several authors have argued that accuracy-first epistemology ends up licensing problematic epistemic bribes. They charge that it is better, given the accuracy-first approach, to deliberately form one false belief if this will lead to forming many other true beliefs. We argue that this is not a consequence of the accuracy-first view. If one forms one false belief and a number of other true beliefs, then one is committed to many other false propositions, e.g., the conjunction of that false belief with any of the true beliefs. Once we properly account for all the falsehoods that are adopted by the person who takes the bribe, it turns out that the bribe does not increase accuracy.">

<title>Online Articles - Brian Weatherson - Accuracy and the Imps</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" href="https://use.typekit.net/uzz2drx.css">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Online Articles - Brian Weatherson</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://brian.weatherson.org"> <i class="bi bi-mortarboard" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://bsky.app/profile/bweatherson.bsky.social"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Accuracy and the Imps</h1>
                  <div>
        <div class="description">
          <p>Recently several authors have argued that accuracy-first epistemology ends up licensing problematic epistemic bribes. They charge that it is better, given the accuracy-first approach, to deliberately form one false belief if this will lead to forming many other true beliefs. We argue that this is not a consequence of the accuracy-first view. If one forms one false belief and a number of other true beliefs, then one is committed to many other false propositions, e.g., the conjunction of that false belief with any of the true beliefs. Once we properly account for all the falsehoods that are adopted by the person who takes the bribe, it turns out that the bribe does not increase accuracy.</p>
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">epistemology</div>
                <div class="quarto-category">accuracy</div>
              </div>
                  </div>
  </div>
    
  <div class="quarto-title-meta-author">
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-heading">Affiliation</div>
    
      <div class="quarto-title-meta-contents">
      <p class="author"><a href="http://www-personal.umich.edu/~jjoyce/">James Joyce</a> </p>
    </div>
      <div class="quarto-title-meta-contents">
          <p class="affiliation">
              University of Michigan
            </p>
        </div>
        <div class="quarto-title-meta-contents">
      <p class="author"><a href="http://brian.weatherson.org">Brian Weatherson</a> </p>
    </div>
      <div class="quarto-title-meta-contents">
          <p class="affiliation">
              University of Michigan
            </p>
        </div>
      </div>

  <div class="quarto-title-meta">

        
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 1, 2019</p>
      </div>
    </div>
    
      
      <div>
      <div class="quarto-title-meta-heading">Doi</div>
      <div class="quarto-title-meta-contents">
        <p class="doi">
          <a href="https://doi.org/10.5840/logos-episteme201910325">10.5840/logos-episteme201910325</a>
        </p>
      </div>
    </div>
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Sections</h2>
   
  <ul>
  <li><a href="#accuracybribesandscoringrules" id="toc-accuracybribesandscoringrules" class="nav-link active" data-scroll-target="#accuracybribesandscoringrules"><span class="header-section-number">1</span> Accuracy, Bribes and Scoring Rules</a></li>
  <li><a href="#fourcaveats" id="toc-fourcaveats" class="nav-link" data-scroll-target="#fourcaveats"><span class="header-section-number">2</span> Four Caveats</a>
  <ul class="collapse">
  <li><a href="#greavessargumentmayworkagainstsomeformsofconsequentialism" id="toc-greavessargumentmayworkagainstsomeformsofconsequentialism" class="nav-link" data-scroll-target="#greavessargumentmayworkagainstsomeformsofconsequentialism"><span class="header-section-number">2.0.1</span> Greaves’s Imps Argument May Work Against Some Forms of Consequentialism</a></li>
  <li><a href="#separatenessofpropositions" id="toc-separatenessofpropositions" class="nav-link" data-scroll-target="#separatenessofpropositions"><span class="header-section-number">2.0.2</span> Separateness of Propositions</a></li>
  <li><a href="#isthisconsequentialism" id="toc-isthisconsequentialism" class="nav-link" data-scroll-target="#isthisconsequentialism"><span class="header-section-number">2.0.3</span> Is this Consequentialism?</a></li>
  <li><a href="#otherbribes" id="toc-otherbribes" class="nav-link" data-scroll-target="#otherbribes"><span class="header-section-number">2.0.4</span> Other Bribes</a></li>
  </ul></li>
  <li><a href="#appendix-proofs-of-theorems-1-2-3" id="toc-appendix-proofs-of-theorems-1-2-3" class="nav-link" data-scroll-target="#appendix-proofs-of-theorems-1-2-3">Appendix: Proofs of Theorems 1, 2, 3</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="accuracy-and-the-imps.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<section id="accuracybribesandscoringrules" class="level1 page-columns page-full" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Accuracy, Bribes and Scoring Rules</h1>
<p>Belief aims at the truth. So at least in some sense, an agent is doing better at believing the closer they are to the truth. When applied to individual beliefs, this generates epistemic advice that is literally platitudinous: if you know that a change in your attitude towards <em>p</em> will make your attitude towards <em>p</em> more accurate, make that change! When applied to collective bodies of belief though, the advice turns out to be more contentious. Call <strong>epistemic consequentialism</strong> the view that if an agent knows that a change in their overall belief state will make their belief state more accurate, they should make that change, if they have the power to do so.</p>
<aside>
<p>Thanks to Alejandro Pérez Carballo, Richard Pettigrew, and the participants in the Arché Epistemology Seminar for helpful comments.</p>
<p>Image by <a href="https://www.flickr.com/photos/28481088@N00">tanakawho</a> via <a href="https://search.creativecommons.org/photos/116b1f9d-ec74-481f-bff6-2dcc99656d1a">Creative Commons</a>.</p>
</aside>
<p>Hilary <span class="citation" data-cites="Greaves2013">Greaves (<a href="#ref-Greaves2013" role="doc-biblioref">2013</a>)</span> has recently argued that epistemic consequentialism is false because it licences certain epistemic ‘bribes’, and these should not be licenced. We’ll argue that the best forms of epistemic consequentialism do not licence some of these bribes after all.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Here is the key case Greaves uses.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;Though they do licence others; see section 2.4 for more discussion.</p></li><li id="fn2"><p><sup>2</sup>&nbsp;Greaves has four other cases, but the Imps case is the only one that is a problem for all forms of consequentialism she discusses. Similar cases have suggested by Selim <span class="citation" data-cites="Berker2013b Berker2013a">(<a href="#ref-Berker2013b" role="doc-biblioref">Berker 2013a</a>, <a href="#ref-Berker2013a" role="doc-biblioref">2013b</a>)</span> and C. S. <span class="citation" data-cites="Jenkins2007">Jenkins (<a href="#ref-Jenkins2007" role="doc-biblioref">2007</a>)</span>, but we’ll focus on Greaves’s discussion since she engages more fully with the literature on scoring rules. We’ll return briefly to Berker’s discussion in section 2.</p></li></div><blockquote class="blockquote">
<p>Emily is taking a walk through the Garden of Epistemic Imps. A child plays on the grass in front of her. In a nearby summerhouse are <span class="math inline">\(n\)</span> further children, each of whom may or may not come out to play in a minute. They are able to read Emily’s mind, and their algorithm for deciding whether to play outdoors is as follows. If she forms degree of belief 0 that there is now a child before her, they will come out to play. If she forms degree of belief 1 that there is a child before her, they will roll a fair die, and come out to play iff the outcome is an even number. More generally, the summerhouse children will play with chance <span class="math inline">\((1-\frac{q(C_0)}{2})\)</span>, where <span class="math inline">\(q(C_0)\)</span> is the degree of belief Emily adopts in the proposition <span class="math inline">\(C_0\)</span> that there is now a child before her. Emily’s epistemic decision is the choice of credences in the proposition <span class="math inline">\(C_0\)</span> that there is now a child before her, and, for each <span class="math inline">\(j = 1, \ldots, n\)</span> the proposition <span class="math inline">\(C_j\)</span> that the <em>j</em>th summerhouse child will be outdoors in a few minutes’ time.</p>
</blockquote>
<blockquote class="blockquote">
<p><span class="math inline">\(\ldots\)</span> if Emily can just persuade herself to ignore her evidence for <span class="math inline">\(C_0\)</span>, and adopt (at the other extreme) credence 0 in <span class="math inline">\(C_0\)</span>, then, by adopting degree of belief 1 in each <span class="math inline">\(C_{j} (j = 1, ... , 10)\)</span>, she can guarantee a perfect match to the remaining truths. Is it epistemically rational to accept this ‘epistemic bribe’? <span class="citation" data-cites="Greaves2013">Greaves (<a href="#ref-Greaves2013" role="doc-biblioref">2013, 918</a>)</span></p>
</blockquote>
<p>The epistemic consequentialist says that it is best to have credences that are as accurate as possible. We will focus on believers who assign probabilistically coherent credences (degrees of belief) to the propositions in some “target set” <span class="math inline">\(\mathscr{X}\)</span>, and we will think of the “degree of fit” between her beliefs and the truth as being measured by a strictly proper scoring rule. This is a function <span class="math inline">\(\mathbf{I}_{\mathscr{X}}\)</span> which associates each pair <span class="math inline">\(\langle \mathbf{cred}, @ \rangle\)</span> consisting of a credence function <span class="math inline">\(\mathbf{cred}\)</span> whose domain includes <span class="math inline">\(\mathscr{X}\)</span> and a consistent truth-value assignment @ for elements of <span class="math inline">\(\mathscr{X}\)</span> with a non-negative real number <span class="math inline">\(\mathbf{I}_{\mathscr{X}}(@, \mathbf{cred})\)</span>. Intuitively, <span class="math inline">\(\mathbf{I}_{\mathscr{X}}\)</span> measures the inaccuracy of the credences that cred assigns to the propositions in <span class="math inline">\(\mathscr{X}\)</span> when their truth-values are as described by @. Note that higher <span class="math inline">\(\mathbf{I}_{\mathscr{X}}\)</span>-values indicate higher levels of epistemic disutility, so that lower is better from a consequentialist perspective. One popular scoring rule is the Brier score, which identifies inaccuracy with the average squared distance between credences and truth-values. (Greaves calls this the ‘quadratic scoring rule’, which is a useful description too.) More formally, we have:</p>
<p><span class="math display">\[\mathbf{Brier}_{\mathscr{X}}(@, \mathbf{cred}) = \frac{1}{|\mathscr{X}|}\sum_{X \in \mathscr{X}} (\mathbf{cred}(X) - @(X))^2\]</span> where <span class="math inline">\(|\mathscr{X}|\)</span> is the number of propositions in <span class="math inline">\(\mathscr{X}\)</span> and <span class="math inline">\(@(X)\)</span> is either zero or one depending upon whether X is true or false.</p>
<p>Another common score is the logarithmic rule, which defines inaccuracy as:</p>
<p><span class="math display">\[\mathbf{Log}_{\mathscr{X}}(@, \mathbf{cred}) = \frac{1}{|\mathscr{X}|}\sum_{X \in \mathscr{X}} -\text{log}(\mathbf{cred}(X)) \cdot @(X)\]</span> For now we will follow Greaves in assuming that our epistemic consequentialist uses the Brier score to measure epistemic disutility, but we will relax that assumption in a little while.</p>
<p>Now let’s think about the ‘bribe’ that Greaves offers, from the point of view of the epistemic consequentialist. The choices are to have one of two credal states, which we’ll call <strong>cred1</strong> and <strong>cred2</strong>. We’ll say <strong>cred1</strong> is the one that best tracks the initial evidence, so <span class="math inline">\(\mathbf{cred1}(C_0) = 1\)</span>, and <span class="math inline">\(\mathbf{cred1}(C_i) = 0.5\)</span> for <span class="math inline">\(i \in {1, ..., 10}\)</span>. And <strong>cred2</strong> is the credence Emily adopts if she accepts the bribe, so <span class="math inline">\(\mathbf{cred2}(C_0) = 0\)</span>, while <span class="math inline">\(\mathbf{cred2}(C_i) = 1\)</span> for <span class="math inline">\(i \in {1, ..., 10}\)</span>. Which state is better?</p>
<p>Thinking like an epistemic consequentialist, you might ask which state is more accurate? It seems like that would be <strong>cred2</strong>. While <strong>cred1</strong> gets <span class="math inline">\(C_0\)</span> exactly right it does not do very well on the other propositions. In contrast, while <strong>cred2</strong> gets <span class="math inline">\(C_0\)</span> exactly wrong, it is perfect on the other ten propositions. So overall, <strong>cred2</strong> looks to have better epistemic consequences: when compared to being right about one proposition and off by 0.5 on ten others, being right on ten is surely worth one false belief. The Brier score seems to bear this out. If we let <span class="math inline">\(\mathscr{X}\)</span>, the target set, consist of <span class="math inline">\(C_0, C_1, ..., C_{10}\)</span>, then we have <span class="math display">\[\begin{aligned}
\mathbf{Brier}_\mathscr{X}(\mathbf{cred1}, @) &amp;= \frac{1}{11}[(1-\mathbf{cred1}(C_0))^2 + \sum_{i = 1}^{10} (@(C_i) - \frac{1}{2}) ^2] = \frac{10}{44} \\
\mathbf{Brier}_\mathscr{X}(\mathbf{cred2}, @) &amp;= \frac{1}{11}[(1-\mathbf{cred2}(C_0))^2 + \sum_{i = 1}^{10} (@(C_i) - cred(C_i)) ^2] = \frac{1}{11} \end{aligned}\]</span> So, it seems that a good epistemic consequentialist will take the bribe. But, doesn’t that seem like the height of epistemic irresponsibility? It means choosing to believe that <span class="math inline">\(C_0\)</span> is certainly false when you have conclusive evidence for thinking that it is true. If you see the child on the lawn in front of you, how can you sanction believing she is not there?</p>
<p>As Greaves admits, intuitions are divided here. Some consequentialists might think that “epistemic bribes” are at least sometimes worth taking, while those of a more deontological bent will always find such trade-offs “beyond the pale” &nbsp;<span class="citation" data-cites="Berker2013b">(<a href="#ref-Berker2013b" role="doc-biblioref">Berker 2013a, 363</a>)</span>. We will largely sidestep these contentious issues here, though our argument will offer comfort to epistemic consequentialists who feel queasy about accepting the bribe offered in Imps. We contend that, when inaccuracy is measured properly, the consequences of adopting the <strong>cred2</strong> credences are strictly worse than the consequences of adopting <strong>cred1</strong>.</p>
<p>The basic problem is that Imps cherry-picks propositions in a way no consequentialist should condone. Its persuasive force rests on the assumption that, for purposes of epistemic evaluation, nothing matters except the accuracies of the credences assigned to propositions in the target set <span class="math inline">\(\mathscr{X}\)</span>. But <span class="math inline">\(\mathscr{X}\)</span> is the wrong target! By confining attention to it Greaves ignores the many other credences to which Emily becomes committed as a consequence of adopting <strong>cred1</strong> or <strong>cred2</strong>. Any (coherent) agent who invests credence zero in <span class="math inline">\(C_0\)</span> must also invest credence zero in any proposition <span class="math inline">\(C_0 \wedge Y\)</span>, where <span class="math inline">\(Y\)</span> is any conjunction or disjunction of elements from <span class="math inline">\(\mathscr{X}\)</span>. Likewise, anyone who invests credence one in <span class="math inline">\(C_n\)</span> must invest credence one in any proposition <span class="math inline">\(C_n \vee Y\)</span>, where <span class="math inline">\(Y\)</span> is any conjunction or disjunction from <span class="math inline">\(\mathscr{X}\)</span>. In the current context (where the probabilities of the various <span class="math inline">\(C_i\)</span> are independent), when Emily adopts a credence function over <span class="math inline">\(\mathscr{X}\)</span> she commits to having a credence for (i) every atomic proposition ±<span class="math inline">\(C_0 \wedge\)</span>± <span class="math inline">\(C_1 \wedge\)</span>±<span class="math inline">\(C_2 \wedge \ldots \wedge\)</span>±<span class="math inline">\(C_{10}\)</span>, where ‘±’ can be either an affirmation or a negation, and (ii) every disjunction of these atomic propositions. In short, she commits to having credences over the whole Boolean algebra <span class="math inline">\(\mathscr{A}_\mathscr{X}\)</span> generated by <span class="math inline">\(\mathscr{X}\)</span>. Since each event of a child coming out is independent, adopting <strong>cred1</strong> will commit her to setting <strong>cred1</strong>(±<span class="math inline">\(C_0 \wedge\)</span>± <span class="math inline">\(C_1 \wedge\)</span>±<span class="math inline">\(C_2 \wedge \ldots \wedge\)</span>±<span class="math inline">\(C_{10}) = \frac{1}{1024}\)</span> when <span class="math inline">\(C_0\)</span> is affirmed, and 0 when it is negated. While adopting <strong>cred2</strong> commits her to setting <strong>cred2</strong>(±<span class="math inline">\(C_0 \wedge\)</span>± <span class="math inline">\(C_1 \wedge\)</span>±<span class="math inline">\(C_2 \wedge \ldots \wedge\)</span>±<span class="math inline">\(C_{10}\)</span>) equal to 1 when <span class="math inline">\(C_0\)</span> is negated and the rest of the <span class="math inline">\(C_i\)</span> are affirmed, and to 0 otherwise. In this way, each of these probability assignments over the 2048 atoms determine a definite probability for every one of the <span class="math inline">\(2^{2048}\)</span> propositions in <span class="math inline">\(\mathscr{A}_\mathscr{X}\)</span>.</p>
<p>It is our view that consequentialists should reject any assessment of epistemic utility that fails to take the accuracies of <em>all</em> these credences into account. All are consequences of adopting <strong>cred1</strong> or <strong>cred2</strong>, and so all should be part of any consequentialist evaluation of the quality of those credal states. The right “target set” to use when computing epistemic disutility is not <span class="math inline">\(\mathscr{X}\)</span> but <span class="math inline">\(\mathscr{A}_\mathscr{X}\)</span>. If we don’t do that, we ignore most of the ways in which <strong>cred1</strong> and <strong>cred2</strong> differ in accuracy. If Emily takes the bribe, she goes from having credence 0.5 in <span class="math inline">\(C_0 \leftrightarrow C_1\)</span> to having credence 0 in it. And that’s unfortunate, because the chance of <span class="math inline">\(C_0 \leftrightarrow C_1\)</span> goes from 0.5 to 1. This is another proposition, as well as <span class="math inline">\(C_0\)</span>, that Emily acquires a false belief in by taking the bribe. Of course, there are other propositions not counted that go the other way. Originally, Emily has a credence of 0.25 in <span class="math inline">\(C_1 \wedge C_2\)</span>, and its chance is also 0.25. After taking the bribe, this has a chance of 1, and her credence in it is 1. That’s an improvement in accuracy. So there are a host of both improvements and deteriorations that are as yet unaccounted for. We should account for them, and making the target set be <span class="math inline">\(\mathscr{A}_\mathscr{X}\)</span> does that.</p>
<p>When seen from this broader perspective, it turns out the seeming superiority of <strong>cred2</strong> over <strong>cred1</strong> evaporates. The rest of this section (and the appendix) is dedicated to demonstrating this. We’ll make the calculations a little easier on ourselves by relying on a theorem concerning Brier scores for coherent agents. Assume, as is the case here, that Emily’s credences are defined over an atomic Boolean alegbra of propositions. The atoms are the ‘worlds’, or states that are maximially specific with respect to the puzzle at hand. In this case there are 2048 states, which we’ll label <span class="math inline">\(s_0\)</span> through <span class="math inline">\(s_{2047}\)</span>. In <span class="math inline">\(s_k\)</span>, the first child is on the lawn iff <span class="math inline">\(k \leq 1023\)</span>, and summerhouse child <span class="math inline">\(i\)</span> comes out iff the (<span class="math inline">\(i\)</span> + 1)th digit in the binary expansion of <span class="math inline">\(k\)</span> is 1. Let <span class="math inline">\(\mathscr{S}_\mathscr{X}\)</span> be the set of all these states. That’s not a terrible target set; as long as Emily is probabilistically coherent it is comprehensive. The theorem in question says that for any credence function <strong>cred</strong> defined over a partition of states <span class="math inline">\(\mathscr{S}\)</span>, and over the algebra <span class="math inline">\(\mathscr{A}\)</span> generated by those states,</p>
<blockquote class="blockquote">
<p><strong>Theorem-1</strong> <span class="math display">\[\mathbf{Brier}_{\mathscr{A}}(\mathbf{cred}, @) = \frac{|\mathscr{S}|}{4}\mathbf{Brier}_{\mathscr{S}}(\mathbf{cred}, @)\]</span></p>
</blockquote>
<p>(The proof of this is in the appendix.) So whichever credence function is more accurate with respect to <span class="math inline">\(\mathscr{S}_{\mathscr{X}}\)</span> will be more accurate with respect to <span class="math inline">\(\mathscr{A}_{\mathscr{X}}\)</span>. So let’s just work out <span class="math inline">\(\mathbf{Brier}_{\mathscr{S}_{\mathscr{X}}}\)</span> for <strong>cred1</strong> and <strong>cred2</strong> at the actual world.</p>
<p>First, <strong>cred1</strong> will appropriately assign credence 0 to each <span class="math inline">\(s_k (k \in {0, ..., 1023})\)</span>. Then it assigns credence <span class="math inline">\(\frac{1}{1024}\)</span> to every other <span class="math inline">\(s_k\)</span>. For 1023 of these, that is off by <span class="math inline">\(\frac{1}{1024}\)</span>, contributing <span class="math inline">\(\frac{1}{2^{20}}\)</span> to the Brier score. And for 1 of them, namely @, it is off by <span class="math inline">\(\frac{1023}{1024}\)</span>, contributing <span class="math inline">\(\frac{1023^2}{2^{20}}\)</span>. So we get: <span class="math display">\[\begin{aligned}
\mathbf{Brier}_{\mathscr{S}_{\mathscr{X}}}(\mathbf{cred1}, @) &amp;= \frac{1}{2048} [1024 \cdot 0 + 1023 \cdot \frac{1}{2^{20}} + \frac{1023^2}{2^{20}}] \\
&amp;= \frac{1}{2048} \cdot \frac{1023 + 1023 ^2}{2^{20}} \\
&amp;= \frac{1}{2048} \cdot \frac{1023 \cdot 1024}{2^{20}} \\
&amp;= \frac{1}{2048} \cdot \frac{1023}{1024} \\
&amp;= \frac{2^{10}-1}{2^{21}}\end{aligned}\]</span> It’s a bit easier to work out <span class="math inline">\(\mathbf{Brier}_{\mathscr{S}_{\mathscr{X}}}(\mathbf{cred2}, s_{2047})\)</span>. (We only need to work out the Brier score for that state, because by the setup of the problem, Emily knows that’s the state she’ll be in if she adopts <strong>cred2</strong>). There are 2048 elements in <span class="math inline">\(\mathscr{S}_{\mathscr{X}}\)</span>. And <strong>cred2</strong> assigns the perfectly accurate credence to 2046 of them, and is perfectly inaccurate on 2, namely <span class="math inline">\(s_{1023}\)</span>, which it assigns credence 1, and <span class="math inline">\(s_{2047}\)</span> which it assigns credence 0. So we have <span class="math display">\[\begin{aligned}
\mathbf{Brier}_{\mathscr{S}_{\mathscr{X}}}(\mathbf{cred2}, s_{2047}) &amp;= \frac{1}{2048} (2046 \cdot 0 + 1 + 1) \\
&amp;= \frac{1}{1024} \\
&amp;= \frac{2^{11}}{2^{21}}\end{aligned}\]</span> In fact, it isn’t even close. If Emily adopts <strong>cred2</strong> she becomes a little more than twice as inaccurate.</p>
<p>It is tedious to calculate <span class="math inline">\(\mathbf{Brier}_{\mathscr{A}_{\mathscr{X}}}(\mathbf{cred1}, @)\)</span> directly, but it is enlightening to work through the calculation of <span class="math inline">\(\mathbf{Brier}_{\mathscr{A}_{\mathscr{X}}}(\mathbf{cred2}, s_{2047})\)</span>. Note that there are two crucial states out of the 2048: <span class="math inline">\(s_{2047}\)</span>, the actual state where all children come out, and state <span class="math inline">\(s_{1023}\)</span> where child 0 does not come out, but the other 10 children all do. There are <span class="math inline">\(2^{2^{11}-2}\)</span> propositions in each of the following four sets:</p>
<ol type="1">
<li><p><span class="math inline">\(\{p: s_{2047} \vDash p\)</span> and <span class="math inline">\(s_{1023} \vDash p\}\)</span></p></li>
<li><p><span class="math inline">\(\{p: s_{2047} \vDash p\)</span> and <span class="math inline">\(s_{1023} \nvDash p\}\)</span></p></li>
<li><p><span class="math inline">\(\{p: s_{2047} \nvDash p\)</span> and <span class="math inline">\(s_{1023} \vDash p\}\)</span></p></li>
<li><p><span class="math inline">\(\{p: s_{2047} \nvDash p\)</span> and <span class="math inline">\(s_{1023} \nvDash p\}\)</span></p></li>
</ol>
<p>If Emily takes the bribe, she will have perfect accuracy with respect to all the propositions in class 1 (which are correctly believed to be true), and all the propositions in class 4 (which are correctly believed to be false). But she will be perfectly inaccurate with respect to all the propositions in class 2 (which are incorrectly believed to be false), and all the propositions in class 3 (which are incorrectly believed to be true). So she is perfectly accurate on half the propositions, and perfectly inaccurate on half of them, so one’s average inaccuracy is <span class="math inline">\(0.5 \cdot 0 + 0.5 \cdot 1 = 0.5\)</span>. And that’s an enormous inaccuracy. It is, in fact, as inaccurate as one can possibly be while maintaining probabilistic coherence.</p>
<blockquote class="blockquote">
<p><strong>Theorem-2</strong>: When inaccuracy over <span class="math inline">\(\mathscr{A}\)</span> is measured using the Brier score, the least accurate credal states are those which assign credence 1 to some false atom of <span class="math inline">\(\mathscr{A}\)</span>.</p>
</blockquote>
<p>(The proof is in the appendix.) So taking the bribe is not a good deal, even by consequentialist lights. And that isn’t too surprising; taking the bribe makes Emily have maximally inaccurate credences on half of the possible propositions about the children.</p>
<p>So far we have followed Greaves in assuming that inaccuracy is measured by the quadratic, or Brier, rule. It turns out that we can drop that assumption. We actually only need some very weak conditions on accuracy rules to get the result that Greaves style bribes are bad deals, though the proof of this becomes a trifle more complicated.</p>
<p>Let <span class="math inline">\(\mathscr{A}\)</span> be an algebra of propositions generated by a partition of <span class="math inline">\(2N\)</span> atoms <span class="math inline">\(a_1, ..., a_{2N}\)</span>. Suppose <span class="math inline">\(a_1\)</span> is the truth, and consider two probability functions, <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> defined in <span class="math inline">\(\mathscr{A}\)</span>. <span class="math inline">\(P\)</span> assigns all its mass to the first <span class="math inline">\(N\)</span> atoms, so that <span class="math inline">\(P(a_k) = 0\)</span> for all <span class="math inline">\(k &gt; N\)</span>. We also assume that <span class="math inline">\(P\)</span> assigns some positive probability to the true atom <span class="math inline">\(a_1\)</span>. <span class="math inline">\(Q\)</span> assigns all its mass to the false atom <span class="math inline">\(a_{2N}\)</span>. Note that this will be a good model of any case where an agent is offered a bribe of the form: drop the positive confidence you have in proposition <span class="math inline">\(p_0\)</span>, instead assign it credence 0, and you’ll be guaranteed a maximally accurate credence in <span class="math inline">\(j\)</span> other logically independent propositions <span class="math inline">\(p_1, ..., p_j\)</span>. The only other assumptions needed to get the model to work are that <span class="math inline">\(p_0\)</span> is actually true, and <span class="math inline">\(N = 2^j\)</span>.</p>
<p>Imagine that the accuracy of a probability function <span class="math inline">\(\pi\)</span> over <span class="math inline">\(\mathscr{A}\)</span> is measured by a proper scoring rule of the form</p>
<p><span class="math display">\[\mathbf{I}(a_n, \pi) = 2^{-2N}\sum_{X \in \mathscr{A}} \mathbf{i}(v_n(X), \pi(X))\]</span> where <span class="math inline">\(v_n(X)\)</span> is <span class="math inline">\(X\)</span>s truth value when <span class="math inline">\(a_n\)</span> is the true atom, and <strong>i</strong> is a score that gives the accuracy of <span class="math inline">\(\pi(X)\)</span> in the event that <span class="math inline">\(X\)</span>s truth value is <span class="math inline">\(v_n(X)\)</span>. We shall assume that this score has the following properties.</p>
<dl>
<dt>Truth Directedness</dt>
<dd>
<p>The value of <span class="math inline">\(\mathbf{i}(1, p)\)</span> decreases monotonically as <span class="math inline">\(p\)</span> increases. The value of <span class="math inline">\(\mathbf{i}(0, p)\)</span> increases monotonically as <span class="math inline">\(p\)</span> decreases.</p>
</dd>
<dt>Extensionality</dt>
<dd>
<p><span class="math inline">\(\mathbf{i}(v_n(X), \pi(X))\)</span> is a function only of the truth-value and the probability; the identity of the proposition does not matter.</p>
</dd>
<dt>Negation Symmetry</dt>
<dd>
<p><span class="math inline">\(\mathbf{i}(v_n(\neg X), \pi(\neg X)) = \mathbf{i}(v_n(X), \pi(X))\)</span> for all <span class="math inline">\(x, n, \pi\)</span>.</p>
</dd>
</dl>
<blockquote class="blockquote">
<p><strong>Theorem-3</strong>: Given these assumptions, <span class="math inline">\(P\)</span>’s accuracy strictly exceeds <span class="math inline">\(Q\)</span>’s.</p>
</blockquote>
<p>Again, the proof is in the appendix.</p>
<p>Theorem-3 ensures that taking the deal that Greaves offers in Imps will reduce Emily’s accuracy relative to any proper scoring rule satisfying Truth Directedness, Extensionality and Negation Symmetry. To see why, think of Emily’s credences as being defined over an algebra generated by the atoms ±<span class="math inline">\(C_0 \wedge\)</span>± <span class="math inline">\(C_1 \wedge\)</span>±<span class="math inline">\(C_2 \wedge \ldots \wedge\)</span>±<span class="math inline">\(C_{10}\)</span>, where it is understood that some <span class="math inline">\(C_0\)</span> atom is true and all the <span class="math inline">\(\neg C_0\)</span> atoms are false. Since Emily is convinced of <span class="math inline">\(C_0\)</span> and believes that every other <span class="math inline">\(C_n\)</span> has some chance of occurring, and since the various <span class="math inline">\(C_n\)</span> are independent of one another, her credence function <strong>cred1</strong> will assigns a positive probability to each <span class="math inline">\(C_0\)</span> atom, including the true atom (whichever that might be). Now, let <span class="math inline">\(Q\)</span> be a credence function that places all its weight on some false atom <span class="math inline">\(\neg C_0 \wedge\)</span>± <span class="math inline">\(C_1 \wedge\)</span>±<span class="math inline">\(C_2 \wedge \ldots \wedge\)</span>±<span class="math inline">\(C_{10}\)</span>. Theorem-3 tells us that Emily’s <strong>cred1</strong> is more accurate than <span class="math inline">\(Q\)</span>, and that this is true no matter which <span class="math inline">\(C_0\)</span> atom is true or which <span class="math inline">\(\neg C_0\)</span> atom <span class="math inline">\(Q\)</span> regards as certain. By taking the bribe Emily will guarantee the truth of <span class="math inline">\(C_0 \wedge C_1 \wedge \dots \wedge C_{10}\)</span>, but the cost will be that she must adopt the <strong>cred2</strong> credences, which assign probability one to the false atom <span class="math inline">\(\neg C_0 \wedge C_1 \wedge \dots \wedge C_{10}\)</span>. Extensionality ensures that any two credence functions that assign probability one to a false atom will have the same inaccuracy score, and that this score will not depend on which atom happens to be the true one. The upshot is that <strong>cred2</strong> will have the same inaccuracy when Emily accepts the bribe as <span class="math inline">\(Q\)</span> does when she rejects it. Thus, since <strong>cred1</strong> is more accurate than <span class="math inline">\(Q\)</span>, it is also more accurate than <strong>cred2</strong>, which means that Emily should reject the bribe in order to promote credal accuracy.</p>
<p>We do not want to oversell this conclusion. Strictly speaking, we have only shown that consequentialists should reject epistemic bribes when doing so requires them to go from being confident in a truth to being certain of some maximally specific falsehood. This is a rather special situation, and there are nearby cases to which our results do not apply, and in which consequentialists may sanction bribe-taking. For example, if Emily only has to cut her credence for <span class="math inline">\(C_0\)</span> in half, say from <span class="math inline">\(\frac{1}{2}\)</span> to <span class="math inline">\(\frac{1}{4}\)</span>, to secure knowledge of <span class="math inline">\(C_1 \wedge \dots \wedge C_{10}\)</span>, then Theorem-3 offers us no useful advice. Indeed, depending on the scoring rule and the nature of the bribe, we suspect that believers will often be able to improve accuracy by changing their credences in ways not supported by their evidence, especially when these changes affect the truth-values of believed propositions. The only thing we insist upon is that, in all such cases, credal accuracy should be measured over all relevant propositions, not just over a select salient few. But that’s something that is independently plausible. Perhaps it might be pragmatically justified to become more accurate on salient propositions at the expense of becoming very inaccurate over hard to state compounds of those propositions, but it is never epistemically justified.</p>
</section>
<section id="fourcaveats" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Four Caveats</h1>
<section id="greavessargumentmayworkagainstsomeformsofconsequentialism" class="level3" data-number="2.0.1">
<h3 data-number="2.0.1" class="anchored" data-anchor-id="greavessargumentmayworkagainstsomeformsofconsequentialism"><span class="header-section-number">2.0.1</span> Greaves’s Imps Argument May Work Against Some Forms of Consequentialism</h3>
<p>We said above that no consequentialist should accept Greaves’s setup of the Imps puzzle, since they should not accept an inaccuracy measure that ignores some kind of introduced inaccuracy. That means that, for all we have said, Greaves’s argument works against those consequentialists who do not agree with us over the suitability of target sets that are neither algebras or partitions. And, at least outside philosophy, some theorists do seem to disagree with us.</p>
<p>For instance, it is common in meteorology to find theorists who measure the accuracy of rain forecasts over an <span class="math inline">\(n\)</span> day period by just looking at the square of the distance between the probability of rain and the truth about rain on each day. To pick an example almost literally at random, Mark <span class="citation" data-cites="Roulston2007">Roulston (<a href="#ref-Roulston2007" role="doc-biblioref">2007</a>)</span> defends the use of the Brier score, calculated just this way, as a measure of forecast accuracy. So Greaves’s target, while not including all consequentialists, does include many real theorists.</p>
<p>That said, it seems there are more mundane reasons to not like this approach to measuring the accuracy of weather forecasts. Consider this simple case. Ankita and Bojan are issuing forecasts for the week that include probabilities of rain. They each think that there is a 0% chance of rain most days. But Ankita thinks there will be one short storm come through during the week, while Bojan issues a 0% chance of rain forecast for each day. Ankita thinks the storm is 75% likely to come on Wednesday, so there’s a 75% chance of rain that day, and 25% likely to come Thursday, so there’s a 25% chance of rain that day.</p>
<p>As it happens, the storm comes on Thursday. So over the course of the week, Bojan’s forecast is more accurate than Ankita’s. Bojan is perfectly accurate on 6 days, and off by 1 on Thursday. Ankita is perfectly accurate on 5 days, and gets an inaccuracy score of <span class="math inline">\(0.75^2 = 0.5625\)</span> on Wednesday and Thursday, which adds up to more than Bojan’s inaccuracy. But this feels wrong. There is a crucial question that Ankita was right about and Bojan was wrong about, namely will there be a storm in the middle of the week. Ankita’s forecast only looks less accurate because we aren’t measuring accuracy with respect to this question. So even when we aren’t concerned with magical cases like Greaves’s, there is a good reason to measure accuracy comprehensively, i.e., with respect to an algebra or a partition.</p>
</section>
<section id="separatenessofpropositions" class="level3" data-number="2.0.2">
<h3 data-number="2.0.2" class="anchored" data-anchor-id="separatenessofpropositions"><span class="header-section-number">2.0.2</span> Separateness of Propositions</h3>
<p>There is a stronger version of the intuition behind the Imps case that we simply reject. The intuition is well expressed by Selim <span class="citation" data-cites="Berker2013b">Berker (<a href="#ref-Berker2013b" role="doc-biblioref">2013a, 365</a>, emphasis in original)</span></p>
<blockquote class="blockquote">
<p>The more general point is this: when determining the epistemic status of a belief in a given proposition, it is epistemically irrelevant whether or not that belief conduces (either directly or indirectly) toward the promotion of true belief and the avoidance of false belief in <em>other</em> propositions beyond the one in question.</p>
</blockquote>
<p>Let’s put that to the test by developing the Ankita and Bojan story a little further. They have decided to include, in the next week’s forecast, a judgment on the credibility of rain. Bojan thinks the evidence is rather patchy. And he has been reading Glenn <span class="citation" data-cites="Shafer1976">Shafer (<a href="#ref-Shafer1976" role="doc-biblioref">1976</a>)</span>, and thinks that when the evidence is patchy, credences in propositions and their negations need not add to 1. So if <span class="math inline">\(p\)</span> is the proposition <em>It will rain next week</em>, Bojan has a credence of 0.4 in both <span class="math inline">\(p\)</span> and <span class="math inline">\(\neg p\)</span>.</p>
<p>Ankita thinks that’s crazy, and suggests that there must be something deeply wrong with the Shafer-based theory that Bojan is using. But Bojan is able to easily show that the common arguments against Shafer’s theory are blatantly question begging &nbsp;<span class="citation" data-cites="Maher1997 Weatherson1999">(<a href="#ref-Maher1997" role="doc-biblioref">Maher 1997</a>; <a href="#ref-Weatherson1999" role="doc-biblioref">Weatherson 1999</a>)</span>. So Ankita tries a new tack. She has been reading <span class="citation" data-cites="Joyce1998">Joyce (<a href="#ref-Joyce1998" role="doc-biblioref">1998</a>)</span>, from which she got the following idea. She argues that Bojan will be better off from the point of view of accuracy in having credence 0.5 in each of <span class="math inline">\(p\)</span> and <span class="math inline">\(\neg p\)</span> than in having credence 0.4 in each. As it stands, one of Bojan’s credences will be off by 0.4, and the other by 0.6, for a Brier score of <span class="math inline">\((0.4^2 + 0.6^2)/2 = 0.26\)</span>, whereas switching would give him a Brier score of <span class="math inline">\((0.5^2 + 0.5^2)/2 = 0.25\)</span>.</p>
<p>But Bojan resists. He offers two arguments in reply.</p>
<p>First, he says, for all Ankita knows, one of his credences might be best responsive to the evidence. And it is wrong, always and everywhere, to change a credence away from one that is best supported by the evidence in order to facilitate an improvement in global accuracy. That, says Bojan, is a violation of the “separateness of propositions” &nbsp;<span class="citation" data-cites="Berker2013b">(<a href="#ref-Berker2013b" role="doc-biblioref">Berker 2013a</a>)</span>.</p>
<p>Second, he says, even by Ankita’s accuracy-based lights, this is a bad idea. After all, he will be making one of his credences less accurate in order to make an improvement in global accuracy. And that’s again a violation of the separateness of propositions. It’s true that he won’t be making himself more inaccurate in one respect so as to secure accuracy in another, as in the bribes case. But he will be following advice that is motivated by the aim of becoming, in total, more accurate, at the expense of accuracy for some beliefs.</p>
<p>We want to make two points in response. First, if the general point that Berker offers is correct, then these are perfectly sound replies by Bojan. Although Bojan is not literally in a bribe case, like Emily, he is being advised to change some credences because the change will make his overall credal state better, even if it makes it locally worse in one place. It does not seem to matter whether he can identify which credence gets made worse. Berker argues that the trade offs that epistemic consequentialism makes the same mistake ethical consequentialism makes; it authorises inappropriate trade-offs. But in the ethical case, it doesn’t matter whether the agent can identify who is harmed by the trade-off. If it is wrong to harm an identifiable person for the greater good, it is wrong to harm whoever satisfies some description in order to produce the greater good.</p>
<p>So if the analogy with anti-consequentialism in ethics goes through, Bojan is justified in rejecting Ankita’s advice. After all there is, according to Berker, a rule against making oneself doxastically worse in one spot for the gain of an overall improvement. And that’s what Bojan would do if he took Ankita’s advice. But, we say, Bojan is not justified in rejecting Ankita’s advice. In fact, Ankita’s advice is sound advice, and Bojan would do well to take it. So Berker’s general point is wrong.</p>
<p>Our second point is a little more contentious. We suspect that if Bojan has a good reason to resist this move of Ankita’s, he has good reason to resist all attacks on his Shafer-based position. So if Berker’s general point is right, it means there is nothing wrong with Bojan’s anti-probabilist position. Now we haven’t argued for this; to do so would require going through all the arguments for probabilism and seeing whether they can be made consistent with Berker’s general point. But our suspicion is that none of them can be, since they are all arguments that turn on undesirable properties of global features of non-probabilistic credal states. So if Berker is right, probabilism is wrong, and we think it is not wrong.</p>
</section>
<section id="isthisconsequentialism" class="level3" data-number="2.0.3">
<h3 data-number="2.0.3" class="anchored" data-anchor-id="isthisconsequentialism"><span class="header-section-number">2.0.3</span> Is this Consequentialism?</h3>
<p>So far we’ve acquiesed with the general idea that Greaves’s and Berker’s target should be called <em>consequentialism</em>. But there are reasons to be unhappy with this label. In general, a consequentialist theory allows agents to make things worse in the here and now, in return for future gains. A consequentialist about prudential decision making, in the sense of <span class="citation" data-cites="Hammond1988">Hammond (<a href="#ref-Hammond1988" role="doc-biblioref">1988</a>)</span>, will recommend exercise and medicine taking. And they won’t be moved by the fact that the exercise hurts and the medicine is foul-tasting. It is worth sacrificing the welfare of the present self for the greater welfare of later selves.</p>
<p>Nothing like that is endorsed, as far as we can tell, by any of the existing ‘epistemic consequentialists’. Certainly the argument that Ankita offers Bojan does not rely on this kind of reasoning. In particular, epistemic consequentialists do not say that it is better to make oneself doxastically worse off now in exchange for greater goods later. Something like that deal is offered to the reader of <span class="citation" data-cites="DescartesMeditations">Descartes (<a href="#ref-DescartesMeditations" role="doc-biblioref">1641/1996</a>)</span>, but it isn’t as popular nowadays.</p>
<p>Rather, the rule that is endorsed is <em>Right now, have the credences that best track the truth!</em> This isn’t clearly a form of consequentialism, since it really doesn’t care about the <em>consequences</em> of one’s beliefs. It does say that it is fine to make parts of one’s doxastic state worse in order to make the whole better. That’s what would happen if Bojan accepted Ankita’s advice. But that’s very different from doing painful exercise, or drinking unpleasant medicine. (Or, for that matter, to withdrawing belief in any number of truths.)</p>
<p>When Greaves tries to flesh out epistemic consequentialism, she compares it to evidential and causal versions of prudential decision theory. But it seems like the right comparison might be to something we could call <em>constitutive</em> decision theory. The core rule, remember, is that agents should form credences that constitute being maximally accurate, not that cause them to be maximally accurate.</p>
<p>The key point here is not the terminological one about who should be called consequentialist. Rather, it is that the distinction between causation and constitution is very significant here, and comparing epistemic utility theory to prudential utility theory can easily cause it to be lost. Put another way, we have no interest in defending someone who wants to defend a causal version of epistemic utility theory, and hence thinks it could be epistemically rational to be deliberately inaccurate now in order to be much more accurate tomorrow. We do want to defend the view that overall accuracy right now is a prime epistemic goal.</p>
</section>
<section id="otherbribes" class="level3" data-number="2.0.4">
<h3 data-number="2.0.4" class="anchored" data-anchor-id="otherbribes"><span class="header-section-number">2.0.4</span> Other Bribes</h3>
<p>As already noted, we have not offered a general purpose response to bribery based objections to epistemic consequentialism. All we’ve shown is that some popular examples of this form of objection misfire, because they offer bribes that are bad by the consequentialists’ own lights. But there could be bribes that are immune to our objection.</p>
<p>For example, imagine that Ankita has, right now, with credence 0.9 in <span class="math inline">\(D_0\)</span>, and 0.5 in <span class="math inline">\(D_1\)</span>. These are good credences to have, since she knows those are the chances of <span class="math inline">\(D_0\)</span> and <span class="math inline">\(D_1\)</span>. She’s then offered an epistemic bribe. If she changes her credence in <span class="math inline">\(D_0\)</span> to 0.91, the chance of <span class="math inline">\(D_1\)</span> will become 1, and she can have credence 1 in <span class="math inline">\(D_1\)</span>. Taking this bribe will increase her accuracy.</p>
<p>We could imagine the anti-consequentialist arguing as follows.</p>
<ol type="1">
<li><p>If epistemic consequentialism is true, Ankita is epistemically justified in accepting this bribe.</p></li>
<li><p>Ankita is not epistemically justified in accepting this bribe.</p></li>
<li><p>So, epistemic consequentialism is not true.</p></li>
</ol>
<p>We’re not going to offer a reply to this argument here; that is a task for a much longer paper. There are some reasons to resist premise one. It isn’t clear that it is conceptually possible to accept the bribe. (It really isn’t clear that it is practically possible, but we’re not sure whether that’s a good reply on the part of the consequentialist.) And it isn’t clear that the argument for premise one properly respects the distinction between causation and constitution we described in the last section.</p>
<p>Even if those arguments fail, the intuitive force of premise two is not as strong as the intuition behind Greaves’s, or Berker’s, anti-bribery intuitions. And that’s one of the main upshots of this paper. It’s commonly thought that for the consequentialist, in any field, everything has its price. The result we proved at the end of section one shows this isn’t true. It turns out that no good epistemic consequentialist should accept a bribe that leads them to believing an atomic proposition they have conclusive evidence is false, no matter how strong the inducements. Maybe one day there will be a convincing bribery based case that epistemic consequentialism is unacceptably corrupting of the epistemic soul. But that case hasn’t been made yet, because we’ve shown a limit on how corrupt the consequentialist can be.</p>
</section>
</section>
<section id="appendix-proofs-of-theorems-1-2-3" class="level1 unnumbered page-columns page-full">
<h1 class="unnumbered">Appendix: Proofs of Theorems 1, 2, 3</h1>
<blockquote class="blockquote">
<p><strong>Theorem-1</strong>: Brier<span class="math inline">\(_{\mathscr{A}}(\mathbf{c},@) = \frac{N}{4}\text{Brier}_{\mathscr{S}}(\mathbf{c},@)\)</span> where <span class="math display">\[\begin{aligned}
\text{Brier}_{\mathscr{S}}(\mathbf{c},@) &amp;= \frac{\sum_{s \in \mathscr{S}} (@(s) - c(s))^2}{N}\end{aligned}\]</span></p>
</blockquote>
<p>To prove this we rely on a series of lemmas.</p>
<aside>
Alejandro Pérez Carballo gives a more direct and elegant proof of this result in a recent manuscript. We have kept our inefficient proof since its structure provides a guide for the proof of Theorem-3.
</aside>
<p>Let <span class="math inline">\(\mathscr{A}\)</span> be the algebra generated by a finite partition of states <span class="math inline">\(\mathscr{S}= \{s_1, s_2, \dots, s_N\}\)</span>. @ is a truth-value assignment for propositions in <span class="math inline">\(\mathscr{A}\)</span>. For simplicity, assume <span class="math inline">\(s_1\)</span> is the true state, so that @(<span class="math inline">\(s_1\)</span>) = 1 and @(<span class="math inline">\(s_n\)</span>) = 0 for <span class="math inline">\(n &gt; 1\)</span>. The credence function <strong>c</strong> assigns values of <span class="math inline">\(c_1, c_2, \dots, c_{N-1}, c_N\)</span> to the elements of <span class="math inline">\(\mathscr{S}\)</span>, where <span class="math inline">\(\sum^{N}_{n=1} c_n = 1\)</span> in virtue of coherence.</p>
<p>It will be convenient to start by partitioning <span class="math inline">\(\mathscr{A}\)</span> into four “quadrants”. Let <span class="math inline">\(B\)</span> range over all disjunctions with disjunctions drawn from <span class="math inline">\(\mathscr{B}= \{s_2, s_3, \dots, s_{N-1}\}\)</span> (including the empty disjunction, i.e., the logical contradition <span class="math inline">\(\bot\)</span>). Then, <span class="math inline">\(\mathscr{A}\)</span> can be split into four disjoint parts:</p>
<p><span class="math inline">\(\mathscr{A}_1 = \{B \vee s_1 \vee s_N: B\)</span> a disjunction of the elements of <span class="math inline">\(\mathscr{B}\}\)</span></p>
<p><span class="math inline">\(\mathscr{A}_2 = \{B \vee s_1: B\)</span> a disjunction of the elements of <span class="math inline">\(\mathscr{B}\}\)</span></p>
<p><span class="math inline">\(\mathscr{A}_3 = \{B \vee s_N: B\)</span> a disjunction of the elements of <span class="math inline">\(\mathscr{B}\}\)</span></p>
<p><span class="math inline">\(\mathscr{A}_4 = \{B: B\)</span> a disjunction of the elements of <span class="math inline">\(\mathscr{B}\}\)</span></p>
<p>Notice that:</p>
<p><span class="math inline">\(\mathscr{A}_1 \cup \mathscr{A}_2\)</span> contains all and only the true propositions in <span class="math inline">\(\mathscr{A}\)</span>.</p>
<p><span class="math inline">\(\mathscr{A}_3 \cup \mathscr{A}_4\)</span> contains all and only the false propositions in <span class="math inline">\(\mathscr{A}\)</span>.</p>
<p><span class="math inline">\(\mathscr{A}_1\)</span> and <span class="math inline">\(\mathscr{A}_4\)</span> are <em>complementary</em> sets, i.e., all elements of <span class="math inline">\(\mathscr{A}_4\)</span> are negations of elements of <span class="math inline">\(\mathscr{A}_1\)</span>, and conversely.</p>
<p><span class="math inline">\(\mathscr{A}_2\)</span> and <span class="math inline">\(\mathscr{A}_3\)</span> are also complementary.</p>
<p><span class="math inline">\(\mathscr{A}_1 \cup \mathscr{A}_4\)</span> is the subalgebra of <span class="math inline">\(\mathscr{A}\)</span> generated by <span class="math inline">\(\{s_1 \vee s_N, s_2, s_3, \dots, s_{N-1}\}\)</span>.</p>
<p>All four quadrants have the same cardinality of <span class="math inline">\(2^{N-2}\)</span>.</p>
<p>For an additive scoring rule <span class="math inline">\(\mathbf{I}(\mathbf{c}, @) = \sum_{A \in \mathscr{A}}\mathbf{i}(\mathbf{c}(A), @(A))\)</span> and <span class="math inline">\(j = 1, 2, 3, 4\)</span>, define <span class="math inline">\(\mathbf{I}_j = \sum_{A \in \mathscr{A}_j}\mathbf{i}(\mathbf{c}(A), @(A))\)</span>, and note that <span class="math inline">\(\mathbf{I}(\mathbf{c}, @) = 2^{-N}(\mathbf{I}_1 + \mathbf{I}_2 + \mathbf{I}_3 + \mathbf{I}_4)\)</span>.</p>
<blockquote class="blockquote">
<p><strong>Lemma-1.1</strong>: If <span class="math inline">\(\textbf{I}\)</span> is negation symmetric, i.e., if <span class="math inline">\(\mathbf{i}(\mathbf{c}(\neg A), @(\neg A)) = \mathbf{i}(\mathbf{c}(A), @(A))\)</span> for all <span class="math inline">\(A\)</span>, then <span class="math inline">\(\mathbf{I}_1 = \mathbf{I}_4\)</span> and <span class="math inline">\(\mathbf{I}_2 = \mathbf{I}_3\)</span>, and <span class="math inline">\(\mathbf{I}(\mathbf{c},@) = 2^{1-N}(\mathbf{I}_2 + \mathbf{I}_4)\)</span>.</p>
</blockquote>
<p><strong>Proof</strong>: This is a direct consequence of the fact that <span class="math inline">\(\mathscr{A}_1\)</span> is complementary to <span class="math inline">\(\mathscr{A}_4\)</span> and that <span class="math inline">\(\mathscr{A}_2\)</span> is complementary to <span class="math inline">\(\mathscr{A}_3\)</span> since this allows us to write</p>
<p><span class="math display">\[\begin{aligned}
\mathbf{I}_1(\mathbf{c},@) &amp;= \sum_{A \in \mathscr{A}_1} \mathbf{i}(\mathbf{c}(A), @(A)) = \sum_{A \in \mathscr{A}_1} \mathbf{i}(\mathbf{c}(\neg A), @(\neg A)) = \mathbf{I}_4(\mathbf{c},@). \\
\mathbf{I}_3(\mathbf{c},@) &amp;= \sum_{A \in \mathscr{A}_3} \mathbf{i}(\mathbf{c}(A), @(A)) = \sum_{A \in \mathscr{A}_3} \mathbf{i}(\mathbf{c}(\neg A), @(\neg A)) = \mathbf{I}_2(\mathbf{c},@). \text{ QED}\\\end{aligned}\]</span> Applying Lemma 1.1 with <strong>I</strong> = <strong>Brier</strong> we get</p>
<p><span class="math display">\[\begin{aligned}
(\#)\quad \mathbf{Brier}_{\mathscr{A}}(\mathbf{c}, @) &amp;= 2^{1-N} \sum_{A \in \mathscr{A}} (@(A) - c(A))^2 \\
&amp;= 2^{1-N} \sum_B [(1-c_1)^2 - 2(1-c_1)\mathbf{c}(B) + \mathbf{c}(B)^2]\end{aligned}\]</span> since</p>
<p><span class="math display">\[\begin{aligned}
\mathbf{Brier}_2 &amp;= \sum_B[1 - \mathbf{c}(B \vee s_1)]^2 &amp;&amp;= \sum_B[(1 - c_1) - \mathbf{c}(B)]^2 \\
&amp; &amp;&amp;= \sum_B [(1-c_1)^2 - 2(1-c_1)\mathbf{c}(B) + \mathbf{c}(B)^2] \\
\mathbf{Brier}_4 &amp;= \sum_B \mathbf{c}(B)^2 &amp;&amp; \quad\end{aligned}\]</span></p>
<blockquote class="blockquote">
<p><strong>Lemma-1.2</strong> <span class="math display">\[\begin{aligned}
(\sum_{n=2}^{N-1} c_n)^2 &amp;= \sum_{n=2}^{N-1} c{_n}^2 + 2 \sum_{n=2}^{N-2} \sum_{j&gt;n}^{N-1}c_nc_j\end{aligned}\]</span></p>
</blockquote>
<p>Proof by induction. Easy.</p>
<blockquote class="blockquote">
<p><strong>Lemma-1.3</strong> <span class="math display">\[\begin{aligned}
\mathbf{Brier}_{\mathscr{S}}(\mathbf{c},@) &amp;= \frac{2}{N}[(1-c_1)^2 + \sum_{n=2}^{N-1} c{_n}^2  - (1-c_1)(\sum_{n=2}^{N-1}c_n) + \sum_{n=2}^{N-2} \sum_{j&gt;n}^{N-1}c_nc_j]\end{aligned}\]</span></p>
</blockquote>
<p><strong>Proof</strong>: Using the definition of the Brier score and the fact that <span class="math inline">\(s_1\)</span> is true, we have</p>
<p><span class="math display">\[\begin{aligned}
\mathbf{Brier}_{\mathscr{S}}(\mathbf{c},@) &amp;= \frac{1}{N}[(1 - c_1)^2 + \sum_{n=2}^{N-1} c{_n}^2 + (1 - \sum_{n=1}^{N-1}c_n)^2] \\
&amp;= \frac{1}{N}[(1 - c_1)^2 + \sum_{n=2}^{N-1} c{_n}^2 + ((1 -c_1) - \sum_{n=2}^{N-1}c_n)^2] \\
&amp;= \frac{1}{N}[(1 - c_1)^2 + \sum_{n=2}^{N-1} c{_n}^2 + (1 -c_1)^2 - 2(1 - c_1) \sum_{n=2}^{N-1}c_n + (\sum_{n=2}^{N-1}c_n)^2] \\
&amp;= \frac{1}{N}[(1 - c_1)^2 + \sum_{n=2}^{N-1} c{_n}^2 + (1 -c_1)^2 - 2(1 - c_1) \sum_{n=2}^{N-1}c_n  \\
&amp;\quad \quad +\sum_{n=2}^{N-1} c{_n}^2 + 2 \sum_{n=2}^{N-2} \sum_{j&gt;n}^{N-1}c_nc_j] \quad \text{(Lemma-1.2)}\end{aligned}\]</span> Then grouping like terms and factoring out 2 yields the desired result. QED</p>
<blockquote class="blockquote">
<p><strong>Lemma-1.4</strong> <span class="math display">\[\begin{aligned}
\sum_{n=2}^{N-1}c_n &amp;= 2^{3-N}\sum_{B \in \mathscr{B}}\mathbf{c}(B)\end{aligned}\]</span></p>
</blockquote>
<p><strong>Proof</strong>: For each <span class="math inline">\(n = 2, 3, \dots, N-1\)</span>, each <span class="math inline">\(s_n\)</span> appears in half of the <span class="math inline">\(2^{N-2}\)</span> disjunctions with disjuncts drawn from <span class="math inline">\(\mathscr{B}\)</span>. As a result, each <span class="math inline">\(c_n\)</span> appears as a summand <span class="math inline">\(2^{N-3}\)</span> times among the sums that express the various <span class="math inline">\(\mathbf{c}(B)\)</span>. So <span class="math inline">\(\sum_{B \in \mathscr{B}}\mathbf{c}(B) = 2^{N-3}\sum_{n=2}^{N-1}c_n\)</span>. QED</p>
<blockquote class="blockquote">
<p><strong>Lemma-1.5</strong> <span class="math display">\[\begin{aligned}
\sum_{B \in \mathscr{B}}\mathbf{c}(B)^2 &amp;= 2^{N-3}[\sum_{n=2}^{N-1} c{_n}^2 + \sum_{n=2}^{N-2} \sum_{j&gt;n}^{N-1}c_nc_j]\end{aligned}\]</span></p>
</blockquote>
<p><strong>Proof</strong>: We proceed by induction starting with the first meaningful case of <span class="math inline">\(N=4\)</span>, where calculation shows <span class="math inline">\(\sum_B\mathbf{c}(B)^2 = (c_2 + c_3)^2 + c{_2}^2 + c{_3}^2 = 2[c{_2}^2 + c{_3}^2 + c_2c_3]\)</span>. Now, assume the identity holds for disjunctions <span class="math inline">\(B\)</span> of elements of <span class="math inline">\(\mathscr{B}\)</span> and show that it holds for disjunctions <span class="math inline">\(A\)</span> of elements of <span class="math inline">\(\mathscr{B}\cup \{s_N\}\)</span>.</p>
<p><span class="math display">\[\begin{aligned}
\sum_A\mathbf{c}(A)^2 &amp;= \sum_B\mathbf{c}(B)^2 + \sum_B\mathbf{c}(B \vee s_N)^2 \\
&amp;= \sum_B\mathbf{c}(B)^2 + \sum_B(\mathbf{c}(B)^2 + 2c_N\mathbf{c}(B) + c{_N}^2)\\
&amp;= 2\sum_B\mathbf{c}(B)^2 + 2c_N\sum_B\mathbf{c}(B) + \sum_Bc{_N}^2 \\
&amp;= 2 \cdot 2^{N-3}[\sum_{n=2}^{N-1} c{_n}^2 + \sum_{n=2}^{N-2} \sum_{j&gt;n}^{N-1}c_nc_j] + 2c_N\sum_B\mathbf{c}(B) + \sum_Bc{_N}^2 &amp;&amp;\text{(Induction Hypothesis)}\\
&amp;= 2^{N-2}[\sum_{n=2}^{N-1} c{_n}^2 + \sum_{n=2}^{N-2} \sum_{j&gt;n}^{N-1}c_nc_j] + 2^{N-2}c_N\sum_{n=2}^{N-1}c_n + \sum_Bc{_N}^2 &amp;&amp;\text{(Lemma-1.4)} \\
&amp;= 2^{N-2}[\sum_{n=2}^{N-1} c{_n}^2 + \sum_{n=2}^{N-2} \sum_{j&gt;n}^{N-1}c_nc_j] + 2^{N-2}c_N\sum_{n=2}^{N-1}c_n + 2^{N-2}c{_N}^2 &amp;&amp;\text{Since $|\mathscr{B}| = 2^{N-2}$} \\
&amp;= 2^{N-2}[\sum_{n=2}^{N} c{_n}^2 + \sum_{n=2}^{N-1} \sum_{j&gt;n}^{N}c_nc_j] &amp;&amp; \text{ QED}\end{aligned}\]</span> Plugging the results of the last two lemmas into Lemma-1.3 produces a result of</p>
<p><span class="math display">\[\begin{aligned}
\mathbf{Brier}_{\mathscr{S}}(\textbf{c},@) &amp;= \frac{2}{N}[(1-c_1)^2 + 2^{3-N}\sum_{B \in \mathscr{B}}\mathbf{c}(B)^2 - 2^{3-N}(1-c_1)\sum_{B \in \mathscr{B}}\mathbf{c}(B)] \\
&amp;= \frac{2}{N}\sum_{B \in \mathscr{B}}[2^{2-N}(1-c_1)^2 + 2^{3-N}\mathbf{c}(B)^2 - 2^{3-N}(1-c_1)\mathbf{c}(B)] \\
&amp;= \frac{2^{3-N}}{N}\sum_{B \in \mathscr{B}}[(1 - c_1)^2 + 2\mathbf{c}(B)^2 - 2(1-c_1)\mathbf{c}(B)]\end{aligned}\]</span> Comparing this to (#) we see that it is just <span class="math inline">\(\frac{N}{4}\)</span> times Brier<span class="math inline">\(_\mathscr{S}(\mathbf{c},@)\)</span>, as we aimed to prove. QED.</p>
<blockquote class="blockquote">
<p><strong>Theorem-2</strong>. When inaccuracy over <span class="math inline">\(\mathscr{A}\)</span> is measured using the Brier score, the least accurate credal states are those which assign credence 1 to some false atom of <span class="math inline">\(\mathscr{A}\)</span>.</p>
</blockquote>
<p><strong>Proof</strong>: As before, suppose that <span class="math inline">\(@(s_1) = 1\)</span>, and let <strong>c</strong> be a credence function that assigns credence 1 to some false atom <span class="math inline">\(s_2, s_3,..., s_N\)</span> of <span class="math inline">\(\mathscr{A}\)</span>. In light of Theorem-1 it suffices to show that <span class="math inline">\(\mathbf{Brier}_\mathscr{S}(\mathbf{c}, @) &gt; \mathbf{Brier}_\mathscr{S}(\mathbf{b}, @)\)</span> where <strong>b</strong> does not assign credence 1 to any false atom. Start by noting that for any credence function <span class="math inline">\(\pi\)</span> defined on the atoms of <span class="math inline">\(\mathscr{A}\)</span> one has</p>
<p><span class="math display">\[\begin{aligned}
\mathbf{Brier}_\mathscr{S}(\pi,@) &amp;= \frac{1}{N}[(1-\pi_1)^2 + \sum_{n=2}^{N-1}\pi{_n}^2+ (1-\sum_{n=1}^{N-1}\pi{_n})^2] \\
&amp;= \frac{1}{N}[1 - 2\pi_1 + \sum_{n=1}^{N-1}\pi{_n}^2+ (1-\sum_{n=1}^{N-1}\pi{_n})^2]\end{aligned}\]</span></p>
<p>But, since each <span class="math inline">\(\pi_n \in [0, 1]\)</span> is non-negative, it follows that <span class="math inline">\(\pi_1 \geq \pi{_1}^2, \pi_2 \geq \pi{_2}^2, \dots, \pi_N \geq \pi{_N}^2\)</span> with the inequality strict in each case unless <span class="math inline">\(\pi_n\)</span> is either 1 or 0.</p>
<p>This means that the sum <span class="math inline">\(\sum_{n=1}^{N-1}\pi{_n}^2+ (1-\sum_{n=1}^{N-1}\pi{_n})^2\)</span> is less than or equal to 1, with equality if and only if exactly one of the atoms <span class="math inline">\(s_n\)</span> is assigned probability 1 (and the rest have probability zero). As a result, <strong>Brier</strong><span class="math inline">\(_\mathscr{S}(\pi, @) \leq \frac{2}{N}(1 - \pi_1)\)</span> with equality if and only if exactly one of the atoms <span class="math inline">\(s_n\)</span> is assigned probability 1. So, there are three relevant cases:</p>
<p>If <span class="math inline">\(\pi\)</span> assigns some false atom probability 1, <strong>Brier</strong><span class="math inline">\(_\mathscr{S}(\pi, @) = \frac{2}{N}\cdot(1 - 0) = \frac{2}{N}\)</span>.</p>
<p>If <span class="math inline">\(\pi\)</span> assigns the true atom probability 1, <strong>Brier</strong><span class="math inline">\(_\mathscr{S}(\pi, @) = \frac{2}{N}\cdot(1 - 1) = 0\)</span>.</p>
<p>If <span class="math inline">\(\pi\)</span> does not assign any atom probability 1, <strong>Brier</strong><span class="math inline">\(_\mathscr{S}(\pi, @) &lt; \frac{2}{N}\cdot(1 - c_1) \leq \frac{2}{N}\)</span>.</p>
<p>So, since <strong>c</strong> fits case (i) and <strong>b</strong> fits case (ii) or (iii) we have the desired result. QED</p>
<blockquote class="blockquote">
<p><strong>Theorem-3</strong>: Let <span class="math inline">\(\mathscr{A}\)</span> be an algebra of propositions generated by atoms <span class="math inline">\(a_1, ..., a_{2N}\)</span>, where <span class="math inline">\(a_1\)</span> is the truth. Let <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> be probability functions defined on <span class="math inline">\(\mathscr{A}\)</span>. <span class="math inline">\(P\)</span> assigns all its mass to the first <span class="math inline">\(N\)</span> atoms, so that <span class="math inline">\(P(a_1 \vee \dots \vee a_N) = 1\)</span>, and it also assigns some positive probability to <span class="math inline">\(a_1\)</span>. <span class="math inline">\(Q\)</span> assigns all its mass to the false atom <span class="math inline">\(a_{2N}\)</span>, so that <span class="math inline">\(Q(a_{2N}) = 1\)</span>. Then, for any proper score <strong>I</strong> satisfying Truth-directedness, Extensionality and Negation Symmetry we have <span class="math inline">\(\mathbf{I}(v_1, P) &lt; \mathbf{I}(v_1, Q)\)</span> where <span class="math inline">\(v_1\)</span> is the truth-value assignment associated with <span class="math inline">\(a_1\)</span> (i.e., where <span class="math inline">\(v_1(X) = 1\)</span> if and only if <span class="math inline">\(a_1\)</span> entails <span class="math inline">\(X\)</span>).</p>
</blockquote>
<p><strong>Proof</strong>: We can divide the algebra <span class="math inline">\(\mathscr{A}\)</span> into four quadrants <span class="math display">\[\begin{aligned}
\mathscr{A}^1 &amp;= \{X \in \mathscr{A}: a_1 \vDash X \text{ and } a_{2N} \vDash X\} \\
\mathscr{A}^2 &amp;= \{X \in \mathscr{A}: a_1 \vDash X \text{ and } a_{2N} \nvDash X\} \\
\mathscr{A}^3 &amp;= \{X \in \mathscr{A}: a_1 \nvDash X \text{ and } a_{2N} \vDash X\} \\
\mathscr{A}^4 &amp;= \{X \in \mathscr{A}: a_1 \nvDash X \text{ and } a_{2N} \nvDash X\}\end{aligned}\]</span> We know the following:</p>
<ul>
<li><p><span class="math inline">\(Q\)</span> is maximally accurate on <span class="math inline">\(\mathscr{A}^1 \cup \mathscr{A}^4\)</span>. Every proposition in <span class="math inline">\(\mathscr{A}^1\)</span> is true, and <span class="math inline">\(Q\)</span> assigns it a probability of 1. Every proposition in <span class="math inline">\(\mathscr{A}^4\)</span> is false, and <span class="math inline">\(Q\)</span> assigns it a probability of 0.</p></li>
<li><p><span class="math inline">\(Q\)</span> is maximally inaccurate on <span class="math inline">\(\mathscr{A}^2 \cup \mathscr{A}^3\)</span>. Every proposition in <span class="math inline">\(\mathscr{A}^2\)</span> is true, and <span class="math inline">\(Q\)</span> assigns it a probability of 0. Every proposition in <span class="math inline">\(\mathscr{A}^3\)</span> is false, and <span class="math inline">\(Q\)</span> assigns it a probability of 1.</p></li>
<li><p><span class="math inline">\(P\)</span> is maximally accurate on <span class="math inline">\(\mathscr{A}^3 \cup \mathscr{A}^4\)</span>. Every proposition in <span class="math inline">\(\mathscr{A}^3 \cup \mathscr{A}^4\)</span> is false, and <span class="math inline">\(P\)</span> assigns it a probability of 0.</p></li>
<li><p>Each quadrant has <span class="math inline">\(2^{2N-2}\)</span> elements.</p></li>
</ul>
<blockquote class="blockquote">
<p><strong>Lemma-3.1</strong>: When <span class="math inline">\(a_1\)</span> is true, the accuracy score of <span class="math inline">\(P\)</span> over the propositions in <span class="math inline">\(\mathscr{A}^1\)</span> is identical to the accuracy score of <span class="math inline">\(P\)</span> over the propositions in <span class="math inline">\(\mathscr{A}^2\)</span>.</p>
</blockquote>
<p><strong>Proof</strong>: Note first that the function <span class="math inline">\(F: \mathscr{A}^1 \rightarrow \mathscr{A}^2\)</span> that takes <span class="math inline">\(X\)</span> to <span class="math inline">\(X \wedge \neg a_{2N}\)</span> is a bijection of <span class="math inline">\(\mathscr{A}^1\)</span> onto <span class="math inline">\(\mathscr{A}^2\)</span>. Since every proposition in <span class="math inline">\(\mathscr{A}^1 \cup \mathscr{A}^2\)</span> is true, we can then write the respective accuracy scores of <span class="math inline">\(\mathscr{A}^1\)</span> and <span class="math inline">\(\mathscr{A}^2\)</span> as <span class="math display">\[\begin{aligned}
\mathbf{I}_{\mathscr{A}^1}(a_1, P) &amp;= 2^{2-2N} \cdot \sum_{X \in \mathscr{A}^1} \mathbf{I}(1, P(X)) \\
\mathbf{I}_{\mathscr{A}^2}(a_1, P) &amp;= 2^{2-2N} \cdot \sum_{X \in \mathscr{A}^1} \mathbf{I}(1, P(X \wedge \neg a_{2N}))\end{aligned}\]</span> Note: <span class="math inline">\(X\)</span> ranges over <span class="math inline">\(\mathscr{A}^1\)</span> in both summations. But since <span class="math inline">\(P(a_{2N}) = 0\)</span> we have <span class="math inline">\(P(X) = P(X \wedge a_{2N})\)</span> for each <span class="math inline">\(X\)</span> in <span class="math inline">\(\mathscr{A}^1\)</span>. Since <strong>I</strong> is extensional, this means that <span class="math inline">\(\mathbf{I}(1, P(X)) = \mathbf{I}(1, P(X \wedge a_{2N}))\)</span> for each <span class="math inline">\(X\)</span> in <span class="math inline">\(\mathscr{A}^1\)</span>. And, it follows that <span class="math inline">\(\mathbf{I}_{\mathscr{A}^1}(a_1, P)\)</span> and <span class="math inline">\(\mathbf{I}_{\mathscr{A}^2}(a_1, P)\)</span> are identical. (Note that even if <span class="math inline">\(P(a_{2N}) &gt; 0\)</span>, Truth-directedness entails that <span class="math inline">\(\mathbf{I}_{\mathscr{A}^1}(a_1, P) &lt; \mathbf{I}_{\mathscr{A}^2}(a_1, P)\)</span>.)</p>
<blockquote class="blockquote">
<p><strong>Lemma-3.2</strong>: When <span class="math inline">\(a_1\)</span> is true, the accuracy score of <span class="math inline">\(Q\)</span> over <span class="math inline">\(\mathscr{A}^2\)</span> is identical to the accuracy score of <span class="math inline">\(Q\)</span> over <span class="math inline">\(\mathscr{A}^3\)</span>.</p>
</blockquote>
<p><strong>Proof</strong>: To see this, note first that the function <span class="math inline">\(G: \mathscr{A}^2 \rightarrow \mathscr{A}^3\)</span> that takes <span class="math inline">\(X\)</span> to <span class="math inline">\(G(X) = \neg X\)</span> is a bijection (i.e., the negation of everything in <span class="math inline">\(\mathscr{A}^2\)</span> is in <span class="math inline">\(\mathscr{A}^3\)</span> and vice-versa). This, together with the fact that <span class="math inline">\(\mathscr{A}^2\)</span> contains only truths and <span class="math inline">\(\mathscr{A}^3\)</span> contains only falsehoods, lets us write <span class="math display">\[\begin{aligned}
\mathbf{I}_{\mathscr{A}^2}(a_1, Q) &amp;= 2^{2-2N} \cdot \sum_{X \in \mathscr{A}^2} \mathbf{I}(1, Q(X)) \\
\mathbf{I}_{\mathscr{A}^3}(a_1, Q) &amp;= 2^{2-2N} \cdot \sum_{X \in \mathscr{A}^2} \mathbf{I}(0, Q(\neg X))\end{aligned}\]</span> But since <strong>I</strong> is negation symmetric, <span class="math inline">\(\mathbf{I}(1, Q(X)) = \mathbf{I}(0, Q(\neg X))\)</span> for every <span class="math inline">\(X\)</span>, which means that <span class="math inline">\(\mathbf{I}_{\mathscr{A}^2}(a_1, Q) = \mathbf{I}_{\mathscr{A}^3}(a_1, Q)\)</span>. (Note that this proof made no assumptions about <span class="math inline">\(Q\)</span> except that it was a probability.)</p>
<blockquote class="blockquote">
<p><strong>Lemma-3.3</strong>: If <span class="math inline">\(P(a_1) &gt; 0\)</span>, the accuracy score of <span class="math inline">\(P\)</span> over <span class="math inline">\(\mathscr{A}^2\)</span> is strictly less than the accuracy score of <span class="math inline">\(Q\)</span> over <span class="math inline">\(\mathscr{A}^2\)</span>.</p>
</blockquote>
<p><strong>Proof</strong>: Since <span class="math inline">\(Q(X) = 0\)</span> everywhere on <span class="math inline">\(\mathscr{A}^2\)</span> we have <span class="math display">\[\begin{aligned}
\mathbf{I}_{\mathscr{A}^2}(a_1, P) &amp;= 2^{2-2N} \cdot \sum_{X \in \mathscr{A}^2} \mathbf{I}(1, P(X)) \\
\mathbf{I}_{\mathscr{A}^2}(a_1, Q) &amp;= 2^{2-2N} \cdot \sum_{X \in \mathscr{A}^2} \mathbf{I}(1, 0) \end{aligned}\]</span> But, by Truth Directedness <span class="math inline">\(\mathbf{I}(1, 0) &gt; \mathbf{I}(1, P(X))\)</span> since <span class="math inline">\(P(a_1) &gt; 0\)</span> implies that <span class="math inline">\(P(X) &gt; 0\)</span> for all <span class="math inline">\(X \in \mathscr{A}^2\)</span>. Thus <span class="math inline">\(\mathbf{I}_{\mathscr{A}^2}(a_1, Q) &gt; \mathbf{I}_{\mathscr{A}^2}(a_1, P)\)</span>.</p>
<p>To complete the proof of the theorem we need only note that <span class="math display">\[\begin{aligned}
\mathbf{I}_{\mathscr{A}}(a_1, P) &amp;= \frac{\mathbf{I}_{\mathscr{A}^1}(a_1, P)}{4} + \frac{\mathbf{I}_{\mathscr{A}^2}(a_1, P)}{4} &amp;\text{(since }P\text{ is perfect on }\mathscr{A}^3 \cup \mathscr{A}^4) \\
&amp;= \frac{\mathbf{I}_{\mathscr{A}^2}(a_1, P)}{2} &amp;\text{Lemma-3.1} \\
&amp;&lt; \frac{\mathbf{I}_{\mathscr{A}^2}(a_1, Q)}{2} &amp;\text{Lemma-3.3} \\
&amp;= \frac{\mathbf{I}_{\mathscr{A}^2}(a_1, Q)}{4} + \frac{\mathbf{I}_{\mathscr{A}^3}(a_1, Q)}{4} &amp;\text{Lemma-3.2} \\
&amp;= \mathbf{I}_{\mathscr{A}}(a_1, Q) &amp;\text{(since }Q\text{ is perfect on }\mathscr{A}^1 \cup \mathscr{A}^4)\end{aligned}\]</span></p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Berker2013b" class="csl-entry" role="listitem">
Berker, Selim. 2013a. <span>“Epistemic Teleology and the Separateness of Propositions.”</span> <em>Philosophical Review</em> 122 (3): 337–93. <a href="https://doi.org/10.1215/00318108-2087645">https://doi.org/10.1215/00318108-2087645</a>.
</div>
<div id="ref-Berker2013a" class="csl-entry" role="listitem">
———. 2013b. <span>“The Rejection of Epistemic Consequentialism.”</span> <em>Philosophical Issues</em> 23 (1): 363–87. <a href="https://doi.org/10.1111/phis.12019">https://doi.org/10.1111/phis.12019</a>.
</div>
<div id="ref-DescartesMeditations" class="csl-entry" role="listitem">
Descartes, René. 1641/1996. <em>Meditations on First Philosophy, <span class="roman">Tr. John Cottingham</span></em>. Cambridge: Cambridge University Press.
</div>
<div id="ref-Greaves2013" class="csl-entry" role="listitem">
Greaves, Hilary. 2013. <span>“Epistemic Decision Theory.”</span> <em>Mind</em> 122 (488): 915–52. <a href="https://doi.org/10.1093/mind/fzt090">https://doi.org/10.1093/mind/fzt090</a>.
</div>
<div id="ref-Hammond1988" class="csl-entry" role="listitem">
Hammond, Peter J. 1988. <span>“Consequentialist Foundations for Expected Utility.”</span> <em>Theory and Decision</em> 25 (1): 25–78. <a href="https://doi.org/10.1007/BF00129168">https://doi.org/10.1007/BF00129168</a>.
</div>
<div id="ref-Jenkins2007" class="csl-entry" role="listitem">
Jenkins, C. S. 2007. <span>“Entitlement and Rationality.”</span> <em>Synthese</em> 157 (1): 25–45. <a href="https://doi.org/10.1007/s11229-006-0012-2">https://doi.org/10.1007/s11229-006-0012-2</a>.
</div>
<div id="ref-Joyce1998" class="csl-entry" role="listitem">
Joyce, James M. 1998. <span>“A Non-Pragmatic Vindication of Probabilism.”</span> <em>Philosophy of Science</em> 65 (4): 575–603. <a href="https://doi.org/10.1086/392661">https://doi.org/10.1086/392661</a>.
</div>
<div id="ref-Maher1997" class="csl-entry" role="listitem">
Maher, Patrick. 1997. <span>“Depragmatised Dutch Book Arguments.”</span> <em>Philosophy of Science</em> 64 (2): 291–305. <a href="https://doi.org/10.1086/392552">https://doi.org/10.1086/392552</a>.
</div>
<div id="ref-Roulston2007" class="csl-entry" role="listitem">
Roulston, Mark S. 2007. <span>“Performance Targets and the Brier Score.”</span> <em>Meterological Applications</em> 14: 185–94. <a href="https://doi.org/10.1002/met.21">https://doi.org/10.1002/met.21</a>.
</div>
<div id="ref-Shafer1976" class="csl-entry" role="listitem">
Shafer, Glenn. 1976. <em>A Mathematical Theory of Evidence</em>. Princeton: Princeton University Press.
</div>
<div id="ref-Weatherson1999" class="csl-entry" role="listitem">
Weatherson, Brian. 1999. <span>“Begging the Question and Bayesians.”</span> <em>Studies in the History and Philosophy of Science Part A</em> 30: 687–97.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>