<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.523">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Brian Weatherson">
<meta name="dcterms.date" content="2024-03-05">
<meta name="description" content="In recent years the literature on decision theory has become disjointed. There isn’t as much discussion as there should be on how different problems impact one another. This paper aims to bring together work on problems involving demons, problems about attitudes to risk, problems about incomplete preferences, and problems about dynamic choice. In the first three of these cases, I end up defending a pre-existing view, but in each case the argument for that view is strengthened by seeing how the premises that support it are essential to solving one of the other problems. The most novel part of the view is the theory of dynamic choice that I offer: a sequence of choices is rational only if both the so-called ‘resolute’ and ‘sophisticated’ theories of dynamic choice would permit it. This theory would be implausible if paired with many rival solutions to the first three problems, but fits nicely with the view I’ll develop through the paper that decision theory is much less constraining than most theorists hold.">

<title>Four Problems in Decision Theory</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" href="https://use.typekit.net/uzz2drx.css">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Online Papers - Brian Weatherson</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://brian.weatherson.org"> <i class="bi bi-mortarboard" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://bsky.app/profile/bweatherson.bsky.social"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Four Problems in Decision Theory</h1>
                  <div>
        <div class="description">
          <p>In recent years the literature on decision theory has become disjointed. There isn’t as much discussion as there should be on how different problems impact one another. This paper aims to bring together work on problems involving demons, problems about attitudes to risk, problems about incomplete preferences, and problems about dynamic choice. In the first three of these cases, I end up defending a pre-existing view, but in each case the argument for that view is strengthened by seeing how the premises that support it are essential to solving one of the other problems. The most novel part of the view is the theory of dynamic choice that I offer: a sequence of choices is rational only if both the so-called ‘resolute’ and ‘sophisticated’ theories of dynamic choice would permit it. This theory would be implausible if paired with many rival solutions to the first three problems, but fits nicely with the view I’ll develop through the paper that decision theory is much less constraining than most theorists hold.</p>
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">games and decisions</div>
                <div class="quarto-category">unpublished</div>
              </div>
                  </div>
  </div>
    
  <div class="quarto-title-meta-author">
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-heading">Affiliation</div>
    
      <div class="quarto-title-meta-contents">
      <p class="author"><a href="http://brian.weatherson.org">Brian Weatherson</a> </p>
    </div>
    <div class="quarto-title-meta-contents">
          <p class="affiliation">
              University of Michigan
            </p>
        </div>
    </div>

  <div class="quarto-title-meta">

        
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 5, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Sections</h2>
   
  <ul>
  <li><a href="#four-problems" id="toc-four-problems" class="nav-link active" data-scroll-target="#four-problems"><span class="header-section-number">1</span> Four Problems</a>
  <ul class="collapse">
  <li><a href="#sec-demons" id="toc-sec-demons" class="nav-link" data-scroll-target="#sec-demons"><span class="header-section-number">1.1</span> Demons</a></li>
  <li><a href="#risk" id="toc-risk" class="nav-link" data-scroll-target="#risk"><span class="header-section-number">1.2</span> Risk</a></li>
  <li><a href="#non-linearity" id="toc-non-linearity" class="nav-link" data-scroll-target="#non-linearity"><span class="header-section-number">1.3</span> Non-Linearity</a></li>
  <li><a href="#sec-dynamic-choice" id="toc-sec-dynamic-choice" class="nav-link" data-scroll-target="#sec-dynamic-choice"><span class="header-section-number">1.4</span> Dynamic Choice</a></li>
  </ul></li>
  <li><a href="#the-single-choice-principle" id="toc-the-single-choice-principle" class="nav-link" data-scroll-target="#the-single-choice-principle"><span class="header-section-number">2</span> The Single Choice Principle</a>
  <ul class="collapse">
  <li><a href="#equivalence-principles" id="toc-equivalence-principles" class="nav-link" data-scroll-target="#equivalence-principles"><span class="header-section-number">2.1</span> Equivalence Principles</a></li>
  <li><a href="#sec-scp-intro" id="toc-sec-scp-intro" class="nav-link" data-scroll-target="#sec-scp-intro"><span class="header-section-number">2.2</span> Introducing the Single Choice Principle</a></li>
  </ul></li>
  <li><a href="#applications" id="toc-applications" class="nav-link" data-scroll-target="#applications"><span class="header-section-number">3</span> Applications</a>
  <ul class="collapse">
  <li><a href="#evidential-decision-theory" id="toc-evidential-decision-theory" class="nav-link" data-scroll-target="#evidential-decision-theory"><span class="header-section-number">3.1</span> Evidential Decision Theory</a></li>
  <li><a href="#buchak-on-risk" id="toc-buchak-on-risk" class="nav-link" data-scroll-target="#buchak-on-risk"><span class="header-section-number">3.2</span> Buchak on Risk</a></li>
  <li><a href="#linearity" id="toc-linearity" class="nav-link" data-scroll-target="#linearity"><span class="header-section-number">3.3</span> Linearity</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="four-prob.docx"><i class="bi bi-file-word"></i>MS Word</a></li><li><a href="Four Problems in Decision Theory.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<p>Contemporary decision theory has become disjointed. There is less overlap than there should be in work on adjacent problems. This paper aims to undo some of that, by showing that four problems that have largely been worked on in isolation cast useful light on each other. Some of the conclusions that draw will be familiar: on one of the problems I’m going to defend a similar answer to what Melissa <span class="citation" data-cites="Fuscond">Fusco (<a href="#ref-Fuscond" role="doc-biblioref">n.d.</a>)</span> has defended; on another I’m going to defend a similar answer to one defended by Harvey <span class="citation" data-cites="Ledermannd">Lederman (<a href="#ref-Ledermannd" role="doc-biblioref">2024</a>)</span>. What’s primarily distinctive about the arguments here is that they show these questions are connected, and the arguments for my preferred answers are going to be intertwined.</p>
<p>This paper is part of a broader project of identifying the decision theory that is implicit in standard, textbook approaches to game theory, and arguing that this decision theory is better than the ones currently on the philosophical market. I used to think the first part of this project would be boring - game theorists are just typical Causal Decision Theorists. This can’t be true for five reasons. First, these textbooks don’t mention counterfactuals at all, but counterfactuals are central to typical presentations of Causal Decision Theory. Second, solution concepts in game theory are typically not <em>single-valued</em>, in the technical sense defined by <span class="citation" data-cites="Pearce1984">Pearce (<a href="#ref-Pearce1984" role="doc-biblioref">1984</a>)</span>, while typical versions of Causal Decision Theory are single-valued. Third, sometimes the unique solution to a game involves mixed strategies, while Causal Decision Theory, in its typical formulations, never says that a mixed strategy is uniquely optimal. Fourth, the solution concepts used for things like the beer-quiche game <span class="citation" data-cites="ChoKreps1987">(<a href="#ref-ChoKreps1987" role="doc-biblioref">Cho and Kreps 1987</a>)</span> put constraints that go beyond coherence constraints on the players, and typical formulations of Causal Decision Theory allow any coherent credence function. Finally, the textbook solution concepts for dynamic games don’t correspond to any view in the philosophical literature on dynamic games.</p>
<p>Game theory textbooks tend to be several hundred pages, and identifying all the unique characteristics of the implicit decision theory, like the five from the previous paragraph, would take just as much space. So I’m going to simplify a lot here. In particular, I’m not going to talk about mixed strategies, except occasionally in footnotes. That is, I’m not going to assume anything about the availability or unavailability of mixed strategies in the arguments I put forward. That said, some of the positions I put forward are similar enough to existing positions that there are well known objections in the literature, and in many cases my preferred response to those objections does rely on the availability of mixed strategies. Getting all the details of those right would massively extend the paper, so I’ll stay away from those discussions here. Relatedly, while I will spend a lot of time on problems where there are multiple pure strategy equilibria, I won’t discuss any problems where there are no pure strategy equilibria. Those are for another day. With those qualifications in place, it’s time to get to the four problems I will discuss.</p>
<section id="four-problems" class="level1 page-columns page-full" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Four Problems</h1>
<section id="sec-demons" class="level2 page-columns page-full" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="sec-demons"><span class="header-section-number">1.1</span> Demons</h2>
<p>When a student starts decision theory, they are introduced to a view that is simple, elegant, and wrong. The view starts by assuming that a chooser, hereafter called Chooser, has a set of possible actions <em>A</em> available. We’ll use <em>a</em> to represent an arbitrary member of that set. And there is a set of possible states <em>S</em>, with <em>s</em> being used to pick out an arbitrary member. It is assumed that a probability distribution Pr over <em>S</em> is given, and that each action-state pair has a numerical value. I’ll write <em>V</em> for the value function, so <em>V</em>(<em>as</em>) is the value of performing act <em>a</em> in state <em>s</em>.</p>
<p>The simple, elegant, and wrong theory is that Chooser should value each act <em>a</em> by its expected value. That is, the value of act <em>a</em> is Σ<sub><em>s</em>&nbsp;∈&nbsp;<em>S</em></sub>&nbsp;Pr(<em>s</em>)<em>V</em>(<em>as</em>). And Chooser should then choose the act with the highest value.</p>
<p>The problem with this view is that if Chooser has any influence over which state is actual, then this view will recommend obviously bad actions. Assume that the only possibly actions are <em>a</em> and <em>b</em>, the only two states are <em>s</em> and <em>t</em>, and while <em>a</em> will almost certainly cause <em>s</em> to be actual, <em>b</em> will almost certainly cause <em>b</em> to be actual. Now let the payoffs for all four action-state combinations be as in <a href="#tbl-joycewindow" class="quarto-xref">Table&nbsp;1</a>.</p>
<div id="tbl-joycewindow" class="anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-joycewindow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: A counterexample to the simple theory.
</figcaption>
<div aria-describedby="tbl-joycewindow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><em>s</em></th>
<th style="text-align: center;"><em>t</em></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><em>a</em></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1001</td>
</tr>
<tr class="even">
<td style="text-align: center;"><em>b</em></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1000</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The problem is that in <a href="#tbl-joycewindow" class="quarto-xref">Table&nbsp;1</a> it obviously makes sense to do <em>b</em>, since that brings about the best option, but the simple theory says that the value of <em>a</em> is 1 more than the value of <em>b</em>. So <a href="#tbl-joycewindow" class="quarto-xref">Table&nbsp;1</a> is a counterexample to the simple theory. So far every decision theorist would agree. But here agreement ends. There is no agreement on either why the simple theory fails in this case, or what should go in its place.</p>
<p>Evidential decision theorists such as Arif <span class="citation" data-cites="Ahmed2014">Ahmed (<a href="#ref-Ahmed2014" role="doc-biblioref">2014</a>)</span> say the problem is that there is an evidential connection between the acts and the states. They say that instead of the simple theory Chooser should value options using this formula.</p>
<dl>
<dt>EDT</dt>
<dd>
<em>V</em>(<em>a</em>) = Σ<sub><em>s</em>&nbsp;∈&nbsp;<em>S</em></sub>&nbsp;Pr(<em>s</em> | <em>a</em>)<em>V</em>(<em>as</em>)
</dd>
</dl>
<p>As with the simple theory, the only rule is that Chooser should maximise value. The difference between EDT and the simple theory is that EDT replaces an unconditional probability with a conditional probability in the formula that gives the value of options. This will get the right result in <a href="#tbl-joycewindow" class="quarto-xref">Table&nbsp;1</a>, but gives some strange results in other cases.</p>
<p>Reinterpret <a href="#tbl-joycewindow" class="quarto-xref">Table&nbsp;1</a> so that the states are causally independent of the actions, but which action Chooser chooses provides excellent evidence about which state they are in. To use the standard example, going back to <span class="citation" data-cites="Nozick1969">Nozick (<a href="#ref-Nozick1969" role="doc-biblioref">1969</a>)</span>, imagine that a demon (hereafter called Demon) has predicted Chooser’s choice. There is no backwards causation, so Chooser’s choice is causally independent of Demon’s prediction. But Chooser believes Demon is incredibly reliable, so Pr(<em>s</em>&nbsp;|&nbsp;<em>a</em>)&nbsp;≈&nbsp;1, and Pr(<em>t</em>&nbsp;|&nbsp;<em>b</em>)&nbsp;≈&nbsp;1. For ease of reference, I’ll use <a href="#tbl-newcomb" class="quarto-xref">Table&nbsp;2</a> as the game table for this problem, where the states are the predictions of an accurate Demon. In <a href="#tbl-newcomb" class="quarto-xref">Table&nbsp;2</a>, Chooser selects <strong>U</strong>p or <strong>D</strong>own, and Demon <strong>P</strong>redicts this choice. In general in what follows, if a state is labelled <strong>PX</strong>, it means that Demon has predicted that Chooser will select X. Using that notation <a href="#tbl-newcomb" class="quarto-xref">Table&nbsp;2</a> is just Newcomb’s Problem.</p>
<div id="tbl-newcomb" class="anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-newcomb-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Newcomb’s Problem
</figcaption>
<div aria-describedby="tbl-newcomb-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong>PU</strong></th>
<th style="text-align: center;"><strong>PD</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>U</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1001</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>D</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1000</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>In <a href="#tbl-newcomb" class="quarto-xref">Table&nbsp;2</a>, EDT says that Chooser should do <em>a</em>. There is a simple argument that Chooser should do <em>b</em>: whatever the world is like, it will have a higher return. This argument convinced many people that we need a different theory, and over the 1970s and 1980s a lot of people settled on something like CfDT as the right alternative.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;The canonical statement of this view is <span class="citation" data-cites="GibbardHarper1978">Gibbard and Harper (<a href="#ref-GibbardHarper1978" role="doc-biblioref">1978</a>)</span>.</p></li></div><dl>
<dt>CfDT</dt>
<dd>
<em>V</em>(<em>a</em>) = Σ<sub><em>s</em>&nbsp;∈&nbsp;<em>S</em></sub>&nbsp;Pr(<em>a</em> □→ <em>s</em>)<em>V</em>(<em>as</em>)
</dd>
</dl>
<p>That’s a way to value options; the theory is just that one should choose the option with maximal value. Recently Brian <span class="citation" data-cites="Hedden2023">Hedden (<a href="#ref-Hedden2023" role="doc-biblioref">2023</a>)</span> has argued that this theory is preferable to <em>Causal</em> Decision Theory, properly so called. I’m sympathetic to the reply offered by Dmitri <span class="citation" data-cites="Gallowndppq">Gallow (<a href="#ref-Gallowndppq" role="doc-biblioref">n.d.-a</a>)</span> that CfDT just is what Causal Decision Theorists in the 1970s and 1980s were typically defending. But I also think, for reasons that will soon become clear, that some other theories which are quite different to this are also <em>causal</em> in the relevant sense. So from now on I’ll use “Causal Decision Theory” to name a family of theories, and CfDT will be a distinctive member of that family.</p>
<p>Another theory in that family says that the simple theory was essentially correct, it was just applied at the wrong time. This theory, which I’ll call Gamified Decision Theory, or GDT, starts with the following two claims. First, the relevant state probabilities are those at the end of deliberation, once a choice has been made, not at the start of deliberation. Second, when we use those <em>ex post</em> probabilities, the simple theory is fine. In symbols, the core formula that GDT uses is this.</p>
<dl>
<dt>GDT</dt>
<dd>
V(a) = Σ<sub><em>s</em>&nbsp;∈&nbsp;<em>S</em></sub>&nbsp;Pr′(<em>s</em>)<em>V</em>(<em>as</em>)
</dd>
</dl>
<p>In this formula, Pr′ is the probability distribution over states after Chooser has made their decision. GDT says that only options that have maximal value using this formula are choice-worthy.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> This allows that different options, with different values, could be choice-worthy. All that matters is that given the probability distribution over states that Chooser has when they have decided to perform an act, that act is utility maximising. In <a href="#tbl-first-coord" class="quarto-xref">Table&nbsp;3</a>, GDT says that both Up and Down are choice-worthy.</p>
<div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;My preferred version of GDT adds several more constraints to this - it has a separate constraint for ruling out weakly dominated options, and a constraint for solving beer-quiche games, and maybe a constraint for ruling out mixed strategies in coordination games. But having maximal value ex post is a necessary condition for choice-worthiness.</p></li></div><div id="tbl-first-coord" class="anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-first-coord-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3: An asymmetric coordination problem
</figcaption>
<div aria-describedby="tbl-first-coord-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong>PU</strong></th>
<th style="text-align: center;"><strong>PD</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>U</strong></td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>D</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">2</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>One of our four problems is to work out which of these theories is right. I’ll be arguing for GDT.</p>
<p>It’s sometimes said that problems involving Demon should not be treated as central to decision theory because Demon is so unrealistic. I think this view is mistaken twice over. For one thing, Demon isn’t that much more unrealistic than the precise probabilistic models of the future of humanity that routinely do get used. More importantly, the problems that come up in this section arise in some very ordinary models. As <span class="citation" data-cites="Lewis1979en">Lewis (<a href="#ref-Lewis1979en" role="doc-biblioref">1979</a>)</span> pointed out, Prisoners’ Dilemma with a twin raises much the same problems. Standard approaches to game theory presuppose that other players are like perfectly accurate demons.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> Most importantly, all the views about how to make decisions in Newcomb-like problems come apart as soon as we assume Demon is better than chance at predicting Chooser. And better than chance predictions can be reasonably believed. I suspect if I was allowed to interview and observe people before they chose, I could predict their choices at well over 60% accuracy, and probably over 70%. To simplify the math, I’ll work with a Demon who is perfectly accurate, or at least arbitrarily accurate.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> But with some extra attention to detail, we could rewrite every example in the paper with a realistic Demon. I think having very accurate Demons is a worthwhile tradeoff of clarity for realism, but if you disagree it’s not that hard to imagine the paper rewritten with demons only somewhat better than chance.</p>
<div class="no-row-height column-margin column-container"><li id="fn3"><p><sup>3</sup>&nbsp;Matthias <span class="citation" data-cites="Risse2000">Risse (<a href="#ref-Risse2000" role="doc-biblioref">2000</a>)</span> criticises these standard approaches on this point, and while I’m sympathetic to his criticism, it’s worth taking seriously how wide-spread the assumption of perfect prediction is across the academy.</p></li><li id="fn4"><p><sup>4</sup>&nbsp;That is, I’ll assume Demon’s accuracy is 1‑ε, for arbitrarily small ε.</p></li></div></section>
<section id="risk" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="risk"><span class="header-section-number">1.2</span> Risk</h2>
<p>Think about what value of <em>x</em> would make Chooser indifferent between these two options, and why that would be the right value</p>
<ol type="1">
<li>$1,000,000</li>
<li>A gamble that returns $2,000,000 with probability <em>x</em>, and $0 with probability 1-<em>x</em>.</li>
</ol>
<p>What factors are relevant to solving for <em>x</em>? One factor is the declining marginal utility of money. Money primarily has exchange value, and if Chooser won $2,000,000, the things Chooser would buy with the second million dollars are largely things they declined to buy with the first million. Hence the second million will be worth much less to them than the first, barring a pronounced taste for expensive goods that lack valuable parts. That’s one factor that goes into solving for <em>x</em>. Every decision theorist agrees it is important, and that it is part of why whatever value <em>x</em> takes, it is surely well above ½.</p>
<p>But is it the only factor? If Chooser is rational, is knowing the function from the money they have to the utility they get from money enough to solve for <em>x</em>? The orthodox answer is that it is. Lara <span class="citation" data-cites="BuchakRisk">Buchak (<a href="#ref-BuchakRisk" role="doc-biblioref">2013</a>)</span> has argued that it is not. We also need to know how much Chooser values, or more likely disvalues, risk. That is, we need to know how risk-seeking, or risk-averse, Chooser is.</p>
<p>The orthodox view is that all we need to know are three numbers:</p>
<ul>
<li>The value Chooser assigns to their current wealth, which we can set as 0 for ease of calculation.</li>
<li>The value Chooser assigns to having $1,000,000 more than their current wealth, which we can set as 1 again for ease of calculation.</li>
<li>The value Chooser assigns to having $2,000,000 more than their current wealth, which we will label <em>c</em>.</li>
</ul>
<p>Then on the standard view, the value of the gamble is <em>cx</em>, so the gamble is equal to the sure million iff <em>x</em>&nbsp;=&nbsp;1/<em>c</em>. On Buchak’s view, rational Chooser has a risk function <em>f</em>, that measures their sensitivity to risk. The function must be monotonic increasing, with <em>f</em>(0)&nbsp;=&nbsp;0, and <em>f</em>(1)&nbsp;=&nbsp;1. If Chooser is risk-averse, then typically <em>f</em>(<em>x</em>)&nbsp;&lt;&nbsp;<em>x</em>.</p>
<p>Buchak’s view reduces to the orthodox view if <em>f</em>(<em>x</em>)&nbsp;=&nbsp;<em>x</em>. I’m going to argue that given one very natural constraint, we can show that <em>f</em>(<em>x</em>) must indeed equal <em>x</em>. I’m far from the first to make an argument on these lines; I think the arguments that <span class="citation" data-cites="Briggs2015">Briggs (<a href="#ref-Briggs2015" role="doc-biblioref">2015</a>)</span> and <span class="citation" data-cites="Thoma2019">Thoma (<a href="#ref-Thoma2019" role="doc-biblioref">2019</a>)</span> make for the same conclusion are also successful. What’s novel about what I’m going here is two-fold. First, the premise I’ll use is, I think, weaker and more plausible than the premises used in other arguments. Second, and more importantly, I’ll be using the same premise to resolve problems involving demons as to argue against Buchak’s view. A big aim of this paper is to bring different parts of contemporary decision theory together. As a quick glance at the literature will tell you, there isn’t much overlap between work on views like Buchak’s and work on problems involving demons, though both of them are large literatures. This is a mistake, and one I’m hoping to help rectify here.</p>
</section>
<section id="non-linearity" class="level2 page-columns page-full" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="non-linearity"><span class="header-section-number">1.3</span> Non-Linearity</h2>
<p>Standard approaches to decision theory assign to Chooser a probability function and a utility function, both defined over (some) propositions. The domain of each function is some subset of the reals; the interval [0,1] for the probability, and some bounded interval for the utilities. The real numbers have a distinctive topology. Among other things, they are totally ordered: for any two numbers, either one is greater, or they are equal. So assuming that probabilities and utilities are numerical involves assuming, among other things, that they are also totally ordered. That is, for any two propositions, the probability(/utility) of the first is either greater than, less than, or equal to, that of the other. Call this assumption Ordering.</p>
<p>Ordering is controversial, both for probabilities and utilities. For probabilities, it has been criticised since Keynes’s <em>Treatise on Probability</em> <span class="citation" data-cites="Keynes1921">(<a href="#ref-Keynes1921" role="doc-biblioref">1921</a>)</span>, and in recent times has been criticised by, among others, Peter <span class="citation" data-cites="Walley1991">Walley (<a href="#ref-Walley1991" role="doc-biblioref">1991</a>)</span> and James <span class="citation" data-cites="Joyce2010">Joyce (<a href="#ref-Joyce2010" role="doc-biblioref">2010</a>)</span>. For utilities, the most prominent critic has been Ruth Chang <span class="citation" data-cites="Chang2002 Chang2015">(<a href="#ref-Chang2002" role="doc-biblioref">2002</a>, <a href="#ref-Chang2015" role="doc-biblioref">2015</a>)</span>.</p>
<p>It takes a little work to create a counterexample to Ordering. It’s no good to just put forward two things and say it isn’t clear which is larger. For one thing, it might simply be unknown which is larger. For another, they might be equal. We’ll come back to the first concern in a bit. Ruth <span class="citation" data-cites="Chang2002">Chang (<a href="#ref-Chang2002" role="doc-biblioref">2002</a>)</span> points out a natural way to avoid the second complaint. Consider three options <em>A</em>, <em>B</em>, and <em>A</em>+, with the following features.</p>
<ul>
<li><em>A</em> and <em>B</em> concern different subject matters.</li>
<li>It is unclear whether the value of <em>A</em> or of <em>B</em> is larger. (The ‘value’ here could be either probability or utility.)</li>
<li><em>A</em>+ is by design fractionally larger than <em>A</em>. If the value is utility, <em>A</em>+ could be <em>A</em> plus a cookie. If it is probability, <em>A</em>+ could be the disjunction <em>A or this lottery ticket wins</em>.</li>
<li>If <em>A</em> and <em>B</em> were equal in value, then since <em>A</em>+ is greater than <em>A</em>, <em>A</em>+ would be greater than <em>B</em>.</li>
<li>But it is also unclear whether <em>A</em>+ is greater than <em>B</em>.</li>
</ul>
<p>Call this the sweetening argument, since <em>A</em>+ is generated from <em>A</em> by making it a bit better, sweetening it.</p>
<p>Just like there are many critics of Ordering, there are many defenders. <span class="citation" data-cites="DorrEtAl2023">Dorr, Nebel, and Zuehl (<a href="#ref-DorrEtAl2023" role="doc-biblioref">2023</a>)</span> defend it on semantic grounds. Adam <span class="citation" data-cites="Elga2010">Elga (<a href="#ref-Elga2010" role="doc-biblioref">2010</a>)</span> argues that violations of Ordering for probabilities leads to susceptibility to a money pump. Johan <span class="citation" data-cites="Gustafsson2022">Gustafsson (<a href="#ref-Gustafsson2022" role="doc-biblioref">2022</a>)</span> makes a similar in favour of Ordering for utilities.</p>
<p>Even critics of Ordering have noted its unintuitive characteristics. <span class="citation" data-cites="BradleySteele2016">Bradley and Steele (<a href="#ref-BradleySteele2016" role="doc-biblioref">2016</a>)</span> argue that violations of Ordering for probabilities leads to thinking it is acceptable to pay to avoid information.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> Harvey <span class="citation" data-cites="Ledermannd">Lederman (<a href="#ref-Ledermannd" role="doc-biblioref">2024</a>)</span> argues that violations of Ordering for utilities leads to violations of a principle he calls Negative Dominance.</p>
<div class="no-row-height column-margin column-container"><li id="fn5"><p><sup>5</sup>&nbsp;It’s uncontroversial that in some cases we pay to avoid information, e.g., we take efforts to avoid spoilers for movies. Even if the information doesn’t change the value of the final product, we might pay to avoid it if the information is not partitional <span class="citation" data-cites="Das2023">(<a href="#ref-Das2023" role="doc-biblioref">Das 2023</a>)</span>, or we don’t know we’ll conditionalise <span class="citation" data-cites="Nethnd">(<a href="#ref-Nethnd" role="doc-biblioref">Neth, n.d.</a>)</span>. But if none of these three conditions are met, and probabilities and utilities satisfy Ordering, we should never pay to avoid information <span class="citation" data-cites="Blackwell1951">(<a href="#ref-Blackwell1951" role="doc-biblioref">Blackwell 1951</a>)</span>.</p></li></div><blockquote class="blockquote">
<p><strong>Negative Dominance</strong><br>
It’s rationally required that: if [one] strictly prefers one game of chance to another, one prefers one of the prizes that the first might yield, to one of the prizes that the second might yield.</p>
</blockquote>
<p>Both Bradley and Steele, and Lederman, think that ultimately Ordering should be rejected, and we should live with these unintuitive results. They are both pointing out troubling features of their own view. (Something philosophers should do more often.)</p>
<p>In each case it isn’t hard to convert the argument they give to a problem for the other kind of Ordering violation. If Ordering fails for utilities, a Bradley and Steele-style argument shows that it is worth paying to avoid information, and if it fails for probabilities, a Lederman style argument shows that Negative Dominance fails.</p>
<p>I’m going to offer a new defence of Ordering violations. The defence has two parts. First, I’ll argue that even if Ordering holds for probabilities and for values of states, it does not hold for values of actions. A bit loosely, even if Ordering is true for preferences over ends, it isn’t true for preferences over means. This shows we have independent reason to reject any principle that entails Ordering is true in general. That includes Negative Dominance<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>, and the semantic principles Dorr et al endorse. Second, I’m going to argue that many of the criticisms of views that permit Ordering violations presuppose a false view about how rational dynamic choice works. This is how I’ll respond to Elga, Gustafsson, and Bradley and Steele.</p>
<div class="no-row-height column-margin column-container"><li id="fn6"><p><sup>6</sup>&nbsp;Negative Dominance doesn’t on its own entail Ordering, but it does in conjunction with some other principles that I accept, and indeed will be indirectly defending in this paper.</p></li></div></section>
<section id="sec-dynamic-choice" class="level2 page-columns page-full" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="sec-dynamic-choice"><span class="header-section-number">1.4</span> Dynamic Choice</h2>
<p>On that note, it’s time to introduce the last of our four problems - what the general theory of rational dynamic choice should look like. First, I’ll set up how I’m conceiving of dynamic choice situations.</p>
<p>For the purposes of this paper, a <strong>decision tree</strong> is a sextuple ⟨<em>W</em>, <em>R</em>, <em>V</em>, <em>a</em>, <em>I</em>, Pr⟩ such that:</p>
<ul>
<li><em>W</em> is a finite set of nodes. One of these nodes, call it <em>o</em> for origin, is designated as the initial node.</li>
<li><em>R</em> is a relation on <em>W</em> such that for any <em>x</em>&nbsp;∈&nbsp;<em>W</em>, ¬<em>xRo</em>, and if <em>y</em>&nbsp;≠&nbsp;<em>o</em>, there is a unique <em>x</em> such that <em>xRy</em>. Intuitively, the decision problem starts at <em>o</em>, and continues by moving from a node <em>x</em> to another node <em>y</em> such that <em>xRy</em> until there is nowhere further to go. Say that <em>x</em> is a predecessor of <em>y</em> if <em>xR+y</em>, where <em>R+</em> is the ancestral of <em>R</em>.</li>
<li><em>V</em> is a value function. It maps each terminal node of <em>W</em> to a real number. A node <em>x</em> is a terminal node iff there is no <em>y</em> such that <em>xRy</em>.</li>
<li><em>a</em> is a function from non-terminal nodes in <em>W</em> to the set {C,&nbsp;D,&nbsp;N} that says who the agent is for each node. Intuitively, C is for Chooser, D is for Demon, and N is for Nature. That agent ‘chooses’ where the game goes next.</li>
<li><em>I</em> is a partition of the nodes the non-terminal nodes <em>x:&nbsp;a(x)&nbsp;=</em>C. The elements of this partition are called information sets. Intuitively, when Chooser reaches a node where they must choose, they know that they are in one member of this partition, i.e., one information set, and nothing more. Any two nodes in the same information set have the same number of outbound links.</li>
<li>Pr is a conditional probability function. It says that given a <em>strategy</em> for Chooser, and that a particular non-terminal node <em>x</em> which is assigned to Demon or Nature has reached, what the probability is that we’ll move to some further node <em>y</em> such that <em>xRy</em>. If <em>x</em> is assigned to Nature, this probability is independent of Chooser’s strategy.</li>
</ul>
<p>A <strong>strategy</strong> for one of the three players, Demon, Chooser or Nature, is a function from all the nodes in the tree which are assigned to them, to the move they will make if that node is reached.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> Given any decision tree, one can generate a <strong>strategic decision problem</strong> where the possible actions are strategies for Chooser, and the states are pairs of strategies for Demon and strategies for Nature. One question that will be central</p>
<div class="no-row-height column-margin column-container"><li id="fn7"><p><sup>7</sup>&nbsp;It doesn’t matter much for our purposes, but note that in general a strategy includes what to do if one reaches a node that is ruled out by one’s own prior choices.</p></li></div><p>There are two standard positions in philosophy for how to navigate decision trees. The <strong>resolute</strong> view says that Chooser should use the correct static theory of choice to pick a strategy at the start, and then resolutely stick with it. The <strong>sophisticated</strong> theory says that Chooser should take each node as a new choice, treat their past choices as fixed, and treat their future choices as another more-or-less knowable part of the world, and do whatever is best given those constraints. My view is that both of these are wrong.</p>
<p>The <strong>dual mandate</strong> approach, which I favour, says that Chooser should adopt a strategy that makes sense and stick to it, just like the resolute theory says, <em>and</em> Chooser should make choices that make sense at each point, just like the sophisticated theory says. It disagrees with the two existing theories on two counts. First, it denies that either provides a sufficient theory for a sequence of choices being rational. Second, it says that if Chooser adopts a plan that makes sense now, and will continue to make sense at each node conditional on reaching that node, Chooser does not have to regard the future as unknowable. Rather, Chooser can know that they will keep following the sensible plan they have adopted. The point is not just that Chooser knows they will continue to be rational. If Chooser has many rational choices, once they adopt one, Chooser can know they’ll stick to it.</p>
<p>This leads to the first reason for adopting the Dual Mandate view: it respects the distinctive relationship that holds between time-slices of the same person. On the resolute view, later stages of Chooser regard earlier stages as their Lord and Master, dictating what to do even if it no longer makes sense. On the sophisticated view, later stages of Chooser regard earlier stages as just someone that they used to know. As <span class="citation" data-cites="Stalnaker1999">Stalnaker (<a href="#ref-Stalnaker1999" role="doc-biblioref">1999</a>)</span> points out, neither of these feels right; we want something between those two pictures. Now this doesn’t entail that the Dual Mandate view is right, since there are a lot of theories that are intuitively between the two pictures. But it should suggest that we look for something like the Dual Mandate view.</p>
<p>The second argument for it is that widely adopted in other disciplines. In most textbook presentations of game theory, the first solution concept for dynamic games that gets introduced is subgame perfect equilibrium. This idea traces back to <span class="citation" data-cites="Selten1965">Selten (<a href="#ref-Selten1965" role="doc-biblioref">1965</a>)</span>. It says that in an equilibrium, all players will adopt strategies that are in equilibrium over the whole game, and which are in equilibrium when restricted to ‘subgames’.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> The Dual Mandate View is my attempt to translate this idea into decision theoretic language. But what I want to stress here is that the idea that choices should be rational both at a time, and over time, is completely uncontroversial in game theory; it’s just presented in the textbooks as the way to solve dynamic games.</p>
<div class="no-row-height column-margin column-container"><li id="fn8"><p><sup>8</sup>&nbsp;A subgame of the original game is the set of all nodes reachable from a particular node that is in a single information set, with all the other properties and relations of those nodes held fixed.</p></li></div><p>The third argument is that decision theorists appeal to something like the Dual Mandate View already. Jack <span class="citation" data-cites="Spencer2023">Spencer (<a href="#ref-Spencer2023" role="doc-biblioref">2023</a>)</span> argues that (some versions of) Causal Decision Theory are “dynamically inconsistent”. By that he means that there are some decision trees where the target version of CDT, plus the sophisticated approach to rational choice, ends up selecting a choice that is strictly worse than an available choice. Spencer’s example relies on the unavailability of mixed strategies, and I don’t think his targets should accept that assumption. So I don’t think his overall argument works. But I do think the reasoning he uses is correct. If a sequence of choices leaves one necessarily worse off than some other available sequence of choices, that shows the first sequence was bad. But why does this show the first sequence is bad, rather than just, say, unlucky? The Dual Mandate View has an answer to this question; sequences of choices must be part of rationally playable strategies, and dominated strategies are not rationally playable.</p>
</section>
</section>
<section id="the-single-choice-principle" class="level1 page-columns page-full" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> The Single Choice Principle</h1>
<section id="equivalence-principles" class="level2 page-columns page-full" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="equivalence-principles"><span class="header-section-number">2.1</span> Equivalence Principles</h2>
<p>In <a href="#sec-dynamic-choice" class="quarto-xref">Section&nbsp;1.4</a>, I set out two ways of describing certain problems: as decision trees and as strategy tables. You might wonder whether this is just notational variation. Do the tree and its associated table represent the same problem? Or, at least, do they represent problems that have the same answers for deep reasons.</p>
<p>At first glance, the answer to this question is obviously no. The problems have different kinds of answers. Consider the following game, which I’ll call Non-Credible Threat.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<div class="no-row-height column-margin column-container"><li id="fn9"><p><sup>9</sup>&nbsp;The example is based on the example Wikipedia uses to illustrate the game-theoretic concept of a non-credible threat <span class="citation" data-cites="wiki-non-credible">Non-credible Threat (<a href="#ref-wiki-non-credible" role="doc-biblioref">2024</a>)</span>.</p></li></div><ol type="1">
<li>First, Demon chooses Left or Right.</li>
<li>Then, after Demon’s choice is revealed, Chooser selects Up or Down.</li>
<li>If Chooser selects Down, they get 1. If Chooser selects Up, they get 3 if Demon chose Left, and 0 if Demon chose Right.</li>
<li>Demon’s choice was driven by their (very accurate) prediction of Chooser’s strategy. If they predicted Chooser would adopt the strategy (Up-if-Left, Up-if-Right), they chose Left; otherwise they chose Right.</li>
</ol>
<p><a href="#fig-first-dynamic" class="quarto-xref">Figure&nbsp;1</a> is the tree for Non-Credible Threat, and <a href="#tbl-first-dynamic" class="quarto-xref">Table&nbsp;4</a> is the strategy table for it. (In the table, and from now on when discussing this game, I’ll use XY to mean the strategy (X-if-Left, Y-if-Right). So UU is the strategy of going Up whatever Demon does.) The way to read figures like <a href="#fig-first-dynamic" class="quarto-xref">Figure&nbsp;1</a> is to start at the open circle. In this case, it’s in the middle of the figure. That’s the origin of the game. Lines between nodes show what can be reached from one node. These are directional, but I won’t include arrows because the position of the origin determines the direction. The circle nodes are points where a choice is to be made, and each such node is labelled with who makes the choice. The square nodes are terminal nodes, and they are labelled with values showing Chooser’s payout if that node is reached.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-first-dynamic" class="quarto-figure quarto-figure-center anchored" width="384">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-first-dynamic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="four-prob_files/figure-html/fig-first-dynamic-1.png" class="img-fluid figure-img" width="384">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-first-dynamic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Tree Diagram of the Non-Credible Threat game.
</figcaption>
</figure>
</div>
</div>
</div>
<div id="tbl-first-dynamic" class="anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-first-dynamic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4: Strategy table for <a href="#fig-first-dynamic" class="quarto-xref">Figure&nbsp;1</a>, the Non-Credible Threat game.
</figcaption>
<div aria-describedby="tbl-first-dynamic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong>PUU</strong></th>
<th style="text-align: center;">¬<strong>PUU</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>UU</strong></td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>UD</strong></td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><strong>DU</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>DD</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Call a <em>run</em> through the game a sequence of moves from the origin to a terminal node. A run through the game is <em>rational</em> iff every move Chooser makes is rational. Now we can phrase the questions from the opening paragraph of this section a bit more precisely. What is the relationship between rational runs through trees like <a href="#fig-first-dynamic" class="quarto-xref">Figure&nbsp;1</a>, and rational strategies in tables like <a href="#tbl-first-dynamic" class="quarto-xref">Table&nbsp;4</a>? And we can see an immediate complication. In any run through the tree, Chooser makes one binary selection; but to select a strategy is to make two binary selections.</p>
<p>There is a simple way around this problem. (What I’m about to describe is too simplistic for many purposes, but it will do for ours.) Say that a tree and its associated table are <em>dynamically-strategically equivalent</em>, for short <em>ds-equivalent</em>, iff the following two conditions are met.</p>
<ol type="1">
<li>For any rational run through the tree, there is a rational strategy in the table that agrees with the run on what to do at nodes where Chooser actually made choices during the run.</li>
<li>For any rational strategy in the table, any run that follows this strategy is rational.</li>
</ol>
<p>Then say a class of tree-table pairs is ds-equivalent iff every member of the class is. With those definitions on board, we can ask a bunch of questions.</p>
<ul>
<li>Is the class of all tree-table pairs ds-equivalent?</li>
<li>Is the class of all tree-table pairs that don’t involve demons ds-equivalent?</li>
<li>Is the class of all tree-table pairs where Chooser moves at most once in each run ds-equivalent?</li>
</ul>
<p>And this list is obviously not exhaustive.</p>
<p>A positive answer to the first question would render all the other questions redundant. And a positive answer there is not completely implausible. But most decision theorists would answer it negatively. Many would say that <a href="#fig-first-dynamic" class="quarto-xref">Figure&nbsp;1</a>/<a href="#tbl-first-dynamic" class="quarto-xref">Table&nbsp;4</a> is already a counterexample. In <a href="#fig-first-dynamic" class="quarto-xref">Figure&nbsp;1</a> the only rational strategy is UD. By the time Chooser moves, there is no uncertainty; Chooser just selects the larger or the smaller value, and larger is better. On the other hand, many theories say that UU is a rational strategy in <a href="#tbl-first-dynamic" class="quarto-xref">Table&nbsp;4</a>. Evidential Decision Theory says this, but so do some Causal Decision Theories. Whether this is plausible or not turns on tricky questions about the normative significance of Weak Dominance reasoning, and on whether we should thin of Demon as perfectly accurate or just arbitrarily accurate. For what it’s worth, I think the only rational move in <a href="#tbl-first-dynamic" class="quarto-xref">Table&nbsp;4</a> is UD, so I think this pair is ds-equivalent. But I do not think that’s obvious, and I certainly don’t think it could be a premise in an argument for or against any decision theory.</p>
<p>There is a much more restricted ds-equivalence claim that can properly serve as a premise in reasoning about decision theory, and it’s time to introduce it.</p>
</section>
<section id="sec-scp-intro" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="sec-scp-intro"><span class="header-section-number">2.2</span> Introducing the Single Choice Principle</h2>
<p>In <a href="#fig-first-dynamic" class="quarto-xref">Figure&nbsp;1</a>/<a href="#tbl-first-dynamic" class="quarto-xref">Table&nbsp;4</a>, Chooser has two binary choices to make. They will make at most one on them in any run through the game. But a strategy for Chooser has to settle both questions.</p>
<p>For the rest of this paper, I’m going to primarily focus on decision trees where there is only one possible decision for Chooser to make. Chooser might not get to make it; the game might end without Chooser making a move. But Chooser knows at the start of the game that if they do have to move, exactly what the situation will be in when they move. There is nothing they can learn between the start of the game and when they move, other than the fact that they do in fact have to move. That’s to say, all the nodes where they move are epistemically indistinguishable; they are all in the same information set.</p>
<p>The point of this section is to argue that in any such game, dynamic-strategic equivalence holds. I’m going to defend what I’ll call the <strong>Single Choice Principle</strong>.</p>
<blockquote class="blockquote">
<p><strong>Single Choice Principle (SCP)</strong><br>
In any decision tree in which all the nodes where Chooser acts are in a single information set, an option is choice-worthy in the dynamic form of the game iff it is choice-worthy in the strategic form of the game.</p>
</blockquote>
<p>There are two arguments for the SCP, one semantic and one intuitive. I’ll start with the semantic.</p>
<p>Imagine the game-master asking Chooser for a strategy in the strategic form of the game. Normally, to ask someone for a strategy, one asks them a series of conditional questions: <em>If we get to here, what will you do?</em>, <em>And if we get to this other point, what will you do?</em>, and so on. Here there is just one question to ask: <em>If we get to the information set where you have to choose, what will you do?</em></p>
<p>Now imagine the game-master asking Chooser for a move in the dynamic form of the game. By the rules of the game, they have to fill in Chooser on which information set we’ve reached. So they’ll tell Chooser: <em>We’ve got to the information set where you have to choose</em>. And then they’ll ask <em>What do you do?</em></p>
<p>At a deep level, the game-master is asking the same question on each occasion. How does one figure out what to do if one reaches a situation? As <span class="citation" data-cites="RamseyGeneralProp">Ramsey (<a href="#ref-RamseyGeneralProp" role="doc-biblioref">[1929] 1990</a>)</span> says, one adds the assumption that one reached that situation “hypothetically to [one’s] stock of knowledge” (155n) and reasons on that basis about what to do. Apart from the fact that it’s hypothetical, that’s exactly the same thing one does when one learns that one is in a particular situation. One adds the fact that one is in a situation to one’s actual stock of knowledge, and reasons on that basis about what to do. It’s true that here we are thinking about practical reasoning not theoretical reasoning, but the thought that these are just the same processes, and just the same outcomes to them are rationally permissible, is just as plausible here as in Ramsey’s original case.</p>
<p>In general, the same answers are rationally permissible to the following two questions:</p>
<ol type="1">
<li>If <em>p</em>, what will you do?</li>
<li><em>p</em>, now what will you do?</li>
</ol>
<p>And the SCP is just a special case of the equivalence of these questions. Here <em>p</em> is that Chooser has reached the one-and-only information set in the tree where they must choose.</p>
<p>The intuitive argument comes from thinking about how strange violations of the SCP sound in practice. Here it’s helpful to have an example. Our first example game, which I’ll call Four-Three-Closed, has three stages. At stage one, Demon predicts whether Chooser will play Up or Down at stage three (if it is reached). Demon’s predictions are (and are believed by Chooser to be) arbitrarily accurate no matter what Chooser does. At stage two, if Demon predicts Up, a fair coin is flipped. If it lands Heads, the game ends, and Chooser gets 0. If lands Tails, or Demon predicts Down, we proceed to stage 3. At that point, Chooser selects Up or Down, and their payouts are as follows:</p>
<ul>
<li>If Demon predicted incorrectly, they get 0.</li>
<li>If Demon correctly predicted that they would choose Up, they get 4.</li>
<li>If Demon correctly predicted that they would choose Down, they get 3.</li>
</ul>
<p><a href="#fig-four-three-closed" class="quarto-xref">Figure&nbsp;2</a> shows the tree for the game, and <a href="#tbl-four-three-closed" class="quarto-xref">Table&nbsp;5</a> shows the payouts for each possible move by Demon, Chooser, and Nature (i.e., the coin).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-four-three-closed" class="quarto-figure quarto-figure-center anchored" width="384">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-four-three-closed-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="four-prob_files/figure-html/fig-four-three-closed-1.png" class="img-fluid figure-img" width="384">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-four-three-closed-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Tree Diagram of the Four-Three-Closed game.
</figcaption>
</figure>
</div>
</div>
</div>
<div id="tbl-four-three-closed" class="anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-four-three-closed-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;5: The game table for <a href="#fig-four-three-closed" class="quarto-xref">Figure&nbsp;2</a>
</figcaption>
<div aria-describedby="tbl-four-three-closed-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<colgroup>
<col style="width: 14%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 22%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong>Up-Heads</strong></th>
<th style="text-align: center;"><strong>Up-Tails</strong></th>
<th style="text-align: center;"><strong>Down-Heads</strong></th>
<th style="text-align: center;"><strong>Down-Tails</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>Up</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>Down</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">3</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>There is one extra bit of notation in <a href="#fig-four-three-closed" class="quarto-xref">Figure&nbsp;2</a>; the dashed lines around the two nodes where Chooser acts. These lines mean that when Chooser gets to one of those nodes, all the know is that they are somewhere in the set; they do not know which node they are at. If they do get there, they’ll know that they are not at the left-most branch of the tree, so they are facing the table shown by <a href="#tbl-four-three-closed-good" class="quarto-xref">Table&nbsp;6</a>.</p>
<div id="tbl-four-three-closed-good" class="anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-four-three-closed-good-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;6: The strategy table for <a href="#fig-four-three-closed" class="quarto-xref">Figure&nbsp;2</a> if Chooser knows they must choose.
</figcaption>
<div aria-describedby="tbl-four-three-closed-good-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong>Up-Tails</strong></th>
<th style="text-align: center;"><strong>Down-Heads</strong></th>
<th style="text-align: center;"><strong>Down-Tails</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>Up</strong></td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>Down</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">3</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Conditional on playing Up, they’ll have got some weak evidence against Demon’s reliability, but that won’t make a major difference if they started out thinking that Demon was arbitrarily accurate. So whether Chooser reaches <a href="#tbl-four-three-closed-good" class="quarto-xref">Table&nbsp;6</a> as part of <a href="#fig-four-three-closed" class="quarto-xref">Figure&nbsp;2</a>, or it was the first interaction they have with Demon shouldn’t make a difference to how they act.</p>
<p>Despite that, imagine Chooser does violate SCP. In particular, imagine they are disposed to play Up in <a href="#tbl-four-three-closed-good" class="quarto-xref">Table&nbsp;6</a>, and Down in <a href="#tbl-four-three-closed" class="quarto-xref">Table&nbsp;5</a>. To make vivid how odd this is, we’ll also imagine that Chooser is talking to the Game-Master while they wait for Demon’s prediction.</p>
<blockquote class="blockquote">
<p><strong>Chooser</strong>: Do they normally take this long?<br>
<strong>Game-Master</strong>: Sometimes. Predictions are hard.<br>
<strong>C</strong>: Well, as long as they get it right.<br>
<strong>GM</strong>: What are you thinking of playing? You know, if you have to play?<br>
<strong>C</strong>: I think Up. Four beats three, and Demon is almost always right.<br>
<strong>GM</strong>: Makes sense.<br>
<strong>C</strong>: Hey look, I’ve got a meeting in a few minutes, is there anything we can do to hurry them along?<br>
<strong>GM</strong>: Nah, but if you like just tell me what you’ll play, and if it gets that far I’ll put in the move for you.<br>
<strong>C</strong>: Thanks, that’s great. I’m playing Down.<br>
<strong>GM</strong>: Why did you change your mind?<br>
<strong>C</strong>: What do you mean? I didn’t change my mind.<br>
<strong>GM</strong>: You just said Up, now you’re playing Down.<br>
<strong>C</strong>: That was a different question. Earlier I thought I’d have to play after it was revealed that I had a move to make. Now I’m just putting in a move that will be played if I have a move to make. Totally different.<br>
<strong>GM</strong>: So if you stayed, you would play Up?<br>
<strong>C</strong>: For sure. But I want you to play Down.</p>
</blockquote>
<p>This sounds incoherent to me. It’s not that I think either move is wrong. In fact I’m going to argue that both Up and Down are permissible moves. It’s that I think Chooser is answering the same question, what will you, a rational player, do if you have to choose, in two different ways depending on how it is asked. Coherence requires that Chooser answer that question the same way every time, and this incoherence is a sign that something’s deeply wrong with Chooser.</p>
<p>This argument for the SCP is similar to the depragmatised version of the Dutch Book argument that David <span class="citation" data-cites="Christensen1996">Christensen (<a href="#ref-Christensen1996" role="doc-biblioref">1996</a>)</span> offers. The point, he says, of Dutch Book arguments is not that the victim loses money. There are ways to avoid the loss by strategic betting, and even if there weren’t, this would show a practical failing not a theoretical flaw. What Dutch Book arguments do show, at least if they are successful, is that the victim is incoherent in a particular way. They value the same thing differently under two different descriptions. And they are even in a position to see, if they think about it, that these descriptions pick out the same thing.</p>
<p>That’s what goes on in this dialogue. Chooser is asked the same question, what will you do if it is your move, twice. When they are asked it in the context of imagining themselves actually choosing, they say Up. When they are asked in the context of giving Game-Master a move in advance, they say Down. But it’s the same question each time.</p>
<p>There are two other arguments for the SCP that I don’t want to lean quite as heavily on.</p>
<p>One is that the SCP is just an instance of the Sure-Thing Principle, and the Sure-Thing Principle is true. There are two problems with this argument. One is that I want to deploy the SCP against theories that go out of their way to reject Sure-Thing. If the only argument for the SCP was from Sure-Thing, these uses would be blatantly question-begging. The other is that it’s not clear that my preferred theory, Gamified Decision Theory (GDT), actually endorses Sure-Thing in full generality. The arguments that Dmitri <span class="citation" data-cites="Gallownd">Gallow (<a href="#ref-Gallownd" role="doc-biblioref">n.d.-b</a>)</span> gives for the inconsistency of Causal Decision Theory and Sure-Thing might generalise to GDT as well.</p>
<p>Another argument is that SCP follows from the more general principle of dynamic-strategic equivalence. But arguing for the SCP this way would require arguing that only UpUp is rational in <a href="#tbl-first-dynamic" class="quarto-xref">Table&nbsp;4</a>. And while that might be right, I don’t want to rest the whole paper on it.</p>
<p>It’s better to argue from the Ramsey test, and from the intuition that Chooser is being incoherent in the above dialogue, and those are the two arguments I’ll rely on in what follows.</p>
</section>
</section>
<section id="applications" class="level1 page-columns page-full" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Applications</h1>
<section id="evidential-decision-theory" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="evidential-decision-theory"><span class="header-section-number">3.1</span> Evidential Decision Theory</h2>
<p>Evidential Decision Theory (EDT) is inconsistent with the Single Choice Principle. <a href="#fig-four-three-closed" class="quarto-xref">Figure&nbsp;2</a> can be used to show this, but it’s a little clearer to work with a variant example. Change the case so that if Chooser has a choice, they get 4 if they choose Up, and 3 if they choose Down, whatever Demon predicted. So the game tree looks like <a href="#fig-four-three-open" class="quarto-xref">Figure&nbsp;3</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-four-three-open" class="quarto-figure quarto-figure-center anchored" width="384">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-four-three-open-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="four-prob_files/figure-html/fig-four-three-open-1.png" class="img-fluid figure-img" width="384">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-four-three-open-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Tree Diagram of the Four-Three-Open game.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Before Chooser knows whether they must make a choice, the strategy table looks like <a href="#tbl-four-three-open-early" class="quarto-xref">Table&nbsp;8 (a)</a>; at the time they have to choose it looks like <a href="#tbl-four-three-open-late" class="quarto-xref">Table&nbsp;8 (b)</a>. Note that the values in <a href="#tbl-four-three-open-early" class="quarto-xref">Table&nbsp;8 (a)</a> are expected values, since EDT says that once we conditionalise on what Demon does, all that matters is expected value.</p>
<div id="tbl-panel" class="quarto-layout-panel anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-panel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7: Two strategy tables for <a href="#fig-four-three-open" class="quarto-xref">Figure&nbsp;3</a>.
</figcaption>
<div aria-describedby="tbl-panel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="tbl-panel" style="flex-basis: 50.0%;justify-content: center;">
<div id="tbl-four-three-open-early" class="anchored">
<figure class="quarto-float quarto-subfloat-tbl figure">
<figcaption class="quarto-float-caption-top quarto-subfloat-caption quarto-subfloat-tbl" id="tbl-four-three-open-early-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) The strategy table at game start.
</figcaption>
<div aria-describedby="tbl-four-three-open-early-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong>PUp</strong></th>
<th style="text-align: center;"><strong>PDown</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>Up</strong></td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>Down</strong></td>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">3</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="tbl-panel" style="flex-basis: 50.0%;justify-content: center;">
<div id="tbl-four-three-open-late" class="anchored">
<figure class="quarto-float quarto-subfloat-tbl figure">
<figcaption class="quarto-float-caption-top quarto-subfloat-caption quarto-subfloat-tbl" id="tbl-four-three-open-late-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) The strategy table at choice time.
</figcaption>
<div aria-describedby="tbl-four-three-open-late-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong>PUp</strong></th>
<th style="text-align: center;"><strong>PDown</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>Up</strong></td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>Down</strong></td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">3</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
</div>
</div>
</figure>
</div>
<p>EDT, like most other theories, says to choose Up in <a href="#tbl-four-three-open-late" class="quarto-xref">Table&nbsp;8 (b)</a>. But <a href="#tbl-four-three-open-early" class="quarto-xref">Table&nbsp;8 (a)</a> is a Newcomb problem, and EDT says to choose Down. That pair of views is, according to SCP, incoherent. EDT recommends rational Chooser give different answers to the following two questions.</p>
<ul>
<li>Assuming you have to choose, what do you do?</li>
<li>What will you do if you have to choose?</li>
</ul>
<p>Whatever answer one gives to either question, rational Chooser gives to the other question as well.</p>
<p>The point here is not that EDT recommends a dominated option in <a href="#tbl-four-three-open-early" class="quarto-xref">Table&nbsp;8 (a)</a>. This argument doesn’t work against other views that recommend dominated options like Levinstein and Soares’s Functional Decision Theory <span class="citation" data-cites="LevinsteinSoares2020">(<a href="#ref-LevinsteinSoares2020" role="doc-biblioref">Levinstein and Soares 2020</a>)</span>. After all, they answer these two questions the same way. And the objection is that EDT offers different answers to questions that should get the same answer.</p>
<p>Nor is it just that EDT recommends paying to avoid information. At the start of the game, EDT thinks that Down is worth 1 more than Up, and they’ll choose Up if they get the information that they must choose, and they will almost certainly choose. So given a choice between paying nearly 1 to choose now, and choosing after they learn what whether they have to choose, they will pay to avoid learning the information. That’s a familiar worry for EDT, and <span class="citation" data-cites="AhmedPrice2012">Ahmed and Price (<a href="#ref-AhmedPrice2012" role="doc-biblioref">2012</a>)</span> have a response to it.</p>
<p>Rather, the worry is that the particular information Chooser gets in this case, namely that they have to choose, should not make a difference to how they choose. When one is thinking of making a choice that will only be effective if <em>p</em>, one should assume <em>p</em>, and choose as if that assumption was in place. And that’s exactly what EDT does not do in <a href="#fig-four-three-open" class="quarto-xref">Figure&nbsp;3</a>.</p>
</section>
<section id="buchak-on-risk" class="level2 page-columns page-full" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="buchak-on-risk"><span class="header-section-number">3.2</span> Buchak on Risk</h2>
<p>Most decision theorists think treat the question of how to make decisions when probabilities and utilities are precise, states are known to be causally independent of actions, and there are no demons around, as a solved problem. In those cases the simple and elegant theory from <a href="#sec-demons" class="quarto-xref">Section&nbsp;1.1</a> is widely thought to be correct. One should simply maximise expected utility.</p>
<p>The most important alternative to the standard view is the risk-sensitive view developed by Lara <span class="citation" data-cites="BuchakRisk">Buchak (<a href="#ref-BuchakRisk" role="doc-biblioref">2013</a>)</span>.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> The core of Buchak’s theory is a non-standard way of valuing a gamble. For simplicity, we’ll focus on gambles with finitely many outcomes. Associate a gamble with a random variable <em>O</em>, which takes values <em>o</em><sub>1</sub>, …, <em>o<sub>n</sub></em>, where <em>o<sub>j</sub></em>&nbsp;&gt;&nbsp;<em>o<sub>i</sub></em> iff <em>j</em>&nbsp;&gt;&nbsp;<em>i</em>. Buchak says that the risk-weighted expected utility of <em>O</em> is given by this formula, where <em>r</em> is the agent’s risk-weighting function.</p>
<div class="no-row-height column-margin column-container"><li id="fn10"><p><sup>10</sup>&nbsp;Buchak’s view builds on earlier work by John <span class="citation" data-cites="Quiggin1982">Quiggin (<a href="#ref-Quiggin1982" role="doc-biblioref">1982</a>)</span> which was designed to model how people actually make choices in some famous choice situations.</p></li></div><p><span class="math display">\[
REU(O) = o_1 + \sum_{i = 2}^n r(\Pr(O \geq o_i))(o_i - o_{i-1})
\]</span></p>
<p>The decision rule then is simple: choose the gamble with the highest REU.</p>
<p>The key notion here is the function <em>r</em>, which measures Chooser’s attitudes to risk. If <em>r</em> is the identity function, then this definition becomes a slightly non-standard way of defining expected utility. Buchak allows it to be much more general. The key constraints are that <span class="math inline">\(r\)</span> is monotonically increasing, that <em>r</em>(0)&nbsp;=&nbsp;0 and <em>r</em>(1)&nbsp;=&nbsp;1. In general, if <em>r</em>(<em>x</em>)&nbsp;&lt;&nbsp;<em>x</em>, Chooser is some intuitive sense more risk-averse than an expected utility maximiser, while if <em>r</em>(<em>x</em>)&nbsp;&gt;&nbsp;<em>x</em>, Chooser is more risk-seeking. The former case is more relevant to everyday intuitions, and it’s what I’ll focus on. Indeed, I’ll focus on the case where <em>r</em>(<em>x</em>)&nbsp;=&nbsp;<em>x</em><sup>2</sup>, which is also a case Buchak uses a lot.</p>
<p>There are a number of good reasons to like Buchak’s theory. Standard expected utility theory explains risk-aversion in a surprisingly roundabout way. Risk-aversion simply falls out as a consequence of the fact that at almost all points, almost all goods have a declining marginal utiility. This is theoretically elegant - risk-aversion and relative satiation are explained in a single framework - but has a number of downsides. For one thing, it doesn’t allow rational agents to have certain kinds of risk-aversion, such as the kind described by <span class="citation" data-cites="Allais1953">Allais (<a href="#ref-Allais1953" role="doc-biblioref">1953</a>)</span>. For another, it doesn’t seem like risk-aversion just is the same thing as the declining marginal utility of goods. Buchak’s theory, by putting attitudes to risk into <em>r</em>, avoids both these problems.</p>
<p>Unfortunately, Buchak’s theory is inconsistent with the Single Choice Principle. I’ll show this for the case <em>r</em>(<em>x</em>)&nbsp;=&nbsp;<em>x</em><sup>2</sup>, but it’s not much harder to produce similar examples for any value of <em>r</em> other than <em>r</em>(<em>x</em>)&nbsp;=&nbsp;<em>x</em>. In <a href="#fig-buchak" class="quarto-xref">Figure&nbsp;4</a> at stage 1 a fair die will be rolled. If it lands 1 or 2, Nature moves Left; if it lands 3 or 4, Nature moves Middle; otherwise, Nature moves Right. If Nature moves Left, the game ends, and Chooser gets 1. Otherwise Chooser is told that Nature did not move Left, but not whether they moved Middle or Right. If Chooser selects Down, they get 1. If Chooser selects Up, they get 5 if Nature moved Middle, and 0 otherwise.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-buchak" class="quarto-figure quarto-figure-center anchored" width="384">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-buchak-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="four-prob_files/figure-html/fig-buchak-1.png" class="img-fluid figure-img" width="384">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-buchak-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Tree Diagram of the counterexample to REU.
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#tbl-buchak-early" class="quarto-xref">Table&nbsp;8 (a)</a> shows the strategic table of <a href="#fig-buchak" class="quarto-xref">Figure&nbsp;4</a>, and <a href="#tbl-buchak-late" class="quarto-xref">Table&nbsp;8 (b)</a> shows the decision table Chooser faces at the time they have to choose.</p>
<div id="tbl-panel" class="quarto-layout-panel anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-panel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;8: Two strategy tables for <a href="#fig-buchak" class="quarto-xref">Figure&nbsp;4</a>.
</figcaption>
<div aria-describedby="tbl-panel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="tbl-panel" style="flex-basis: 50.0%;justify-content: center;">
<div id="tbl-buchak-early" class="anchored">
<figure class="quarto-float quarto-subfloat-tbl figure">
<figcaption class="quarto-float-caption-top quarto-subfloat-caption quarto-subfloat-tbl" id="tbl-buchak-early-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) The strategy table at game start.
</figcaption>
<div aria-describedby="tbl-buchak-early-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong>Left</strong></th>
<th style="text-align: center;"><strong>Middle</strong></th>
<th style="text-align: center;"><strong>Right</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>Up</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>Down</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="tbl-panel" style="flex-basis: 50.0%;justify-content: center;">
<div id="tbl-buchak-late" class="anchored">
<figure class="quarto-float quarto-subfloat-tbl figure">
<figcaption class="quarto-float-caption-top quarto-subfloat-caption quarto-subfloat-tbl" id="tbl-buchak-late-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) The strategy table at choice time.
</figcaption>
<div aria-describedby="tbl-buchak-late-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong>Middle</strong></th>
<th style="text-align: center;"><strong>Right</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>Up</strong></td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>Down</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
</div>
</div>
</figure>
</div>
<p>In <a href="#tbl-buchak-early" class="quarto-xref">Table&nbsp;8 (a)</a>, the REU of Down is 1 (since that’s the only possible outcome), and the REU of Up is 8/9. There is a 2/3 chance of getting at least 1, so that’s worth 4/9, and there’s a 1/3 chance of getting another 4, so that’s also worth 4/9, and adding those gives 8/9. So the optimal strategy, according to REU theory, is Down. That is, REU says to prefer the strategy <em>Choose Down if you have to choose</em> to the strategy <em>Choose Up if you have to choose</em>.</p>
<p>But if we get to the choice point, we’re at <a href="#tbl-buchak-late" class="quarto-xref">Table&nbsp;8 (b)</a>. And in that table the REU of Up is 5 times 1/4, i.e., 5/4. So at that point, REU says to choose Up. What REU says to do if you have to choose is different to which strategy it chooses for the one and only point you have to choose at. This is incoherent, so the theory is false.</p>
<p>The point is not that this is a completely novel argument; on it’s own it’s not that much more persuasive than earlier objections to Buchak’s view. What I want to stress here is the connection to puzzles about demons. The same principle that provided an objection to EDT also provides an objection to Buchak’s REU theory. This raises a particularly tricky problem for EDT. What could possibly motivate the combination of EDT with orthodox expected utility theory?</p>
<p>If our aim as decision theorists is to maximise agreement between theory and intuitions about cases, we perhaps should endorse EDT over CDT, but we should also endorse Buchak’s theory over orthodox expected utility theory. If our aim instead is to have a theory that is consistent with intuitions about decision theoretic principles, there are lots of reasons to reject Buchak’s theory. It violates the Sure Thing Principle, and its weaker cousin, the Single Choice Principle. It violates the principle that one shouldn’t pass up free information <span class="citation" data-cites="CampbellMooreSalow2020">(<a href="#ref-CampbellMooreSalow2020" role="doc-biblioref">Campbell-Moore and Salow 2020</a>)</span>. It violates various sensible principles of dynamic choice <span class="citation" data-cites="Briggs2015 Thoma2019">(<a href="#ref-Briggs2015" role="doc-biblioref">Briggs 2015</a>; <a href="#ref-Thoma2019" role="doc-biblioref">Thoma 2019</a>)</span>. But EDT violates all these principles too. It’s really hard to see the starting point, the initial set of premises, that leads to the conclusion that orthodox expected utility, plus EDT, is the right combination of views.</p>
<p>This isn’t just a problem for EDT. Every theory that starts with expected value maximisation, then adds some complications to deal with demons, owes an answer to the following question. Why is this theory better than its counterpart that starts with Buchak’s theory, and adds the same demonic complications? It can’t be that it does better at capturing intuitions about cases, since the Buchakian theory wins on that score. It has to be that it satisfies more important principles. But the thing about principles is that they have to be, well, principled. They can’t be things that get dropped as soon as the going gets tough or a demon turns up. If the reason to reject the Buchakian counterpart to one’s theory is that the alternative theory says free evidence should be shunned, or the Sure Thing Principle abandoned, one must consistently say that free evidence should be valued, or the Sure Thing Principle preserved. This turns out to be a very hard standard to meet.</p>
<p>One big benefit of Gamified Decision Theory is that it has an answer to this compulsory question. GDT preserves the Single Choice Principle, and its Buchakian counterpart does not.</p>
</section>
<section id="linearity" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="linearity"><span class="header-section-number">3.3</span> Linearity</h2>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="four-prob_files/figure-html/chunk-b-1.png" class="img-fluid figure-img" width="384"></p>
<figcaption>Tree Diagram of the Four-Three Closed game</figcaption>
</figure>
</div>
</div>
</div>



</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Ahmed2014" class="csl-entry" role="listitem">
Ahmed, Arif. 2014. <em>Evidence, Decision and Causality</em>. Cambridge: <span>C</span>ambridge <span>U</span>niversity <span>P</span>ress.
</div>
<div id="ref-AhmedPrice2012" class="csl-entry" role="listitem">
Ahmed, Arif, and Huw Price. 2012. <span>“Arntzenius on ‘Why Ain’cha Rich?’.”</span> <em>Erkenntnis</em> 77 (1): 15–30. doi: <a href="https://doi.org/10.1007/s10670-011-9355-2">10.1007/s10670-011-9355-2</a>.
</div>
<div id="ref-Allais1953" class="csl-entry" role="listitem">
Allais, M. 1953. <span>“Le Comportement de l’homme Rationnel Devant Le Risque: Critique Des Postulats Et Axiomes de l’ecole Americaine.”</span> <em>Econometrica</em> 21 (4): 503–46. doi: <a href="https://doi.org/10.2307/1907921">10.2307/1907921</a>.
</div>
<div id="ref-Blackwell1951" class="csl-entry" role="listitem">
Blackwell, David. 1951. <span>“Comparison of Experiments.”</span> <em>Proceedings of the Berkeley Symposium on Mathematical Statistics and Probability</em> 2 (1): 93–102.
</div>
<div id="ref-BradleySteele2016" class="csl-entry" role="listitem">
Bradley, Seamus, and Katie Steele. 2016. <span>“Can Free Evidence Be Bad? Value of Informationfor the Imprecise Probabilist.”</span> <em>Philosophy of Science</em> 83 (1): 1–28. doi: <a href="https://doi.org/10.1086/684184">10.1086/684184</a>.
</div>
<div id="ref-Briggs2015" class="csl-entry" role="listitem">
Briggs, Ray. 2015. <span>“Costs of Abandoning the Sure-Thing Principle.”</span> <em>Canadian Journal of Philosophy</em> 45 (5): 827–40. doi: <a href="https://doi.org/10.1080/00455091.2015.1122387">10.1080/00455091.2015.1122387</a>.
</div>
<div id="ref-BuchakRisk" class="csl-entry" role="listitem">
Buchak, Lara. 2013. <em>Risk and Rationality</em>. Oxford: Oxford University Press.
</div>
<div id="ref-CampbellMooreSalow2020" class="csl-entry" role="listitem">
Campbell-Moore, Catrin, and Bernhard Salow. 2020. <span>“Avoiding Risk and Avoiding Evidence.”</span> <em>Australasian Journal of Philosophy</em> 98 (3): 495–515. doi: <a href="https://doi.org/10.1080/00048402.2019.1697305">10.1080/00048402.2019.1697305</a>.
</div>
<div id="ref-Chang2002" class="csl-entry" role="listitem">
Chang, Ruth. 2002. <span>“The Possibility of Parity.”</span> <em>Ethics</em> 112 (4): 659–88. doi: <a href="https://doi.org/10.1086/339673">10.1086/339673</a>.
</div>
<div id="ref-Chang2015" class="csl-entry" role="listitem">
———. 2015. <span>“Value Incomparability and Incommensurability.”</span> In <em>The Oxford Handbook of Value Theory</em>, edited by Iwao Hirose and Jonas Olson, 205–24. Oxford: Oxford University Press. doi: <a href="https://doi.org/10.1093/oxfordhb/9780199959303.013.0012">10.1093/oxfordhb/9780199959303.013.0012</a>.
</div>
<div id="ref-ChoKreps1987" class="csl-entry" role="listitem">
Cho, In-Koo, and David M. Kreps. 1987. <span>“Signalling Games and Stable Equilibria.”</span> <em>The Quarterly Journal of Economics</em> 102 (2): 179–221. doi: <a href="https://doi.org/10.2307/1885060">10.2307/1885060</a>.
</div>
<div id="ref-Christensen1996" class="csl-entry" role="listitem">
Christensen, David. 1996. <span>“Dutch-Book Arguments <span>D</span>e-Pragmatized: Epistemic Consistency for Partial Believers.”</span> <em>Journal of Philosophy</em> 93 (9): 450–79. doi: <a href="https://doi.org/10.2307/2940893">10.2307/2940893</a>.
</div>
<div id="ref-Das2023" class="csl-entry" role="listitem">
Das, Nilanjan. 2023. <span>“The Value of Biased Information.”</span> <em>British Journal for the Philosophy of Science</em> 74 (1): 25–55. doi: <a href="https://doi.org/10.1093/bjps/axaa003">10.1093/bjps/axaa003</a>.
</div>
<div id="ref-DorrEtAl2023" class="csl-entry" role="listitem">
Dorr, Cian, Jacob M. Nebel, and Jake Zuehl. 2023. <span>“The Case for Comparability.”</span> <em>Noûs</em> 57 (2): 414–53. doi: <a href="https://doi.org/10.1111/nous.12407">10.1111/nous.12407</a>.
</div>
<div id="ref-Elga2010" class="csl-entry" role="listitem">
Elga, Adam. 2010. <span>“Subjective Probabilities Should Be Sharp.”</span> <em>Philosophers’ Imprint</em> 10: 1–11.
</div>
<div id="ref-Fuscond" class="csl-entry" role="listitem">
Fusco, Melissa. n.d. <span>“Absolution of a Causal Decision Theorist.”</span> <em>No<span>û</span>s</em>. doi: <a href="https://doi.org/10.1111/nous.12459">10.1111/nous.12459</a>. Early view.
</div>
<div id="ref-Gallowndppq" class="csl-entry" role="listitem">
Gallow, J. Dmitri. n.d.-a. <span>“Counterfactual Decision Theory Is Causal Decision Theory.”</span> Pacific Philosophical Quarterly. doi: <a href="https://doi.org/10.1111/papq.12451">10.1111/papq.12451</a>.
</div>
<div id="ref-Gallownd" class="csl-entry" role="listitem">
———. n.d.-b. <span>“The Sure Thing Principle Leads to Instability.”</span> Philosophical Quarterly. <a href="https://philpapers.org/archive/GALTST-2.pdf">https://philpapers.org/archive/GALTST-2.pdf</a>.
</div>
<div id="ref-GibbardHarper1978" class="csl-entry" role="listitem">
Gibbard, Allan, and William Harper. 1978. <span>“Counterfactuals and Two Kinds of Expected Utility.”</span> In <em>Foundations and Applications of Decision Theory</em>, edited by C. A. Hooker, J. J. Leach, and E. F. McClennen, 125–62. Dordrecht: Reidel.
</div>
<div id="ref-Gustafsson2022" class="csl-entry" role="listitem">
Gustafsson, Johan E. 2022. <em>Money-Pump Arguments</em>. Cambridge: Cambridge University Press.
</div>
<div id="ref-Hedden2023" class="csl-entry" role="listitem">
Hedden, Brian. 2023. <span>“Counterfactual Decision Theory.”</span> <em>Mind2</em> 132 (527): 730–61. doi: <a href="https://doi.org/10.1093/mind/fzac060">10.1093/mind/fzac060</a>.
</div>
<div id="ref-Joyce2010" class="csl-entry" role="listitem">
Joyce, James M. 2010. <span>“A Defence of Imprecise Credences in Inference and Decision Making.”</span> <em>Philosophical Perspectives</em> 24 (1): 281–323. doi: <a href="https://doi.org/10.1111/j.1520-8583.2010.00194.x">10.1111/j.1520-8583.2010.00194.x</a>.
</div>
<div id="ref-Keynes1921" class="csl-entry" role="listitem">
Keynes, John Maynard. 1921. <em>Treatise on Probability</em>. London: Macmillan.
</div>
<div id="ref-Ledermannd" class="csl-entry" role="listitem">
Lederman, Harvey. 2024. <span>“Of Marbles and Matchsticks.”</span> <em>Oxford Studies in Epistemology</em>.
</div>
<div id="ref-LevinsteinSoares2020" class="csl-entry" role="listitem">
Levinstein, Benjamin Anders, and Nate Soares. 2020. <span>“Cheating Death in Damascus.”</span> <em>Journal of Philosophy</em> 117 (5): 237–66. doi: <a href="https://doi.org/10.5840/jphil2020117516">10.5840/jphil2020117516</a>.
</div>
<div id="ref-Lewis1979en" class="csl-entry" role="listitem">
Lewis, David. 1979. <span>“Prisoners’ Dilemma Is a <span>N</span>ewcomb Problem.”</span> <em>Philosophy and Public Affairs</em> 8 (3): 235–40.
</div>
<div id="ref-Nethnd" class="csl-entry" role="listitem">
Neth, Sven. n.d. <span>“Rational Aversion to Information.”</span> British Journal for the Philosophy of Science. doi: <a href="https://doi.org/10.1086/727772">10.1086/727772</a>. Early view.
</div>
<div id="ref-wiki-non-credible" class="csl-entry" role="listitem">
Non-credible Threat. 2024. <span>“Non-Credible Threat — <span>W</span>ikipedia<span>,</span> the Free Encyclopedia.”</span> <a href="https://en.wikipedia.org/w/index.php?title=Non-credible_threat&amp;oldid=1180356705">https://en.wikipedia.org/w/index.php?title=Non-credible_threat&amp;oldid=1180356705</a>. [Online; accessed 7-March-2024].
</div>
<div id="ref-Nozick1969" class="csl-entry" role="listitem">
Nozick, Robert. 1969. <span>“Newcomb’s Problem and Two Principles of Choice.”</span> In <em>Essays in Honor of Carl <span>G</span>. Hempel: A Tribute on the Occasion of His Sixty-Fifth Birthday. Hempel: A Tribute on the Occasion of His Sixty-Fifth Birthday</em>, edited by Nicholas Rescher, 114–46. Riedel: Springer.
</div>
<div id="ref-Pearce1984" class="csl-entry" role="listitem">
Pearce, David G. 1984. <span>“Rationalizable Strategic Behavior and the Problem of Perfection.”</span> <em>Econometrica</em> 52 (4): 1029–50. doi: <a href="https://doi.org/10.2307/1911197">10.2307/1911197</a>.
</div>
<div id="ref-Quiggin1982" class="csl-entry" role="listitem">
Quiggin, John. 1982. <span>“A Theory of Anticipated Utility.”</span> <em>Journal of Economic Behavior &amp; Organization</em> 3 (4): 323–43. doi: <a href="https://doi.org/10.1016/0167-2681(82)90008-7">10.1016/0167-2681(82)90008-7</a>.
</div>
<div id="ref-RamseyGeneralProp" class="csl-entry" role="listitem">
Ramsey, Frank. (1929) 1990. <span>“General Propositions and Causality.”</span> In <em>Philosophical Papers</em>, edited by D. H. Mellor, 145–63. Cambridge: Cambridge University Press.
</div>
<div id="ref-Risse2000" class="csl-entry" role="listitem">
Risse, Mathias. 2000. <span>“What Is Rational about Nash Equilibria?”</span> <em>Synthese</em> 124 (3): 361–84. doi: <a href="https://doi.org/10.1023/a:1005259701040">10.1023/a:1005259701040</a>.
</div>
<div id="ref-Selten1965" class="csl-entry" role="listitem">
Selten, Reinhard. 1965. <span>“Spieltheoretische Behandlung Eines Oligopolmodells Mit Nachfragetr<span>ä</span>gheit.”</span> <em>Zeitschrift f<span>ü</span>r Die Gesamte Staatswissenschaft</em> 121 (2): 301–24.
</div>
<div id="ref-Spencer2023" class="csl-entry" role="listitem">
Spencer, Jack. 2023. <span>“Can It Be Irrational to Knowingly Choose the Best?”</span> <em>Australasian Journal of Philosophy</em> 101 (1): 128–39. doi: <a href="https://doi.org/10.1080/00048402.2021.1958880">10.1080/00048402.2021.1958880</a>.
</div>
<div id="ref-Stalnaker1999" class="csl-entry" role="listitem">
Stalnaker, Robert. 1999. <span>“Extensive and Strategic Forms: Games and Models for Games.”</span> <em>Research in Economics</em> 53 (3): 293–319. doi: <a href="https://doi.org/10.1006/reec.1999.0200">10.1006/reec.1999.0200</a>.
</div>
<div id="ref-Thoma2019" class="csl-entry" role="listitem">
Thoma, Johanna. 2019. <span>“Risk Aversion and the Long Run.”</span> <em>Ethics</em> 129 (2): 230–53. doi: <a href="https://doi.org/10.1086/699256">10.1086/699256</a>.
</div>
<div id="ref-Walley1991" class="csl-entry" role="listitem">
Walley, Peter. 1991. <em>Statisical Reasoning with Imprecise Probabilities</em>. London: Chapman &amp; Hall.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>