---
title: "Citations, Then and Now"
abstract: |
  This note looks at articles that were relatively widely cited soon after publication, and asks how often they have been cited in recent years. The main finding is that between 1980 and the late 1990s, many articles that were widely cited at the time have largely disappeared from the citation record in recent times.
date: September 3 2024
author:
  - name: Brian Weatherson 
    url: http://brian.weatherson.org
    affiliation: University of Michigan
    affiliation_url: https://umich.edu
    orcid_id: 0000-0002-0830-141X
categories:
  - history of analytic
  - in progress
  - unpublished
pdf-engine: xelatex
draft: true
execute:
  echo: false
  warning: false
format:
  html:
    fig-format: svg
    fig-height: 9
    fig-width: 12
    fig-dpi: 300
    fig-responsive: true
    fontsize: 1.1rem
  pdf:
    fig-format: pdf
    include-after-body: 
        text: |
          \noindent Published online in September 2024.
---

```{r}
#| label: loader
#| cache: false

require(tidyverse)
require(slider)
require(stringr)
require(knitr)

if(knitr::is_latex_output()) {
  knitr::opts_chunk$set(dev = 'cairo_pdf')
}

# Graph Themes
old <- theme_set(theme_minimal())
theme_set(old)
theme_update(plot.title = element_text(family = "Scala Pro", size = 24, face = "bold"),
             plot.subtitle = element_text(family = "Scala Sans Pro", size = 20),
             axis.text = element_text(family = "Scala Sans Pro", size = 18),
             plot.background = element_rect(fill = "#F9FFFF"),
             panel.background = element_rect(fill = "white"),
             legend.background = element_rect(fill = "#F9FFFF"),
             panel.grid = element_line(color = "grey92"),
             legend.text = element_text(family = "Scala Sans Pro", size = 20),
             strip.text = element_text(family = "Scala Sans Pro", size = 20),
             legend.key.spacing.y = unit(0.5, 'lines'),
             legend.key.spacing.x = unit(1, 'cm')
  )

if(knitr::is_latex_output()) {
theme_update(plot.title = element_text(family = "Europa-Bold", size = 14),
             plot.subtitle = element_text(family = "EB Garamond", size = 11),
             axis.text = element_text(family = "EB Garamond", size = 10),
             plot.background = element_rect(fill = "white"),
             panel.background = element_rect(fill = "white"),
             legend.background = element_rect(fill = "white"),
             panel.grid = element_line(color = "grey92"),
             legend.text = element_text(family = "EB Garamond", size = 11),
             strip.text = element_text(family = "EB Garamond", size = 12),
             legend.key.spacing.y = unit(-0.3, 'lines'),
             legend.key.spacing.x = unit(0, 'cm')
  )

}
```

```{r}
#| lable: mainscripts
#| cache: false

require(tidyverse)
require(slider)
require(stringr)
require(lsa)

load("philo_bib_fix.RData")
load("philo_cite_with_jp.RData")

start_year <- 1965
end_year <- 2022
window <- 0
min_data <- 5

active_philo_bib <- philo_bib_fix |>
  filter(year >= start_year, year <= end_year)

authadjust <- function(x){
  paste0(str_extract(x, '\\b[^,]+$'), " ", str_to_title(str_extract(x,".+(?=,)")))
}

authadjust_short <- function(x){
  str_to_title(str_extract(x,".+(?=,)"))
}

article_years <- active_philo_bib |>
  as_tibble() |>
  select(id, year)

citation_tibble <- philo_cite_with_jp |>
  as_tibble() |>
  rename(new = id, old = refs) |>
  left_join(article_years, by = c("old" = "id")) |>
  rename(old_year = year)  |>
  left_join(article_years, by = c("new" = "id")) |>
  rename(new_year = year) |> # The next lines are new - restricting attention to 1966-end_year
  filter(new_year <= end_year, new_year >= start_year, old_year >= start_year, old_year <= end_year) |>
  mutate(range_year = floor((old_year)/5)*5) |>
  filter(old_year <= 2014)

all_still_standing <- c()
all_median <- c()

for (i in 4:0){
  new_citation_tibble <- citation_tibble |>
    mutate(range_year = floor((old_year-i)/5)*5+i)
  all_early_cites <- new_citation_tibble |>
    filter(new_year - range_year <= 9)
  
  all_late_cites <- new_citation_tibble |>
    filter(new_year >= 2020)
  
  tally_late_cites <- all_late_cites |>
    ungroup() |>
    group_by(old) |>
    tally() |>
    arrange(desc(n))
  
  summ_early_cites <- all_early_cites |>
    ungroup() |>
    group_by(old, old_year, range_year) |>
    summarise(e_cites = n(), .groups = "drop")
  
  summ_late_cites <- all_late_cites |>
    ungroup() |>
    group_by(old, old_year, range_year) |>
    summarise(l_cites = n(), .groups = "drop")
  
  combined_cites <- summ_early_cites |>
    full_join(summ_late_cites, by = c("old", "old_year", "range_year")) |>
    mutate(
      across(everything(), ~replace_na(.x, 0))
    ) |>
    mutate(
      e_score = e_cites + l_cites/1000,
      l_score = l_cites + e_cites/1000
    ) |>
    group_by(range_year) |>
    mutate(
      e_rank = min_rank(-e_score),
      l_rank = min_rank(-l_score),
      o_rank = pmin(e_rank, l_rank)
    ) |>
    ungroup() |>
    arrange(o_rank, -e_score, -l_score) |>
    group_by(range_year) |>
    mutate(f_rank = row_number()) |>
    filter(f_rank <= 100) |>
    ungroup() |>
    left_join(philo_bib_fix, by = c("old" = "id", "old_year" = "year"))
  
  still_standing <- combined_cites |>
    filter(e_rank <= 20) |>
    select(e_cites, l_cites, auth, old_year, range_year, art_title, journal, everything()) |>
    arrange(range_year, desc(e_cites))
  
  still_standing_by_range <- still_standing |>
    filter(l_cites >= 16) |>
    ungroup() |>
    group_by(range_year) |>
    tally()
  
  median_new_cites_of_classics <- combined_cites |>
    ungroup() |>
    group_by(range_year) |>
    filter(e_rank <= 20) |>
    summarise(cites = median(l_cites))
  
  all_still_standing <- bind_rows(all_still_standing, still_standing_by_range)
  all_median <- bind_rows(all_median, median_new_cites_of_classics)
}

```

This post is about how citation patterns change. In particular, it is about what kinds of articles are widely cited when they first come out, but less cited in the future. The key result is that there were surprisingly many of these articles in journals between 1980 and 1995. The main cause of the drop in citations seems to be simple changes in trends. In particular, so much journal attention was paid to relatively a priori investigations into mental content. That's not nearly as large a part of the philosophical landscape now, so the articles that focus on it are less widely cited.

The dataset I'm using is the same as in [an earlier post](http://brian.weatherson.org/quarto/posts/citations-raw-data/citations.html), and I won't repeat it here. The big thing to know is that I'm just looking at one hundred Anglophone, relatively analytic, philosophy journals, and looking at citations in those journals to those journals. For this study I'm going to start in 1965. 

Note that because of a gap in the Web of Science data, I had to manually add citations to _Journal of Philosophy_ articles from 1971 to 1974, but I don't have citations by those articles. That leads to some weirdnesses, but I don't think it drastically affects these results. 

Note also that Web of Science doesn't start indexing _Analysis_ until 1975. This does affect the results substantially; there is no point looking pre-1965 because so many of the widely cited articles are in _Analysis_. I suspect having _Analysis_ would make a pretty big change to 1965-1970 as well, but I can't be sure.

# Study 1 - Counting widely cited articles {#sec-study-one}

The main focus here is on articles published between 1965 and 2014. I'm stopping in 2014 because I want to be able to compare how articles were cited soon after publication, with how they have been cited recently. That requires having enough non-recent years that are 'soon after publication'. Since my dataset stops in mid-2022, that implied stopping in 2014.

Divide that fifty year period up into ten periods of five years each, in the obvious way. So for each decade we have the early and late half of the decade, though we just have late 1960s and early 2010s.

For each half-decade, and each article published in it, find two values.

- The **early cites** to the article are citations by the end of the subsequent half-decade. So for articles published between 1990 and 1994, that means citations in or before 1999.
- The **late cites** to the article are citations in 2020, 2021, and the part of 2022 covered in the dataset.

The late cites might not seem like much of a dataset. But because there are so many articles published now, and because citation practices have changed so much, that includes many many citations. The dataset I have goes back to the mid-1950s, but over a quarter of the citations are in these two and a half years.

Having done that, rank the articles by the number of early cites they have, using the number of late cites as a tiebreaker. The tiebreakers are important, because citations just within journals are not very high; the typical case is that there are lots of ties.

Then choose the top twenty articles, i.e., the twenty articles that were most cited by the end of the subsequent half-decade. (With ties broken by looking at what was most cited recently.) For the period 1990-1994, @tbl-early-1990s lists the twenty articles in question.

```{r}
#| label: tbl-early-1990s
#| cache: true
#| tbl-cap: "The twenty articles from 1990-1994 most widely cited at the time."

kable(
  still_standing |>
    filter(range_year == 1990) |>
    select(Article = full_cite)
)
```

If we look at all the articles in the dataset, just over 1% have been cited sixteen or more times since 2020. (Just under 1% have been cited seventeen or more times.) Call this top 1% of cited articles the _widely cited_ articles in recent philosophy. Our first question is how many of these twenty articles that were the most cited at the time, are widely cited in this sense.

The answer is just four: Stephen Yablo's paper on mental causation, Philip Kitcher's paper on the division of cognitive labour, and Karen Neander's two papers on functions. @tbl-early-1990s-expanded shows how often each of these articles were cited in the 'early' years, i.e., 1990-1999, and how often they are cited in the 'late years', i.e., from 2020 to mid 2022.

```{r}
#| label: tbl-early-1990s-expanded
#| cache: true
#| tbl-cap: "Early and late citations to twenty articles from 1990-1994."

kable(
  still_standing |>
    filter(range_year == 1990) |>
    select(`Early Cites` = e_cites, `Late Cites` = l_cites, Article = full_cite)
)
```

This is extremely unusual, though as we'll see in a bit it is something of an outlier result. If we do the same thing for each of the five year periods, we typically see about 8-10 articles be widely cited in this way, with the numbers rising as we get closer to the present. @fig-still-standing shows the numbers for each half-decade. (Note that the year on the x-axis is the start of the half-decade being shown.)

```{r}
#| label: fig-still-standing
#| cache: true
#| fig-cap: "How many of the twenty articles most cited at the time are still widely cited."

still_standing_by_range |>
  ggplot(aes(x = range_year, y = n)) +
  geom_point() +
  labs(x = element_blank(),
       y = element_blank()) +
  ylim(0, 20)
```

As you can see, the period 1990-1994 really stands out here. But it's a bit crude to just look at what's above or below a threshold. Let's try being a bit more finegrained.

# Study 2 - Median citations of The Twenty {#sec-study-two}

Instead of looking at how many of the twenty articles crossed a somewhat arbitrarily selected threshold, we could look instead at the median number of citations they have in the period 2020-2022. I'm using median not mean because the means end up being largely determined by how widely cited the one or two most cited pieces are. If we use the same twenty articles for each five year period, and calculate the median number of citations they have in 2020-2022, we get the results seen in @fig-median-cites.

```{r}
#| label: fig-median-cites
#| cache: true
#| fig-cap: "The median number of recent citations to twenty articles most cited at the time."

median_new_cites_of_classics |>
  ggplot(aes(x = range_year, y = cites)) +
  geom_point() +
  labs(x = element_blank(),
       y = element_blank()) +
  ylim(0, 42)
```

The 1990-1994 period still does poorly, but it's not as dramatic as on @fig-still-standing.

The 1970-1974 period does surprisingly badly on this measure. That period includes the four very widely cited articles listed in @tbl-early-1970s-sample.

```{r}
#| label: tbl-early-1970s-sample
#| cache: true
#| tbl-cap: "Four very widely cited articles from the early 1970s"

kable(
  still_standing |>
    filter(range_year == 1970) |>
    arrange(desc(l_cites)) |>
    slice(1:4) |>
    select(`Early Cites` = e_cites, `Late Cites` = l_cites, Article = full_cite)
)
```

But several other articles that were more prominent at the time, including two by Hartry Field and two by Richard Rorty, are not nearly as prominent in the recent literature. The large number of citations to these four articles doesn't move the median that much.

# Study 3 -  Rolling Periods {#sec-study-three}

If you look back at @tbl-early-1990s, you see a lot of articles from 1990 and 1991 in particular. This shouldn't be a surprise. The way the twenty articles were selected was by looking at the most cited articles by a fixed date, in this case 1999. Articles published in 1990 and 1991 had a lot more time to accumulate citations by 1999 than articles published later in the half-decade.

One way to fix that is to get away from having round numbers in our five year periods. For any year *y* from 1965 to 2010, we can perform the following calculations.

- Select the articles published between *y* and *y+4.
- Sort them by the number of citations they have by *y*+9 (using citations since 2020 as a tiebreaker).
- Ask how many of the top twenty on that list are widely cited recently (i.e., have at least sixteen citations).

If we set *y* to be 1990, that gives us the results we saw in @tbl-early-1990s and @tbl-early-1990s-expanded. But we can do it for years that don't end with 0 and 5. If we do it for all the years from 1965 to 2010, we get the results in @fig-all-still-standing.

```{r}
#| label: fig-all-still-standing
#| cache: true
#| fig-cap: "How many of the twenty articles most cited at the time are still widely cited."

all_still_standing |>
  filter(range_year >= 1965, range_year <= 2010) |>
  ggplot(aes(x = range_year, y = n)) +
  geom_point() +
  labs(x = element_blank(),
       y = element_blank()) +
  ylim(0, 20)
```

The odd result for 1990 itself looks like an outlier here. Why are the years around it so different?

It's easy to explain why the value for 1989 is different. The articles listed in @tbl-top-1989 were published in 1989, and widely cited.

```{r}
#| label: tbl-top-1989
#| cache: true
#| tbl-cap: "Widely cited articles from 1989"

new_citation_tibble <- citation_tibble |>
  filter(old_year == 1989)

the_89_early_cites <- new_citation_tibble |>
  filter(new_year <= 1998)

the_89_late_cites <- new_citation_tibble |>
  filter(new_year >= 2020)

the_89_early_cites <- the_89_early_cites |>
  ungroup() |>
  group_by(old, old_year, range_year) |>
  summarise(e_cites = n(), .groups = "drop") |>
  filter(e_cites >= 15)

the_89_late_cites <- the_89_late_cites |>
  ungroup() |>
  group_by(old, old_year, range_year) |>
  summarise(l_cites = n(), .groups = "drop") |>
  filter(l_cites >= 16)

the_89_both <- the_89_early_cites |>
  inner_join(the_89_late_cites, by = c("old", "old_year", "range_year")) |>
  left_join(philo_bib_fix, by = c("old" = "id", "old_year" = "year")) |>
  select(`Early Cites` = e_cites, `Late Cites` = l_cites, Article = full_cite)

kable(the_89_both)
```

The range 1989-1993 includes those four articles which the range 1990-1994 does not. But what is going on with the range 1991-1995? How does adding 1995 to the set make such a difference? It's a bit more complicated than that. The nine articles from 1991-1995 which are widely cited recently are shown in @tbl-top-1991.

```{r}
#| label: tbl-top-1991
#| cache: true
#| tbl-cap: "Widely cited articles from 1991"

new_citation_tibble <- citation_tibble |>
  filter(old_year >= 1991, old_year <= 1995)

the_91_early_cites <- new_citation_tibble |>
  filter(new_year <= 2000)

the_91_late_cites <- new_citation_tibble |>
  filter(new_year >= 2020)

the_91_early_cites <- the_91_early_cites |>
  ungroup() |>
  group_by(old, old_year, range_year) |>
  summarise(e_cites = n(), .groups = "drop") 

the_91_late_cites <- the_91_late_cites |>
  ungroup() |>
  group_by(old, old_year, range_year) |>
  summarise(l_cites = n(), .groups = "drop") 

the_91_both <- the_91_early_cites |>
  full_join(the_91_late_cites, by = c("old", "old_year", "range_year")) |>
  mutate(
    across(everything(), ~replace_na(.x, 0))
  ) |>
  mutate(
    e_score = e_cites + l_cites/1000,
    l_score = l_cites + e_cites/1000
  ) |>
  mutate(
    e_rank = min_rank(-e_score),
    l_rank = min_rank(-l_score),
    o_rank = pmin(e_rank, l_rank)
  ) |>
  arrange(o_rank, -e_score, -l_score) |>
  mutate(f_rank = row_number()) |>
  filter(f_rank <= 100) |>
  ungroup() |>
  left_join(philo_bib_fix, by = c("old" = "id", "old_year" = "year")) |>
  filter(e_rank <= 20)

kable(
  the_91_both |>
    arrange(desc(l_cites)) |>
    filter(l_cites >= 16) |>
    select(`Early Cites` = e_cites, `Late Cites` = l_cites, Article = full_cite)
)
```

What's happened here is that several of the articles, most notably the Lewis and Dennett ones, did not get a huge number of citations straight away. They counted for the period 1991-1995 but not the period 1990-1994 because they were so often cited in 2000.

There is something nice about this way of counting how many 'early' cites a paper has. What counts as a citation 'at the time' in philosophy is somewhat vague. Philosophy moves slowly, at least relative to some sciences, so citations within the first five years are clearly early citations. Citations when the paper is ten years old or more are not early citations. Between those two, there is some vagueness.

One way to handle that vagueness would be to stipulate what we mean by 'early'. Any such stipulation would be somewhat arbitrary, and any results would have to be checked by re-running the model for other stipulations.

The method here of looking at rolling, overlapping, intervals allows us to accommodate the vagueness. Consider two hypothetical papers. Paper one gets fifty citations the year it comes out, and is never cited again. Paper two is not cited for eight years, then gets fifty citations every year after that. Paper one will be in the top twenty papers with the most early cites for five different periods; all the ones it is eligible for. Paper two will only be in the top twenty for one of those intervals, the very last one it was eligible for. So for graphs like @fig-all-still-standing, paper one will impact (and pull down), five of the points, while paper two will only impact (and pull up), one of them. If paper two had started getting citations earlier, it would have impacted more of the points. In that way, graphs like @fig-all-still-standing take account of the vagueness in 'early'.

Later on, we will want to focus on articles, like article one, that affect many points in the graph, and it's useful to think about why different articles might be differentially important to this graph.

Summing up, @fig-all-still-standing that there was something a bit unusual about the results in @sec-study-one and @sec-study-two. It was only by a very particular choice of years that the period 1990-1994 looks so unusual.

But the broader picture shows that the particular period 1990-1994 was a bit unusual relative to its surrounds. It still leaves us with a question about those surrounds. And we need one last study to see the thing that most needs explaining.

# Study 4 - Medians in Rolling Periods {#sec-study-four}

As in @sec-study-three, do the following calculation for each year *y*.

- Select the articles published between *y* and *y+4.
- Sort them by the number of citations they have by *y*+9 (using citations since 2020 as a tiebreaker).
- Focus on the top twenty in that list.

But instead of asking how many of these twenty are 'widely cited', instead calculate the median number of citations since 2020 for those twenty articles. The results are shown in @fig-all-median.

```{r}
#| label: fig-all-median
#| cache: true
#| fig-cap: "The median number of recent cites for the twenty articles most cited at the time."

require(ggforce)
all_median |>
  filter(range_year >= 1965, range_year <= 2010) |>
  ggplot(aes(x = range_year, y = cites)) +
  geom_point() +
  labs(x = element_blank(),
       y = element_blank()) +
  ylim(0, 42)
```

This is a really amazing graph. Every year from 1980 to 1995 is worse than every year from 1974 to 1979, and every year from 1996 to the present. How could this have happened?

# Three Explanations {#sec-three-explanations}

When we think about what @fig-all-median is measuring, we can see that there are three ways that the result might have come about. Each of these 'ways' suggests different places to look for the underlying explanation, but first we need to test which of them matches the data.

First, it might be that philosophers in recent years have systematically ignored journal articles published in the 1980s and 1990s. If there are few widely cited articles from those years, these medians will be pulled down.

Second, it might be that the widely cited articles from the 1980s and 1990s are particularly likely to have not been cited much at the time. It's easy to find examples of that. Rae Langton's 1993 paper "Speech Acts and Unspeakable Acts" has 49 citations between 2020 and mid-2022. But it doesn't show up in @fig-all-median because it had hardly any citations for more than a decade after it was published. If the work that philosophers now focus on from the 1980s and 1990s was systematically ignored when it first came out, we'd again see the shape of the graph in @fig-all-median.

Third, it might be that the articles which were particularly heavily discussed at the time are discussed much less these days. So consider two articles from 1988, Frank Jackson and Philip Pettit's "Functionalism and Broad Content", and John Rawls's "The Priority of Right and Ideas of the Good". Both of them were so widely discussed that they became among the twenty most cited recent articles within five years of publication. In the terms discussed earlier, they each impact five points on the graph. And this impact is to drag the points down, because each of them was only cited five times between 2020 and mid-2022. Now I say 'only' even though this is still a non-trivial number of citations; two-thirds of the papers in the database have no citations at all in this time. It is, however, a lot fewer citations than you might expect given their immediate prominence.

All three of these explanations get at part of the truth, but I think the data suggests the third of them is the most important. One striking thing that happens around 2000 is that papers like the Jackson and Pettit, and the Rawls, stop showing up in the data. From that point on, if a paper is widely discussed when it's published, it's still widely discussed from 2020 to mid-2022.

The other two explanations don't explain quite so sharp a break. The second explanation does particularly badly on that score; papers that don't take off right away but which eventually become very widely discussed in recent philosophy are more common in the 2000s than in the 1990s. The first explanation does a bit better at matching the data, but only a bit; there are plenty of papers in the 1980s and 1990s that are discussed in recent philosophy, even if they are discussed a bit less than papers from the 1970s and 2000s.

Let's look at these explanations in turn to back up those claims.

# Explanation 1 - The Missing Decades {#sec-missing-decades}

A simple explanation of @fig-all-median would be that no one discusses papers from the 1980s and 1990s nowadays, so they don't discuss papers from the 1980s and 1990s that were widely discussed at the time. This is  a quarter true at most, as the following two graphs show.

@fig-all-widely-cited shows the number of papers published each year which are cited 16 or more times, i.e., which are 'widely cited', between 2020 and 2022.

```{r}
#| label: fig-all-widely-cited
#| cache: true
#| fig-cap: "Number of widely cited articles published each year"

citation_tibble |>
  filter(old_year >= 1974, old_year <= 2006, new_year >= 2020) |>
  group_by(old) |>
  tally() |>
  filter(n >= 16) |>
  left_join(philo_bib_fix, by = c("old" = "id")) |>
  select(n, auth, year, art_title, journal, everything()) |>
  ungroup() |>
#  group_by(year) |>
 # tally() |>
  ggplot(aes(x = year)) + geom_bar() +
    labs(x = element_blank(),
       y = element_blank()) 
```

The number of widely cited articles goes up, but it doesn't go up dramatically enough to explain @fig-all-median. Another way to see this is to look at @fig-all-median-unqualified. This modifies @fig-all-median by removing the qualification that the articles had to be widely cited at the time. For each rolling five year period, it records the median number of citations of the twenty most cited articles full stop. (That is, it is the average of the citations of the tenth most and eleventh most cited articles from that five year period.)

```{r}
#| label: fig-all-median-unqualified
#| cache: true
#| fig-cap: "Median citations of the twenty most cited articles from overlapping five year periods."

median_cites_unqualified <- tribble(~year, ~median)

for (y in 1974:2008){
  temp <- citation_tibble |>
    filter(old_year >= y, old_year <= y + 4, new_year >= 2020) |>
    group_by(old) |>
    tally() |>
    arrange(-n) |>
    slice(1:20)
  median_cites_unqualified <- median_cites_unqualified |>
    add_row(year = y, median = median(temp$n))
}

ggplot(median_cites_unqualified, aes(x = year, y = median)) + geom_point() +
      labs(x = element_blank(),
       y = element_blank()) 
```

There is a jump at 1996; that is, the range 1996-2000 does much better on this metric than any five year range earlier than that. So that's why I think this explanation is perhaps a quarter true. But there are two reasons to think it isn't the whole story.

First, part of the surprise in @fig-all-median was that the period 1980-1995 was lower than either side of it. That's not something we see in @fig-all-median-unqualified. This perhaps explains the jump around 1996, but it doesn't explain the drop around 1980.

Second, the absolute values on @fig-all-median-unqualified are so high that it tells against the kind of explanation being offered here. Apart from ranges centered on the mid-1980s, in most five year periods there are ten or more papers that are cited forty or more times in the recent literature. That's easily enough to make the dip in @fig-all-median go away. The key thing here is to not just look at the shape of @fig-all-median-unqualified, but to look at the scale. It's just not true that philosophers are systemtically ignoring work from the 1980s and 1990s, even if they aren't paying it quite as much attention as they are paying to work from the early 2000s.

# Explanation 2 - Late Bloomers {#sec-late-bloomers}

```{r}
#| label: latebloomcode
#| cache: true

the_700 <- c()

for (y in 1974:2008){
  the_20 <- citation_tibble |>
    ungroup() |>
    select(-range_year) |>
    filter(old_year >= y, old_year <= y + 4) |>
    filter(new_year <= y + 9 | new_year >= 2020) |>
    mutate(cite_age = case_when(
      new_year <= y + 9 ~ "e_cites",
      new_year >= 2020 ~ "l_cites"
    )) |>
    group_by(old, old_year, cite_age) |>
    summarise(cites = n(), .groups = "drop") |>
    pivot_wider(id_cols = c(old), names_from = cite_age, values_from = cites) |>
    replace_na(list(e_cites = 0, l_cites = 0)) |>
    mutate(score = e_cites + l_cites/1000) |>
    mutate(the_rank = rank(-score)) |>
    arrange(the_rank) |>
    slice(1:20) |>
    select(-score, -the_rank) |>
    mutate(range_year = y) |>
    left_join(philo_bib_fix, by = c("old" = "id")) |>
    select(e_cites, l_cites, auth, year, range_year, art_title, journal, everything()) 
  
  the_700 <- bind_rows(the_700, the_20)
}

the_700 <- the_700 |>
  ungroup() |>
  group_by(old) |>
  mutate(appear = n()) |>
  select(appear, everything()) |>
  arrange(-appear, l_cites, old)

appear_median <- the_700 |>
  ungroup() |>
  group_by(appear) |>
  summarise(l_cites = median(l_cites))

the_700 |> 
    filter(appear == 3) |>
    ungroup() |>
    mutate(l_cites = replace(l_cites, l_cites == 0, 0.5)) |>
    ungroup() |>
    distinct(old, .keep_all = TRUE) |>
    select(year, l_cites) |>
    ggplot(aes(x = year, y = l_cites)) + 
      geom_point() + 
      scale_y_log10() +
      ggrepel::geom_label_repel(data = filter(the_700, appear == 3, (l_cites <= 1 | (year >= 2000 & l_cites <= 10))), aes(label = shortcite))

the_700_graph <- the_700 |>
  filter(appear == 3, year >= 1979) |>
  ungroup() |>
  mutate(l_cites = replace(l_cites, l_cites == 0, 0.5)) |>
  distinct(old, .keep_all = TRUE) |>
  mutate(outlier = case_when(
    l_cites <= 5 ~ TRUE,
    year >= 2000 & l_cites <= 9 ~ TRUE,
    TRUE ~ FALSE))

ggplot(the_700_graph, aes(x = year, y = l_cites))  + 
  geom_point() + 
  scale_y_log10(limits = c(0.5, 250)) 

widely_cited <- citation_tibble |>
  filter(old_year >= 1974, old_year <= 2010) |>
  filter(new_year <= old_year + 9 | new_year >= 2020) |>
  mutate(cite_age = case_when(
    new_year <= old_year + 9 ~ "e_cites",
    new_year >= 2020 ~ "l_cites"
  )) |>
  group_by(old, old_year, cite_age) |>
  summarise(cites = n(), .groups = "drop") |>
  pivot_wider(id_cols = c(old, old_year), names_from = cite_age, values_from = cites) |>
  replace_na(list(e_cites = 0, l_cites = 0)) |>
  left_join(philo_bib_fix, by = c("old" = "id", "old_year" = "year")) |>
  select(e_cites, l_cites, auth, old_year, art_title, journal, everything()) |>
  filter(l_cites >= 16)

widely_cited_years <- widely_cited |>
  filter(l_cites >= 16) |>
  group_by(old_year) |>
  tally()

very_late_bloomers <- widely_cited |>
  anti_join(the_700, by = "old") |>
  filter(old_year <= 2005) |>
  arrange(-l_cites)
```

Before looking at the data, I would have guessed that this was the right explanation: the distinctive thing about the 1980s and 1990s was that there was so much interesting work being done whose interest was only recognised much later. That is, to put it bluntly, not what the data shows at all. It's true that papers like Langton's 1993 paper exist. But there are many more such papers outside the 1980s and 1990s than inside them.

@tbl-very-late-bloomers comes from taking all the articles that never appear on the lists of twenty most cited at the time articles, and sorting them by how many citations they have from 2020 to mid-2022.

```{r}
#| label: tbl-very-late-bloomers
#| cache: false
#| tbl-cap: "Articles with the higher number of recent citations that are not in the top twenty for any five year span."

kable(
  very_late_bloomers |>
    arrange(-l_cites) |>
    slice(1:10) |>
    select(Citations = l_cites, Article = full_cite)
)
```

There are two things to note about this list.

One is that it is much more female than any list we've seen so far. Four of the ten papers are written by women. There is an interesting research project here about the difference in citation dynamics for papers written by women and men, but I'll leave that for another day.

The other is that only two of the papers are from the 1990s, and none are from the 1980s. One of those two is Joyce's 1998 paper that (eventually) launched the accuracy-first program in epistemology. Because it is so late in the 1990s, it could only have affected the pattern in @fig-all-median at the very margin.

That's so say, while it's true that there are papers like Langton's, and DeRose's 1992 paper 