<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.30">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Brian Weatherson">
<meta name="dcterms.date" content="2025-08-14">

<title>Deference and Infinite Frames – Brian Weatherson</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-de070a7b0ab54f8780927367ac907214.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-2b3e328b71be8d25427581baeb23079b.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-de070a7b0ab54f8780927367ac907214.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-4c44098e78fdd705b9debb9eb66aa123.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-dcf4b32a2094a7fbc35852421cc1fa0d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../site_libs/bootstrap/bootstrap-4c44098e78fdd705b9debb9eb66aa123.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" href="https://use.typekit.net/uzz2drx.css">
<meta name="quarto:status" content="draft">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../trad_defn.css">
</head>

<body class="floating nav-fixed slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner"><div id="quarto-draft-alert" class="alert alert-warning"><i class="bi bi-pencil-square"></i>Draft</div>
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Brian Weatherson</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-papers" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Papers</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-papers">    
        <li>
    <a class="dropdown-item" href="../../../papers.html">
 <span class="dropdown-text">All Papers</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../epist.html">
 <span class="dropdown-text">Epistemology</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../gdt.html">
 <span class="dropdown-text">Games and Decisions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../books.html">
 <span class="dropdown-text">On Books</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-books" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Books</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-books">    
        <li>
    <a class="dropdown-item" href="https://brian.weatherson.org/ne/">
 <span class="dropdown-text">Normative Externalism</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://lda.weatherson.org/">
 <span class="dropdown-text">A History of Philosophy Journals</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://brian.weatherson.org/kahis/">
 <span class="dropdown-text">Knowledge: A Human Interest Story</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../cv.html"> 
<span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../teaching.html"> 
<span class="menu-text">Teaching Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://scholar.google.com/citations?user=rz5RF8kAAAAJ&amp;hl=en&amp;oi=ao" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-google"></i></a>
    <a href="mailto: brian@weatherson.org" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-mailbox"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Deference and Infinite Frames</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">epistemology</div>
                <div class="quarto-category">logic</div>
                <div class="quarto-category">unpublished</div>
              </div>
                  </div>
  </div>
    
  <div class="quarto-title-meta-author">
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-heading">Affiliation</div>
    
      <div class="quarto-title-meta-contents">
      <p class="author"><a href="http://brian.weatherson.org">Brian Weatherson</a> </p>
    </div>
    <div class="quarto-title-meta-contents">
          <p class="affiliation">
              University of Michigan
            </p>
        </div>
    </div>

  <div class="quarto-title-meta">

        
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 14, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  <div>
    <div class="abstract">
      <div class="block-title">Abstract</div>
      <p>This paper concerns three recent results concerning probabilistic deference. The results show interesting things about how various kinds of deference work on finite frames, but in each case the results do not naturally generalise to infinite frames. The non-generalisation raises interesting philosophical questions about the epistemological significance of the results, but those questions are set aside here. The priority in this paper is simply showing that the results fail when we allow frames to be infinite.</p>
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Sections</h2>
   
  <ul>
  <li><a href="#sec-gallow" id="toc-sec-gallow" class="nav-link active" data-scroll-target="#sec-gallow"><span class="header-section-number">1</span> Dual Deference</a></li>
  <li><a href="#sec-nesting" id="toc-sec-nesting" class="nav-link" data-scroll-target="#sec-nesting"><span class="header-section-number">2</span> Evidence and Nesting</a></li>
  <li><a href="#sec-dorst" id="toc-sec-dorst" class="nav-link" data-scroll-target="#sec-dorst"><span class="header-section-number">3</span> Trust and Value</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">4</span> Conclusion</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="defer-three.docx"><i class="bi bi-file-word"></i>MS Word</a></li><li><a href="Deference and Infinite Frames.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">






<p>This paper concerns three recent results concerning probabilistic deference. The results show interesting things about how various kinds of deference work on finite frames, but in each case the results do not naturally generalise to infinite frames. The non-generalisation raises interesting philosophical questions about the epistemological significance of the results, but those questions are set aside here. The priority in this paper is simply showing that the results fail when we allow frames to be infinite.</p>
<section id="sec-gallow" class="level1 page-columns page-full" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Dual Deference</h1>
<p>If A and C are probability functions, the strongest kind of deference (with respect to some proposition <em>p</em>) is when C takes A’s probability in <em>p</em> to settle what the correct probability is. More formally, it is that ∀<em>a</em>: C(<em>p</em>&nbsp;|&nbsp;A(<em>p</em>)&nbsp;=&nbsp;<em>a</em>)&nbsp;=&nbsp;<em>a</em>. Our first question is when C can defer in this strong sense to two different functions A and B.</p>
<p>There are two cases when this can happen quite easily. The first is when C is certain that A and B will agree, i.e., C(A&nbsp;=&nbsp;B)&nbsp;=&nbsp;1. The second is when C takes one or other of the functions to be superior, i.e., when they disagree to always go with what one particular function says. So if C takes A to be superior, then ∀<em>a</em>,&nbsp;<em>b</em>: C(<em>p</em>&nbsp;|&nbsp;A(<em>p</em>)&nbsp;=&nbsp;<em>a</em> ∧&nbsp;B(<em>p</em>)&nbsp;=&nbsp;<em>b</em>)&nbsp;=&nbsp;<em>a</em>. But is there a third option? Can C think that A and B are both worthy of total deference, that they might disagree, and when they do the right thing to do is to land somewhere between their two credences?</p>
<p>Dmitri <span class="citation" data-cites="Gallow2018">Gallow (<a href="#ref-Gallow2018" role="doc-biblioref">2018</a>)</span> proved one important negative result here. He showed that there is no triple of probability functions C, A, B satisfying the following constraints.</p>
<ol type="1">
<li>∀<em>a</em>: C(<em>p</em> | A(<em>p</em>) = <em>a</em>) = <em>a</em>;</li>
<li>∀<em>b</em>: C(<em>p</em> | B(<em>p</em>) = <em>b</em>) = <em>b</em>;</li>
<li>C(A = B) &lt; 1;</li>
<li>For some λ&nbsp;∈&nbsp;(0,1), ∀<em>a</em>,<em>b</em>:&nbsp;C(<em>p</em>&nbsp;|&nbsp;A(<em>p</em>)&nbsp;=&nbsp;<em>a</em>&nbsp;∧&nbsp;B(<em>p</em>)&nbsp;=&nbsp;<em>b</em>)&nbsp;=&nbsp;λ<em>a</em>&nbsp;+&nbsp;(1-λ)<em>b</em>.</li>
</ol>
<p>That is, C can’t defer to both A and B individually, think that A and B might disagree, and in the event they do disagree, plan to take a fixed linear mixture of A’s probability and B’s probability as the probability of <em>p</em>. This result, unlike most we’ll discuss in this paper, does not make any finiteness assumptions, but it does make this strong assumption in point 4 about how C will mix A and B’s probabilities.</p>
<p>Snow Zhang recently proved a result that mostly generalises Gallow’s result, though it does weaken it in one crucial respect. (We’re describing here a simplification of Zhang’s result, which also generalises the number of possible experts.) She shows that it is impossible for A, B and C to satisfy the following five constraints.</p>
<ol type="1">
<li>∀<em>a</em>: C(<em>p</em> | A(<em>p</em>) = <em>a</em>) = <em>a</em>;</li>
<li>∀<em>b</em>: C(<em>p</em> | B(<em>p</em>) = <em>b</em>) = <em>b</em>;</li>
<li>C(A = B) &lt; 1;</li>
<li>For any <em>a</em>,<em>b</em>:&nbsp;C(<em>p</em>&nbsp;|&nbsp;A(<em>p</em>)&nbsp;=&nbsp;<em>a</em>&nbsp;∧&nbsp;B(<em>p</em>)&nbsp;=&nbsp;<em>b</em>)&nbsp;is strictly between <em>a</em> and <em>b</em>.</li>
<li>For some finite set of values S, C(A(<em>p</em>)&nbsp;∈&nbsp;S ∧&nbsp;B(<em>p</em>)&nbsp;∈&nbsp;S)&nbsp;=&nbsp;1.</li>
</ol>
<p>This section shows that the last constraint is essential; it is possible to satisfy the first four constraints without it. We’ll show this by constructing a model where the first four constraints are satisfied. In this model there will uncountably many values that A(<em>p</em>) and B(<em>p</em>) could take. It’s an open question whether Zhang’s result holds if we weaken 5 to say that S is countable.</p>
<p>Let X, Y and Z be normal distributions with mean 0 and variance 1. In symbols, each of them is <span class="math inline">\(\mathcal{N}\)</span>(0,1). So the sum of any two of them has distribution <span class="math inline">\(\mathcal{N}\)</span>(0,2), and the sum of all three has distribution <span class="math inline">\(\mathcal{N}\)</span>(0,3). Let <em>p</em> be the proposition that this sum, X&nbsp;+&nbsp;Y&nbsp;+&nbsp;Z, is positive. Let C be a probability function that incorporates all these facts, but has no other direct information about X, Y, and Z. So C(<em>p</em>)&nbsp;=&nbsp;½, since in all respects C’s opinions are symmetric around 0.</p>
<p>C knows some things about A and B. Both of them know everything C knows about X, Y, Z, and each are logically and mathematically omniscient, and know precisely what evidence they have.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> One of them knows the value of X, and one of them knows the value of X&nbsp;+&nbsp;Y. A fair coin was flipped. If it landed heads, then A knows X and B knows X&nbsp;+&nbsp;Y; if it landed tails, it was the other way around. C knows about this arrangement, but doesn’t know how the coin landed. Let H be the proposition that it landed heads.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;That is, each of them satisfy positive and negative introspection for evidence. The next two sections will drop the assumption that more informed functions satisfy negative introspection.</p></div></div><p>Since both A and B know everything C knows plus something more, and satisfy positive and negative introspection, C should defer to them. If C knew which knew X&nbsp;+&nbsp;Y and which only knew X, they would defer to the one who knew X&nbsp;+&nbsp;Y. They don’t know this, but conditional on knowing the values of A(<em>p</em>) and B(<em>p</em>), they can go close to figuring it out.</p>
<p>Assume for now that the coin landed heads, so H is true. We’ll work out the joint density function for A and B. Then we can work out the same density function conditional on ¬H, and from those two facts work out the posterior probability of H. Call this value <em>h</em>. Conditional on A(<em>p</em>)&nbsp;=&nbsp;<em>a</em>, and B(<em>p</em>)&nbsp;=&nbsp;<em>b</em>, C’s probability for p should be (1-<em>h</em>)<em>a</em>&nbsp;+&nbsp;<em>hb</em>. That’s because conditional on A(<em>p</em>)&nbsp;=&nbsp;<em>a</em>, B(<em>p</em>)&nbsp;=&nbsp;<em>b</em> and H, C’s probability for <em>p</em> should be <em>b</em>, while conditional on A(<em>p</em>)&nbsp;=&nbsp;<em>a</em>, B(<em>p</em>)&nbsp;=&nbsp;<em>b</em> and ¬H, C’s probability for <em>p</em> should be <em>a</em>. The short version of what follows is that since <em>h</em> is a function of <em>a</em> and <em>b</em> and is always in (0,1), it follows that C obeys constraint 4.</p>
<p>Given H, we can work out the value of X from A(<em>p</em>)&nbsp;=&nbsp;<em>a</em>. In what follows, <span class="math inline">\(\Phi\)</span>(<em>x</em>) is the cumulative distribution for the standard normal distribution, i.e., for <span class="math inline">\(\mathcal{N}\)</span>(0,1), and <span class="math inline">\(\Phi\)</span><sup>-1</sup> is its inverse. If X&nbsp;=&nbsp;<em>x</em>, then <em>p</em> is true iff Y&nbsp;+&nbsp;Z&nbsp;&gt; -<em>x</em>. Since Y&nbsp;+&nbsp;Z is a normal distribution with mean 0 and variance 2, i.e., standard deviation <span class="math inline">\(\sqrt{2}\)</span>, the probability of this is <span class="math inline">\(\Phi\)</span>(<span class="math inline">\(\frac{x}{\sqrt{2}}\)</span>). So <em>x</em>&nbsp;=&nbsp;<span class="math inline">\(\sqrt{2}\Phi\)</span><sup>-1</sup>(<em>a</em>).</p>
<p>Given H, that X&nbsp;=&nbsp;<span class="math inline">\(\sqrt{2}\Phi\)</span><sup>-1</sup>(<em>a</em>), and B(<em>p</em>), we can work out what Y must be as well. If B(<em>p</em>)&nbsp;=&nbsp;<em>b</em>, that means that the probability that Z&nbsp;&gt;&nbsp;-(X&nbsp;+&nbsp;Y) is <em>b</em>. Since Z just is a standard normal distribution, that means that X&nbsp;+&nbsp;Y is <span class="math inline">\(\Phi\)</span><sup>-1</sup>(<em>b</em>), and hence Y is <span class="math inline">\(\Phi\)</span><sup>-1</sup>(<em>b</em>) - <span class="math inline">\(\sqrt{2}\Phi\)</span><sup>-1</sup>(<em>a</em>).</p>
<p>Now we can work out the joint density function for <em>a</em> and <em>b</em> conditional on H. Given H, A(<em>p</em>)&nbsp;=&nbsp;<em>a</em> and B(<em>p</em>)&nbsp;=&nbsp;<em>b</em> just when X = <span class="math inline">\(\sqrt{2}\Phi\)</span><sup>-1</sup>(<em>a</em>) and Y&nbsp;=&nbsp;<span class="math inline">\(\Phi\)</span><sup>-1</sup>(<em>b</em>) - <span class="math inline">\(\sqrt{2}\Phi\)</span><sup>-1</sup>(<em>a</em>). And if we write <span class="math inline">\(\phi\)</span>(<em>x</em>) for the density function for the standard normal distribution<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, the joint distribution for A(<em>p</em>)&nbsp;=&nbsp;<em>a</em>&nbsp;∧&nbsp;B(<em>p</em>)&nbsp;=&nbsp;<em>b</em> given H has density</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;i.e., <span class="math inline">\(\phi(x) = \frac{e^{-\frac{x^2}{2}}}{\sqrt{2\pi}}\)</span>.</p></div></div><p><span class="math display">\[
\phi(\sqrt{2}\Phi^{-1}(a)) \phi(\Phi^{-1}(b) - \sqrt{2}\Phi^{-1}(a))
\]</span></p>
<p>By a parallel calculation, the joint density function for for A(<em>p</em>)&nbsp;=&nbsp;<em>a</em>&nbsp;∧&nbsp;B(<em>p</em>)&nbsp;=&nbsp;<em>b</em> given ¬H has density</p>
<p><span class="math display">\[
\phi(\sqrt{2}\Phi^{-1}(b)) \phi(\Phi^{-1}(a) - \sqrt{2}\Phi^{-1}(b))
\]</span></p>
<p>So given that A(<em>p</em>)&nbsp;=&nbsp;<em>a</em>&nbsp;∧&nbsp;B(<em>p</em>)&nbsp;=&nbsp;<em>b</em>, the probability of H is</p>
<p><span class="math display">\[
\frac{
\phi(\sqrt{2}\Phi^{-1}(a)) \phi(\Phi^{-1}(b) - \sqrt{2}\Phi^{-1}(a))
}{
\phi(\sqrt{2}\Phi^{-1}(a)) \phi(\Phi^{-1}(b) - \sqrt{2}\Phi^{-1}(a)) + \phi(\sqrt{2}\Phi^{-1}(b)) \phi(\Phi^{-1}(a) - \sqrt{2}\Phi^{-1}(b))
}
\]</span></p>
<p>If we call that value λ, it follows that C(<em>p</em>&nbsp;|&nbsp;A(<em>p</em>)&nbsp;=&nbsp;<em>a</em>&nbsp;∧&nbsp;B(<em>p</em>)&nbsp;=&nbsp;<em>b</em>)&nbsp;=&nbsp;λ<em>b</em>&nbsp;+&nbsp;(1-λ)<em>a</em>, and since λ&nbsp;∈&nbsp;(0,1), this means that C satisfies constraint 4. This is consistent with Gallow’s result because λ is not a constant, it is a function of <em>a</em> and <em>b</em>. And it is consistent with Zhang’s result because each of A(<em>p</em>) and B(<em>p</em>) can take infinitely many, in fact uncountably many, values. If one tries to make a similar construction to this one with only finitely many possible values for the probabilities, there will be some value which only the more informed probability can take, and in that case C’s posterior probability will be equal to the probability of the more informed expert.</p>
<p>To understand the relationship between <em>a</em>, <em>b</em>, and C’s posterior probability, it helps to visualise one part of it. <a href="#fig-two-experts" class="quarto-xref">Figure&nbsp;1</a> shows what value this posterior takes for different values of <em>b</em> holding fixed <em>a</em>&nbsp;=&nbsp;0.75.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-two-experts" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-two-experts-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="defer-three_files/figure-html/fig-two-experts-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-two-experts-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The posterior probability of C(<em>p</em>) given A(<em>p</em>)&nbsp;=&nbsp;0.75.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The distribution loosely follows what <span class="citation" data-cites="Levinstein2015">Levinstein (<a href="#ref-Levinstein2015" role="doc-biblioref">2015</a>)</span> calls Thrasymachus’s Principle. The more opinionated of the two experts gets much stronger weight. You can see this in part by seeing how close the above graph gets to <em>x</em>&nbsp;=&nbsp;<em>y</em> at either extreme. But it’s perhaps more vivid if we plot the posterior probability that the coin landed Tails against the different values of B(<em>p</em>), as in <a href="#fig-two-experts-heads" class="quarto-xref">Figure&nbsp;2</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-two-experts-heads" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-two-experts-heads-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="defer-three_files/figure-html/fig-two-experts-heads-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-two-experts-heads-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: The posterior probability of the coin landing Tails given A(<em>p</em>)&nbsp;=&nbsp;0.75.
</figcaption>
</figure>
</div>
</div>
</div>
<p>When B(<em>p</em>) is between 0.25 and 0.75, i.e., when it is closer to 0.5 than A(<em>p</em>) is, C is confident that the coin landed Tails, and that A is more informed and hence more worthy of deference. When B(<em>p</em>) takes a more extreme value, then C is confident that the coin landed Heads, and hence that B is more worthy of deference. In general, this model backs up Levinstein’s intuition that more opinionated sources are probably better informed, and hence more worthy of deference.</p>
</section>
<section id="sec-nesting" class="level1 page-columns page-full" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Evidence and Nesting</h1>
<p>The previous section assumed that C strongly deferred to A and B. We now turn to the question of when C should do that. A natural thought, one we relied on in that discussion, was that C should defer when they regard A and B as better informed than they are. This can be motivated with a famous result from David Blackwell <span class="citation" data-cites="Blackwell1951">(<a href="#ref-Blackwell1953" role="doc-biblioref">1953</a>)</span>. Let E<sub>1</sub> and E<sub>2</sub> be functions from W to subsets of W. Intuitively, these are <em>experiments</em>; The Experimenter will perform E<sub><em>i</em></sub> and learn they are in E<em><sub>i</sub></em>(<em>w</em>), where <em>w</em> is the world they are in. Blackwell assumes that the range of each E<sub><em>i</em></sub> is a partition of W; The Experimenter always learns what cell of the partition they are in.</p>
<p>The short version of the big result is that E<sub>1</sub> is guaranteed to be more valuable than E<sub>2</sub> iff E<sub>1</sub> is more informative than E<sub>2</sub>. All of that needs clarifying though.</p>
<p>Say E<sub>1</sub> is a <em>refinement</em> of E<sub>2</sub> iff for all <em>w</em>, E<sub>1</sub>(<em>w</em>)&nbsp;⊆&nbsp;E<sub>2</sub>(<em>w</em>). Formally, this is how we’ll capture the intuitive notion of being more informative.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;Note that comparisons here always include equality. An experiment is a refinement of itself, is more informative than itself, and is more valuable than itself. This can lead to confusion, but it’s the standard terminology, and the alternative is much more wordy.</p></div><div id="fn4"><p><sup>4</sup>&nbsp;I’m defining random variable and expected value the way they are usually defined in philosophy. In some fields it is more common to define random variables as functions from a probability space to reals, where a probability space has W and Pr as constituents. Then we can define expectation as a one-place function that simply takes a random variable as input. I think the philosophers’ way of speaking is more useful, and in any case I’m a philosopher so it’s more natural to me. But note there is a potential terminological confusion here.</p></div></div><p>Let O be a finite set of options: {O<sub>1</sub>,&nbsp;…,&nbsp;O<sub><em>n</em></sub>}. Each O<sub><em>i</em></sub> is a function from W to reals. Intuitively, they are bets, and the number is the return on each bet. I’ll follow standard terminology in philosophy and say that a function from worlds to reals is a <em>random variable</em>. Given a random variable X (defined on W) and a probability function Pr, we can define the expectation Exp(W, Pr) as ΣPr(<em>w</em>)X(<em>w</em>), where the sum is across members of W.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p>Say a strategy S is a function from E and W to O such that if E(<em>x</em>)&nbsp;=&nbsp;E(<em>y</em>), then S(<em>x</em>)&nbsp;=&nbsp;S(<em>y</em>). That is, strategies are not more fine-grained than evidence. Intuitively, a strategy is something that The Experimenter can implement given their evidence, so it can’t require them to make more discriminations than their evidence does. For each S, we can define a random variable S<sub>R</sub> (read this as the return of S), such that S<sub>r</sub>(<em>w</em>)&nbsp;=&nbsp;S(<em>w</em>)(<em>w</em>). In words, the return of S at <em>w</em> is the value at <em>w</em> of the option S selects at <em>w</em>.</p>
<p>Finally, say that a strategy is <strong>recommended</strong><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> by Pr (relative to E, O and W) just in case for all <em>w</em> in W, and alternative options O<sub>a</sub> in O, Exp(S(<em>w</em>),&nbsp;Pr(•&nbsp;|&nbsp;E(<em>w</em>))) ⩾ Exp(O<sub>a</sub>,&nbsp;Pr(•&nbsp;|&nbsp;E(<em>w</em>))). In words, the option selected by S at <em>w</em> has maximal expected utility out of the options in O, relative to the result of updating Pr on the evidence available at <em>w</em>. Given these notions, we can state two important results Blackwell proves.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;This term is taken from <span class="citation" data-cites="DorstEtAl2021">Dorst et al. (<a href="#ref-DorstEtAl2021" role="doc-biblioref">2021</a>)</span></p></div></div><p>First, for any O, W and Pr, if E<sub>1</sub> is a refinement of E<sub>2</sub>, S<sub>1</sub> is recommended by E<sub>1</sub> and S<sub>2</sub> is recommended by E<sub>2</sub>, then Exp(S<sub>1</sub>, Pr)&nbsp;⩾&nbsp;Exp(S<sub>2</sub>, Pr). No matter what practical problem The Experimenter is facing, and no matter what their priors are, they are better off adopting a strategy recommended by the more informative experiment.</p>
<p>Second, for any W, if E<sub>1</sub> is not a refinement of E<sub>2</sub>, then for some O and Pr, there exists an S<sub>1</sub> is recommended by E<sub>1</sub> and S<sub>2</sub> is recommended by E<sub>2</sub> such that Exp(S<sub>1</sub>, Pr)&nbsp;&lt;&nbsp;Exp(S<sub>2</sub>, Pr). That is, if E<sub>1</sub> is not more informative than E<sub>2</sub>, then for some practical problem, it is better in expectation to perform E<sub>2</sub> and carry out some strategy recommended by it.</p>
<p>Blackwell isn’t the first to connect the value of experiments to the relative value of strategies and options in this way; for some history of this idea see <span class="citation" data-cites="Das2023">Das (<a href="#ref-Das2023" role="doc-biblioref">2023</a>)</span> and <span class="citation" data-cites="LeCam1996">Cam (<a href="#ref-LeCam1996" role="doc-biblioref">1996</a>)</span>. But he works out the consequences of it in much more detail than anyone had before him. (The two results I’ve listed here don’t go close to exhausting what he proved, but they are enough for our purposes.) Philosophers have primarily focussed on the first of these two results. And they have focussed largely on the special case when E<sub>2</sub>(<em>w</em>)&nbsp;=&nbsp;W; i.e., when ‘performing’ experiment E<sub>2</sub> means getting no information at all.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> In this section we’ll also ignore the second result, but we will pay attention to the case where E<sub>2</sub> isn’t universal.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;Further, they haven’t always credited Blackwell (or the earlier results from Peirce and Ramsey that Das discusses) when they do discuss the results. We’re grateful to John Quiggin for pointing out to us the importance of Blackwell’s results in this context.</p></div></div><p>John <span class="citation" data-cites="Geanakoplos1989">Geanakoplos (<a href="#ref-Geanakoplos1989" role="doc-biblioref">[1989] 2021</a>)</span> proved an interesting generalisation of this first result. As noted earlier, Blackwell’s theorems presuppose that each experiment is partitional. Formally, E is partitional iff for all <em>w</em>, <em>w</em>&nbsp;∈&nbsp;E(<em>w</em>), and for all <em>w</em>,&nbsp;<em>v</em>, if <em>v</em> ∈ E(<em>w</em>), then E(<em>w</em>)&nbsp;=&nbsp;E(<em>v</em>). Geanakoplos shows something interesting about experiments that are reflexive, transitive, and nested. These are defined as follow (with leading quantifiers over worlds left implicit)</p>
<dl>
<dt>Reflexive</dt>
<dd>
<em>w</em> ∈ E(<em>w</em>).
</dd>
<dt>Transitive</dt>
<dd>
If <em>v</em> ∈ E(<em>w</em>), then E(<em>w</em>) ⊆ E(<em>v</em>).
</dd>
<dt>Nested</dt>
<dd>
Either E(<em>w</em>)&nbsp;∩ E(<em>v</em>) = ∅, or E(<em>w</em>) ⊆ E(<em>v</em>), or E(<em>v</em>) ⊆ E(<em>w</em>).
</dd>
</dl>
<p>He shows that both the results of Blackwell’s described above continue to hold when E<sub>1</sub> is reflexive, transitive, and nested, as long as E<sub>2</sub> is partitional.</p>
<p>This result has had some influence on recent philosophical work. It suggests the following kind of argument.</p>
<ol type="1">
<li>Performing experiments is valuable.</li>
<li>Performing experiments is valuable iff experiments are nested.</li>
<li>Therefore, experiments are nested.</li>
</ol>
<p>That’s fairly crude as stated, but it’s possible to develop it into a more sophisticated argument that has implications for what the correct epistemic logic should be. You can (more sophisticated) versions of this argument in <span class="citation" data-cites="Spencer2018">Spencer (<a href="#ref-Spencer2018" role="doc-biblioref">2018</a>)</span> and <span class="citation" data-cites="Dorst2019">Dorst (<a href="#ref-Dorst2019" role="doc-biblioref">2019</a>)</span>, and criticisms of these arguments in <span class="citation" data-cites="Williamson2019">Williamson (<a href="#ref-Williamson2019" role="doc-biblioref">2019</a>)</span> and <span class="citation" data-cites="Das2023">Das (<a href="#ref-Das2023" role="doc-biblioref">2023</a>)</span>.</p>
<p>The aim of this section is to show that two of the assumptions that Geanakoplos uses in proving these results are essential. First, E<sub>2</sub> has to be partitional; it is not sufficient that it is reflexive, transitive, and nested. Second, it cannot be that both W and O are infinite. Both results arguably help the Williamson-Das side of the debate mentioned in the previous paragraph, but we won’t go into that in more detail here. The aim is just to show the formal limits of Geanakoplos’s result.</p>
<p>Here is the model that shows that more refined experiments do not necessarily have higher expected value if both experiments are reflexive, transitive, and nested.</p>
<ul>
<li>W = {w<sub>1</sub>, w<sub>2</sub>, w<sub>3</sub>}</li>
<li>Pr(w<sub>1</sub>)&nbsp;=&nbsp;Pr(w<sub>2</sub>)&nbsp;=&nbsp;Pr(w<sub>3</sub>)&nbsp;= ⅓</li>
<li>O = {O<sub>1</sub>, O<sub>2</sub>}</li>
<li>O<sub>1</sub>(w<sub>1</sub>)&nbsp;= O<sub>1</sub>(w<sub>2</sub>)&nbsp;= O<sub>1</sub>(w<sub>3</sub>)&nbsp;= 0</li>
<li>O<sub>2</sub>(w<sub>1</sub>)&nbsp;=&nbsp;3</li>
<li>O<sub>2</sub>(w<sub>2</sub>)&nbsp;=&nbsp;9</li>
<li>O<sub>2</sub>(w<sub>3</sub>)&nbsp;=&nbsp;-6</li>
<li>E<sub>1</sub>(w<sub>1</sub>)&nbsp;=&nbsp;{w<sub>1</sub>,&nbsp;w<sub>3</sub>}</li>
<li>E<sub>1</sub>(w<sub>2</sub>)&nbsp;=&nbsp;{w<sub>2</sub>}</li>
<li>E<sub>1</sub>(w<sub>3</sub>)&nbsp;=&nbsp;{w<sub>3</sub>}</li>
<li>E<sub>2</sub>(w<sub>1</sub>)&nbsp;=&nbsp;{w<sub>1</sub>,&nbsp;w<sub>2</sub>, w<sub>3</sub>}</li>
<li>E<sub>2</sub>(w<sub>2</sub>)&nbsp;=&nbsp;{w<sub>2</sub>, w<sub>3</sub>}</li>
<li>E<sub>2</sub>(w<sub>3</sub>)&nbsp;=&nbsp;{w<sub>3</sub>}</li>
</ul>
<p>Given no information, the optimal strategy is to always take the bet, i.e., choose O<sub>2</sub> over the fixed return of 0 that is O<sub>1</sub>. This has an expected return of 2. Given E<sub>1</sub>, the only recommended strategy is to choose O<sub>1</sub> at w<sub>1</sub> and w<sub>3</sub>, and O<sub>2</sub> at w<sub>2</sub>, for an expected return of 2. But given the less informative E<sub>2</sub>, the recommended strategy is to choose O<sub>2</sub> at w<sub>1</sub> and w<sub>2</sub>, and O<sub>1</sub> at w<sub>3</sub>, for an expected return of 4. In this case, performing the less informative experiment has higher expected returns. (Though to be clear, both experiments have positive expected returns, relative to not doing anything.)</p>
<p>Next we’ll show the result does not hold when W and O are infinite. We have to be careful here because it’s easy to have a case where S<sub>1</sub> and S<sub>2</sub> are undefined. And it’s not interesting that Exp(S<sub>1</sub>,&nbsp;Pr)&nbsp;⩾&nbsp;Exp(S<sub>2</sub>, Pr) might sometimes fail to be true simply because one or other term in it isn’t defined. So we’ll restrict attention to cases where utilities are bounded, for any E and any <em>w</em> there is an optimal strategy given E(<em>w</em>), and the expectation of any recommended strategy is defined.</p>
<p>Let W be the reals in (0,1). E<sub>1</sub>(<em>x</em>)&nbsp;=&nbsp;[<em>x</em>,1), and E<sub>2</sub>(<em>x</em>)&nbsp;=&nbsp;(0,1). For any <em>x</em> in [0,1], let O<sub><em>x</em></sub>(<em>y</em>) be&nbsp;-1 if <em>x</em>&nbsp;&nbsp;<em>y</em>, and <em>x</em> if <em>x</em>&nbsp;&gt;&nbsp;<em>y</em>, and O be the set of all these O<sub><em>x</em></sub>. And Pr is the flat distribution over (0,1); the only fact we’ll need is that whenever 0&nbsp;&lt;&nbsp;<em>x</em>&nbsp;&lt;&nbsp;<em>y</em>&nbsp;&lt;&nbsp;1, the probability that the actual world is in (<em>x</em>,&nbsp;<em>y</em>) is <em>y</em>&nbsp;-&nbsp;<em>x</em>.</p>
<p>The only strategy recommended by E<sub>2</sub> is to always choose O<sub>0</sub>, which has a guaranteed return of 0. The strategy recommended by E<sub>1</sub> is to choose O<sub><em>x</em></sub> upon learning that the true value is in (<em>x</em>,&nbsp;1). That has an expected return of <em>x</em>, which is higher than all the alternatives. But following that strategy all the time has a guaranteed return of -1, which is worse than the strategy recommended by E<sub>2</sub>. And that’s true even though E<sub>2</sub> is partitional, and E<sub>1</sub> is reflexive, transitive, and nested.</p>
<p>Now there is something odd about this example - each of the O<sub><em>x</em></sub> is discontinuous. In each case, the payouts jump from -1 to <em>x</em> at a particular point. This suggests a question to which we don’t know the answer: If every member of O is continuous, are more refined experiments valuable in expectation? It is also unknown whether Geanakoplos’s results hold in countable frames. But what this model shows is that if we allow discontinuous payouts, and uncountable frames, the result does not hold.</p>
</section>
<section id="sec-dorst" class="level1 page-columns page-full" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Trust and Value</h1>
<p>The role of experiments in the frames discussed in <a href="#sec-nesting" class="quarto-xref">Section&nbsp;2</a> is somewhat curious. They are in one respect central, the theorems are all restricted to whether frames are partitional, nested, etc, but they are in another respect ephemeral. Ultimately what matters is not the experiment, but the probability that The Experimenter has after performing an experiment. This latter way of thinking is a helpful way to understand a striking recent result by <span class="citation" data-cites="DorstEtAl2021">Dorst et al. (<a href="#ref-DorstEtAl2021" role="doc-biblioref">2021</a>)</span>.</p>
<p>Say a probability frame is an ordered pair ⟨W, P⟩ such that W is a set (intuitively, of worlds), and P is a function from W to probability functions defined on w. One way to generate such a pair is to have some experiment E and prior probability Pr, each defined on W, and have P(<em>w</em>) be Pr(•&nbsp;|&nbsp;E(<em>w</em>)). But you can just cut out the E and Pr, and focus simply on W and P. As <span class="citation" data-cites="DorstEtAl2021">Dorst et al. (<a href="#ref-DorstEtAl2021" role="doc-biblioref">2021</a>)</span> show, this turns out to be mathematically a very helpful move. It lets you see a lot more interesting features of these frames.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> They call frames where P is generated from E and Pr in this way <em>prior frames</em>, and those will be the focus of discussion here, but it is interesting to see them as a special case of a more general class.</p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;At least in the case where W is finite; we’ll be getting to the issues when it is not.</p></div></div><p>One thing they prove by looking at the more general class is that when W is finite, the following two claims are equivalent. (I’ll state the claims formally, then explain my notation.)</p>
<dl>
<dt>Total Trust</dt>
<dd>
E(X&nbsp;|&nbsp;{<em>w</em>:&nbsp;Exp(X,&nbsp;P(<em>w</em>))&nbsp;⩾&nbsp;<em>t</em>},&nbsp;π)&nbsp;⩾&nbsp;<em>t</em>
</dd>
<dt>Value</dt>
<dd>
If O is a set of options, <em>s</em> is a recommended strategy for O, and <em>o</em> is a member of O, then Exp(<em>s</em>,&nbsp;π)&nbsp;⩾&nbsp;E(<em>o</em>,&nbsp;π).
</dd>
</dl>
<p>There is a bit there to unpack. We’ll follow them in using π for a probability function that is outside the frame. We’ll sometimes call it Novice’s probability function, as opposed to P(<em>w</em>) which is The Experimenter’s probability function at <em>w</em>.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> We’re generalising the notion of expectation a bit to allow for conditional expectations; Exp(X&nbsp;|&nbsp;p,&nbsp;Pr) is the expectation of X according to Pr(•&nbsp;|&nbsp;p). So here’s what Total Trust says. Take any random variable X. Update π on the proposition that consists of all and only worlds where The Experimenter at that world has an expected value for X at least equal to <em>t</em>. After that update, Novice also expects X’s value to be at least <em>t</em>.</p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;When the frame is a prior frame, it is natural to focus on the case where π&nbsp;=&nbsp;Pr, but again we’re not just looking at prior frames.</p></div></div><p>We discussed recommended strategies in <a href="#sec-nesting" class="quarto-xref">Section&nbsp;2</a>, so there is less to say about Value. What it says is that Novice does not expect any member of O to do better than any recommended strategy.</p>
<!--A decision problem is just a set of random variables. Intuitively, the problem is that Novice has to choose which bet to take from the set O, with the return being the value of the chosen bet at the actual world. A strategy for Novice is to defer the decision to The Expert. Formally, a strategy *s* is a function from W to O; it picks a random variable, i.e., a bet, at each world. For a strategy to be *recommended*, it has to satisfy two constraints. First, if P(*i*) = P(*j*), then *s*(*i*) = *s*(*j*). A strategy can't be more discriminating than The Expert's credences. For the second constraint, associate each strategy *s* with a random variable S such that S(*w*) = *s*(*w*)(*w*). That is, the value of S at *w* is the return at *w* of the member of O that *s* selects at *w*. The constraint then says that for any *O*~1~ ∈ O, E(*s*(*w*), P(*w*)) ⩾ E(O~1~, P(*w*)). That is, at *w*, The Expert does not think there is a member of O that in expectation does better than *s*(*w*). Given all that, Value says that The Novice does not expect any member of O to do better than any recommended strategy.-->
<p>One way Dorst et al put the equivalence between Total Trust and Value (on finite frames) is that π Totally Trusts a frame ⟨W, P⟩ iff it Values that frame. What I’ll show is that this equivalence breaks down when we drop the finiteness assumptions. Indeed, it breaks down even when W is countably infinite.</p>
<p>Start with a frame I’ll call <strong>Coin</strong>. A fair coin will be flipped repeatedly until it lands Tails. Let F be a random variable such that F&nbsp;=&nbsp;<em>x</em> iff the coin is flipped <em>x</em> times. (If the coin never lands Tails, we’ll stipulate that F&nbsp;=&nbsp;1. Since this has probability 0, it doesn’t make a difference to what follows, but this case will matter below.) Novice knows these facts about F, so π(F&nbsp;=&nbsp;<em>x</em>)&nbsp;=&nbsp;2<sup>-<em>x</em></sup>. If F&nbsp;=&nbsp;<em>x</em>, then The Experimenter knows F&nbsp;⩾&nbsp;<em>x</em>, and updates on that. That is, P(F&nbsp;=&nbsp;<em>x</em>)&nbsp;=&nbsp;π(•|F&nbsp;⩾&nbsp;x). For any positive integer <em>i</em>, let O<sub>i</sub> be the random variable that takes value 0 at F&nbsp;=&nbsp;<em>j</em>&nbsp;when <em>j</em>&nbsp;⩽&nbsp;<em>i</em>, and value 2<sup><em>i</em></sup> at F&nbsp;=&nbsp;<em>j</em> when <em>j</em>&nbsp;&gt; <em>i</em>. Let O be the set of each O<sub><em>i</em></sub>. The strategy <em>s</em> such that <em>s</em>(F&nbsp;=&nbsp;<em>i</em>)&nbsp;=&nbsp;O<sub><em>i</em></sub> is recommended, as can be easily checked. But E(<em>s</em>)&nbsp;=&nbsp;0, while for any <em>o</em> ∈&nbsp;O, E(<em>o</em>,&nbsp;π)&nbsp;= ½. So Value fails on <strong>Coin</strong>.</p>
<p>On the other hand, π does Totally Trust <strong>Coin</strong>. For any random variable X and threshold <em>t</em>, say an integer <em>k</em> is a cut-off if either Exp(X&nbsp;|&nbsp;F&nbsp;⩾&nbsp;<em>k</em>,&nbsp;π)&nbsp;⩾&nbsp;<em>t</em> and Exp(X&nbsp;|&nbsp;F&nbsp;⩾&nbsp;<em>k</em>&nbsp;+&nbsp;1,&nbsp;π)&nbsp;&lt;&nbsp;<em>t</em>, or Exp(X&nbsp;|&nbsp;F&nbsp;⩾&nbsp;<em>k</em>,&nbsp;π)&nbsp;&lt;&nbsp;<em>t</em> and Exp(X&nbsp;|&nbsp;F&nbsp;⩾&nbsp;<em>k</em>&nbsp;+&nbsp;1,&nbsp;π)&nbsp;⩾&nbsp;<em>t</em>. Let c<sub><em>i</em></sub> be the <em>i</em>’th cutoff. Partition the integers into the regions between cutoffs. More precisely, do the following. If 1 is not a cutoff, the first cell of the partition is {1,&nbsp;…,&nbsp;c<sub>1</sub>-1}; otherwise the first cell is just {1}. If there is a last cutoff <em>c</em>, the last cell is {c,&nbsp;c+1,&nbsp;…}. Otherwise, each cell is {c<sub><em>i</em></sub>,&nbsp;…,&nbsp;c<sub><em>i</em>+1</sub>-1}. Say a cell is <em>positive</em> if for every <em>k</em> in it, Exp(X&nbsp;|&nbsp;F&nbsp;⩾&nbsp;<em>k</em>,&nbsp;π)&nbsp;⩾&nbsp;<em>t</em>, and negative otherwise. (By the construction of the cells, Exp(X&nbsp;|&nbsp;F&nbsp;⩾&nbsp;<em>k</em>,&nbsp;π)&nbsp;⩾&nbsp;<em>t</em> is true for either all or none of the members.)</p>
<p>Let {c<sub><em>i</em></sub>,&nbsp;…,&nbsp;c<sub><em>i</em>+1</sub>-1} be an arbitrary positive interval. By construction, Exp(X&nbsp;|&nbsp;F&nbsp;⩾&nbsp;c<sub><em>i</em></sub>,&nbsp;π) ⩾&nbsp;<em>t</em>, and Exp(X&nbsp;|&nbsp;F&nbsp;⩾&nbsp;c<sub><em>i</em>+1</sub>,&nbsp;π)&nbsp;&lt;&nbsp;<em>t</em>. Since for some λ ∈ (0,1), Exp(X&nbsp;|&nbsp;F&nbsp;⩾&nbsp;c<sub><em>i</em></sub>,&nbsp;π) = λExp(X&nbsp;|&nbsp;F&nbsp;∈ {c<sub><em>i</em></sub>,&nbsp;…,&nbsp;c<sub><em>i</em>+1</sub>-1},&nbsp;π)&nbsp;+ (1-λ)Exp(X&nbsp;|&nbsp;F&nbsp;⩾&nbsp;c<sub><em>i</em>+1</sub>,&nbsp;π), it follows that Exp(X&nbsp;|&nbsp;F&nbsp;∈ {c<sub><em>i</em></sub>,&nbsp;…,&nbsp;c<sub><em>i</em>+1</sub>-1},&nbsp;π) ⩾&nbsp;<em>t</em>. Since this was an arbitrary positive interval, it follows that Exp(X&nbsp;|&nbsp;F&nbsp;∈&nbsp;I,&nbsp;π)&nbsp;⩾&nbsp;<em>t</em> for any positive interval I. Since Exp(X&nbsp;|&nbsp;{<em>w</em>:&nbsp;Exp(X,&nbsp;P(<em>w</em>))&nbsp;⩾&nbsp;<em>t</em>},&nbsp;π) is a weighted average of the values of Exp(X&nbsp;|&nbsp;F&nbsp;∈&nbsp;I,&nbsp;π) where I is one or other of the positive intervals, it follows that E(X&nbsp;|&nbsp;{<em>w</em>:&nbsp;Exp(X,&nbsp;P(<em>w</em>))&nbsp;⩾&nbsp;<em>t</em>},&nbsp;π)&nbsp;⩾&nbsp;<em>t</em>, as required.</p>
<!--Old proof that isn't quite working: To see this, let X be a random variable, and let *t* be any value. Let {*i*, …, *j*-1} be a set satisfying the following constraints. First, either *i* = 1 or E(X | F ⩾ *i*-1, π) ⩾ *t*. Second, for any *n* in that set, E(X | F ⩾ *n*, π) < *t*. Third, E(X | F ⩾ *j*, π) ⩾ *t*. Since E(X | F ⩾ *i*, π) = π(F < j | F ⩾ i)E(X | *i* ⩽ F < j) + π(F ⩾ j | F ⩾ i)E(X | F ⩾ j), it follows that E(X | *i* ⩽ F < j) < *t*. The set of all values *x* such that E(X | F ⩾ *x*, π) < *t* consists of at most countably many such sets, plus possibly an open set {*i*, *i*+1, …} such that whenever *x* ⩾ *i*, E(X | F ⩾ *x*, π) < *t*. So E(X | {*x*: E(X, P(F = *x*)) < *t*}, π) is the weighted average of countably many values each of which is less than *t*, so it is less than *t*.-->
<p>So π Totally Trusts <strong>Coin</strong>, but doesn’t Value it. So the equivalence between Total Trust and Value fails here. But you might very reasonably object on two scores. First, the value function used to generate the counterexample was unbounded, and we know that unbounded value functions lead to all sorts of paradoxes. Second, I didn’t just make W infinite, I made O infinite as well, so this isn’t a minimal generalisation of the original claim. It turns out that if we put both these constraints on, then the equivalence fails in the other direction: It is possible to get a frame that π Values, but does not Totally Trust.</p>
<p>Call the following frame <strong>Bentham</strong>. Again, a coin will be flipped until it lands Tails. If it ever lands Tails, F is the number of flips. If it never lands Tails, which has probability 0, then F&nbsp;=&nbsp;∞. Again, Novice knows these facts, and so far the case is just like <strong>Coin</strong>. But in this case, if F&nbsp;=&nbsp;<em>x</em>, The Experimenter knows that F&nbsp;⩽&nbsp;<em>x</em>, and The Experimenter updates on that. So if F&nbsp;=&nbsp;∞, The Experimenter learns nothing, but otherwise they can rule out all but finitely many possibilities. More precisely, P(F&nbsp;=&nbsp;<em>x</em>)&nbsp;=&nbsp;π(•|F&nbsp;⩽&nbsp;x).</p>
<p>The Novice probability does not Value this frame. Let Y be a random variable such that Y(F&nbsp;=&nbsp;∞) = 0, and for all finite <em>n</em>, Y(F&nbsp;=&nbsp;<em>n</em>) = 1 - 2<sup>-<em>n</em></sup>. E(Y&nbsp;|&nbsp;{<em>w</em>:&nbsp;Exp(Y,&nbsp;P(<em>w</em>))&nbsp;⩾&nbsp;⅔},&nbsp;π) =&nbsp;0&nbsp;&lt; ⅔. The only world <em>w</em> where Exp(Y,&nbsp;P(<em>w</em>))&nbsp;⩾&nbsp;⅔ is F&nbsp;=&nbsp;∞, and at F&nbsp;=&nbsp;∞, Y&nbsp;=&nbsp;0.</p>
<p>On the other hand, π does Totally Trust this frame. To see this, for any set of options O, recommended strategy S, random variable X (all defined on W), and integer <em>n</em>, let W<em>n</em> be the set {F&nbsp;=&nbsp;1, …, F&nbsp;=&nbsp;<em>n</em>}, O<sub><em>n</em></sub>, P<sub><em>n</em></sub>, S<sub><em>n</em></sub> and X<sub><em>n</em></sub> be the restrictions of O, P and S to worlds in W<em>n</em>. From the way P is constructed, i.e., by conditionalising on the set of worlds where F is no greater than it actually is, it follows that if S is recommended on ⟨W,&nbsp;P⟩, then S<sub><em>n</em></sub> is recommended on ⟨W<sub><em>n</em></sub>,&nbsp;P<sub><em>n</em></sub>⟩. Since ⟨W<sub><em>n</em></sub>,&nbsp;P<sub><em>n</em></sub>⟩ is a finite prior frame where E is reflexive, transitive and nested, and Pr&nbsp;=&nbsp;π, it follows by the result of Geanakoplos described in <a href="#sec-nesting" class="quarto-xref">Section&nbsp;2</a>, that the expected return of S<sub><em>n</em></sub> is greater than the expected return of any option in O<sub><em>n</em></sub>. For any random variable X, Exp(X,&nbsp;π) is the limit as <em>n</em> tends to ∞ of Exp(X<sub><em>n</em></sub>,&nbsp;π); this is because as <em>n</em> grows this covers all words in W except F&nbsp;=&nbsp;∞, which has probability 0. If the expected return of S is the limit <em>n</em> tends to ∞ of the expected return of S<em><sub>n</sub></em>, and the expected return of an option in O is the limit as <em>n</em> tends to ∞ of its counterpart in O<sub><em>n</em></sub>, and S<em><sub>n</sub></em> is better (in expectation) than every option in O<sub><em>n</em></sub>, it follows that S is better (in expectation) than every option in O. So Value is satisfied, as required.</p>
</section>
<section id="conclusion" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Conclusion</h1>
<ul>
<li>Say some stuff about why infinite frames matter.</li>
<li>It’s true that humans are finite, and so any infinite frame will be at best a model of a real human.</li>
<li>But any probabilistic model is really a model, since real humans also can’t do the computations needed to be perfectly computationally coherent.</li>
<li>And in some cases infinite models are simpler, and in important senses closer to reality.</li>
<li>It’s more natural to use the model in <a href="#sec-gallow" class="quarto-xref">Section&nbsp;1</a> than to use some discrete approximation to it, to model a scientist thinking about quantities that are roughly normally distributed.</li>
<li>We shouldn’t think that because circles are infinitely curved it’s more natural to model someone thinking about a chiliagon than to model them thinking about a circle.</li>
<li>There is something odd about the use of discontinuous models, as in <a href="#sec-nesting" class="quarto-xref">Section&nbsp;2</a>, and there are real puzzles about unbounded utility.</li>
<li>But any mathematical result that is meant to have epistemological significance should apply to at least some infinite cases.</li>
</ul>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Blackwell1951" class="csl-entry" role="listitem">
Blackwell, David. 1951. <span>“Comparison of Experiments.”</span> <em>Proceedings of the Berkeley Symposium on Mathematical Statistics and Probability</em> 2 (1): 93–102.
</div>
<div id="ref-Blackwell1953" class="csl-entry" role="listitem">
———. 1953. <span>“Equivalent Comparisons of Experiments.”</span> <em>The Annals of Mathematical Statistics</em> 24 (2): 265–72.
</div>
<div id="ref-LeCam1996" class="csl-entry" role="listitem">
Cam, L. Le. 1996. <span>“Comparison of Experiments: A Short Review.”</span> In <em>Statistics, Probability and Game Theory: Papers in Honor of David Blackwell</em>, edited by T. S. Ferguson, L. S. Shapley, and J. B. MacQueen, 127–38. Hayward, CA: Institute of Mathematical Statistics. doi: <a href="https://doi.org/10.1214/lnms/1215453569">10.1214/lnms/1215453569</a>.
</div>
<div id="ref-Das2023" class="csl-entry" role="listitem">
Das, Nilanjan. 2023. <span>“The Value of Biased Information.”</span> <em>British Journal for the Philosophy of Science</em> 74 (1): 25–55. doi: <a href="https://doi.org/10.1093/bjps/axaa003">10.1093/bjps/axaa003</a>.
</div>
<div id="ref-Dorst2019" class="csl-entry" role="listitem">
Dorst, Kevin. 2019. <span>“Evidence: A Guide for the Uncertain.”</span> <em>Philosophy and Phenomenological Research</em> 100 (3): 586–632. doi: <a href="https://doi.org/10.1111/phpr.12561">10.1111/phpr.12561</a>.
</div>
<div id="ref-DorstEtAl2021" class="csl-entry" role="listitem">
Dorst, Kevin, Benjamin A. Levinstein, Bernhard Salow, Brooke E. Husic, and Branden Fitelson. 2021. <span>“Deference Done Better.”</span> <em>Philosophical Perspectives</em> 35 (1): 99–150. doi: <a href="https://doi.org/10.1111/phpe.12156">10.1111/phpe.12156</a>.
</div>
<div id="ref-Gallow2018" class="csl-entry" role="listitem">
Gallow, J. Dmitri. 2018. <span>“No One Can Serve Two Epistemic Masters.”</span> <em>Philosophical Studies</em> 175 (10): 2389–98. doi: <a href="https://doi.org/10.1007/s11098-017-0964-8">10.1007/s11098-017-0964-8</a>.
</div>
<div id="ref-Geanakoplos1989" class="csl-entry" role="listitem">
Geanakoplos, John. (1989) 2021. <span>“Game Theory Without Partitions, and Applications to Speculation and Consensus.”</span> <em>The B.E. Journal of Theoretical Economics</em> 21 (2): 361–94. doi: <a href="https://doi.org/10.1515/bejte-2019-0010">https://doi.org/10.1515/bejte-2019-0010</a>.
</div>
<div id="ref-Levinstein2015" class="csl-entry" role="listitem">
Levinstein, Benjamin Anders. 2015. <span>“With All Due Respect: The Macro-Epistemology of Disagreement.”</span> <em>Philosophers’ Imprint</em> 15 (13): 1–20.
</div>
<div id="ref-Spencer2018" class="csl-entry" role="listitem">
Spencer, Jack. 2018. <span>“No Crystal Balls.”</span> <em>Noûs</em> 54 (1): 105–25. doi: <a href="https://doi.org/10.1111/nous.12252">10.1111/nous.12252</a>.
</div>
<div id="ref-Williamson2019" class="csl-entry" role="listitem">
Williamson, Timothy. 2019. <span>“Evidence of Evidence in Epistemic Logic.”</span> In <em>Higher-Order Evidence: New Essays</em>, edited by Mattias Skipper and Asbjørn Steglich-Petersen, 265–97. Oxford: <span>O</span>xford <span>U</span>niversity <span>P</span>ress. doi: <a href="https://doi.org/10.1093/oso/9780198829775.003.0013">10.1093/oso/9780198829775.003.0013</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/brian\.weatherson\.org\/quarto-papers");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>