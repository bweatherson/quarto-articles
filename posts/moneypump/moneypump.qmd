---
title: "Consistency and Resoluteness"
abstract: |
  When does a little story in which a character loses money, or at least comes out with less money than they might easily have had, reveal a defect in that character's rationality? We argue that these stories are less philosophically revealing than is often assumed. In particular, we argue the story can only be used in this kind of argument if the character has firm beliefs about what they will do later in the story. This constraint is, we argue, violated in recent arguments against imprecise credences and incomparable values.
author:
  - name: Harvey Lederman
    url: https://www.harveylederman.com
    affiliation: University of Texas
    affiliation_url: https://utexas.edu
    orcid_id: 0000-0001-9438-097X
  - name: Brian Weatherson 
    url: http://brian.weatherson.org
    affiliation: University of Michigan
    affiliation_url: https://umich.edu
    orcid_id: 0000-0002-0830-141X
date: 02-15-2025
categories:
  - epistemology
  - games and decisions
draft: true
format:
  html:
    css: ../trad_defn.css
  pdf:
    output-file: "Consistency and Resoluteness"
    include-in-header:
      - file: ../quarto2024.tex
      - text: |
         \cehead{
                 Lederman and Weatherson
                 }
    include-after-body: 
        text: |
          \noindent Draft of February 2025.
---

One genre of parable has played a key role in philosophical theorizing about rationality. In some respects, the conventions of the genre are simple: A character is portrayed, presented with certain choices, and, in response, loses something of value, with no compensatory gain. The inevitable moral is then drawn: the protagonist displays a rational defect.

Recently this kind of parable has been deployed by Adam @Elga2010, to argue against imprecise credences, and by Johan Gustaffsson [-@Gustafsson2022; @Gustafsson2025], to argue against incomplete preferences. We argue that these parables fail to ground convincing arguments. This is interesting both for debates about the nature of credences and values, but also for more general debates about the role of these parables in philosophy.

Let's start with three such parables that we hope you'll agree are not persuasive.

Dylan owns _B_, but has a slight preference for _A_. So they trade _B_ plus ε for _A_. The next day they wake up with the opposite preference, and trade _A_ plus ε for _B_. At the end they are back where they started, minus 2ε. Should this story make us think that rational people never change their tastes? Hopefully not.

Blake has credence 0.6 in _p_. They pay 0.55 for a bet that pays 1 if _p_, and 0 otherwise. The next morning, they wake up and find, much to their surprise, that they now have credence 0.4 in _p_. They sell the bet for 0.45, netting a loss of 0.1. This one is a little more controversial, but we also don't think that this shows that changing one's beliefs is irrational.^[Two important caveats here. One is that believers in various uniqueness theses will think that Blake is not perfectly rational; see @KopecTitelbaum2016 for a survey of the issues here. But note that uniqueness is a theory of substantive rationality, and these stories are meant to reveal violations of structural rationality. So we think uniqueness shouldn't be assumed here. Another is that there is an argument from David @Lewis1999b that not conditionalising will lead to a money pump, and Blake doesn't conditionalise. But as several authors have pointed out (e.g., @Bradley2005), Lewis's argument shows at most that any policy other than conditionalisation leads to a money pump. And Blake has no such policy; they just find themselves with new beliefs.]

Leslie is offered the following trade: If they pay 5, they will receive a bet that pays 8 if this fair coin lands heads, and 0 if it lands tails. Also, they have the option of paying 1 to put off their decision until after the coin is flipped. Textbook theories of rationality say that they should pay the 1 and take this option. But whatever way the coin lands, and whatever they do, they would have been better off doing that without paying 1. Here we think everyone will agree that Leslie does nothing irrational by paying to delay the decision, even though whatever happens, they could have done better. In general, paying for options is not always irrational. Anyone who pays extra for a cancellable flight or hotel does that, and these payments are not always irrational.

These cases show, we think, that stories involving money pumps don't reveal irrationality on the part of the protagonist if the story involves changes of desire, or changes of belief, either through 'fickle' change (@Woodard2022) or through learning. We want to suggest a similar constraint in the same neighbourhood. The protagonist must have beliefs about what they will do at future nodes, and these beliefs must update by conditionalisation. If that's not true, we will argue, the money pump parable doesn't show anything.

<!--
In other respects, though, the generic conventions of this sort of parable are complex, and often not articulated explicitly. For instance, certain aspects of the protagonist's state of mind must remain constant throughout the story. If someone likes grapes today and pays money for them, but due to factors outside their control, finds tomorrow that they don't like those grapes at all, it's not a defect of \emph{rationality} if they sell the grapes for a loss. Or again, if a person buys a flexible plane ticket today thinking they may later change their mind about the trip; it's no defect of their rationality if they end up going on the trip, at a loss relative to what they could have paid. As these cases illustrate, if the protagonist of the parable changes, the story wouldn't so clearly illustrate a rational defect as opposed to something else. People change; that's life, a bit of tough luck, not foolishness.

But what exactly are the requirements of the genre of the moneypump? One response to the cases above is to hold that they require no character development of a certain kind. The psychology of the characters depicted in these stories is typically simplistic; they have desires/preferences and beliefs/credences, but nothing more. So, one might hold that the genre requires that these states----both the protagonist's preferences and their beliefs---must remain fixed throughout the story. But this claim (and in particular the one about beliefs) is too strong. Even when a money pump is given `` with foresight'', the person will come to know (and hence believe) that certain things have happened, which they merely knew (believed) would happen before. If such tensed claims are different than the untensed ones, they will gain (and lose) knowledge---and beliefs---as the story unfolds. 

A weaker condition, which we expect is one most proponents of these arguments have had implicitly in mind, would require that the protagonist's desires or preferences alone must remain constant, while the person's beliefs may evolve (at least provided they do so in otherwise rational ways). The main goal of this note is to argue that this requirement is not enough: a moneypump argument dramatizes a rational defect only if the character it depicts is able to have certain knowledge or beliefs about what they will do. We will discuss different versions of this condition in what follows, but perhaps the simplest states that a moneypump must concern characters who can form beliefs about what they will do, and, once they come to believe that they will perform an action, this belief evolves in response to the evidence throughout the rest of the story. 
 %A far harder question, however, concerns whether they need also to know at the outset what they will do, or whether they might have mistaken beliefs about what they will do, or for that matter no beliefs at all. 
-->
So consider a canonical money-pump argument against incomplete preferences, often called the "Single Souring Moneypump" [@Chang1997 11; @Gustafsson2022 26]. The tree for this is shown in @fig-single-souring.

```{r}
#| echo: FALSE
#| output: FALSE

require(Rcpp)
require(tidyverse)
font_opts <- list(extra.preamble=c("\\usepackage{fontspec}", 
                                   "\\setmainfont{EB Garamond}"))

if(knitr::is_latex_output()) {
  knitr::opts_chunk$set(dev = 'tikz')
}
options(tinytex.engine = "xelatex")
```

```{r engine='tikz', engine.opts=font_opts}
#| label: fig-single-souring
#| fig.cap: "The Single Souring Moneypump"
#| fig.ext: 'pdf'
#| cache: FALSE
#| echo: FALSE

\usetikzlibrary{calc}

\tikzset{
% Two node styles for game trees: solid and hollow
solid node/.style={circle,draw,inner sep=1.5,fill=black},
hollow node/.style={circle,draw,inner sep=1.5},
square node/.style={rectangle,draw, inner sep = 1, fill = black}
}

% Specify spacing for each level of the tree
\tikzstyle{level 1}=[level distance=12mm,sibling distance=15mm]
\tikzstyle{level 2}=[level distance=15mm,sibling distance=15mm]
\tikzstyle{level 3}=[level distance=13mm,sibling distance=11mm]


\begin{tikzpicture}[grow=right, sloped]
\node[hollow node, draw] {}
    child {
        node[solid node, draw] {}
        child {
            node[square node, fill, inner sep=1.5pt, label=right:{\emph{B}}] {}
            edge from parent
            node[above] {}
        }
        child {
            node[square node, fill, inner sep=1.5pt, label=right:{\emph{A}-}] {}
            edge from parent
            node[below] {}
        }
        edge from parent
        node[below] {}
    }
        child {
        node[square node, fill, inner sep=1.5pt, label=right:{\emph{A}}] {}
        edge from parent
        node[above] {}
    };
\end{tikzpicture}
```


The agent is presented first with a choice between taking Up, which results in _A_, or Down, which results in a choice between option _B_ and _A_-. The protagonist is assumed to prefer _A_ to _A_-, but to have no relevant preferential relations between either _A_ and _B_ or _A_- and _B_ (that is, they are not indifferent between the elements of these pairs, and do not prefer one to the other). Plausibly, then, the agent is rationally permitted, in their first choice, to take either option: they can take Up and get _A_ or take Down and face the choice between _A_- and _B_. The problem is what happens if they take this second option. For in that case, it would seem that they are permitted again to take _A_-, but this is a loss relative to what they could have had at no cost, i.e. _A_.

In this simple case, a normal person who made the decision to go Down, rather than the sure thing of _A_, would do so in the belief (in fact, presumably, in the knowledge) that they would go on to choose _B_, not _A_-. Indeed, it seems to us that anyone who made this choice without the belief that they would later choose _B_ would be doing something odd in the case as described. So, if such a person did make the choice in the first place, to go down, giving themselves the option between _B_ and _A_-, and if they then chose _A_-, this choice would either (a) require a change in their belief about what they would do, or (b) require that the person choose _A_- while still believing that we would choose _B_. The second of these options, (b), quickly leads to inconsistency given natural constraints on the sort of person for whom a moneypump dramatizes a rational defect. Provided the hero knows that they're in fact faced with the choice, and provided they update their conditional belief that, if they are faced with the choice, they will choose _B_, then at the moment they make the choice, they will believe that they are choosing _B_. Provided they also believe that they are choosing what they are choosing when they choose it, they will believe that they are choosing _A_-. Given knowledge that these were exclusive options, the hero's beliefs are inconsistent, hence irrational. 

If a moneypump only dramatizes incoherence if it is compatible with the protagonist's beliefs about what they will do being held fixed (ruling out (a) as an option in the above story), and we can furthermore motivate a rational requirement that, in this case, the person who goes Down believes that they will later choose _B_, this moneypump (and its descendants, on which, more soon) would disappear. If, however, beliefs like this one are instead allowed to shift in the course of a moneypump, and only their preferences must be held fixed throughout the story, then the moneypump is genuine. So which is it?
%It takes a bit to spell out why \emph{exactly} the latter would be rational---we'll come back to that below---but for now the question is whether (a) is a problem. If I change my mind in the course of the choice, would that violate the generic conventions of the money-pump, or is this the sort of change of belief that should be allowed?

So far we have spoken about the capacity to rationally form beliefs about what one will do, and to have that belief evolve rationally through the moment of choice. A different approach, which we are also open to, would be to require that a moneypump illustrates a relevant rational defect only if the character portrayed is capable of knowing what they will later do. Since knowledge requires truth, if it is a requirement of the genre that the character can choose Down only if they know they will choose _B_ later, then a person who will ultimately choose _A_- will not have been an appropriate target of the moneypump (since they will not have known that they would choose _B_). We ourselves think this diagnosis is important, and to different degrees even find it attractive, but we will mostly focus below on the diagnosis in terms of belief, because we expect it to be more widely appealing to proponents of moneypumps, who are typically interested in a notion of rationality that can be articulated in terms of belief/credence and desire/preference alone. We'll also abbreviate the relevant condition by saying that the person has the ability to form beliefs about what they will do, leaving implicit the very important additional requirement that, once formed, this belief continues to evolve in response to the evidence.

The above discussion helps to illustrate the important distinction between the claim that a condition is a rational requirement and the claim that a moneypump can dramatize a rational defect only if it depicts people who satisfy a given condition. It is at least controversial whether, even in simple cases like the Single-Souring Moneypump, being able to know what you will do later is a requirement of rationality. Suppose that, unforeseen by the moneypumper or the chooser, a blow to the head will make the chooser have a thirst for _A_- in between their choice of Down and their decision between _A_- and _B_. They would then violate the putative rational requirement. Some will conclude that the rational requirement should be rejected, since it does not seem that the protagonist is irrational for making their initial choice, even though that was made without knowledge of what they would do at the later time. Others will hold that, the person is irrational \emph{with respect to the whole sequence} of their actions, arguing that a sequence can be irrational even if none of its constituent choices is. (On its own, the choice of A- in the second round would also be rational in this case, in light of what they then prefer.) We will not attempt to settle this controversy here. Instead we want to emphasize that this debate about what is a \emph{rational requirement} is a different one from the question of what background conditions on the protagonist's psychology are required if a moneypump is to be the basis for dramatizing a rational defect. We do not think it is at all plausible that there is a rational requirement that people's tastes remain the same. But we do think that, in the context of such preference changes (as in the case of the grapes or the plane tickets), a loss no longer dramatizes a rational defect. Such changes put the person out of bounds, as it were. The same point applies to beliefs about what one will do: we are not claiming that it is a rational requirement that, in every case, a person be able to form such beliefs. We are instead claiming that it is only in cases where people are capable of forming such beliefs that a moneypump illustrates a rational defect.

%The same style of argument can't be leveled against a requirement that a person who knowingly faces this sequence of choices choose Down only if they believe they will choose _B_. If the person is, in advance, uncertain of whether their preferences will stay the same at the later nodes, and for this reason they don't have the relevant belief, then it's quite a different problem than the one we saw above. In that case you're forced to treat yourself a bit like another person, a future randomizing device. If your preferences are ``standard'' (satisfying completeness and independence) there's no problem: you should just choose what's best by your current lights. If they're not, and say, they're incomplete, then the question will depend on hard issues about how people with such nonstandard preferences should handle decisions under risk (or for that matter uncertainty), which isn't our topic here.

Before turning to our argument for this claim, we want to further illustrate the application of our constraint to two prominent examples: one due to Elga, and the other due to Gustafsson. The discussion will help to develop the exact form of our thesis, and also highlight the contrast between our own diagnosis of what goes wrong in these cases, and a different diagnosis, advocated by proponents of resolute choice.

ELGA:

We turn now to Gustafsson's ``A behavioral moneypump...'' This moneypump assumes a decision-maker whose choices between incomparable options are determined probabilistically. The agent faces a first choice, to go Up or Down. Regardless of which way they go, a coin will be tossed. If they have chosen Up,  they receive _A_- (if Heads) or _B_- (if Tails). If they choose Down, and the coin is Heads, they will choose between B- - and A. If the coin comes up Tails they will choose between B and A. Given arbitrary probabilities on the agent's choices, Gustafsson shows that we can choose a biased coin in such a way that the agent is rationally required to choose Up. But this is a moneypump, since the agent could improve their choice in every state: if Heads, by going Down and choosing _A_; if Tails by going Down and choosing _B_. 

There are two senses in which, in Gustafsson's example the protagonist cannot rationally form beliefs about what they will do at the outset. The first is that, they do not know how the coin will land, and so should not form an outright belief about what they will do (if they go Down). The second is that, they are not in a position to form a belief about what they will do \emph{even conditional on the coin landing Heads} (or for that matter Tails). It is this second sense of inability that our condition is designed to rule out: our claim is that moneypumps are effective only if they are compatible with the person having knowledge of / belief in certain conditionals about how they will act given the resolution of relevant empirical uncertainty. If one can only form probabilistic beliefs about what one will do in this conditional sense, our claim is that the person is alienated from their future selves in a way that defangs the moneypump.  Gustafsson's behavioral moneypump is a moneypump only for someone who is alienated from themselves in this way. If, however, we're allowed to include requirements about what beliefs they will have about their own choices (and the preservation of those beliefs), then the person who chooses Down may be required to do so believing they'll choose _A_ if Heads and _B_ if Tails. The probabilities disappear, and the person would be irrational if they deviated from the plan---not because they have deviated from the plan, but because that conflicts with what they believed they would do. (The same point can be made for the moneypump in Gustafsson 2022 TODO page number.)

This discussion illustrates how our approach differs from the usual form of Resolute Choice, or even from what Gustafsson calls Conservative Choice, in that it comes ready-made with an explanation for why deviating from the plan is irrational. Elga and Gustafsson both complain (CITE) against the fan of resolute choice that it's not clear why having made a plan should be a reason for a future choice. Gustafsson also argues that it's not clear why having made a plan should even be a tie-breaker when other things are equal. But the idea here is not that having made the plan gives you a reason to take one action or another. In the case of our proposal about knowledge, it's that a person who doesn't know what they will later do is out of bounds, not in the field of play. If they could have the knowledge, then since what one knows must be true, they would act in the relevant way. In the case of our proposal about belief, it's that a person who could not form and maintain the beliefs would be out of bounds. If they could form and maintain the beliefs, they would be moneypumped only if they violated the \emph{consistency} of their beliefs (which is irrational in a different way).

We think it is already of interest that the fan of incomplete beliefs or preferences (to mention just two) could respond to moneypump arguments against their position by advancing the idea that the opponent has got the generic conventions wrong. The true generic conventions, they might claim, require that beliefs about what you'll do stay the same throughout the process, once they're formed. The opponent of incompleteness might reject this claim about the genre, but the debate would at least have changed subject-matter. More strongly, we think this move would neutralize such moneypump arguments into a draw instead of a clear loss for those who favor the rational permissibility of such incompleteness.

But we want to go further than just suggesting this view, to give a direct argument for it. The argument is based on the following case, a slight variant of one from Rubinstein and Piccione, discussed by Stalnaker (1999, p 317). A fair coin will be flipped, and you will see the outcome. Regardless of how it comes up, you can choose to opt out or to opt in.  If you opt out, you get a payoff of 2. If you opt in, your memory of the outcome will be erased, and you'll face a second choice: guessing the outcome of the coin. If the coin came up Heads, and you guess correctly, you get a payoff of 6, otherwise 0. If it comes up Tails and you guess correctly, you get a payoff of 6, otherwise 0. 

There are two optimal strategies, each of which has an expected payout of 4. On the first, one opts out if Heads and opts in if Tails, choosing Tails at the next choice. On the second, one opts out if Tails and opts in if Heads, choosing Heads at the next choice. We think that the sort of character depicted in a moneypump should be able to execute one of these strategies, and obtain the best expectation. Either of our proposals---that such a character must be able to know what they will do, or that such a character must be able to form a belief about what they will do---would explain this verdict. If the person is able to come to know what they will do later (and remember that this is a form of conditional knowledge---they know what they will do if the coin comes up a certain way), then they will be able---by making the decision to execute this strategy---to come to know that if it is Heads (say) they will opt in and then play Heads. If they know this then plausibly, if they know that it is Heads, they know that they will opt in and then play Heads. Similarly, if they are able to come to believe that if it is Heads they will opt in and then play Heads (and maintain this belief), then if they come to know that it is Heads, they will plausibly believe that they will opt in and then play Heads. If this belief persists, then consistency will demand that they in fact play Heads.%\footnote{In the original version of the above case there is an asymmetry in the second round. If you opt in, the coin came up Heads, and you guess correctly, you get a payoff of 6, otherwise 0. If you opt in, it comes up Tails and you guess correctly, you get a payoff of 5, otherwise 0. In such a case, we have the judgment that the strategy if Heads, opt out, if Tails, opt in and then play Tails is the uniquely rational one. The question is why. Our suggestion is that, if the person plans and therefore come to believe that they will choose to opt out if Tails and then opt in followed by Heads if Heads, this makes the later choice of Tails (if Heads) irrational. Choosing Tails at that node would conflict with your earlier belief that you would choose Heads, by reasoning similar to the reasoning I gave above for the Single Souring Moneypump. If, in forgetting the outcome of the coin toss, the person also forgets their belief about what they would do at various nodes, it is not clear that the optimal strategy is the uniquely rational one. The fact that you can, in forming these plans and hence beliefs about what you will do, determine what will be consistent with your beliefs at later nodes, explains why you can in this case (as you couldn't in a two-person version) choose the optimal strategy. In choosing a plan at the start, you choose what you believe. In choosing what you believe, you choose what will be consistent with your beliefs, and hence what you will do if you remain rational.

%We haven't focused on this case in the main text because we think there are alternative stories that would deliver the same verdict about the rational action.
%}

This case seems to us similar to the stylized cases presented in moneypumps. Someone who grants this, and holds that only preferences (but nothing else) are held fixed in a moneypump, would have to concede that even a person with the preferences of a classical expected utility maximizer with utility linear in money would not be able to achieve the maximum payout in this case. They might of course claim that empirical forgetting of the kind depicted above should be ruled out, and not allowed in a true moneypump. But this new requirement---that for relevant empirical claims there is no loss of knowledge or belief---must be argued for as a further feature of moneypumps. Moreover, it is at least on a par with our own view, which says that the protagonist of a moneypump is able to know or form and preserve a belief about what  they will do. So we contend that this case provides evidence that to be the basis for drawing a moral of irrationality, the moneypump must be consistent with the claim that the protagonist can form beliefs about what they will do.

We have presented our main claim as an \emph{additional} claim, over and above the idea that preferences should be held fixed for a moneypump to reach its intended moral. We are, in fact, attracted to a stronger claim, that our condition is a replacement for this more standard one. In other words, we are open to the idea that preferences need not be held fixed in a moneypump, provided the protagonist is capable of knowing or having a belief about what they will do. This claim, just like the one about preferences, would deliver the correct verdict in our grapes and plane ticket cases. Moreover, in cases where preference-changes are relevant to the case but not relevant to the actions before a person (for instance, if in the single-souring moneypump, the person came to prefer _A_ over _B_, after making the initial choice to go down, while holding the rest of their preferences fixed), it does not seem to us that all bets are off about the rationality of the subsequent action. The \emph{reason} changes of preference matter in moneypumps seems to be that they make belief / knowledge about what the person will do impossible.

We have focused on an understanding of moneypumps as dramatizations of defects of rationality (CITE Christensen). A different understanding of such arguments is that the possibility of exploitation is itself the problem, not merely a dramatization of an underlying rational defect. There is then a question of what forms of exploitability are problematic. Our discussion of ``generic constraints'' could be translated into claims about the conditions under which exploitability is a rational problem. But we expect the translation to be less compelling to those who have this ``realistic'' understanding of moneypumps. In real life, we often do not know what we will do (even in this conditional sense), and are not in a position to form (rational) beliefs about it. We think there are independent reasons to reject this way of understanding moneypumps, but here is not the place to argue for that claim.

<!--
\begin{tikzpicture}[grow=right, sloped]
\node[circle, draw] {}
    child {
        node[circle, draw] {}
        child {
            node[circle, fill, inner sep=1.5pt, label=right:{\emph{B}}] {}
            edge from parent
            node[above] {}
        }
        child {
            node[circle, fill, inner sep=1.5pt, label=right:{\emph{A}-}] {}
            edge from parent
            node[below] {}
        }
        edge from parent
        node[below] {}
    }
        child {
        node[circle, fill, inner sep=1.5pt, label=right:{\emph{A}}] {}
        edge from parent
        node[above] {}
    };
\end{tikzpicture}
-->