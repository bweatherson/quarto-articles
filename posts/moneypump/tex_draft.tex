\documentclass[11pt]{article}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{setspace}
\usepackage{verbatim}
\usepackage{amsfonts}
\usepackage{amssymb}

\usepackage{nicefrac}

\usepackage{qtree}

\usepackage{tikz}

\usepackage{color}
\definecolor{ao(english)}{rgb}{0.0, 0.5, 0.0}

\usepackage{multirow,array}

\usetikzlibrary{decorations.pathreplacing}


\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 1},backref=true,colorlinks=true,citecolor=blue,linkcolor=blue]
 {hyperref}
 
 

%\usepackage{amssymb}
\usepackage{latexsym}
\usepackage{float}
\usepackage{graphicx}
\usepackage{enumitem}
%\usepackage{chngcntr}
\usepackage[left=1.8in,right=1.8in,top=1.4in,bottom=1.4in]{geometry}
\usepackage[font=small,labelsep=none]{caption}


\usepackage{natbib}



\usepackage[title]{appendix}
\usepackage{graphicx}
%\usepackage{stmaryrd}

\frenchspacing
\usepackage{CJK}


%\relative\long\def\lb{\llbracket}
%\relative\long\def\rb{\rrbracket}
%\relative\long\def\la{\langle}
%\relative\long\def\ra{\rangle}
%\relative\long\def\ul{\ulcorner}
%\relative\long\def\ur{\urcorner}

%\relative\long\def\alna{\succcurlyeq}
%\relative\long\def\smn{\ggcurly}

\usepackage{tikz}
\usetikzlibrary{calc}

\newcommand{\blacktriangleq}{\mathrel{\ooalign{$\blacktriangleright$\cr\hidewidth\raise-1.1ex\hbox{$-$}\hidewidth}}}



\setlength{\bibsep}{.01in}
% \setlength{\textwidth}{6.0in}
% \setlength{\textheight}{8.0in}
% \renewcommand{\topmargin}{-.0in}
\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}{Acknowledgement}[section]
\newtheorem{algorithm}{Algorithm}[section]
\newtheorem{assumption}{Assumption}[section]
\newtheorem{axiom}{Axiom}[section]
\newtheorem{case}{Case}[section]
\newtheorem{claim}{Claim}[section]
\newtheorem{conclusion}{Conclusion}[section]
\newtheorem{condition}{Condition}[section]
\newtheorem{conjecture}[theorem]{Conjecture}%[section]
\newtheorem{corollary}[theorem]{Corollary}%[section]
\newtheorem{criterion}{Criterion}[section]
%\newtheorem{definition}{Definition}[section]

\newtheorem{exercise}{Exercise}[section]
%\newtheorem{lemma}[theorem]{Lemma}%[section]
\newtheorem{notation}{Notation}[section]
\newtheorem{observation}{Observation}[section]
\newtheorem{problem}{Problem}[section]
\newtheorem{property}{Property}[section]
\newtheorem*{propertyun}{Property}
\newtheorem*{proposition*}{Proposition}
\newtheorem{proposition}[theorem]{Proposition}%[section]
%\newtheorem{remark}{Remark}[section]
\newtheorem*{remarkun}{Remark}
\newtheorem{fact}{Fact}[section]
\newtheorem{solution}{Solution}[section]
\newtheorem{summary}{summary}[section]
%\newtheorem{example}{Example}[section]

%\usepackage[linewidth=1pt]{mdframed}


\theoremstyle{definition}
\newtheorem{example}{Example}
%\theoremstyle{definition}
%\newtheorem{definition}[theorem]{Definition}[section]
\theoremstyle{definition}
\newtheorem{remark}[theorem]{Remark}%[section]

\global\long\def\rich{Richness}
\global\long\def\a{Anonymity}
\global\long\def\pi{Permutation Invariance}
\global\long\def\p{Strict Pareto}
\global\long\def\c{Completeness}
\global\long\def\eap{Ex Ante Pareto}
\global\long\def\sd{Stochastic Dominance}
\global\long\def\pan{Pairwise Anonymity}

\global\long\def\D{\mathbb D}
\global\long\def\I{\mathbb I}
\global\long\def\W{\mathbb W}
\global\long\def\P{\mathbb P}
\global\long\def\L{\mathbb L}


\title{Consistency and Resoluteness}
\author{}
\date{\today}

\begin{document}

\maketitle

One genre of parable has played a key role in philosophical theorizing about rationality. In some respects, the conventions of the genre are simple: A character is portrayed, presented with certain choices, and, in response, loses something of value, with no compensatory gain. The inevitable moral is then drawn: the protagonist displays a rational defect.

In other respects, though, the generic conventions of this sort of parable are complex, and often not articulated explicitly. For instance, certain aspects of the protagonist's state of mind must remain constant throughout the story. If someone likes grapes today and pays money for them, but due to factors outside their control, finds tomorrow that they don't like those grapes at all, it's not a defect of \emph{rationality} if they sell the grapes for a loss. Or again, if a person buys a flexible plane ticket today thinking they may later change their mind about the trip; it's no defect of their rationality if they end up going on the trip, at a loss relative to what they could have paid. As these cases illustrate, if the protagonist of the parable changes, the story wouldn't so clearly illustrate a rational defect as opposed to something else. People change; that's life, a bit of tough luck, not foolishness.

But what exactly are the requirements of the genre of the moneypump? One response to the cases above is to hold that they require no character development of a certain kind. The psychology of the characters depicted in these stories is typically simplistic; they have desires/preferences and beliefs/credences, but nothing more. So, one might hold that the genre requires that these states----both the protagonist's preferences and their beliefs---must remain fixed throughout the story. But this claim (and in particular the one about beliefs) is too strong. Even when a money pump is given `` with foresight'', the person will come to know (and hence believe) that certain things have happened, which they merely knew (believed) would happen before. If such tensed claims are different than the untensed ones, they will gain (and lose) knowledge---and beliefs---as the story unfolds. 

A weaker condition, which we expect is one most proponents of these arguments have had implicitly in mind, would require that the protagonist's desires or preferences alone must remain constant, while the person's beliefs may evolve (at least provided they do so in otherwise rational ways). The main goal of this note is to argue that this requirement is not enough: a moneypump argument dramatizes a rational defect only if the character it depicts is able to have certain knowledge or beliefs about what they will do. We will discuss different versions of this condition in what follows, but perhaps the simplest states that a moneypump must concern characters who can form beliefs about what they will do, and, once they come to believe that they will perform an action, this belief evolves in response to the evidence throughout the rest of the story. 
 %A far harder question, however, concerns whether they need also to know at the outset what they will do, or whether they might have mistaken beliefs about what they will do, or for that matter no beliefs at all. 

The significance of this claim can be illustrated by considering a canonical money-pump argument against incomplete preferences, often called the ``Single Souring Moneypump'' (Chang, Gustafsson). The agent is presented first with a choice between taking Up, which results in $A$, or Down, which results in a choice between option $B$ and $A-$. The protagonist is assumed to prefer $A$ to $A-$, but to have no relevant preferential relations between either $A$ and $B$ or $A-$ and $B$ (that is, they are not indifferent between the elements of these pairs, and do not prefer one to the other). Plausibly, then, the agent is rationally permitted, in their first choice, to take either option: they can take Up and get $A$ or take Down and face the choice between $A-$ and $B$. The problem is what happens if they take this second option. For in that case, it would seem that they are permitted again to take $A-$, but this is a loss relative to what they could have had at no cost, i.e. $A$.

In this simple case, a normal person who made the decision to go Down, rather than the sure thing of $A$, would do so in the belief (in fact, presumably, in the knowledge) that they would go on to choose $B$, not $A-$. Indeed, it seems to us that anyone who made this choice without the belief that they would later choose $B$ would be doing something odd in the case as described. So, if such a person did make the choice in the first place, to go down, giving themselves the option between $B$ and $A-$, and if they then chose $A-$, this choice would either (a) require a change in their belief about what they would do, or (b) require that the person choose $A-$ while still believing that we would choose $B$. The second of these options, (b), quickly leads to inconsistency given natural constraints on the sort of person for whom a moneypump dramatizes a rational defect. Provided the hero knows that they're in fact faced with the choice, and provided they update their conditional belief that, if they are faced with the choice, they will choose $B$, then at the moment they make the choice, they will believe that they are choosing $B$. Provided they also believe that they are choosing what they are choosing when they choose it, they will believe that they are choosing $A-$. Given knowledge that these were exclusive options, the hero's beliefs are inconsistent, hence irrational. 

If a moneypump only dramatizes incoherence if it is compatible with the protagonist's beliefs about what they will do being held fixed (ruling out (a) as an option in the above story), and we can furthermore motivate a rational requirement that, in this case, the person who goes Down believes that they will later choose $B$, this moneypump (and its descendants, on which, more soon) would disappear. If, however, beliefs like this one are instead allowed to shift in the course of a moneypump, and only their preferences must be held fixed throughout the story, then the moneypump is genuine. So which is it?
%It takes a bit to spell out why \emph{exactly} the latter would be rational---we'll come back to that below---but for now the question is whether (a) is a problem. If I change my mind in the course of the choice, would that violate the generic conventions of the money-pump, or is this the sort of change of belief that should be allowed?

So far we have spoken about the capacity to rationally form beliefs about what one will do, and to have that belief evolve rationally through the moment of choice. A different approach, which we are also open to, would be to require that a moneypump illustrates a relevant rational defect only if the character portrayed is capable of knowing what they will later do. Since knowledge requires truth, if it is a requirement of the genre that the character can choose Down only if they know they will choose $B$ later, then a person who will ultimately choose $A-$ will not have been an appropriate target of the moneypump (since they will not have known that they would choose $B$). We ourselves think this diagnosis is important, and to different degrees even find it attractive, but we will mostly focus below on the diagnosis in terms of belief, because we expect it to be more widely appealing to proponents of moneypumps, who are typically interested in a notion of rationality that can be articulated in terms of belief/credence and desire/preference alone. We'll also abbreviate the relevant condition by saying that the person has the ability to form beliefs about what they will do, leaving implicit the very important additional requirement that, once formed, this belief continues to evolve in response to the evidence.

The above discussion helps to illustrate the important distinction between the claim that a condition is a rational requirement and the claim that a moneypump can dramatize a rational defect only if it depicts people who satisfy a given condition. It is at least controversial whether, even in simple cases like the Single-Souring Moneypump, being able to know what you will do later is a requirement of rationality. Suppose that, unforeseen by the moneypumper or the chooser, a blow to the head will make the chooser have a thirst for $A-$ in between their choice of Down and their decision between $A-$ and $B$. They would then violate the putative rational requirement. Some will conclude that the rational requirement should be rejected, since it does not seem that the protagonist is irrational for making their initial choice, even though that was made without knowledge of what they would do at the later time. Others will hold that, the person is irrational \emph{with respect to the whole sequence} of their actions, arguing that a sequence can be irrational even if none of its constituent choices is. (On its own, the choice of A- in the second round would also be rational in this case, in light of what they then prefer.) We will not attempt to settle this controversy here. Instead we want to emphasize that this debate about what is a \emph{rational requirement} is a different one from the question of what background conditions on the protagonist's psychology are required if a moneypump is to be the basis for dramatizing a rational defect. We do not think it is at all plausible that there is a rational requirement that people's tastes remain the same. But we do think that, in the context of such preference changes (as in the case of the grapes or the plane tickets), a loss no longer dramatizes a rational defect. Such changes put the person out of bounds, as it were. The same point applies to beliefs about what one will do: we are not claiming that it is a rational requirement that, in every case, a person be able to form such beliefs. We are instead claiming that it is only in cases where people are capable of forming such beliefs that a moneypump illustrates a rational defect.

%The same style of argument can't be leveled against a requirement that a person who knowingly faces this sequence of choices choose Down only if they believe they will choose $B$. If the person is, in advance, uncertain of whether their preferences will stay the same at the later nodes, and for this reason they don't have the relevant belief, then it's quite a different problem than the one we saw above. In that case you're forced to treat yourself a bit like another person, a future randomizing device. If your preferences are ``standard'' (satisfying completeness and independence) there's no problem: you should just choose what's best by your current lights. If they're not, and say, they're incomplete, then the question will depend on hard issues about how people with such nonstandard preferences should handle decisions under risk (or for that matter uncertainty), which isn't our topic here.

Before turning to our argument for this claim, we want to further illustrate the application of our constraint to two prominent examples: one due to Elga, and the other due to Gustafsson. The discussion will help to develop the exact form of our thesis, and also highlight the contrast between our own diagnosis of what goes wrong in these cases, and a different diagnosis, advocated by proponents of resolute choice.

ELGA:

We turn now to Gustafsson's ``A behavioral moneypump...'' This moneypump assumes a decision-maker whose choices between incomparable options are determined probabilistically. The agent faces a first choice, to go Up or Down. Regardless of which way they go, a coin will be tossed. If they have chosen Up,  they receive $A-$ (if Heads) or $B-$ (if Tails). If they choose Down, and the coin is Heads, they will choose between B- - and A. If the coin comes up Tails they will choose between B and A. Given arbitrary probabilities on the agent's choices, Gustafsson shows that we can choose a biased coin in such a way that the agent is rationally required to choose Up. But this is a moneypump, since the agent could improve their choice in every state: if Heads, by going Down and choosing $A$; if Tails by going Down and choosing $B$. 

There are two senses in which, in Gustafsson's example the protagonist cannot rationally form beliefs about what they will do at the outset. The first is that, they do not know how the coin will land, and so should not form an outright belief about what they will do (if they go Down). The second is that, they are not in a position to form a belief about what they will do \emph{even conditional on the coin landing Heads} (or for that matter Tails). It is this second sense of inability that our condition is designed to rule out: our claim is that moneypumps are effective only if they are compatible with the person having knowledge of / belief in certain conditionals about how they will act given the resolution of relevant empirical uncertainty. If one can only form probabilistic beliefs about what one will do in this conditional sense, our claim is that the person is alienated from their future selves in a way that defangs the moneypump.  Gustafsson's behavioral moneypump is a moneypump only for someone who is alienated from themselves in this way. If, however, we're allowed to include requirements about what beliefs they will have about their own choices (and the preservation of those beliefs), then the person who chooses Down may be required to do so believing they'll choose $A$ if Heads and $B$ if Tails. The probabilities disappear, and the person would be irrational if they deviated from the plan---not because they have deviated from the plan, but because that conflicts with what they believed they would do. (The same point can be made for the moneypump in Gustafsson 2022 TODO page number.)

This discussion illustrates how our approach differs from the usual form of Resolute Choice, or even from what Gustafsson calls Conservative Choice, in that it comes ready-made with an explanation for why deviating from the plan is irrational. Elga and Gustafsson both complain (CITE) against the fan of resolute choice that it's not clear why having made a plan should be a reason for a future choice. Gustafsson also argues that it's not clear why having made a plan should even be a tie-breaker when other things are equal. But the idea here is not that having made the plan gives you a reason to take one action or another. In the case of our proposal about knowledge, it's that a person who doesn't know what they will later do is out of bounds, not in the field of play. If they could have the knowledge, then since what one knows must be true, they would act in the relevant way. In the case of our proposal about belief, it's that a person who could not form and maintain the beliefs would be out of bounds. If they could form and maintain the beliefs, they would be moneypumped only if they violated the \emph{consistency} of their beliefs (which is irrational in a different way).

We think it is already of interest that the fan of incomplete beliefs or preferences (to mention just two) could respond to moneypump arguments against their position by advancing the idea that the opponent has got the generic conventions wrong. The true generic conventions, they might claim, require that beliefs about what you'll do stay the same throughout the process, once they're formed. The opponent of incompleteness might reject this claim about the genre, but the debate would at least have changed subject-matter. More strongly, we think this move would neutralize such moneypump arguments into a draw instead of a clear loss for those who favor the rational permissibility of such incompleteness.

But we want to go further than just suggesting this view, to give a direct argument for it. The argument is based on the following case, a slight variant of one from Rubinstein and Piccione, discussed by Stalnaker (1999, p 317). A fair coin will be flipped, and you will see the outcome. Regardless of how it comes up, you can choose to opt out or to opt in.  If you opt out, you get a payoff of 2. If you opt in, your memory of the outcome will be erased, and you'll face a second choice: guessing the outcome of the coin. If the coin came up Heads, and you guess correctly, you get a payoff of 6, otherwise 0. If it comes up Tails and you guess correctly, you get a payoff of 6, otherwise 0. 

There are two optimal strategies, each of which has an expected payout of 4. On the first, one opts out if Heads and opts in if Tails, choosing Tails at the next choice. On the second, one opts out if Tails and opts in if Heads, choosing Heads at the next choice. We think that the sort of character depicted in a moneypump should be able to execute one of these strategies, and obtain the best expectation. Either of our proposals---that such a character must be able to know what they will do, or that such a character must be able to form a belief about what they will do---would explain this verdict. If the person is able to come to know what they will do later (and remember that this is a form of conditional knowledge---they know what they will do if the coin comes up a certain way), then they will be able---by making the decision to execute this strategy---to come to know that if it is Heads (say) they will opt in and then play Heads. If they know this then plausibly, if they know that it is Heads, they know that they will opt in and then play Heads. Similarly, if they are able to come to believe that if it is Heads they will opt in and then play Heads (and maintain this belief), then if they come to know that it is Heads, they will plausibly believe that they will opt in and then play Heads. If this belief persists, then consistency will demand that they in fact play Heads.%\footnote{In the original version of the above case there is an asymmetry in the second round. If you opt in, the coin came up Heads, and you guess correctly, you get a payoff of 6, otherwise 0. If you opt in, it comes up Tails and you guess correctly, you get a payoff of 5, otherwise 0. In such a case, we have the judgment that the strategy if Heads, opt out, if Tails, opt in and then play Tails is the uniquely rational one. The question is why. Our suggestion is that, if the person plans and therefore come to believe that they will choose to opt out if Tails and then opt in followed by Heads if Heads, this makes the later choice of Tails (if Heads) irrational. Choosing Tails at that node would conflict with your earlier belief that you would choose Heads, by reasoning similar to the reasoning I gave above for the Single Souring Moneypump. If, in forgetting the outcome of the coin toss, the person also forgets their belief about what they would do at various nodes, it is not clear that the optimal strategy is the uniquely rational one. The fact that you can, in forming these plans and hence beliefs about what you will do, determine what will be consistent with your beliefs at later nodes, explains why you can in this case (as you couldn't in a two-person version) choose the optimal strategy. In choosing a plan at the start, you choose what you believe. In choosing what you believe, you choose what will be consistent with your beliefs, and hence what you will do if you remain rational.

%We haven't focused on this case in the main text because we think there are alternative stories that would deliver the same verdict about the rational action.
%}

This case seems to us similar to the stylized cases presented in moneypumps. Someone who grants this, and holds that only preferences (but nothing else) are held fixed in a moneypump, would have to concede that even a person with the preferences of a classical expected utility maximizer with utility linear in money would not be able to achieve the maximum payout in this case. They might of course claim that empirical forgetting of the kind depicted above should be ruled out, and not allowed in a true moneypump. But this new requirement---that for relevant empirical claims there is no loss of knowledge or belief---must be argued for as a further feature of moneypumps. Moreover, it is at least on a par with our own view, which says that the protagonist of a moneypump is able to know or form and preserve a belief about what  they will do. So we contend that this case provides evidence that to be the basis for drawing a moral of irrationality, the moneypump must be consistent with the claim that the protagonist can form beliefs about what they will do.

We have presented our main claim as an \emph{additional} claim, over and above the idea that preferences should be held fixed for a moneypump to reach its intended moral. We are, in fact, attracted to a stronger claim, that our condition is a replacement for this more standard one. In other words, we are open to the idea that preferences need not be held fixed in a moneypump, provided the protagonist is capable of knowing or having a belief about what they will do. This claim, just like the one about preferences, would deliver the correct verdict in our grapes and plane ticket cases. Moreover, in cases where preference-changes are relevant to the case but not relevant to the actions before a person (for instance, if in the single-souring moneypump, the person came to prefer $A$ over $B$, after making the initial choice to go down, while holding the rest of their preferences fixed), it does not seem to us that all bets are off about the rationality of the subsequent action. The \emph{reason} changes of preference matter in moneypumps seems to be that they make belief / knowledge about what the person will do impossible.

We have focused on an understanding of moneypumps as dramatizations of defects of rationality (CITE Christensen). A different understanding of such arguments is that the possibility of exploitation is itself the problem, not merely a dramatization of an underlying rational defect. There is then a question of what forms of exploitability are problematic. Our discussion of ``generic constraints'' could be translated into claims about the conditions under which exploitability is a rational problem. But we expect the translation to be less compelling to those who have this ``realistic'' understanding of moneypumps. In real life, we often do not know what we will do (even in this conditional sense), and are not in a position to form (rational) beliefs about it. We think there are independent reasons to reject this way of understanding moneypumps, but here is not the place to argue for that claim.


\end{document}