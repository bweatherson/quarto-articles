% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  11pt,
  letterpaper,
  DIV=11,
  numbers=noendperiod,
  twoside]{scrartcl}
\usepackage{xcolor}
\usepackage[left=1.1in, right=1in, top=0.8in, bottom=0.8in,
paperheight=9.5in, paperwidth=7in, includemp=TRUE, marginparwidth=0in,
marginparsep=0in]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{3}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
  \setmainfont[ItalicFont=EB Garamond Italic,BoldFont=EB Garamond
SemiBold]{EB Garamond Math}
  \setsansfont[]{EB Garamond}
  \setmathfont[]{Garamond-Math}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{setspace}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother


% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}



\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\setlength\heavyrulewidth{0ex}
\setlength\lightrulewidth{0ex}
\usepackage[automark]{scrlayer-scrpage}
\clearpairofpagestyles
\cehead{
  Brian Weatherson
  }
\cohead{
  Draft Paper on Moneypumps
  }
\ohead{\bfseries \pagemark}
\cfoot{}
\makeatletter
\newcommand*\NoIndentAfterEnv[1]{%
  \AfterEndEnvironment{#1}{\par\@afterindentfalse\@afterheading}}
\makeatother
\NoIndentAfterEnv{itemize}
\NoIndentAfterEnv{enumerate}
\NoIndentAfterEnv{description}
\NoIndentAfterEnv{quote}
\NoIndentAfterEnv{equation}
\NoIndentAfterEnv{longtable}
\NoIndentAfterEnv{abstract}
\renewenvironment{abstract}
 {\vspace{-1.25cm}
 \quotation\small\noindent\emph{Abstract}:}
 {\endquotation}
\newfontfamily\tfont{EB Garamond}
\addtokomafont{disposition}{\rmfamily}
\addtokomafont{title}{\normalfont\itshape}
\let\footnoterule\relax

\makeatletter
\renewcommand{\@maketitle}{%
  \newpage
  \null
  \vskip 2em%
  \begin{center}%
  \let \footnote \thanks
    {\itshape\huge\@title \par}%
    \vskip 0.5em%  % Reduced from default
    {\large
      \lineskip 0.3em%  % Reduced from default 0.5em
      \begin{tabular}[t]{c}%
        \@author
      \end{tabular}\par}%
    \vskip 0.5em%  % Reduced from default
    {\large \@date}%
  \end{center}%
  \par
  }
\makeatother
\RequirePackage{lettrine}

\renewenvironment{abstract}
 {\quotation\small\noindent\emph{Abstract}:}
 {\endquotation\vspace{-0.02cm}}
\cehead{
        Lederman and Weatherson
        }
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Draft Paper on Moneypumps},
  pdfauthor={Harvey Lederman; Brian Weatherson},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}


\title{Draft Paper on Moneypumps}
\author{Harvey Lederman \and Brian Weatherson}
\date{2025}
\begin{document}
\maketitle
\begin{abstract}
When does a little story in which a character loses money, or at least
comes out with less money than they might easily have had, reveal a
defect in that character's rationality? We argue that these stories
illustrate irrationality in a far narrower range of cases than is often
assumed. In particular, we argue the story can only be used in this kind
of argument if the character has firm beliefs about what they will do
later in the story. This constraint is, we argue, violated in recent
arguments against imprecise credences and incomparable values.
\end{abstract}


\setstretch{1.1}
\section{Introduction}\label{introduction}

One genre of parable has played a key role in philosophical theorizing
about rationality. In some respects, the conventions of the genre are
simple: A character is portrayed, presented with certain choices, and
loses something of value, with no compensatory gain. The moral is then
drawn: the protagonist displays a rational defect.

But in other respects, the generic conventions of the parable of the
moneypump are complex. Not every case in which someone loses something
of value without recompense illustrates a rational defect. Lightning
might strike, or unjust, whimsical gods might deprive the protagonist of
some good. If the parable is to be the basis for its intended moral,
strict rules must be followed about the protagonist's state of mind, and
how their losses come about.

The first aim of this paper is to argue that, if a moneypump illustrates
a rational defect, it must be compatible with its protagonist having
firm beliefs at the start about what they will do if presented with any
of the choices described in the parable, and with the protagnoist's
changing these conditional beliefs only by updating them in response to
evidence. We will then argue that this thesis rules out several
prominent moneypumps: against imprecise credences Elga
(\citeproc{ref-Elga2010}{2010}) and incomplete preferences Gustafsson
(\citeproc{ref-Gustafsson2022}{2022}), Gustafsson
(\citeproc{ref-Gustafsson2025}{forthcoming}). Our proposal provides an
alternative to more familiar responses to such arguments. For instance,
unlike ``resolute choice'', it does not require that an agent's choice
of a plan at an earlier time give them reasons for action at a later
time. It also does not require that a sequence of choices be evaluated
as irrational when none of its constituent decisions are.

\section{Generic Constraints}\label{generic-constraints}

To illustrate the general idea that moneypump arguments must obey
generic conventions about the characters they depict, we begin with
three stories of losses without recompense which, we hope you'll agree,
do not illustrate the irrationality of their protagonists.

\begin{quote}
\textbf{Changing Preferences} Adrian owns \(B\), but has a slight
preference for \(A\). So he trades \(B\) plus \(\varepsilon\) for \(A\).
The next day he wakes up with the opposite preference, and trades \(A\)
plus \(\varepsilon\) for \(B\). At the end he is back where he started,
minus 2\(\varepsilon\).
\end{quote}

\begin{quote}
\textbf{Changing Beliefs} Blake has credence 0.6 in \(p\). She pays 0.5
for a bet that pays 1 if \(p\), and 0 otherwise. The next morning, she
wakes up and find, much to her surprise, that she now has credence 0.2
in \(p\). She sells the bet for 0.3, netting a loss of 0.2.
\end{quote}

\begin{quote}
\textbf{Waiting to Resolve Uncertainty} Cameron is offered the option to
bet on a fair coin toss before the coin is tossed, or to pay 1 to bet
after it is tossed (and after Cameron has observed the outcome of the
toss). The bet costs 5, and if they bet correctly, Cameron will receive
8, while if they guess incorrectly they will receive nothing. Plausibly,
Cameron should pay the 1 and then, once they have seen the outcome of
the coin flip, place a ``bet'' on the correct outcome. But notice that,
whatever way the coin lands, Cameron would have been better off making
the correct bet in advance, without paying 1.
\end{quote}

In each of these three cases, the protagonist loses something of value,
with no compensatory gain. But none of the stories provides evidence for
a verdict of (structural) irrationality. The story of Adrian clearly is
not a basis for concluding that preference changes are irrational.
Similarly (though this is more controversial) the story of Blake is not
a basis for concluding that changes of belief are a defect of
(structural) rationality.\footnote{Those who accept various uniqueness
  theses will think that Blake is not perfectly rational; see Kopec and
  Titelbaum (\citeproc{ref-KopecTitelbaum2016}{2016}) for a survey of
  the issues here. But uniqueness is a theory of substantive
  rationality, so this is no challenge to our claim that the case
  doesn't impugn Blake's structrual rationality. A second way of
  challenging our claim that Blake doesn't exhibit a defect of
  structural rationality might be based on an argument from David Lewis
  (\citeproc{ref-Lewis1999b}{1999}) that not conditionalising will lead
  to a money pump. But as several authors have pointed out (e.g.,
  Bradley (\citeproc{ref-Bradley2005}{2005})), Lewis's argument shows at
  most that any policy other than conditionalisation leads to a money
  pump. And Blake has no such policy; she just finds herself with new
  beliefs.} And, finally, the story of Cameron is not a basis for
concluding that paying to resolve one's uncertainty is a defect of
rationality in any sense; paying is clearly rationally permitted,
perhaps even required, in this case.

These cases show that stories involving sure loss relative to what a
person could have had don't reveal irrationality on the part of the
protagonist if the story involves certain changes of desire, or certain
changes of belief, whether because of `fickle' change (as in Blake's
case) or because of learning (as in Cameron's). In other words,
moneypump arguments are successful in general only if they are
compatible with their protagonists having relevantly stable preferences,
and relevantly stable beliefs. The constraint on such arguments that we
will propose is in the same neighbourhood: (i) that protagonists must
have beliefs about what they will do if future nodes are reached, and
(ii) that they must alter these beliefs only in response to arriving at
whatever nodes they do arrive at, moving from ``if I arrive at node
\(n\), I will choose action \(a\)'' to ``I am choosing action \(a\)''.
(For brevity, we will say that beliefs which obey this latter constraint
are *resilient\}.) In our view, stories which are incompatible with the
protagonist having such beliefs make no progress toward illustrating a
rational defect, anymore than the stories of Adrian, Blake and Cameron
do.

\section{The Constraint in Action}\label{the-constraint-in-action}

To illustrate our proposed constraint at work, consider a canonical
moneypump argument against incomplete preferences, often called the
``Single Souring Moneypump'' (\citeproc{ref-Chang1997intro}{Chang 1997};
\citeproc{ref-Gustafsson2022}{Gustafsson 2022, 26}). The tree for this
moneypump is shown in Figure~\ref{fig-single-souring}.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{moneypump_files/figure-pdf/fig-single-souring-1.jpg}}

}

\caption{\label{fig-single-souring}The Single Souring Moneypump}

\end{figure}%

The agent, call him Dylan, is presented at \(t_1\) with a choice between
taking Up, which results in \(A\), or Down, which results in a choice
(at \(t_2\)) between option \(A\)- and \(B\). Dylan is assumed to prefer
\(A\) to \(A\)-, but to have no relevant preferential relations between
either \(A\) and \(B\) or \(A\)- and \(B\). That is, he is not
indifferent between the elements of these pairs, and does not prefer one
to the other. (We will also assume for now that Dylan only has pure
strategies available, and cannot choose mixed strategies; we return to
this below.) Plausibly, Dylan is rationally permitted, at \(t_1\), to
take either option: he can take Up and get \(A\) or take Down and face
the choice between \(A\)- and \(B\). The problem is what happens if he
goes Down. For in that case, it would seem that he is also permitted at
\(t_2\) to take \(A\)- (since he doesn't disprefer it to \(B\)). But
this is a loss relative to what he could have had at no cost,
i.e.\textasciitilde{}\(A\).\footnote{This is a ``non-forcing''
  moneypump. For the distinction between forcing and non-forcing
  moneypumps, see Gustafsson and Espinoza
  (\citeproc{ref-GustafssonEspinoza2010}{2010, 761--62}) and Gustafsson
  (\citeproc{ref-Gustafsson2022}{2022, 27}).}

But let us suppose that our constraint holds: that Dylan has firm,
resilient beliefs about what he will do if faced with any of the
relevant choices. In other words, Dylan either firmly believes that if
he goes Down he will choose \(A\)- or he believes that if he goes Down
he will choose \(B\). Clearly, going Down with the former belief (that
he will choose \(A\)-) is irrational, given his option to choose \(A\)
by going Up. Moreover, if Dylan believes, when he chooses Down, that he
will go on to choose \(B\), but he nevertheless goes on to choose
\(A\)-, this choice would either (a) require a change in his belief
about what he would do other than updating in response to arriving at
the relevant node (i.e.~require that his belief is not resilient), or
(b) require that Dylan choose \(A\)- while believing that he is choosing
\(B\). The second of these options, (b), quickly leads to inconsistency
given natural assumptions about the sort of person for whom a moneypump
dramatizes a rational defect. Provided Dylan knows that he's in fact
faced with the choice between \(A\)- and \(B\), and provided he
correctly updates his conditional belief that, if he is faced with the
choice, he will choose \(B\), then at the moment he makes the choice, he
will believe that he is choosing \(B\). Provided he also believes that
he is choosing \(A\)- (which is after all what he is doing), and he
knows that these are exclusive options, Dylan's beliefs would be
inconsistent, and hence irrational. So, if a moneypump dramatizes
incoherence only if it is compatible with the protagonist having firm,
resilient beliefs about what they will do if they reach any of the
choice nodes (ruling out (a) as an option in the above story), and if we
can furthermore argue for a rational requirement that Dylan will go Down
only if he believes that he will later choose \(B\) even if he has mixed
strategies available to him, this moneypump could not dramatize the
incoherence of incomplete preferences.

\section{Arguing for the Constraint}\label{arguing-for-the-constraint}

We have two main arguments for the claim that a successful moneypump
must be compatible with the protagonist having firm beliefs about what
they would do at every node, and updating those beliefs only by
transitioning from \emph{if I arrive at node \(n\), I will choose action
\(X\)} to \emph{I am choosing action \(X\)} if they are in fact at node
\(n\).

The first is that this principle unifies and explains our earlier cases
involving Adrian (Preference Change), Blake (Belief Change), and Cameron
(Waiting to Resolve Uncertainty). There should be some story about why
the losses (or at least non-maximal gains) in those cases are not
evidence of irrationality, and ideally it should be a simple, common,
story. We have such a story to offer. The parables only serve as the
basis for this conclusion if the protagonist starts with firm, resilient
beliefs about what they will do at later stages. Adrian (Preference
Change) violates this constraint since he does not foresee his change of
preference, and thus believes that, if offered a choice at the later
time, he will stick with \(A\), rather than paying \(\varepsilon\) to
switch to \(B\). Blake (Belief Change) violates this constraint since
she does not foresee her change of credence, and thus predicts that,
when offered the choice of a bet at the later time, she will stick with
her original choice as well. Cameron (Waiting to Resolve Uncertainty)
violates the constraint because their beliefs about what they will do
are sensitive to the outcome of the coin, not just to which choice they
are facing at which time. Our principle correctly deems all three cases
out of bounds for the application of a moneypump argument. Although the
agent does not maximise returns, this isn't because they are irrational,
it is because they violate this principle.

Our second argument is that our constraint helps to make sense of why
players can achieve their maximal expectation in certain kinds of
decision problems where, intuitively, rational players should be able to
do so. The following example is taken (with very minor modifications)
from Stalnaker (\citeproc{ref-Stalnaker1999}{1999}), who in turn takes
it from Piccione and Rubinstein
(\citeproc{ref-PiccioneRubinstein1997}{1997}).

A fair coin will be flipped, and Ellis will see the outcome. Regardless
of how the coin comes up, Ellis can choose to opt out or to opt in. If
she opts out, she gets 2. If she opts in, her memory of how the coin
landed will be erased, and she will face a second choice: guessing the
outcome of the coin. If she guesses correctly, she gets 6, otherwise 0.

There are two optimal strategies in this decision problem, each of which
has an expected payout of 4. On the first, Ellis opts out if Heads and
opts in if Tails, choosing Tails if she is offered the second choice. On
the second, Ellis opts out if Tails and opts in if Heads, choosing Heads
if she is offered the second choice. We think that the sort of character
depicted in a moneypump should be able to execute one of these
strategies, and obtain the optimal expectation. If Ellis can form firm,
resilient beliefs about what she will do, then she can carry out one or
other of these strategies. But if it were consistent with the
conventions of a moneypump story that Ellis could either (a) not have a
firm belief at the earlier time about what she would do if presented
with further choices at the later time, or (b) change this belief other
than via our specified updating mode (i.e.~it is not resilient), then it
would also be allowed that, if Ellis opted in, she would simply have to
guess how the coin landed. The best Ellis could do would be to opt in
regardless of what happens, and then guess at the second decision node.
This strategy has an expected return of 3, by contrast to the expected
return of 4 Ellis could achieve by playing either of the optimal
strategies. Our claim about the generic conventions explains why there
is no moneypump based on this case against classical expected utility
theory: the putative ``moneypump'' is out of bounds.

We conclude the defense of our main thesis by noting that, as a matter
of sociological fact, the position we are defending is not, as it might
seem to some, an unusual or esoteric one. The ideas we are describing
are standard throughout decision theory and game theory. We invite you
to open any game theory textbook and look at how it treats decisions
over time. All of the theories put forward will assume, usually without
comment, that each player has firm beliefs about what strategy they have
adopted, and so how they will act at later times. These ``actions''
might include mixed strategies, so the player might not know what moves
they will make. But it's an unchallenged assumption that rational action
in a dynamic game requires having a firm belief about what one's later
self will do. Treating one's later self as an alien entity, or as
something like the weather that might change at random, is almost
unheard of in economics. \%So, while many philosophers have (implicitly)
rejected our view, this is not reflective of the prevailing orthodoxy
among those developing formal theories of decision-making. Of course,
the economists might be wrong. But we think it is at least of interest
that there is a tradition of working with formal models of
decision-making which sees this assumption as a natural one.

A more demanding position than the one we have defended would say that a
moneypump must be consistent with the decision-maker's having knowledge
of what they would do, not merely belief. On this approach, we suppose
that if Dylan goes Down, he does so in the knowledge that if he goes
Down he will choose \(B\). Together with our specification of how update
works, this assumption allows us to immediately derive the result that
Dylan chooses \(B\) (because knowledge is factive) without any
assumptions about the consistency of Dylan's beliefs. Since knowledge
requires belief, this view entails ours, and we will not argue against
it here. We see proponents of it as fellow-travelers, and have defended
the weaker version of our general position here in the hope that it will
be more generally attractive.

\section{Applications: Three
Moneypumps}\label{applications-three-moneypumps}

We now turn to working out applications of our thesis to specific money
pump arguments. We first complete our consideration of the
Single-Souring Moneypump (and discuss connections to Gustafsson
(\citeproc{ref-Gustafsson2022}{2022})). We then consider the moneypump
of Elga (\citeproc{ref-Elga2010}{2010}), and close by considering the
work of Gustafsson (\citeproc{ref-Gustafsson2025}{forthcoming}).

\subsection{Single Souring and Mixed
Strategies}\label{single-souring-and-mixed-strategies}

We already began above to discuss how our claim allows proponents of
incomplete preferences to offer a response to the Single-Souring
Moneypump. In that earlier discussion, however, we left one important
loose end. We did not provide a full-throated defense of the claim that
it is a rational requirement that if Dylan has beliefs about what he
will do at future nodes, he will choose to go Down only if he believes
that he will choose \(B\).\footnote{Note that even if the alternative
  position, which uses knowledge rather than belief is accepted, it
  plausibly would still suffice to argue for this rational requirement,
  since if this belief is required, then the person could plausibly not
  have knowledge that they would act in any way other than the one
  prescribed by the belief.} It is clear that Dylan should not go Down
with a belief that he will later choose \(A\)-: in that case, he would
in effect be choosing \(A\)- over \(A\). But we need to say more about
ways in which Dylan might go Down without either believing that he will
choose \(A\)-, or believing that he will choose \(B\).

Two such ways are already ruled out by the proposed constraint defended
above. One is that Dylan has no attitude at all about what he will later
do. The other is that he has some non-extreme probability about what he
will do, but regards his future decision as something like the weather
that he can at best have an informed guess about. Neither of this is
compatible with Dylan have a firm, resilient belief about what he will
do if he reaches future nodes.

But there is, perhaps, a third option we haven't yet ruled out. Dylan
might have an intermediate probability about his future actions because
he is playing a mixed strategy.

Just what mixed strategies are, and when they are rationally
permissible, is a notoriously difficult question. We're hardly going to
resolve this here, but we do need to lay out some of the options, for it
turns out that what our argument says about the permissibility of mixed
strategies (provided any mixed strategies are permissible) depends on
the details of just how these strategies are understood.

Our preferred way of understanding mixed strategies is in terms of
beliefs that other parties have about what a player will do. What it
means to say that a player's strategy is (for example) a 60/40 mix of Up
and Down at a node means that other players have credence 0.6 that, were
that node reached, the player would go Up
(\citeproc{ref-Aumann1987}{Aumann 1987}). If that's all a mixed strategy
is, then since there are no other players here, there isn't a missing
option for Dylan that we haven't covered.

One might, in a similar spirit, say that a mixed strategy requires that
all players, including Dylan himself, have this credence.\footnote{Williams
  (\citeproc{ref-Williams2014}{2014}) distinguishes between choosing
  randomly, and choosing to randomise. We mean this paragraph to be
  about the case where Dylan chooses randomly at \(t_2\), and the next
  paragraph (and following) to be about the case where he chooses to
  randomise.} If this is all that a mixed strategy is, then again we're
back in the situation where Dylan lacks a firm prediction of his future
decisions, which is ruled out by our proposed constraint on genuine
moneypumps.

But our earlier arguments did not rule out the possibility that Dylan
adopts a mixed strategy where this is understood in a more ``objective''
way, involving an external randomizing device. If Dylan is choosing to
randomize in this way, he does in some sense have a firm belief at
\(t_1\) about what he'll do at \(t_2\): he'll get out his coin, or dice,
or spinner, and see what they tell him to do.

But if this is what a mixed strategy comes to, we will argue that the
mixed strategy is irrational for a more familiar reason. Assume that at
\(t_2\) Dylan sets the randomizing device to choose \(A\)- with
probability \(p\), and at \(t_1\) he believes that he'll use the
randomizing device and follow what it says. Then he would be better off
randomizing at \(t_1\), choosing \(A\) with probability \(p\), and Down
followed by \(B\) with probability \(1-p\). This alternative
stochastically dominates the alternative of randomizing at \(t_2\). So,
the alternative is irrational.

There are two natural objections to this argument. The first is to the
premise that it is a rational requirement not to choose stochastically
dominated options.\footnote{For discussion of this premise see, for
  example, Hare (\citeproc{ref-hare2010take}{2010}), Bader
  (\citeproc{ref-bader2018stochastic}{2018}), Lederman
  (\citeproc{ref-ledermanmarbles}{Forthcoming}), Tarsney
  (\citeproc{ref-tarsneyexpected}{forthcoming}).} We ourselves accept
this premise. But some fans of incomplete preferences reject
it.\footnote{Bales, Cohen, and Handfield
  (\citeproc{ref-bales2014decision}{2014}), Schoenfield
  (\citeproc{ref-schoenfield2014decision}{2014})} We think that the
moneypump argument \emph{is} successful against this particular view
about rational permissibility for incomplete preferences, but that this
is a problem with that particular view, not with incomplete preferences
more generally.

The second natural objection to our argument is to the claim that Dylan
can do something at \(t_1\), e.g., flip a coin or roll some dice, which
will determine what he does at \(t_2\). Why would the result of the
earlier coin flip give him a reason to choose \(B\) rather than \(A\)-
at \(t_2\)? To this objection, we say that this ability to have a
randomizing device at one time settle what one does at another time is
essential to the ``objective'' understanding of mixed strategies we are
considering here.

To illustrate this point, let's assume, contra what we've been assuming
so far, that something like the approach to decision theory in von
Neumann and Morgenstern (\citeproc{ref-vNM1944}{1944}) is correct, and
agents have precise numerical credences and utilities. Moreover, let's
assume they can rationally randomize when carrying out mixed strategies.
Given these assumptions, if a player rationally chooses to randomize,
then they must be indifferent between the actions over which they
randomize. But if they are, then when they see the results from their
randomizing device, it is unclear why they should ``follow their plan''
as opposed to choosing any of the other actions over which they were
randomizing (since, by hypothesis, they were indifferent between these
actions). In fact, it is not even clear why (if randomization is
costless, as is standardly assumed) they should not just randomize
again. There is always a temporal gap between randomizing and acting,
and even on this classical picture, the gap must be filled in by some
extra assumptions. If (given those assumptions) Dylan can randomize
before \(t_2\) to settle what to do at \(t_2\), he can just as easily
randomize before \(t_1\) to settle what to do at \(t_2\). Fans of the
classical view of rationality require some form of
decision-with-time-lag to make sense of mixed strategies as
randomization. So it is no cost for the fan of incomplete preferences to
also invoke such decisions when considering this view of mixed
strategies. \%Note that we don't say any of this randomization is in
fact rational; we're not taking a stand on whether it is.

This completes our argument for the rational requirement to choose Down
only if one believes that one will choose \(B\) (even if one chooses
Down as the result of randomization). We note that this response to the
Single-Souring Moneypump, which relies on the combination of our generic
constraint on moneypumps, with the specific claim that, for such agents
it is a rational requirement to go Down only if they believe they will
choose \(B\) at the later node, extends straightforwardly to provide a
response to the \emph{forcing} moneypump for incomplete preferences due
to Gustafsson (\citeproc{ref-Gustafsson2022}{2022, 34--39}), so we will
not work through the details here.\footnote{Gustafsson provides a list
  of principles which govern his proposed moneypump. Our position
  satisfies all of these explicitly stated premises jointly; it rejects
  an implicit premise, namely, that specifying an agent's preferences in
  a decision-tree is enough to determine what actions are and are not
  rationally permissible in the decision tree. Our claim is that beliefs
  can also matter, i.e.~that what actions in a decision tree are
  rationally permitted may depend on further descriptive facts about
  what beliefs the agent has. \%In a choice between \(A\) and \(B\), for
  instance, Dylan cannot choose \(A\) rationally if at the very same
  time he believes that he will choose \(B\) (and knows that these are
  exclusive options etc.).}

\subsection{Elga's Argument}\label{elgas-argument}

We turn next to the influential argument of Elga
(\citeproc{ref-Elga2010}{2010}). Elga asks us to consider someone, let's
call them Finley, who has maximally imprecise credences on some
proposition \(H\). Elga will offer Finley two bets, one after the other:

\begin{quote}
\textbf{Bet A} If \(H\) is true, Finley loses \$10. If \(H\) is false,
they win \$15.
\end{quote}

\begin{quote}
\textbf{Bet B} If \(H\) is true, Finley wins \$15. If \(H\) is false,
they lose \$10.
\end{quote}

Elga holds that it is rationally required to take at least one of these
bets, and he argues that fans of imprecise credences cannot deliver this
verdict. But his arguments do not succeed given two further claims. The
first is that our generic constraint is correct. The second is that, if
Finley is a person who has firm beliefs about what they will do later,
it is rationally required that, if Finley declines Bet A, they must do
so believing that they will accept Bet B. We have already argued at
length for the first of these claims. It remains to argue for the
second.

Our argument relies on two simplifications, both of which seem
reasonable in the circumstances. First, since Elga's argument does not
rely on mixed strategies, we'll also set them aside here. (In any case,
we would handle them in much the same way as we did in the Single
Souring Moneypump.) Second, as in the case of incomplete preferences,
we're not going to show that every theory for decision making with
imprecise credences can avoid Elga's argument. To show that our
constraint does real work here, we just need to show that it opens up a
new defense of at least one such decision theory.\footnote{In Elga
  (\citeproc{ref-elga2012errata}{2012}), Elga concedes that the
  ``maximize minimum expected utility'' theory of Gärdenfors and Sahlin
  (\citeproc{ref-gardenfors1982unreliable}{1982}) also escapes his
  argument (see Sahlin and Weirich
  (\citeproc{ref-sahlin2014unsharp}{2014})). The response we give here
  is quite different.} In particular, we'll start from the theory that
Weatherson (\citeproc{ref-weatherson2008decision}{2008}) calls Caprice.

According to Caprice, some decisions are rational for an agent whose
credences are represented by a set \(R\) of credence functions iff there
is some \(\Pr \in R\) such that each decision is utility maximising
according to \(\Pr\). In addition to Caprice, and in the spirit of our
proof of possibility, we will assume the following principle:\footnote{In
  fact we think Caprice implies \textbf{Don't Go Irrational}, but we
  don't want to rely on this possibly controversial claim, and all we
  need is one theory for imprecise credences that avoids Elga's
  argument.}

\begin{quote}
\textbf{Don't Go Irrational} If the agent believes that they will make
some choices, and these choices are (collectively) rational according to
Caprice, then it is irrational to make any further choice such that the
collection of it plus the further choices the agent believes they will
make is irrational according to Caprice.
\end{quote}

Intuitively, \textbf{Don't Go Irrational} says that an individual choice
that takes the agent from believing that they are doing some things that
are (in fact) rational, to believing that they are doing some things
that are (in fact) irrational, is itself irrational. It's a way of
moving from the irrationality of a collection of actions to the
irrationality of the marginal action that generates the irrationality.

Caprice is incompatible with Finley declining both bets, provided Finley
has a belief about what they will do at all future decisions. There is
no possible \(\Pr\), and hence no \(\Pr\) in the set representing their
imprecise credence, according to which declining both is utility
maximising. So if Finley believes that they will decline the second bet,
then by \textbf{Don't Go Irrational} it is irrational to decline the
first bet.

\subsection{Gustafsson's Behavioural
Moneypump}\label{gustafssons-behavioural-moneypump}

Finally, we turn to Gustafsson's most recent moneypump argument against
incomplete preferences Gustafsson
(\citeproc{ref-Gustafsson2025}{forthcoming}), which employs quite
different considerations than we've discussed so far. Gustafsson is
(admirably) explicit in this moneypump about what attitudes the
protagonist has to their future actions. But the moneypump depends on
considering protagonists who have intermediate credence in their future
actions. In other words, it is directly incompatible with the constraint
we have argued for on successful moneypumps.

In defense of focusing on protagonists with such intermediate credence,
Gustafsson says that if a person has a disposition to choose \(X\) over
\(Y\) with probability 1, they count as ``effectively'' preferring \(X\)
to \(Y\). Gustafsson's point is that, practically speaking, any such
agent will behave as if they had complete preferences, and thus cannot
be subject to a moneypump (since moneypumps only ``see'' the agent's
behavior). If one accepts our proposed constraint on genuine moneypumps,
however, this is good news for the fan of incomplete preferences: it
means that if our constraint on beliefs entails such a disposition to
choose, the constraint renders such arguments ineffectual.

But one might think that there is a concern for our approach lurking
here. One might worry that our proposed constraint on moneypumps is in
fact incompatible with genuinely incomplete preferences---one of the
phenomena whose rationality we believe can be defended by using our
constraint. If these \emph{effective} preferences amounted to real
preferences, then even if it were true that our constraint ruled out
moneypumps against incomplete preferences, it might do so by claiming
that no such agents could be protagonists in such stories at all. And
this latter claim might be thought to be a different threat to the
rationality of incomplete preferences.

But this threat is not genuine, because effective preference is not the
same thing as preference. To see this, consider Glenn, who has the
disposition that, whenever he has to bet on the flip of a fair coin, he
chooses Heads. Glenn may act in a way similar to someone who prefers
Heads to Tails (and thus effectively prefer it), but there are at least
two reasons for denying that Glenn prefers betting on Heads to betting
on Tails. First, it just seems implausible; forming such a tie-breaking
resolution is different from forming a preference. Second, a standard
principle about rationality, one that is often used in deriving
credences and utilities from betting dispositions, is that one prefers a
bet on \(p\) to a bet on \(q\) (with the same stakes) if and only if one
thinks \(p\) is more probable than \(q\). If Glenn genuinely prefers
betting on Heads to betting on Tails when the coin is fair, he violates
this standard principle.

So we reject the worry that having a firm belief about one's future
choices (and hence an effective preference in Gustafsson's sense) would
rule out out having incomplete preferences. It is consistent, as we have
been assuming throughout, that people have firm beliefs about what they
will do, which do not amount to preferences between future choices.

\section{Comparison to other
approaches}\label{comparison-to-other-approaches}

The view of this paper is importantly different from standard responses
to moneypump arguments. It is often thought that if one wants to defend
the rationality of Dylan's preferences in light of the fact that he ends
up with \(A\)-, one should find some way in which the choice of \(A\)-
over \(B\) at \(t_2\) is irrational considered on its own (and
irrespective of what beliefs the person has about what they will
choose). This thought is common ground between philosophers like Chang
(\citeproc{ref-Chang2005}{2005}), who think Dylan is rational, and
philosophers like Gustafsson (\citeproc{ref-Gustafsson2022}{2022}), who
think he is not. So there is a lot of debate about whether rationality
requires sticking to earlier plans, as Chang suggests\footnote{Chang's
  later views on this are a bit more nuanced. See Chang
  (\citeproc{ref-Chang2017}{2017}) and Doody
  (\citeproc{ref-Doody2019}{2019}, sect. 4) for a careful analysis of
  how Chang's views on the case have changed over time.}, or whether the
rationality of a choice at a time is independent of past choices, as
Gustafsson suggests. For instance, both Elga
(\citeproc{ref-Elga2010}{2010, 8--9}) Gustafsson
(\citeproc{ref-Gustafsson2022}{2022, 66--74}) argue (against fans of
``Resolute Choice'') that making a plan at an earlier time does not
provide a person with a practical reason in favor of one action rather
than the other at a later time, unless they somehow fetishize following
their plan.\footnote{On resolute choice in decision theory, see
  McClennen (\citeproc{ref-McClennen1990}{1990}), though there much of
  the focus is on preference change. In action theory, a similar theory
  is defended by Bratman (\citeproc{ref-Bratman1987}{1987}) and Holton
  (\citeproc{ref-Holton2009}{2009}). The worry that such views require
  that plans be reasons has been widely discussed; see Setiya
  (\citeproc{ref-sep-intention}{2022}, sect. 4).} We think this debate
is looking in the wrong place. There are three other places we could be
looking.

It could be that Dylan is irrational, but the irrationality is at
\(t_1\). This would be the case if, for example, Dylan chose to go Down
at \(t_1\) while believing that he would take \(A\)- at \(t_2\).

A second possibility, which we haven't discussed to this point, is more
radical. This is that Dylan is irrational over the period from \(t_1\)
to \(t_2\) without being irrational at either time (Weatherson
(\citeproc{ref-weatherson2008decision}{2008, 12})). We want to at least
suggest that changes like Blake's could involve intertemporal
irrationality even if Blake is not irrational at either time. And it
seems consistent to say that the combination of choosing Down and \(A\)-
is irrational even if neither single act is irrational.

The third option is the one we have been most focused on throughout the
paper. Adrian, Blake, Cameron and Dylan may all end up with less than
they could have had. But this need not be a sign of irrationality; it
might be that they simply don't satisfy the presuppositions of the
moneypump argument. Once one makes clear what attitude Dylan does or
does not have at \(t_1\) towards the action that will be taken at
\(t_2\), this presupposition failure becomes clear. In particular, if we
do assume that Dylan firmly, resiliently believes at \(t_1\) that he
will choose \(B\) if he reaches \(t_2\), the consistency of Dylan's
later beliefs can do the work that ``reasons to follow one's plan'' were
supposed to do for proponents of Resolute Choice. Consistency of belief
provides a rational constraint on what the person can choose, which is
not a practical reason in favor of one of the actions.

These three alternative explanations are not necessarily in tension. It
might be that if Dylan believes at \(t_1\) that \(A\)- will be chosen at
\(t_2\), that the irrational act is at \(t_1\), while if he does not
believe this before \(t_1\) but arbitrarily changes his belief by
\(t_2\), he is outside the scope of moneypump arguments. Either way, one
can reject the moneypump argument without saying that Dylan does
something irrational at \(t_2\).

We have focused on an understanding of moneypumps as dramatizations of
defects of rationality (Christensen
(\citeproc{ref-christensen1996dutch}{1996})). A different understanding
of such arguments is that the possibility of exploitation is itself the
problem, not merely a dramatization of an underlying rational defect.
There is then a question of what forms of exploitability are
problematic. Our discussion of ``generic constraints'' could be
translated into claims about the conditions under which exploitability
is a rational problem. But we expect the translation to be less
compelling to those who have this ``realistic'' understanding of
moneypumps. In real life, we often do not know what we will do if a
choice arises, and are not in a position to form (rational) firm beliefs
about it. We think there are independent reasons to reject this way of
understanding moneypumps, but arguing for that claim is a project for
another day.

The parable of the moneypump is an important and powerful device for
displaying rational defects. But the simplicity of these stories masks
an underlying complexity in when, exactly, a story of this kind does
license the moral that its protagonist displays a rational defect. We
have proposed a new constraint which, we have argued, captures a
necessary constraint for drawing this moral. We hope that greater
clarity about the rules of the genre of parable will help lay the
foundations for more exact deployment of this important tool.

\subsection*{References}\label{references}
\addcontentsline{toc}{subsection}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-Aumann1987}
Aumann, Robert. 1987. {``Correlated Equilibrium as an Expression of
Bayesian Rationality.''} \emph{Econometrica} 55 (1): 1--18. doi:
\href{https://doi.org/10.2307/1911154}{10.2307/1911154}.

\bibitem[\citeproctext]{ref-bader2018stochastic}
Bader, Ralf M. 2018. {``Stochastic Dominance and Opaque Sweetening.''}
\emph{Australasian Journal of Philosophy} 96 (3): 498--507.

\bibitem[\citeproctext]{ref-bales2014decision}
Bales, Adam, Daniel Cohen, and Toby Handfield. 2014. {``Decision Theory
for Agents with Incomplete Preferences.''} \emph{Australasian Journal of
Philosophy} 92 (3): 453--70.

\bibitem[\citeproctext]{ref-Bradley2005}
Bradley, Richard. 2005. {``Radical Probabilism and Bayesian
Conditioning.''} \emph{Philosophy of Science} 72 (2): 342--64. doi:
\href{https://doi.org/10.1086/432427}{10.1086/432427}.

\bibitem[\citeproctext]{ref-Bratman1987}
Bratman, Michael E. 1987. \emph{Intention, Plans, and Practical Reason}.
Cambridge, MA.: Harvard University Press.

\bibitem[\citeproctext]{ref-Chang1997intro}
Chang, Ruth. 1997. {``Introduction.''} In \emph{Incommensurability,
Incomparability, and Practical Reason}, edited by Ruth Chang, 1--34.
Harvard.

\bibitem[\citeproctext]{ref-Chang2005}
---------. 2005. {``Parity, Interval Value, and Choice.''} \emph{Ethics}
115 (2): 331--50. doi:
\href{https://doi.org/10.1086/426307}{10.1086/426307}.

\bibitem[\citeproctext]{ref-Chang2017}
---------. 2017. {``Hard Choices.''} \emph{Journal of the American
Philosophical Association} 3 (1): 1--21. doi:
\href{https://doi.org/10.1017/apa.2017.7}{10.1017/apa.2017.7}.

\bibitem[\citeproctext]{ref-christensen1996dutch}
Christensen, David. 1996. {``Dutch-Book Arguments Depragmatized:
Epistemic Consistency for Partial Believers.''} \emph{Journal of
Philosophy} 93 (9): 450--79.

\bibitem[\citeproctext]{ref-Doody2019}
Doody, Ryan. 2019. {``Opaque Sweetening and Transitivity.''}
\emph{Australasian Journal of Philosophy} 97 (3): 579--91. doi:
\href{https://doi.org/10.1080/00048402.2018.1520269}{10.1080/00048402.2018.1520269}.

\bibitem[\citeproctext]{ref-Elga2010}
Elga, Adam. 2010. {``Subjective Probabilities Should Be Sharp.''}
\emph{Philosophers' Imprint} 10: 1--11.

\bibitem[\citeproctext]{ref-elga2012errata}
---------. 2012. {``Errata for Subjective Probabilities Should Be
Sharp.''} Downloaded from
\url{https://www.princeton.edu/~adame/papers/sharp/sharp-errata.pdf}.

\bibitem[\citeproctext]{ref-gardenfors1982unreliable}
Gärdenfors, Peter, and Nils-Eric Sahlin. 1982. {``Unreliable
Probabilities, Risk Taking, and Decision Making.''} \emph{Synthese} 53
(3): 361--86.

\bibitem[\citeproctext]{ref-Gustafsson2025}
Gustafsson, Johan E. forthcoming. {``A Behavioural Money-Pump Argument
for Completeness.''} \emph{Theory and Decision}, forthcoming. doi:
\href{https://doi.org/10.1007/s11238-025-10025-3}{10.1007/s11238-025-10025-3}.

\bibitem[\citeproctext]{ref-Gustafsson2022}
---------. 2022. \emph{Money-Pump Arguments}. Cambridge: Cambridge
University Press.

\bibitem[\citeproctext]{ref-GustafssonEspinoza2010}
Gustafsson, Johan E., and Nicolas Espinoza. 2010. {``Conflicting Reasons
in the Small-Improvement Argument.''} \emph{The Philosophical Quarterly}
60 (241): 754--63. doi:
\href{https://doi.org/10.1111/j.1467-9213.2009.648.x}{10.1111/j.1467-9213.2009.648.x}.

\bibitem[\citeproctext]{ref-hare2010take}
Hare, Caspar. 2010. {``Take the Sugar.''} \emph{Analysis} 70 (2):
237--47. doi:
\href{https://doi.org/10.1093/analys/anp174}{10.1093/analys/anp174}.

\bibitem[\citeproctext]{ref-Holton2009}
Holton, Richard. 2009. \emph{Willing, Wanting, Waiting}. Oxford: Oxford
University Press.

\bibitem[\citeproctext]{ref-KopecTitelbaum2016}
Kopec, Matthew, and Michael G. Titelbaum. 2016. {``The Uniqueness
Thesis.''} \emph{Philosophy Compass} 11 (4): 189--200. doi:
\href{https://doi.org/10.1111/phc3.12318}{10.1111/phc3.12318}.

\bibitem[\citeproctext]{ref-ledermanmarbles}
Lederman, Harvey. Forthcoming. {``Of Marbles and Matchsticks.''}
\emph{Oxford Studies in Epistemology} 8 (Forthcoming).

\bibitem[\citeproctext]{ref-Lewis1999b}
Lewis, David. 1999. {``Why Conditionalize?''} In \emph{Papers in
Metaphysics and Epistemology}, 403--7. Cambridge University Press.
Originally written as a course handout in 1972.

\bibitem[\citeproctext]{ref-McClennen1990}
McClennen, Edward. 1990. \emph{Rationality and Dynamic Choice}.
Cambridge: {C}ambridge {U}niversity {P}ress.

\bibitem[\citeproctext]{ref-PiccioneRubinstein1997}
Piccione, Michele, and Ariel Rubinstein. 1997. {``On the Interpretation
of Decision Problems with Imperfect Recall.''} \emph{Games and Economic
Behavior} 20 (1): 3--24. doi:
\url{https://doi.org/10.1006/game.1997.0536}.

\bibitem[\citeproctext]{ref-sahlin2014unsharp}
Sahlin, Nils-Eric, and Paul Weirich. 2014. {``Unsharp Sharpness.''}
\emph{Theoria} 80 (1): 100--103.

\bibitem[\citeproctext]{ref-schoenfield2014decision}
Schoenfield, Miriam. 2014. {``Decision Making in the Face of Parity.''}
\emph{Philosophical Perspectives} 28: 263--77. doi:
\href{https://doi.org/10.1111/phpe.12044}{10.1111/phpe.12044}.

\bibitem[\citeproctext]{ref-sep-intention}
Setiya, Kieran. 2022. {``{Intention}.''} In \emph{The {Stanford}
Encyclopedia of Philosophy}, edited by Edward N. Zalta and Uri Nodelman,
{W}inter 2022.
\url{https://plato.stanford.edu/archives/win2022/entries/intention/};
Metaphysics Research Lab, Stanford University.

\bibitem[\citeproctext]{ref-Stalnaker1999}
Stalnaker, Robert. 1999. {``Extensive and Strategic Forms: Games and
Models for Games.''} \emph{Research in Economics} 53 (3): 293--319. doi:
\href{https://doi.org/10.1006/reec.1999.0200}{10.1006/reec.1999.0200}.

\bibitem[\citeproctext]{ref-tarsneyexpected}
Tarsney, Christian. forthcoming. {``Expected Value, to a Point: Moral
Decision-Making Under Background Uncertainty.''} \emph{Noûs},
forthcoming. doi:
\href{https://doi.org/10.1111/nous.12544}{10.1111/nous.12544}.

\bibitem[\citeproctext]{ref-vNM1944}
von Neumann, John, and Oskar Morgenstern. 1944. \emph{Theory of Games
and Economic Behavior}. Princeton, NJ: Princeton University Press.

\bibitem[\citeproctext]{ref-weatherson2008decision}
Weatherson, Brian. 2008. {``Decision Making with Imprecise
Probabilities.''} \emph{Ms., Dept. Of Philosophy, University of
Michigan}.

\bibitem[\citeproctext]{ref-Williams2014}
Williams, J. Robert G. 2014. \emph{Philosophers' Imprint} 14 (1): 1--34.

\end{CSLReferences}



\noindent Draft of April 2025.


\end{document}
