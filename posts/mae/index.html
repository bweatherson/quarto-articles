<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.479">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Brian Weatherson">
<meta name="dcterms.date" content="2013-04-25">
<meta name="description" content="Timothy Williamson has argued that cases involving fallible measurement show that knowledge comes apart from justified true belief in ways quite distinct from the familiar ‘double luck’ cases. I start by describing some assumptions that are necessary to generate Williamson’s conclusion, and arguing that these assumptions are well justified. I then argue that the existence of these cases poses problems for theorists who suppose that knowledge comes apart from justified true belief only in a well defined class of cases. I end with some general discussion of what we can know on the basis of imperfect measuring devices.">

<title>Online Articles - Brian Weatherson - Margins and Errors</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" href="https://use.typekit.net/uzz2drx.css">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Online Articles - Brian Weatherson</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://brian.weatherson.org"> <i class="bi bi-mortarboard" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://bsky.app/profile/bweatherson.bsky.social"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Margins and Errors</h1>
                  <div>
        <div class="description">
          <p>Timothy Williamson has argued that cases involving fallible measurement show that knowledge comes apart from justified true belief in ways quite distinct from the familiar ‘double luck’ cases. I start by describing some assumptions that are necessary to generate Williamson’s conclusion, and arguing that these assumptions are well justified. I then argue that the existence of these cases poses problems for theorists who suppose that knowledge comes apart from justified true belief only in a well defined class of cases. I end with some general discussion of what we can know on the basis of imperfect measuring devices.</p>
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">epistemology</div>
              </div>
                  </div>
  </div>
    
  <div class="quarto-title-meta-author">
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-heading">Affiliation</div>
    
      <div class="quarto-title-meta-contents">
      <p class="author"><a href="http://brian.weatherson.org">Brian Weatherson</a> </p>
    </div>
      <div class="quarto-title-meta-contents">
          <p class="affiliation">
              University of Michigan
            </p>
        </div>
      </div>

  <div class="quarto-title-meta">

        
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 25, 2013</p>
      </div>
    </div>
    
      
      <div>
      <div class="quarto-title-meta-heading">Doi</div>
      <div class="quarto-title-meta-contents">
        <p class="doi">
          <a href="https://doi.org/10.1080/0020174X.2013.775015">10.1080/0020174X.2013.775015</a>
        </p>
      </div>
    </div>
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Sections</h2>
   
  <ul>
  <li><a href="#measurement-justification-and-knowledge" id="toc-measurement-justification-and-knowledge" class="nav-link active" data-scroll-target="#measurement-justification-and-knowledge"><span class="header-section-number">0.1</span> Measurement, Justification and Knowledge</a></li>
  <li><a href="#the-class-of-gettier-cases-is-disjunctive" id="toc-the-class-of-gettier-cases-is-disjunctive" class="nav-link" data-scroll-target="#the-class-of-gettier-cases-is-disjunctive"><span class="header-section-number">0.2</span> The Class of Gettier Cases is Disjunctive</a></li>
  <li><a href="#there-is-no-solution-to-the-gettier-problem" id="toc-there-is-no-solution-to-the-gettier-problem" class="nav-link" data-scroll-target="#there-is-no-solution-to-the-gettier-problem"><span class="header-section-number">0.3</span> There is No Solution to the Gettier Problem</a></li>
  <li><a href="#what-can-we-learn-from-fallible-machines" id="toc-what-can-we-learn-from-fallible-machines" class="nav-link" data-scroll-target="#what-can-we-learn-from-fallible-machines"><span class="header-section-number">0.4</span> What Can We Learn from Fallible Machines?</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<p>Recently, Timothy <span class="citation" data-cites="WilliamsonLofoten">Williamson (<a href="#ref-WilliamsonLofoten" role="doc-biblioref">2013</a>)</span> has argued that considerations about margins of errors can generate a new class of cases where agents have justified true beliefs without knowledge. I think this is a great argument, and it has a number of interesting philosophical conclusions. In this note I’m going to go over the assumptions of Williamson’s argument. I’m going to argue that the assumptions which generate the justification without knowledge are true. I’m then going to go over some of the recent arguments in epistemology that are refuted by Williamson’s work. And I’m going to end with an admittedly inconclusive discussion of what we can know when using an imperfect measuring device.</p>
<aside>
<p>Published in <em>Inquiry</em> 56: 63-76.</p>
Picture by <a href="https://www.flickr.com/photos/90692748@N04">docoverachiever</a> via <a href="https://search.creativecommons.org/photos/f4d370f5-23bc-4104-a35a-f92238a460d0">Creative Commons</a>.
</aside>
<section id="measurement-justification-and-knowledge" class="level3 page-columns page-full" data-number="0.1">
<h3 data-number="0.1" class="anchored" data-anchor-id="measurement-justification-and-knowledge"><span class="header-section-number">0.1</span> Measurement, Justification and Knowledge</h3>
<p>Williamson’s core example involves detecting the angle of a pointer on a wheel by eyesight. For various reasons, I find it easier to think about a slightly different example: measuring a quantity using a digital measurement device. This change has some costs relative to Williamson’s version – for one thing, if we are measuring a quantity it might seem that the margin of error is related to the quantity measured. If I eyeball how many stories tall a building is, my margin of error is 0 if the building is 1-2 stories tall, and over 10 if the building is as tall as the World Trade Center. But this problem is not as pressing for digital devices, which are often very <em>unreliable</em> for small quantities. And, at least relative to my preferences, the familiarity of quantities makes up for the loss of symmetry properties involved in angular measurement.</p>
<p>To make things explicit, I’ll imagine the agent <span class="math inline">\(S\)</span> is using a digital scale. The scale has a <strong>margin of error</strong> <span class="math inline">\(m\)</span>. That means that if the reading, i.e., the <strong>apparent mass</strong> is <span class="math inline">\(a\)</span>, then the agent is justified in believing that the mass is in <span class="math inline">\([a-m, a+m]\)</span>. We will assume that <span class="math inline">\(a\)</span> and <span class="math inline">\(m\)</span> are luminous; i.e., the agent knows their values, and knows she knows them, and so on. This is a relatively harmless idealisation for <span class="math inline">\(a\)</span>; it is pretty clear what a digital scale reads.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> It is a somewhat less plausible assumption for <span class="math inline">\(m\)</span>. But we’ll assume that <span class="math inline">\(S\)</span> has been very diligent about calibrating her scale, and that the calibration has been recently and skillfully carried out, so in practice <span class="math inline">\(m\)</span> can be assessed very accurately.</p>
<div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;This isn’t always true. If a scale flickers between reading 832g and 833g, it takes a bit of skill to determine what <em>the reading</em> is. But we’ll assume it is clear in this case. On an analogue scale, the luminosity assumption is rather implausible, since it is possible to eyeball with less than perfect accuracy how far between one marker and the next the pointer is.</p></li></div><p>We’ll make three further assumptions about <span class="math inline">\(m\)</span> that strike me as plausible, but which may I guess be challenged. I need to be a bit careful with terminology to set out the first one. I’ll use <span class="math inline">\(V\)</span> and <span class="math inline">\(v\)</span> as variables that both pick out the <strong>true value</strong> of the mass. The difference is that <span class="math inline">\(v\)</span> picks it out rigidly, while <span class="math inline">\(V\)</span> picks out the value of the mass in any world under consideration. Think of <span class="math inline">\(V\)</span> as shorthand for <em>the mass of the object</em> and <span class="math inline">\(v\)</span> as shorthand for <em>the actual mass of the object</em>. (More carefully, <span class="math inline">\(V\)</span> is a <em>random</em> variable, while <span class="math inline">\(v\)</span> is a standard, rigid, variable.) Our first assumption then is that <span class="math inline">\(m\)</span> is also related to what the agent can know. In particular, we’ll assume that if the reading <span class="math inline">\(a\)</span> equals <span class="math inline">\(v\)</span>, then the agent can know that <span class="math inline">\(V \in [a-m, a+m]\)</span>, and can’t know anything stronger than that. That is, the margin of error for justification equals, in the best case, the margin of error for knowledge. The second is that the scale has a readout that is finer than <span class="math inline">\(m\)</span>. This is usually the case; the last digit on a digital scale is often not significant. The final assumption is that it is metaphysically possible that the scale has an error on an occasion that is greater than <span class="math inline">\(m\)</span>. This is a kind of fallibilism assumption – saying that the margin of error is <span class="math inline">\(m\)</span> does not mean there is anything incoherent about talking about cases where the error on an occasion is greater than <span class="math inline">\(m\)</span>.</p>
<p>This error term will do a lot of work in what follows, so I’ll use <span class="math inline">\(e\)</span> to be the <strong>error</strong> of the measurement, i.e., <span class="math inline">\(|a-v|\)</span>. For ease of exposition, I’ll assume that <span class="math inline">\(a \geq v\)</span>, i.e., that any error is on the high side. But this is entirely dispensible, and just lets me drop some disjunctions later on.</p>
<p>Now we are in a position to state Williamson’s argument. Assume that on a particular occasion, <span class="math inline">\(0 &lt; e &lt; m\)</span>. Perhaps <span class="math inline">\(v = 830, m =10\)</span> and <span class="math inline">\(a = 832\)</span>, so <span class="math inline">\(e = 2\)</span>. Williamson appears to make the following two assumptions.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;I’m not actually sure whether Williamson <em>makes</em> the first, or thinks it is the kind of thing anyone who thinks justification is prior to knowledge should make.</p></li></div><ol type="1">
<li><p>The agent is justified in believing what they would know if appearances matched reality, i.e., if <span class="math inline">\(V\)</span> equalled <span class="math inline">\(a\)</span>.</p></li>
<li><p>The agent cannot come to know something about <span class="math inline">\(V\)</span> on the basis of a suboptimal measurement that they could not also know on the basis of an optimal measurement.</p></li>
</ol>
<p>I’m assuming here that the optimal measurement displays the correct mass. I don’t assume the actual measurement is <em>wrong</em>. That would require saying something implausible about the semantic content of the display. It’s not obvious that the display has a content that could be true or false, and if it does have such a content it might be true. (For instance, the content might be that the object on the scale has a mass near to <span class="math inline">\(a\)</span>, or that with a high probability it has a mass near to <span class="math inline">\(a\)</span>, and both of those things are true.) But the optimal measurement would be to have <span class="math inline">\(a = v\)</span>, and in this sense the measurement is suboptimal.</p>
<p>The argument then is pretty quick. From the first assumption, we get that the agent is justified in believing that <span class="math inline">\(V \in [a - m, a + m]\)</span>. Assume then that the agent forms this justified belief. This belief is incompatible with <span class="math inline">\(V \in [v - m, a - m)\)</span>. But if <span class="math inline">\(a\)</span> equalled <span class="math inline">\(v\)</span>, then the agent wouldn’t be in a position to rule out that <span class="math inline">\(V \in [v - m, a - m)\)</span>. So by premise 2 she can’t knowledgeably rule it out on the basis of a mismeasurement. So her belief that <span class="math inline">\(V \geq a - m\)</span> cannot be knowledge. So this justified true belief is not knowledge.</p>
<p>If you prefer doing this with numbers, here’s the way the example works using the numbers above. The mass of the object is 830. So if the reading was correct, the agent would know just that the mass is between 820 and 840. The reading is 832. So she’s justified in believing, and we’ll assume she does believe, that the mass is between 822 and 842. That belief is incompatible with the mass being 821. But by premise 2 she can’t know the mass is greater than 821. So the belief doesn’t amount to knowledge, despite being justified and, crucially, true. After all, 830 is between 822 and 842, so her belief that the mass is in this range is true. So simple reflections on the workings on measuring devices let us generate cases of justified true beliefs that are not knowledge.</p>
<p>I’ll end this section with a couple of objections and replies.</p>
<p><em>Objection</em>: The argument that the agent can’t know that <span class="math inline">\(V \in [a - m, a + m]\)</span> is also an argument that the argument can’t justifiably believe that <span class="math inline">\(V \in [a - m, a + m]\)</span>. After all, why should it be possible to get justification from a suboptimal measurement when it isn’t possible to get the same justification from an optimal measurement?</p>
<p><em>Reply</em>: It is possible to have justification to believe an outright falsehood. It is widely believed that you can have justification even when none of your evidential sources are even approximately accurate <span class="citation" data-cites="Cohen1984">(<a href="#ref-Cohen1984" role="doc-biblioref">Cohen 1984</a>)</span>. And even most reliabilists will say that you can have false justified beliefs if you use a belief forming method that is normally reliable, but which badly misfires on this occasion. In such cases we clearly get justification to believe something from a mismeasurement that we wouldn’t get from a correct measurement. So the objection is based on a mistaken view of justification.</p>
<p><em>Objection</em>: Premise 2 fails in cases using random sampling. Here’s an illustration. An experimenter wants to know what percentage of <span class="math inline">\(F\)</span>s are <span class="math inline">\(G\)</span>. She designs a survey to ask people whether they are <span class="math inline">\(G\)</span>. The survey is well designed; everyone gives the correct answer about themselves. And she designs a process for randomly sampling the <span class="math inline">\(F\)</span>s to get a good random selection of 500. It’s an excellent process; every <span class="math inline">\(F\)</span> had an equal chance of being selected, and the sample fairly represents the different demographically significant subgroups of the <span class="math inline">\(F\)</span>s. But by the normal processes of random variation, her group contains slightly more <span class="math inline">\(G\)</span>s than the average. In her survey, 28% of people said (truly!) that they were <span class="math inline">\(G\)</span>, while only 26% of <span class="math inline">\(F\)</span>s are <span class="math inline">\(G\)</span>s. Assuming a margin of error in such a study of 4%, it seems plausible to say she knows that between 25 and 32% of <span class="math inline">\(F\)</span>s are <span class="math inline">\(G\)</span>s. But that’s not something she could have known the survey had come back correctly reporting that 26% of <span class="math inline">\(F\)</span>s are <span class="math inline">\(G\)</span>s.</p>
<p><em>Reply</em>: I think the core problem with this argument comes in the last sentence. A random survey isn’t, in the first instance, a measurement of a population. It’s a measurement of those surveyed, from which we draw extrapolations about the population. In that sense, the only <em>measurement</em> in the imagined example was as good as it could be; 28% of surveyed people are in fact <span class="math inline">\(G\)</span>. So the survey was correct, and it is fine to conclude that we can in fact know that between 24 and 32 percent of <span class="math inline">\(F\)</span>s are <span class="math inline">\(G\)</span>s.</p>
<p>There are independent reasons for thinking this is the right way to talk about the case. If a genuine measuring device, like a scale, is off by a small amount, we regard that as a reason for tinkering with the device, and trying to make it more accurate. That’s one respect in which the measurement is suboptimal, even if it is correct within the margin of error. This reason to tinker with the scale is a reason that often will be outweighed. Perhaps it is technologically infeasible to make the machine more accurate. More commonly, the only way to guarantee greater accuracy would be more cost and hassle than it is worth. But it remains a reason. The fact that this experiment came out with a deviation between the sample and the population is <em>not</em> a reason to think that it could have been run in a better way, or that there is some reason to improve the survey. That’s just how random sampling goes. If it were a genuine measurement of the population, the deviation between the ‘measurement’ and what is being measured would be a reason to do things differently. There isn’t any such reason, so the sample is not truly a measurement.</p>
<p>So I don’t think this objection works, and I think the general principle that you can’t get extra knowledge from a suboptimal measurement is right. But note also that we don’t need this general principle to suggest that there will be cases of justified true belief without knowledge in the cases of measurement. Consider a special case where <span class="math inline">\(e\)</span> is just less than <span class="math inline">\(m\)</span>. For concreteness, say <span class="math inline">\(a = v + 0.95m\)</span>, so <span class="math inline">\(e = 0.95m\)</span>. Now assume that whatever is justifiedly truly believed in this case is known, so <span class="math inline">\(S\)</span> knows that <span class="math inline">\(V \in [a - m, a + m]\)</span>. That is, <span class="math inline">\(S\)</span> knows that <span class="math inline">\(V \in [v - 0.05m, a + m]\)</span>.</p>
<p>We don’t need any principles about measurement to show this is false; safety considerations will suffice. <span class="citation" data-cites="Williamson2000-WILKAI">Williamson (<a href="#ref-Williamson2000-WILKAI" role="doc-biblioref">2000</a>)</span> says that a belief that <span class="math inline">\(p\)</span> is safe only if <span class="math inline">\(p\)</span> is true in all nearby worlds. But given how close <span class="math inline">\(v\)</span> is to the edge of the range <span class="math inline">\([v - 0.05m, a + m]\)</span>. Rival conceptions of safety don’t help much more than this. The most prominent of these, suggested by <span class="citation" data-cites="Sainsbury1996">Sainsbury (<a href="#ref-Sainsbury1996" role="doc-biblioref">1995</a>)</span>, says that a belief is safe only if the method that produced it doesn’t produce a false belief in any nearby world. But if the scale was off by <span class="math inline">\(0.95m\)</span>, it could have been off by <span class="math inline">\(1.05m\)</span>, so that condition fails too.</p>
<p>I don’t want the last two paragraphs to leave too concessive an impression. I think the objection fails because it relies on a misconception of the notion of measurement. But I think that even if the objection works, we can get a safety based argument that some measurement cases will produce justified true beliefs without knowledge. And that will matter for the argument of the next two sections.</p>
</section>
<section id="the-class-of-gettier-cases-is-disjunctive" class="level3 page-columns page-full" data-number="0.2">
<h3 data-number="0.2" class="anchored" data-anchor-id="the-class-of-gettier-cases-is-disjunctive"><span class="header-section-number">0.2</span> The Class of Gettier Cases is Disjunctive</h3>
<p>There’s an unfortunate terminological confusion surrounding gaps between knowledge and justification. Some philosophers use the phrase ‘Gettier case’ to describe any case of a justified true belief that isn’t knowledge. Others use it to describe just cases that look like the cases in <span class="citation" data-cites="Gettier1963">Gettier (<a href="#ref-Gettier1963" role="doc-biblioref">1963</a>)</span>, i.e., cases of true belief derived from justified false belief. I don’t particularly have strong views on whether either of these uses is <em>better</em>, but I do think it is important to keep them apart.</p>
<p>I’ll illustrate the importance of this by discussing a recent argument due to Jeremy Fantl and Matthew McGrath <span class="citation" data-cites="FantlMcGrath2009">(<a href="#ref-FantlMcGrath2009" role="doc-biblioref">Fantl and McGrath 2009</a> Ch. 4)</span>. I’ve previously discussed this argument <span class="citation" data-cites="Weatherson2011-WEAKBI">(<a href="#ref-Weatherson2011-WEAKBI" role="doc-biblioref">Weatherson 2011</a>)</span>, but I don’t think I quite got to the heart of why I don’t like the kind of reasoning they are using.</p>
<p>The argument concerns an agent, call her <span class="math inline">\(T\)</span>, who has the following unfortunate combination of features. She is very confident that <span class="math inline">\(p\)</span>. And with good reason; her evidence strongly supports <span class="math inline">\(p\)</span>. For normal reasoning, she takes <span class="math inline">\(p\)</span> for granted. That is, she doesn’t distinguish between <span class="math inline">\(\varphi\)</span> is best given <span class="math inline">\(p\)</span>, and that <span class="math inline">\(\varphi\)</span> is simply best. And that’s right too, given the strong evidence that <span class="math inline">\(p\)</span>. But she’s not crazy. Were she to think that she was facing a bet on extreme odds concerning <span class="math inline">\(p\)</span>, she would cease taking <span class="math inline">\(p\)</span> for granted, and revert to trying to maximise expected value given the high probability that <span class="math inline">\(p\)</span>. But she doesn’t think any such bet is salient, so her disposition to retreat from <span class="math inline">\(p\)</span> to <em>Probably p</em> has not been triggered. So far, all is going well. I’m inclined to say that this is enough to say that <span class="math inline">\(T\)</span> justifiedly believes that <span class="math inline">\(p\)</span>. She believes that <span class="math inline">\(p\)</span> in virtue of the fact that she takes <span class="math inline">\(p\)</span> for granted in actual reasoning.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> She’s disposed to stop doing so in some circumstances, but until that disposition is triggered, she has the belief. And this is the right way to act given her evidence, so her belief is justified. So far, so good.</p>
<div class="no-row-height column-margin column-container"><li id="fn3"><p><sup>3</sup>&nbsp;There are some circumlocutions here because I’m being careful to be sensitive to the points raised in <span class="citation" data-cites="SchroederRoss2012">Ross and Schroeder (<a href="#ref-SchroederRoss2012" role="doc-biblioref">2014</a>)</span> about the relationship between belief and reasoning. I think there’s less distance between the view they put forward and the view I defended in <span class="citation" data-cites="Weatherson2005-WEACWD">Weatherson (<a href="#ref-Weatherson2005-WEACWD" role="doc-biblioref">2005</a>)</span> than they do, but this is a subtle matter, and for this paper’s purposes I want to go along with Ross and Schroeder’s picture of belief.</p></li></div><p>Unfortunately, <span class="math inline">\(T\)</span> really does face a bet on long odds about <span class="math inline">\(p\)</span>. She knows she has to choose between <span class="math inline">\(\varphi\)</span> and <span class="math inline">\(\psi\)</span>. And she knows that <span class="math inline">\(\varphi\)</span> will produce the better outcome iff <span class="math inline">\(p\)</span>. But she thinks the amount she’ll gain by choosing <span class="math inline">\(\psi\)</span> if <span class="math inline">\(\neg p\)</span> is roughly the same as the amount she’ll gain by choosing <span class="math inline">\(\varphi\)</span> if <span class="math inline">\(p\)</span>. That’s wrong, and her evidence clearly shows it is wrong. If <span class="math inline">\(p\)</span> is false, then <span class="math inline">\(\varphi\)</span> will be <em>much</em> worse than <span class="math inline">\(\psi\)</span>. In fact, the potential loss here is so great that <span class="math inline">\(\psi\)</span> has the greater expected value given the correct evidential probability of <span class="math inline">\(p\)</span>. I think that means she doesn’t know that <span class="math inline">\(p\)</span>. Someone who knows that <span class="math inline">\(p\)</span> can ignore <span class="math inline">\(\neg p\)</span> possibilities in practical reasoning. And someone who could ignore <span class="math inline">\(\neg p\)</span> possibilities in practical reasoning would choose <span class="math inline">\(\varphi\)</span> over <span class="math inline">\(\psi\)</span>, since it is better if <span class="math inline">\(p\)</span>. But <span class="math inline">\(T\)</span> isn’t in a position to make that choice, so she doesn’t know that <span class="math inline">\(p\)</span>.</p>
<p>(I’ve said here that <span class="math inline">\(T\)</span> is wrong about the costs of choosing <span class="math inline">\(\varphi\)</span> if <span class="math inline">\(p\)</span>, and her evidence shows she is wrong. In fact I think she doesn’t know <span class="math inline">\(p\)</span> if either of those conditions obtain. But here I only want to use the weaker claim that she doesn’t know <span class="math inline">\(p\)</span> if both conditions obtain.)</p>
<p>Fantl and McGrath agree about the knowledge claim, but disagree about the justified belief claim. They argue as follows (this is my version of the ‘Subtraction Argument’ from page 97 of their book).</p>
<ol type="1">
<li><p><span class="math inline">\(T\)</span> is justfied in choosing <span class="math inline">\(\varphi\)</span> iff she knows that <span class="math inline">\(p\)</span>.</p></li>
<li><p>Whether <span class="math inline">\(T\)</span>’s belief that <span class="math inline">\(p\)</span> is true is irrelevant to whether she is justified in choosing <span class="math inline">\(\varphi\)</span>.</p></li>
<li><p>Whether <span class="math inline">\(T\)</span>’s belief that <span class="math inline">\(p\)</span> is ‘Gettiered’ is irrelevant to whether she is justified in choosing <span class="math inline">\(\varphi\)</span>.</p></li>
<li><p>Knowledge is true, justified, UnGettiered belief.</p></li>
<li><p>So <span class="math inline">\(T\)</span> is justfied in choosing <span class="math inline">\(\varphi\)</span> iff she is justified in believing that <span class="math inline">\(p\)</span>.</p></li>
<li><p><span class="math inline">\(T\)</span> is not justified in choosing <span class="math inline">\(\varphi\)</span>.</p></li>
<li><p>So <span class="math inline">\(T\)</span> is not justified in believing that <span class="math inline">\(p\)</span>.</p></li>
</ol>
<p>I think this argument is only plausible if we equivocate on what it is for a belief to be ‘Gettiered’.</p>
<p>Assume first that ‘Gettiered’ means ‘derived from a false intermediate step’. Then premise 4 is false, as Williamson’s example shows. <span class="math inline">\(S\)</span> has a justified true belief that is neither knowledge nor derived from a false premise.</p>
<p>Assume then that ‘Gettiered’ simply means that the true belief is justified without being known. In that case we have no reason to accept premise 3. After all, the class of true justified beliefs that are not knowledge is pretty open ended. Before reading Williamson, we may not have thought that this class included the beliefs of agents using measuring devices that were functioning properly but imperfectly. But it does. Prior to the end of epistemology, we simply don’t know what other kind of beliefs might be in this class. There’s no way to survey all the ways for justification to be insufficient for knowledge, and see if all of them are irrelevant to the justification for action. I think one way a justified belief can fall short of knowledge is if it is tied up with false beliefs about the stakes of bets. It’s hard to say that that is irrelevant to the justification of action.</p>
<p>It is by now reasonably well known that logical subtraction is a very messy and complicated business. See, for instance, <span class="citation" data-cites="Humberstone2000">Humberstone (<a href="#ref-Humberstone2000" role="doc-biblioref">2000</a>)</span> for a clear discussion of the complications. In general, unless it is analytic that <span class="math inline">\(F\)</span>s are <span class="math inline">\(G\)</span>s and <span class="math inline">\(H\)</span>s, for some antecedently understood <span class="math inline">\(G\)</span> and <span class="math inline">\(H\)</span>, there’s nothing interesting to say about the class of things that are <span class="math inline">\(G\)</span> but not <span class="math inline">\(F\)</span>. It will just be a disjunctive shambles. The same is true for knowledge and justification. The class of true beliefs that are justified but not known is messy and disjunctive. We shouldn’t expect to have any neat way of overviewing it. That in part means we can’t say much interesting about it as a class, contra premise 3 in the above argument. It also means the prospects for ‘solving the Gettier problem’ are weak. We’ll turn to that issue next.</p>
</section>
<section id="there-is-no-solution-to-the-gettier-problem" class="level3" data-number="0.3">
<h3 data-number="0.3" class="anchored" data-anchor-id="there-is-no-solution-to-the-gettier-problem"><span class="header-section-number">0.3</span> There is No Solution to the Gettier Problem</h3>
<p>The kind of example that Edmund <span class="citation" data-cites="Gettier1963">Gettier (<a href="#ref-Gettier1963" role="doc-biblioref">1963</a>)</span> gives to refute the justified true belief theory of knowledge has what Linda Zagzebski <span class="citation" data-cites="Zagzebski2009">(<a href="#ref-Zagzebski2009" role="doc-biblioref">2009, 117</a>)</span> aptly calls a “double luck” structure. In Gettier’s original cases, there’s some bad luck that leads to a justified belief being false. But then there’s some good luck that leads to an inference from that being true. As was quickly realised in the literature, the good and bad luck doesn’t need to apply to separate inferential steps. It might be that the one belief that would have been false due to bad luck also ends up being true due to good luck.</p>
<p>This has led to a little industry, especially in the virtue epistemology section of the market, of attempts to “solve the Gettier problem” by adding an anti-luck condition to justification, truth and belief and hoping that the result is something like an analysis of knowledge. As <span class="citation" data-cites="Zagzebski1994">Zagzebski (<a href="#ref-Zagzebski1994" role="doc-biblioref">1994</a>)</span> showed, this can’t be an <em>independent</em> condition on knowledge. If it doesn’t entail truth, then we will be able to recreate the Gettier cases. But maybe a ‘fourth’ condition that entails truth (and perhaps belief) will suffice. Let’s quickly review some of these proposals.</p>
<p>So <span class="citation" data-cites="Zagzebski1996">Zagzebski (<a href="#ref-Zagzebski1996" role="doc-biblioref">1996</a>)</span> suggested that the condition is that the belief be true <em>because</em> justified. John <span class="citation" data-cites="Greco2010">Greco (<a href="#ref-Greco2010" role="doc-biblioref">2010</a>)</span> says that the extra condition is that the beliefs be “intellectually creditable”. That is, the primary that the subject ended up with a true belief is that it was the result of her reliable cognitive faculties. Ernest <span class="citation" data-cites="Sosa2007">Sosa (<a href="#ref-Sosa2007" role="doc-biblioref">2007</a>)</span> said that knowledge is belief that is true because it manifests intellectual competence. John <span class="citation" data-cites="Turri2011">Turri (<a href="#ref-Turri2011" role="doc-biblioref">2011</a>)</span> says that knowledge is belief the truth of which is a manifestation of the agent’s intellectual competence.</p>
<p>It should be pretty clear that no such proposal can work if what I’ve said in earlier sections is remotely right. Assume again that <span class="math inline">\(v = 830, a = 832\)</span> and <span class="math inline">\(m = 10\)</span>. The agent believes that <span class="math inline">\(V \in [822, 842]\)</span>. This belief is, we’ve said, justified and true. Does it satisfy these extra conditions?</p>
<p>My short answer is that it does. My longer answer is that it does if any belief derived from the use of a measuring device does, and since some beliefs derived from the use of measuring devices amount to knowledge, the epistemologists are committed to the belief satisfying the extra condition. Let’s go through those arguments in turn.</p>
<p>In our story, <span class="math inline">\(S\)</span> demonstrates a range of intellectual competencies. She uses a well-functioning measuring device. It is the right kind of device for the purpose she is using. By hypothesis, she has had the machine carefully checked, and knows exactly the accuracy of the machine. She doesn’t form any belief that is too precise to be justified by the machine. And she ends up with a true belief precisely because she has so many competencies.</p>
<p>Note that if we change the story so <span class="math inline">\(a\)</span> is closer to <span class="math inline">\(v + m\)</span>, the case that the belief is true in virtue of <span class="math inline">\(S\)</span> being so competent becomes even stronger. Change the case so that <span class="math inline">\(a = 839\)</span>, and she forms the true belief that <span class="math inline">\(V \in [829, 849]\)</span>. Now if <span class="math inline">\(S\)</span> had not been so competent, she may have formed a belief with a tighter range, since she could easily have guessed that the margin of error of the machine is smaller. So in this case the truth of the belief is very clearly due to her competence. But as we noted at the end of section 1, in the cases where <span class="math inline">\(a\)</span> is near <span class="math inline">\(v + m\)</span>, the argument that we have justified true belief without knowledge is particularly strong. Just when the gap between justification and knowledge gets most pronounced, the competence based approach to knowledge starts to issue the strongest verdicts <em>in favour</em> of knowledge.</p>
<p>But maybe this is all a mistake. After all, the object doesn’t have the mass it has because of <span class="math inline">\(S\)</span>’s intellectual competence. The truth of any claim about its mass is not because of <span class="math inline">\(S\)</span>’s competence, or a manifestation of that competence. So maybe these epistemologists get the correct verdict that <span class="math inline">\(S\)</span> does not know that <span class="math inline">\(V \in [a - m, a + m]\)</span>?</p>
<p>Not so quick. Even had <span class="math inline">\(a\)</span> equalled <span class="math inline">\(v\)</span>, all these claims would have been true. And in that case, <span class="math inline">\(S\)</span> would have known that <span class="math inline">\(V\)</span> was within <span class="math inline">\(m\)</span> of the measurement. What is needed for these epistemological theories to be right is that there can be a sense that a belief that <span class="math inline">\(p\)</span> can be true in virtue of some cause <span class="math inline">\(C\)</span> without <span class="math inline">\(C\)</span> being a cause of <span class="math inline">\(p\)</span>. I’m inclined to agree with the virtue epistemologists that such a sense can be given. (I think it helps to give up on content essentialism for this project, as suggested by <span class="citation" data-cites="David2002">David (<a href="#ref-David2002" role="doc-biblioref">2002</a>)</span> and endorsed in@Weatherson2004-WEALMT.) But I don’t think it will help. There’s no real way in which a belief is true because of competencies, or in which the truth of a belief manifests competence, in the good case where <span class="math inline">\(a = v\)</span>, but not in the bad cases, where <span class="math inline">\(a\)</span> is in <span class="math inline">\((0, m)\)</span>. These proposals might help with ‘double luck’ cases, but there is more to the space between justification and knowledge than those cases. Of course, I think the space in question includes some cases involving false beliefs about the practical significance of <span class="math inline">\(p\)</span>, but I don’t expect everyone to agree with that. Happily, the Williamsonian cases should be less controversial.</p>
</section>
<section id="what-can-we-learn-from-fallible-machines" class="level3" data-number="0.4">
<h3 data-number="0.4" class="anchored" data-anchor-id="what-can-we-learn-from-fallible-machines"><span class="header-section-number">0.4</span> What Can We Learn from Fallible Machines?</h3>
<p>My presentation of Williamson’s argument in section 1 abstracted away from several features of his presentation. In particular, I didn’t make any positive assumption about what the agent can know when they find out that the machine reads <span class="math inline">\(a\)</span>. Williamson makes a suggestion, though he offers it more as the most internalist friendly suggestion than the most likely correct hypothesis.</p>
<p>The suggestion, which I’ll call the <strong>Circular Reading Centred</strong> hypothesis, is that the most the agent can know is that <span class="math inline">\(V \in [a - (e + m), a + (e + m)]\)</span>. That is, the agent can know that <span class="math inline">\(V\)</span> is in a region centred on <span class="math inline">\(a\)</span>, the ‘radius’ of which is the margin of error <span class="math inline">\(m\)</span>, plus the error on this occasion <span class="math inline">\(e\)</span>. This is actually a quite attractive suggestion, though not the only suggestion we could make. Let’s look through some other options and see how well they work.</p>
<p>We said above that the agent can’t know more from a mismeasurement than they can know from an accurate measurement. And we said that given an accurate measurement, the most they can know is that <span class="math inline">\(V \in [v - m, v + m]\)</span>. So here’s one very restrictive suggestion: if <span class="math inline">\(a \in [v - m, v + m]\)</span>, then the agent can know that <span class="math inline">\(V \in [v - m, v + m]\)</span>. But we can easily rule that out on the basis of considerations about justification. The strongest proposition the agent is justified in believing is that <span class="math inline">\(V \in [a - m, a + m]\)</span>. If the agent could know that <span class="math inline">\(V \in [v - m, v + m]\)</span>, then she could know that <span class="math inline">\(V \notin (v + m, a + m]\)</span>, even though she isn’t justified in believing this. This is absurd, so that proposal is wrong.</p>
<p>We now have two principles on the table: <span class="math inline">\(S\)</span> can’t know anything by a mismeasurement that she knows on the basis of a correct measurement, and that she can only know things she’s justified in believing. The first principle implies that for all <span class="math inline">\(x \in [v - m, v + m]\)</span>, that <span class="math inline">\(V = x\)</span> is epistemically possible. The second implies that for all <span class="math inline">\(x \in [a -m, a + m]\)</span>, that <span class="math inline">\(V = x\)</span> is epistemically possible. Our next proposal is that the epistemic possibilities, given a reading of <span class="math inline">\(a\)</span>, are just that <span class="math inline">\(V \in [v - m, v + m] \cup [a - m, a + m]\)</span>.</p>
<p>But this is fairly clearly absurd too. Assume that <span class="math inline">\(a &gt; v + 2m\)</span>. This is unlikely, but as we said above not impossible. Now consider the hypothesis that <span class="math inline">\(V \in (v + m, a - m)\)</span>. On the current hypothesis, this would be ruled out. That is, she would know it doesn’t obtain. But this seems bizarre. There are epistemic possibilities all around it, but somehow she’s ruled out this little gap, and done so on the basis of a horrifically bad measurement.</p>
<p>This suggests two other approaches that are consistent with the two principles, and which do not have such an odd result. I’ll list them alongside the proposal we mentioned earlier.</p>
<dl>
<dt>Circular Appearance Centred</dt>
<dd>
<p>The strongest proposition the agent can know is that <span class="math inline">\(V \in [a - (e + m), a + (e + m)]\)</span>.</p>
</dd>
<dt>Circular Reality Centred</dt>
<dd>
<p>The strongest proposition the agent can know is that <span class="math inline">\(V \in [v - (e + m), v + (e + m)]\)</span>.</p>
</dd>
<dt>Elliptical</dt>
<dd>
<p>The strongest proposition the agent can know is that <span class="math inline">\(V \in [v - m, a + m]\)</span>.</p>
</dd>
</dl>
<p>The last proposal is called <strong>Elliptical</strong> because it in effect says that there are two foci for the range of epistemic possibilities. The agent can’t rule out anything within <span class="math inline">\(m\)</span> of the true value, or anything within <span class="math inline">\(m\)</span> of the apparent value, or anything between those.</p>
<p>Actually we can motivate the name even more by considering a slight generalisation of the puzzle that we started with. Assume that <span class="math inline">\(R\)</span> is trying to determine the location of an object in a two-dimensional array. As before, she has a digital measuring device, perhaps a GPS locator trained on the object in question. And she knows that margin of error of the device is <span class="math inline">\(m\)</span>. The object is actually located at <span class="math inline">\(\langle x_v, y_v \rangle\)</span>, and the device says it is at <span class="math inline">\(\langle x_a, y_a \rangle\)</span>. So the epistemic possibilities, by the reasoning given above, should include the circles with radius <span class="math inline">\(m\)</span> centred on <span class="math inline">\(\langle x_v, y_v \rangle\)</span> and <span class="math inline">\(\langle x_a, y_a \rangle\)</span>. Call these circles <span class="math inline">\(C_v\)</span> and <span class="math inline">\(C_a\)</span>. Unless <span class="math inline">\(\langle x_v, y_v \rangle= \langle x_a, y_a \rangle\)</span>, the union of these circles will not be convex. If the distance between <span class="math inline">\(\langle x_v, y_v \rangle\)</span> and <span class="math inline">\(\langle x_a, y_a \rangle\)</span> is greater than <span class="math inline">\(2m\)</span>, the union won’t even be connected. So just as we ‘filled in’ the gap in the one-dimensional case, the natural thing to say is that any point in the convex hull of <span class="math inline">\(C_v\)</span> and <span class="math inline">\(C_a\)</span> is an epistemic possibility.</p>
<p>But now see what happens if we say those are all of the epistemic possibilities, i.e., that the agent knows that the true value lies in the convex hull of the two circles. Here’s what it might look like.</p>
<p>Now consider the line from <span class="math inline">\(\langle x_v, y_v \rangle\)</span> to <span class="math inline">\(\langle x_a, y_a \rangle\)</span>. No matter how bad the measurement is, the convex hull of the two circles <span class="math inline">\(C_v\)</span> and <span class="math inline">\(C_a\)</span> will include no points more than distance <span class="math inline">\(m\)</span> from the line between <span class="math inline">\(\langle x_v, y_v \rangle\)</span> to <span class="math inline">\(\langle x_a, y_a \rangle\)</span>. That is, the agent can know something surprisingly precise about how close <span class="math inline">\(V\)</span> is to a particular line, even on the basis of a catastrophically bad measurement.</p>
<p>There are some circumstances where this wouldn’t be counterintuitive. Assume that <span class="math inline">\(x_v = x_a\)</span>, while <span class="math inline">\(y_v\)</span> and <span class="math inline">\(y_a\)</span> are very very different. And assume further that <span class="math inline">\(\langle x_a, y_a \rangle\)</span> is calculated by using two very different procedures for the <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> coordinates. (Much as sailors used to use very different procedures to calculate longitude and latitude.) Then the fact that one process failed badly doesn’t, I think, show that we can’t get fairly precise knowledge from the other process.</p>
<p>But that’s not the general case. If the machine determines <span class="math inline">\(\langle x_a, y_a \rangle\)</span> by a more holistic process, then a failure on one dimension should imply that we get less knowledge on other dimensions, since it makes it considerably flukier that we got even one dimension right. So I think the space of epistemic possibilities, in a case involving this kind of errant measurement, must be greater than the convex hull of <span class="math inline">\(C_v\)</span> and <span class="math inline">\(C_a\)</span>.</p>
<p>Fortunately, there are a couple of natural generalisations of the elliptical proposal that avoid this complication. One of them says that the space of epistemic possibilities forms an ellipse. In particular, it is the set of all points such that the sum of the distance from that point to <span class="math inline">\(\langle x_v, y_v \rangle\)</span> and the distance from that point to <span class="math inline">\(\langle x_a, y_a \rangle\)</span> is less than or equal to <span class="math inline">\(2m + e\)</span>, where <span class="math inline">\(e\)</span> again is the distance between the measured and actual value. As you can quickly verify, that includes all points on the line from <span class="math inline">\(\langle x_v, y_v \rangle\)</span> to <span class="math inline">\(\langle x_a, y_a \rangle\)</span>, plus an extension of length <span class="math inline">\(m\)</span> beyond in each direction. But it doesn’t just contain the straight path between <span class="math inline">\(C_v\)</span> and <span class="math inline">\(C_a\)</span>; it ‘bulges’ in the middle. And the considerations above suggest that is what should happen.</p>
<p>The other alternative is to drop the idea that the space of possibilities should be elliptical, and have another circular proposal. In particular, we say that the space of possibilities is the circle whose centre is halfway between <span class="math inline">\(\langle x_v, y_v \rangle\)</span> and <span class="math inline">\(\langle x_a, y_a \rangle\)</span>, and whose radius is <span class="math inline">\(m + \nicefrac{e}{2}\)</span>. Again, that will include all points on the line from <span class="math inline">\(\langle x_v, y_v \rangle\)</span> to <span class="math inline">\(\langle x_a, y_a \rangle\)</span>, plus an extension of length <span class="math inline">\(m\)</span> beyond in each direction. But it will include a much larger space in the middle.</p>
<p>I think both of these are somewhat plausible proposals, though the second suffers from a slightly weaker version of the objection I’m about to mount to the Circular Reality Centred proposal. But they do share one weakness that I think counts somewhat against them. It’s easy enough to see what the weakness is in the one-dimensional case, so let’s return to it for the time being, and remember we’re assuming that <span class="math inline">\(a &gt; v\)</span>.</p>
<p>Consider a case where <span class="math inline">\(e\)</span> is rather large, much larger than <span class="math inline">\(m\)</span>. This affects how far below <span class="math inline">\(v\)</span> we have to go in order to reach possibilities that are ruled out by the measurement. But it doesn’t affect how far above <span class="math inline">\(v\)</span> we have to go in order to reach such possibilities. Indeed, no matter how bad <span class="math inline">\(e\)</span> is, we can be absolutely certain that we know <span class="math inline">\(V &lt; a + 2m\)</span>, or that we know that <span class="math inline">\(V &gt; a - 2m\)</span>. That seems a little odd; if the measurement is so badly mistaken, it seems wrong that it can give us such a fine verdict, at least in one direction.</p>
<p>I don’t think that’s a conclusive objection. Well, I don’t think many of the considerations I’ve listed here are <em>conclusive</em>, but this seems even weaker. But it is a reason to look away from the elliptical proposal and back towards the circular proposals that we started with.</p>
<p>If we just look at first order knowledge claims, it is hard to feel much of an intuitive pull towards one or other of the alternatives. Perhaps safety based considerations favour the Reality Centred over the Appearance Centred version, but I don’t think the salient safety consideration is that strong.</p>
<p>If we look at iterated knowledge claims, however, there is a big problem with the Reality Centred approach. The intuition here is clearer if we use numerical examples, so I’ll work through a case with numbers first, then do the general version next.</p>
<p>Assume, as above, that <span class="math inline">\(v = 830, a = 834\)</span> and <span class="math inline">\(m = 10\)</span>. So we have a pretty decent measurement here. On the Reality Centred proposal, the strongest thing that <span class="math inline">\(S\)</span> can know is that <span class="math inline">\(V \in [816, 844]\)</span>. So it is an epistemic possibility that <span class="math inline">\(V = 816\)</span>. Assume that that’s the actual possibility. Then the measurement is rather bad; the new value for <span class="math inline">\(e\)</span> is 18. Were <span class="math inline">\(V\)</span> to equal 816, while <span class="math inline">\(a\)</span> equalled 834, then on the Reality Centred approach, the epistemic possibilities would be a circle of radius <span class="math inline">\(e+m\)</span>, i.e., 28, around the actual value, i.e., 816. So the strongest thing the agent could know is that <span class="math inline">\(V \in [788, 844]\)</span>. On the other hand, if <span class="math inline">\(V\)</span> were 844, the strongest thing the agent could know is that <span class="math inline">\(V \in [824, 864]\)</span>. Putting those together, the strongest thing the agent can know that she knows is that <span class="math inline">\(V \in [788, 864]\)</span>. That’s a very large range already. Similar calculations show that the strongest thing the agent can know that she knows that she knows is that <span class="math inline">\(V \in [732, 904]\)</span>.</p>
<p>Now I’ll grant that intuitions about second and third order knowledge are not always maximally sharp. But I think it is very implausible that a relatively accurate measurement like this could lead to such radical ignorance in the second and third orders of knowledge. So I think the Reality Centred approach can’t be right.</p>
<p>The general form the case is as follows. The strongest thing the agent can know is that <span class="math inline">\(V \in [v - (e + m), a + m]\)</span>. The strongest thing she can know that she knows is that <span class="math inline">\(V \in [v - 3(e + m), a + 3m]\)</span>. And the strongest thing she can know that she knows that she knows is that <span class="math inline">\(V \in [v - 7(e + m), a + 7m]\)</span>. In general, we have <em>exponential</em> growth of the possibilities as we add one extra order of knowledge. That seems absurd to me, so the Reality Centred approach is wrong.</p>
<p>Note that this isn’t a problem with the Appearance Centred approach. The first-order epistemic possibilities are that <span class="math inline">\(V \in [a - (e + m), a + e + m]\)</span>. If <span class="math inline">\(V\)</span> is at the extremes of this range, then <span class="math inline">\(e\)</span> will be rather large. For example, if <span class="math inline">\(V\)</span> were equal to <span class="math inline">\(a + e + m\)</span>, then the new error would be <span class="math inline">\(e + m\)</span>, since the measured value is still <span class="math inline">\(a\)</span>. So the range of possibilities would be that <span class="math inline">\(V \in [a - ((e + m) + m), a + ((e + m) + m)]\)</span>. Somewhat surprisingly, those would also be the possibilities if <span class="math inline">\(V\)</span> were equal to <span class="math inline">\(a - (e + m)\)</span>, since the only feature of <span class="math inline">\(V\)</span> that affects the epistemic possibilities for <span class="math inline">\(V\)</span> is its distance from <span class="math inline">\(a\)</span>. So for all <span class="math inline">\(S\)</span> knows that she knows, <span class="math inline">\(V\)</span> could be anything in <span class="math inline">\([a - (e + 2m), a + (e + 2m)]\)</span>. Similar reasoning shows that for all <span class="math inline">\(V\)</span> knows that she knows that she knows, <span class="math inline">\(V\)</span> could be anything in <span class="math inline">\([a - (e + 3m), a + (e + 3m)]\)</span>. In general, <span class="math inline">\(V\)</span> has <span class="math inline">\(n\)</span>’th order knowledge that <span class="math inline">\(V\)</span> is in <span class="math inline">\([a - (e + nm), a + (e + nm)]\)</span>. This linear growth in the size of the range of epistemic possibilities is more plausible than the exponential growth on the Reality Centred approach.</p>
<p>So all things considered, I think the Circular Appearance Centred approach is the right one, as Williamson suggests. Any simple alternative seems to have rather counterintuitive consequences.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Cohen1984" class="csl-entry" role="listitem">
Cohen, Stewart. 1984. <span>“Justification and Truth.”</span> <em>Philosophical Studies</em> 46 (3): 279–95. <a href="https://doi.org/10.1007/bf00372907">https://doi.org/10.1007/bf00372907</a>.
</div>
<div id="ref-David2002" class="csl-entry" role="listitem">
David, Marian. 2002. <span>“Content Essentialism.”</span> <em>Acta Analytica</em> 17: 103–14. <a href="https://doi.org/10.1007/bf03177510">https://doi.org/10.1007/bf03177510</a>.
</div>
<div id="ref-FantlMcGrath2009" class="csl-entry" role="listitem">
Fantl, Jeremy, and Matthew McGrath. 2009. <em>Knowledge in an Uncertain World</em>. Oxford: Oxford University Press.
</div>
<div id="ref-Gettier1963" class="csl-entry" role="listitem">
Gettier, Edmund L. 1963. <span>“Is Justified True Belief Knowledge?”</span> <em>Analysis</em> 23 (6): 121–23. <a href="https://doi.org/10.2307/3326922">https://doi.org/10.2307/3326922</a>.
</div>
<div id="ref-Greco2010" class="csl-entry" role="listitem">
Greco, John. 2010. <em>Achieving Knowledge</em>. Cambridge: Cambridge University Press.
</div>
<div id="ref-Humberstone2000" class="csl-entry" role="listitem">
Humberstone, Lloyd. 2000. <span>“Parts and Partitions.”</span> <em>Theoria</em> 66 (1): 41–82. <a href="https://doi.org/10.1111/j.1755-2567.2000.tb01144.x">https://doi.org/10.1111/j.1755-2567.2000.tb01144.x</a>.
</div>
<div id="ref-SchroederRoss2012" class="csl-entry" role="listitem">
Ross, Jacob, and Mark Schroeder. 2014. <span>“Belief, Credence, and Pragmatic Encroachment.”</span> <em>Philosophy and Phenomenological Research</em> 88 (2): 259–88. <a href="https://doi.org/10.1111/j.1933-1592.2011.00552.x">https://doi.org/10.1111/j.1933-1592.2011.00552.x</a>.
</div>
<div id="ref-Sainsbury1996" class="csl-entry" role="listitem">
Sainsbury, Mark. 1995. <span>“Vagueness, Ignorance and Margin for Error.”</span> <em>British Journal for the Philosophy of Science</em> 46: 589–601. <a href="https://doi.org/10.1093/bjps/46.4.589">https://doi.org/10.1093/bjps/46.4.589</a>.
</div>
<div id="ref-Sosa2007" class="csl-entry" role="listitem">
Sosa, Ernest. 2007. <em>A Virtue Epistemology: Apt Belief and Reflective Knowledge</em>. Oxford: Oxford University Press.
</div>
<div id="ref-Turri2011" class="csl-entry" role="listitem">
Turri, John. 2011. <span>“Manifest Failure: The Gettier Problem Solved.”</span> <em>Philosophers’ Imprint</em> 11 (8): 1–11. <a href="http://hdl.handle.net/2027/spo.3521354.0011.008">http://hdl.handle.net/2027/spo.3521354.0011.008</a>.
</div>
<div id="ref-Weatherson2005-WEACWD" class="csl-entry" role="listitem">
Weatherson, Brian. 2005. <span>“<span>Can We Do Without Pragmatic Encroachment?</span>”</span> <em>Philosophical Perspectives</em> 19 (1): 417–43. <a href="https://doi.org/10.1111/j.1520-8583.2005.00068.x">https://doi.org/10.1111/j.1520-8583.2005.00068.x</a>.
</div>
<div id="ref-Weatherson2011-WEAKBI" class="csl-entry" role="listitem">
———. 2011. <span>“Knowledge, Bets and Interests.”</span> In <em>Forthcoming Volume on Knowledge Ascriptions</em>, edited by Jessica Brown and Mikkel Gerken, 75–103. Oxford: Oxford University Press.
</div>
<div id="ref-Williamson2000-WILKAI" class="csl-entry" role="listitem">
Williamson, Timothy. 2000. <em><span class="nocase">Knowledge and its Limits</span></em>. Oxford University Press.
</div>
<div id="ref-WilliamsonLofoten" class="csl-entry" role="listitem">
———. 2013. <span>“Gettier Cases in Epistemic Logic.”</span> <em>Inquiry</em> 56 (1): 1–14. <a href="https://doi.org/10.1080/0020174X.2013.775010">https://doi.org/10.1080/0020174X.2013.775010</a>.
</div>
<div id="ref-Zagzebski1994" class="csl-entry" role="listitem">
Zagzebski, Linda. 1994. <span>“The Inescapability of Gettier Problems.”</span> <em>The Philosophical Quarterly</em> 44 (174): 65–73. <a href="https://doi.org/10.2307/2220147">https://doi.org/10.2307/2220147</a>.
</div>
<div id="ref-Zagzebski1996" class="csl-entry" role="listitem">
———. 1996. <em>Virtues of the Mind: An Inquiry into the Nature of Virtue and the Ethical Foundations of Knowledge</em>. Cambridge: Cambridge University Press.
</div>
<div id="ref-Zagzebski2009" class="csl-entry" role="listitem">
———. 2009. <em>On Epistemology</em>. Belmont, CA.: Wadsworth.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>