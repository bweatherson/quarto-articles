---
title: "Incomplete Preference"
description: |
  Philosophers have typically studied incomplete preference by looking at situations where agents have incomplete preferences over ends. In this paper, I start by looking at cases where agents have incomplete preferences over means. The lessons from these cases provide strong support for the view that incomplete preferences can be rational. Many arguments against incomplete preferences turn out to rely on assumptions that are implausible in full generality.
author:
  - name: Brian Weatherson 
    url: http://brian.weatherson.org
    affiliation: University of Michigan
    affiliation_url: https://umich.edu
    orcid_id: 0000-0002-0830-141X
date: 01-17-2024
citation: false
categories:
  - games and decisions
  - unpublished
format:
  html: default
  pdf:
    output-file: "Incomplete Preferences"
    include-after-body: 
      text: |
         Unpublished. Posted online in 2024.
---

# Introduction

One of the striking features of the contemporary decision theory literature is the separation between work that discusses Newcomb problem style demons, and work that does not. Both of these halves of decision theory are thriving, but they are largely thriving in isolation from each other. This feels like a mistake, and both halves could learn from the other. This paper is a step towards bringing the two closer together. In particular, it will argue that thinking about problems involving demons gives us reason to reject several arguments against the rationality of incomplete preferences.

Our taking off point will be Harvey Lederman's recent discussion of a familiar principle of **Independence** and a new principle he calls **Negative Dominance**.

Independence
:    It’s rationally required that: if someone is not averse or
prone to risk, they prefer a game of chance *A* to a game of chance
*B* if and only if they also prefer a game consisting of a *p* chance of
*A* and a (1 − *p*) chance of some other *C* to a game consisting of a *p*
chance of *B* and a (1 − *p*) chance of the same *C*. [@Lederman2024 pg 8]

Negative Dominance
:    It’s rationally required that: if [a chooser] strictly prefers
one game of chance to another, she prefers one of the prizes that the
first might yield, to one of the prizes that the second might yield. [@Lederman2024 pg 5]

Lederman shows that given some very weak assumptions, Independence, Negative Dominance, and Incomplete Preferences are inconsistent. Incomplete Preferences is best understood as the denial of the claim that preferences have to be complete.

Complete Preferences
:    A preference ordering is *complete* just in case, for any two alternatives X and Y, you either prefer X to Y, prefer Y to X, or are indifferent between the two. [@Doody2019a 559]

Lederman goes on to note, without endorsing, an argument that takes Independence and Negative Dominance as premises, and concludes that Incomplete Preferences is false. I'm going to argue that when we think about cases involving demons, the natural generalisations of Independence and Negative Dominance are themselves inconsistent. That shows there can't be an argument against Incomplete Preferences here.

Getting the machinery on the table to show this will take some time, but it will have other payoffs. The same machinery can be used to quickly reply to money pump arguments against incomplete preferences (@Gustaffson2023) and imprecise credences (@Elga20xx), and to semantic arguments against each of these things (@DorrEtAl2022, @DorrEtAl2023).

# Games and Demons

## Games as Decisions

It's a fairly old point by now that once we allow demons into decision theory, as we did when we started discussing Newcomb's Problem, some games look a lot like decision problems. As @Lewis1981a notes, a pair of (self-interested) twins playing Prisoners' Dilemma is facing something like a Newcomb Problem.

It's easy to overstate the point Lewis is making here, and the title of his paper probably encourages this overstatement. But what's true is that each of the twins faces a problem where Evidential Decision Theory (EDT) recommends one course of action, and standard forms of Causal Decision Theory (CDT) recommend another. That's enough to suggest there is a connection between this debate within decision theory and some familiar problems in game theory.

## Decisions as Games

A few years later, William @Harper1986 argued that we can turn many decision problems involving demons into games. At least in Newcomb's Problem, the demon is just like a game player with a simple reward function. They get a positive reward if they correctly predict what the human player takes, and no reward otherwise. That is, we can turn the decision problem in @tbl-newcomb-decision into the game in @tbl-newcomb-game.

|          |  **P1**    | **P2** |
|:--------:|:----------:|:------:|
|  **1**   |   1000     |  0     |
|  **2**   |   1001     |  1     |

: Newcomb's Problem. {#tbl-newcomb-decision}

|          |  **1**    | **2** |
|:--------:|:----------:|:------:|
|  **1**   |   1000, 1  |  0, 0     |
|  **2**   |   1001, 0  |  1, 1     |

: Newcomb's Problem as a game. {#tbl-newcomb-game}

In @tbl-newcomb-decision, the rows are labelled 1 and 2 for human taking either 1 box or two. The columns have a 'P' in front of the options for the human because they are what the demon **predicts**. In the game version, i.e., @tbl-newcomb-game, I've just labeled them as 1 and 2 because the fact that they are predictions is now moved into the payoff structure.

There is only one Nash equilibrium of @tbl-newcomb-game, and it's the result that dominance reasoning gets you to in @tbl-newcomb-decision. This is a paper in decision theory, and I'll mostly work with cases like @tbl-newcomb-decision. But a lot of what I say here is just taking fairly familiar points from game theory, and translating them back into decision-theoretic language. And that idea is something I'm taking directly from @Harper1986.

## Three Approaches to Probabilistic Dependence

If we allow that states can be probabilistically dependent on actions, as the predictions of a demon can be probabilistically (though not causally) dependent on human's choice, this makes a difference to how we calculate expected utilities. Everyone agrees, for example, that just multiplying state probabilities by the utility of the state given some action, and summing the total, does not produce a useful guide to action if states are causally dependent on actions. And most everyone agrees that if states and actions are both causally and probabilistically independent (and all relevant values are numerical), then multiplying and summing like this is exactly what one should do to figure out the best action. But there are a number of theories that disagree with each other in general, but agree in these extreme cases. Philosophers have primarily focussed on two of these; I'll note a third that is just as plausible.

One approach is that of Evidential Decision Theory. It says the problem with all that multiplying and summing is that it had the wrong input. We shouldn't start with the probability of a state. Rather, we should start with the probability of a state given an action. In symbols, where A ranges over the actions and S over the states, the value V of an action is given by

$$
V(A) = \sum \Pr(S | A) V(S \wedge A)
$$

The rational actor maximises this value. 

A standard version of causal decision theory agrees with the general approach, but says the amendment was wrong. It says that the input should be the probability of some kind of counterfactual. In particular, it says the utility U of an action is given by

$$
U(A) = \sum \Pr(A \square \rightarrow S) V(S \wedge A)
$$

There are some bells and whistles needed if there are multiple states that might occur, but this is the basic idea. (Dmitri @Gallow2024 has a detailed argument that this really captures the essence of the classic versions of Causal Decision Theory.)

It's an interesting fact that game theorists typically use neither of these options. Pick up a game theory text, and the standard definition of expected utility includes neither conditional probabilities, as in the definition of V, nor probabilities of counterfactuals, as in the definition of U. Indeed, it is common to not even see a symbol for counterfactuals in such a book, even though they are doing 

EDT
Counterfactuals - Quote Hedden and Gallow
Ex Post unconditional probabilities

## Three Approaches to Dynamics

Purely Strategic
Purely Consequentialist
Both

Why Both

1. Know what you'll do
2. Backward Looking constraints
3. Temporal wide scope norms

Key thing: Ability to carry out sensible plans isn't the same as ability to bind
Only requires that one can bind oneself to things conditional on them being choiceworthy

## Mixed Strategies

Setting aside, though they are relevant

## Choice, Not Preference

If one is using the ex post approach to demonic problems, as game theorists typically do, one loses something that philosophers occasionally care about. The about of one's algorithms is not a preference order; it's just a set of choice-worthy options.

It's easy to say what makes something choice-worthy on this model. Conditional on it being chosen, it maximises expected utility. But among two choices that are not choice-worthy, which one is preferable? There are ways to try to extend the ex post approach to answer this question, but none of them are particularly satisfactory, and I won't walk you through the various failures here. Instead I'll just note that given this approach, it makes sense to simply accept that the role of a decision theory is to provide a function from decision problems to choice-worthy options.

This is a practical problem because the principles we've stated earlier, **Incomplete Preferences**, **Independence**, and **Negative Dominance**, are all stated in terms of preferences. So one immediate task is to restate them in terms of choice-worthiness.

There is a familiar, and I think correct, way to do this for **Incomplete Preferences**, familiar from @XXX1974 and @Chang2002.^[I learned about @XXXX1974 from @DorrEtAl2023.] If A and B are equally preferred, then some small *sweetening* of A will be preferred to B. X is a sweetening of Y iff X sometimes produces the same outcome as Y, and sometimes produces a strictly better outcome, and the latter has either positive probability, or results from the taking of a choice-worthy option.^[It doesn't always make sense in this framework to assign probabilities to ones own choices, which is why these two disjuncts are both needed.] Then we can define **Incomplete Choice** as follows.

Incomplete Choice
:    A choice function C is **incomplete** iff there exist options A, A+, and B, where A+ is a sweetening of B, and C(\{A, B\}) = \{A, B\}, and C(\{A+, B\}) = \{A+, B\}.

In terms of preference, C(\{A, B\}) = \{A, B\} means that A and B are either equally preferred, or there is no preference between them. If they are equally preferred, then C(\{A+, B\}) = \{A+\}, since sweetenings break ties. So if C(\{A+, B\}) = \{A+, B\}, there must be an incomplete preference, as required. That's to say, if you take preferences as primitive, and define choice functions in terms of them, you should accept **Incomplete Choice** iff you accept **Incomplete Preference**. I'm taking **Incomplete Choice** as the basic definition of incompleteness, but you can think it's the right diagnostic for incompleteness even if you don't think it's basic.


# Two Structural Constraints

## Choiceworthy Options

Quick summary of why to use choice not preference

## Collapse

C(A, S) = C(A u S)

## Choice Reflection

If A in C-sub-i(S) for all outcomes i of a lottery, then A in C(S)

# Three Theories that Violate These Constraints

## Multiple Equilibria

If there are multiple equilibria, each of them is choiceworthy
Go over how it violates both

## Imprecise Credence

Dilation examples
Let S = {Pr: Pr(p) = Pr(q) = 1/2}, and consider bets on p before-after learning q.

## Incomplete Preferences

Lederman example

# Independence and Reflection

As noted above, Lederman makes a convincing case that Incomplete Preferences, Independence, and Choice Reflection are inconsistent. One might be tempted to argue that since Independence and Choice Reflection are so plausible, this is bad news for Incomplete Preferences. This temptation should be resisted. Complete Preferences, Independence, and Choice Reflection are also inconsistent, once there are demons around. In fact, we can show something stronger: Complete Preferences and Independence are inconsistent.

Given Complete Preferences, options A and B are equally good in @tbl-symmetric-coordination. After all, the names of options shouldn't make a difference to which option is better, and there is nothing else to separate them.^[Depending on how precisely one formulates Independence, one might be able to derive from it that the names of options don't matter. But I don't think it's worth fussing over this, since no one is likely to object to this premise.] 

|          |  **PA**    | **PB** |
|:--------:|:----------:|:------:|
|  **A**   |   *y*      |  0     |
|  **B**   |   0        |  *y*   |

: A symmetric coordination game. {#tbl-symmetric-coordination}

Now consider the variant in @tbl-asymmetric-coordination, with *x* > *y* > 0.

|          |  **PA**    | **PB** |
|:--------:|:----------:|:------:|
|  **A**   |   *x*      |  0     |
|  **B**   |   0        |  *y*   |

: An symmetric coordination game. {#tbl-asymmetric-coordination}

Since we get from @tbl-symmetric-coordination to @tbl-asymmetric-coordination by sweetening option A, and in @tbl-symmetric-coordination, A and B were equally good, it follows, given Complete Preferences, that in @tbl-asymmetric-coordination, A is better than B.

Now consider the following two stage game, which I'll call the Independence Game. At stage 1, Demon will predict whether Chooser will take A or B. If Demon predicts A, the game will end with probability 0.5, and Chooser will get a payout of 0. Otherwise, the game will continue to stage 2, as it will if Demon predicts B. At stage 2, @tbl-main-game-stage-two will be played.

|          |  **PA**    | **PB** |
|:--------:|:----------:|:------:|
|  **A**   |   4        |  0     |
|  **B**   |   0        |  3     |

: Stage two of the Independence Game. {#tbl-main-game-stage-two}

Note that if Chooser is arbitrarily confident that Demon will predict correctly, they should retain that confidence after learning that the game has made it to stage two. After all, even if they choose A, the fact that the game didn't exit isn't particularly strong evidence against the Demon making an accurate prediction. It should double their credence that Demon predicted inaccurately, but double an arbitrarily small quantity is still very small.

Given Complete Preferences, if the game reaches Stage 2, Chooser should choose A. After all, @tbl-main-game-stage-two has the same form as @tbl-asymmetric-coordination, and we saw above that in that game, A should be chosen.

Now make one small change to the game. Chooser is not asked to play at stage 2. Instead, after Demon has made their prediction, but before it is announced, they are asked to choose a strategy for the Independence Game. What strategy they choose won't make a difference if Demon has predicted A, and the coin flip has meant that the game ends. But it will make a difference if the game reaches stage 2. Indeed, picking a strategy for the Independence Game just is answering the question: _If the game reaches Stage Two, what do you want to do?_.

And here we run into a problem. By Independence, Chooser should adopt the strategy of doing A. After all, the strategy choices make no difference if the game ends at stage 1, and if the game gets to stage 2, we just saw that (given Complete Preferences), A is better than B. On the other hand, before learning whether the game ends at stage 1, @tbl-main-game-strategic is the decision table Chooser faces, with the expected values of each of the choice/prediction pairs.

|          |  **PA**    | **PB** |
|:--------:|:----------:|:------:|
|  **A**   |   2        |  0     |
|  **B**   |   0        |  3     |

: Stragetic form of the Independence Game. {#tbl-main-game-strategic}

The value in the top-left cell in @tbl-main-game-strategic comes from the fact that if Chooser selects A, and Demon predicts A, then Chooser gets a payout of 4 with probability 0.5, and 0 with probability 0.5, for an expected return of 2.

Given Complete Preferences, in that game, Chooser should prefer B. After all, this is just a version of @tbl-asymmetric-coordination with the labels flipped.




So the problem isn't just Incomplete Preferences or Imprecise Credences

# Independence and Collapse

Same example shows that collapse fails

# Money Pumps

As long as you have the dual mandate, you avoid the money pump
See the Dutch Book coming reasoning

# Semantics

The Single Choice Principle has just as much semantic support
It's just the Ramsey test
Should instead go with theoretical virtues
Lederman says that should allow incomplete preferences because the value structure of the world could be incomplete
This shows another reason; incomplete preferences over choices is compatible with complete preferences over outcomes.
