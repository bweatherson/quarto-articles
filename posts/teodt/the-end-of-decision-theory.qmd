---
title: "The End of Decision Theory"
description: |
  What question are decision theorists trying to answer, and why is it worth trying to answer it? A lot of philosophers talk as if the aim of decision theory is to describe how we should make decisions, and the reason to do this is to help us make better decisions. I disagree on both fronts. The aim of the decision theory is to describe how a certain kind of idealised decider does in fact decide. And the reason to do this is that this idealisation, like many other idealisations, helps generate explanations of real-world behaviour. We shouldn't do what these ideal deciders do, or try to be more like them, because a lot of what they do only makes sense because of the differences between us and them. Still, sometimes those differences are small enough that they can be ignored in explanations, and that's when decision theory is useful.
bibliography: ../../brian-quarto.bib
date: February 22 2024
author:
  - name: Brian Weatherson 
    url: http://brian.weatherson.org
    affiliation: University of Michigan
    affiliation_url: https://umich.edu
    orcid_id: 0000-0002-0830-141X
citation: false
categories:
  - games and decisions
  - unpublished
format:
  html: default
  pdf:
    output-file: "The End of Decision Theory"
    include-after-body: 
      text: |
         Unpublished. Posted online in 2024.
    include-in-header: 
      text: |
          \usepackage[english]{babel}
---

# What is Decision Theory a Theory Of?

If you're reading a journal like this, you're probably familiar with seeing papers defending this or that decision theory. Familiar decision theories include:

- Causal Decision Theory [@GibbardHarper1978; @Lewis1981b; @Skyrms1990; @Joyce1999];
- Evidential Decision Theory [@Ahmed2014];
- Benchmark theory [@Wedgwood2013a];
- Risk-Weighted theory [@BuchakRisk];
- Tournament Decision Theory [@Podgorski2022]; and
- Functional Decision Theory [@LevinsteinSoares2020]

Other theories haven't had snappy 'isms' applied to them, such as the non-standard version of Causal Decision Theory that Dmitri @Gallow2020 defends, or the pluralist decision theory that Jack @Spencer2021 defends, or the broadly ratificationist theory that Melissa @Fuscond defends.

This paper isn't going to take sides between these nine or more theories.^[The arguments here are intended to support a theory like Fusco's, but in a fairly roundabout way, but the connection between what I say here and Fusco's theory would take a paper as long as this one to set out.] Rather it is going to ask a prior pair of questions.

1. If these are the possible answers, what is the question? That is, what is the question to which decision theories are possible answers?
2. Why is that an interesting question? What do we gain by answering it?

On 1, I will argue that decision theories are answers to a question about what an ideal decider would do. The 'ideal' here is like the 'ideal' in a scientific idealisation, not the ideal in something like an ideal advisor moral theory. That is, the ideal decider is an idealisation in the sense of being simple, not in the sense of being perfect. The ideal decision maker is ideal in the same way that the point-masses in the ideal gas model are ideal; they are (relatively) simple to work with. The main opponent I have in mind is someone who says that in some sense decision theory tells us what decisions we should make.

On 2, I will argue that the point of asking this question is that these idealisations play important roles in explanatorily useful models of social interactions, such as the model of the used car market that George @Akerlof1970 described. Here, the main opponent I have in mind is someone who says that decision theory is useful because it helps us make better decisions.

There is another pair of answers to this question which is interesting, but which I won't have a lot to say about here. David Lewis held that "central question of decision theory is: which choices are the ones that serve oneâ€™s desires according to one's beliefs?" [@Lewis-Gorman-10071979 472]. That's not far from the view I have, though I'd say it's according to one's evidence. But I differ a bit more from Lewis as to the point of this activity. For him, a central role for decision theory is supplying a theory of constitutive rationality to an account of mental content [@Lewis1994b 321-2]. I think the resulting theory is too idealised to help there, and that's before we get to questions about whether we should accept the approach to mental content that requires constitutive rationality. That said, the view I'm defending is going to be in many ways like Lewis's: the big task of decision theory is describing an idealised system, not yet recommending it.

The nine theories I mentioned above disagree about a lot of things. In philosophy we typically spend our time looking at cases where theories agree. Not here! I will focus almost exclusively on two cases where those nine theories all say the same thing. I'll assume that whatever question they are asking, the correct answer to it in those two cases must agree with all nine theories. That will be enough to defend the view I want to defend, which is that a decision theory is correct iff is true in the right kind of idealisation.

# Three Cases

## Betting

Chooser has \$110, and is in a sports betting shop. There is a basketball game about to start, between two teams they know to be equally matched. Chooser has three options: bet the \$110 on Home, bet it on Away, keep money. If they bet and are right, they win \$100 (plus get the money back they bet), if they are wrong, they lose the money. Given standard assumptions about how much Chooser likes money, all the decision theories I'm discussing say Chooser should not bet.

From this it follows that decision theory is not in the business of answering this question: *What action will produce the best outcome?*. We know, and so does Chooser, that the action that produces the best outcome is to bet on the winning team. Keeping their money in their pocket is the only action they know will be sub-optimal. And it's what decision theory says to do.

This is to say, decision theory is not axiology. It's not a theory of evaluating outcomes, and saying which is best. Axiology is a very important part of philosophy, but it's not what decision theorists are up to.

So far this will probably strike you, dear reader, as obvious. But there's another step, that I think will strike some people as nearly as obvious, that I'm at pains to resist. Some might say that decision theorists don't tell Chooser to bet on the winner because this is lousy advice. Chooser can't bet on the winner, at least not as such. That, I'll argue, would be a misstep. Decision theorists do not restrict themselves to answers that can be practically carried out.

## Salesman

We'll focus on a version of what Julia @Robinson1949 called the travelling salesman problem. Given some points on a map, find the shortest path through them. We'll focus on the 257 cities shown on the map in @fig-map.

```{r}
#| echo: false
#| warning: false
#| message: false 
#| cache: false
#| label: fig-map
#| fig-cap: "257 American cites; we'll try to find the shortest path through them."
require(tidyverse)
require(TSP)
require(maps)

theme_map <- function(base_size=9, base_family="") {
  require(grid)
  theme_bw(base_size = base_size, base_family = base_family) %+replace%
    theme(axis.line = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank(),
          axis.title = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          panel.grid = element_blank(),
          panel.spacing = unit(0, "lines"),
          plot.background = element_blank(),
          legend.justification = c(0,0),
          legend.position = c(0,0)
    )
}

theme_set(theme_map())

all_states <- map_data("state") %>% 
  group_by(region) %>% 
  tally() %>% 
  select(state = region)

all_states$code <- c("AL", "AZ", "AR", "CA", "CO", "CT", "DE", "DC", "FL", "GA",
                     "ID", "IL", "IN", "IA", "KS", "KY", "LA", "ME", "MD", "MA", 
                     "MI", "MN", "MS", "MO", "MT", "NE", "NV", "NH", "NJ", "NM", 
                     "NY", "NC", "ND", "OH", "OK", "OR", "PA", "RI", "SC", "SD", 
                     "TN", "TX", "UT", "VT", "VA", "WA", "WV", "WI", "WY")

used_states <- 1:49

long_states <- all_states$state[used_states]
short_states <- all_states$code[used_states]

data("USCA312")
data("USCA312_GPS")

cities <- as_tibble(as.matrix(USCA312))

city_numbers <- tibble(
  id = 1:312,
  thecities = colnames(cities)
) %>% 
  mutate(used_city = case_when(str_sub(thecities, -2) %in% short_states  ~ 1,
                               TRUE ~ 0))

the_city_numbers <- filter(city_numbers, used_city == 1)$id


our_cities <- cities %>% 
  select(all_of(the_city_numbers)) %>% 
  slice(the_city_numbers)

our_gps <- USCA312_GPS %>% 
  slice(the_city_numbers) %>% 
  rowid_to_column()

city_matrix <- as.matrix(our_cities)

rownames(city_matrix) <- filter(city_numbers, used_city == 1)$thecities

## Fine tour
#tour_line <- solve_TSP(as.TSP(city_matrix), method="farthest_insertion")
#tour_line <- solve_TSP(as.TSP(city_matrix), method="two_opt", tour = tour_line)

## Not good tour
#tour_line <- solve_TSP(as.TSP(city_matrix), method="cheapest_insertion", start = 17) # - Very messy

## Generate tour by longitude - really bad
#tour_line <- TOUR(arrange(our_gps, long)$rowid, tsp = as.TSP(city_matrix))

## Best tour
load("tour_line.RData")

#tour_line <- TOUR(bad_path, tsp = as.TSP(city_matrix))
#tour_line <- solve_TSP(as.TSP(city_matrix), method="two_opt", tour = tour_line)
#tour_length(tour_line)

# Turn tour to map path
paths <- tribble(
  ~step, ~property, ~rowid, ~long, ~lat
)

for (i in 1:nrow(our_gps)){
  x <- tour_line[i]
  first_city <- our_gps %>% slice(x)
  next_city <- our_gps %>% slice(x %% 31)
  paths <- paths %>%
    add_row(step = i, property = "from", rowid = first_city$rowid[1], long = first_city$long[1], lat = first_city$lat[1])# %>%
  #    add_row(step = i, property = "to", rowid = next_city$rowid[1], long = next_city$long[1], lat = next_city$lat[1])
}

x <- tour_line[1]

paths <- paths %>% add_row(step = 24, property = "from", rowid = our_gps$rowid[x], long = our_gps$long[x], lat = our_gps$lat[x])


state_map_data <- map_data("state") %>%
  #  filter(subregion != "north" | is.na(subregion)) %>%
  filter(region %in% long_states) 

tour_map <- ggplot(state_map_data, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", colour = "grey90") + 
  geom_point(data = our_gps %>% select(long, lat), aes(x = long, y = lat), size = 0.25, inherit.aes = FALSE) +
#  geom_path(data = paths %>% select(long, lat), aes(x = long, y = lat), inherit.aes = FALSE, colour = "grey30", alpha = 0.5 ) + 
  coord_quickmap() +
#  labs(x = paste0("Tour length: ", tour_length(tour_line), " miles.")) +
  labs(x = "") +
  theme(axis.title.x = element_text())
#tour_length(tour_line)
tour_map

#str_c(our_gps$name, sep = "; ", collapse = "; ")
```

The task is to find the shortest path through those 257 cities.^[Include citation as to where I got the map, and the packages used in this, and to where I learned some of this stuff about TS problems.]

All nine of the decision theories I mentioned, and as far as I know every competitor to them in the philosophical literature, say the thing to do here is to draw whichever of the 256! possible paths is shortest. That is not particularly helpful advice. Unless you know a lot about problems like this, you can't draw the shortest path through the map. And least, you can't draw it as such. You can't draw it in the way that you can't enter the correct code on a locked phone [@MandelkernEtAl2017].

One of the striking things about this puzzle is that it turns out there are some helpful things that can be said. One helpful bit of advice to someone trying to solve a problem like this is to use a Farthest Insertion Algorithm. Insertion algorithms say to start with a random city, then add cities to the path one at a time, at each time finding the point to insert the city into the existing path that adds the least distance. The Farthest Insertion Algorithm says that the city added at each stage is the one farthest from the existing path. Insertion algorithms in general produce pretty good paths in a very short amount of time - at least on normal computers. And the Farthest Insertion Algorithm is, most of the time, the best Insertion Algorithm to use. @fig-farthest shows the result of one output of this algorithm.^[The algorithm is silent on which city you start with, and usually chooses this randomly.]

```{r}
#| echo: false
#| cache: false
#| warning: false
#| message: false 
#| label: fig-farthest
#| fig-cap: "An output of the Farthest Insertion Algorithm, with a length of 21075 miles"
theme_set(theme_map())
tour_line <- solve_TSP(as.TSP(city_matrix), method = "farthest_insertion", start = 1)

paths <- tribble(
  ~step, ~property, ~rowid, ~long, ~lat
)


for (i in 1:nrow(our_gps)){
  x <- tour_line[i]
  first_city <- our_gps %>% slice(x)
  next_city <- our_gps %>% slice(x %% 31)
  paths <- paths %>%
    add_row(step = i, property = "from", rowid = first_city$rowid[1], long = first_city$long[1], lat = first_city$lat[1])# %>%
  #    add_row(step = i, property = "to", rowid = next_city$rowid[1], long = next_city$long[1], lat = next_city$lat[1])
}

x <- tour_line[1]


paths <- paths %>% add_row(step = 1 + nrow(our_gps), property = "from", rowid = our_gps$rowid[x], long = our_gps$long[x], lat = our_gps$lat[x])

tour_map <- ggplot(state_map_data, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", colour = "grey90") + 
  geom_point(data = our_gps %>% select(long, lat), aes(x = long, y = lat), size = 0.25, inherit.aes = FALSE) +
  geom_path(data = paths %>% select(long, lat), aes(x = long, y = lat), inherit.aes = FALSE, colour = "grey30", alpha = 0.5 ) + 
  coord_quickmap() +
#  labs(x = paste0("Tour length: ", tour_length(tour_line), " miles.")) +
  labs(x = "") +
  theme(axis.title.x = element_text())
tour_map
```

The path in @fig-farthest is not bad, but with only a bit of extra computational work, one can do better. A fairly simple optimisation algorithm takes a map as input, and then deletes pairs of edges at a time, and finds the shortest path of all possible paths with all but those two edges. The process continues until no improvements can be made by deleting two edges at a time, at which point you've found a somewhat resilient local minimum. @fig-two-opt is the output from applying this strategy to the path in @fig-farthest.

```{r}
#| echo: false
#| cache: false
#| label: fig-two-opt
#| fig-cap: "The output of an optimisation process, which reduced the path length to 20891 miles."
#| warning: false
#| message: false 
theme_set(theme_map())
tour_line <- solve_TSP(as.TSP(city_matrix), method = "farthest_insertion", start = 1)
tour_line <- solve_TSP(as.TSP(city_matrix), method = "two_opt", tour = tour_line)

paths <- tribble(
  ~step, ~property, ~rowid, ~long, ~lat
)

for (i in 1:nrow(our_gps)){
  x <- tour_line[i]
  first_city <- our_gps %>% slice(x)
  next_city <- our_gps %>% slice(x %% 31)
  paths <- paths %>%
    add_row(step = i, property = "from", rowid = first_city$rowid[1], long = first_city$long[1], lat = first_city$lat[1])# %>%
  #    add_row(step = i, property = "to", rowid = next_city$rowid[1], long = next_city$long[1], lat = next_city$lat[1])
}

x <- tour_line[1]

paths <- paths %>% add_row(step = 1 + nrow(our_gps), property = "from", rowid = our_gps$rowid[x], long = our_gps$long[x], lat = our_gps$lat[x])


tour_map <- ggplot(state_map_data, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", colour = "grey90") + 
  geom_point(data = our_gps %>% select(long, lat), aes(x = long, y = lat), size = 0.25, inherit.aes = FALSE) +
  geom_path(data = paths %>% select(long, lat), aes(x = long, y = lat), inherit.aes = FALSE, colour = "grey30", alpha = 0.5 ) + 
  coord_quickmap() +
#  labs(x = paste0("Tour length: ", tour_length(tour_line), " miles.")) +
  labs(x = "") +
  theme(axis.title.x = element_text())
tour_map
```

This optimisation tends to produce paths that look a lot like the original, but are somewhat shorter. For most practical purposes, the best advice you could give someone faced with a problem like this is to use a Farthest Insertion Algorithm, then optimise it in this way. Or, if they have a bit more time, they could do this a dozen or so times, and see if different starting cities led to slightly shorter paths.

While this is good advice, and indeed it's what most people should do, it's not typically what is optimal to do. For that reason, it's not what our nine decision theories would say to do. If one had unlimited and free computing power available, hacks like these would be pointless. One would simply look at all the possible paths, and see which was shortest. I do not have free, unlimited computing power, so I didn't do this. Using some black box algorithms I did not particularly understand, I was able to find a shorter path, however. It took some time, both of mine and my computer's, and for most purposes it would not have been worth the hassle of finding it. Still, just to show it exists, I've plotted it as @fig-best.


```{r}
#| echo: false
#| cache: false
#| label: fig-best
#| warning: false
#| message: false
#| fig-cap: "The shortest path I could find, with a distance of 20301 miles."
my_list <- as.integer(unlist(strsplit("0,84,59,240,13,198,121,58,102,89,170,20,212,135,231,127,136,107,147,17,151,97,24,142,162,228,87,229,194,206,116,138,244,158,61,108,207,44,54,11,132,9,55,143,26,86,103,47,117,7,96,216,46,251,95,184,69,179,250,174,153,183,242,15,99,119,110,181,248,4,249,164,10,234,71,148,109,152,161,246,222,42,33,150,137,149,100,219,252,175,78,34,30,38,123,130,134,57,173,171,12,16,144,36,32,168,235,2,208,239,25,226,186,35,74,254,167,223,245,39,1,51,256,45,8,56,221,60,98,50,124,129,31,146,159,77,230,118,104,145,83,125,232,6,65,81,19,189,120,106,18,92,112,215,90,49,115,178,139,210,94,133,187,163,28,43,238,62,218,192,53,220,111,82,237,156,73,247,196,233,113,114,191,126,157,213,214,64,243,41,105,67,185,70,225,68,193,140,190,79,141,27,166,180,211,23,93,101,37,169,155,197,176,29,217,241,253,21,209,227,172,195,75,76,22,154,201,204,202,224,188,182,40,85,14,203,128,160,199,200,255,122,80,165,236,72,205,3,88,91,48,63,52,177,66,5,131",",")))
my_list_adj <- my_list + 1
tour_line <- TOUR(my_list_adj, tsp = as.TSP(city_matrix))

theme_set(theme_map())

paths <- tribble(
  ~step, ~property, ~rowid, ~long, ~lat
)

for (i in 1:nrow(our_gps)){
  x <- tour_line[i]
  first_city <- our_gps %>% slice(x)
  next_city <- our_gps %>% slice(x %% 31)
  paths <- paths %>%
    add_row(step = i, property = "from", rowid = first_city$rowid[1], long = first_city$long[1], lat = first_city$lat[1])# %>%
  #    add_row(step = i, property = "to", rowid = next_city$rowid[1], long = next_city$long[1], lat = next_city$lat[1])
}

x <- tour_line[1]

paths <- paths %>% add_row(step = 1 + nrow(our_gps), property = "from", rowid = our_gps$rowid[x], long = our_gps$long[x], lat = our_gps$lat[x])


tour_map <- ggplot(state_map_data, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", colour = "grey90") + 
  geom_point(data = our_gps %>% select(long, lat), aes(x = long, y = lat), size = 0.25, inherit.aes = FALSE) +
  geom_path(data = paths %>% select(long, lat), aes(x = long, y = lat), inherit.aes = FALSE, colour = "grey30", alpha = 0.5 ) + 
  coord_quickmap() +
#  labs(x = paste0("Tour length: ", tour_length(tour_line), " miles.")) +
  labs(x = "") +
  theme(axis.title.x = element_text())
tour_map

```

I'm not sure if @fig-best is as short as possible, but I couldn't find a shorter one. Still, unless those 200 miles really make a difference, it wouldn't have been worth the trouble it took to find this map.

## The Two Cases

Let's summarise these two cases in a table.

|                 |    Betting    |     Salesman     |
|-----------------|:-------------:|:----------------:|
| Best outcome    | Bet on winner |  Shortest path   |
| Decision theory |     Pass      |  Shortest path   |
| Best advice     |     Pass      | Learn algorithms |

The first row says which action would produce the best outcome in the two cases. The third row says what advice one ought give someone who had to choose in the two cases. And the middle row says what all the decision theories say about the two cases. Notably, it agrees with neither the first nor third row. Decision theory is neither in the business of saying what will produce the best result, nor with giving the most useful advice. So what is it doing?

# Decision Theory as Idealisation

Imagine a version of Chooser with, as Rousseau might have put it, their knowledge as it is, and their computational powers as they might be. That is, a version of Chooser who has unlimited, and free, computational powers, but no more knowledge of the world than the actually have - save what they learn by performing deductions from their existing knowledge.

Decision theories describe what that version of Chooser would do in the problem that Chooser is facing. In the betting case, adding unlimited computing power doesn't tell you who is going to win the game. So that version of Chooser will still avoid betting. But in the Salesman case, adding unlimited computing power is enough to solve the problem. They don't even have to use any fancy techniques. To find the shortest path, all it takes is finding the length of each path, and sorting the results. The first requires nothing more that addition; at least if, as was the case here, we provided the computer with the distances between any pairs of cities as input. The second just requires being able to do a bubble sort, which is technically extremely simple. To be sure, doing all these additions, then doing a bubble sort on the results, will take longer than most human lives on the kinds of computers most people have available to them. But a version of Chooser with unlimited, free, computational power will do these computations no problem at all.

If we say that Chooser should maximise expected utility, and we expect them to compute that, then we're asking Chooser to perform a task that is one step harder than calculating the shortest path in a Salesman problem. To calculate an expected utility, for each option one looks up a probability and a utility for each state^[Exactly which probability it is, or indeed whether it even strictly is a probability, varies by which theory one chooses. But the basic idea that Chooser multiples something probability like by a utility is common across theories], multiplies the two together, then adds the results to get a value for the option. One repeats that for each state, and finds an extreme value. Calculating the shortest path is exactly the same, except one only has to look up one number (a distance) rather than two (a probability and a utility), and there is no multiplication. Solving for the shortest path is strictly easier than finding the maximum expected utility. And yet finding the shortest path is practically impossible.

This is one reason I focussed on Salesman problems rather than other mathematical claims that Chooser is, in the standard models, assumed to know. I didn't ask Chooser to bet on the Twin Primes conjecture. It's possible one could come up with a model where finding the maximum expected utility is typically possible but resolving the Twin Primes conjecture is not; it's really hard to see how an agent who could always calculate expected utilities couldn't solve a Salesman problem.

There are two other things that are distinctively interesting about this problem which I'll simply note here, and defer longer discussion of them to another day. First, it is possible to give practical useful advice about how to solve Salesman problems. I've repeated some of the better advice I've heard in the previous section. Second, when someone follows this advice and does badly, as can happen with carefully designed maps, it seems they are unlucky in just the same way that someone who maximises expected utility but gets a low amount of actual utility is unlucky. This raises some interesting questions about the normative significance of expected utility maximisation that will be in the background of the rest of the discussion here; hopefully I'll return to them in later work.

At this point you might complain that I've talked about decision theories asking Chooser to *calculate* expected utilities. They do no such thing. This is a point that Frank Knight made a century ago.

> Let us take Marshall's example of a boy gathering and eating berries ... We can hardly suppose that the boy goes through such mental operations as drawing curves or making estimates of utility and disutility scales. [@Knight1921 66-7]

And Knight does not say this is irrational. As long as the boy gets enough berries, he's doing fine. In more modern terminology, we might say that describing 

## Technical Detour

Most philosophical decision theory concerns decisions under uncertainty, not decisions like Salesman that are made under certainty.
<!--
-   But the structure is still the same.

## Technical Detour

They say that for each option, you should loop through the possible states of the world, in each case multiplying something (usually a probability) by something else (usually a utility), and then summing the results. Then you choose the maximum.

-   That's exactly the same technical task as solving Salesman by brute force.[^the_end_of_decision_theory-2]

[^the_end_of_decision_theory-2]: Actually one step harder because of the multiplication, but otherwise the same.

## Summary

Decision theory describes what a particular kind of idealised agent **will** do.

- I've bolded **will** because it's going to turn out that's the important modal to use here; as opposed to *should*.
- If there is any normativity here, it's in the **idealised** part of that sentence, not the modal.

# Idealisations as Life Goals

## A Modest Proposal

Decision theory is relevant to how we should act because:

1. It tells us that idealised people do use decision theory, and
2. We should try to be like idealised people.
C.  We should try to use decision theory. 

---

![I think this stands for What Would Jeffrey Do?](bracelet.jpg)

## First Objection - Knowing the Inputs

To use decision theory as a guide to action, I need to know the utility of the possible states. 

- Knowing ordering isn't enough, need cardinality of each utility.
- I can only ever tell that the utility of A is half way between that of B and C by thinking about whether A is better or worse to take than a 50/50 bet on B or C.
- I need to make decisions to get the inputs to decision theory.
- And I think this is the usual case.

## Second Objection - The General Theory of the Second Best

In general, it's not true that one should try to approximate what the ideal is like.

---

![_The General Theory of the Second Best_, by R. G. Lipsey and Kelvin Lancaster, The Review of Economic Studies, 1956](lipsey.png)

This is one of the most philosophically important economics papers ever published.

## Second Best

Often times, the right thing to do is something whose value consists in mitigating the costs of our other flaws.

- We should, especially in high stakes settings, stop and have a little think before acting.
- The "ideal agent" of decision theory never stops to have a think.
- Stopping is costly, and **they** don't gain anything from it.

## Second Best

- The ideal agent does lots of things we don't do.
- They always take reasonable hedges against costly possibilities, and they never stop to have a think.
- Knowing that the ideal agent is *F* doesn't tell us whether we should try to be *F* unless we also know that *F* is more like the first of these than the second.
- And decision theory, in **anything like its current form**, is not particularly helpful on this score.

## Third Objection - The Yoda Objection

Decision theory doesn't say what one should try or not try, it says what one should do.

- So it's weird to infer something about trying from a theory about doing.

## Yoda

I think there's something importantly right about this - decision theory gives criteria of correctness not methods of deliberation - but that in turn shows us why it might be useful.


# Idealisations as Models

## Two Notions of Idealisation

In philosophy we use the word 'idealisation' for two rather different kinds of thing.

1. Perfect
2. Simple

The point particles in ideal gas theory are not perfect - having volume is not an imperfection. 

Nor are they things to aim for - high school chemistry does not imply a rule: **Smaller the better**.

But they are simple.

## Idealisations in Decision Theory

Decision theory provides idealisations in the second sense - they are **simplifications**.

- Just like the point masses we use in the ideal gas law, they say not what should happen, but what would happen in the absence of certain complications.

## Idealisations in Decision Theory

Why do I say this idealisation is a simplification not a perfection?

1. Allocating zero seconds to hard math problems is not a perfection.
2. The idealised self isn't  absolutely perfect - they have very restricted information.

## Idealisations in Decision Theory

The idealised self that gets used is god-like in one respect - computational ability - but human-like in another - informational awareness.

- That's a common feature of idealised models.
- You abstract away from one feature, but not others.

## Why Care?

That's what we do, but why do we do it?

- Because sometimes these models are enlightening.
- Sometimes, the fact that we have computational limitations is not relevant to predicting/explaining/understanding what we will do.

## Really, Why Care?

It's tempting to identify these with high stakes situations, since those are ones where we'll throw enough computational resources at the problem that we have god-like powers.

- But that isn't quite right.
- In some high stakes cases, we also throw enough investigative resources at the problem that holding actual knowledge fixed is a bad modelling assumption.

## Informational Limitations

What we need are cases where there are principled limitations to our informational capacities, such as,

1. Cases where the information concerns the future; or 
2. Cases where someone has (or may have) just as strong an incentive to hide information from us.

I'll end with a discussion of an important instance of the second.^[Photo of George Akerlof on next slide by Yan Chi Vinci Chow.]

## Akerlof on Lemons

::: {.columns}

:::: {.column width=35%}

![](akerlof.jpg){width=80% height=80%}

::::

:::: {.column width=65%}

![](lemon.jpg){width=71% height=71%}

::::

:::

## Akerlof on Lemons

::: {.columns}

:::: {.column width=35%}

![](akerlof.jpg){width=80% height=80%}

::::

:::: {.column width=65%}

![](lemon_car.jpg){width=80% height=80%}

::::

:::

## A 20th Century Puzzle

Used cars sold at a huge discount to new cars, even when the cars were just a few months old with almost no usage.

- There was no agreed upon explanation for this, with the most common theory being that it reflected a preference/prejudice on the part of buyers.

## Akerlof's Theory

Make the following assumptions.

1. Cars vary a lot in quality, even coming from the same production line.
2. Sellers of used cars know how good this token car is.
3. Buyers of used cars do not; they only know how good the model is in general.
4. People rarely sell cars they just bought.
5. Everyone involved is an expected utility maximiser.

## Akerlof's Theory

Akerlof built a formal model with the following properties.

- The most common reason to sell a car one just bought is the discovery that it was a bad instance of that kind of car.
- Knowing this, buyers of used cars demanded a big discount in exchange for the possibility they were buying a dud.
- Everyone is acting rationally within the model, given their asymmetric information.

## Akerlof's Theory

If he was right (and I basically think he was) you'd expect the used car discount to fall if either of the following things happened.

1. Production lines got more reliable, and cars off the same line were more similar to one another; or
2. Buyers had access to better tools to judge the quality of used cars.

By 2020 both of those things had happened, and the used car discount was almost zero. (Then in 2021 it went negative for weird reasons.)

## Back To Philosophy

You can't build models like this without a theory of rational action under uncertainty.

- And that's the payoff of philosophical decision theory.
- It's an essential input to useful models, like this one.

## Consequences for Decision Theory

The thing about explanatory models is that they can have very limited scope.

- There are lots of properties of gases that you cannot explain with the ideal gas model.

## Consequences for Decision Theory

This matters because a lot of people in decision theory assume that a good decision theory will have something to say about every possible choice situation.

- But if you're in the business of explanation, it's fine to say that the theory only applies in some cases, and it only provides explanations in those cases.

## Consequences for Decision Theory

There are (at least) two interesting notions around here:

1. What the ideal decider would do in a particular situation.
2. What it would be advisable for a real life human to do in this situation.

- These come apart in Travelling Salesman cases, and we should keep open the possibility that they also come apart in cases that philosophers talk about.

## For Another Day

At this point you might expect that I'd have a theory that does go silent on a bunch of hard cases, and which explains away a bunch of intuitions about cases as intuitions about advisability, not about what an ideal decider does, and you'd be right on both counts.

- And I'm happy to talk about that theory (and those cases) at literally any length people want.
- But it's mostly for another talk.

## For Yet Another Day

You might also wonder at this point whether there are other idealisations we could make, which are useful in different circumstances to the standard computationally perfect, informationally limited model.

- I used to think the answer was no on broadly a priori grounds.
- But this was wrong, and the work on cursed equilibrium shows it was wrong.
- There are some potentially really interesting questions here for philosophy of economics that engages seriously with 21st century economics.

## Conclusions

- Decision theory provides idealisations.
- These are not things we should aim for, but simplifications that play a role in explanations.
-->