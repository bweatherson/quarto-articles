---
title: "When are Philosophy Articles Cited?"
draft: true
abstract: |
  It's natural to believe that philosophy citations are typically to long ago pieces. We're still talking about philosophers from millenia ago. More strikingly, we're still talking about papers from half a century ago not as historical papers, but as part of the contemporary debate. But a systematic look at the citation data shows that these cases are outliers. Most citations are to recently published works. Surprisingly, this is less true in recent years than it used to be. The effect of electronic publishing and communication has been to make citations, on average, older. After we adjust for the typical age of philosophy citations, and this changing trend, it turns out that the 2000s were a particularly influential time in philosophy publishing. Articles published in that decade are cited more than earlier or later articles, once we adjust for the typical times articles are cited, and the changing patterns of citation. This is arguably related to broad changes in the interests of philosophers, towards social philosophy, and epistemology.
execute:
  echo: false
  warning: false
date: today
bibliography: 
 - /Users/weath/Documents/quarto-articles/brian-quarto.bib
 - /Users/weath/Documents/citations-2025/autobib.bib
number-sections: true
keep-tex: true
ergo:
  volume: "TBC"
  issue: "TBC"
  year: "2025"
  doi: "https://doi.org/TBC"
  startpage: 1
crossref:
  custom:
    - kind: float
      key: apptbl
      latex-env: apptbl
      reference-prefix: Table A
      space-before-numbering: false
author:
  - name: "Anon"
    affiliation: "Anon Institution"
    email: "anon@institution.edu"
categories:
  - history of analytic
  - old version
  - for submission
format:
  html:
    fig-format: png
    fig-width: 10
    fig-height: 7
  docx: default
  pdf: 
    pdf-engine: pdflatex
    documentclass: ergoclass
    geometry: "twoside=true, 
               headsep=.25in, 
               headheight=1in, 
               footskip=.35in, 
               paperwidth=7in,
               paperheight=10in, 
               top=1in, 
               bottom=1in, 
               inner=.8in, 
               outer=.8in"
    fontfamily: mathpazo  # This tells Quarto to use mathpazo instead of lmodern
    template-partials:
      - before-body.tex
      - title.tex
    include-in-header:
      file: preamble.tex
    include-after-body: 
        text: |
          \noindent 
          
          \noindent Draft for submission
    cite-method: natbib
    biblio-style: "apalike"
    output-file: "When are Philosophy Articles Cited.pdf"
---


```{r}
#| label: loader
#| cache: false

require(tidyverse)
require(slider)
require(stringr)
require(knitr)
require(lsa)
require(wesanderson)

load("/Users/weath/Documents/citations-2025/philo_bib_through_2024.RData")
load("/Users/weath/Documents/citations-2025/philo_cite_through_2024.RData")
load("/Users/weath/Documents/articles/apc/active_journal_list.RData")

if(knitr::is_latex_output()) {
  knitr::opts_chunk$set(dev = 'cairo_pdf')
}

# Graph Themes
old <- theme_set(theme_minimal())
theme_set(old)
theme_update(plot.title = element_text(family = "Scala Pro", size = 24, face = "bold"),
             plot.subtitle = element_text(family = "Scala Sans Pro", size = 30),
             axis.text = element_text(family = "Scala Sans Pro", size = 18),
             title = element_text(family = "Scala Sans Pro", size = 18),
             plot.background = element_rect(fill = "#F9FFFF"),
             panel.background = element_rect(fill = "white"),
             legend.background = element_rect(fill = "#F9FFFF"),
             panel.grid = element_line(color = "grey92"),
             legend.text = element_text(family = "Scala Sans Pro", size = 20),
             strip.text = element_text(family = "Scala Sans Pro", size = 20),
             legend.key.spacing.y = unit(0.5, 'lines'),
             legend.key.spacing.x = unit(1, 'cm')
  )

if(knitr::is_latex_output()) {
theme_update(axis.title = element_text(family = "Palatino", size = 11),
             plot.title = element_text(family = "Palatino", face = "bold", size = 14),
             plot.subtitle = element_text(family = "Palatino", size = 11),
             axis.text = element_text(family = "Palatino", size = 10),
             plot.background = element_rect(fill = "white"),
             panel.background = element_rect(fill = "white"),
             legend.background = element_rect(fill = "white"),
             panel.grid = element_line(color = "grey92"),
             legend.text = element_text(family = "Palatino", size = 11),
             strip.text = element_text(family = "Palatino", size = 12),
             legend.key.spacing.y = unit(-0.3, 'lines'),
             legend.key.spacing.x = unit(0, 'cm')
  )
}
```

```{r}
#| label: buildgraphs
#| cache: true

start_year <- 1956
end_year <- 2024
min_data <- 5

# New attempt
# Two categories: available and typical
# Available means published before citing article
# Typical means published 3-10 years before citing article
# The 3 is because weird things have happened with recent cites in recent years

typical_low <- 3
typical_high <- 10

# This sets the color for one-color graphs

point_col <- wes_palette("AsteroidCity1")[3]

active_philo_bib <- philo_bib_through_2024 |>
  filter(year >= start_year, year <= end_year)

active_philo_cite <- philo_cite_through_2024 |>
  filter(
    id %in% active_philo_bib$id,
    refs %in% active_philo_bib$id
  )

citation_tibble <- active_philo_cite |>
  as_tibble() |>
  rename(new = id, old = refs) |>
  left_join(active_philo_bib |>
            select(id, year), 
            by = c("old" = "id")) |>
  rename(old_year = year)  |>
  left_join(active_philo_bib |>
            select(id, year), by = c("new" = "id")) |>
  rename(new_year = year) |>
  filter(old_year >= start_year,
         new_year <= end_year,
         old_year >= start_year,
         new_year <= end_year)

# Find the highly cited articles, and count their citations separately

high_threshold <- 15

highly_cited <- citation_tibble |>
  group_by(old) |>
  tally(name = "citations") |>
  filter(citations >= high_threshold) |>
  rename(id = old)

highly_cited_per_year <- active_philo_bib |>
  filter(id %in% highly_cited$id) |>
  group_by(year) |>
  tally(name = "high_articles") 

# Now a tibble of how many times articles in year x are cited in year y

year_in_year_out <- citation_tibble |>
  filter(old_year >= 1956) |>
  group_by(old_year, new_year) |>
  tally(name = "citations") |> # Now add the 'missing' pairs
  ungroup() |>
  complete(old_year, new_year, fill = list(citations = 0)) |>
  left_join(citation_tibble |>
              group_by(old) |>
              filter(n() >= high_threshold) |>
              group_by(old_year, new_year) |>
              tally(name = "high_citations") |> # Now add the 'missing' pairs
              ungroup() |>
              complete(old_year, new_year, fill = list(high_citations = 0)),
            by = c("old_year", "new_year")) |>
  replace_na(list(high_citations = 0)) |>
  mutate(low_citations = citations - high_citations)

# This works out how many citations there are each year to 3-10 year old articles

citations_in_typical_year <- year_in_year_out |>
  mutate(age = new_year - old_year) |>
  filter(age >= typical_low, age <= typical_high) |>
  group_by(new_year) |>
  summarise(typical_citations = sum(citations)) 

# I'm going to count the 'typical' articles as those published between 3 and 10 years before the citing year
# The 'available' articles are those published before the time

# Tibble for number of publications each year, and cumulative, or 'available'

articles_per_year <- active_philo_bib |>
  rename(old_year = year) |>
  group_by(old_year) |>
  tally(name = "articles") |>
  mutate(available = cumsum(articles)) |>
  mutate(typical_articles = slide_dbl(articles, sum, .before  = typical_high) - slide_dbl(articles, sum, .before = typical_low - 1)) |>
  filter(old_year >= 1956) |>
  left_join(highly_cited_per_year, by = c("old_year" = "year")) |>
  mutate(low_articles = articles - high_articles)

articles_per_year_plot <- articles_per_year |>
  ggplot(aes(x = old_year, y = articles)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Number of indexed articles")

typical_plot <- articles_per_year |>
  ggplot(aes(x = old_year, y = typical_articles)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Number of typical indexed articles")

# Same for citations

all_citations_per_year <- citation_tibble |>
  group_by(new_year) |>
  tally(name = "citations") 

all_citations_per_year_plot <- all_citations_per_year |>
  ggplot(aes(x = new_year, y = citations)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Citations to indexed articles")

typical_citations_per_year <- citation_tibble |>
  filter(new_year >= old_year + typical_low, new_year <= old_year + typical_high) |>
  group_by(new_year) |>
  tally(name = "citations") 

typical_citations_per_year_plot <- typical_citations_per_year |>
  ggplot(aes(x = new_year, y = citations)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Citations to indexed articles from typical years")


# Outbound citations

outbound_citations <- left_join(
  articles_per_year,
  all_citations_per_year,
  by = c("old_year" = "new_year")
) |>
  mutate(outbound_rate = citations/articles) |>
  mutate(outbound = round(outbound_rate, 2))

outbound_citations_plot <- outbound_citations |>
  filter(old_year != 1955) |>
  ggplot(aes(x = old_year, y = outbound)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Outbound citations per indexed articles")

# Citations per typical article

typical_citation_rate_per_year <- typical_citations_per_year |>
  left_join(articles_per_year, by = c("new_year" = "old_year")) |>
  #filter(new_year >= start_year + typical_high) |>
  left_join(citations_in_typical_year, by = "new_year") |>
  mutate(mean_cites = typical_citations/typical_articles)

typical_citation_rate_per_year_plot <- typical_citation_rate_per_year |>
  ggplot(aes(x = new_year, y = mean_cites)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Annual citation rate of typical articles.")

# All citations to typical articles in a year
ct_all <- citation_tibble |>
  filter(new_year >= old_year + typical_low, new_year <= old_year + typical_high) |>
  group_by(new_year) |>
  tally(name = "typical_citations")

age_effect_tibble <- year_in_year_out |>
  filter(old_year >= start_year, old_year <= end_year + 1 - min_data, new_year >= start_year + typical_high) |>
  filter(new_year >= old_year) |>
  left_join(
    select(
      articles_per_year, 
      old_year, 
      articles,
      high_articles,
      low_articles), 
    by = "old_year") |>
  left_join(
    select(
      articles_per_year, 
      old_year, 
      typical_articles), 
    by = c("new_year" = "old_year")) |>
  left_join(ct_all, by = "new_year") |> 
  mutate(age = new_year - old_year) |>
  mutate(cite_ratio = (citations/articles)/(typical_citations/typical_articles)) |>
  mutate(high_cite_ratio = (high_citations/high_articles)/(typical_citations/typical_articles))  |>
  mutate(low_cite_ratio = (low_citations/low_articles)/(typical_citations/typical_articles)) 

age_effect_tibble_plot <- age_effect_tibble |>
  filter(old_year >= start_year + 1, old_year <= end_year - min_data, new_year >= start_year) |>
  ggplot(aes(x = new_year, y = cite_ratio)) +
  geom_point(size = 0.25, color = point_col) +
  facet_wrap(~old_year, ncol = 6) +
  xlab(element_blank()) +
  ylab(element_blank()) +
  theme(axis.text = element_text(size = 10),
        strip.text = element_text(size = 12))

age_effect_grouped <- age_effect_tibble |>
  filter(new_year >= old_year) |>
  filter(new_year <= old_year + end_year - start_year + 1 - min_data) |>
  mutate(age = new_year - old_year) |>
  group_by(age) |>
  summarise(mean_effect = mean(cite_ratio),
            high_mean_effect = mean(high_cite_ratio),
            low_mean_effect = mean(low_cite_ratio))

age_effect_tibble_adj <- age_effect_tibble |>
  mutate(age = new_year - old_year) |>
  filter(age <= end_year - start_year - min_data) |>
  left_join(age_effect_grouped, by = "age")

age_effect_grouped_plot <- age_effect_grouped |>
  ggplot(aes(x = age, y = mean_effect)) +
  geom_point() +
  xlab("Article age") +
  ylab("Mean citation ratio")

year_by_year_with_effect <- year_in_year_out |>
  filter(new_year >= old_year) |>
  filter(new_year <= end_year) |>
  filter(old_year >= start_year, old_year <= end_year - min_data + 1, new_year >= start_year + typical_high) |>
  mutate(age = new_year - old_year) |>
  filter(age <= end_year - start_year - min_data) |>
  left_join(age_effect_grouped, by = "age") |>
  left_join(
    select(
      age_effect_tibble, old_year, new_year, cite_ratio
    ), by = c("old_year", "new_year")
  ) |>
  mutate(surplus = cite_ratio - mean_effect) |>
  arrange(-surplus)

# The next one calculates the difference between each year and the average. 
# But this has odd effects at the periphery, and compares each year to something it is part of.
# Below, in yiyo_extended, I try to work out what happens when each year is compared to the other years
# This is more work because you have to calculate the 'other years' value again each time

year_by_year_average <- year_by_year_with_effect |>
#  filter(age <= 7) |>
#  filter(old_year != 1973) |>
  group_by(old_year) |>
  summarise(mean_surplus = mean(surplus))

year_by_year_average_plot <- year_by_year_average |>
  mutate(rolling = slide_mean(mean_surplus, before = 4, after = 4)) |>
  ggplot(aes(x = old_year, y = mean_surplus)) +
  geom_line(
    aes(x = old_year, y = rolling),
    linewidth = 0.5,
    alpha = 0.5,
    color = point_col
  ) +
  geom_point(color = point_col)  +
  xlab(element_blank()) +
  scale_x_continuous(breaks = (98:100)*20) +
  ylab("Mean annual citations above average") +
  scale_y_continuous(labels = scales::percent)

year_by_year_average_plot_short <- year_by_year_with_effect |>
  filter(age <= 7) |>
  filter(old_year >= 1975) |>
  group_by(old_year) |>
  summarise(mean_surplus = mean(surplus)) |>
  mutate(rolling = slide_mean(mean_surplus, before = 4, after = 4)) |>
  ggplot(aes(x = old_year, y = mean_surplus)) +
  geom_point(color = point_col)  +
  geom_line(
    aes(x = old_year, y = rolling),
    linewidth = 0.5,
    alpha = 0.5,
    color = point_col
  ) +
  xlab(element_blank()) +
  scale_x_continuous(breaks = (98:100)*20) +
  ylab("Mean annual citations above average") +
  scale_y_continuous(labels = scales::percent)

year_by_year_average_plot_long<- year_by_year_with_effect |>
  filter(age > 7) |>
  filter(old_year >= 1975) |>
  group_by(old_year) |>
  summarise(mean_surplus = mean(surplus)) |>
  mutate(rolling = slide_mean(mean_surplus, before = 4, after = 4)) |>
  ggplot(aes(x = old_year, y = mean_surplus)) +
  geom_point(color = point_col)  +
  geom_line(
    aes(x = old_year, y = rolling),
    linewidth = 0.5,
    alpha = 0.5,
    color = point_col
  ) +
  xlab(element_blank()) +
  scale_x_continuous(breaks = (98:100)*20) +
  ylab("Mean annual citations above average") +
  scale_y_continuous(labels = scales::percent)

#print(year_by_year_average_plot)

effect_by_age_average <- function(early, late){
  age_effect_tibble |>
    filter(age >= early, age <= late) |>
    #    add_count(old_year, name = "data_points") |>
    #    filter(data_points >= min_data) |>
    group_by(old_year) |>
    summarise(mean_ratio = mean(cite_ratio)) |>
    ggplot(aes(x = old_year, y = mean_ratio)) +
    geom_point() +
    geom_smooth() +
    xlab(element_blank()) +
    ylab(element_blank()) +
    labs(title = case_when(
      early == late ~ paste0("Citation ratio at age ", early),
      TRUE ~ paste0("Mean citation ratio from ages ",early," to ",late)))
}

effect_by_age_facet <- function(early, late){age_effect_tibble |>
    filter(age>= early, age <= late) |>
    ggplot(aes(x = old_year, y = cite_ratio)) +
    geom_point() + geom_smooth() +
    facet_wrap(~age, ncol = 4)
}

year_to_mean_plot <- function(the_year){
  age_effect_tibble_adj |>
    filter(old_year == the_year) |>
    ggplot(aes(x = age, y = cite_ratio)) +
    geom_point(size = 2, alpha = 1, color = hcl(h = (the_year-1975)*(360/43)+15, l = 65, c = 100)) +
    # geom_jitter(aes(size=(old_year==2008 | old_year == 1985), shape = (old_year==2008)), alpha = 1) +
    #  geom_jitter(aes(size=(old_year %in% c(1978, 1980, 1985, 1987)), alpha = 1)) +
    # scale_size_manual(values=c(0.3,2)) +
    xlab("Age of cited articles") +
    ylab("Citation ratio") +
    geom_line(aes(x = age, y = mean_effect), color = point_col) +
    geom_point(aes(x = age, y = mean_effect), color = point_col, size = 0.4) +
    theme(legend.position = "none")
}

```

```{r}
#| label: calculate-variables

citations_1956 <- scales::label_comma()(
  filter(all_citations_per_year, new_year == 1956)$citations)
citations_2024 <- scales::label_comma()(
  filter(all_citations_per_year, new_year == 2024)$citations)

number_of_articles <- scales::label_comma()(nrow(active_philo_bib))
number_of_citations <- scales::label_comma()(nrow(active_philo_cite))

synthese_2021 <- scales::label_comma()(
  nrow(
    filter(
      active_philo_bib,
      year == 2021,
      journal == "Synthese"
    )
  )
)
synthese_2022 <- scales::label_comma()(
  nrow(
    filter(
      active_philo_bib,
      year == 2022,
      journal == "Synthese"
    )
  )
)
```

# Introduction {#sec-introduction}

This paper examines citation patterns of philosophy journal articles. Philosophy journals obviously cite more than just other philosophy journals, and philosophy articles get cited beyond journals. But examining journal-to-journal citations provides a relatively complete dataset for systematic generalization about how articles are cited over time. Some of these generalizations are surprising.

Before examining the data, I held two beliefs about philosophy citations. First, philosophers cite very old papers. We still regularly teach papers over half a century old in introductory classes: @WOSA1969Y444700002, @WOSA1971Y116900003, @WOSA1972Z066400001, and @10.2307_2025310. These aren't taught as history but as contributions to contemporary debate. I thought this pattern extended to less famous papers. Second, technological changes of the last quarter century were reversing this practice. Innovations—email, preprint archives (arXiv, SSRN, PhilPapers), and official preprints like EarlyView—made it easier to cite newer works. The delay between publication and wide recognition was removed, so citations should be getting younger.

Both beliefs were wrong.

On the first point, my generalization from famous papers was mistaken. Normal papers differ from famous ones not just in citation frequency but in citation patterns. The main evidence is the _citation ratio_, which measures how often articles from year _o_ (old) are cited in year _n_, adjusted for total citations in year _n_. (Full explanation in @sec-age.) @fig-master-citation-ratio shows average citation ratios for different citation _ages_—years between _o_ and _n_.^[The graph includes jitter for visibility. Each decade of publication has a different color (broken out in @fig-decades-cite-ratio). The graph starts in 1975 because earlier data is noisier, for reasons discussed below.]

```{r}
#| label: fig-master-citation-ratio
#| fig-cap: "Age effects from 1975 onwards, with overall average shown."

age_effect_post_1975 <- year_in_year_out |>
  filter(old_year >= 1975,
         new_year >= old_year) |>
  left_join(
    select(
      articles_per_year, 
      old_year, 
      articles,
      high_articles,
      low_articles), 
    by = "old_year") |>
  left_join(
    select(
      articles_per_year, 
      old_year, 
      typical_articles), 
    by = c("new_year" = "old_year")) |>
  left_join(ct_all, by = "new_year") |> 
  mutate(
    age = new_year - old_year,
    cite_ratio = (citations/articles)/(typical_citations/typical_articles),
    high_cite_ratio = (high_citations/high_articles)/
      (typical_citations/typical_articles),
    low_cite_ratio = (low_citations/low_articles)/
      (typical_citations/typical_articles)) |>
  ungroup() |>
  group_by(new_year - old_year) |>
  mutate(
    mean_cite_ratio = mean(cite_ratio),
    mean_high_cite_ratio = mean(high_cite_ratio),
    mean_low_cite_ratio = mean(low_cite_ratio)
  ) |>
  ungroup() |>
  mutate(decade = paste0(
    floor((old_year-5)/10),
    "5-",
    floor((old_year-5)/10)+1,
    "4"
  ))

ggplot(age_effect_post_1975, aes(x = new_year - old_year, 
                                 y = cite_ratio,
                                 color = decade)) +
  geom_jitter(size = 0.5, alpha = 0.7) +
  xlab("Age of cited articles") +
  ylab("Citation ratio") +
  geom_line(aes(x = age, y = mean_cite_ratio), color = point_col) +
  labs(color = element_blank()) +
  theme(legend.position = "none")
```

Each dot represents a citation ratio for a year pair; the line shows the average for each age. The pattern is clear: articles are cited far more when young than when old.

My initial 'evidence' wasn't entirely wrong. Redoing @fig-master-citation-ratio for articles with 15+ citations yields @fig-ageeffecteverything-high. (This captures a small percentage of articles but a substantial percentage of citations.)

```{r}
#| label: fig-ageeffecteverything-high
#| fig-cap: "Citation ratios for highly cited articles"

ggplot(age_effect_post_1975, aes(x = new_year - old_year, 
                                 y = high_cite_ratio,
                                 color = decade)) +
  geom_jitter(size = 0.5, alpha = 0.7) +
  xlab("Age of cited articles") +
  ylab("Citation ratio") +
  geom_line(aes(x = age, y = mean_high_cite_ratio), color = point_col) +
  labs(color = element_blank()) +
  theme(legend.position = "none")
```

The y-axis values in @fig-ageeffecteverything-high are higher than in @fig-master-citation-ratio—unsurprisingly, highly cited articles get cited more frequently. What's striking is the shape difference. Typical articles, if cited at all, are cited soon after publication then fade. Highly cited articles continue being cited decades later.

These results aren't obvious—things could have differed. Some articles were ignored initially but accumulated five to ten citations decades later. Others were frequently cited early but are now largely ignored (particularly in philosophy of science and philosophy of mind, for different reasons in each case). These are outliers; they could have been typical but aren't. Most articles influential early remain so.

For the second point, we can break @fig-master-citation-ratio into ten-year chunks. @fig-decades-cite-ratio groups points from @fig-master-citation-ratio into 'decades' (1975-1984, 1985-1994, etc., given 1975-2024 data). For easier comparison, I removed the incomplete final decade and points with ages over 20.

```{r}
#| label: fig-decades-cite-ratio
#| fig-cap: "Citation ratios for different decades"
#| fig-subcap:
#|    - "1975-1984"
#|    - "1985-1994"
#|    - "1995-2004"
#|    - "2005-2014"
#| layout-ncol: 2

ten_year_graph <- function(x){
  temp <- age_effect_post_1975 |>
    filter(old_year >= x, old_year <= x + 9, 
           new_year >= old_year, new_year <= old_year + 20) |>
    group_by(new_year - old_year) |>
    mutate(mean_effect = mean(cite_ratio))
  
  temp |>
    ggplot(aes(x = age, y = cite_ratio, color = as.factor(old_year))) +
    geom_jitter(size = 0.5, alpha = 0.7) +
    xlab("Age of cited articles") +
    ylab("Citation ratio") +
    geom_line(aes(x = age, y = mean_effect), color = point_col) +
    geom_point(aes(x = age, y = mean_effect), color = point_col, size = 0.4) +
    theme(legend.position = "none") +
    ylim(0, 1.6)
}

ten_year_graph(1975)
ten_year_graph(1985)
ten_year_graph(1995)
ten_year_graph(2005)
```

Three trends emerge in @fig-decades-cite-ratio, especially after the second graph:

1. Peaks arrive later. In early graphs, the line declines by age 5; in the last, it barely falls.
2. Peaks are lower. The last graph barely crosses 1.
3. Declines are flatter. At age 15, values rise steadily over time.

Citations are getting older. While articles from a given year are still cited more at ages 2-5 than 12-15, this difference has fallen markedly. Technology's effect on citations has been opposite to my expectation.

This paper has two aims.

First, I explain the methodology behind these graphs and defend my choices. The conclusion: these graphs show that citations were traditionally to very recent articles but are now more frequently to older ones.

Second, I examine which years have been most influential, after adjusting for typical citation rates. The early 1970s stand out—unsurprisingly. More surprising: the 2000s are the next most influential period. Several factors contribute, but the rising importance of epistemology is likely primary (as @Petrovich2024 also found with different data). More generally, examining citation patterns illuminates philosophical history. Most work on analytic philosophy's history stops at the early 1970s; this is an early attempt to quantify subsequent developments following Kripke, Lewis, Rawls, and others.

# Age of Citations {#sec-age-of-citations}

## Methodology {#sec-methodology}

The data comes from Web of Science (WoS). This section explains which data I used and how I assembled it.

Most data comes from XML files WoS makes available to subscribing institutions. My institution's subscription (which provided data through 2021) has lapsed, so post-2021 data comes from the WoS website.^[Also via institutional subscription; the XML is more expensive.]

The XML file is large—over a terabyte decompressed. To make it manageable, I filtered to _articles_ (excluding discussion notes, book reviews, editorial matters) categorized as Philosophy or History & Philosophy of Science. I then hand-selected the hundred journals with the most inbound citations that were (a) primarily English language, (b) not primarily history of science, and (c) broadly 'analytic' rather than 'continental'. These choices were somewhat subjective, but yielded a reasonable collection of journals important for understanding recent anglophone analytic philosophy.

The journal list and basic statistics appear in @sec-statistics. For these journals, I included all articles and notes/reviews over 15 pages. I did not restrict to pieces labeled Philosophy or History & Philosophy of Science—for interdisciplinary journals like _Mind and Language_, these labels were unreliable, and I wanted a complete picture.

I supplemented the XML data in two ways. First, WoS does not index _The Journal of Philosophy_ from 1971-1974. Other journals are also missing in 1974, but this was the longest and most significant gap. The Journal published groundbreaking articles during this period by @Frankfurt1971, @Boolos1971, @Benacerraf1973, @Kim1973, @Friedman1974, @Levi1974, and Lewis [-@Lewis1971cen; -@Lewis1973ben]. Omitting these would undermine the analysis. I used JSTOR to compile a complete article list (excluding notes and book reviews) for _Journal of Philosophy_ in these years, then searched citations in @tbl-list-of-journals for references to them. This meant using different article/non-article classifications, with some odd results.^[The JSTOR list excluded the symposium on Kenneth Arrow's "Some Ordinalist-Utilitarian Notes on Rawls's Theory of Justice"; I'm unsure why.] It also required substantial data cleaning.^[Much of this involved sorting through varied spellings of Brian O'Shaughnessy's name.] Despite efforts at consistency, some early-1970s discontinuities may stem from this data acquisition difference.

Tables in @sec-introduction start in 1975 partly from consistency concerns about dual-method data compilation, but mainly because WoS begins indexing _Analysis_ only in 1975. Without _Analysis_—especially papers on knowledge analysis and inferentialism—the picture of citation patterns in those years is incomplete. I include 1956-1974 in some analyses below, but that data is less complete and less useful for identifying trends.

Second, my XML data extends only through mid-2022. I downloaded all articles and citations from these 100 journals for 2021-2024 from the WoS website, processing them with the bibliometrix package [@bibliometrix]. Using 2021 data as a check, the methods yielded similar results—differences were under 1% for article counts and slightly over 1% for citations. The match isn't perfect but is close enough that I used 2022-2024 data from WoS via bibliometrix.

## Journal to Journal {#sec-journal-to-journal}

This study examines one citation type: philosophy journal articles citing other philosophy journal articles. This excludes much—edited volumes, theses, conference programs, books, and citations in adjacent fields.

These restrictions have three justifications.

First, journal-to-journal data is cleaner. When WoS records one indexed article citing another, the citation record includes the cited article's WoS ID. This eliminates cleaning errors in citation details. Authors commonly cite incorrect page numbers and, less frequently but often enough to require checking, incorrect titles, author names (especially hard-to-spell names), or publication years. Cleaning this is labor-intensive. Restricting to cases with WoS IDs doesn't avoid this problem so much as delegate it to WoS. @Petrovich2024 examined all citations in five leading philosophy journals; covering more than five wasn't practical given the cleaning required. I sacrifice some comprehensiveness but cover twenty times more journals. Neither approach is wrong—examining different things, the studies complement each other.

Second, journals enable comprehensiveness. Determining average citation rates for philosophy books from a given year would require a database of all books—perhaps possible via the Library of Congress, but challenging. For edited volume chapters, I don't know where to start. Journals number their issues; confirming completeness is straightforward.

Third, using whole journals makes demarcating philosophy more manageable. I can show what I mean by philosophy journals: those in @tbl-list-of-journals. Going book-by-book or chapter-by-chapter would be massive work for both compilation and verification. I'm not quantifying philosophy articles in journals, but articles in philosophy journals. The demarcation problem remains non-trivial (should I include _Cognition_?), and some boundaries are inevitably arbitrary. But this approach involves fewer such boundaries, and they're more transparent.

Restricting to philosophy-journal-to-philosophy-journal citations has two major downsides.

For inbound citations, books and journal articles differ in what they cite, creating different field impressions. History of philosophy involves less journal publishing, and published articles cite primary sources and recent books more than journal articles. This work offers minimal insight into developments in history of philosophy. Also—important later—books are cited at much older ages than articles. @Petrovich2024 notes that through the 1990s, Quine, Wittgenstein, and Davidson were among the most cited authors. None appear near the top examining only cited journal articles.

Davidson raises another issue about journal article citations. A citation registers as being to a journal article only if the journal is identified—ideally by name, though DOI works—in the citing article. Older works often cite famous articles by mentioning reprint collections. Someone citing "Actions, Reasons, and Causes" who gives only the bibliographic detail that it's chapter one of _Essays on Actions and Events_ won't necessarily create a journal-to-journal citation in WoS. Most articles aren't reprinted, and currently people cite originals as well as or instead of reprints. Overall this isn't a large effect, but for finding most-cited articles, it's a major error source.^[I planned to study which articles had the largest citation declines as a measure of changing philosophical fashion. But most articles I found with large falls had been reprinted so often that this effect explained most of the pattern. It's not a large effect overall, but searching for outliers mostly finds unreliable data.]

For outbound citations, this study doesn't show how often journals are cited outside philosophy. It also doesn't show citations in books, but that's less problematic—book and journal citation patterns are similar. However, citations inside philosophy poorly predict citations outside. In @tbl-list-of-journals, _Journal of Medical Ethics_ articles are collectively rarely cited. This reflects my excluding medical journals where that journal is cited more often. The data tells you something: if you want confirmation that 'core' philosophy journals don't publish much bioethics, _Journal of Medical Ethics_ citation numbers are evidence. But they're not evidence about the journal's overall impact—we're not looking in the right place.

## Age, Period, and Cohort {#sec-apc}

To understand citation patterns, I'll borrow terminology common in sociology and medicine. An example best introduces it. Imagine we observe interesting patterns among teenagers in the late 1960s and wonder about explanations. Two pattern types immediately suggest themselves, along with tests.

First, the behavior could reflect being teenagers—an **age effect**. Test: see if similar patterns appear with teenagers at other times.

Second, the behavior could reflect the 1960s, when many striking things happened—a **period effect**. Test: see if non-teenagers in the 1960s show the same pattern.

A third explanation is important. These people were born in the early 1950s—the post-war baby boom. Colloquially, they're boomers. Perhaps that explains the pattern—a **cohort effect**. Test: examine the same people at other life stages.

Cohort effects are easily overlooked; sometimes they resemble age effects. @GhitzaEtAl2023 argue that many hypotheses about voting age effects (e.g., older people being naturally conservative) are really cohort effects. @Bump2023 argues that understanding boomers' distinctive role is crucial for understanding modern American life.

Mathematical reasons also complicate separating these effects. Many statistical techniques for separating influences fail when linear correlations exist between variable combinations. Here the correlation is maximal: by definition, cohort plus age equals period. Some workarounds exist—see @KeyesEtAl2010 for options and @Rohrer2025 for recent skepticism about general solutions—but the challenge remains.

Conceptually, separating these effects is difficult when effect strength changes over time. As noted initially, testing which effect is strongest naturally involves examining other times. This works when age effects are constant. When they're not (as may be true here), it's harder.

However, keeping these three effects in mind helps summarize the data:

- The **age effect**: articles are cited most at ages two to five years.
- The **period effect**: citations are far more numerous in recent years. Partly this reflects more published articles; partly it reflects citations per article growing substantially over the 2000s-2010s and exploding in the 2020s.
- The **cohort effect**: articles from the 1970s and 2000s are cited more than expected given age and period effects, while articles from other times—especially before 1965 and around 1990—are cited less. The reasons are more complicated; I return to them below.

The period effect is largest and, in some ways, least interesting. I'll start by quantifying it and arguing for screening it off.

# Period Effects {#sec-period}

The database contains `r number_of_citations` citations, unevenly distributed over time—they grow rapidly. In 1956, there are only `r citations_1956` citations (unsurprisingly, without preprint citations, few articles cite pieces from that year). By 2024, there are `r citations_2024`. @fig-citationsperyear shows this growth.

```{r}
#| label: fig-citationsperyear
#| fig-cap: "Citations in the dataset by year."

all_citations_per_year_plot
```

As noted in @sec-methodology, I used different extraction methods from 2022 onward. The 2021-2022 drop might reflect this change, but I don't think so. First, 2021 is likely an outlier: _Synthese_ published `r synthese_2021` articles in 2021 but only `r synthese_2022` in 2022. Second, applying the 2022-2024 method to 2020-2021 yielded close agreement (within 1-2%) for each year.

What explains this dramatic growth through 2021? Partly, more articles are being published and indexed. @fig-articlesperyear shows article counts by year.

```{r}
#| label: fig-articlesperyear
#| fig-cap: "Articles in the dataset by publication year."

articles_per_year_plot
```

This explains some growth, but not all—the curve in @fig-articlesperyear isn't nearly as steep as in @fig-citationsperyear. Citations per article are also rising. @fig-outboundcitations plots average citations to other dataset articles each year.

```{r}
#| label: fig-outboundcitations
#| fig-cap: "Average citations to indexed articles by year."

outbound_citations_plot
```

Several factors explain this graph's shape.

At the left edge, boundary effects are obvious. Since we count only citations to articles published since 1956, articles in the 1950s naturally have few citations. Since articles rarely get unpublished, more articles become available to cite each year.

This can't explain the massive jumps at @fig-outboundcitations's right edge. That jump reflects converging cultural trends: simply more citations overall (casual journal perusal confirms this), and more journal citations versus book or edited volume citations.

Sharp jumps like this warrant data checking. Cross-checking every entry is impractical, but spot-checks look correct. The change appears led by prestigious journals. For each journal, I calculated average outbound citations (to these hundred journals) for the 2010s and 2020-2024. The ten journals with the largest increases appear in @tbl-large-growth.

\newpage

```{r}
#| label: tbl-large-growth
#| tbl-cap: "Mean outbound citations for selected journals over two decades."

who_cites_more <- citation_tibble |>
  left_join(
    select(
      active_philo_bib,
      id,
      journal
    ), by = c("new" = "id")
  ) |>
  filter(new_year >= 2010, new_year <= 2024) |>
  mutate(period = case_when(
    new_year < 2020 ~ "2010-2019",
    TRUE ~ "2020-2024"
  )) |>
  group_by(journal, period) |>
  summarise(articles = n_distinct(new), citations = n(), .groups = "drop") |>
  mutate(name_len = str_length(journal)) |>
  mutate(mean_cites = citations/articles) |>
  pivot_wider(id_cols = c(journal, name_len), names_from = period, values_from = mean_cites) |>
  mutate(diff = `2020-2024` - `2010-2019`) |>
  mutate(Difference = round(diff, 1),
         `2010-2019` = round(`2010-2019`, 1),
         `2020-2024` = round(`2020-2024`, 1)) |>
  arrange(-diff) |>
  slice(1:10) |>
  select(Journal = journal,
         `2010-2019`,
         `2020-2024`,
         Difference)

kable(who_cites_more)

```

_Philosophical Review_ publishes only 10-12 articles annually, so high variation is expected. Still, the 2010s change isn't just small-sample variation. Of its 22 articles in 2020-2021, only one [@WOS000575210400003] had fewer than 14.8 outbound citations. With just 22 articles, anything could happen, but having all but one exceed the historical average by chance would be surprising.

We could simply ask what proportion of citations accrue to articles in a given year, but that would overcorrect. The 2020s have more citations to distribute, but also more articles sharing them. We must adjust for both. Here's how.

An article is _typically cited_ if published 3-10 years before the citing year. As @fig-master-citation-ratio showed, citations typically peak then. Using this definition, @fig-articlecounts shows typically cited article counts at any given time (for 2000, it shows articles published 1990-1997).

```{r}
#| label: fig-articlecounts
#| fig-cap: "Typically cited articles by year."

typical_plot
```

@fig-citationcounts shows how often these 'typical' articles are cited each year; @fig-citationrate shows mean citations to typical articles per year.

```{r}
#| label: fig-citationcounts
#| fig-cap: "Citations to typical articles by year."

typical_citations_per_year_plot
```

```{r}
#| label: fig-citationrate
#| fig-cap: "Mean annual citations to typical articles."

typical_citation_rate_per_year_plot 

```

Two things stand out in @fig-citationrate. First, the graph is flat for a long time—from mid-1970s to early-2000s, it bounces without much movement. Then it takes off, peaks in 2021, and returns to the long-term trend. Second, the numbers are never high. Throughout most of this study, even peak-age articles (3-10 years old) are cited once per _decade_ in these hundred journals. Since citation rates are extremely long-tailed with means well above medians, this overstates how often the 'average article' gets cited. Frequent citation is decidedly not the norm.^[Long-term, average citations per article equals average times an article is cited, so most articles having just a handful of philosophy journal citations is unsurprising.]

My initial measure of article influence is citation frequency divided by typical article citation frequency. This is somewhat arbitrary—I could have chosen ranges other than 3-10 years, but this works reasonably well. I tried other measures; they produced either implausible data trends or implausible judgments about paper influence. This measure had a nice property: how influential the leading 50 articles from a period were 10-20 years later was reasonably stable, suggesting it corrects for period effects well.


# Age Effects {#sec-age}

Next, I determine how article age affects citation frequency. The simplest approach—examining a typical year to see how its articles are cited over time—would be completely wrong. @fig-1990-outbound-citations shows citation patterns for 1990 articles.

```{r}
#| label: fig-1990-outbound-citations
#| fig-cap: "Citations to 1990-published articles."

year_in_year_out |>
  filter(old_year == 1990, new_year >= 1990) |>
  ggplot(aes(x = new_year, y = citations)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Number of citations")
```

Using citations as influence measures, @fig-1990-outbound-citations suggests 1990 articles were collectively most influential in 2021. That's not true—they were most influential 2-4 years post-publication, like most articles. The 2020s simply published so many articles, each citing so many pieces, that even three-decade-old articles get lifted by the rising tide.

A more intuitive influence measure uses typical articles from @sec-period. Adjust @fig-1990-outbound-citations by dividing each value by two things: first, the typical article citation rate from @fig-citationrate (adjusting for period effects); second, the number of 1990-published articles (yielding per-article influence). The result is the **citation ratio** from @fig-master-citation-ratio. @fig-1990-outbound-citations-norm shows 1990's citation ratio.

```{r}
#| label: fig-1990-outbound-citations-norm
#| fig-cap: "Normalized citations to 1990-published articles."

year_in_year_out |>
  filter(old_year == 1990, new_year >= 1990) |>
  left_join(
    select(
      typical_citation_rate_per_year,
      new_year,
      mean_cites
    )
  ) |>
  mutate(norm_cites = citations/(mean_cites* 1428)) |>  
  ggplot(aes(x = new_year, y = norm_cites)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Normalised citations")
```

Two reasons support @fig-1990-outbound-citations-norm as a more plausible influence measure than @fig-1990-outbound-citations. One appeals to intuition: I know 1990 work came up in discussions far more in the 1990s than 2020s. While such intuitive evidence deserves some weight, it's obviously unreliable alone. The better reason: we get very similar graphs no matter which initial year we pick. This was visible in @fig-decades-cite-ratio, but it's worth seeing how stable this is.

An explicit citation ratio definition helps. Let *c*(*o*, *n*) be citations of year-*o* articles (old year) in year *n* (new year). Let *a*(*o*) be articles published in year *o*. Then citation ratio *r*(*o*, *n*) is:

$$
r(o, n) = \left(\frac{c(o, n)}{a(o)}\right) / \left(\frac{\sum\limits_{i = n-10}^{n-3}c(i, n)}{\sum\limits_{i = n-10}^{n-3}a(i)}\right)
$$

In @fig-ageeffecttibble-early and @fig-ageeffecttibble-late, each facet represents different *o* values, the x-axis is *n*, and the y-axis is *r*(*o*, *n*). The key observation: these graphs are remarkably steady. I've cheated slightly—showing earlier years would reveal different shapes. 1960s citations are so sparse that noise overwhelms signal. Since then, patterns are reasonably steady.

```{r}
#| label: fig-ageeffecttibble-early
#| fig-cap: "Citation rates for articles published 1968-1992."
#| fig-height: 12
#| fig-width: 9

age_effect_tibble |>
  filter(old_year >= start_year + 1, old_year <= end_year - min_data, new_year >= start_year) |>
  filter(old_year >= 1968, old_year <= 1992) |>
  ggplot(aes(x = new_year, y = cite_ratio)) +
  geom_point(size = 0.7, color = point_col) +
  facet_wrap(~old_year, ncol = 5) +
  xlab(element_blank()) +
  ylab(element_blank()) +
  theme(axis.text = element_text(size = 10),
        strip.text = element_text(size = 12))
```

```{r}
#| label: fig-ageeffecttibble-late
#| fig-cap: "Citation rates for articles published 1993-2017."
#| fig-height: 12
#| fig-width: 9

age_effect_tibble |>
  filter(old_year >= start_year + 1, old_year <= end_year - min_data, new_year >= start_year) |>
  filter(old_year >= 1993, old_year <= 2017) |>
  ggplot(aes(x = new_year, y = cite_ratio)) +
  geom_point(size = 0.7, color = point_col) +
  facet_wrap(~old_year, ncol = 5) +
  xlab(element_blank()) +
  ylab(element_blank()) +
  theme(axis.text = element_text(size = 10),
        strip.text = element_text(size = 12))
```

# Cohort Effects {#sec-cohort}

Period and age effects together explain much of the citation pattern trends. But systematic deviations remain. @fig-twodeviations shows some examples—each graph is a facet from @fig-ageeffecttibble-early with a line showing average age effects.

```{r}
#| label: fig-twodeviations
#| fig-cap: "Citations from a given year compared to average citations."
#| fig-subcap: 
#|   - "1979"
#|   - "1985"
#| layout-ncol: 2

year_to_mean_plot(1979)
year_to_mean_plot(1987)
```

In 1979, yearly values predominantly exceed the mean line; in 1987, they're largely below it. My main cohort effect measure is the average ratio between yearly data (dots) and average values (line) for each such graph. 1979 dots average about 13% above the mean; 1987, about 9% below. Repeating this for every dataset year yields @fig-cohort.

```{r}
#| label: fig-cohort
#| fig-cap: "Cohort effects by publication year."

year_by_year_average_plot
```

Technical notes on @fig-cohort: I added a rolling average line (four years either side, or as many as available) to highlight features. In calculating means, I included only years with at least five years of data for calculating mean age effects. So I haven't included what happens when `{r} start_year` papers are cited after `{r} end_year - min_data`—insufficient data exists to determine 'expected' aging curves at those points.

Five periods appear in the graph:

1. Pre-mid-1960s journal articles are very rarely cited.
2. After that, especially in the early 1970s, many highly cited articles appear.
3. A stagnation period follows—things mostly don't return to pre-1965 lows but stay consistently below zero.
4. An uptick begins mid-1990s, peaking dramatically in 2007.
5. A dramatic dropoff follows almost immediately after 2007's high.

The first two trends make sense; the latter three less so. The remainder of this paper explains what's happening and what it reveals about philosophy's history and the philosophy profession's history.

```{r}
#| label: find-old-high-cites

old_high_cites <- citation_tibble |>
  filter(old_year <= 1963) |>
  group_by(old) |>
  tally(name = "citations") |>
  slice_max(order_by = citations, n = 20) |>
  left_join(
    select(
      active_philo_bib,
      old = id,
      displayauth,
      year,
      title
    ), by = "old"
  ) |>
  filter(citations >= 150) |>
  arrange(year) |>
  mutate(the_cite = paste0(
    "@",
    str_replace_all(old, ":","")
  ))

list_of_old_high_cites <- knitr::combine_words(old_high_cites$the_cite)
```

Before 1965, philosophy's most significant work wasn't in WoS-indexed journals—partly because books were more important, partly because WoS indexes are incomplete for early years. We lack "Is Knowledge Justified True Belief?" [@Gettier1963] because _Analysis_ indexing starts only in 1975, and Austin's major papers—"Ifs and Cans" and "A Plea for Excuses" [@Austin1956; @Austin1956b]—because their venues aren't indexed as journals. We do have important papers by `r list_of_old_high_cites`, but these had less impact than contemporary books, especially _Intention_ [@Anscombe1957], _Word and Object_ [@Quine1960], and _The Structure of Scientific Revolutions_ [@Kuhn1962].

Then, starting in the late 1960s, nearly every philosophy area was transformed, with much action in journals. The period's two most important works—_A Theory of Justice_ [@Rawls1971] and _Naming and Necessity_ [@Kripke1980]—weren't journal articles. But journal articles did revolutionize many fields, including:

- Free will [@WOSA1969Y444700002; @10.2307_2024717];
- Practical ethics [@WOSA1971Y116900003; @WOSA1972Z066400001];
- Meaning and reference [@10.2307_2025079];
- Philosophy of mathematics [@10.2307_2025075];
- Causation [@10.2307_2025310; @10.2307_2025096]; and
- Personal identity [@WOSA1971Y036400001]

Additionally, surprisingly many papers became influential later rather than immediately, including work by @WOSA1970ZE33800001, @WOSA1970ZE32700001, @WOSA1970Y384700002, and @WOSA1973P242100001. @fig-cohort's early-1970s story is directionally plausible, though magnitude is hard to confirm given spotty data. Before the late 1960s-early 1970s, philosophy journals had never published such high-quality work in this quantity.

To understand subsequent developments, we must examine data more closely. @fig-cohort-short is @fig-cohort restricted to the first seven post-publication years—for each publication year, it measures citations of that year's articles during their first seven years, adjusted identically for age and period effects. I start in 1975 to exclude noisy early data.

```{r}
#| label: fig-cohort-short
#| fig-cap: Short-term citation rates (first seven years post-publication).

year_by_year_average_plot_short +
  ggtitle("Short term citation rates")
```

In @fig-cohort, 2010 articles are cited slightly more than 1990 articles (after adjustments). But in @fig-cohort-short, they're cited 20% less. Generally, nearly every 1980s-1990s article batch shows solid first-seven-year citation rates. So @fig-cohort-short lacks @fig-cohort's 1980s dip. This contrasts strikingly with @fig-cohort-long, measuring only post-seven-year citations.

```{r}
#| label: fig-cohort-long
#| fig-cap: Long-term citation rates (after the first seven years).

year_by_year_average_plot_long +
  ggtitle("Long term citation rates")
```

In @fig-cohort-long, every 2000-2016 year averages higher than every 1980-1999 year. Starting around 1998, a large change occurs in how often articles over seven years old are cited.

This explains @fig-cohort's right-edge dropoff—the fifth period I described. Citations are aging, but for mid-2010s articles, we lack data on citations ten or more years post-publication. Averaging their first-few-year citations compared to a generation ago's first-few-year citations underestimates their influence.

This doesn't explain everything. @fig-cohort-long appears to stop rising in the 2010s. But it explains much. 1980s-1990s articles were heavily cited soon after publication, but their citation rates didn't hold up like later articles. 2000s articles were cited less initially than late-20th-century articles but far more as time passed. This might also apply to 2010s articles, but it's too early to determine.

Even accepting this, questions remain.

Why is this temporal citation shift occurring? Shouldn't technology shift things oppositely? I discuss this in @sec-technology.

Why are citations rising so much generally, even accounting for increased article publication? @sec-technology partially explains this, but @sec-culture discusses two cultural factors.

Finally, why do periods around 1990 and 2005 stand out? Around 1990, @fig-cohort-short shows an upward spike and @fig-cohort-long a low point. Around 2005, both graphs exceed long-term trends. The answers partly involve technological factors (@sec-technology) and cultural factors (@sec-culture) but also reflect important changes in philosophically central topics. This hints at an important twentieth/twenty-first-century philosophy discontinuity, which I address in @sec-content.

# Technology and Citations {#sec-technology}

A common view holds that electronic publication primarily speeds _distribution_. The data doesn't support this. If true, we'd expect short-term citations—especially very short-term—to rise over time.

By the late twentieth century, printing and postage were mature technologies. We weren't awaiting steam ships to deliver journal issues to distant shores. Philosophy journal distribution used the same technology as medicine and other time-sensitive fields. From this perspective, the internet would accelerate distribution by weeks or months at most—barely visible on yearly graphs. Postal improvements, especially increased airmail use, may affect 1980s-1990s citation numbers—more citations to foreign journals soon after publication than in earlier decades, for example.

But Online First, Early View, and similar quasi-publication forms haven't made much difference. They appear slightly in the data—occasionally articles are cited before official publication—but such cases are rare.

Technology's biggest effect was on _search_, not distribution. Before widespread computer use, searching books was far easier than searching journal articles. Classification systems placed books near others on the same topic. Card catalogs listed book subjects. Even book titles helped locate topics. Finding relevant journal articles was much harder and, it seems, rarely done.

Physical storage and access also differed notably between books and journals. Nearly every academic has a bookshelf; far fewer have large journal collections. Departments occasionally kept physical journals, but accessing them often meant walking across campus to the library. Accessing a book might mean walking four steps to a shelf. This physical difference likely contributed to books' and articles' relative prominence in bibliographies.

One exception existed to this access pattern (at least in any twentieth-century department I knew, though I think this was widespread): Departments sometimes kept latest journal issues in a department library or common room—much more prominent and accessible. Whether this explains why pre-1995 journal citations are so often to very recent journals is unclear, but it probably helped.

Search technology changes appear central to the story. Before widespread computer adoption, old journal articles were very hard to find. This changed somewhat with electronic, easily searchable _Philosophers' Index_ versions, and dramatically when journals went online. This partly explains why older articles—especially non-classic older articles—are now more widely cited.

# Culture Changes {#sec-culture}

Two cultural changes significantly affected citation patterns: one concerning journal articles' role, another concerning citation norms.

Looking back at century-old journals, pieces sometimes resemble blog posts more than current journal articles. Even substantive pieces feel like means to an end—the journal article as much a book trial run as a complete project report.

By the twenty-first century, this changed completely. Articles are longer, even in venues like _Analysis_. More importantly, they're often finished products, not draft runs for future books. Prominent philosophers' reputations rest largely or entirely on articles (e.g., Jonathan Schaffer). Large philosophy fields—epistemic contextualism, metaphysical grounding—have canonical texts that are almost entirely articles, not books. This isn't entirely new (post-Gettier knowledge analysis literature was largely article-based), but it's a growing trend. This partially explains aging citations: fields based in articles generate more older-article citations, especially when those articles haven't been superseded by books.^[Articles once widely cited but rarely cited now are heavily populated by those forming the basis for widely cited books.]

The bigger trend is philosophers' increasing tendency to include brief citations to work they're not discussing in detail but which locate the paper in a literature. Obviously if an article cites 26 other journal articles—as @tbl-large-growth showed the average recent _Philosophical Review_ paper does—it can't possibly discuss all in depth. (This count excludes books and edited volume articles.) For long, a striking philosophy-adjacent-disciplines difference was the lack of citations largely serving to place a paper in a literature. Their growth partially explains aging citations: authors citing their subfield's history include some older articles.

Why did this change occur? Technology is part of the story (@sec-technology)—it's now easier. But this can't be everything, since the practice was more widespread in other fields before these technologies arrived. Specialization growth is another part. Writing about content externalism in the 1990s didn't require a citation trail back to Kripke and Putnam—everyone knew these debates' history; it didn't need rehashing. Since then, it's become less clear that any field's history is universally known, creating more background need.

But the biggest explanation part is likely interdisciplinary work growth in the 2000s. This appears in many fields, including experimental philosophy's rise and increasing philosophy-of-mind empirical sophistication. I'll focus on one other aspect: philosophy of language's move toward debates also active in linguistics. Part of what we see in the 2000s is citation norms adoption from linguistics into philosophy of language. Philosophy of language wasn't as important to journals in the 2000s as earlier decades.^[I won't argue this here—it would require nearly another paper and more data sources. Short version: nothing in twenty-first-century philosophy of language was as crucial to journals as debates over names and descriptions and over wide and narrow content had been in earlier decades.] But it was an important vector for citation norms spreading from linguistics to philosophy, especially since much philosophy-of-language work overlapped with that decade's key epistemology debate: contextualism. I'll end this paper examining how changes in what philosophers discussed interact with citation data.

# Content Changes {#sec-content}

Philosophy publishing's center of gravity shifts over our time period. Through at least the early 2000s, analytic philosophy is in what @Sider2020 [2] calls the "modal era". One aspect of this era that Sider highlights is that essence questions were equated with necessity questions in ways they weren't before or after.^[During this era, the necessity-of-origins thesis and origin essentialism thesis were typically taken as not just mutually supporting but literally identical—an identity claim not widely endorsed before 1970 or after 2010.] This should be taken as era symptom, not definition. What's really defining was how modality became central to disputes across the discipline.

Consider, for example, what @Jackson1998 called the 'location problem'—how to locate in the world something the philosopher thinks exists and is not fundamental. Jackson argues that saying how to locate the non-fundamental in the fundamental is a compulsory question for anyone doing 'serious metaphysics', with the one and only answer involving modality. As he says,

> When does a putative feature of our world have a place in the account some serious metaphysics tells of what our world is like? I have already mentioned one answer: if the feature is entailed by the account told in the terms favoured by the metaphysics in question, it has a place in the account told in the favoured terms. This is hardly controversial considered as a sufficient condition, but, I will now argue, it is also a necessary condition: the one and only way of having a place in an account told in some set of preferred terms is by being entailed by that account—a view I will refer to as the entry by entailment thesis. [@Jackson1998 5]

Jackson went on to say other things about entailment not widely endorsed. But at this early book stage, he was largely expressing conventional wisdom. In a review disagreeing with many book parts, @Yablo2000Jackson [20] says "Not many eyebrows will be raised by Jackson's view that metaphysics is committed to 'entry by entailment' theses." The quoted parts aren't controversial, especially the one Jackson flags as ever so slightly more controversial.

The idea that entailment—i.e., necessitation—had been central to understanding how the non-fundamental relates to the fundamental was central to philosophy for many years by this point. We can see how central using a slightly different statistic: grand-citations.

The number of grand-citations an article *a* has is the number of triples ⟨*a*, *b*, *c*⟩ such that *c* cites *b* and *b* cites *a*—the sum of citations of articles citing *a*. Grand-citations over time show David Lewis's centrality to philosophy journals: five of the six articles with the most grand-citations are by Lewis. Looking at particular times shows journals' changing face. Grand-citations take time to accrue, so I'll examine twenty-year periods—for various years, which articles published in the preceding twenty years had the most grand-citations through that year.

```{r}
#| label: calculate-grand-cites
#| cache: true

# Grand cites at a time

overall_grand_cites <- c()

for (end_year in (199:202)*10){
  temp_citation_count <- citation_tibble |>
    filter(new_year <= end_year,
           old_year >= end_year - 20) |>
    group_by(old) |>
    tally(name = "citations")
  
  temp_grand_cites <- citation_tibble |>
    filter(new_year <= end_year,
           old_year >= end_year - 20) |>
    left_join(temp_citation_count,
              by = c("new" = "old")) |>
    replace_na(replace = list(citations = 0)) |>
    group_by(old) |>
    summarise(grand_cites = sum(citations)) |>
    left_join(
      select(
        active_philo_bib,
        old = id,
        displayauth,
        year,
        title
      ), by = "old"
    ) |>
    arrange(-grand_cites)
  
  temp_grand_cites_summary <- temp_grand_cites |>
    slice(1:100) |>
    left_join(
      temp_citation_count,
      by = "old"
    ) |>
    mutate(
      Article = paste0(
        displayauth,
        " -@",
        str_replace_all(old, ":",""),
        " \"",
        title,
        "\""
      )
    ) |>
    mutate(rank = row_number(),
           as_of = end_year) |>
    select(
      `As Of` = as_of,
      old,
      Rank = rank,
      Article,
      Cites = citations,
      `Grand-Cites` = grand_cites
    )
  
  overall_grand_cites <- overall_grand_cites |>
    bind_rows(temp_grand_cites_summary)
}

```

@tbl-grand-cite-2000 lists articles published from 1980 onward with the most grand-citations through 2000.

```{r}
#| label: tbl-grand-cite-2000
#| tbl-cap: "1980s-1990s articles with the most grand-citations by 2000."

kable(
  overall_grand_cites |>
    filter(`As Of` == 2000) |>
    select(-`As Of`, -old) |>
    slice(1:10)
)
```

I've included article names to show how central supervenience was to this literature.^[The relationship story between twentieth-century work on functions and twenty-first-century work on mechanisms is interesting but for another time.] Four articles have 'supervenience' in the title! Jaegwon Kim stood at this literature's center. My citation data somewhat _underestimates_ his influence—people often cited his edited collection _Supervenience and Mind_ [@Kim1993], usually not tracked by WoS.

These articles' subsequent history largely explains @fig-cohort's relatively low 1980s values. Much of this supervenience work has fallen out of philosophical discourse. @tbl-grand-cite-2000-now shows how many citations @tbl-grand-cite-2000 articles have since 2021.

```{r}
#| label: tbl-grand-cite-2000-now
#| tbl-cap: "Citations of @tbl-grand-cite-2000 articles since 2021." 

temp <- citation_tibble %>%
  filter(new_year >= 2021) %>%
  group_by(old) %>%
  tally(name = "Citations since 2021") 

temp2 <-   overall_grand_cites |>
    filter(`As Of` == 2000) |>
    slice(1:10) %>%
    left_join(temp, by = "old") %>%
        mutate(
      Article = paste0(
        "@",
        str_replace_all(old, ":","")
      )
    ) %>%
     # select(Article, Cites, `Grand-Cites`, `Citations since 2021`)
    left_join(
      select(
        active_philo_bib,
        old = id,
        displayauth,
        year,
        title
      ), by = "old"
    ) |>
      select(Article, `Citations since 2021`)
kable(temp2)
```

Supervenience articles simply aren't cited much these days. The same pattern recurs examining other nearly-as-widely-discussed supervenience papers (e.g., @WOSA1989T680600002 and @WOSA1984ST78300010) and papers from the debate family on wide and narrow content, mental individualism, empty names, and hallucinations—all using supervenience notions to define debates. Articles by @WOSA1986AYX3200002, @WOSA1988P549200004, @WOSA1989T680600002, @WOSA1983RU36600003, @WOSA1991FF02900001, and @WOSA1991EN62900001, all very influential then, have been barely cited since 2021. Even some Lewis papers on these topics (e.g., @WOSA1981MS19500002 and @WOSA1983PZ01000001) have just a handful of recent citations. A debate family central to philosophy for years—particularly central to what _Philosophical Review_ published in the 1980s—has simply dropped off the agenda. This hugely impacts citation numbers.

Moving into the 2000s, focus shifts dramatically, as @tbl-grand-cite-2010 shows.

```{r}
#| label: tbl-grand-cite-2010
#| tbl-cap: "Top 10 1990s-2000s articles by grand-citations through 2010."

kable(
  overall_grand_cites |>
    filter(`As Of` == 2010) |>
    select(-`As Of`, -old) |>
    slice(1:10)
)
```

The biggest single topic was epistemology contextualism, with major papers by @WOSA1996VY21200001 and @WOSA1995RC31600001 at the center. What I want to focus on particularly, though, is another DeRose paper on that list: "Epistemic Possibilities." It has fewer cites than any other paper there but the fourth-most grand-cites. This is partly because it was important to both epistemology and philosophy of language. But another reason is that the debate it triggered was one of the first places where linguistics citation norms were applied in philosophy. This is part of the evidence for my @sec-culture claims about changing norms' importance to citation rates.

Moving to the 2010s, focus shifts again, as @tbl-grand-cite-2020 shows. Here we see evidence for my earlier specialization-increase claim. The papers with the most grand-citations address subjects like mechanisms, dogmatism, disagreement, pragmatic encroachment, and priority monism—a much broader topic range than was central to philosophy a few decades earlier. Crucially, topics overlap so little that someone working in them can't expect philosophers working in other topics to know even debate basics. (Perhaps people working on various epistemology topics on that list can expect slightly more background knowledge from people working on other epistemology topics, but that's about it.) So writers need more citations just so readers will have basic topic understanding.

```{r}
#| label: tbl-grand-cite-2020
#| tbl-cap: "Top 10 1990s-2000s articles by grand-citations through 2020."

kable(
  overall_grand_cites |>
    filter(`As Of` == 2020) |>
    select(-`As Of`, -old) |>
    slice(1:10)
)
```


# Conclusion

I need to write a conclusion.

# Appendix: Summary Statistics {#sec-statistics}

The paper uses the journals shown in @tbl-list-of-journals.

```{r}
#| label: tbl-list-of-journals
#| tbl-cap: "Journals used in this paper"

journal_summary <- active_philo_bib %>%
  group_by(journal) %>%
  summarise(
    earliest_year = min(year, na.rm = TRUE),
    latest_year = max(year, na.rm = TRUE),
    n_articles = n()
  )

# Outbound citations: join articles to their journal, count refs per journal
outbound_cites <- active_philo_cite %>%
  left_join(active_philo_bib %>% select(id, journal), by = "id") %>%
  group_by(journal) %>%
  summarise(outbound_citations = n())

# Inbound citations: join refs to their journal, count refs per journal
inbound_cites <- active_philo_cite %>%
  left_join(active_philo_bib %>% select(id, journal), by = c("refs" = "id")) %>%
  group_by(journal) %>%
  summarise(inbound_citations = n())

# Combine all summaries
journal_summary <- journal_summary %>%
  left_join(outbound_cites, by = "journal") %>%
  left_join(inbound_cites, by = "journal") %>%
  replace_na(list(outbound_citations = 0, inbound_citations = 0)) |>
  rename(
    Journal = journal,
    `First Year` = earliest_year,
    `Last Year` = latest_year,
    `Articles` = n_articles,
    `Inbound Citations` = inbound_citations,
    `Outbound Citations` = outbound_citations
  )

kable(journal_summary)
```

What I've called an _article_ here is anything that either (a) marked as an article or research-article by WoS, or (b) marked as a review, discussion, or note by WoS and is at least 15 pages long. I needed to include (b) because some very important works (e.g., @WOSA1963CEU0700001 and @WOS000272855000002) were not recorded as articles by WoS.

The years here are **not** the first and last years that the journals published, but the earliest and latest years that are in the WoS index (as of the time I pulled the data). As mentioned in the main text, this makes a big difference for some journals, especially _Analysis_.

The way WoS handles the 'supplements' to _Noûs_, i.e., _Philosophical Perspectives_ and _Philosophical Issues_, is a little uneven. Some years these are recorded as being their own thing, i.e., with a source name of _Philosophical Perspectives_ or _Philosophical Issues_; and some years they are recorded as special issues of _Noûs_. When they were listed as special issues, the citations were extremely unreliable. Some high profile articles are recorded as having no citations until several years after publication. The bibliographic information for the articles themselves was also spotty. So I've manually removed all records that were listed as special or supplementary issues of _Noûs_ (and similarly removed the citations to those articles that did get tracked). What you see here are just the standalone issues of _Philosophical Perspectives_.