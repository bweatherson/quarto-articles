<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.479">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Brian Weatherson">
<meta name="dcterms.date" content="2021-03-30">
<meta name="description" content="This paper contributes to the project of articulating and defending the supra-Bayesian approach to judgment aggregation. I discuss three cases where a person is disposed to defer to two different experts, and ask how they should respond when they learn about the opinion of each. The guiding principles are that this learning should go by conditionalisation, and that they should aim to update on the evidence that the expert had updated on. But this doesn’t settle how the update on pairs of experts should go, because we also need to know how the experts are related. I work through three examples showing how the results change given different prior beliefs about this relationship.">

<title>Online Articles - Brian Weatherson - Mixing Expert Opinion</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" href="https://use.typekit.net/uzz2drx.css">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Online Articles - Brian Weatherson</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://brian.weatherson.org"> <i class="bi bi-mortarboard" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://bsky.app/profile/bweatherson.bsky.social"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Mixing Expert Opinion</h1>
            <p class="subtitle lead">Three Worked Examples</p>
                  <div>
        <div class="description">
          <p>This paper contributes to the project of articulating and defending the supra-Bayesian approach to judgment aggregation. I discuss three cases where a person is disposed to defer to two different experts, and ask how they should respond when they learn about the opinion of each. The guiding principles are that this learning should go by conditionalisation, and that they should aim to update on the evidence that the expert had updated on. But this doesn’t settle how the update on pairs of experts should go, because we also need to know how the experts are related. I work through three examples showing how the results change given different prior beliefs about this relationship.</p>
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">games and decisions</div>
                <div class="quarto-category">unpublished</div>
              </div>
                  </div>
  </div>
    
  <div class="quarto-title-meta-author">
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-heading">Affiliation</div>
    
      <div class="quarto-title-meta-contents">
      <p class="author"><a href="http://brian.weatherson.org">Brian Weatherson</a> </p>
    </div>
      <div class="quarto-title-meta-contents">
          <p class="affiliation">
              University of Michigan
            </p>
        </div>
      </div>

  <div class="quarto-title-meta">

        
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 30, 2021</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Sections</h2>
   
  <ul>
  <li><a href="#case-one-conditionally-independent-evidence" id="toc-case-one-conditionally-independent-evidence" class="nav-link active" data-scroll-target="#case-one-conditionally-independent-evidence"><span class="header-section-number">0.1</span> Case One: Conditionally Independent Evidence</a></li>
  <li><a href="#case-two-common-marbles" id="toc-case-two-common-marbles" class="nav-link" data-scroll-target="#case-two-common-marbles"><span class="header-section-number">0.2</span> Case Two: Common Marbles</a></li>
  <li><a href="#case-three-differentially-informed-experts" id="toc-case-three-differentially-informed-experts" class="nav-link" data-scroll-target="#case-three-differentially-informed-experts"><span class="header-section-number">0.3</span> Case Three: Differentially Informed Experts</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">0.4</span> Summary</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<p>What should you do if two experts, each of whom you are disposed to defer to, disagree? The answer depends on what you know about the relationship between the experts’ evidence. I’m going to argue for this dependence claim, and work through three examples that start the process of illustrating the nature of the dependence. The first example concerns a case where the evidence the experts have is maximally independent. This case has been well analysed by <span class="citation" data-cites="EaswaranEtAl2016">Easwaran et al. (<a href="#ref-EaswaranEtAl2016" role="doc-biblioref">2016</a>)</span>, and my main contribution is to offer a new (and perhaps more explanatory) proof of their primary conclusion. The second case is where you know what proportion of the experts’ evidence is shared. And the third is where you know that one expert is more informed, but you don’t know which. In each of the last two cases I’ll show the computed exact values of the posterior probabilities after conditionalising on the expert credences, and also show some simple methods for approximating these exact values. The approximations are, I suspect, a little more robust when we move from the simple examples I’ll describe to more realistic ones.</p>
<aside>
Chairs by François-Honoré-Georges Jacob-Desmalter. Picture via <a href="https://collections.louvre.fr/ark:/53355/cl010097627">Louvre</a>.
</aside>
<p>So let’s get more precise about the question we’re asking, and also give names to the characters in the story. (It feels weird to talk about you when I don’t know who you are, so I prefer having named characters.) Assume Player regards Ivy and Zack as experts about <span class="math inline">\(p\)</span> in the following sense.</p>
<ol class="example" type="1">
<li>If Player learns that Ivy’s credence in <span class="math inline">\(p\)</span> is <span class="math inline">\(x\)</span>, and nothing else, he will change his credence in <span class="math inline">\(p\)</span> to <span class="math inline">\(x\)</span>.</li>
<li>If Player learns that Zack’s credence in <span class="math inline">\(p\)</span> is <span class="math inline">\(x\)</span>, and nothing else, he will change his credence in <span class="math inline">\(p\)</span> to <span class="math inline">\(x\)</span>.</li>
</ol>
<p>Given that, what is the answer to this question.</p>
<ol start="3" class="example" type="1">
<li>If Player learns that Ivy’s credence in <span class="math inline">\(p\)</span> is <span class="math inline">\(y\)</span>, and Zack’s credence in <span class="math inline">\(p\)</span> is <span class="math inline">\(z\)</span>, and nothing else, what should his credence in <span class="math inline">\(p\)</span> become?</li>
</ol>
<p>Following <span class="citation" data-cites="BaccelliStewart2021">Baccelli and Stewart (<a href="#ref-BaccelliStewart2021" role="doc-biblioref">2021</a>)</span>, let’s distinguish two kinds of answers to this question. The <em>supra-Bayesian</em> says that this case, like every other case, calls for conditionalisation. This is going to be the kind of answer I defend. Here’s how we spell this answer out. First, we rewrite (1) and (2) as (4) and (5)</p>
<ol start="4" class="example" type="1">
<li><span class="math inline">\(\forall x: Cr_P(p | Cr_I(p) = x) = x\)</span></li>
<li><span class="math inline">\(\forall x: Cr_P(p | Cr_Z(p) = x) = x\)</span></li>
</ol>
<p>Where <span class="math inline">\(Cr_P, Cr_I\)</span> and <span class="math inline">\(Cr_Z\)</span> are Player, Ivy and Zack’s credence functions respectively. Then (3) gets rephrased as a request for the value of</p>
<ol start="6" class="example" type="1">
<li><span class="math inline">\(Cr_P(p | Cr_I(p) = y \wedge Cr_I(p) = z)\)</span></li>
</ol>
<p>That’s good as far as it goes, but it raises two natural questions. First, what reasonable credal functions make (4) and (5) true, and what do they tend to say about (6)? Second, given the massive computational difficulty in calculating values like (6) in real time, are there heuristics for approximating its value in realistic cases? This paper aims to make progress on both questions. It offers some examples of reasonable credal functions satisfying (4) and (5), and uses them to suggest some heuristics for approximating (6) in somewhat realistic cases.</p>
<p>But before we get to those answers, we should look at the other kind of answer <span class="citation" data-cites="BaccelliStewart2021">Baccelli and Stewart (<a href="#ref-BaccelliStewart2021" role="doc-biblioref">2021</a>)</span> mention: pooling answers. A pooling answer to (3) says that we should find some function that in some way ‘pools’ <span class="math inline">\(y\)</span> and <span class="math inline">\(z\)</span> to answer (3). One obvious such function is the arithmetic mean. The answer to (3) is just <span class="math inline">\((y + z)/2\)</span>. Unfortunately, this won’t do for three reasons. One reason, as proven independently by <span class="citation" data-cites="Gallow2018">Gallow (<a href="#ref-Gallow2018" role="doc-biblioref">2018</a>)</span> and <span class="citation" data-cites="Bradley2017">Bradley (<a href="#ref-Bradley2017" role="doc-biblioref">2017</a>)</span> is that it is incompatible with supra-Bayesianism. A second reason, as stressed by <span class="citation" data-cites="RussellEtAl2015">Russell, Hawthorne, and Buchak (<a href="#ref-RussellEtAl2015" role="doc-biblioref">2015</a>)</span>, is that it is in cases where Player defers to Ivy and Zack across a range of questions, this answer is incompatible with Player, Ivy and Zack all updating on external evidence by conditionalisation.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> A third reason, as stressed by <span class="citation" data-cites="Levinstein2015">Levinstein (<a href="#ref-Levinstein2015" role="doc-biblioref">2015</a>)</span> and <span class="citation" data-cites="EaswaranEtAl2016">Easwaran et al. (<a href="#ref-EaswaranEtAl2016" role="doc-biblioref">2016</a>)</span> is that in some cases the intuitively correct answer to (3) is not between <span class="math inline">\(y\)</span> and <span class="math inline">\(z\)</span>.</p>
<div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;Note that supra-Bayesianism is the view that Player should update on expert testimony by conditionalisation. This objection does not assume supra-Bayesianism, but does assume that conditionalisation is the right rule for normal, non-testimonial, updating.</p></li><li id="fn2"><p><sup>2</sup>&nbsp;I say ‘something like’ because you might want to allow some extra parameters in the answer if, for example, you want to give different weights to the two experts. That kind of detail won’t matter to the argument here; we’re just going to focus on cases where the experts are treated symmetrically.</p></li></div><p>The last of these reasons is most pressing. The natural response to the first two reasons is to move to some other kind of pooling. Both <span class="citation" data-cites="RussellEtAl2015">Russell, Hawthorne, and Buchak (<a href="#ref-RussellEtAl2015" role="doc-biblioref">2015</a>)</span> and <span class="citation" data-cites="BaccelliStewart2021">Baccelli and Stewart (<a href="#ref-BaccelliStewart2021" role="doc-biblioref">2021</a>)</span> suggest that we should use some kind of geometric pooling instead of linear pooling. In this context, to use geometric pooling is to give an answer to (3) something like<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p><span class="math display">\[
\frac{\sqrt{yz}}{\sqrt{yz} + {\sqrt{(1-y)(1-z)}}}
\]</span></p>
<p>And that pooling function can be shown to avoid the first two reasons for not using linear pooling. But it can’t avoid the third, and that’s what I’m going to focus on here.</p>
<p>There are three somewhat distinct reasons you might use pooling to answer (3).</p>
<p>First, you might use it as a replacement for supra-Bayesianism. I’m going to argue that if you do this, you also have to give up on Bayesianism across the board. Sometimes the recipient of expert opinion can reliably infer the evidence behind the opinion reliably. In those cases, regular Bayesianism implies that the recipient should update on just that evidence. And that regular, not supra, Bayesian principle is enough to dispose of pooling answers.</p>
<p>There are two more plausible uses for a pooling answer. Second, you might use it as a constraint on supra-Bayesianism. You could argue that if the values that (6) takes for various <span class="math inline">\(y, z\)</span> do not look like some kind of pooling function, that’s evidence the prior <span class="math inline">\(Cr_P\)</span> was irrational to start with. And third, you might use it as an approximation for supra-Bayesianism. It’s a lot easier to calculate linear or geometric means than to work out precisely the value of (6). Both of the last two uses are intuitively very plausible. One of the arguments of this paper is that they are, unfortunately, ultimately untenable. There just isn’t much use around here for pooling.</p>
<p>Pooling answers to (3) look a lot like conciliationist approaches to peer disagreement. Indeed, the form of pooling that uses linear averaging is sometimes thought to be a application of the Equal Weight View <span class="citation" data-cites="Elga2007">(<a href="#ref-Elga2007" role="doc-biblioref">Elga 2007</a>)</span>. Supra-Bayesian answers look like evidentialist approaches to peer disagreement. In particular, they look a lot like the Total Evidence View <span class="citation" data-cites="Lackey2010-LACWSW">(<a href="#ref-Lackey2010-LACWSW" role="doc-biblioref">Lackey 2010</a>)</span>. I’m going to use an even older motivation for them: the evidentialist approach to testimony defended by Frank <span class="citation" data-cites="Jackson1987">Jackson (<a href="#ref-Jackson1987" role="doc-biblioref">1987</a>)</span>. On Jackson’s view, testimony that <span class="math inline">\(p\)</span> is evidence that the speaker has evidence for <span class="math inline">\(p\)</span>. The way to rationally update on it depends on what kind of evidence you think the speaker is likely to have, given they’ve concluded <span class="math inline">\(p\)</span>, and what you would (rationally) do with that evidence. Typically, the answer is <em>Conclude p</em>. Jackson argues that while this is typical, it isn’t always the right answer. And it fails to be the right answer in just the cases you shouldn’t accept the speaker’s testimony.</p>
<p>So to simplify here, I’m going to look at some cases where Player can simply deduce, given one of the experts’ credences, what their evidence must have been. And then Player will update on that evidence. As we’ll see, different assumptions about how the evidence of the experts interacts leads to different answers to (3).</p>
<p>Two quick notes. First, I’m only going to look at cases where the experts are treated symmetrically. That’s a restriction, but it’s a useful one for letting us see the range of cases. Second, I’m going to be agreeing with <span class="citation" data-cites="EaswaranEtAl2016">Easwaran et al. (<a href="#ref-EaswaranEtAl2016" role="doc-biblioref">2016</a>)</span> a lot, especially in the first half of the paper. I’m ultimately going to consider some different kinds of cases to what they consider - but that’s a difference in focus, not a difference in conclusions. (They look at a bunch of kinds of cases that I won’t consider as well; it’s not like I’m going strictly beyond their work.) This paper is intended as a complement to theirs, not at all a substitute. But I think it’s a valuable complement, because I’ll show how some very realistic cases require a generalisation of their model, and make some suggestions for what that generalisation should look like.</p>
<section id="case-one-conditionally-independent-evidence" class="level3" data-number="0.1">
<h3 data-number="0.1" class="anchored" data-anchor-id="case-one-conditionally-independent-evidence"><span class="header-section-number">0.1</span> Case One: Conditionally Independent Evidence</h3>
<p>In our first case, the experts’ evidence is as independent as possible. Here’s a story to think about how that could be. Carmen has an urn with 50 marbles, 25 black and 25 white. She draws one at random and marks it with invisible ink. She has a scanner that can detect which marble is marked, but no one else can tell it apart from the other marbles. Let <span class="math inline">\(p\)</span> be the proposition that the marked marble is white - that’s what we’ll focus on from now on.</p>
<p>After selecting one marble to be marked, she puts together a jar containing the marked marble and 9 other marbles drawn at random from the urn. (I’ll use ‘urn’ for where Carmen keeps all the unused marbles, and ‘jar’ for what she constructs to show the experts.) She shows that to one of the experts, let’s say Ivy. She gets to inspect the jar, i.e., count how many marbles in it are white and black. She then reports to Player, but crucially not to Zack, her credence in <span class="math inline">\(p\)</span>.</p>
<p>In this example, the next thing that happens is that Carmen takes the jar back, removes the 9 unmarked marbles, puts them back in the urn, and draws a new set of 9 marbles. (That set may overlap with the first set of course.) She puts these 9 in the jar, along with the marked marble, and shows the jar to Zack. He examines the jar, and reports to Player his credence in <span class="math inline">\(p\)</span>.</p>
<p>Now in this case we can work out precisely how Player should update on these two pieces of information. When one expert reports a credence of <span class="math inline">\(x\)</span> in <span class="math inline">\(p\)</span>, Player can infer that they saw <span class="math inline">\(10x\)</span> white marbles. After all, what the expert knows is just that the marked marble is equally likely to be any of the marbles in the jar they see. So given <span class="math inline">\(Cr_I(p) = y\)</span> and <span class="math inline">\(Cr_Z(p) = z\)</span>, Player can infer how many white marbles were in each jar. And he can work out the probability of each of those jars turning up given <span class="math inline">\(p\)</span> and given <span class="math inline">\(\neg p\)</span>. And that’s enough to plug into Bayes’s Theorem to work out a posterior probability for <span class="math inline">\(p\)</span>. When you do that, you get the following result.</p>
<ol start="7" class="example" type="1">
<li><span class="math inline">\(Cr_P(p | Cr_I(p) = y \wedge Cr_Z(p) = z) = \frac{yz}{yz + (1-y)(1-z)}\)</span></li>
</ol>
<p>I’m not going to work through the derivation of this, because it’s a straightforward consequence of something I will derive below. If you do want to check it for yourself, the key input is that the probability of drawing <span class="math inline">\(x\)</span> white balls in <span class="math inline">\(t\)</span> draws without replacement from an urn with <span class="math inline">\(w\)</span> white balls and <span class="math inline">\(b\)</span> black balls is</p>
<p><span class="math display">\[
\frac{\binom{w}{x} \binom{b}{t-x}}{\binom{w+b}{t}}
\]</span></p>
<p>More importantly, (7) looks just like a special case of the central formula (Upco) that <span class="citation" data-cites="EaswaranEtAl2016">Easwaran et al. (<a href="#ref-EaswaranEtAl2016" role="doc-biblioref">2016</a>)</span> use. And that’s not surprising, since this case uses the same conditional independence assumption that they make through much of their paper. To say that <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are conditionally independent given <span class="math inline">\(C\)</span> is just to say that <span class="math inline">\(\Pr(A \wedge B | C) = \Pr(A | C)\Pr(B | C)\)</span>. In this case, any pair of claims about how many white balls are in the jars shown to Ivy and to Zack are conditionally independent, both conditional on <span class="math inline">\(p\)</span> and on <span class="math inline">\(\neg p\)</span>.</p>
<p>The right hand side of (7) also looks a lot like the geometric means described above. The big difference is that the square root signs have disappeared. And that makes a difference, because it means the result violates what <span class="citation" data-cites="BaccelliStewart2021">Baccelli and Stewart (<a href="#ref-BaccelliStewart2021" role="doc-biblioref">2021</a>)</span> call Unanimity. This principle requires that <span class="math inline">\(Cr_P(p | Cr_I(p) = y \wedge Cr_I(p) = y) = y\)</span>. If (7) is true then Unanimity is violated in every case except where <span class="math inline">\(y\)</span> equals 0, 0.5 or 1. But this is bad news for Unanimity, because the case for (7) in this case seems very strong. Player really knows how many white marbles were in each jar, and it’s just a bit of algebra to get from there to (7) via conditionalisation. And it’s very plausible that conditionalisation is the right way to update on evidence about how many marbles are in a jar. So any principle incompatible with (7) is false.</p>
<p>It turns out that varying how many marbles are in the urn Carmen starts with does not change (7). But changing the ratio of white marbles to black marbles in the urn does change the formula. If the proportion of the initial urn that is white is <span class="math inline">\(r\)</span>, then the general result is</p>
<ol start="8" class="example" type="1">
<li><span class="math inline">\(Cr_P(p | Cr_I(p) = y \wedge Cr_I(p) = z) = \frac{yz(1-r)}{yz(1-r) + (1-y)(1-z)r}\)</span></li>
</ol>
<p>Again, this isn’t a new result; <span class="citation" data-cites="EaswaranEtAl2016">Easwaran et al. (<a href="#ref-EaswaranEtAl2016" role="doc-biblioref">2016, 27</a>)</span> derive an even more general formula from which this falls out as a special case. But my way of deriving it is just different enough to be worth including.</p>
<p>Let <span class="math inline">\(I_x\)</span> be the disjunction of all possible evidence propositions that would lead Ivy to have credence <span class="math inline">\(x\)</span> in <span class="math inline">\(p\)</span>. In this case <span class="math inline">\(I_x\)</span> is a simple proposition that there are <span class="math inline">\(10x\)</span> white marbles in the jar, but we don’t need to assume that <span class="math inline">\(I_x\)</span> will be anything like that simple. Everything that follows about <span class="math inline">\(I_x\)</span> also holds for <span class="math inline">\(Z_x\)</span>, the disjunction of all possible evidence propositions that would lead Ivy to have credence <span class="math inline">\(x\)</span> in <span class="math inline">\(p\)</span>, but I won’t repeat the derivations. Since Player defers to Ivy, i.e., (4) is true, we have the following proof. (All credences are Player’s, so I’ll drop the subscripts.)</p>
<p><span class="math display">\[\begin{align*}
Cr(p | I_x) &amp;= x &amp;&amp;\therefore \\
Cr(p \wedge I_x) &amp;= x \cdot Cr(I_x) \\
&amp;= x (Cr(p \wedge I_x) + Cr(\neg p \wedge I_x)) &amp;&amp;\therefore \\
(1-x)Cr(p \wedge I_x) &amp;= x \cdot Cr(\neg p \wedge I_x)) &amp;&amp;\therefore \\
Cr(\neg p \wedge I_x)) &amp;= \frac{1-x}{x} Cr(p \wedge I_x) &amp;&amp;\therefore \\
Cr(I_x | \neg p) &amp;= \frac{(1-x)Cr(p)}{x\cdot Cr(\neg p)}Cr(I_x | p)
\end{align*}\]</span></p>
<p>So we know the ratio of <span class="math inline">\(Cr(I_x | p)\)</span> to <span class="math inline">\(Cr(I_x | \neg p)\)</span>. That will become useful in what follows. Assuming evidentialism, what matters for (6) is working out the value of <span class="math inline">\(Cr(p | I_y \wedge Z_z)\)</span>. But we now know enough to do that.</p>
<p><span class="math display">\[
Cr(p | I_y \wedge Z_z) = \frac{Cr(p \wedge I_y \wedge Z_z)}{Cr(I_y \wedge Z_z)}
\]</span></p>
<p>Using the general fact that <span class="math inline">\(X\)</span> is equivalent to <span class="math inline">\((p \wedge X) \vee (\neg p \wedge X)\)</span>, and that Player’s credences are probabilistic, so his credence in an exclusive disjunction equals the sum of the credence in the disjuncts, we know this equals.</p>
<p><span class="math display">\[
\frac{Cr(p \wedge I_y \wedge Z_z)}{Cr(p \wedge I_y \wedge Z_z) + Cr(\neg p \wedge I_y \wedge Z_z)}
\]</span></p>
<p>Since <span class="math inline">\(Cr(p \wedge X) = Cr(X | p)Cr(p)\)</span>, we can rewrite this as</p>
<p><span class="math display">\[
\frac{Cr(I_y \wedge Z_z | p) Cr(p)}{Cr(I_y \wedge Z_z | p)Cr(p) + Cr(I_y \wedge Z_z | \neg p)Cr(\neg p)}
\]</span></p>
<p>And since <span class="math inline">\(I_y\)</span> and <span class="math inline">\(Z_z\)</span> are independent given both <span class="math inline">\(p\)</span> and <span class="math inline">\(\neg p\)</span>, this becomes</p>
<p><span class="math display">\[
\frac{Cr(I_y| p) Cr(Z_z | p) Cr(p)}{Cr(I_y| p) Cr(Z_z | p) Cr(p) + Cr(I_y| \neg p) Cr(Z_z | \neg p) Cr(\neg p)}
\]</span></p>
<p>If we assume the initial value of <span class="math inline">\(Cr(p) = r\)</span>, and use the earlier derived fact that <span class="math inline">\(Cr(I_x | \neg p) = \frac{(1-x)r}{x(1-r)}Cr(p)\)</span> this becomes</p>
<p><span class="math display">\[
\frac{Cr(I_y| p) Cr(Z_z | p)r}{Cr(I_y| p) Cr(Z_z | p)r + \frac{(1-y)r}{y(1-r)} Cr(I_y| p) \frac{(1-z)r}{z(1-r)} Cr(Z_z | p) (1-r)}
\]</span> Now we can finally eliminate <span class="math inline">\(Cr(I_y| p) Cr(Z_z | p)r\)</span> from the top and bottom, so this becomes</p>
<p><span class="math display">\[
\frac{1}{1 + \frac{(1-y)(1-z)r}{yz(1-r)}}
\]</span></p>
<p>Or in other words</p>
<p><span class="math display">\[
\frac{yz(1-r)}{yz(1-r) + (1-y)(1-z)r}
\]</span></p>
<p>And that’s the completely general result when the evidence the experts has is conditionally independent of both <span class="math inline">\(p\)</span> and <span class="math inline">\(\neg p\)</span>, and Player starts with credence <span class="math inline">\(r\)</span> in <span class="math inline">\(p\)</span>.</p>
<p>But this case is surely rare. Experts typically have some training in common that isn’t shared by non-experts. So their reasons for having a credence in <span class="math inline">\(p\)</span> that differs from our prior will not be completely independent. <span class="citation" data-cites="EaswaranEtAl2016">Easwaran et al. (<a href="#ref-EaswaranEtAl2016" role="doc-biblioref">2016</a>)</span> note that sometimes we can adjust for the common evidence by conditionalising on the common evidence to come up with a new ‘prior’, or perhaps I should say ‘intermediate’ credence, <span class="math inline">\(r\)</span>, then applying this formula. This is slightly more general, but still not a lot. Part of what makes us non-experts be non-experts is that we don’t have this common training, so we can’t identify what’s common between the experts. Let’s see if we can come up with a slightly more general case.</p>
</section>
<section id="case-two-common-marbles" class="level3 page-columns page-full" data-number="0.2">
<h3 data-number="0.2" class="anchored" data-anchor-id="case-two-common-marbles"><span class="header-section-number">0.2</span> Case Two: Common Marbles</h3>
<p>In our second case, Carmen once again has an urn with 50 marbles, 25 black and 25 white. She draws one at random and marks it with invisible ink. She can tell which one this is, but no one else can. And <span class="math inline">\(p\)</span> is still the proposition that the marked marble is white - that’s what we’ll focus on from now on. After selecting the marble to be marked, she puts together a jar containing the marked marble and 9 other marbles drawn at random from the urn. She shows that to one of the experts, let’s say Ivy. She gets to inspect the jar, i.e., count how many marbles in it are white and black. She then reports to Player, but crucially not to Zack, her credence in <span class="math inline">\(p\)</span>.</p>
<p>So far, it’s just like the last case. But what happens next is (possibly) different. In this case, Carmen removes <span class="math inline">\(m\)</span> unmarked marbles from the jar, puts them back in the urn, and draws a new set of <span class="math inline">\(m\)</span> marbles to put in the jar. It’s all random, so this could include some of the marbles she just removed. She shows the jar to Zack, he inspects it, and reports his credence in <span class="math inline">\(p\)</span> to Player. And, crucially, player knows <span class="math inline">\(m\)</span>, the number of marbles that are in common between the jars. So <span class="math inline">\(m\)</span> is a measure of the independence of the experts’ opinions.</p>
<p>Once again, we can work out precisely what Player’s credence should be given <span class="math inline">\(m\)</span>, and the two credences. Unfortunately, it’s just a long formula that doesn’t seem to reduce nicely. But if you’ve got a machine that’s good at calculating hypergeometric distributions, and you dear reader are probably reading this paper on a machine that’s good at calculating hypergeometric distributions, it’s not that hard to calculate the values by brute force. I won’t list all the values, there are several hundred of them, but I’ll present them graphically here. (Note I’ll leave off the case where one or other expert announces a credence of 0 or 1; in that case Player knows whether <span class="math inline">\(p\)</span> is true, so the question of how to merge the credences is easy.)</p>
<p><img src="mixing-expert-opinion_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
<p>Here is how to read the graph. Each row corresponds to a partiular credence announced by Ivy; the credence is shown on the right. Each column corresponds to a partiular credence announced by Zack; that credence is shown on the top. The x-axis of the individual graphs shows the value for <span class="math inline">\(m\)</span>, the number of marbles removed. And the y-axis shows Player’s final credence in <span class="math inline">\(p\)</span>. There are more dots on some graphs than others because some combinations of Ivy credence, Zack credence and <span class="math inline">\(m\)</span> are impossible. The announced credences can’t, by the rules of the game, differ by more than <span class="math inline">\(0.1m\)</span>.</p>
<p>One notable feature of that graph is that as <span class="math inline">\(m\)</span> gets larger, the final credence tends to move away from 0.5; it tends to get more opinionated. Another notable feature, though probably not one you can see in this resolution, is that this move towards greater opinionation happens in a surprisingly linear fashion. To a first approximation, Player’s credence moves away from 0.5 roughly the same amount for each addition to <span class="math inline">\(m\)</span>, at least holding <span class="math inline">\(y\)</span> and <span class="math inline">\(z\)</span> fixed.</p>
<p>It’s not perfectly linear, but it’s much closer than I would have guessed looking at how really quite non-linear the inputs are. Let’s zoom in on a part of the graph to see this more vividly.</p>
<p><img src="mixing-expert-opinion_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672"></p>
<p>The curve in the bottom right panel is not really linear; it definitely curves downwards. But as you move your eye upwards and leftwards in the table, the curves look much much straighter. The panel where they both announce 0.7 is really remarkably straight. If we focus on the middle of the big graph, this is even more striking. (I’ve left off the cases where Zack announces a credence under 0.5 because those graphs are just mirror images of graphs already shown.)</p>
<p><img src="mixing-expert-opinion_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
<p>Why does this matter? Because pooling functions are easy to use, and the supra-Bayesian needs something to match that ease of use. It’s a cliche that for every problem there is a solution that is simple, intuitive, and wrong. And the version of the pooling approach that uses linear averages is very simple, very intuitive, and very wrong. The version that uses geometric averages strikes most people as less simple and intuitive (or maybe I’m just bad at explaining it), but it is less wrong. But still, sometimes simple, intuitive and wrong is exactly what you need! Computation is hard, life is short, precision is overrated. Why not just average if you are just looking to get something roughly right?</p>
<p>The supra-Bayesian can exploit the more-or-less linearity of the graphs above graphs to come up with an approximation to these ideal Bayesian credence. And the approximation isn’t that much harder to calculate than the geometric average. Intuitively, it works like this. If the experts have exactly the same evidence, we take the geometric average of their opinions.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> If the experts’ evidence is conditionally independent, we use the formula from <span class="citation" data-cites="EaswaranEtAl2016">Easwaran et al. (<a href="#ref-EaswaranEtAl2016" role="doc-biblioref">2016</a>)</span> that I rederived in the last section. In between, we just need a guess <span class="math inline">\(k\)</span> about what proportion of the evidence they share, and what is independent. And we use that guess to come up with an average of those two things, the geometric average and the formula for conditionally independent evidence. So our estimation of the new credence is this, where <span class="math inline">\(y\)</span> and <span class="math inline">\(z\)</span> are the announced credences, and <span class="math inline">\(k\)</span> is the measure of independence of the evidence.</p>
<div class="no-row-height column-margin column-container"><li id="fn3"><p><sup>3</sup>&nbsp;We are working with cases so far where there is a unique rational credence for each evidence, so if they have the same evidence they have the same credence, and which kind of averaging we use is redundant. What matters about the geometric average is how it enters into mixtures, as we’re about to see.</p></li></div><p><span class="math display">\[
(1-k)\frac{\sqrt{yz}}{\sqrt{yz} + \sqrt{(1-y)(1-z)}} + k\frac{yz}{yz + (1-y)(1-z)}
\]</span></p>
<p>Let’s check visually how this does against the exact calculations. In the graphs that follow, I’ll use circles for the ideally calculated posterior credences, and triangles for the estimates made using this formula.</p>
<p><img src="mixing-expert-opinion_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="672"></p>
<p>That looks pretty good. There is a tiny bit of separation in the bottom right panel, but otherwise the estimate tracks the calculated credences pretty closely. Let’s look at the middle of the graph.</p>
<p><img src="mixing-expert-opinion_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="672"></p>
<p>And all through here the dots are overlapping. That’s close enough. So at least in this special case, the supra-Bayesian can produce an estimate that is very close to the ideally calculated credence. So we don’t need to resort to pooling even as an approximation device.</p>
<p>But the simplifications here are dire. Here are six ways we might want to generalise the model.</p>
<ol type="1">
<li>Have the prior probabilities of <span class="math inline">\(p\)</span> and <span class="math inline">\(\neg p\)</span> vary.</li>
<li>Have more colors for the marbles, and have each expert announce credences over all the colors.</li>
<li>Have the person doing the merger be uncertain about <span class="math inline">\(k\)</span>.</li>
<li>Have the experts sample the jars they are given, not inspect them fully.</li>
<li>Have more than two experts.</li>
<li>Allow that some experts are more informed than others.</li>
</ol>
<p>The first two points are not that hard. I could produce a string of graphs for different priors over the colors, or for more colors, and the typical story is not that different to what we’ve seen so far. It just gets messy because we have more degrees of freedom than is consistent with a concise graphical display.</p>
<p>The next two points are harder. It’s not that they are harder to come up with the idea value. For any prior over <span class="math inline">\(k\)</span>, or sampling technique that’s available to the expert, it’s pretty easy to write code to come up with the optimal calculated credences. It’s rather that the number of degrees of freedom are so great that it gets a little harder to eyeball how good any given approximation is. The big point is that the posterior distribution of <span class="math inline">\(k\)</span> will usually be different to the prior. In extreme cases, the announced expert credences might rule out some hypotheses about <span class="math inline">\(k\)</span>. So it won’t just be a matter of calculating the values of the above formula for each value of <span class="math inline">\(k\)</span>, and averaging them out using the prior probabilities of <span class="math inline">\(k\)</span>. There is a lot of possible future research here.</p>
<p>Having more than two experts raises both computational questions, like what we’ve just discussed, and conceptual questions. Consider even what happens when we go to three experts. Imagine the balls are numbered, and say <span class="math inline">\(M_i\)</span> is the proposition that ball <span class="math inline">\(i\)</span> is numbered, and <span class="math inline">\(J_{i, e}\)</span> is that ball <span class="math inline">\(i\)</span> is in the jar shown to expert <span class="math inline">\(e\)</span>. To represent the degree of connectedness of one expert’s evidence to the other(s) in the two expert case, we really just need to specify one variable: <span class="math inline">\(\Pr(J_{i, 1} | J_{i, 2} \wedge \neg M_i)\)</span>. But in the three expert case, we need three variables to be specified.</p>
<ul>
<li><span class="math inline">\(\Pr(J_{i, 1} | J_{i, 2} \wedge J_{i, 3} \wedge \neg M_i)\)</span></li>
<li><span class="math inline">\(\Pr(J_{i, 1} | J_{i, 2} \wedge \neg J_{i, 3} \wedge \neg M_i)\)</span></li>
<li><span class="math inline">\(\Pr(J_{i, 1} | \neg J_{i, 2} \wedge J_{i, 3} \wedge \neg M_i)\)</span></li>
</ul>
<p>And if there are four experts, there are seven of these variables. And this number grows exponentially as the number of experts rises.</p>
<p>The point is not just that the compututations of the ideal supra-Bayesian credence require an exponentially increasing number of inputs as the number of experts rises. It’s that even thinking about how to approximate this ideal calculation, we need a good way to conceptualise this space whose dimensionality rises exponentially with the number of experts in a way that lets us even think about what a good approximation would look like. I don’t have an answer to this; it feels like a question for future research.</p>
<p>What I will try to make some headway on instead is the last question, what happens if we do not assume the experts are just as well informed as each other.</p>
</section>
<section id="case-three-differentially-informed-experts" class="level3" data-number="0.3">
<h3 data-number="0.3" class="anchored" data-anchor-id="case-three-differentially-informed-experts"><span class="header-section-number">0.3</span> Case Three: Differentially Informed Experts</h3>
<p>In our last case, one expert is better informed than the other. Carmen first fills the jar with the marked marble and 19 randomly chosen unmarked marbles. She flips a coin to decide which expert to show this jar to. They inspect the jar, and record their credence in <span class="math inline">\(p\)</span> to the nearest 0.1. (We’ll come back very soon to why this is rounded.) Carmen then removes 10 unmarked marbles from the jar, chosen at random, and then shows it to the other expert. They inspect it, and come up with a new credence in <span class="math inline">\(p\)</span>. Then both these recorded numbers are reported to Player, without any indication about who saw the larger jar and who saw the smaller one.</p>
<p>There is a weird thing in this setup in that one of the experts reports something other than their precise credence. The reason I set up the example this way is to make it impossible for the recipient of the expert opinion to infer who saw the smaller jar. If they both reported their actual credence, it would be possible for the recipient to be told one of them has credence 0.75 in <span class="math inline">\(p\)</span> and the other has credence 0.6. And then it would be obvious that the hearer should have credence 0.6 in <span class="math inline">\(p\)</span>, since that’s the credence of the more informed person. So I made the first person round to the nearest 0.1 to make it harder to make such inferences.</p>
<p>Given all that setup we can work out what Player’s credence in <span class="math inline">\(p\)</span> should be given the two announcements. (I’m rounding to three decimal places to save space.I’m leaving off the cases where one or other party announces an extremal credence - the hearer agrees with those credences, at least to three decimal places. And the ‘NA’ values are where it is impossible given the setup for those to be the announced values.)</p>
<div class="cell-output-display">
<table data-quarto-postprocess="true" class="table">
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">Ivy/Zack</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">0.1</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">0.2</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">0.3</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">0.4</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">0.5</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">0.6</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">0.7</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">0.8</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">0.9</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.1</td>
<td style="text-align: right;">0.100</td>
<td style="text-align: right;">0.103</td>
<td style="text-align: right;">0.100</td>
<td style="text-align: right;">0.100</td>
<td style="text-align: right;">0.100</td>
<td style="text-align: right;">0.100</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
</tr>
<tr class="even">
<td style="text-align: right;">0.2</td>
<td style="text-align: right;">0.103</td>
<td style="text-align: right;">0.200</td>
<td style="text-align: right;">0.208</td>
<td style="text-align: right;">0.203</td>
<td style="text-align: right;">0.202</td>
<td style="text-align: right;">0.200</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
</tr>
<tr class="odd">
<td style="text-align: right;">0.3</td>
<td style="text-align: right;">0.100</td>
<td style="text-align: right;">0.208</td>
<td style="text-align: right;">0.300</td>
<td style="text-align: right;">0.320</td>
<td style="text-align: right;">0.325</td>
<td style="text-align: right;">0.348</td>
<td style="text-align: right;">0.500</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
</tr>
<tr class="even">
<td style="text-align: right;">0.4</td>
<td style="text-align: right;">0.100</td>
<td style="text-align: right;">0.203</td>
<td style="text-align: right;">0.320</td>
<td style="text-align: right;">0.400</td>
<td style="text-align: right;">0.439</td>
<td style="text-align: right;">0.500</td>
<td style="text-align: right;">0.652</td>
<td style="text-align: right;">0.800</td>
<td style="text-align: right;">0.900</td>
</tr>
<tr class="odd">
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.100</td>
<td style="text-align: right;">0.202</td>
<td style="text-align: right;">0.325</td>
<td style="text-align: right;">0.439</td>
<td style="text-align: right;">0.500</td>
<td style="text-align: right;">0.561</td>
<td style="text-align: right;">0.675</td>
<td style="text-align: right;">0.798</td>
<td style="text-align: right;">0.900</td>
</tr>
<tr class="even">
<td style="text-align: right;">0.6</td>
<td style="text-align: right;">0.100</td>
<td style="text-align: right;">0.200</td>
<td style="text-align: right;">0.348</td>
<td style="text-align: right;">0.500</td>
<td style="text-align: right;">0.561</td>
<td style="text-align: right;">0.600</td>
<td style="text-align: right;">0.680</td>
<td style="text-align: right;">0.797</td>
<td style="text-align: right;">0.900</td>
</tr>
<tr class="odd">
<td style="text-align: right;">0.7</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">0.500</td>
<td style="text-align: right;">0.652</td>
<td style="text-align: right;">0.675</td>
<td style="text-align: right;">0.680</td>
<td style="text-align: right;">0.700</td>
<td style="text-align: right;">0.792</td>
<td style="text-align: right;">0.900</td>
</tr>
<tr class="even">
<td style="text-align: right;">0.8</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">0.800</td>
<td style="text-align: right;">0.798</td>
<td style="text-align: right;">0.797</td>
<td style="text-align: right;">0.792</td>
<td style="text-align: right;">0.800</td>
<td style="text-align: right;">0.897</td>
</tr>
<tr class="odd">
<td style="text-align: right;">0.9</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">0.900</td>
<td style="text-align: right;">0.900</td>
<td style="text-align: right;">0.900</td>
<td style="text-align: right;">0.900</td>
<td style="text-align: right;">0.897</td>
<td style="text-align: right;">0.900</td>
</tr>
</tbody>
</table>


</div>
<p>And a striking thing about this table is how close it comes to verifying a strong form of what <span class="citation" data-cites="Levinstein2015">Levinstein (<a href="#ref-Levinstein2015" role="doc-biblioref">2015</a>)</span> calls Thrasymachus’ Principle. The hearer defers to the expert with the strongest view, i.e., the view that’s furthest from the prior. In contemporary terms, the hearer listens to the expert with the hottest take. It isn’t an unvarnished form of that. When one says 0.5 and the other says 0.6 you end up with 0.561, not 0.6. But that’s in large part because there’s a good chance that the person who said 0.6 was merely rounding up as the result of a coin flip. In general, the rule in this case is find the expert credence that is furthest from the prior, and adopt it.</p>
<p>There is a reason that a case like this should follow Thrasymachus’ Principle. If the experts are rational, hotter takes should correspond to stronger evidence. And while it isn’t impossible for the person with more evidence to have in a sense weaker evidence, the extra evidence may be full of defeaters for the first obtained evidence, it is pretty unlikely. In general, if someone is worthy of deference, and they have a strong view, they have strong evidence. If someone else has a weaker view, i.e., a view closer to the prior, the best explanation is that they simply don’t have the evidence that the person with stronger view does.</p>
<p>So again, we shouldn’t pool the opinions in any interesting sense. The table shows the optimal response by supra-Bayesian lights. And the simple approximation is, “When one expert has clearly stronger views, listen to them. Otherwise take the geometric mean.”</p>
</section>
<section id="summary" class="level3" data-number="0.4">
<h3 data-number="0.4" class="anchored" data-anchor-id="summary"><span class="header-section-number">0.4</span> Summary</h3>
<p>Let’s take stock of what’s been covered so far.</p>
<ul>
<li>I’ve argued against all three uses of pooling answers to the question of how to merge expert opinions. Sometimes the pooling answer is clearly wrong, often it won’t be a good constraint on priors, and there are better ways to approximate the correct supra-Bayesian answer.</li>
<li>I’ve connected supra-Bayesianism to some familiar positions in epistemology, the view on testimony in <span class="citation" data-cites="Jackson1987">Jackson (<a href="#ref-Jackson1987" role="doc-biblioref">1987</a>)</span> and the view on disagreement in <span class="citation" data-cites="Lackey2010-LACWSW">Lackey (<a href="#ref-Lackey2010-LACWSW" role="doc-biblioref">2010</a>)</span>.</li>
<li>I’ve shown that if you take that approach, that conditionalising on someone else’s credence is just conditionalising on the fact that they have evidence that rationalises such a credence by their lights, then the principle <span class="citation" data-cites="EaswaranEtAl2016">Easwaran et al. (<a href="#ref-EaswaranEtAl2016" role="doc-biblioref">2016</a>)</span> recommend for updating on the credences of others follows directly from the assumptions that each expert is independently worthy of deference, and the evidence the experts have is conditionally independent.</li>
<li>I’ve developed a toy example that lets us think about cases where the hearer doesn’t know which parts of the evidence are in common, but does know how much is in common.</li>
<li>And I’ve shown that in that case, the correct supra-Bayesian answer is nicely approximated by a linear average of two familiar formulas.</li>
<li>I developed a toy example that lets us think about the case where one expert is known to be more informed, but we aren’t sure which it is.</li>
<li>And in that case I showed that what <span class="citation" data-cites="Levinstein2015">Levinstein (<a href="#ref-Levinstein2015" role="doc-biblioref">2015</a>)</span> calls Thrasymachus’ Principle is approximately right; we should defer to the ‘stronger’, i.e., more opinionated, expert.</li>
</ul>
<p>At the end of section 2 I mentioned six ways in which we might make the model even more general. This is very much not meant to be the last word. But I suspect these kinds of examples can be used to provide useful approximations, or guides, to real life situations where we know something about the relationship between the experts. The general lesson is that by looking at toy cases, we can provide practical advice for how to emulate, or at least approximate, the supra-Bayesian approach for merging expert opinion. And this advice will be better than the advice that anyone who ignores the relationship between the experts can offer.</p>
<p>But there is one last kind of relationship between experts that I haven’t made any progress on modeling, and it is a big one. What should we say about cases where the experts know each others credences? This is an old and, to my mind, open question. For reasons that trace back to <span class="citation" data-cites="Aumann1976">Aumann (<a href="#ref-Aumann1976" role="doc-biblioref">1976</a>)</span>, in anything like the kind of model I’ve used here, if the experts know each other’s credences, they have to agree. And someone who knows both credences should agree with them. But the real world obviously contains experts who do agree to disagree. What to say about those cases is the biggest open questions around here, and I’m not sure whether this approach can help. <span class="citation" data-cites="Gallow2018">Gallow (<a href="#ref-Gallow2018" role="doc-biblioref">2018</a>)</span> ends his paper by raising doubts about whether it is rational to be disposed to defer to two different experts. I’m not worried about that in general; I’ve described three very different kinds of cases where it is rational. But I suspect one could not be rationally disposed to defer to two experts who one knows are themselves disposed to agree to disagree. That, however, is a story for another paper. This paper has described a number of cases where the hearer knows something the experts doesn’t know: namely what other experts think. And it has described both precise and approximate answers for what to do in those interesting cases.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Aumann1976" class="csl-entry" role="listitem">
Aumann, Robert J. 1976. <span>“Agreeing to Disagree.”</span> <em>The Annals of Statistics</em> 4 (6): 1236–39. <a href="https://doi.org/10.1214/aos/1176343654">https://doi.org/10.1214/aos/1176343654</a>.
</div>
<div id="ref-BaccelliStewart2021" class="csl-entry" role="listitem">
Baccelli, Jean, and Rush T. Stewart. 2021. <span>“Support for Geometric Pooling.”</span> <em>Review of Symbolic Logic</em> forthcoming. <a href="https://doi.org/doi:10.1017/S1755020320000416">https://doi.org/doi:10.1017/S1755020320000416</a>.
</div>
<div id="ref-Bradley2017" class="csl-entry" role="listitem">
Bradley, Richard. 2017. <span>“Learning from Others: Conditioning Versus Averaging.”</span> <em>Theory and Decision</em> 85 (1): 5–20. <a href="https://doi.org/10.1007/s11238-017-9615-y">https://doi.org/10.1007/s11238-017-9615-y</a>.
</div>
<div id="ref-EaswaranEtAl2016" class="csl-entry" role="listitem">
Easwaran, Kenny, Luke Fenton-Glynn, Christopher Hitchcock, and Joel D. Velasco. 2016. <span>“Updating on the Credences of Others: Disagreement, Agreement, and Synergy.”</span> <em>Philosophers’ Imprint</em> 16 (11): 1–39.
</div>
<div id="ref-Elga2007" class="csl-entry" role="listitem">
Elga, Adam. 2007. <span>“Reflection and Disagreement.”</span> <em>No<span>û</span>s</em> 41 (3): 478–502. <a href="https://doi.org/10.1111/j.1468-0068.2007.00656.x">https://doi.org/10.1111/j.1468-0068.2007.00656.x</a>.
</div>
<div id="ref-Gallow2018" class="csl-entry" role="listitem">
Gallow, J. 2018. <span>“No One Can Serve Two Epistemic Masters.”</span> <em>Philosophical Studies</em> 175 (10): 2389–98. <a href="https://doi.org/10.1007/s11098-017-0964-8">https://doi.org/10.1007/s11098-017-0964-8</a>.
</div>
<div id="ref-Jackson1987" class="csl-entry" role="listitem">
Jackson, Frank. 1987. <em>Conditionals</em>. Blackwell: Oxford.
</div>
<div id="ref-Lackey2010-LACWSW" class="csl-entry" role="listitem">
Lackey, Jennifer. 2010. <span>“What Should We Do When We Disagree.”</span> <em>Oxford Studies in Epistemology</em> 3: 274–93.
</div>
<div id="ref-Levinstein2015" class="csl-entry" role="listitem">
Levinstein, Benjamin Anders. 2015. <span>“With All Due Respect: The Macro-Epistemology of Disagreement.”</span> <em>Philosophers’ Imprint</em> 15 (13): 1–20.
</div>
<div id="ref-RussellEtAl2015" class="csl-entry" role="listitem">
Russell, Jeffrey Sanford, John Hawthorne, and Lara Buchak. 2015. <span>“Groupthink.”</span> <em>Philosophical Studies</em> 172 (5): 1287–1309. <a href="https://doi.org/10.1007/s11098-014-0350-8">https://doi.org/10.1007/s11098-014-0350-8</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>