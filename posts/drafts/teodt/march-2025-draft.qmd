---
title: "Why Do Decision Theory?"
abstract: |
  What question are decision theorists trying to answer, and why is it worth trying to answer it? A lot of philosophers talk as if the aim of decision theory is articulate a standard for making decisions well, and the reason to do this is to help us make better decisions. I disagree on both fronts. The aim of the decision theory is, or at least should be, to describe how a certain kind of idealised decider does in fact decide. The reason to do this is that this idealisation, like many other idealisations, helps generate explanations of real-world behaviour. We shouldn't do what these ideal deciders do, or try to be more like them, because a lot of what they do only makes sense because of the differences between us and them. Still, sometimes those differences are small enough that they can be ignored in explanations, and that's when decision theory is useful.
date: March 15 2025
author:
  - name: Brian Weatherson 
    url: http://brian.weatherson.org
    affiliation: University of Michigan
    affiliation_url: https://umich.edu
    orcid_id: 0000-0002-0830-141X
citation: false
categories:
  - games and decisions
  - unpublished
  - in progress
bibliography: ../../../brian-quarto.bib
draft: true
csl: ../../../chicago-with-note.csl
format:
  html: default
  docx:
      reference-doc: ../../../quarto-articles-template.docx
  pdf:
      output-file: "Why Do Decision Theory"
      include-after-body: 
        text: |
           \noindent Unpublished. Posted online in 2025.
---

# Introduction {#sec-intro}

What are we doing when we do decision theory? What questions are decision theorists trying to answer? And what do we gain by knowing those answers?

Most philosophical decision theorists would answer these questions with something like the view I'll call **prescriptivism**. We're trying to say how people should ideally decide, and knowing how people should decide will help people make better decisions. On this model, the decision theorist is like a high school coach saying "Here's how the good ones make decisions, now go out and act like them."

I'm going to argue against prescriptivism, and in favour of **explanationism**. According to explanationism, decision theory is primarily a descriptive project. It says this is how people actually make decisions, at least approximately, some of the time. What we gain from this is access to a certain kind of explanation of various social phenomena. On this model, the decision theorist is like a high school science teacher saying "Here's how things work in a very simplified model, but even this simplified model shows you something about the world."

The big difference between the two views comes in how they treat the idealisations involved in decision theory. I'll spend some time in this paper on just what those idealisations are, though hopefully the point that there are some is common ground. On the prescriptivist view, when we say that a decision maker ideally does X, we mean that doing X is perfect, and we should aim to be a more perfect deciders. On the explanationist view, the idealisations are models.^[Whether they are what @Weisberg2007 calls "Galilean idealisations" or "minimal idealisations" depends on just what use they are being put to. The ones that I'm going to talk about are primarily the latter.] These models are not standards of perfection. We don't think the fact that molecules in the toy model used to derive the ideal gas law are point-sized mean that having zero volume is a perfection, or that it is better for molecules to be smaller. It's just that their size is unimportant for the phenomena we're explaining, and so we abstract away from it.

I'll start with two reasons for rejecting the prescriptivist view. One is that it does not treat like cases alike. In particular, it makes a distinction between empirical uncertainty and arithmetic uncertainty that it should not, were it a prescriptive theory. The second is that it would be bad to resemble the 'ideal' in some respects. To play its prescriptive role, decision theory would have to be supplemented with a theory about which aspects of the ideal are and are not worthy of emulation. There isn't much work on this question, and it isn't at all clear that it would be easier to solve it than to directly provide workable advice.

Setting out the objections to prescriptivism is relatively easy. Defending explanationism is harder going. There are three obvious objections. The first is that it's a bad description, since people obviously don't act the way decision theory says they do. This, I think, is a fairly weak objection and I won't spend much time on it. People do not act exactly like the theory says, but no model describes exactly how the subject behaves. As the cliche goes, all models are wrong, but some models are useful.

This leads to the second objection, which is much more worrying. This model, says the objector, is not in fact useful. Sure it tells us that people who prefer vanilla ice cream are more likely to order it. But we didn't need a whole field of philosophy to tell us that. What are the interesting explanations the theory offers? Here I follow a suggestion from Kate @Vredenburgh2024. The interestiing explanations around here are not individual, but social. Vredenburgh uses the model of segregation in @Schelling1971 as her main example.^[This is also used as one kind of paradigm model by @MWeisberg2013, so it clearly fits in nicely with the picture of decision theory as modeling. A key point that Vredenburgh makes is that the kind of functional states that decision theory uses are particularly apt for use in explanation here because we want to stress what's common to the actors in a model like this, even if the functional states are realised differently in different actors.]

I'm going to focus on a closely related but distinct class of explanations, what I'll call **reflexive explanations**. A reflexive explanation is one where the fact that agents in the model believe that the model is correct is partially responsible for the model working. Most game-theoretic explanations are reflexive in this sense. The main example I'll use is the model of the used car market that George @Akerlof1970 developed, though I'll also look at some recent work on the software industry. In both cases I'll argue that decision theory is a vital input into interesting explanations.

The third objection is that if decision theory earns its keep in the explanation of empirical regularities, like the surprisingly low price of used cars, it's odd that it is such an a priori discipline. Here the fact that it plays a role in explanations that are reflexive will be crucial. It's only the fact that decision theory is putatively a theory of rational choice that makes it fit to enter into reflexive explanations.

[Add paragraph about Roussos and other predecessors.]

# Two Initial Objections {#sec-two}

One critic reads the introduction and says that the task I've set is too easy. I'm asking what we do when we do decision theory, and he says that's simple. We're trying to say what _rational_ choice is. Don't I know what rationality is, he demands. No, I say, I don't. And I'll say more in @sec-two-cases about why I find this so unclear.

Another critic says that the task is too hard. Look at the range of various theories of decision out there on the market, he says. At this point he produces a paper where he provides a short summary of the theories put forward by Lara @BuchakRisk, Arif @Ahmed2014, Ben Levinstein and Nate Soares [-@LevinsteinSoares2020], William @Harper1986, James @Joyce1999, Frank @Arntzenius2008, Johan @Gustafsson2011, Ralph @Wedgwood2013a, Dmitri @Gallow2020, Abelard @Podgorski2022, David @Barnett2022, Jack @Spencer2023 and Melissa @Fuscond. The paper goes on to provide, for each pair of views, a case where they disagree, along with his verdict about which theory gets the case right. It's not for the faint of heart. How, he demands, can I find something in common between those?

There are two replies to such a critic. First, intuitively these theories disagree. That suggests that there is a common question to which they are offering competing answers. My job is to find that question. Second, amidst this flurry of disagreement, there are points of agreement. I'll focus (also in @sec-two-cases) on two cases where they basically all agree. I say 'basically' because Buchak puts forward a family of rivals to orthodox theories, and the views she calls risk-seeking don't agree with everyone else on one of the cases. But the risk-averse views, which are her primary focus, do agree with all the other views listed.

It's going to turn out those two cases alone are enough to raise problems for prescriptivism, and indeed to make it a bit mysterious what we could be up to when we do decision theory.

# Clarifying the Views {#sec-clarify}

Prescriptivism and Explanationism are views about why we do decision theory. They are views about the reasons for doing decision theory. Like all questions about reasons, they can be read as questions about justifying reasons, or about motivating reasons. I'm interested in both, but this paper is primarily about justifying reasons. There is an interesting analogy to be drawn between the view that explanationism is the right theory of motivating reasons and varieties of hermeneutic fictionalism [@sep-fictionalism ยง2.2], but I'll leave that for another day. For now the view is about what is a good reason to do decision theory, and my argument is that prescriptivism provides a bad reason, while explanationism provides a good reason.

I've stated these two views fairly informally so far; let's make them more precise. Both of them are conjunctions of two related but in principle distinct theses. First prescriptivism, which is **P1** and **P2**:

P1
:    Decision theory describes what ideal deciders are like, and provides a standard of evaluation for actual deciders: good deciders resemble the ideal.

P2
:    The point of doing decision theory is to provide guidance and advice for actual deciders. By seeing the ideal more clearly, actual deciders can improve by coming to resemble it in more respects.

P1 says that the kind of ideal is a standard of perfection, and P2 says that describing that standard is to provide useful advice. In place of those, explanationism offers to contrary theses, **E1** and **E2**:

E1
:    Decision theory describes what ideal deciders are like, and predicts that in suitable circumstances, actual deciders will resemble them.

E2
:    The point of doing decision theory is to provide an input into explanations of social phenomena, in cases where actual deciders behave sufficiently similarly to ideal deciders.

The ideal is a kind of model, and like all good models, it is a useful input into good explanations.

There is a third view which is interesting but I won't get into here. It's put forward by David Lewis, but unlike almost everything else Lewis said, it hasn't received much commentary. He held that the "central question of decision theory is: which choices are the ones that serve oneโs desires according to one's beliefs?" [@Lewis-Gorman-10071979 472]. That's I think different from both P1 and E1, though it's perhaps closer to E1. The reason this activity is philosophically interesting, says Lewis, is rather different from both P2 and E2. For Lewis, a central role for decision theory is supplying a theory of constitutive rationality to an account of mental content [@Lewis1994b 321-2]. I think the resulting theory is too idealised to help there, and that's before we get to questions about whether we should accept the approach to mental content that requires constitutive rationality. Lewis's view also requires that we can cleanly factorise the theory of rationality into a theory of rational belief, a theory of rational desire, and a theory of rationally acting to serve one's desires given one's beliefs. Recent philosophical work on moral motivation (e.g., @Markovits2014) and on inquiry (e.g., @Friedman2020) leave me rather sceptical that such a factorisation is possible. But that's a story for another time; for now I just want to flag that there are interesting ways to reject both prescriptivism and explanationism.

# Two Cases {#sec-two-cases}

## Case One: Betting

Chooser has \$110, and is in a sports betting shop. There is a basketball game about to start, between two teams they know to be equally matched. Chooser has three options: bet the \$110 on Home, bet it on Away, keep money. If they bet and are right, they win \$100 (plus get the money back they bet), if they are wrong, they lose the money. Given standard assumptions about how much Chooser likes money, all the decision theories I'm discussing say Chooser should not bet.

From this it follows that decision theory is not in the business of answering this question: *What action will produce the best outcome?*. We know, and so does Chooser, that the action that produces the best outcome is to bet on the winning team. Keeping their money in their pocket is the only action they know will be sub-optimal. And it's what decision theory says to do.

This is to say, decision theory is not axiology. It's not a theory of evaluating outcomes, and saying which is best. Axiology is a very important part of philosophy, but it's not what decision theorists are up to. So what are they up to? The next case makes this question more perplexing.

## Case Two: Salesman

A much studied class of problems has this form: given some points on a map, find the shortest path through all of them. Julia @Robinson1949 called this the travelling salesman problem.^[For a thorough history of the problem, see @Schrijver2005. For an accessible history of the problem, which includes these references, see @wiki-salesman.] I'll start with the version that uses the 257 points shown on @fig-map.

```{r}
#| echo: false
#| warning: false
#| message: false 
#| cache: false
#| label: fig-map
#| fig-cap: "257 American cites; our task is to find the shortest path that goes through all of them."

require(tidyverse)
require(TSP)
require(maps)
require(wesanderson)

point_col <- wes_palette("AsteroidCity1")[3]

theme_map <- function(base_size=9, base_family="") {
  require(grid)
  theme_bw(base_size = base_size, base_family = base_family)
  theme(axis.line = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank(),
        panel.background = element_blank(),
        panel.border = element_blank(),
        panel.grid = element_blank(),
        panel.spacing = unit(0, "lines"),
        plot.background = element_blank(),
        legend.justification = c(0,0),
        legend.position = c(0,0)
        )
}

theme_set(theme_map())

all_states <- map_data("state") %>% 
  group_by(region) %>% 
  tally() %>% 
  select(state = region)

all_states$code <- c("AL", "AZ", "AR", "CA", "CO", "CT", "DE", "DC", "FL", "GA",
                     "ID", "IL", "IN", "IA", "KS", "KY", "LA", "ME", "MD", "MA", 
                     "MI", "MN", "MS", "MO", "MT", "NE", "NV", "NH", "NJ", "NM", 
                     "NY", "NC", "ND", "OH", "OK", "OR", "PA", "RI", "SC", "SD", 
                     "TN", "TX", "UT", "VT", "VA", "WA", "WV", "WI", "WY")

used_states <- 1:49

long_states <- all_states$state[used_states]
short_states <- all_states$code[used_states]

data("USCA312")
data("USCA312_GPS")

cities <- as_tibble(as.matrix(USCA312))

city_numbers <- tibble(
  id = 1:312,
  thecities = colnames(cities)
	) |> 
  mutate(used_city = case_when(
                       str_sub(thecities, -2) %in% short_states ~ 1,
                       TRUE ~ 0
                       )
        )

the_city_numbers <- filter(city_numbers, used_city == 1)$id

our_cities <- cities |> 
  select(all_of(the_city_numbers)) |>
  slice(the_city_numbers)

our_gps <- USCA312_GPS |> 
  slice(the_city_numbers) |> 
  rowid_to_column()

city_matrix <- as.matrix(our_cities)

rownames(city_matrix) <- filter(city_numbers, used_city == 1)$thecities

## Best tour
load("/Users/weath/Documents/quarto-articles/posts/drafts/teodt/tour_line.RData")

# Turn tour to map path
paths <- tribble(
  ~step, 
  ~property, 
  ~rowid, 
  ~long, 
  ~lat
)

for (i in 1:nrow(our_gps)){
  x <- tour_line[i]
  first_city <- our_gps %>% slice(x)
  paths <- paths %>%
    add_row(step = i, 
            property = "from", 
            rowid = first_city$rowid[1], 
            long = first_city$long[1], 
            lat = first_city$lat[1])
}

x <- tour_line[1]

paths <- paths |>
   add_row(step = 24, 
           property = "from", 
           rowid = our_gps$rowid[x], 
           long = our_gps$long[x], 
           lat = our_gps$lat[x])

state_map_data <- map_data("state") |>
  filter(region %in% long_states) 

tour_map <- ggplot(state_map_data, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", 
               colour = "grey90") + 
  geom_point(data = our_gps |> select(long, lat), 
             aes(x = long, y = lat), 
             size = 0.25, 
             color = point_col,
             inherit.aes = FALSE) +
  coord_quickmap() +
  labs(x = "") +
  theme(axis.title.x = element_text())

tour_map
```

The task is to find the shortest path through those 257 cities.^[The 257 cities are the cities in the lower 48 states from the 312 cities in North America that John @Burkhart2011 mapped in his dataset USCA312.]

All of the decision theories the critic described in @sec-two, and as far as I know every competitor to them in the philosophical literature, say the thing to do here is to draw whichever of the 256! possible paths is shortest. That is not particularly helpful advice. Unless you know a lot about problems like this, you can't draw the shortest path through the map. More precisely, you can't draw it as such. You can't draw it in the way that you can't enter the correct code on a locked phone [@MandelkernEtAl2017]. 

One of the striking things about this puzzle is that it turns out there are some helpful things that can be said. One helpful bit of advice to someone trying to solve a problem like this is to use a Farthest Insertion Algorithm.^[To implement both this algorithm and the optimisation I'll mention below, I've used the TSP package by Michael Hashler and Kurt Hornik [-@HashlerHornik2007]. The description of the two steps owes a lot to their summaries in the package documentation.] Insertion algorithms say to start with a random city, then add cities to the path one at a time, at each time finding the point to insert the city into the existing path that adds the least distance. The Farthest Insertion Algorithm says that the city added at each stage is the one farthest from the existing path. Insertion algorithms in general produce pretty good paths in a very short amount of time - at least on normal computers. And the Farthest Insertion Algorithm is, most of the time, the best Insertion Algorithm to use. @fig-farthest shows the result of one output of this algorithm.^[The algorithm is silent on which city you start with, and usually chooses this randomly.]

```{r}
#| echo: false
#| cache: true
#| warning: false
#| message: false 
#| label: fig-farthest
#| fig-cap: "An output of the Farthest Insertion Algorithm, with a length of 21075 miles."

theme_set(theme_map())
tour_line <- solve_TSP(as.TSP(city_matrix), 
         method = "farthest_insertion", start = 1)

paths <- tribble(
  ~step, ~property, ~rowid, ~long, ~lat
)

for (i in 1:nrow(our_gps)){
  x <- tour_line[i]
  first_city <- our_gps |>
      slice(x)
  paths <- paths |>
    add_row(step = i, 
            property = "from", 
            rowid = first_city$rowid[1], 
            long = first_city$long[1], 
            lat = first_city$lat[1])
}

x <- tour_line[1]

paths <- paths |>
    add_row(step = 1 + nrow(our_gps), 
            property = "from", 
            rowid = our_gps$rowid[x], 
            long = our_gps$long[x], 
            lat = our_gps$lat[x])

# Way to automatically generate maps
# Change this to make the others change, though note that they need to be not cached

make_map <- function(the_data, the_gps, the_path){
  ggplot(the_data, 
         aes(long, 
             lat, 
             group = group)) +
    geom_polygon(fill = "white", 
                 colour = "grey90") + 
    geom_point(data = our_gps |>
                 select(
                   long, 
                   lat
                   ), 
               aes(
                 x = long, 
                 y = lat
                 ), 
               size = 0.25, 
               color = point_col,
               inherit.aes = FALSE) +
    geom_path(data = the_path |>
                select(
                  long, 
                  lat
                  ), 
              aes(
                x = long, 
                y = lat), 
              inherit.aes = FALSE, 
              colour = point_col, 
              alpha = 0.2) + 
    coord_quickmap() +
    labs(x = "") +
    theme(axis.title.x = element_text())
}

tour_map <- make_map(
  state_map_data,
  our_gps,
  paths
  )
tour_map
```

The path in @fig-farthest is not bad, but with only a bit of extra computational work, one can do better. A fairly simple optimisation algorithm takes a map as input, and then deletes pairs of edges at a time, and finds the shortest path of all possible paths with all but those two edges. The process continues until no improvements can be made by deleting two edges at a time, at which point you've found a somewhat resilient local minimum. @fig-two-opt is the output from applying this strategy to the path in @fig-farthest.

```{r}
#| echo: false
#| cache: false
#| label: fig-two-opt
#| fig-cap: "The output of an optimisation process, which reduced the path length to 20891 miles."
#| warning: false
#| message: false 

theme_set(theme_map())
tour_line <- solve_TSP(as.TSP(city_matrix), 
                       method = "farthest_insertion", 
                       start = 1)
tour_line <- solve_TSP(as.TSP(city_matrix), 
                       method = "two_opt", 
                       tour = tour_line)

paths <- tribble(
  ~step, ~property, ~rowid, ~long, ~lat
)

for (i in 1:nrow(our_gps)){
  x <- tour_line[i]
  first_city <- our_gps |>
    slice(x)
  paths <- paths |>
    add_row(step = i, 
            property = "from", 
            rowid = first_city$rowid[1], 
            long = first_city$long[1], 
            lat = first_city$lat[1])
}

x <- tour_line[1]

paths <- paths|>
  add_row(step = 1 + nrow(our_gps), 
          property = "from", 
          rowid = our_gps$rowid[x], 
          long = our_gps$long[x], 
          lat = our_gps$lat[x])


tour_map <- make_map(
  state_map_data,
  our_gps,
  paths
  )
tour_map
```

This optimisation tends to produce paths that look a lot like the original, but are somewhat shorter. For most practical purposes, the best advice you could give someone faced with a problem like this is to use a Farthest Insertion Algorithm, then optimise it in this way. Or, if they have a bit more time, they could do this a dozen or so times, and see if different starting cities led to slightly shorter paths.

While this is good advice, and indeed it's what most people should do, it's not typically what is optimal to do. For that reason, it's not what our nine decision theories would say to do. If one had unlimited and free computing power available, hacks like these would be pointless. One would simply look at all the possible paths, and see which was shortest. I do not have free, unlimited computing power, so I didn't do this. Using some black box algorithms I did not particularly understand, I was able to find a shorter path, however. It took some time, both of mine and my computer's, and for most purposes it would not have been worth the hassle of finding it. Still, just to show it exists, I've plotted it as @fig-best.


```{r}
#| echo: false
#| cache: false
#| label: fig-best
#| warning: false
#| message: false
#| fig-cap: "The shortest path I could find, with a distance of 20301 miles."

my_list <- as.integer(unlist(strsplit("0,84,59,240,13,198,121,58,102,89,170,20,212,135,231,127,136,107,147,17,151,97,24,142,162,228,87,229,194,206,116,138,244,158,61,108,207,44,54,11,132,9,55,143,26,86,103,47,117,7,96,216,46,251,95,184,69,179,250,174,153,183,242,15,99,119,110,181,248,4,249,164,10,234,71,148,109,152,161,246,222,42,33,150,137,149,100,219,252,175,78,34,30,38,123,130,134,57,173,171,12,16,144,36,32,168,235,2,208,239,25,226,186,35,74,254,167,223,245,39,1,51,256,45,8,56,221,60,98,50,124,129,31,146,159,77,230,118,104,145,83,125,232,6,65,81,19,189,120,106,18,92,112,215,90,49,115,178,139,210,94,133,187,163,28,43,238,62,218,192,53,220,111,82,237,156,73,247,196,233,113,114,191,126,157,213,214,64,243,41,105,67,185,70,225,68,193,140,190,79,141,27,166,180,211,23,93,101,37,169,155,197,176,29,217,241,253,21,209,227,172,195,75,76,22,154,201,204,202,224,188,182,40,85,14,203,128,160,199,200,255,122,80,165,236,72,205,3,88,91,48,63,52,177,66,5,131",",")))

my_list_adj <- my_list + 1
tour_line <- TOUR(my_list_adj, tsp = as.TSP(city_matrix))

theme_set(theme_map())

paths <- tribble(
  ~step, ~property, ~rowid, ~long, ~lat
)

for (i in 1:nrow(our_gps)){
  x <- tour_line[i]
  first_city <- our_gps |>
    slice(x)
  paths <- paths |>
    add_row(step = i, 
            property = "from", 
            rowid = first_city$rowid[1], 
            long = first_city$long[1], 
            lat = first_city$lat[1])
}

x <- tour_line[1]

paths <- paths|>
  add_row(step = 1 + nrow(our_gps), 
          property = "from", 
          rowid = our_gps$rowid[x], 
          long = our_gps$long[x], 
          lat = our_gps$lat[x])

tour_map <- make_map(
  state_map_data,
  our_gps,
  paths
  )
tour_map
```

I'm not sure if @fig-best is as short as possible, but I couldn't find a shorter one. Still, for many purposes it wouldn't have been worth the trouble it took to find this map.

## The Two Cases

@tbl-examples summarises the examples from the last two sections.

|                 |    Betting    |     Salesman     |
|-----------------|:-------------:|:----------------:|
| Best outcome    | Bet on winner |  Shortest path   |
| Decision theory |     Pass      |  Shortest path   |
| Best advice     |     Pass      | Learn algorithms |

: How three approaches to decision theory handle the two cases {#tbl-examples}

The first row says which action would produce the best outcome in the two cases. The third row says what advice one ought give someone who had to choose in the two cases. And the middle row says what all the decision theories say about the two cases. Notably, it agrees with neither the first nor third row. Decision theory is neither in the business of saying what will produce the best result, nor with giving the most useful advice. So what is it doing?
