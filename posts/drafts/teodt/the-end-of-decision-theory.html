<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.30">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Brian Weatherson">
<meta name="dcterms.date" content="2024-02-27">

<title>The End of Decision Theory – Brian Weatherson</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-de070a7b0ab54f8780927367ac907214.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-2b3e328b71be8d25427581baeb23079b.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-de070a7b0ab54f8780927367ac907214.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-4c44098e78fdd705b9debb9eb66aa123.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-dcf4b32a2094a7fbc35852421cc1fa0d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../site_libs/bootstrap/bootstrap-4c44098e78fdd705b9debb9eb66aa123.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" href="https://use.typekit.net/uzz2drx.css">
<meta name="quarto:status" content="draft">


</head>

<body class="floating nav-fixed slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner"><div id="quarto-draft-alert" class="alert alert-warning"><i class="bi bi-pencil-square"></i>Draft</div>
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Brian Weatherson</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-papers" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Papers</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-papers">    
        <li>
    <a class="dropdown-item" href="../../../papers.html">
 <span class="dropdown-text">All Papers</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../epist.html">
 <span class="dropdown-text">Epistemology</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../gdt.html">
 <span class="dropdown-text">Games and Decisions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../books.html">
 <span class="dropdown-text">On Books</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-books" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Books</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-books">    
        <li>
    <a class="dropdown-item" href="https://brian.weatherson.org/ne/">
 <span class="dropdown-text">Normative Externalism</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://lda.weatherson.org/">
 <span class="dropdown-text">A History of Philosophy Journals</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://brian.weatherson.org/kahis/">
 <span class="dropdown-text">Knowledge: A Human Interest Story</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../cv.html"> 
<span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../teaching.html"> 
<span class="menu-text">Teaching Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://scholar.google.com/citations?user=rz5RF8kAAAAJ&amp;hl=en&amp;oi=ao" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-google"></i></a>
    <a href="mailto: brian@weatherson.org" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-mailbox"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">The End of Decision Theory</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">games and decisions</div>
                <div class="quarto-category">unpublished</div>
                <div class="quarto-category">in progress</div>
              </div>
                  </div>
  </div>
    
  <div class="quarto-title-meta-author">
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-heading">Affiliation</div>
    
      <div class="quarto-title-meta-contents">
      <p class="author"><a href="http://brian.weatherson.org">Brian Weatherson</a> </p>
    </div>
    <div class="quarto-title-meta-contents">
          <p class="affiliation">
              University of Michigan
            </p>
        </div>
    </div>

  <div class="quarto-title-meta">

        
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 27, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  <div>
    <div class="abstract">
      <div class="block-title">Abstract</div>
      <p>What question are decision theorists trying to answer, and why is it worth trying to answer it? A lot of philosophers talk as if the aim of decision theory is to describe how we should make decisions, and the reason to do this is to help us make better decisions. I disagree on both fronts. The aim of the decision theory is to describe how a certain kind of idealised decider does in fact decide. And the reason to do this is that this idealisation, like many other idealisations, helps generate explanations of real-world behaviour. We shouldn’t do what these ideal deciders do, or try to be more like them, because a lot of what they do only makes sense because of the differences between us and them. Still, sometimes those differences are small enough that they can be ignored in explanations, and that’s when decision theory is useful.</p>
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Sections</h2>
   
  <ul>
  <li><a href="#what-is-decision-theory-a-theory-of" id="toc-what-is-decision-theory-a-theory-of" class="nav-link active" data-scroll-target="#what-is-decision-theory-a-theory-of"><span class="header-section-number">1</span> What is Decision Theory a Theory Of?</a></li>
  <li><a href="#two-cases" id="toc-two-cases" class="nav-link" data-scroll-target="#two-cases"><span class="header-section-number">2</span> Two Cases</a>
  <ul class="collapse">
  <li><a href="#betting" id="toc-betting" class="nav-link" data-scroll-target="#betting"><span class="header-section-number">2.1</span> Betting</a></li>
  <li><a href="#salesman" id="toc-salesman" class="nav-link" data-scroll-target="#salesman"><span class="header-section-number">2.2</span> Salesman</a></li>
  <li><a href="#the-two-cases" id="toc-the-two-cases" class="nav-link" data-scroll-target="#the-two-cases"><span class="header-section-number">2.3</span> The Two Cases</a></li>
  </ul></li>
  <li><a href="#decision-theory-as-idealisation" id="toc-decision-theory-as-idealisation" class="nav-link" data-scroll-target="#decision-theory-as-idealisation"><span class="header-section-number">3</span> Decision Theory as Idealisation</a></li>
  <li><a href="#idealisations-as-models" id="toc-idealisations-as-models" class="nav-link" data-scroll-target="#idealisations-as-models"><span class="header-section-number">4</span> Idealisations as Models</a></li>
  <li><a href="#conclusions" id="toc-conclusions" class="nav-link" data-scroll-target="#conclusions"><span class="header-section-number">5</span> Conclusions</a>
  <ul class="collapse">
  <li><a href="#the-value-of-limited-theories" id="toc-the-value-of-limited-theories" class="nav-link" data-scroll-target="#the-value-of-limited-theories"><span class="header-section-number">5.1</span> The Value of Limited Theories</a></li>
  <li><a href="#the-ideal-agent" id="toc-the-ideal-agent" class="nav-link" data-scroll-target="#the-ideal-agent"><span class="header-section-number">5.2</span> The Ideal Agent</a></li>
  <li><a href="#non-ideal-theory" id="toc-non-ideal-theory" class="nav-link" data-scroll-target="#non-ideal-theory"><span class="header-section-number">5.3</span> Non-Ideal Theory</a></li>
  <li><a href="#reconciliation" id="toc-reconciliation" class="nav-link" data-scroll-target="#reconciliation"><span class="header-section-number">5.4</span> Reconciliation</a></li>
  <li><a href="#other-idealisations" id="toc-other-idealisations" class="nav-link" data-scroll-target="#other-idealisations"><span class="header-section-number">5.5</span> Other Idealisations</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="the-end-of-decision-theory.docx"><i class="bi bi-file-word"></i>MS Word</a></li><li><a href="The End of Decision Theory.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">






<section id="what-is-decision-theory-a-theory-of" class="level1 page-columns page-full" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> What is Decision Theory a Theory Of?</h1>
<p>If you’re reading a paper like this, you’re probably familiar with seeing papers defending this or that decision theory. Familiar decision theories include:</p>
<ul>
<li>Causal Decision Theory <span class="citation" data-cites="GibbardHarper1978 Lewis1981b Skyrms1990 Joyce1999">(<a href="#ref-GibbardHarper1978" role="doc-biblioref">Gibbard and Harper 1978</a>; <a href="#ref-Lewis1981b" role="doc-biblioref">Lewis 1981</a>; <a href="#ref-Skyrms1990" role="doc-biblioref">Skyrms 1990</a>; <a href="#ref-Joyce1999" role="doc-biblioref">Joyce 1999</a>)</span>;</li>
<li>Evidential Decision Theory <span class="citation" data-cites="Ahmed2014">(<a href="#ref-Ahmed2014" role="doc-biblioref">Ahmed 2014</a>)</span>;</li>
<li>Benchmark theory <span class="citation" data-cites="Wedgwood2013a">(<a href="#ref-Wedgwood2013a" role="doc-biblioref">Wedgwood 2013</a>)</span>;</li>
<li>Risk-Weighted theory <span class="citation" data-cites="BuchakRisk">(<a href="#ref-BuchakRisk" role="doc-biblioref">Buchak 2013</a>)</span>;</li>
<li>Tournament Decision Theory <span class="citation" data-cites="Podgorski2022">(<a href="#ref-Podgorski2022" role="doc-biblioref">Podgorski 2022</a>)</span>; and</li>
<li>Functional Decision Theory <span class="citation" data-cites="LevinsteinSoares2020">(<a href="#ref-LevinsteinSoares2020" role="doc-biblioref">Levinstein and Soares 2020</a>)</span></li>
</ul>
<p>Other theories haven’t had snappy ‘isms’ applied to them, such as the non-standard version of Causal Decision Theory that Dmitri <span class="citation" data-cites="Gallow2020">Gallow (<a href="#ref-Gallow2020" role="doc-biblioref">2020</a>)</span> defends, or the pluralist decision theory that Jack <span class="citation" data-cites="Spencer2021">Spencer (<a href="#ref-Spencer2021" role="doc-biblioref">2021</a>)</span> defends, or the broadly ratificationist theory that Melissa <span class="citation" data-cites="Fuscond">Fusco (<a href="#ref-Fuscond" role="doc-biblioref">n.d.</a>)</span> defends.</p>
<p>This paper isn’t going to take sides between these nine or more theories.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Rather it is going to ask a prior pair of questions.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;The arguments here are intended to support a theory like Fusco’s, but in a fairly roundabout way, but the connection between what I say here and Fusco’s theory would take a paper as long as this one to set out.</p></div></div><ol type="1">
<li>If these are the possible answers, what is the question? That is, what is the question to which decision theories are possible answers?</li>
<li>Why is that an interesting question? What do we gain by answering it?</li>
</ol>
<p>On 1, I will argue that decision theories are answers to a question about what an ideal decider would do. The ‘ideal’ here is like the ‘ideal’ in a scientific idealisation, not the ideal in something like an ideal advisor moral theory. That is, the ideal decider is an idealisation in the sense of being simple, not in the sense of being perfect. The ideal decision maker is ideal in the same way that the point-masses in the ideal gas model are ideal; they are (relatively) simple to work with. The main opponent I have in mind is someone who says that in some sense decision theory tells us what decisions we should make.</p>
<p>On 2, I will argue that the point of asking this question is that these idealisations play important roles in explanatorily useful models of social interactions, such as the model of the used car market that George <span class="citation" data-cites="Akerlof1970">Akerlof (<a href="#ref-Akerlof1970" role="doc-biblioref">1970</a>)</span> described. Here, the main opponent I have in mind is someone who says that decision theory is useful because it helps us make better decisions.</p>
<p>There is another pair of answers to this question which is interesting, but which I won’t have a lot to say about here. David Lewis held that “central question of decision theory is: which choices are the ones that serve one’s desires according to one’s beliefs?” <span class="citation" data-cites="Lewis-Gorman-10071979">(<a href="#ref-Lewis-Gorman-10071979" role="doc-biblioref"><strong>Lewis-Gorman-10071979?</strong></a>)</span>. That’s not far from the view I have, though I’d say it’s according to one’s evidence. But I differ a bit more from Lewis as to the point of this activity. For him, a central role for decision theory is supplying a theory of constitutive rationality to an account of mental content <span class="citation" data-cites="Lewis1994b">(<a href="#ref-Lewis1994b" role="doc-biblioref">Lewis 1994, 321–22</a>)</span>. I think the resulting theory is too idealised to help there, and that’s before we get to questions about whether we should accept the approach to mental content that requires constitutive rationality. That said, the view I’m defending is going to be in many ways like Lewis’s: the big task of decision theory is describing an idealised system, not yet recommending it.</p>
<p>The nine theories I mentioned above disagree about a lot of things. In philosophy we typically spend our time looking at cases where theories agree. Not here! I will focus almost exclusively on two cases where those nine theories all say the same thing. I’ll assume that whatever question they are asking, the correct answer to it in those two cases must agree with all nine theories. That will be enough to defend the view I want to defend, which is that a decision theory is correct iff is true in the right kind of idealisation.</p>
</section>
<section id="two-cases" class="level1 page-columns page-full" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Two Cases</h1>
<section id="betting" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="betting"><span class="header-section-number">2.1</span> Betting</h2>
<p>Chooser has $110, and is in a sports betting shop. There is a basketball game about to start, between two teams they know to be equally matched. Chooser has three options: bet the $110 on Home, bet it on Away, keep money. If they bet and are right, they win $100 (plus get the money back they bet), if they are wrong, they lose the money. Given standard assumptions about how much Chooser likes money, all the decision theories I’m discussing say Chooser should not bet.</p>
<p>From this it follows that decision theory is not in the business of answering this question: <em>What action will produce the best outcome?</em>. We know, and so does Chooser, that the action that produces the best outcome is to bet on the winning team. Keeping their money in their pocket is the only action they know will be sub-optimal. And it’s what decision theory says to do.</p>
<p>This is to say, decision theory is not axiology. It’s not a theory of evaluating outcomes, and saying which is best. Axiology is a very important part of philosophy, but it’s not what decision theorists are up to.</p>
<p>So far this will probably strike you, dear reader, as obvious. But there’s another step, that I think will strike some people as nearly as obvious, that I’m at pains to resist. Some might say that decision theorists don’t tell Chooser to bet on the winner because this is lousy advice. Chooser can’t bet on the winner, at least not as such. That, I’ll argue, would be a misstep. Decision theorists do not restrict themselves to answers that can be practically carried out.</p>
</section>
<section id="salesman" class="level2 page-columns page-full" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="salesman"><span class="header-section-number">2.2</span> Salesman</h2>
<p>We’ll focus on a version of what Julia <span class="citation" data-cites="Robinson1949">Robinson (<a href="#ref-Robinson1949" role="doc-biblioref">1949</a>)</span> called the travelling salesman problem.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> Given some points on a map, find the shortest path through them. We’ll focus on the 257 cities shown on the map in <a href="#fig-map" class="quarto-xref">Figure&nbsp;1</a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;For a thorough history of the problem, see <span class="citation" data-cites="Schrijver2005">Schrijver (<a href="#ref-Schrijver2005" role="doc-biblioref">2005</a>)</span>. For an accessible history of the problem, which includes these references, see <span class="citation" data-cites="wiki-salesman">Travelling salesman problem (<a href="#ref-wiki-salesman" role="doc-biblioref">2024</a>)</span>.</p></div></div><div class="cell">
<div class="cell-output-display">
<div id="fig-map" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="the-end-of-decision-theory_files/figure-html/fig-map-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: 257 American cites; our task is to find the shortest path that goes through all of them.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The task is to find the shortest path through those 257 cities.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;The 257 cities are the cities in the lower 48 states from the 312 cities in North America that John <span class="citation" data-cites="Burkhart2011">Burkardt (<a href="#ref-Burkhart2011" role="doc-biblioref">2011</a>)</span> mapped in his dataset USCA312.</p></div></div><p>All nine of the decision theories I mentioned, and as far as I know every competitor to them in the philosophical literature, say the thing to do here is to draw whichever of the 256! possible paths is shortest. That is not particularly helpful advice. Unless you know a lot about problems like this, you can’t draw the shortest path through the map. And least, you can’t draw it as such. You can’t draw it in the way that you can’t enter the correct code on a locked phone <span class="citation" data-cites="MandelkernEtAl2017">(<a href="#ref-MandelkernEtAl2017" role="doc-biblioref">Mandelkern, Schultheis, and Boylan 2017</a>)</span>.</p>
<p>One of the striking things about this puzzle is that it turns out there are some helpful things that can be said. One helpful bit of advice to someone trying to solve a problem like this is to use a Farthest Insertion Algorithm.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> Insertion algorithms say to start with a random city, then add cities to the path one at a time, at each time finding the point to insert the city into the existing path that adds the least distance. The Farthest Insertion Algorithm says that the city added at each stage is the one farthest from the existing path. Insertion algorithms in general produce pretty good paths in a very short amount of time - at least on normal computers. And the Farthest Insertion Algorithm is, most of the time, the best Insertion Algorithm to use. <a href="#fig-farthest" class="quarto-xref">Figure&nbsp;2</a> shows the result of one output of this algorithm.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;To implement both this algorithm and the optimisation I’ll mention below, I’ve used the TSP package by Michael Hashler and Kurt Hornik <span class="citation" data-cites="HashlerHornik2007">(<a href="#ref-HashlerHornik2007" role="doc-biblioref">2007</a>)</span>. The description of the two steps owes a lot to their summaries in the package documentation.</p></div><div id="fn5"><p><sup>5</sup>&nbsp;The algorithm is silent on which city you start with, and usually chooses this randomly.</p></div></div><div class="cell">
<div class="cell-output-display">
<div id="fig-farthest" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-farthest-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="the-end-of-decision-theory_files/figure-html/fig-farthest-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-farthest-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: An output of the Farthest Insertion Algorithm, with a length of 21075 miles.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The path in <a href="#fig-farthest" class="quarto-xref">Figure&nbsp;2</a> is not bad, but with only a bit of extra computational work, one can do better. A fairly simple optimisation algorithm takes a map as input, and then deletes pairs of edges at a time, and finds the shortest path of all possible paths with all but those two edges. The process continues until no improvements can be made by deleting two edges at a time, at which point you’ve found a somewhat resilient local minimum. <a href="#fig-two-opt" class="quarto-xref">Figure&nbsp;3</a> is the output from applying this strategy to the path in <a href="#fig-farthest" class="quarto-xref">Figure&nbsp;2</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-two-opt" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-two-opt-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="the-end-of-decision-theory_files/figure-html/fig-two-opt-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-two-opt-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: The output of an optimisation process, which reduced the path length to 20891 miles.
</figcaption>
</figure>
</div>
</div>
</div>
<p>This optimisation tends to produce paths that look a lot like the original, but are somewhat shorter. For most practical purposes, the best advice you could give someone faced with a problem like this is to use a Farthest Insertion Algorithm, then optimise it in this way. Or, if they have a bit more time, they could do this a dozen or so times, and see if different starting cities led to slightly shorter paths.</p>
<p>While this is good advice, and indeed it’s what most people should do, it’s not typically what is optimal to do. For that reason, it’s not what our nine decision theories would say to do. If one had unlimited and free computing power available, hacks like these would be pointless. One would simply look at all the possible paths, and see which was shortest. I do not have free, unlimited computing power, so I didn’t do this. Using some black box algorithms I did not particularly understand, I was able to find a shorter path, however. It took some time, both of mine and my computer’s, and for most purposes it would not have been worth the hassle of finding it. Still, just to show it exists, I’ve plotted it as <a href="#fig-best" class="quarto-xref">Figure&nbsp;4</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-best" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-best-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="the-end-of-decision-theory_files/figure-html/fig-best-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-best-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: The shortest path I could find, with a distance of 20301 miles.
</figcaption>
</figure>
</div>
</div>
</div>
<p>I’m not sure if <a href="#fig-best" class="quarto-xref">Figure&nbsp;4</a> is as short as possible, but I couldn’t find a shorter one. Still, for many purposes it wouldn’t have been worth the trouble it took to find this map.</p>
</section>
<section id="the-two-cases" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="the-two-cases"><span class="header-section-number">2.3</span> The Two Cases</h2>
<p><a href="#tbl-examples" class="quarto-xref">Table&nbsp;1</a> summarises the examples from the last two sections.</p>
<div id="tbl-examples" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-examples-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: How three approaches to decision theory handle the two cases
</figcaption>
<div aria-describedby="tbl-examples-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th style="text-align: center;">Betting</th>
<th style="text-align: center;">Salesman</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Best outcome</td>
<td style="text-align: center;">Bet on winner</td>
<td style="text-align: center;">Shortest path</td>
</tr>
<tr class="even">
<td>Decision theory</td>
<td style="text-align: center;">Pass</td>
<td style="text-align: center;">Shortest path</td>
</tr>
<tr class="odd">
<td>Best advice</td>
<td style="text-align: center;">Pass</td>
<td style="text-align: center;">Learn algorithms</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The first row says which action would produce the best outcome in the two cases. The third row says what advice one ought give someone who had to choose in the two cases. And the middle row says what all the decision theories say about the two cases. Notably, it agrees with neither the first nor third row. Decision theory is neither in the business of saying what will produce the best result, nor with giving the most useful advice. So what is it doing?</p>
</section>
</section>
<section id="decision-theory-as-idealisation" class="level1 page-columns page-full" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Decision Theory as Idealisation</h1>
<p>Imagine a version of Chooser with, as Rousseau might have put it, their knowledge as it is, and their computational powers as they might be. That is, a version of Chooser who has unlimited, and free, computational powers, but no more knowledge of the world than the actually have - save what they learn by performing deductions from their existing knowledge.</p>
<p>Decision theories describe what that version of Chooser would do in the problem that Chooser is facing. In the betting case, adding unlimited computing power doesn’t tell you who is going to win the game. So that version of Chooser will still avoid betting. But in the Salesman case, adding unlimited computing power is enough to solve the problem. They don’t even have to use any fancy techniques. To find the shortest path, all it takes is finding the length of each path, and sorting the results. The first requires nothing more that addition; at least if, as was the case here, we provided the computer with the distances between any pairs of cities as input. The second just requires being able to do a bubble sort, which is technically extremely simple. To be sure, doing all these additions, then doing a bubble sort on the results, will take longer than most human lives on the kinds of computers most people have available to them. But a version of Chooser with unlimited, free, computational power will do these computations no problem at all.</p>
<p>If we say that Chooser should maximise expected utility, and we expect them to compute that, then we’re asking Chooser to perform a task that is one step harder than calculating the shortest path in a Salesman problem. To calculate an expected utility, for each option one looks up a probability and a utility for each state<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>, multiplies the two together, then adds the results to get a value for the option. One repeats that for each state, and finds an extreme value. Calculating the shortest path is exactly the same, except one only has to look up one number (a distance) rather than two (a probability and a utility), and there is no multiplication. Solving for the shortest path is strictly easier than finding the maximum expected utility. And yet finding the shortest path is practically impossible.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;Exactly which probability it is, or indeed whether it even strictly is a probability, varies by which theory one chooses. But the basic idea that Chooser multiples something probability like by a utility is common across theories</p></div></div><p>This is one reason I focussed on Salesman problems rather than other mathematical claims that Chooser is, in the standard models, assumed to know. I didn’t ask Chooser to bet on the Twin Primes conjecture. It’s possible one could come up with a model where finding the maximum expected utility is typically possible but resolving the Twin Primes conjecture is not; it’s really hard to see how an agent who could always calculate expected utilities couldn’t solve a Salesman problem.</p>
<p>There are two other things that are distinctively interesting about this problem which I’ll simply note here, and defer longer discussion of them to another day. First, it is possible to give practical useful advice about how to solve Salesman problems. I’ve repeated some of the better advice I’ve heard in the previous section. Second, when someone follows this advice and does badly, as can happen with carefully designed maps, it seems they are unlucky in just the same way that someone who maximises expected utility but gets a low amount of actual utility is unlucky. This raises some interesting questions about the normative significance of expected utility maximisation that will be in the background of the rest of the discussion here; hopefully I’ll return to them in later work.</p>
<p>At this point you might complain that I’ve talked about decision theories asking Chooser to <em>calculate</em> expected utilities. They do no such thing. This is a point that Frank Knight made a century ago.</p>
<blockquote class="blockquote">
<p>Let us take Marshall’s example of a boy gathering and eating berries … We can hardly suppose that the boy goes through such mental operations as drawing curves or making estimates of utility and disutility scales. <span class="citation" data-cites="Knight1921">(<a href="#ref-Knight1921" role="doc-biblioref">Knight 1921, 66–67</a>)</span></p>
</blockquote>
<p>And Knight does not say this is irrational. As long as the boy gets enough berries, he’s doing fine. In other terminology, we might say that decision theory provides a criteria of rightness, not a deliberation procedure. I’m taking this distinction from Peter <span class="citation" data-cites="Railton1984">Railton (<a href="#ref-Railton1984" role="doc-biblioref">1984</a>)</span>. Alastair <span class="citation" data-cites="Norcross1997">Norcross (<a href="#ref-Norcross1997" role="doc-biblioref">1997</a>)</span> notes that the phrase “criterion of rightness” is used in the context of drawing this distinction by Sidgwick <span class="citation" data-cites="Sidgwick1907">(<a href="#ref-Sidgwick1907" role="doc-biblioref">1907, bk. 4</a>, Chapter 1, §1)</span>. As long as one follows the rules of decision theory, even if one follows them largely instinctually like Marshall’s boy, one is rational.</p>
<p>This move just brings us back to the original problem. It’s easy to understand the distinction in Sidgwick. The criterion of rightness is that one actually produces the best outcome. Which decision procedure actually produces that outcome is hard to determine in advance, though there are good reasons for suspecting that aiming for the best outcome as such is not the optimal procedure. Why, however, should we think that maximising <em>expected</em> utility is a criteria of rightness? What benefits does it have, over the standard of maximising actual utility, as such a criteria? It is a somewhat easier rule to use, which makes it a better deliberation procedure. Unfortunately, as the Salesman cases show, there are other procedures that are better again qua deliberation procedures too. So what benefit does it have?</p>
<p>One possible answer to this challenge is that expected utility maximisation, or whatever one’s favourite decision theory endorses, is a goal; it is something we should try to achieve. On this picture, decision theory is relevant because it tells us what idealised people are like, and it recommends we try to be like them. In practice we can’t always be like them, as in the Salesman problem, but we should try.</p>
<p>The problem with this answer is that it is not, in general, good to try to be like the ideal. The key point goes back to Lipsey and Lancaster’s <em>General Theory of the Second Best</em> <span class="citation" data-cites="LipseyLancaster">(<a href="#ref-LipseyLancaster" role="doc-biblioref">Lipsey and Lancaster 1956</a>)</span>. Often times, the right thing to do is something whose value consists in mitigating the costs of our other flaws. It’s not true in general, indeed it’s rather rare that it’s true in practice, that approaches which differ from the ideal in one respect are better than all approaches which differ from the ideal in two respects. For example, us non-ideal agents should, especially in high stakes settings, stop and have a little think before acting. The ideal agent of decision theory never stops to have a think. After all, stopping is costly, and the ideal agent gets no gain from incurring that cost.</p>
<p>In general, we differ from the ideal agent in any number of ways. Some of these are respects in which we’d be better off being more like them. For example, they correctly hedge against costly but realistic risks. But some of these are respects in which we’d be worse off being more like them. For instance, they never stop to have a think, or put in effort to get better at calculations. Knowing that the ideal agent is <em>F</em> doesn’t tell us whether we should try to be <em>F</em> unless we also know that <em>F</em> is more like hedging rather than more like never trying to get better at calculating. That, unfortunately, is not something which we can really figure out from within the idealised approach to decision theory that is standard these days.</p>
</section>
<section id="idealisations-as-models" class="level1 page-columns page-full" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Idealisations as Models</h1>
<p>At the start I said that the word ‘idealised’ gets used differently in ethics and in philosophy of science. The main claim I want to make in this section is that we should understand the idealisations in decision theory in the latter sense. In particular, we should understand them as simplifications. Michael <span class="citation" data-cites="Weisberg2007">Weisberg (<a href="#ref-Weisberg2007" role="doc-biblioref">2007</a>)</span> identifies three kinds of idealisations in science: Galilean, which distort the situation to make computation easier; minimalist, which only include the factors one takes to be causally significant to a situation; and multiple models, where one tries to understand a situation by considering different minimal idealisations with different strengths and weaknesses. The idealisations in decision theory are the second kind. They aren’t particularly computationally tractable, unlike the Galilean idealisations, and there is typically just the one of them.</p>
<p>Another way to put this is that the idealisations in, say, ideal gas theory are <em>simple</em> rather than <em>perfect</em>. We do not think that having volume is an imperfection. Maybe some religious traditions think this, but it isn’t baked into introductory chemistry. Nor do we think that they are things we should aim for. Introductory chemistry does not imply a <em>Smaller the better!</em> rule for molecules. Rather, it says that volumeless molecules with perfectly elastic collisions are simple, and that some of the phenomena of real gases can be explained by looking at this simple model.</p>
<p>Decision theory is engaged in the same kind of project. Just like the point masses we use in the ideal gas law, they say not what should happen, but what would happen in the absence of certain complications. The idealisation here is not a perfection, for two reasons. First, allocating zero seconds to hard but important math problems is not a perfection, it’s a practical vice. Yet it’s what the ideal agent does. Second, the idealised self is not in fact absolutely perfect. They have similar informational limitations to what we do.</p>
<p>This is the point of the basketball example. The idealised self that gets used in decision theory is god-like god-like in one respect - computational ability - but human-like in another - informational awareness. That’s a common feature of idealised models; one doesn’t idealised away from absolutely everything.</p>
<p>Why do we use these models? Part of the answer here comes back to the much discussed question of why we use models at all. I’m going to assume that part of the answer is that minimal models are explanatorily powerful when the difference between the minimal model and reality is not relevant to predicting, explaining, or understanding what happens in the real world. So my hypothesis is that the idealised models of decision theory are, at least sometimes, relevant to predicting, explaining, or understanding what happens in the real world.</p>
<p>It’s tempting to identify the situations where decision theory is relevant with high stakes situations. After all, in high-stakes situations deciders are disposed to throw enough computational resources at the problem that the differences between ordinary people and ideal agents shrinks. since those are ones where we’ll throw enough computational resources at the problem that we have god-like powers. But that is isn’t quite right. After all, in many high stakes cases, the decider also throws enough investigative resources at the problem that holding actual knowledge fixed is a bad modelling assumption.</p>
<p>To find a case where decision theory is relevant, we need are cases where there are principled limitations to the decider’s informational capacities. There are two kinds of cases that are relevant here. One is where the information concerns the future, and the decision must be made now. And the other is where the information that someone else has (or at least may have) just as much incentive to suppress the information as the decider has to find it. Most textbook examples of the usefulness of decision theory concern the first kind, though they don’t always make explicit why it matters that the case is future directed. I’m going to work through a case of the second kind that I think is enlightening about the way decision theory is valuable.</p>
<p>Until very recently, used cars sold at a huge discount to new cars, even when the cars were just a few months old with almost no usage. For a long time there was no agreed upon explanation for this phenomena. The most common theory was that it reflected a preference, or perhaps a prejudice, on the part of buyers. George <span class="citation" data-cites="Akerlof1970">Akerlof (<a href="#ref-Akerlof1970" role="doc-biblioref">1970</a>)</span> showed how this discount could be explained in a model of perfectly rational agents. His model makes the following assumptions.</p>
<ol type="1">
<li>Cars vary a lot in quality, even cars that come from the same production line.</li>
<li>Sellers of used cars know how good the particular car they are selling is.</li>
<li>Buyers of used cars do not know how good the car is; they only know how good that model of cars generally is.</li>
<li>People rarely sell cars they just bought.</li>
<li>Everyone involved is an expected utility maximiser.</li>
</ol>
<p>Based on these five assumptions, Akerlof built a formal model of the market for recently used cars. In the model, the most common reason to sell a car one just bought is the discovery that it was a bad instance of that kind of car. Knowing this, buyers of used cars demanded a big discount in exchange for the possibility they were buying a dud. But as long as there are enough forced sellers of good recently purchased cars, who prefer whatever money they can get for their car to keeping the car, there can be an equilibrium where lightly used cars sell at a heavy discount to new cars, and it is rational for (some) owners to sell into this market, and for (some) buyers to buy in this market.</p>
<p>If Akerlof was right, and I think he was largely correct, you’d expect the used car discount to fall if either of the following things happened. First, it would fall if production lines got more reliable, and cars off the same line were more similar to one another. And second, it would fall if buyers had access to better tools<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> to judge the quality of used cars. By 2020 both of those things had happened, and the used car discount was almost zero.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;Better that is than a drive around the block test drive.</p></div><div id="fn8"><p><sup>8</sup>&nbsp;Then during the pandemic very strange things happened in the used car market and the ‘discount’ arguably went negative. Whatever was happening there was not explained by the Akerlof model.</p></div></div><p>The philosophical significance of this is that one can’t build models like Akerlof’s without a theory of rational action under uncertainty. The big payoff of philosophical decision theory is that it’s an essential input to useful models, like the Akerlof model. Since those models are useful, getting the inputs to them right is useful.</p>
</section>
<section id="conclusions" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Conclusions</h1>
<p>This has largely been a work of meta-philosophy. I’ve argued that decision theorists are building idealisations in the sense of simple models. And I’ve argued that this is a good project not because it issues in advice, or evaluation, but because it provides inputs to explanations. In particular, decision theoretic explanations are often accurate when people can behave somewhat like computationally ideal agents, but must still behave like informationally limited agents.</p>
<p>If I’m right, there are several consequences for first-order decision theory. I’ll end the paper going over four of them.</p>
<section id="the-value-of-limited-theories" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="the-value-of-limited-theories"><span class="header-section-number">5.1</span> The Value of Limited Theories</h2>
<p>We use different styles of explanations for different phenomena. If a product routinely sells for $7.99, we might use a rational choice explanation for why the price is roughly $8 rather than roughly $10, and then a very different kind of explanation for why it is $7.99 rather than $8.01. It isn’t always a weakness of an explanation that it does not generalise to as many cases as one might have hoped.</p>
<p>This matters for decision theory. If a decision theory goes silent on a certain kind of case, that isn’t necessarily a bad thing. One sometimes hears theorists talk as if the fact that a theory doesn’t say what to do in a particular situation is very bad, because the point of decision theory is to provide advice. But if decision theory goes silent on cases where we don’t think decision theoretic explanations are likely to be good, that’s not necessarily a bad thing.</p>
</section>
<section id="the-ideal-agent" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="the-ideal-agent"><span class="header-section-number">5.2</span> The Ideal Agent</h2>
<p>I’ve left off a lot of details about exactly what the ideal agent is like. I said they are computationally good, but informationally limited. This leaves open a lot of questions. Do they have perfect information about their own beliefs and desires, or about their own plans? Are they able to stick to a plan, and if so, which kinds of plans can they stick to?</p>
<p>One way to try answering these questions is by asking whether the inability to know one of these things, or do one of these things, is a kind of imperfection. If it is, we’ve discovered a new feature of the ideal, perfect agent.</p>
<p>If I’m right, that’s the wrong way to go about answering the question. We should ask instead if assuming that the ideal decider has these features makes them too dissimilar to real people for explanatory purposes. For instance, I think we should allow that ideal deciders can play mixed strategies, because being able to play mixed strategies does not make the ideal decider that different to real people. In circumstances where real deciders have sufficient computational resources that ideal deciders are good models for them, real deciders also have sufficient resources to play mixed strategies.</p>
<p>Whether I’m right or wrong about mixed strategies, the point I want to really stress is the approach to answering these questions about idealisations. The right idealisation does not describe what we should be like, but rather what it is helpful to model us as being like.</p>
</section>
<section id="non-ideal-theory" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="non-ideal-theory"><span class="header-section-number">5.3</span> Non-Ideal Theory</h2>
<p>If actual decision theory is a kind of ideal theory, that means there is a space for a non-ideal theory. And there are a bunch of interesting philosophical questions about it. I think the right non-ideal theory will be some kind of reliabilism. Even if that’s right, it hardly settles matters. There are, after all, many different kinds of reliabilism, and we’d need to have answers to the decision theoretic equivalents of the generality problem, and the new evil demon problem. Still, these feel like answerable questions, and there are interesting projects to work on here.</p>
</section>
<section id="reconciliation" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="reconciliation"><span class="header-section-number">5.4</span> Reconciliation</h2>
<p>If two types of theory exist, but ideal and non-ideal, some reconciliation possibilities open up. Perhaps the right thing to say about Newcomb’s Problem is that there is a sense in which one should take one box, and there is a sense in which one should take two boxes. One way to get this result would be to endorse the following three claims.</p>
<ol type="1">
<li>The right ideal decision theory is some broadly causal decision theory.</li>
<li>The right non-ideal decision theory is some kind of reliabilism.</li>
<li>In Newcomb’s Problem, one boxers and two boxers are in the same reference class, so the right thing to do is the thing that, on average, produces the best results in that large class.</li>
</ol>
<p>I don’t want to endorse all these; I’m particularly sceptical of 3. The point is just that when we distinguish ideal from non-ideal theories we open up some new options in what might seem like stale debates.</p>
</section>
<section id="other-idealisations" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="other-idealisations"><span class="header-section-number">5.5</span> Other Idealisations</h2>
<p>The most interesting question that opens up from this way of thinking about decision theory is whether we could develop any other idealisations that are explanatorily powerful. As Weisberg notes, an important kind of idealisation involves developing many models that help explain different phenomena. Here that might involve changing what information the ideal agent has, or what computational powers they have.</p>
<p>In economics there has been some interesting projects along these lines. One that’s particularly relevant here is the development of cursed equilibrium models (<span class="citation" data-cites="EysterRabin2005">Eyster and Rabin (<a href="#ref-EysterRabin2005" role="doc-biblioref">2005</a>)</span>). In cursed equilibrium models, agents maximise expected utility with respect to some information, but not the information they actually have. In particular, they don’t always take fully into account what they can figure out about other people’s information from observing the acts other people perform. It’s a bit more complicated than this in practice, but roughly it’s as if people ignore what other people are doing.</p>
<p>These models are relevant here for two reasons. One is that the main example I used of decision theory working, Akerlof’s model for used cars, involved people making just the kind of inference that they do not make in cursed equilibrium models. The reason the used car market settles at such a discount, in an Akerlof model, is that buyers reason from the fact that sellers are choosing to sell that sellers have private information. That inference, from observed behaviour to conclusions about the private information the other person has, is exactly what agents do not make in cursed equilibrium models. This matters because in a bunch of experimental settings, cursed equilibrium models make more accurate predictions than rational choice models.</p>
<p>This doesn’t on its own show the Akerlof explanation is wrong. It might just show that explanation was incomplete. To complete the explanation we could simply add the premises that cars are expensive, and that people act more carefully when making expensive purchases. The first premise is clearly true, cars are indeed expensive, and there is some evidence for the second. Still, thinking about cursed equilibrium models, which are still incredibly idealised, helps both explain new phenomena, and appreciate more fully the explanations that rational choice models make.</p>
<p>Cursed equilibrium models have not been developed nearly as fully as rational choice models; it’s only very recently that fully dynamic versions of them have been put forward <span class="citation" data-cites="CohenLi2023">Fong, Lin, and Palfrey (<a href="#ref-Fong2023" role="doc-biblioref">forthcoming</a>)</span>. I certainly don’t want to say this is the only way to modify the idealisations in standard decision theory, or even the best such way. What I do want to say is that thinking about decision theory as the project of building good simplified models suggests that the project of building multiple models of decision could have some value.</p>



</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Ahmed2014" class="csl-entry" role="listitem">
Ahmed, Arif. 2014. <em>Evidence, Decision and Causality</em>. Cambridge: <span>C</span>ambridge <span>U</span>niversity <span>P</span>ress.
</div>
<div id="ref-Akerlof1970" class="csl-entry" role="listitem">
Akerlof, George. 1970. <span>“The Market for "Lemons": Quality Uncertainty and the Market Mechanism.”</span> <em>Quarterly Journal of Economics</em> 84 (3): 488–500. doi: <a href="https://doi.org/10.2307/1879431">10.2307/1879431</a>.
</div>
<div id="ref-BuchakRisk" class="csl-entry" role="listitem">
Buchak, Lara. 2013. <em>Risk and Rationality</em>. Oxford: Oxford University Press.
</div>
<div id="ref-Burkhart2011" class="csl-entry" role="listitem">
Burkardt, John. 2011. <span>“Cities.”</span> <a href="https://people.sc.fsu.edu/~jburkardt/datasets/cities/cities.html">https://people.sc.fsu.edu/~jburkardt/datasets/cities/cities.html</a>.
</div>
<div id="ref-CohenLi2023" class="csl-entry" role="listitem">
Cohen, Shani, and Shengwu Li. 2023. <span>“Sequential Cursed Equilibrium.”</span> 2023. <a href="https://arxiv.org/abs/2212.06025">https://arxiv.org/abs/2212.06025</a>.
</div>
<div id="ref-EysterRabin2005" class="csl-entry" role="listitem">
Eyster, Erik, and Matthew Rabin. 2005. <span>“Cursed Equilibrium.”</span> <em>Econometrica</em> 73 (5): 1623–72. <a href="https://10.1111/j.1468-0262.2005.00631.x">10.1111/j.1468-0262.2005.00631.x</a>.
</div>
<div id="ref-Fong2023" class="csl-entry" role="listitem">
Fong, Meng-Jhang, Po-Hsuan Lin, and Thomas R. Palfrey. forthcoming. <span>“Cursed Sequential Equilibrium.”</span> <em>American Economic Review</em>, forthcoming.
</div>
<div id="ref-Fuscond" class="csl-entry" role="listitem">
Fusco, Melissa. n.d. <span>“Absolution of a Causal Decision Theorist.”</span> <em>No<span>û</span>s</em>. doi: <a href="https://doi.org/10.1111/nous.12459">10.1111/nous.12459</a>. Early view.
</div>
<div id="ref-Gallow2020" class="csl-entry" role="listitem">
Gallow, J. Dmitri. 2020. <span>“The Causal Decision Theorist’s Guide to Managing the News.”</span> <em>The Journal of Philosophy</em> 117 (3): 117–49. doi: <a href="https://doi.org/10.5840/jphil202011739">10.5840/jphil202011739</a>.
</div>
<div id="ref-GibbardHarper1978" class="csl-entry" role="listitem">
Gibbard, Allan, and William Harper. 1978. <span>“Counterfactuals and Two Kinds of Expected Utility.”</span> In <em>Foundations and Applications of Decision Theory</em>, edited by C. A. Hooker, J. J. Leach, and E. F. McClennen, 125–62. Dordrecht: Reidel.
</div>
<div id="ref-HashlerHornik2007" class="csl-entry" role="listitem">
Hahsler, Michael, and Kurt Hornik. 2007. <span>“TSP—Infrastructure for the Traveling Salesperson Problem.”</span> <em>Journal of Statistical Software</em> 23 (2): 1–21. doi: <a href="https://doi.org/10.18637/jss.v023.i02">10.18637/jss.v023.i02</a>.
</div>
<div id="ref-Joyce1999" class="csl-entry" role="listitem">
Joyce, James M. 1999. <em>The Foundations of Causal Decision Theory</em>. Cambridge: Cambridge University Press.
</div>
<div id="ref-Knight1921" class="csl-entry" role="listitem">
Knight, Frank. 1921. <em>Risk, Uncertainty and Profit</em>. Chicago: University of Chicago Press.
</div>
<div id="ref-LevinsteinSoares2020" class="csl-entry" role="listitem">
Levinstein, Benjamin Anders, and Nate Soares. 2020. <span>“Cheating Death in Damascus.”</span> <em>Journal of Philosophy</em> 117 (5): 237–66. doi: <a href="https://doi.org/10.5840/jphil2020117516">10.5840/jphil2020117516</a>.
</div>
<div id="ref-Lewis1981b" class="csl-entry" role="listitem">
Lewis, David. 1981. <span>“Causal Decision Theory.”</span> <em>Australasian Journal of Philosophy</em> 59 (1): 5–30. doi: <a href="https://doi.org/10.1080/00048408112340011">10.1080/00048408112340011</a>. Reprinted in his <em>Philosophical Papers</em>, Volume 2, Oxford: Oxford University Press, 1986, 305-337. References to reprint.
</div>
<div id="ref-Lewis1994b" class="csl-entry" role="listitem">
———. 1994. <span>“Reduction of Mind.”</span> In <em>A Companion to the Philosophy of Mind</em>, edited by Samuel Guttenplan, 412–31. Oxford: Blackwell. doi: <a href="https://doi.org/10.1017/CBO9780511625343.019">10.1017/CBO9780511625343.019</a>. Reprinted in his <em>Papers in Metaphysics and Epistemology</em>, 1999, 291-324, Cambridge: Cambridge University Press. References to reprint.
</div>
<div id="ref-LipseyLancaster" class="csl-entry" role="listitem">
Lipsey, R. G., and Kelvin Lancaster. 1956. <span>“The General Theory of Second Best.”</span> <em>Review of Economic Studies</em> 24 (1): 11–32. doi: <a href="https://doi.org/10.2307/2296233">10.2307/2296233</a>.
</div>
<div id="ref-MandelkernEtAl2017" class="csl-entry" role="listitem">
Mandelkern, Matthew, Ginger Schultheis, and David Boylan. 2017. <span>“Agentive Modals.”</span> <em>Philosophical Review</em> 126 (3): 301–43. doi: <a href="https://doi.org/10.1215/00318108-3878483">10.1215/00318108-3878483</a>.
</div>
<div id="ref-Norcross1997" class="csl-entry" role="listitem">
Norcross, Alastair. 1997. <span>“Consequentialism and Commitment.”</span> <em>Pacific Philosophical Quarterly</em> 78 (4): 380–403. doi: <a href="https://doi.org/10.1111/1468-0114.00045">10.1111/1468-0114.00045</a>.
</div>
<div id="ref-Podgorski2022" class="csl-entry" role="listitem">
Podgorski, Aberlard. 2022. <span>“Tournament Decision Theory.”</span> <em>No<span>û</span>s</em> 56 (1): 176–203. doi: <a href="https://doi.org/10.1111/nous.12353">10.1111/nous.12353</a>.
</div>
<div id="ref-Railton1984" class="csl-entry" role="listitem">
Railton, Peter. 1984. <span>“Alienation, Consequentialism, and the Demands of Morality.”</span> <em>Philosophy and Public Affairs</em> 13 (2): 134–71.
</div>
<div id="ref-Robinson1949" class="csl-entry" role="listitem">
Robinson, Julia. 1949. <span>“On the Hamiltonian Game (a Traveling Salesman Problem).”</span> Santa Monica, CA: The RAND Corporation.
</div>
<div id="ref-Schrijver2005" class="csl-entry" role="listitem">
Schrijver, Alexander. 2005. <span>“On the History of Combinatorial Optimization (till 1960).”</span> <em>Handbooks in Operations Research and Management Science</em> 12: 1–68. doi: <a href="https://doi.org/10.1016/S0927-0507(05)12001-5">10.1016/S0927-0507(05)12001-5</a>.
</div>
<div id="ref-Sidgwick1907" class="csl-entry" role="listitem">
Sidgwick, Henry. 1907. <em>The Methods of Ethics</em>. Seventh. London: Macmillan. Accessed via Project Gutenberg at <a href="https://www.gutenberg.org/files/46743/46743-h/46743-h.htm" class="uri">https://www.gutenberg.org/files/46743/46743-h/46743-h.htm</a>.
</div>
<div id="ref-Skyrms1990" class="csl-entry" role="listitem">
Skyrms, Brian. 1990. <em>The Dynamics of Rational Deliberation</em>. Cambridge, MA: Harvard University Press.
</div>
<div id="ref-Spencer2021" class="csl-entry" role="listitem">
Spencer, Jack. 2021. <span>“An Argument Against Causal Decision Theory.”</span> <em>Analysis</em> 81 (1): 52–61. doi: <a href="https://doi.org/10.1093/analys/anaa037">10.1093/analys/anaa037</a>.
</div>
<div id="ref-wiki-salesman" class="csl-entry" role="listitem">
Travelling salesman problem. 2024. <span>“Travelling Salesman Problem— <span>W</span>ikipedia<span>,</span> the Free Encyclopedia.”</span> <a href="https://en.wikipedia.org/w/index.php?title=Travelling_salesman_problem&amp;oldid=1209291065">https://en.wikipedia.org/w/index.php?title=Travelling_salesman_problem&amp;oldid=1209291065</a>. [Online; accessed 27-February-2024].
</div>
<div id="ref-Wedgwood2013a" class="csl-entry" role="listitem">
Wedgwood, Ralph. 2013. <span>“Gandalf’s Solution to the Newcomb Problem.”</span> <em>Synthese</em> 190 (14): 2643–75. doi: <a href="https://doi.org/10.1007/s11229-011-9900-1">10.1007/s11229-011-9900-1</a>.
</div>
<div id="ref-Weisberg2007" class="csl-entry" role="listitem">
Weisberg, Michael. 2007. <span>“Three Kinds of Idealization.”</span> <em>The Journal of Philosophy</em> 104 (12): 639–59. doi: <a href="https://doi.org/10.5840/jphil20071041240">10.5840/jphil20071041240</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/brian\.weatherson\.org\/quarto-papers");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>