What are we doing when we do decision theory? What questions are decision theorists trying to answer? And what do we gain by knowing those answers?

Most philosophical decision theorists would answer these questions with something like the view I'll call **prescriptivism**. We're trying to say how people should ideally decide, and knowing how people should decide will help people make better decisions. On this model, the decision theorist is like a high school coach saying "Here's how the good ones make decisions, now go out and act like them."

I'm going to argue against prescriptivism, and in favour of **explanationism**. According to explanationism, decision theory is primarily a descriptive project. It says this is how people actually make decisions, at least approximately, some of the time. What we gain from this is access to a certain kind of explanation of various social phenomena. On this model, the decision theorist is like a high school science teacher saying "Here's how things work in a very simplified model, but even this simplified model shows you something about the world."

The big difference between the two views comes in how they treat the idealisations involved in decision theory. I'll spend some time in this paper on just what those idealisations are, though hopefully the point that there are some is common ground. On the prescriptivist view, when we say that a decision maker ideally does X, we mean that doing X is perfect, and we should aim to be a more perfect deciders. On the explanationist view, the idealisations are models.^[Whether they are what @Weisberg2007 calls "Galilean idealisations" or "minimal idealisations" depends on just what use they are being put to. The ones that I'm going to talk about are primarily the latter.] These models are not standards of perfection. We don't think the fact that molecules in the toy model used to derive the ideal gas law are point-sized mean that having zero volume is a perfection, or that it is better for molecules to be smaller. It's just that their size is unimportant for the phenomena we're explaining, and so we abstract away from it.

I'll start with two reasons for rejecting the prescriptivist view. One is that it does not treat like cases alike. In particular, it makes a distinction between empirical uncertainty and arithmetic uncertainty that it should not, were it a prescriptive theory. The second is that it would be bad to resemble the 'ideal' in some respects. To play its prescriptive role, decision theory would have to be supplemented with a theory about which aspects of the ideal are and are not worthy of emulation. There isn't much work on this question, and it isn't at all clear that it would be easier to solve it than to directly provide workable advice.

Setting out the 