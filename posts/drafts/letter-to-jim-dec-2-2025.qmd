---
date: 4 December 2025
draft: true
format:
    pdf:
        geometry: "left=1.1in,
                 right=1in,
                 top=0.8in,
                 bottom=0.8in,
                 paperheight=11in,
                 paperwidth=8.5in,
                 includemp=TRUE,
                 marginparwidth=0in,
                 marginparsep=0in"
        include-after-body:
            text: |
                \vspace{1pt}
        include-in-header: 
            file: ../quarto2024-blank.tex
---

\noindent Hi Jim,

I'm looking forward to the EWIP on Friday. I had a couple of thoughts that I thought would be best to get to you before then. That's mostly because they concern bees in my bonnet that it wouldn't be worth wasting EWIP time on. But also there are a couple of things that might be easier to write down than not.

### Misers {-}

I'm not really convinced that rational misers are coherent. Money has exchange value not use value. (If not, it's not really money.) And rational people first exchange it for things they want more and then things they want less. So to a first approximation, the declining marginal utility of money follows just from the metaphysics of money and the rationality of actors. Now none of this matters, because you're just doing finite games and you could say the payouts are lottery tickets which (assuming Buchak is wrong about risk sensitivity) have constant utility. Still, I don't like it as an assumption.

### Probability and Possibility {-}

There's a really fun example (for at least some value of 'fun') where probability 1 and certainty come apart. Assume you have two options *A* and *B*, and Sybill has probability 1 of being correct. The payouts are given in @tbl-red-green.

|    |  *S~A~* | *S~B~* |
|:--:|:-------:|:------:|
| *A* |   1    |    1   |
| *B* |   1    |    0   |

: Probability 1 comes apart from certainty {#tbl-red-green}

In equilibrium you'll play *A* with probability 1, and hence Sybill will predict *A* with probability 1. That means *B* has the same expected utility as *A*, and can be **rationally** picked. So even if you know you'll be rational, you can't be certain you won't play *B*. But it's probability 1 that you won't.

### Buridan {-}

Is this what Buridan says? I thought he didn't even discuss the donkey; it was a later example put forward by critics of his view. The view, by the way, isn't much different to the view you're describing here, so it would make sense for him to say that. My main knowledge of this comes from @AdamsonMedieval [ch. 65], so it's all very second hand.

### Sophisticated {-}

Using this name for your view makes it seem like it will be very close to sophisticated choice theories of rational decision. Is this intentional? I'm not sure that it's a good idea, since there are a few differences.

### Mixed Strategies {-}

My current view is that saying mixed strategies are always available is the same kind of reasonable idealisation as assuming self-knowledge (as you explicitly do), or assuming perfect and costless computational skills (as I think you implicitly do). Sure a randomising device might not be available, but a way of multiplying large numbers might not be either, yet we assume away the second complication. I'm not sure why the first is more implausible.

If that means Frustrator isn't really possible, well that's fine with me!!

### Asymmetric Death in Damascus {-}

Do you have a story for how the following can be possible together?

1. Chooser picks between some options that have equal expected value.
2. Chooser has asymmetric credences about which option they'll take.

This should happen, if I've understood the theory correctly, if we modify Frustrator to add a dollar to each of the *A* outcomes. The story you tell in sections 4-6 about picking doesn't make it obvious why asymmetric probabilities should be possible. 

Is it something like that you should still pick, but you have some slightly higher credence that you'll pick B, so the expected values of the two options are the same? If so, why should you be more confident you'll pick B? I'm mostly puzzled about how the theory handles this case.

### Downstream Reach {-}

I didn't get exactly how the constraint in section 8 was supposed to apply. Here are some variant cases about what might happen at 12.01 that I think shouldn't make a difference, but I can't quite tell why, on your view, they don't.

At 12.01 you have a choice between punching yourself in the head or not doing that. Punching yourself has a utility of -10, and is independent of what Sybill does. Now you've got a choice at 12.01, so it's not completely degenerate.

But maybe dumb choices are ruled out. OK, let's say at 12.01 you have three choices: Raise left hand, Raise right hand, Do nothing. If you do nothing, the boxes won't be opened, and you'll get nothing. Raising a hand is how you request opening the boxes, but it doesn't make a difference which hand you use. Still, it's a decision. So does this mean news value applies.

Maybe we want to collapse equivalent choices. OK, change the case a little more. If you raise your left hand, after the box is opened a coin will be flipped. If it lands heads, you'll get double what's in the box; if it lands tails, you'll get nothing. If you raise your right hand, you'll get the box. As a rational miser, you're indifferent between the hands, but that's fairly contingent. Is this a further decision?

Or maybe some of the stuff at the end about types is meant to help with these problems. I wasn't sure I was completely following that, but maybe the view is that given a type, you won't have any real decisions left?
