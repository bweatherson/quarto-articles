---
title: "Trends in *Philosophical Studies*"
abstract: |
  *Philosophical Studies* has become one of the most important journals for work in several large topics in philosophy. This paper uses data from the word distributions in those papers, and the citations of the papers, to look at how it has changed over time, and how it became so central.
date: today
draft: false
execute:
  echo: false
  warning: false
author:
  - name: Brian Weatherson 
    url: http://brian.weatherson.org
    affiliation: University of Michigan
    affiliation_url: https://umich.edu
    orcid_id: 0000-0002-0830-141X
categories:
  - history of analytic
  - unpublished
  - in progress
format:
    html:
       css: ../trad_defn.css
    pdf:
      fig-format: pdf
      output-file: "Trends in Philosophical Studies"
      include-in-header:
        - file: ../quarto2024.tex
        - text: |
            \setkomafont{descriptionlabel}{\normalfont\scshape\bfseries}
      include-after-body: 
        text: |
          \noindent Published online in October 2024.
format-links: [html]
bibliography: 
  - /Users/weath/Documents/citations-2025/autobib.bib
  - /Users/weath/Documents/quarto-articles/brian-quarto.bib
---

```{r}
#| label: loader
#| cache: false

for (ipkg in c("tidyverse", 
               "tidytext", 
               "tm", 
               "topicmodels", 
               "lsa",
               "slider",
               "knitr")) {
  if (!require(ipkg, character.only = TRUE)) {
    install.packages(ipkg)
    library(ipkg, character.only = TRUE)
  }
}

if (knitr::is_latex_output()) {
  knitr::opts_chunk$set(dev = 'cairo_pdf')
}

options(knitr.kable.NA = '')

# Graph Themes
old <- theme_set(theme_minimal())
theme_set(old)
theme_update(plot.title = element_text(family = "Scala Pro", size = 24, face = "bold"),
             plot.subtitle = element_text(family = "Scala Sans Pro", size = 20),
             axis.text = element_text(family = "Scala Sans Pro", size = 18),
             axis.title = element_text(family = "Scala Sans Pro", size = 18),
             plot.background = element_rect(fill = "#F9FFFF"),
             panel.background = element_rect(fill = "white"),
             legend.background = element_rect(fill = "#F9FFFF"),
             panel.grid = element_line(color = "grey92"),
             legend.text = element_text(family = "Scala Sans Pro", size = 20),
             strip.text = element_text(family = "Scala Sans Pro", size = 20),
             legend.key.spacing.y = unit(1, 'lines'),
             legend.key.spacing.x = unit(1, 'cm')
  )

if (knitr::is_latex_output()) {
theme_update(plot.title = element_text(family = "Europa-Bold", size = 14),
             plot.subtitle = element_text(family = "EB Garamond", size = 11),
             axis.text = element_text(family = "EB Garamond", size = 10),
             axis.title = element_text(family = "EB Garamond", size = 10),
             plot.background = element_rect(fill = "white"),
             panel.background = element_rect(fill = "white"),
             legend.background = element_rect(fill = "white"),
             panel.grid = element_line(color = "grey92"),
             legend.text = element_text(family = "EB Garamond", size = 11),
             strip.text = element_text(family = "EB Garamond", size = 12),
             legend.key.spacing.y = unit(-0.3, 'lines'),
             legend.key.spacing.x = unit(0, 'cm')
  )

}

load("~/Documents/lda-cites-unigrams-only/ps_cites.RData")
load("~/Documents/lda-cites-unigrams-only/ps_meta.RData")
load("~/Documents/lda-cites-unigrams-only/ps_join.RData")
load("~/Documents/lda-cites-unigrams-only/common_ps_words.RData")
load("~/Documents/lda-cites-unigrams-only/ps_lda_s155376_c5_r1000.RData")
load("~/Documents/citations-2025/philo_cite.RData")
load("~/Documents/citations-2025/philo_bib.RData")
```

```{r}
#| label: commontibs
#| cache: true

philo_bib <- philo_bib |>
  mutate(year = as.numeric(year))

id_year_journal <- philo_bib |>
  select(wos_id = id, year, journal)

all_cites <- philo_cite |>
  rename(old = refs, new = id) |>
  left_join(id_year_journal, by = c("old" = "wos_id")) |>
  rename(old_year = year, old_journal = journal) |>
  left_join(id_year_journal, by = c("new" = "wos_id")) |>
  rename(new_year = year, new_journal = journal) |>
#  filter(old_year >= 1980, old_year <= 2019) |>
  mutate(decade = paste0(floor(new_year/10),"0s")) |>
  mutate(citing_journal = case_when(
    new_journal == "Philosophical Studies" ~ "PS",
    TRUE ~ "NPS")) |>
  mutate(cited_journal = case_when(
    old_journal == "Philosophical Studies" ~ "PS",
    TRUE ~ "NPS"))
  
active_cites <- all_cites |>
  filter(old_year >= 1980, old_year <= 2019)

article_count <- philo_bib |>
  ungroup() |>
  filter(year >= 1980, year <= 2019) |>
  group_by(journal, year) |>
  tally(name = "articles")

journal_citation_count <-  active_cites |>
    ungroup() |>
    group_by(old_journal) |>
    tally(name = "Citations") |>
    rename(Journal = old_journal) |>
    arrange(-Citations)

journal_article_count <-   article_count |>
    ungroup() |>
    group_by(journal) |>
    summarise(Articles = sum(articles)) |>
    rename(Journal = journal) |>
    arrange(-Articles)

journal_citation_rate <- left_join(
  journal_article_count,
  journal_citation_count,
  by = "Journal") |>
  mutate(`Citation Rate` = round(Citations/Articles, 2)) |>
  arrange(desc(`Citation Rate`))
```


# Intro

TKTK 

# Sources {#sec-sources}

This article is primarily based on data-driven analysis of articles published in philosophy journals, and in particular in _Philosophical Studies_, from 1980 to 2019. The studies here are primarily based on two sources: citation data from Web of Science, and word lists from JSTOR.

Through [University X] I downloaded the Web of Science (hereafter, WoS) Core Collection in XML format. Within it, I selected 100 prominent philosophy journals that WoS indexes. The journals I selected are, like _Philosophical Studies_ primarily English-language, analytic philosophy journals. I filtered the citations for just citations from and to those 100 journals. So what we're working with is citations of philosophy journals in philosophy journals.

This is obviously a small subset of all citations. It excludes citations in academic journals in other fields, in books and edited volumes, and in many other places that Google Scholar indexes, such as dissertations, lecture notes, slides, and draft manuscripts. Losing that information is a cost, but there are three large upsides. First, these citations are much more accurate; I haven't found any false positives when using this filtered set, and only a handful of false negatives. Second, we can be more confident that our data set is relatively complete; finding a full list of philosophy journals is easier than finding a full list of edited volumes in philosophy. Third, by looking at citations internal to philosophy, we can get a sense of philosophy's self-image, and how it changes over time.

The downloadable citation data is not particularly up to date. I am including citations beyond 2019, because it's helpful to get a sense of how some of these articles have been received in more recent years. But the data I have only goes through mid-2022. I'll often simply say 2022; but note that even that year is incomplete.

The other source I used is JSTOR, and in particular the Data for Research (DfR) program that they provide through their Constellate project. This lets you download lists of the words used in various journal articles, along with a count of how often each word is used.^[It also provides bigrams and trigrams, which I've occasionally used.] It also provides word counts for the articles, which I have used in @sec-overview. The words an author uses are a pretty good guide to what they are talking about; if the word 'denotation' is used frequently, it's probably a philosophy of language article.

# Inbound Citations {#sec-overview}

## Overview of Citations {#sec-citations-overview}

Articles in _Philosophical Studies_ get cited a lot. Our first study is simply a count of citations in the 100 journals to articles published in the 100 journals between 1980 and 2019. @tbl-all-cites shows the five journals with the largest number of citations.

```{r}
#| label: tbl-all-cites
#| tbl-cap: "Leading journals by total number of citations (Articles published 1980-2019)."

kable(
  journal_citation_count |>
    slice(1:5)
)
```

_Philosophical Studies_ is in first place on that list in part, but only in part, because it publishes so much. @tbl-all-articles lists the top five journals by the number of articles they have published.

```{r}
#| label: tbl-all-articles
#| tbl-cap: "Leading journals by total number of articles (Articles published 1980-2019)."

kable(
  journal_article_count |>
    slice(1:5)
)
```

_Synthese_ has 20% more articles, but 25% fewer citations. The other three journals on that list are somewhat special cases. Two of them get a lot of citations outside of philosophy, and this is only a study of citations in philosophy journals, and _Analysis_ only publishes short papers, and so while they get a lot of citations per page, they don't get as many citations per article as other journals.

Still, we'd expect on general principles that raw volume of publication wouldn't make a big difference. Citations tend to follow something like a log-normal distribution [@Brzezinski2015]. The bulk of the citations come from a handful of highly cited articles. Publishing more articles helps, but is no guarantee. 

If we look not at total citations, but at citations per article as in @tbl-citation-rate, we get a list that looks a bit more like a familiar ranking of philosophy journals by prestige.

```{r}
#| label: tbl-citation-rate
#| tbl-cap: "Leading journals by citation rate (Articles published 1980-2019)."

ranked_journal_citation_rate <- journal_citation_rate |>
  rowid_to_column(var = "Rank")

this_table <- bind_rows(
  ranked_journal_citation_rate |> slice(1:5),
  tibble(
    Journal = "...",
  ),
  ranked_journal_citation_rate |> slice(13:14)
)

kable(
  this_table
)
```

I've included _Philosophy and Phenomenological Research_ there because, like _Philosophical Studies_, it publishes many book symposia. And, like _Philosophical Studies_, the articles in these symposia are typically not cited very much.

## Articles? {#sec-what-is-article}

This raises a tricky question of what exactly counts as an _article_. We all have a sense of what a paradigm article, like "Two Notions of Necessity" [@WOSA1980KA40400001] is an article; the table of contents is not, and nor are corrections. Nor are book reviews; if they were then _Philosophical Review_ would have ten times as many articles listed. But there are trickier cases. Which parts of a book symposium are articles? A symposium typically has a précis, some commentary articles, and some replies. One could make a case for all of these being articles, or none of them. They are all somewhat borderline cases. _Philosophical Studies_ also publishes various conference proceedings. The main papers at these conferences are clearly articles; in fact, they include some of the most highly cited articles the journal has published. But in some cases they also publish commentaries on the papers, and one could go either way on classifying those as articles or something else.^[One of these conference proceedings, in 2011, included Tamar Szabò Gendler's influential "The Epistemic Costs of Implicit Bias" [@WOS000295087100003], which is the first article in the journals I'm looking at with the phrase 'implicit bias' in the title. It also included a widely cited commentary on that article by Andy @Egan2011. Web of Science classified the commentary as "Editorial Matter". While that's clearly wrong, I'm not sure what the right classification should be. Unlike Egan's commentary, most of these commentaries get very few citations, so excluding them doesn't make a huge difference to the totals, and slightly increases the average.]

Web of Science has five main classifications of entries other than corrections, front matter, etc: Articles, which is what we're primarily using, Book-Review, which we're wholly excluding, and then Discussion, Review, and Note. These sometimes get used for things that either are clearly not articles, e.g., lists or work published on a topic recently, and sometimes for short pieces that are probably best excluded from citation analysis. The short pieces listed as discussion notes that journals like _Mind_, _Australasian Journal of Philosophy_, and _British Journal for the Philosophy of Science_ frequently print often fall into this category.

Sometimes, however, more substantive pieces get listed under one of these categories. This seemed to be a particular problem with _Philosophical Review_, I suspect simply because of the word 'Review' in the name. Major works by Stanley @WOSA1962CGX0500005, Jonathan @WOS000272855000002, and Harvey @WOS000810220800002 all got listed as not being articles.^[The Cavell article was in the discussion section of the January 1962 issue of the Review, so this classification is understandable. The other two are not.] For purposes of this paper, I've decided to treat anything twenty pages or longer as an article, even if it was listed as a Discussion, Review, or Note. One could argue that this includes too much. Should the review essay that Sophie Grace @WOS000540751100005 wrote on Cora Diamond's recent book count as an article? It was originally listed as a review, but because it's twenty pages, I counted it. You could make a case either way. This doesn't much affect _Philosophical Studies_, but I'm bringing it up to note the complexities here.

Another way to see the complexities comes from comparing the two data sources that I'm using for this piece: Web of Science and JSTOR. The two do not agree on which articles in book symposia are capital-A Articles, as well as on some conference papers. Unfortunately, this is not because they have different principles for how to classify these pieces. Rather, they are both a bit haphazard in their classifications, but in slightly different ways. Both of them will sometimes count symposia entries as book reviews (or occasionally as discussions, notes, or reviews), and sometimes not, and if there's a pattern in either case, I haven't found it. My view is that these are all borderline cases, and so none of the classifications is determinately wrong, but it would be nice to have a more consistent principle.

Because it would be impractical to reclassify all 200,000 entries from the journals I'm looking at, I've decided to mostly go with Web of Science's classifications, subject to the proviso above that I've added back in things twenty pages or longer from three small categories. Different ways of classifying papers, at least as plausible as the one I'm using from Web of Science, could move any of these citation numbers by ten percent or more, so take all the numbers I'm listing as having large error bars. But hopefully they are at least directionally useful.

## Large Trend

Even with those possible errors in mind, it is striking to look at the step-change in citations to _Philosophical Studies_ that occurred in the mid-2000s. Cross-temporal comparisons of citations are hard because changes in the number of journals, the number of articles in those journals, and citation norms, make most comparisons tricky. To try to screen off some of that noise, I'll mostly compare citations to articles published in _Philosophical Studies_ to citations to other articles published at the same time.

In particular, in this section I'll compare _Philosophical Studies_ to a list of nineteen other prominent philosophy journals. From the one hundred journals that I'm primarily looking at, I selected the twenty that have the highest rate of citations per published article, and which Web of Science has indexed every year since 1980.^[The last constraint notably rules out _Philosophers' Imprint_ and _Mind and Language_.] That list includes _Philosophical Studies_, and the other nineteen journals are the comparison class.

@fig-compare-cites-dots shows, for each year from 1980 to 2019, the average number of citations for articles published in _Philosophical Studies_ (in blue), and in the other nineteen (in red). The figure is fairly noisy, but some trends are clear. Before 2000, the red dots, for the other journals, are mostly above the blue dots, for _Philosophical Studies_. After 2000, and especially from 2003 onwards, that is mostly reversed. Despite having less time to accrue citations, articles from the 2000s are cited more, on average, than articles published earlier. But articles published in the 2010s, especially the late 2010s, have many fewer cites largely because they haven't been around as long.

```{r}
#| label: fig-compare-cites-dots
#| fig-cap: "Average citation rates for _Philosophical Studies_ and peer journals."

comp_journal_count <- 20
comp_tag <- paste0(
  "Other top ",
  comp_journal_count,
  " journals"
)

first_year <- philo_bib |>
  group_by(journal) |>
  summarise(first_year = min(year)) |>
  left_join(journal_citation_rate, by = c("journal" = "Journal")) |>
  filter(first_year <= 1980) |>
  arrange(-`Citation Rate`)

comparison_journals <- first_year$journal[1:comp_journal_count]

ps_comp_rate <- active_cites |>
  ungroup() |>
  group_by(old_year, cited_journal) |>
  filter(old_journal %in% comparison_journals) |>
  tally(name = "citations") |>
  ungroup() |>
  rename(year = old_year) |>
  left_join(
    philo_bib |>
      filter(year >= 1980, year <= 2019,
             journal %in% comparison_journals) |>
      mutate(cited_journal = case_when(
        journal == "Philosophical Studies" ~ "PS",
        TRUE ~ "NPS")) |>
      group_by(year, cited_journal) |>
      tally(name = "articles"),
    by = c("cited_journal", "year")) |>
  mutate(rate = citations/articles) |>
  ungroup() |>
  group_by(cited_journal) |>
  arrange(year) |>
  mutate(slide_arts = slide_dbl(articles, sum, .before = 4),
         slide_cites = slide_dbl(citations, sum, .before = 4),
         slide_rate = slide_cites/slide_arts) 
    

ps_comp_rate_wide <- ps_comp_rate |>
  pivot_wider(
    id_cols = year,
    names_from = cited_journal,
    values_from = slide_rate) |>
  mutate(comp = round(PS/NPS, 3))

ggplot(ps_comp_rate |>
         left_join(
           tribble(
             ~cited_journal, ~Journal,
             "PS", "Philosophical Studies",
             "NPS", comp_tag,
           ),
           by = "cited_journal"), 
       aes(x = year, y = rate, color = Journal)) +
       geom_point() +
       labs(x = "Publication Year",
            y = "Citations per article",
            color = element_blank())
```

@fig-compare-cites-rolling smooths out some of the noise in @fig-compare-cites-dots in two ways. First, instead of measuring average citations per year, I measure average citations over a five-year rolling window. This doesn't make a huge difference to the measure for the other nineteen, which is already fairly smooth, but it is useful for smoothing the values for just one journal. Second, instead of showing the red and blue dots separately, I've just displayed the ratio between them.

```{r}
#| label: fig-compare-cites-rolling
#| fig-cap: "Ratio of citations to Philosophical Studies to citations to other journals, for five year rolling windows"

ggplot(ps_comp_rate_wide,
       aes(x = year, y = comp)) +
  geom_point() + 
  labs(x = "Publication Year",
       y = "Ratio",
       subtitle = "Ratio of citation rate in Philosophical Studies to citation rate in other top 20 journals; five year rolling average.") +
  theme(plot.subtitle = element_text(family = "Scala Sans Pro", size = 16))
```

The difference in @fig-compare-cites-rolling between the earlier and recent years is striking. By this one measure, citations per article, _Philosophical Studies_ was doing ok before 2003, but was towards the lower end of the top 20 journals. After 2003, it is doing better than the average journal _in the top 20_.

My very anecdotal impression is that _Philosophical Studies_ is viewed as being more prestigious by younger philosophers than by older philosophers. A toy model of prestige, where it is heavily anchored to how often a journal was cited when one was in graduate school, would explain that difference. That said, I have not done (and am not going to do) a careful study of comparative prestige judgments to know if there is even an effect here to find, or whether my informal sample was not reflective of the wider population.

What's more useful is to look at how things changed in the mid-2000s. Part of the story is that _Philosophical Studies_ started publishing more articles that got a large number of citations. @tbl-top-mid-2000s shows the citation count for some prominent articles from 2003-2007, along with their rank (by citations in philosophy journals) among all articles ever published in _Philosophical Studies_.

```{r}
#| label: tbl-top-mid-2000s
#| tbl-cap: "Highly cited articles from 2003-2007."

citation_count <- active_cites |>
  group_by(old) |>
  tally(name = "cites")

short_bib <- philo_bib |>
  select(id, year, displayauth, title, journal) |>
  left_join(citation_count, by = c("id" = "old")) |>
  replace_na(list(cites = 0))

ps_top_cites <- short_bib |>
  filter(journal == "Philosophical Studies") |>
  slice_max(order_by = cites, n = 30) |>
  arrange(-cites) |>
  rowid_to_column(var = "Rank") |>
  filter(year >= 2003, year <= 2007) |>
  mutate(id = sub(":", "", id)) |>
  mutate(Article = paste0(
    "@",
    sub(":", "", id)
  )) |>
  select(Rank, Article)

kable(ps_top_cites)
```

While it is notable that this five year period included 9 of the top 30 articles by citations, including the top one^[There is a huge gender bias in citations, at least before very recent years, so it is unusual for a journal to have its most cited article be one written by a woman. The gender imbalance in the rest of the list is more typical. This does change a bit if you look just at citations since about 2016, and when we get more data in from the 2020s, it will be very interesting to see how much it has changed.], this isn't all of the story. Just as important is how widely spread around the citations were.

Average numbers of citations can be very misleading. @tbl-quartiles-two-journals compares five year periods from two journals: the _Australasian Journal of Philosophy_ (AJP) from 1980-1984, and _Philosophical Studies_ (PS) from 2003-2007. Q1, Q2 and Q3 are the values such that at least 25%, 50%, and 75% (respectively) of articles from those journals (in those years) have at least that many citations. And at the bottom I've included the average number of citations for articles in those journals, in those years.

```{r}
#| label: tbl-quartiles-two-journals
#| tbl-cap: "Statistics for  AJP 1980-1984, and PS 2003-2007."

this_table <- short_bib |>
  filter(journal == "Australasian Journal Of Philosophy",
         year >= 1980,
         year <= 1984) |>
  summarise(Q1 = round(quantile(cites, 0.25),1),
            Q2 = round(quantile(cites, 0.5),1),
            Q3 = round(quantile(cites, 0.75),1),
            Mean = round(mean(cites),1)) |>
  pivot_longer(cols = everything(),
               names_to = "Statistic",
               values_to = "AJP 1980-1984") |>
  left_join(
    short_bib |>
  filter(journal == "Philosophical Studies",
         year >= 2003,
         year <= 2007) |>
  summarise(Q1 = round(quantile(cites, 0.25),1),
            Q2 = round(quantile(cites, 0.5),1),
            Q3 = round(quantile(cites, 0.75),1),
            Mean = round(mean(cites),1)) |>
  pivot_longer(cols = everything(),
               names_to = "Statistic",
               values_to = "PS 2003-2007"),
  by = "Statistic"
  )
```

The mean number of citations per article is higher for AJP 1980-1984 than for _Philosophical Studies_ 2003-2007. But that's because of the `r sum(temp_ajp$cites)` citations to articles from the AJP in those years, `sum(filter(temp_ajp, displayauth == "David Lewis")$cites)` of them are to five articles by David Lewis. The citations to _Philosophical Studies_ are much more widely spread around.

Now in some part, that's because citations have become more evenly spread around in general in recent philosophy than they were in the 1980s. But it's also in part because _Philosophical Studies_ stands out for how widely spread around its citations are. @fig-quartiles-ps-vs-19 shows this. I've taken the same 19 journals that I used in @fig-compare-cites-rolling, and calculated the same quartile statistics for _Philosophical Studies_, and for those 19 journals collectively, each year from 1980 to 2019. The individual year numbers are rather noisy, so I've also included a five-year rolling average.

```{r}
#| label: fig-quartiles-ps-vs-19
#| fig-cap: "Quartiles of citation counts for _Philosophical Studies_ and other leading journals."

this_table <- short_bib |>
  filter(journal %in% comparison_journals,
         journal != "Philosophical Studies") |>
  mutate(cited_journal = "Other top 20") |>
  bind_rows(short_bib |>
              filter(journal == "Philosophical Studies") |>
              mutate(cited_journal = "Philosophical Studies")) |>
  group_by(cited_journal, year) |>
  filter(year >= 1980, year <= 2019) |>
  summarise(Q1 = round(quantile(cites, 0.25),1),
            Q2 = round(quantile(cites, 0.5),1),
            Q3 = round(quantile(cites, 0.75),1),
            .groups = "drop") |>
  pivot_longer(cols = starts_with("Q"),
               names_to = "statistic",
               values_to = "value") |>
  ungroup() |>
  group_by(cited_journal, statistic) |>
  mutate(rolling = slide_dbl(value, mean, .before = 4)) |>
  ungroup()

ggplot(this_table,
       aes(x = year, y = value, color = statistic)) +
  facet_wrap(vars(cited_journal),
             nrow = 1) +
  geom_point() +
  theme(legend.position = "none") +
  labs(x = "Publication Year",
       y = "Citation Count") +
  scale_x_continuous(breaks = c(1990, 2000, 2010)) +
  scale_y_continuous(limits = c(0, 20)) +
  geom_line(aes(x = year, y = rolling, color = statistic))
```

The height of the peak of the right-hand graph in @fig-quartiles-ps-vs-19 is striking. _Philosophical Studies_ was publishing a lot of articles, and at least a quarter of them are getting well into double-digit citations just in philosophy journals. This tells us that the influence _Philosophical Studies_ was having in philosophy changed, especially over the 2000s. To see how it changed, we need to look inside the journal.

# History of _Philosophical Studies_ {#sec-articles}

## Editorial History

A change like we see in the early 2000s is often a sign of editorial change in the journal. This isn't the case at _Philosophical Studies_, which has had a remarkably stable editorial history.

It was founded by Herbert Feigl and Wilfrid Sellars, both then at the University of Minnesota, in 1950, as the "first American journal expressly devoted to analytic philosophy" [@deVries2005 1-2]. They stayed as editors until Feigl's retirement in 1971, though after 1954 Sellars was listed as the first editor. At Feigl's retirement the journal moved from the University of Minnesota Press to Reidel, where it has stayed ever since.^[Springer is the current continuant of Reidel after several mergers and takeovers.] Sellars edited the journal alone until Keith Lehrer was brought on as associate editor in 1974, starting an association with the journal that would last nearly half a century. The next year Lehrer, who had just moved from Rochester to Arizona, became editor. He stayed in that role until 1982, having been joined by John Pollock (also at Rochester) in 1979. From 1982, Pollock was Editor-in-Chief, and Lehrer went back to being Associate Editor. In 1992 the journal moved 100 miles up I-10, as Stewart Cohen, then at Arizona State, took over as Editor.^[While the journal was at Arizona, at grad student assistant was recognised on the title page as an editorial assistant. Many prominent philosophers had this role over the years, including, in 1983, Stewart Cohen.] Cohen stayed as editor through the rest of the time covered in this study, eventually being an editor of the journal for longer than even Wilfrid Sellars. Thomas Blackson joined as book symposium editor in 2003. Jennifer Lackey and Wayne Davis, who would eventually take over from Cohen, joined as Associate Editors in 2014. In 2016 Cohen was made Editor-in-Chief, while Davis and Lackey were made Editors. None of these changes seem to line up with changes in the citation rate of the journal, so we'll have to look a little deeper to see what happened.

## Publication Rate

Unlike many other journals, _Philosophical Studies_ has had dramatic changes over the years in the number of papers, and number of pages, it publishes per year. The move from University of Minnesota Press to Reidel already led to a large expansion in the size of the journal. And the changes haven't stopped there.^[The studies here all use JSTOR data, not Web of Science, because JSTOR includes word counts. But I'm still using Web of Science's classifications of articles, so this includes some pieces that JSTOR considers to be book reviews.]

We'll start with some basic quantity data about the journal. @fig-article-count-by-year shows how many articles _Philosophical Studies_ has published each year; @fig-word-count-by-year shows the total word count for the journal each year; @fig-word-max-by-year shows the count of the longest article each year; and @fig-word-quartiles shows the 25th, 50th, and 75th percentile article by word count for each year.

```{r}
#| label: article-summary-setup
#| cache: true

ps_meta <- read_csv("posts/phil-studies/PS-metadata.csv",
                    show_col_types = FALSE) |>
  filter(docSubType == "research-article" | docSubType == "book-review") |>
  mutate(id = paste0("PS-", str_sub(id, start = 29))) |>
  mutate(journal = "Philosophical Studies") |>
  select(id, 
         title, 
         journal, 
         year = publicationYear, 
         num = issueNumber, 
         volume = volumeNumber, 
         author = creator, 
         fpage = pageStart,
         lpage = pageEnd,
         words = wordCount) 

ps_meta_binder <- ps_meta |>
  select(id, volume, fpage) |>
  select(jstor_id = id, volume, fpage)

ps_papers <- philo_bib |>
  filter(journal == "Philosophical Studies") |>
  filter(year >= 1980) |>
  filter(year <= 2019)

ps_papers_binder <- ps_papers |>
  select(wos_id = id, volume, fpage) |>
  mutate(volume = as.numeric(volume)) |>
  mutate(fpage = as.character(fpage))

ps_join <- inner_join(
  ps_meta_binder,
  ps_papers_binder,
  by = c("volume", "fpage")
) |>
  select(wos_id, jstor_id)

ps_meta_filter <- ps_meta |>
  filter(id %in% ps_join$jstor_id)

article_count_by_year <- ps_meta_filter |>
  group_by(year) |>
  tally(name = "Articles")

word_count_by_year <- ps_meta_filter |>
  group_by(year) |>
  summarise(wordcount = sum(words))

word_max_by_year <- ps_meta_filter |>
  group_by(year) |>
  summarise(wordmax = max(words))

word_quartile_by_year <- ps_meta_filter |>
  group_by(year) |>
  summarise(Q1 = round(quantile(words, 0.25),1),
            Q2 = round(quantile(words, 0.5),1),
            Q3 = round(quantile(words, 0.75),1),
            .groups = "drop") |>
  pivot_longer(cols = starts_with("Q"),
               names_to = "statistic",
               values_to = "value") |>
  ungroup() |>
  group_by(statistic) |>
  mutate(rolling = slide_dbl(value, mean, .before = 4)) |>
  ungroup()
```

```{r}
#| label: fig-article-count-by-year
#| fig-cap: "Number of articles published each year"

ggplot(article_count_by_year,
       aes(x = year, y = Articles)) +
  geom_point() +
  labs(x = element_blank(),
       y = "Number of Articles") +
  scale_x_continuous(breaks = c(1990, 2000, 2010)) +
  scale_y_continuous(limits = c(0, 275))

```

```{r}
#| label: fig-word-count-by-year
#| fig-cap: "Number of words published each year"

ggplot(word_count_by_year,
       aes(x = year, y = wordcount)) +
  geom_point() +
  labs(x = element_blank(),
       y = "Number of Words") +
  scale_x_continuous(breaks = c(1990, 2000, 2010)) +
  scale_y_continuous(labels = scales::scientific,
                     limits = c(0, 2500000))

```

```{r}
#| label: fig-word-max-by-year
#| fig-cap: "Longest article published each year"

ggplot(word_max_by_year,
       aes(x = year, y = wordmax)) +
  geom_point() +
  labs(x = element_blank(),
       y = "Number of Words") +
  scale_x_continuous(breaks = c(1990, 2000, 2010)) +
  scale_y_continuous(limits = c(0, 30000))

```

```{r}
#| label: fig-word-quartiles
#| fig-cap: "25th, 50th, and 75th percentile word lengths each year."

ggplot(word_quartile_by_year,
       aes(x = year, y = value, color = statistic)) +
  geom_point() +
  theme(legend.position = "none") +
  labs(x = element_blank(),
       y = "Word Count") +
  scale_x_continuous(breaks = c(1990, 2000, 2010)) +
  scale_y_continuous(limits = c(0, 12500)) +
  geom_line(aes(x = year, y = rolling, color = statistic))
```

# Studies

Number of articles
Length of articles
Number of articles over 10K, 15K, 20K
Average citations over the 100 journals - boring because can't compare
Average citations compared to top 25 - more interesting
Maybe redo that graph as a ratio

# Comparisons

Articles with highest ratio of PS cites/general cites
Articles with lowest ratio of PS cites/general cites
Previously I just did that with articles published in PS; that seems wrong

Hmm, this could be complicated. 
Study: For each decade find 20 most cited, and look at how often they are cited in PS.

For 1980s, the low is 0 for Rawls (1980) and Dennett (1971). But Rawls is cited in Post (1984), under a variant name, and Dennett is cited in Lormond (1985), but to the reprint. Maybe just live with the messiness
High five in 1980s are all language, or language-adjacent: Lewis (1979) (both de se and time's arrow), two Perry papers, and Donnellan

For 1990s, the low is 0 for McDowell's Virtue and Reason. Is in Brighouse (1990), but the citation is incomplete and uses the wrong year. Oddly the third lowest is for Discrimination and Perceptual Knowledge, only 2/38. And this looks right.
The highs in 1990s are still language based, though with metaphysics seeping in (Kim on supervenience, Lewis on Universals)

For 2000s, lows include Cummins (1975) (which is hard to track, such a common name), Anderson (1999), and Mechanisms paper (2000).
The highs are very epistemology based - Goldman is among them, and the two big contextualism papers by DeRose and Lewis. Obviously the editor at the time was also a prominent contextualist, but his papers are not cited in the journal at a particularly out of the ordinary rate. (There are many cases in history where editors are cited a lot, but this isn't one of them.)
Just outside top 20, but Jackson and Chalmers has nearly 1/3 its cites in PS. Tracing back to Davies and Humberstone's original paper.
Remarkably, Elusive Knowledge is most cited in the decade; normally this kind of calculation pushes towards less cited, high variance cases.

For 2010s, still mechanisms, Anderson (1999), also Kripke (1975) are the low ones
Top 5 is more varied, both in topic and time: Kolodny (2005), Pryor (2000), Lewis (1986), Frankfurt (1969), Jackson (1982). Could be result of publishing more papers, but striking that it's pulling these older papers in.

# The LDA

Build the model
Note the five categories
Graph the trends
Flag the methodology

# Language

Find the 40 most cited in each topic over the 40 years (i.e., most cited per year)
Look how often they are cited in PS
Look how often they are cited across the 100
See if the trends in PS track wider trends
Find other journals that have similar trends (Analysis, PQ, AJP)

# Metaphysics

Note the two Schaffer papers, and differences in citing @WOS000368189400004
Is that because little grounding
There is some - see graph of words
Maybe just count how 'modal' vs 'postmodal' the 2019 papers are
Maybe do a small LDA of the metaphysics papers

# Ethics

Is there anything to say here?
Does it go more political? Still not citing Anderson, but something?

Delicate. Even happening.
