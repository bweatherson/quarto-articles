{
  "hash": "91eb12d190334dfb28577c18054f55c3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Scepticism, Rationalism, and Externalism\"\ndescription: |\n  I argue that we have to accept one of the three isms in the title. Either inductive scepticism is true, or we have substantial contingent a priori knowledge, or a strongly externalist theory of knowledge is crrect. \ndate: February 9 2006\nauthor:\n  - name: Brian Weatherson \n    url: http://brian.weatherson.org\n    affiliation: University of Michigan\n    affiliation_url: https://umich.edu\n    orcid_id: 0000-0002-0830-141X\ndoi: \"10.1111/j.1520-8583.2005.00068.x\"\ncategories:\n  - epistemology\n  - scepticism\ncitation_url: https://doi.org/10.1111/j.1520-8583.2005.00068.x\njournal:\n    title: \"Oxford Studies in Epistemology\"\n    publisher: \"Oxford University Press\"\nvolume: 1\nnumber: 1\ncitation: false\nbibliography: ../../../articles/Rbib.bib\nself-contained: false\npreview: winter.jpg\noutput:\n  distill::distill_article:\n    toc: true\n    toc_depth: 3\n    number_sections: true\n---\n\n\n\nThis paper is about three of the most prominent debates in modern\nepistemology. The conclusion is that three *prima facie* appealing\npositions in these debates cannot be held simultaneously.\n\n<aside>\nPublished in _Oxford Studies in Epistemology_ 1: 311-31.\n</aside>\n\nThe first debate is **scepticism vs anti-scepticism**. My conclusions\napply to *most* kinds of debates between sceptics and their opponents,\nbut I will focus on the inductive sceptic, who claims we cannot come to\nknow what will happen in the future by induction. This is a fairly weak\nkind of scepticism, and I suspect many philosophers who are generally\nanti-sceptical are attracted by this kind of scepticism. Still, even\nthis kind of scepticism is quite unintuitive. I'm pretty sure I know (1)\non the basis of induction.\n\n<aside>\nThis paper has been presented at Cornell University and the Inland Northwest Philosophy Conference, and each time I received valuable feedback.\n</aside>\n\n1.  It will snow in Ithaca next winter.\n\nAlthough I am taking a very strong version of anti-scepticism to be\nintuitively true here, the points I make will generalise to most other\nversions of scepticism. (Focussing on the inductive sceptic avoids some\npotential complications that I will note as they arise.)\n\n<aside>\nThanks also to David Chalmers, Harold Hodes, Nicholas Sturgeon and, especially, Tamar Szab√≥ Gendler for very helpful comments on various drafts of the paper.\n</aside>\n\nThe second debate is a version of **rationalism vs empiricism**. The\nkind of rationalist I have in mind accepts that some deeply contingent\npropositions can be known a priori, and the empiricist I have in mind\ndenies this. Kripke showed that there are *contingent* propositions that\ncan be known a priori. One example is *Water is the watery stuff of our\nacquaintance*. ('Watery' is David Chalmers's nice term for the\nproperties of water by which folk identify it.) All the examples Kripke\ngave are of propositions that are, to use Gareth Evans's term, deeply\nnecessary [@Evans1979]. It is a matter of controversy presently just how\nto analyse Evans's concepts of deep necessity and contingency, but most\nof the controversies are over details that are not important right here.\nI'll simply adopt Stephen Yablo's recent suggestion: a proposition is\ndeeply contingent if it could have *turned out* to be true, and could\nhave *turned out* to be false [@Yablo2002][^1]. Kripke did not provide\nexamples of any *deeply* contingent propositions knowable a priori,\nthough nothing he showed rules out their existence.\n\nThe final debate is a version of **internalism vs externalism** about\nepistemic justification. The internalist I have in mind endorses a very\nweak kind of access internalism. Say that a class of properties\n(intuitively, a determinable) is *introspective* iff any beliefs an\nagent has about which property in the class (which determinate) she\ninstantiates are guaranteed to not be too badly mistaken.[^2] (Since\n'too badly' is vague, 'introspective' will be vague too, but as we'll\nsee this won't matter to the main argument.) My internalist believes the\nfollowing two claims:\n\n-   Which propositions an agent can justifiably believe supervenes in\n    which introspective properties she instantiates, and this is\n    knowable a priori.[^3]\n\n-   There exist some introspective properties and some deeply contingent\n    propositions about the future such that it's a priori that whoever\n    instantiates those properties can justifiably believe those\n    propositions.\n\nMy externalist denies one or other of these claims. Typically, she holds\nthat no matter what introspective properties you have, unless some\nexternal condition is satisfied (such as the reliability of the\nconnection between instantiating those properties and the world being\nthe way you believe it is) you lack justification. Alternatively, she\nholds that the connection between introspective properties and\njustification is always a posteriori. (Or, of course, she might deny\nboth.)\n\nMy argument will be that the combination of anti-scepticism, empiricism\nand internalism is untenable. Since there's quite a bit to be said for\neach of these claims individually, that their combination is untenable\nmeans we are stuck with a fairly hard choice: accept scepticism, or\nrationalism, or externalism. Of the three, it *may* seem that\nexternalism is the best, but given how weak the version of internalism\nis that I'm using, I think we should take the rationalist option\nseriously.[^4] In this paper I'll just argue against the combination of\nanti-scepticism, empiricism and internalism, and leave it to the reader\nto judge which of the three to reject.\n\nVery roughly, the argument for the trilemma will be as follows. There\nare some propositions *q* such that these three claims are true.\n\n2.  If anti-scepticism is true, then I either know *q* a priori or a\n    posteriori.\n\n3.  If internalism and empiricism is true, I do not know *q* a\n    priori.[^5]\n\n4.  If internalism is true, I do not know *q* a posteriori.\n\nMuch of the paper will be spent giving us the resources to find, and\nstate, such a *q*, but to a first approximation, think of *q* as being a\nproposition like *I am not a brain-in-a-vat whose experiences are as if\nthey were a normal person*.[^6] The important features of *q* are that\n(a) it is entailed by propositions we take ourselves to know, (b) it is\npossibly false and (c) if something is evidence for it, then any\nevidence is evidence for it. I will claim that by looking at\npropositions like this, propositions that say in effect that I am not\nbeing misled in a certain way, it is possible to find a value for *q*\nsuch that (2), (3) and (4) are all true. From that it follows that\n\nFor most of the paper I will assume that internalism and anti-scepticism\nare true, and use those hypotheses to derive rationalism. The paper will\nconclude with a detailed look at the role internalism plays in the\nargument, and this will give us some sense of what an anti-sceptical\nempiricist externalism may look like.\n\n### A Sceptical Argument\n\nAmong the many things I know about future, one of the firmest is (1).\n\n1.  It will snow in Ithaca next winter.\n\nI know this on the basis of inductive evidence about the length of\nmeteorological cycles and the recent history of Ithaca in winter. The\ninductive sceptic now raises the spectre of Winter Wonderland, a kind of\nworld that usually has the same meteorological cycles as ours, and has\nthe same history, but in which it is sunny every day in Ithaca next\nwinter.[^7] She says that to know (1) we must know that (5) is false,\nand we do not.\n\n5.  I am living in Winter Wonderland.\n\nJust how does reflection (5) affect my confidence that I know (1)? The\nsceptic might just appeal to the intuition that I don't know that (5) is\nfalse. But I don't think I have that intuition, and if I do it is much\nweaker than my intuition that I know (1) and that I can infer (5) from\n(1). James Pryor [-@Pryor2000 527-529] has suggested the sceptic is\nbetter off using (5) in the following interesting argument.[^8]\n\n6.  Either you don't know you're not living in Winter Wonderland; or, if\n    you do know that, it's because that knowledge rests in part on your\n    inductive knowledge that it will snow in Ithaca next winter.\n\n7.  If you're to know (1) on the basis of certain experiences or grounds\n    *e*, then for every *q* which is \"bad\" relative to *e* and (1), you\n    have to be in a position to know *q* to be false in a\n    non-question-begging way---i.e., you have to be in a position to\n    know *q* to be false antecedently to knowing that it will snow next\n    winter on the basis of *e*.\n\n8.  \\(5\\) is \"bad\" relative to any course of experience *e* and (1).\n\n9.  You can't know (1), that it will snow next winter on the basis of\n    your current experiences.\n\nAn alternative hypothesis *q* is \"bad\" in the sense used here iff (to\nquote Pryor) \"it has the special features that characterise the\nsceptic's scenarios---whatever those features turn out to be.\" (527) To\na first approximation, *q* is bad relative to *p* and *e* iff you're\nmeant to be able to know *p* on the basis of *e*, but *q* is apparently\ncompatible with *e*, even though it is not compatible with *p*.\n\nPryor argues that the best response to the external world sceptic is\n**dogmatism**. On this theory you can know *p* on the basis of *e* even\nthough you have no prior reason to rule out alternatives to *p*\ncompatible with *e*. Pryor only defends the dogmatic response to the\nexternal world sceptic, but it's worth considering the dogmatist\nresponse to inductive scepticism. According to this response, I *can*\ncome to know I'm not in Winter Wonderland on the basis of my experiences\nto date, even though I didn't know this a priori. So dogmatism is a\nversion of empiricism, and it endorses (6).[^9] The false premise in\nthis argument, according to the dogmatist, is (7). We can know it will\nsnow even though the Winter Wonderland hypothesis is bad relative to\nthis conclusion and our actual evidence, and we have no prior way to\nexclude it.\n\nPryor notes that the sceptic could offer a similar argument concerning\njustification, and the dogmatist offers a similar response.\n\n9.  Either you're not justified in believing that you're not in Winter\n    Wonderland; or, if you are justified in believing this, it's because\n    that justification rests in part on your justified belief that it\n    will snow in Ithaca next winter.\n\n10. If you're to have justification for believing (1) on the basis of\n    certain experiences or grounds *e*, then for every *q* which is\n    \"bad\" relative to *e* and (1), you have to have antecedent\n    justification for believing *q* to be false---justification which\n    doesn't rest on or presuppose any *e*-based justification you may\n    have for believing (1).\n\n11. \\(5\\) is \"bad\" relative to any course of experience *e* you could\n    have and (1).\n\n12. You can't justifiably believe it will snow in Ithaca next winter on\n    the basis of past experiences.\n\nThe dogmatist rejects (10), just as she rejects (7). I shall spend most\nof my time in the next two sections arguing for (10), returning to (7)\nonly at the end. For it seems there are compelling reasons to accept\n(10), and hold that the problem with this argument is either with (9) or\n(11).[^10]\n\n### Dominance Arguments\n\nThe primary argument for (10) will turn on a dominance principle: if you\nwill be in a position to justifiably believe *p* whatever evidence you\nget, and you know this, then you are now justified in believing *p*.\nThis kind of reasoning is perfectly familiar in decision theory: if you\nknow that one of *n* states obtains, and you know that in each of those\nstates you should do X rather than Y, then you know now (or at least you\nshould know) that you should do X rather than Y. This is a very\nplausible principle, and equivalent epistemic principles are just as\nviable. Dominance reasoning can directly support (10) and hence\nindirectly support (7). (As Vann @McGee1999 showed, the dominance\nprinciple in decision theory has to be qualified for certain kinds of\nagents with unbounded utility functions who are faced with a decision\ntree with infinitely many branches. Such qualifications do not seem at\nall relevant here.)\n\nIt will be useful to start with an unsound argument for (10), because\nalthough this argument is unsound, it fails in an instructive way.\nBefore I can present the argument I need to make an attempt at\nformalising Pryor's concept of badness.\n\n> *q* is **bad** relative to *e* and *p* =~df~ *q* is deeply contingent,\n> you know *p* entails $\\neg$*q*, and for any possible evidence\n> *e*$^\\prime$ (that you could have had at the time your total evidence\n> is actually *e*) there exists a *p*$^\\prime$ such that you know\n> *p*$^\\prime$ entails $\\neg$*q* and you are justified in believing\n> *p*$^\\prime$ on the basis of *e*$^\\prime$ if *e*$^\\prime$ is your\n> total evidence.\n\nRoughly, the idea is that a bad proposition is one that would be\njustifiably ruled out by any evidence, despite the fact that it could\nturn out to be true.[^11] Using this definition we can present an\nargument for rationalism. The argument will use some fairly general\npremises connecting justification, evidence and badness. If we were just\ninterested in this case we could replace *q* with (5), *r* with the\nproposition that (5) is false, *e* with my current evidence, and\n*e*$^\\prime$ with some evidence that would undermine my belief that (5)\nis false, if such evidence could exist. The intuitions behind the\nargument may be clearer if you make those substitutions when reading\nthrough the argument. But because the premises are interesting beyond\ntheir application to this case, I will present the argument in its more\ngeneral form.\n\n12. If you are justified in believing (1) on the basis of *e*, and you\n    know (1) entails $\\neg$(5), then you are justified in believing\n    $\\neg$(5) when your evidence is *e*.\n\n13. If you are justified in believing *r* (at time *t*) on the basis of\n    *e*, then there is some other possible evidence *e*$^\\prime$ (that\n    you could have at *t*) such that you would not be justified in\n    believing *r* were your total evidence *e*$^\\prime$.\n\n14. If you are justified in believing *r*, and there is no evidence *e*\n    such that *e* is part of your evidence and you are justified in\n    believing *r* on the basis of *e*, then you are justified in\n    believing *r* a priori.[^12]\n\n15. By definition, *q* is **bad** relative to *e* and *p* iff *q* is\n    deeply contingent, you know *p* entails $\\neg$*q*, and for any\n    possible evidence *e*$^\\prime$ (that you could have when your\n    evidence is *e*) there exists a *p*$^\\prime$ such that you know\n    *p*$^\\prime$ entails $\\neg$*q* and you are justified in believing\n    *p*$^\\prime$ on the basis of *e*$^\\prime$ if *e*$^\\prime$ is your\n    total evidence.\n\n16. So, if *q* is bad relative to *e* and (1), and you are justified in\n    believing (1) on the basis of *e*, then you are justified in\n    believing $\\neg$*q* a priori.\n\n(The references to times in (13) and (15) is just to emphasise that we\nare talking about your current evidence, and ways it could be. That you\ncould observe Winter Wonderland next winter doesn't count as a relevant\nalternative kind of evidence *now*.)\n\nOur conclusion (16) entails (10), since (10) merely required that for\nevery bad proposition relative to *e* and (1), you have 'antecedent'\njustification for believing that proposition to be false, while (16)\nsays this justification is a priori. ('Antecedent' justification need\nnot be a priori as long as it arrives before the particular evidence you\nhave for (1). This is why (16) is strictly stronger than (10).) So if\n(10) is false then one of these premises must be false. I take (15) to\ndefine \"bad\", so it cannot be false. Note that given this definition we\ncannot be certain that (5) is bad. We will return to this point a few\ntimes.\n\nWhich premise should the dogmatist reject? (12) states a fairly mundane\nclosure principle for justified belief. And (13) follows almost\nautomatically from the notion of 'basing'. A belief can hardly be based\nin some particular evidence if any other evidence would support it just\nas well. This does not mean that such a belief cannot be rationally\n*caused* by the particular evidence that you have, just that the\nevidence cannot be the rational *basis* for that belief. The dogmatist\nobjects to (14). There is a prima facie argument for (14), but as soon\nas we set it out we see why the dogmatist is correct to stop us here.\n\nConsider the following argument for (14), which does little more than\nlay out the intuition (14) is trying to express. Assume *r* is such that\nfor any possible evidence *e*, one would be justified in believing *r*\nwith that evidence. Here's a way to reason a priori to *r*. Whatever\nevidence I get, I will be justified in believing that *q*. So I'm now\njustified in believing that *r*, before I get the evidence. Compare a\nsimple decision problem where there is one unknown variable, and it can\none of two values, but whichever value it takes it is better for one to\nchoose X rather than Y. That is sufficient to make it true now that one\nshould choose X rather than Y. Put this way, the argument for (14) is\njust a familiar dominance argument.\n\nTwo flaws with this argument for (14) stand out, each of them arising\nbecause of disanalogies with the decision theoretic case.\n\nFirst, when we apply dominance reasoning in decision theory, we look at\ncases where it would be better to take X rather than Y in every possible\ncase, *and this is known*. This point is usually not stressed, because\nit's usually just assumed in decision theory problems that the players\nknow the consequences of their actions given the value of certain\nunknown variables. It's not obviously a good idea to assume this without\ncomment in applications of decision theory, and it's clearly a bad idea\nto make the same kind of assumption in epistemology. Nothing in the\nantecedent of (14) specifies that we can know, let alone know a priori,\nthat if our evidence is *e* then we are justified in believing *r*. Even\nif this is true, even if it is necessarily true, it may not be knowable.\n\nSecond, in the decision theory case we presupposed it is known that the\nvariable can take only one of two values. Again, there in nothing in the\nantecedent of (14) to guarantee the parallel. Even if an agent knows of\nevery possible piece of evidence that if she gets that evidence she will\nbe justified in believing *r*, she may not be in a position to\njustifiably conclude *r* now because she may not know that these are all\nthe possible pieces of evidence. In other words, she can only use\ndominance reasoning to conclude *r* if she knows *de dicto*, and not\nmerely *de re*, of every possible body of evidence that it justifies\n*r*.\n\nSo the quick argument for (14) fails. Still, it only failed because (14)\nleft out two qualifications. If we include those qualifications, and\nadjust the other premises to preserve validity, the argument will work.\nTo make this adjustment, we need a new definition of badness.\n\n> *q* is **bad** relative to *e* and *p* =~df~\n>\n> 1.  *q* is deeply contingent;\n>\n> 2.  *p* is known to entail $\\neg$*q*; and\n>\n> 3.  it is knowable a priori that for any possible evidence\n>     *e*$^\\prime$ there exists a *p*$^\\prime$ such that *p*$^\\prime$ is\n>     known to entail $\\neg$*q*, and one is justified in believing\n>     *p*$^\\prime$ on the basis of *e*$^\\prime$.\n\nThe aim still is to find an argument for some claim stronger than (10)\nin sceptical argument 2. If we can do that, and if as the sceptic\nsuggests (5) really is bad, then the only anti-sceptical response to\nsceptical argument 2 will be rationalism. So the fact that this looks\nlike a sound argument for a slightly stronger conclusion than (10) is a\nlarge step in our argument that anti-scepticism plus internalism entails\nrationalism. (I omit the references to times from here on.)\n\n12. If you are justified in believing (1) on the basis of *e*, and you\n    know (1) entails $\\neg$(5), then you are justified in believing\n    $\\neg$(5) when your evidence is *e*.\n\n13. If you are justified in believing *r* on the basis of *e*, then\n    there is some other possible evidence *e*$^\\prime$ such that you\n    would not be justified in believing *r* were your total evidence\n    *e*$^\\prime$.\n\n14. If you know you are justified in believing *r*, and you know a\n    priori that there is no evidence *e* you have such that you are\n    justified in believing *r* on the basis of *e*, then you are\n    justified in believing *r* a priori.[^13]\n\n15. By definition, *q* is **bad** relative to *e* and *p* iff *q* is\n    deeply contingent, *p* is known to entail $\\neg$*q*, and it is\n    knowable a priori that for any possible evidence *e*$^\\prime$ there\n    exists a *p*$^\\prime$ such that *p*$^\\prime$ is known to entail\n    $\\neg$*q*, and one is justified in believing *p*$^\\prime$ on the\n    basis of *e*$^\\prime$.\n\n16. So, if *q* is bad relative to *e* and (1), and you are justified in\n    believing (1) on the basis of *e*, then you are justified in\n    believing $\\neg$*q* a priori.\n\nThis is a sound argument for (19), and hence for (10), but as noted on\nthis definition of \"bad\" (11) may be false. If the Winter Wonderland\nhypothesis is to be bad it must be a priori knowable that on any\nevidence whatsoever, you'd be justified in believing it to be false. But\nas we will now see, although no evidence could justify you in believing\nthe Winter Wonderland hypothesis to be true, it is not at all obvious\nthat you are always justified in believing it is false.\n\n### Hunting the Bad Proposition\n\nA proposition is bad if it is deeply contingent but if you could\njustifiably believe it to be false on the basis of your current\nevidence, you could justifiably believe it to be false a priori. If a\nbad proposition exists, then we are forced to choose between rationalism\nand scepticism. To the extent that rationalism is unattractive,\nscepticism starts to look attractive. I think Pryor is right that this\nkind of argument tacitly underlies many sceptical arguments. The\nimportance of propositions like (5) is not that it's too hard to know\nthem to be false. The arguments of those who deny closure principles for\nknowledge notwithstanding, it's very intuitive that it's *easier* to\nknow (5) is false than to know (1) is true. So why does reflection on\n(5) provide more comfort to the inductive sceptic than reflection on\n(1)? The contextualist has one answer, that thinking about (5) moves the\ncontext to one where sceptical doubts are salient. Pryor's work suggests\na more subtle answer. Reflecting on (5) causes us to think about *how*\nwe could come to know it is false, and prima facie it might seem we\ncould not know that a priori or a posteriori. It's that dilemma, and not\nthe mere salience of the Winter Wonderland possibility, that drives the\nbest sceptical argument. But this argument assumes that (5) could not be\nknown to be false on the basis of empirical evidence, i.e. that it is\nbad. If it is not bad, and nor is any similar proposition, then we can\neasily deflect the sceptical argument. However, if we assume\ninternalism, we can *construct* a bad proposition.\n\nThe prima facie case that (5) is bad (relative to (1) and our current\nevidence *e* -- I omit these relativisations from now on) looks strong.\nThe negation of (5) is (20), where *H* is a proposition that summarises\nthe relevant parts of the history of the world.[^14]\n\n20. Either $\\neg$*H* or it will snow in Ithaca next winter.\n\nNow one may argue that (5) is bad as follows. Either our evidence\njustifies believing $\\neg$*H* or it doesn't. If it does, then it clearly\njustifies believing (20), for $\\neg$*H* trivially entails it. If it does\nnot, then we are justified in believing *H*, and whenever we are\njustified believing the world's history is *H*, we can inductively infer\nthat it will snow in Ithaca next winter. The problem with this argument,\nhowever, is fairly clear: the step from the assumption that we are not\njustified in believing $\\neg$*H* to the conclusion we are justified in\nbelieving *H* is a modal fallacy. We might be justified in believing\nneither *H* nor its negation. In such a situation, it's not obvious we\ncould justifiably infer (20). So (5) may not be bad.\n\nA suggestion John @Hawthorne2002 makes seems to point to a proposition\nthat is more plausibly bad. Hawthorne argues that disjunctions like (21)\nare knowable a priori, and this suggests that (22), its negation, is\nbad.\n\n21. Either my evidence is not *e* or it will snow in Ithaca next winter.\n\n22. My evidence is *e* and it will not snow in Ithaca next winter.\n\nHawthorne does not provide a dominance argument that (21) is knowable a\npriori. Instead he makes a direct appeal to the idea that whatever kinds\nof inference we can draw now the basis of our evidence we could have\ndrawn prior to getting *e* as conditional conclusions, conditional on\ngetting *e*. So if I can now know it will snow in Ithaca next winter,\nprior to getting *e* I cold have known the material conditional *If my\nevidence is e, it will snow in Ithaca*, which is equivalent to (21).\nIt's not clear this analogy works, since when we do such hypothetical\nreasoning we take someone to *know* that our evidence is *e*, and this\nmay cause some complications. Could we find a dominance argument to use\ninstead? One might be tempted by the following argument.\n\n23. I know a priori that if my evidence is *e*, then I am justified in\n    believing the second disjunct of (21).\n\n24. I know a priori that if my evidence is not *e*, then I am justified\n    in believing the first disjunct of (21)\n\n25. I know a priori that if I am justified in believing a disjunct\n    of (21) I am justified in believing the disjunction (21).\n\n26. I know a priori that my evidence is either *e* or not *e*.\n\n27. So, I'm justified a priori in believing (21).\n\nThe problem here is the second premise, (24). It's true that if my\nevidence is not *e* then the first disjunct of (21) is true. But there's\nno reason to suppose I am justified in believing any true proposition\nabout my evidence. Timothy [@Williamson2000-WILKAI ch. 8] has argued\nthat the problem with many sceptical arguments is that they assume\nagents know what their evidence is. I doubt that's really the flaw in\nsceptical arguments, but it certainly is the flaw in the argument that\n(22) is bad.\n\nThe problem with using (22) is that the argument for its badness relied\non quite a strong privileged access thesis: whenever my evidence is not\n*e* I am justified in believing it is not. If we can find a weaker\nprivileged access thesis that is true, we will be able to find a\nproposition similar to (22) that is bad. And the very argument\nWilliamson gives against the thesis that we always know what our\nevidence is will show us how to find such a thesis.\n\nWilliamson proposes a margin-of-error model for certain kinds of\nknowledge. On this model, X knows that *p* iff (roughly) *p* is true in\nall situations within X's margin-of-error.[^15] The intuitive idea is\nthat all of the possibilities are arranged in some metric space, with\nthe distance between any two worlds being the measure of their\nsimilarity with respect to X. Then X knows all the things that are true\nin all worlds within some sphere centred on the actual world, where the\nradius of that sphere is given by how accurate she is at forming\nbeliefs.\n\nOne might think this would lead to the principle B:\n*p*¬†${\\rightarrow}$¬†K$\\neg$K$\\neg$*p*, that is, if *p* is true then X\nknows that she does not know $\\neg$*p*. Or, slightly more colloquially,\nif *p* is true then X knows that for all she knows *p* is true. (I use K\nhere as a modal operator. K*A* means that X, the salient subject, knows\nthat *A*.) On a margin-of-error model\n*p*¬†${\\rightarrow}$¬†K$\\neg$K$\\neg$*p* is false only if *p* is actually\ntrue and there is a nearby (i.e. within the margin-of-error) situation\nwhere the agent knows $\\neg$*p*. But if *nearby* is symmetric this is\nimpossible, because the truth of *p* in this situation will rule out the\nknowability of $\\neg$*p* in that situation.\n\nAs Williamson points out, that quick argument is fallacious, since it\nrelies on a too simplistic margin-of-error model. He proposes a more\ncomplicated account: *p* is known at *s* iff there is a distance *d*\ngreater than the margin-of-error and for any situation *s*$^\\prime$ such\nthat the distance between *s* and *s*$^\\prime$ is less than *d*, *p* is\ntrue at *s*$^\\prime$. Given this model, we cannot infer\n*p*¬†${\\rightarrow}$¬†K$\\neg$K$\\neg$*p*. Indeed, the only distinctive\nmodal principle we can conclude is K*p*¬†${\\rightarrow}$¬†*p*. However, as\nDelia Graff @Fara2002 has shown, if we make certain density assumptions\non the space of available situations, we can recover the principle (27)\nwithin this account.[^16]\n\n27. *p*¬†${\\rightarrow}$¬†K$\\neg$KK$\\neg$*p*\n\nTo express the density assumption, let *d*(*s*~1~, *s*~2~) be the\n'distance' between *s*~1~ and *s*~2~, and *m* the margin-of-error. The\nassumption then is that there is a *k* \\> 1 such that for any *s*~1~,\n*s*~2~ such that *d*(*s*~1~,¬†*s*~2~)¬†\\<¬†*km*, there is an *s*~3~ such\nthat *d*(*s*~1~, *s*~3~)¬†\\<¬†*m* and *d*(*s*~3~, *s*~2~)¬†\\<¬†*m*. And this\nwill be made true if there is some epistemic situation roughly\n'half-way' between *s*~1~ and *s*~2~.[^17] That is, all we have to\nassume to recover (27) within the margin-of-error model is that the\nspace of possible epistemic situations is suitably dense. Since the\nmargin-of-error model, and Fara's density assumption, are both\nappropriate for introspective knowledge, (27) is true when *p* is a\nproposition about the agent's own knowledge.\n\nTo build the bad proposition now, let *G* be a quite general property of\nevidence, one that is satisfied by everyone with a reasonable\nacquaintance with Ithaca's weather patterns, but still precise enough\nthat it is a priori that everyone whose evidence is *G* is justified in\nbelieving it will snow in Ithaca next winter. The internalist, remember,\nis committed to such a *G* existing and it being an introspective\nproperty. Now consider the following proposition, which I shall argue is\nbad.[^18]\n\n28. I know that I know my evidence is *G*, and it will not snow in\n    Ithaca next winter.\n\nThe negation of (28) is (29).\n\n29. It will snow in Ithaca next winter, or I don't know that I know my\n    evidence is *G*.\n\nIt might be more intuitive to read (29) as the material conditional\n(29a), though since English conditionals aren't material conditionals\nthis seems potentially misleading.\n\n29. If I know that I know that my evidence is *G*, then it will snow in\n    Ithaca next winter.\n\nTo avoid confusions due to the behaviour of conditionals, I'll focus on\nthe disjunction (29). Assume for now that the margin-of-error model is\nappropriate for propositions about my own evidence. I will return below\nto the plausibility of this assumption. This assumption implies that\nprinciple (27) is always correct when *p* is a proposition about my\nevidence. Given this, we can prove (28) is bad. Note that all my\npossible evidential states either are, or are not, *G*. If they are *G*\nthen by hypothesis I am justified in believing that it will snow in\nIthaca next winter and hence I am justified in believing (29). If they\nare not, then by the principle (27) I know that I don't know that I know\nmy evidence is *G*, so I can come to know (29), so I am justified in\nbelieving (29). So either way I am justified in believing (29). It's\nworth noting that at no point here did I assume that I knew whether my\nevidence was *G*, though I do assume that I know that having evidence\nthat is *G* justifies belief in snow next winter.\n\nAll of this assumes the margin-of-error model looks appropriate for\nintrospective properties. If it isn't, then we can't assume that (27) is\ntrue when *p* is a proposition about the introspective properties I\nsatisfy, and hence the argument that (29) is knowable a priori fails.\nThere's one striking problem with assuming a priori that we can use the\nmargin-of-error model in all situations. It is assumed (roughly) that\nanything that is true in all possibilities within a certain sphere with\nthe subject's beliefs at the centre is known. This sphere must include\nthe actual situation, or some propositions that are actually false may\nbe true throughout the sphere. Since for propositions concerning\nnon-introspective properties there is no limit to how badly wrong the\nsubject can be, we cannot set any limits a priori to the size of the\nsphere. So a priori the only margin-of-error model we can safely use is\nthe sceptical model that says the subject knows that *p* iff *p* is true\nin all situations. For introspective properties the margin-of-error can\nbe limited, because it is constitutive of introspective properties that\nthe speakers beliefs about whether they possess these properties are not\ntoo far from actuality. So there seems to be no problem with using\nWilliamson's nice model as long as we restrict our attention to\nintrospective properties.\n\nIf belief in (29) can be justified a priori, and it is true, does that\nmean it is knowable a priori? If we want to respect Gettier intuitions,\nthen we must not argue directly that since our belief in (29) is\njustified, and it is true, then we know it. Still, being justified and\ntrue is not irrelevant to being known. I assume here, far from\noriginally, that it is a reasonable *presumption* that any justified\ntrue belief is an item of knowledge. This presumption can be defeated,\nif the belief is inferred from a false premise, or if the justification\nwould vanish should the subject acquire some evidence she should have\nacquired, or if there is a very similar situation in which the belief is\nfalse, but it is a reasonable presumption. Unless we really are in some\nsceptical scenario, there is no \"defeater\" that prevents our belief in\n(29) being an item of knowledge. We certainly did not infer it from a\nfalse premise, there is no evidence we *could* get that would undermine\nit, and situations in which it is false are very far from actuality.\n\nSince there are no such defeaters, it is reasonable to infer we can\n*know* (29) a priori. The important premises grounding this inference\nare an anti-sceptical premise, that we can know (1) on the basis of our\ncurrent evidence, and the internalist premise that we used several times\nin the above argument. This completes the argument that the combination\nof empiricism, internalism and anti-scepticism is untenable.\n\n### How Externalism Helps\n\nIt should be obvious how the rationalist can respond to the above\nargument - by simply accepting the conclusion. Ultimately I think that's\nthe best response to this argument. As Hawthorne notes, rationalism is\nthe natural position for fallibilists about knowledge to take, for it is\njust the view that we can know something a priori even though we could\nturn out to be wrong. In other words, it's just fallibilism about a\npriori knowledge. Since fallibilism about a posteriori knowledge seems\ntrue, and there's little reason to think fallibilism about the a priori\nwould be false if fallibilism about the a posteriori is true, the\nrationalist's position is much stronger than many have assumed.[^19] The\ninductive sceptic also has an easy response - reject the initial premise\nthat in my current situation I know that it will snow in Ithaca next\nwinter. There are other responses that deserve closer attention: first,\nthe inductive sceptic who is not a universal sceptic, and in particular\nis not a sceptic about perception, and second the externalist.\n\nI said at the start that the argument generalises to most kinds of\nscepticism. One kind of theorist, the inductive sceptic who thinks we\ncan nonetheless acquire knowledge through perception, may think that the\nargument does not touch the kind of anti-sceptical, internalist,\nempiricist position she adopts. The kind of theorist I have in mind says\nthat the objects and facts we perceive are constitutive of the evidence\nwe receive. So given we are getting the evidence we are actually\ngetting, these objects must exist and those facts must be true. She says\nthat if I'd started with (30), instead of (1), my argument would have\nended up claiming that (31) is bad for some *G*.\n\n30. A hand exists.\n\n31. A hand exists, or I don't know that I know that I'm perceiving a\n    hand.\n\nShe then says that (31) is not deeply contingent, since in any situation\nwhere the first disjunct is false the second is true, so it cannot be\nbad. This response is correct as far as it goes, but it does not go far\nenough to deserve the name anti-sceptical. For it did not matter to the\nabove argument, or to this response that (1) is about the future. All\nthat mattered was that (1) was not *entailed* by our evidence. So had\n(1) been a proposition about the present that we cannot directly\nperceive, such as that it is not snowing in Sydney *right now*, the rest\nof the argument would have been unaffected. The summary here is that if\none is suitably externalist about perception, so one thinks the\nexistence of perceptual states entail the existence of the things being\nperceived, one can accept this argument, accept internalism, accept\nempiricism, and not be an *external world* sceptic. For it is consistent\nwith such a position that one know the existence of the things one\nperceives. But on this picture one can know very little beyond that, so\nfor most practical purposes, the position is still a sceptical one.\n\nThe externalist response is more interesting. Or, to be more precise,\nthe externalist reponse*s* are more interesting. Although I have\nappealed to internalism a couple of times in the above argument, it\nmight not be so clear how the externalist can respond. Indeed, it may be\nworried that by exercising a little more care in various places I could\nhave shown that everyone must accept either rationalism or scepticism.\nThat is the conclusion Hawthorne derives in his paper on deeply\ncontingent a priori knowledge, though as noted above he uses somewhat\nmore contentious reasoning than I do in order to get there. To conclude,\nI will argue that the internalism is crucial to the argument I have\npresented, and I will spell out how the externalist can get out of the\ntrap I've set above.\n\nOne easy move that's available to an externalist is to deny that any\nfacts about justification are a priori. That blocks the move that says\nwe can find a *G* such that it's a priori that anyone whose evidence is\n*G* can know that it will snow in Ithaca next year. This is not an\nessential feature of externalism. One can be an externalist about\njustification and still think it is a priori that if one's evidence has\nthe property *is reliably correlated with snow in the near future* then\nit justifies belief that it will shortly snow. But the position that all\nfacts about justification are a posteriori fits well with a certain kind\nof naturalist attitude, and people with that attitude will find it easy\nto block the sceptical argument I've presented.\n\nCan, however, we use an argument like mine to argue against an\nanti-sceptic empiricist externalist who thinks some of the facts about\njustification *can* be discovered a priori? The strategy I've used to\nbuild the argument is fairly transparent: find a disjunctive a priori\nknowable proposition by partitioning the possible evidence states into a\nsmall class, and adding a disjunct for every cell of the partition. In\nevery case, the disjunct that is added is one that is known to be known\ngiven that evidence. If one of the items of knowledge is ampliative, if\nit goes beyond the evidence, then it is possible the disjunction will be\ndeeply contingent. But the disjunction is known no matter what.\n\nIf internalism is true, then the partition can divide up evidential\nstates according to the introspective properties of the subject. If\nexternalism is true, then such a partition may not be that *useful*,\nbecause we cannot infer much about what the subject is justified in\nbelieving from the introspective properties she instantiates. Consider,\nfor example, the above partition of subjects into the *G* and the\nnot-*G*, where *G* is some introspective property, intuitively one\nsomewhat connected with it snowing in Ithaca next year. The subjects\nthat are not-*G* know that they don't know they know they are *G*,\nbecause they aren't. Externalists need not object to this stage of the\nargument. They can, and should, accept that a margin-of-error model is\nappropriate for introspective properties. Since it's part of the nature\nof introspective properties that we can't be *too* badly wrong about\nwhich ones we instantiate, we're guaranteed to satisfy some reliability\nclause, so there's no ground there to deny the privileged access\nprinciple I defended above.\n\nThe problem is what to say about the cases where the subject is *G*.\nExternalists should say that some such subjects are justified in\nbelieving it will snow in Ithaca next winter, and some are not. For\nsimplicity, I'll call the first group the reliable ones and the others\nthe unreliable ones. If I'm *G* and reliable, then I'm justified in\nbelieving it will snow, and hence in believing (29). But if I'm *G* and\nunreliable, then I'm not justified in believing this. Indeed, if I'm *G*\nand unreliable, there is no obvious argument that I'm justified in\nbelieving *either* of the disjuncts of (29). Since this is a possible\nevidential state, externalists should think there is no dominance\nargument that (29) is a priori knowable.\n\nCould we solve this by adding another disjunct, one that is guaranteed\nto be known if I'm *G* and unreliable? There is no reason to believe we\ncould. If we're unreliable, there is no guarantee that we will *know* we\nare unreliable. Indeed, we may well believe we are reliable. So there's\nno proposition we can add to our long disjunction while saying to\nourselves, \"In the case where the subject is *G* and unreliable, she can\njustifiably believe *this* disjunct.\" If the subject is unreliable, she\nmay not have *any* justified beliefs about the external world. But this\nis just to say the above recipe for constructing bad propositions breaks\ndown. Externalists should have no fear that anything like this approach\ncould be used to construct a proposition they should find bad. This is\nobviously not a positive argument that anti-sceptical empiricist\nexternalism is tenable, but it does suggest that such a position is\nimmune to the kind of argument I have presented here.\n\n[^1]: If you prefer the 'two-dimensional' way of talking, a deeply\n    contingent proposition is one that is true in some possible world\n    'considered as actual'. See @Chalmers2006 for a thorough discussion\n    of ways to interpret this phrase, and the broader notion of\n    so-called 'deep' contingency. Nothing that goes on here will turn on\n    any of the fine distinctions made in that debate - the relevant\n    propositions will be deeply contingent in every plausible sense.\n\n[^2]: That a property is introspective does not mean that whenever a\n    subject instantiates it she is in a position to form a not too badly\n    mistaken belief about it. Even if the subject instantiates the\n    property she may not possess sufficient concepts in order to have\n    beliefs about it. And even if she has the concept she may simply\n    have more pressing cognitive needs than forming certain kinds of\n    belief. Many agents have no beliefs about the smell in their\n    ordinary environment much of the time, for example, and this does\n    not show that phenomenal smell properties are not introspective. All\n    that is required is that if she has any beliefs at all about which\n    determinate she instantiates, the beliefs are immune to massive\n    error.\n\n[^3]: There is a delicate ambiguity in this expression to which a\n    referee drew my attention. The intended meaning is that for any two\n    agents who instantiate the same introspective properties, belief in\n    the same propositions is justified. What's not intended is that if\n    there's an agent who justifiably believes *p*, and the introspective\n    properties they instantiate are *F*~1~, ..., *F~n~*, then any agent\n    who instantiates *F*~1~, ..., *F~n~* is justified in believing *p*.\n    For there might be some other introspective property *F~n~*~+1~ they\n    instantiate that justifies belief in *q*, and *q* might be a\n    defeater for *p*. The 'unintended' claim would be a very strong, and\n    very implausible, claim about the subvenient basis for\n    justification.\n\n[^4]: Rationalism is supported by @BonJour1997 and @Hawthorne2002, and\n    my argument owes a lot to each of their discussions.\n\n[^5]: Aesthetically it would be preferable to have the antecedent of\n    this claim be just that empiricism is true, but unfortunately this\n    does not seem to be possible.\n\n[^6]: I.e. I am not a brain-in-a-vat\\* in the sense of Cohen (1999)\n\n[^7]: If she is convinced that there is no possible world with the\n    *same* history as ours and no snow in Ithaca next winter, the\n    sceptic will change her story so Winter Wonderland's past differs\n    imperceptibly from the past in our world. She doesn't think this\n    issue is particularly relevant to the *epistemological* debate, no\n    matter how interesting the scientific and metaphysical issues may\n    be, and I agree with her.\n\n[^8]: Pryor is discussing the external world sceptic, not the inductive\n    sceptic, so the premises here are a little different to those he\n    provides.\n\n[^9]: It is a version of the kind of internalism discussed in footnote\n    2, since according to the dogmatist seeming to see that *p* can be\n    sufficient justification for belief in *p*. Pryor's preferred\n    version of dogmatism is also internalist in the slightly stronger\n    sense described in the text, but it seems possible that one could be\n    a dogmatist without accepting that internalist thesis. One could\n    accept, for instance, that seeming to see that *p* justifies a\n    belief that *p*, but also think that seeming to see that *q*\n    justifies a belief that *p* iff there is a known reliable connection\n    between *q* and *p*. As I said, even the weaker version of\n    internalism is sufficient to generate a conflict with\n    anti-scepticism and empiricism, provided we just focus on the\n    propositions that can be justifiably believed on the basis of\n    introspective properties.\n\n[^10]: Just which is wrong then? That depends on how \"bad\" is defined.\n    On our final definition (8) will fail, but there are other sceptical\n    arguments, using other sceptical hypotheses, on which (6) fails.\n\n[^11]: Note that there's a subtle shift here in our conception of\n    badness. Previously we said that bad propositions are those you\n    allegedly know on the basis of your actual evidence (if you know\n    *p*) even though they are logically consistent with that evidence.\n    Now we say that they are propositions you could rule out on *any*\n    evidence, even though they are consistent with your actual total\n    evidence. This is a somewhat narrower class of proposition, but\n    focussing on it strengthens the sceptic's case appreciably.\n\n[^12]: {#fnt:ftn13 label=\"fnt:ftn13\"} David Chalmers\n    noted that (10) and (11) entail that *I exist* is a priori. He\n    thought this was a bad result, and a sufficient reason to modify\n    these premises. I'm perfectly happy with saying, following Kaplan,\n    that *I exist* is a priori. I don't think this proves rationalism,\n    because I think it's also deeply necessary that I exist. (It's not\n    deeply necessary that Brian exists, but that's no objection to what\n    I just claimed, because it's not deeply necessary that I'm Brian.)\n\n    This position is controversial though, so I don't want to rest too\n    much weight on it. If you don't think that *I exist* should be a\n    priori, rewrite (11) so that it's conclusion is that you would be\n    justified in believing the material conditional *I exist*\n    ${\\supset}$ *r* a priori. (Note that since I'm presupposing in the\n    dominance argument that all the salient possibilities are ones in\n    which I have some evidence, and hence exist, it's not surprising\n    that *I exist* has a special status within the theory.)\n\n    On a separate point, note that I make no assumptions whatsoever here\n    about what relationship must obtain between a justified belief and\n    the evidence on which it is based. Depending on what the right\n    theory of justification is, that relationship might be entailment or\n    constitution or causation or association or reliable connection or\n    something else or some combination of these. I do assume that a\n    posteriori beliefs are somehow connected to evidence, and if the\n    beliefs are justified this relation is properly called *basing*.\n\n[^13]: Again, if you don't think *I exist* should be a priori, the\n    conclusion should be that *I exist* ${\\supset}$¬†*r* is a priori.\n\n[^14]: I assume *H* includes a 'that's all that's relevant clause' to\n    rule out defeaters. That is, it summaries the relevant history of\n    the world *as such*.\n\n[^15]: There's a considerable amount of idealisation here. What's really\n    true is that X is in a position to know anything true in all\n    situations within her margin-of-error. Since we're working out what\n    is a priori knowable, I'll assume agents are idealised so they know\n    what they are in a position to know. This avoids needless\n    complications we get from multiplying the modalities that are in\n    play.\n\n[^16]: If we translate K as $\\square$ and $\\neg$K$\\neg$ as $\\diamond$,\n    (24) can be expressed as the modal formula\n    *p*¬†${\\rightarrow}$¬†$\\square$$\\diamond$$\\diamond$*p*.\n\n[^17]: Fara actually gives a slightly stronger principle than this, but\n    this principle is sufficient for her purposes, and since it is\n    weaker than Fara's, it is a little more plausible. But the\n    underlying idea here, that we can get strong modal principles out of\n    margin-of-error models by making plausible assumptions about\n    density, is taken without amendment from her paper.\n\n[^18]: If you preferred the amended version of (11) discussed in\n    footnote 12, the bad proposition is *I don't exist or* (28) *is\n    true*.\n\n[^19]: As BonJour points out, rationalism has fallen into such disrepute\n    that many authors leave it out even of surveys of the options. This\n    seems unwarranted given the close connection between rationalism and\n    the very plausible thesis of fallibilism.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}