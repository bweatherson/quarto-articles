{
  "hash": "737656f79db8439aba7a61ba8a9b0148",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Are You a Sim?\"\ndescription: |\n  Nick Bostrom argues that if we accept some plausible assumptions about how the future will unfold, we should believe we are probably not humans. The argument appeals crucially to an indifference principle whose content is unclear. I set out four possible interpretations of the principle, none of which can be used to support Bostrom's argument. On the first two interpretations the principle is false; on the third it does not entail the conclusion; and on the fourth it only entails the conclusion given an auxiliary hypothesis which we have no reason to believe.\ndate: July 1 2003\nauthor:\n  - name: Brian Weatherson \n    url: http://brian.weatherson.org\n    affiliation: University of Michigan\n    affiliation_url: https://umich.edu\n    orcid_id: 0000-0002-0830-141X\ndoi: \"10.1111/1467-9213.00323\"\ncategories:\n  - epistemology\n  - notes\ncitation_url: https://doi.org/10.1111/1467-9213.00323\njournal:\n    title: \"Philosophical Quarterly\"\n    publisher: \"Oxford University Press\"\nvolume: 53\nnumber: 212\ncitation: false\nbibliography: ../../../articles/Rbib.bib\nself-contained: false\npreview: sims.jpg\noutput:\n  distill::distill_article:\n    toc: true\n    toc_depth: 3\n    number_sections: true\n---\n\n\n\nIn Will Wright's delightful game [*The Sims*](http://thesims.ea.com/),\nthe player controls a neighbourhood full of people, affectionately\ncalled sims. The game has no scoring system, or winning conditions. It\njust allows players to create, and to some extent participate in, an\ninteresting mini-world. Right now the sims have fairly primitive\npsychologies, but we can imagine this will be improved as the game\nevolves. The game is very popular now, and it seems plausible that it,\nand the inevitable imitators, will become even more popular as its\npsychological engine becomes more realistic. Since each human player\ncreates a neighbourhood with many, many sims in it, in time the number\nof sims in the world will vastly outstrip the number of humans.\n\n<aside>\nPublished in *Philosophical Quarterly* 53: 425-431.\n\nPicture by [Elven*Nicky](https://www.flickr.com/photos/52635109@N00) via [Creative Commons](https://search.creativecommons.org/photos/c5f0026d-5b24-4e8e-9e0a-055a8e7f9cc8)\n</aside>\n\nLet's assume that as the sims become more and more complex, they will\neventually acquire conscious states much like yours or mine. I do not\nwant to argue for or against this assumption, but it seems plausible\nenough for discussion purposes. I'll reserve the term Sim, with a\ncapital S, for a sim that is conscious. By similar reasoning to the\nabove, it seems in time the number of Sims in the world will far\noutstrip the number of humans, unless humanity either (a) stops\nexisting, or (b) runs into unexpected barriers to computing power or (c)\nloses interest in these kinds of simulators. I think none of these is\nlikely, so I think that over time the ratio of Sims to humans will far\nexceed 1:1.\n\nNick @Bostrom2003 argues that given all that, we should believe that we\nare probably Sims. Roughly, the argument is that we know that most\nagents with conscious states somewhat like ours are Sims. And we don't\nhave any specific evidence that tells on whether we are a Sim or a\nhuman. So the credence we each assign to *I'm a Sim* should equal our\nbest guess as to the percentage of human-like agents that are Sims,\nwhich is far above $\\frac{1}{2}$. As Glenn Reynolds put it, \"Is it\nlive, or is it Memorex? Statistically, it's probably Memorex. Er, and so\nare you, actually.\"[^1] (Is it worrying that we used the assumption that\nwe are human to generate this statistical argument? Not necessarily; if\nwe are Sims then the Sims:humans ratio is probably even higher, so what\nwe know is a lower bound on the proportion of human-like agents that are\nSims.) Less roughly, the argument appeals crucially to the following\nprinciple:\n\n(\\#)\n\n:   *Cr*(*Sim*  *f~Sim~* = *x*) = *x*\n\nHere *Cr* is a rational credence function. I will adopt David Lewis's\ntheory of *de se* belief, and assume that the credence function is\ndefined over properties, rather than propositions @Lewis1979b. Whenever\nI use a term that normally stands for a proposition inside the scope of\n*Cr*, it stands for the property of being in a world where that\nproposition is true. So *f~Sim~* = *x* stands for the property of being\nin a world where 100*x*% of the human-like agents are Sims.\n\nAs Bostrom notes, the main reason for believing (\\#) is that it is an\ninstance of a plausible general principle, which I'll call (\\#\\#).\n\n(\\#\\#)\n\n:   ${\\forall}{\\Phi}$: *Cr*(${\\Phi}$  *f*~${\\Phi}$~ = *x*) = *x*\n\nBostrom does not formulate this more general principle, but it is clear\nthat he intends something like it to be behind his argument, for many of\nthe defences of (\\#) involve substituting some other property in place\nof *Sim* in statements like (\\#). So I will focus here on whether\nanything like (\\#\\#) is plausibly true, and whether it supports (\\#).\nThere are many ways we could interpret (\\#\\#), depending on whether we\ntake *Cr* to be a rational agent's current credences, or in some sense\nthe prior credences before they are affected by some particular\nevidence, and on whether we take the quantifier to be restricted or\nunrestricted. Five particular interpretations stand out as being worth\nconsidering. None of these, however, provides much reason to believe\n(\\#), at least on the reading Bostrom wants to give it. In that reading\n(\\#) the credence function represents the current credences of an agent\nmuch like you or me. If (\\#) isn't interpreted that way, it can't play\nthe dialectical role Bostrom wants it to play. On two of the\ninterpretations, (\\#\\#) is false, on two others it may be true but\nclearly does not entail (\\#), and on the fifth it only entails (\\#) if\nwe make an auxiliary assumption which is far from obviously true.\n\nFor ease of exposition, I will assume that *Cr* describes in some way\nthe credences at some time of a particular rational human-like agent,\nRat, who is much like you or me, except that she is perfectly rational.\n\n### First Interpretation\n\n*Cr* in (\\#\\#) measures Rat's current credences, and the quantifier in\n(\\#\\#) is unrestricted. On this interpretation, (\\#\\#) is clearly false,\nas Bostrom notes. Rat may well know that the proportion of human-like\nagents that are like spaghetti westerns is rather low, while rationally\nbeing quite confident that she likes spaghetti westerns. For any\nproperty ${\\Phi}$ where Rat has some particular information about\nwhether he is one of the ${\\Phi}$s or not, that information, and not\ngeneral facts about the proportion of human-like agents that are\n${\\Phi}$, can (indeed should) guide Rat's credences. So those\nsubstitution instances of (\\#\\#) are false.\n\n### Second Interpretation\n\nJust like the first interpretation, except that we restrict the\nquantifier range so that it only ranges over properties such that Rat\ndoes not know whether she possesses them. This interpretation seems to\nbe hinted at by Bostrom when he says, \"the bland indifference principle\nexpressed by (\\#) prescribes indifference only between hypotheses about\nwhich observer you are, when you have no information about which of\nthese observers you are.\" Even given this restriction, (\\#\\#) is still\nfalse, as the following example shows.\n\nAssume that Rat knows that *f~Sim~* \\> 0.9, which Bostrom clearly takes\nto be consistent with rationality. And assume also that Rat, being a\nnormal human-like agent, knows some fairly specific, and fairly\ndistinctive facts about her conscious life. If Rat is anything like you\nor me, she will have experiences that he can be fairly sure are unique\nto her. Last night, for instance, while Rat was listening to Go-Betweens\nbootlegs, watching baseball, drinking beer, rocking in his rocking chair\nand thinking about Bostrom's simulation argument, she stubbed her toe in\na moderately, but not excessively, painful way. Few people will have\ndone all these things at once, and none in quite that way. Let *C* be\nthe property of ever having had an experience almost just like that. Rat\nknows he is a *C*. She is very confident, though not certain, that she\nis the only human-like *C*. Let a suman be the property of being *C* and\nhuman, or not-*C* and a Sim. For much of the paper we're going to be\nconcerned with the following two properties.\n\n> $x$ is a **suman** =~df~ $x$ is a human $C$ or a Sim who is not a $C$.\n>\n> $x$ is a **him** =~df~ $x$ is a Sim $C$ or a human who is not a $C$.\n\nWe are following Bostrom in assuming that Rat does not know whether she\nis a Sim so she does not know whether she is a suman. But given that\nalmost no one is *C*, it follows that *f~suman~* ${\\approx}$ *f~Sim~*.\nHence *f~suman~* \\> 0.85, for if it is less than *f~Sim~*, it is not\nmuch less. But if *Cr*(a suman) \\> 0.85, and *Cr*(*Sim*) \\> 0.9, and Rat\nis coherent, it follows that *Cr*(*C*) \\< 0.25. But we assumed that Rat\nknew that she was a *C*, and however knowledge and credence are to be\nconnected, it is inconceivable that one could know something while one's\ncredence in it is less than $\\frac{1}{4}$. Hence it must be false\nthat *Cr*(*C*) \\< $\\frac{1}{4}$, but we inferred that from given\nfacts about the story and (\\#\\#), as interpreted here. Hence (\\#\\#), as\ninterpreted here, is false.\n\n### Third Interpretation\n\nOne natural response ot the previous objection is that there shoul dbe\nsome way of restricting (\\#\\#) so that it does not apply to properties\nlike being a suman. Intuitively, the response is that even though Rat\ndoesn't know whether she is a suman, she knows something that is\nrelevant to whether she is a suman, namely that she is a $C$. The\nproblem with this response is that any formal restriction on (\\#\\#) that\nimplements this intuition ends up giving us a version so weak that it\ndoesn't entail (\\#).\n\nThe idea is that what went wrong in the previous case is that even\nthough Rat does not know whether she is a suman, she knows something\nrelevant to this. In particular, she knows that if she is a suman, she\nis one of the sumans that is human, rather than one of the ones that is\na Sim. Our third interpretation avoids the difficulties this raises by\nrestricting the quantifier in (\\#\\#) even further. Say that a property\n${\\Phi}$ is in the domain of the quantifier iff (a) Rat does not know\nwhether she is ${\\Phi}$, and (b) there is no more specific property\n${\\Phi}$$^\\prime$ such that Rat knows that if she is ${\\Phi}$, then she\nis ${\\Phi}$$^\\prime$.[^2] This will rule out the applicability of (\\#\\#)\nto properties like a suman. Unfortunately, it will also rule out the\napplicability of (\\#\\#) to properties like *being a Sim*. For Rat knows\nthat if she is a Sim, then she is a Sim that is also a *C*. So now\n(\\#\\#) doesn't entail (\\#).\n\nThis kind of problem will arise for any attempt to put a purely formal\nrestriction on (\\#\\#). The problem is that, as Goodman noted in a quite\ndifferent context [@Goodman1955], there is no formal distinction between\nthe 'normal' properties, being a human and being a sim, and the\n'deviant' properties, being a suman and being a him. The following four\nbiconditionals are all conceptual truths, and hence must all receive\ncredence 1.\n\nIf the obvious truth of (1a) implies that Rat cannot apply (\\#\\#) to the\nproperty o being a suman once she knows that she is a $C$, for (1a)\nmakes that evidence look clrarly relevant to the issue of whether she is\nsuman, then similar reasoning suggests that the obvious truth of (2a)\nimplies that Rat cannot apply (\\#\\#) to the properties of being a human\nonce she knows that she is a $C$, for (2a) makes that evidence look\nclearly relevant to the issue of whether she is human. The point is that\na restriction on (\\#\\#) that is to deliver (\\#) must fine some\nepistemologically salient distinction between the property of being\nhuman and the property of being suman if it is to rule out one\napplication of (\\#\\#) without ruling out the other, and if we only\nconsider formal constraints, we won't find such a restriction. Our final\nattempt to justify (\\#) from something like (\\#\\#) attempts to avoid\nthis problem by appealing directly to the nature of Rat's evidence.\n\n### Fourth Interpretation\n\nThe problems with the three interpretations of (\\#\\#) so far have been\nthat they applied *after* Rat found out something distinctive about\nherself, that she was a *C*. Perhaps (\\#\\#) is really a constraint on\n*prior* credence functions. *A priori*, Rat's credences should be\ngoverned by an unrestricted version of (\\#\\#). We then have the\nfollowing argument for (\\#). (As noted above, (\\#) is a constraint on\ncurrent credences, so it is not immediately entailed by a constraint on\nprior credences such as (\\#\\#) under its current interpretation.)\n\nP1\n\n:   *A priori*, Rat's conditional credence in her being a Sim given that\n    *f~Sim~* is *x* is *x*.\n\nP2\n\n:   All of Rat's evidence is probabilistically independent of the\n    property of being a Sim.\n\nC\n\n:   Rat's current conditional credence in her being a Sim given that\n    *f~Sim~* is *x* is *x*.\n\nThis interpretation may be reasonably faithful to what Bostrom had in\nmind. The argument just sketched looks similar enough to what he hints\nat in the following quote: \"More generally, if we knew that a fraction\n*x* of all observers with human-type experiences live in simulations,\nand we don't have any information that indicate that our own particular\nexperiences are any more or less likely than other human-type\nexperiences to have been implemented *in vivo* rather than *in machina*,\nthen our credence that we are in a simulation should equal *x*.\" So it's\nnot unreasonable to conclude that he is committed to P2, and intends it\nto be used in the argument that you should give high credence to being a\nSim.[^3] Further, this version of (\\#\\#), where it is restricted to\nprior credences, does not look unreasonable. So if P2 is true, an\nargument for (\\#) might just succeed. So the issue now is just whether\nP2 is true.\n\nWhy might we reject P2? Any of the following three reasons might do.\nFirst, Rat's evidence might be constituted by more than her conscious\nphenomenal states. This reply has an externalist and an internalist\nversion. On the externalist version, Rat's perceptual evidence is\nconstituted in part by the objects she is perceiving. Just as seeing a\ndagger and hallucinating a dagger provide different evidence, so does\nseeing a dagger and sim-seeing a sim-dagger. For reasns Williamson\nnotes, a Sim may not know that she has different evidence to someone\nseeing a dagger when she sim-sees a sim-dagger, but that does not imply\nthat she does not have different evidence unless one also assumes,\nimplausibly, that agents know exactly what their evidence is\n@Williamson2000-WILSAE-2. On the internalist version, our evidence is\nconstituted by our sensory irritations, just as Quine said it is\n[@Quine1973]. If Rat's evidence includes the fact that her eyes are\nbeing irritated thus-and-so, his credence conditional on that that she\nis human should be 1, for if she were a Sim she could not have this\nevidence because she would not have eyes. She may, depending on the kind\nof Sim she is, have sim-eyes, but sim-eyes are not eyes. So Bostrom\nneeds an argument that evidence supervenes on conscious experiences, and\nhe doesn't clearly have one. This is not to say that no such argument\ncould exist. For example, Laurence BonJour provides some intriguing\ngrounds for thinking that our fundamental evidence does consist in\ncertain kinds of conscious states, namely occurrent beliefs\n[@BonJour1999], but we're a long way from knowing that the supervenience\nclaims holds. And if the supervenience claim does not hold, then even if\nSims and humans have the same kind of *experiences*, they may not have\nthe same kind of *evidence*. And if that is true, it is open to us to\nhold that Rat's non-experiential evidence entails that she is not a Sim\n(as both Williamson and Quine suggest), so her evidence will not be\nindependent of the question of whether she is a Sim.\n\nSecondly, even if every one of Rat's experiences is probabilistically\nindependent of the hypothesis that she is a Sim, that doesn't give us a\nsufficient reason to believe that her total evidence is so independent.\nJust because *e*~1~ and *e*~2~ are both probabilistically independent of\n*H*, the conjunction *e*~1~ ${\\wedge}$ *e*~2~ might not be independent\nof *H*. So possibly our reasons for accepting P2 involve a tacit scope\nconfusion.[^4]\n\nFinally, we might wonder just why we'd even think that Rat's evidence is\nprobabilistically independent of the hypothesis that she is human. To be\nsure, her evidence does not entail that she is human. But that cannot be\nenough to show that it is probabilistically independent. For the\nevidence also does not entail that she is suman. And if P2 is true, then\nthe evidence must have quite a bit of bearing on whether she is suman.\nFor Rat's prior credence in being suman is above 0.9 but apparently her\nposterior credence in it should be below 0.15. So the mere fact that the\nevidence does not entail that she is human cannot show that it is\nprobabilistically independent of her being human, for the same reasoning\nwould show it is probabilistically independent of his being suman.\n\nMore generally, we still need a distinction here between the property of\nbeing human and the property of being suman that shows why ordinary\nevidence should be independent of the first property but not the second.\nOne might think the distinction can reside in the fact that *being\nhuman* is a natural property, while *being suman* is gruesome. The\nlesson of Goodman's riddle of induction is that we have to give a\nprivileged position in our epistemic framework to natural properties\nlike *being human*, and this explains the distinction. This response\ngets the status of privileged and gruesome properties back-to-front. The\nreal lesson of Goodman's riddle is that credences in hypotheses\ninvolving natural properties should be distinctively *sensitive* to new\nevidence. Our evidence should make us quite confident that all emeralds\nare green, while giving us little reason to think that all emeralds are\ngrue. What P2 says is that a rather natural hypothesis, that Rat is\nhuman, is *insensitive* to all the evidence Rat has, while a rather\ngruesome hypothesis, that Rat is suman, is *sensitive* to this evidence.\nThe riddle of induction gives us no reason to believe that should\nhappen.\n\nIt seems, though this is a little speculative, that the only reason for\naccepting P2 involves a simple fallacy. It is true that we have no\nreason to think that some evidence, say *C*, is more or less likely\ngiven that Rat is human rather than a Sim. But from this we should *not*\nconclude that we *have* a reason to think it is not more or less likely\ngiven that Rat is human rather than a Sim, which is what P2 requires.\nIndeed, drawing this kind of conclusion will quickly lead to a\ncontradiction, for we can use the same 'reasoning' to conclude that we\nhave a reason to think her evidence is not more or less likely given\nthat Rat is a suman rather than a him.\n\n### Conclusion\n\nNothing I have said here implies that Rat should have a high credence in\nher being human. But it does make one argument that she should not have\na high credence in this look rather tenuous. Further, it is quite\nplausible that if there is no good reason not to give high credence to a\nhypothesis, then it is rationally permissible to give it such a high\ncredence. It may not be rationally mandatory to give it such a high\ncredence, but it is permissible. If Rat is very confident that she is\nhuman, even while knowing that most human-like beings are Sims, she has\nnot violated any norms of reasoning, and hence is not thereby\nirrational. In that respect she is a bit like you and me.\n\n[^1]: [Link](http://www.instapundit.com/archives/003465.php#003465).\n    Reynolds's comment wasn't directly about Bostrom, but it bore the\n    ancestral of the relation *refers* to Bostrom's paper.\n\n[^2]: I think it is this interpretation of (\\#\\#) that Adam Elga\n    implicitly appeals to in his solution to the Sleeping Beauty problem\n    @Elga2000-ELGSBA.\n\n[^3]: Jamie Dreier pointed out to me that what Bostrom says here is\n    slightly more complicated than what I, hopefully charitably,\n    attribute to him. A literal reading of Bostrom's passage suggests he\n    intends the following principle.\n\n      ${\\forall}$*e*: *Cr*(*e*  *Human*) - *Cr*(*e*  *Sim*) =\n    *Cr*(*e*  *Human*) - *Cr*(*e*  *Sim*)      (B)\n\n    The quantifier here ranges over possible experiences *e*, *e* is the\n    actual experience Rat has, and *Cr* is the credence function at the\n    'time' when Rat merely knows that he is human-like and *f~Sim~* is\n    greater than 0.9. I suggested a simpler assumption:\n\n      *Cr*(*Human*  *e*) = *Cr*(*Sim*  *e*)            (I)\n\n    Bostrom needs something a little stronger than (I) to get his\n    desired conclusion, for he needs this to hold not just for Rat's\n    experience *e*, but for your experience and mine as well. But we\n    will not press that point. Given that point, though, (I) is all he\n    needs. And presumably the reason he adopts (B) is because it looks\n    like it entails (I). And indeed it does entail (I) given some fairly\n    innocuous background assumptions.\n\n[^4]: Thanks to Jamie Dreier for reminding me of this point.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}