{
  "hash": "7d4f60f38adbc1d294b92809ca5c3197",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Deontology and Descartes's Demon\"\ndescription: |\n In this paper, I defend a broadly Cartesian position about doxastic freedom. At least some of our beliefs are freely formed, so we are responsible for them. Moreover, this has consequences for epistemology. But the some here is crucial. Some of our beliefs are not freely formed, and we are not responsible for those. And that has epistemological consequences too. Out of these considerations a concept of doxastic responsibility arises that is useful to the externalist in responding to several challenges. I will say at some length how it supports a familiar style of externalism response to the New Evil Demon problem, and I will note some difficulties in reconciling internalism with the idea that justification is a kind of blamelessness. The internalist, I will argue, has to say that justification is a kind of praiseworthiness, and this idea that praise is more relevant to epistemic concepts than blame will be a recurring theme of the paper.\ndate: September 1 2008\nauthor:\n  - name: Brian Weatherson \n    url: http://brian.weatherson.org\n    affiliation: University of Michigan\n    affiliation_url: https://umich.edu\n    orcid_id: 0000-0002-0830-141X\ncategories:\n  - epistemology\n  - epistemic norms\n  - epistemic voluntarism\njournal:\n    title: \"Journal of Philosophy\"\n    publisher: \"Columbia University\"\nvolume: 105\nnumber: 9\ncitation: false\nbibliography: ../../../articles/Rbib.bib\nself-contained: false\npreview: bike.jpg\noutput:\n  distill::distill_article:\n    toc: true\n    toc_depth: 3\n    number_sections: true\n---\n\n\n\n### Digesting Evidence\n\nIn his *Principles of Philosophy*, Descartes says,\n\n> Finally, it is so manifest that we possess a free will, capable of\n> giving or withholding its assent, that this truth must be reckoned\n> among the first and most common notions which are born with us.\n> [@DescartesPrinciples paragraph xxxix]\n\nIn this paper, I am going to defend a broadly Cartesian position about\ndoxastic freedom. At least some of our beliefs are freely formed, so we\nare responsible for them. Moreover, this has consequences for\nepistemology. But the some here is crucial. Some of our beliefs are not\nfreely formed, and we are not responsible for those. And that has\nepistemological consequences too. Out of these considerations a concept\nof doxastic responsibility arises that is useful to the externalist in\nresponding to several challenges. I will say at some length how it\nsupports a familiar style of externalism response to the New Evil Demon\nproblem, and I will note some difficulties in reconciling internalism\nwith the idea that justification is a kind of blamelessness. The\ninternalist, I will argue, has to say that justification is a kind of\npraiseworthiness, and this idea that praise is more relevant to\nepistemic concepts than blame will be a recurring theme of the paper.\n\nWhile the kind of position I am adopting has been gaining supporters in\nrecent years, it is still largely unpopular. The arguments of William\n@Alston1988 have convinced many that it is a mistake to talk of doxastic\nfreedom, or doxastic responsibility. The short version of this argument\nis that our beliefs are involuntary, and freedom and responsibility\nrequire voluntariness. The longer, and more careful, argument involves\ndrawing some distinctions between ways in which we might come to be in a\nstate. It helps to start with an example where the normative facts are\nrelatively uncontroversial, namely digestion.\n\nImagine that Emma eats a meat pie, and due to a malfunction in her\nstomach the pie is not properly digested, leading to some medical\ncomplications. Is Emma responsible for her ill-health? Well, that\ndepends on the back-story. If Emma knew that she could not properly\ndigest meat pies, but ate one anyway, she is responsible for the illness\nvia her responsibility for eating the pie. Even if Emma did not know\nthis, she might be responsible for the state of her stomach. If her\nstomach could not digest the pie because it had been damaged by Emma's\ndietary habits, and say Emma knew that her diet could damage her\nstomach, then Emma is responsible for the state of her stomach and hence\nfor the misdigestion of the pie and hence for her ill-health. But if\nneither of these conditions obtain, if it just happens that her stomach\nmisdigests the pie, then Emma is not responsible for her ill-health.\nEven though the cause of her ill-health is something that her stomach\ndoes, he is not responsible for that since her stomach is not under her\nvoluntary control. Put another way, her responsibility for maintaining\nher own health means that she is responsible for the type of digester\nshe is, but he is not responsible for this token digestion.\n\nSimplifying a little, Alston thinks that the case of belief is similar.\nSay that Emma has a false belief that *p*. Is she responsible for this\npiece of doxastic ill-health? Again, that depends on the back story. If\nEmma believes that *p* because she was careless in gathering evidence,\nand the evidence would have pointed to \\~*p*, then she is responsible\nfor being a bad gatherer of evidence. If Emma has been negligent in\nmaintaining her doxastic health, or worse if she has been doing things\nshe knows endangers doxastic health, then she is responsible for being\nthe type of believer she is. But she is never responsible merely for the\ntoken belief that is formed. Her mind simply digests the evidence she\nhas, and Emma's responsibility only extends to her duty to gather\nevidence for it, and her duty to keep her mind in good working order.\nShe is not responsible for particular acts of evidential digestion.\n\nBut these particular acts of evidential digestion are the primary\nsubject matters of epistemology. When we say Emma's belief is justified\nor unjustified, we frequently mean that it is a good or bad response to\nthe evidence in the circumstances. (I am obviously here glossing over\nenormous disputes about what makes for a good response, what is\nevidence, and what relevance the circumstances have. But most theories\nof justification can be fit into this broad schema, provided we are\nliberal enough in interpreting the terms 'good', 'evidence' and\n'circumstances'.) If Emma is not responsible for her response to the\nevidence, then either we have to divorce justification from\nresponsibility, or we have to say that the concept of justification\nbeing used in these discussions is defective.\n\nWe can summarise these considerations as a short argument. The following\nformulation is from Sharon [@Ryan2003 49].\n\n1.  If we have any epistemic obligations, then doxastic attitudes must\n    sometimes be under our voluntary control.\n\n2.  Doxastic attitudes are never under our voluntarily control.\n\n3.  We do not have any epistemic obligations.\n\nRyan goes on to reject both premises. (And she does so while\ninterpreting \"voluntary control\" to mean \"direct voluntary control\"; the\nresponse is not meant to sidestep Alston's argument.) Matthias\n@Steup2000 [@Steup2008] also rejects both premises of this argument. I\nam more sympathetic to premise 1, but I (tentatively) agree with them,\nagainst what sometimes seems to be orthodoxy, that premise 2 fails. That\nis, I endorse a kind of doxastic voluntarism. (Just what kind will\nbecome clearer as we go along.) There are four questions that anyone who\nendorses voluntarism, and wants to argue that this matters\nepistemologically, should I think answer. These are:\n\n1.  What is wrong with current arguments against voluntarism?\n\n2.  What does the voluntariness of (some) beliefs consist in?\n\n3.  Which kinds of beliefs are voluntary?\n\n4.  What difference does the distinction between these classes make for\n    epistemology?\n\nMy answer to (A) will be similar to Ryan's, and to Steup's, but with I\nthink enough differences in emphasis to be worth working through. My\nanswer to (B), however, will be a little more different. I am going to\ndraw on some work on self-control to argue that some beliefs are\nvoluntary because they are the result of exercises of, or failures to\nexercise, self-control. My answer to (C) is that what I will call\ninferential beliefs are voluntary, while perceptual beliefs are not.\nRyan and Steup sometimes seem to suggest that even perceptual beliefs\nare voluntary, and I do not think this is true. The consequence for\nthis, I will argue in answering (D), is that inferential beliefs should\nbe judged by how well they respond to the evidence, while perceptual\nbeliefs should be judged by how well they reflect reality. When an agent\nhas misleading evidence, their inferential beliefs might be fully\njustified, but their perceptual beliefs, being misleading, are not.\n\nI will detail my answers to those four questions in sections 2, 4, 6 and\n7. In between I will discuss recent work on self-control (section 3) and\nthe contrast between my answer to (B) and other voluntarist answers\n(section 5). In section 8 I will say how my partially voluntarist\nposition gives the externalist a way to avoid the New Evil Demon\nproblem. And in section 9 I will make a direct argument for the idea\nthat justification is a kind of praiseworthiness, not a kind of\nblamelessness.\n\nBefore we start, I want to note two ways, other than Ryan's, of\nformulating an argument against doxastic responsibility. These are going\nto seem quite similar to Ryan's formulation, but I think they hide\nimportant differences. The first version uses the idea that some doings\n(or states) are volitional. That is, we do them (or are in them) because\nwe formed a volition to do so, and this volition causes the doing (or\nstate) in the right kind of way.\n\n1.  If we have any epistemic obligations, then either the formation or\n    maintenance of doxastic attitudes must sometimes be volitional.\n\n2.  The formation or maintenance of doxastic attitudes is never\n    volitional.\n\n3.  We do not have any epistemic obligations.\n\nI will not argue against premise 2 of this argument, though Carl\n@Ginet1985 [@Ginet2001] (1985, 2001) has done so. But I think there's\nlittle to be said for premise 1. The principle behind it is that we are\nonly responsible for volitional doings. And that principle is very\ndubious. We could run the kind of regress arguments against it that\nGilbert @Ryle1949 offers. But it is simpler to note some everyday\ncounterexamples. Borrowing an example from Angela M @AngelaSmith2005, if\nI forget a friend's birthday, that is something I am responsible and\nblameworthy for, but forgetting a birthday is not volitional. (Below I\nwill offer a Rylean argument that we are sometimes praiseworthy for\ndoings that are not volitional.) So this argument fails. Alternatively,\nwe could run the argument by appeal to freedom.\n\n1.  If we have any epistemic obligations, then doxastic attitudes must\n    sometimes be free.\n\n2.  Doxastic attitudes are never free.\n\n3.  We do not have any epistemic obligations.\n\nPremise 1 of this argument is more plausible. But, as we'll see\npresently, premise 2 is not very plausible. Whether Descartes was right\nthat premise 2 is obviously false, it does seem on reflection very hard\nto defend. So this argument fails. Ryan's formulation is interesting\nbecause it is not clear just which of the premises fails. As I said, I\nam going to suggest that premise 2 fails, and that doxastic attitudes\nare voluntary. But this will turn on some fine judgments about the\nvoluntary/involuntary boundary. If I am wrong about those judgments,\nthen the arguments below will suggest that premise 1, not premise 2, in\nRyan's formulation fails. Either way though, the argument is\nunsuccessful.\n\n### Responding to the Involuntarists\n\nThere are two kinds of argument against the idea that belief is\nvoluntary. One kind, tracing back to Bernard @WilliamsDecidingToBelieve,\nholds that the possibility of voluntary belief can be shown to be\nincoherent by reflection on the concept of belief. This argument is no\nlonger widely endorsed. Nishi @Shah2002 provides an excellent discussion\nof the problems with Williams' argument, and I have nothing to add to\nhis work. I will focus on the other kind, that claims we can see that\nbelief is involuntary by observing differences between beliefs and\nparadigm cases of voluntary actions. I will make three objections to\nthese arguments. First, the argument looks much less plausible once we\ndistinguish between having a belief and forming a belief. Second, the\nargument seems to rely on inferring from the fact that we do not do\nsomething (in particular, believe something that we have excellent\nevidence is false) to the conclusion that we can not do it. As Sharon\n@Ryan2003 points out, this little argument overlooks the possibility\nthat we will not do it. Third, the argument relies on too narrow a\nconception of what is voluntary, and when we get a more accurate grasp\non that concept, we'll give up the argument. Here is a representative\nversion of the argument from William Alston.\n\n> Can you, at this moment, start to believe that the United States is\n> still a colony of Great Britain, just by deciding to do so? ...\n> [S]uppose that someone offers you \\$500,000,000 to believe it, and\n> you are much more interested in the money than in believing the truth.\n> Could you do what it takes to get that reward? . . . Can you switch\n> propositional attitudes toward that proposition just by deciding to do\n> so? It seems clear to me that I have no such power. Volitions,\n> decisions, or choosings don't hook up with anything in the way of\n> propositional attitude inauguration, just as they don't hook up with\n> the secretion of gastric juices or cell metabolism. [@Alston1988 122]\n\nNow Alston does note, just one page earlier, that what is really\nrelevant is whether our being in a state of belief is voluntary, not\nwhether the activity of belief formation is voluntary. But he thinks\nnevertheless that issues about whether we can form beliefs, any old\nbeliefs it seems, voluntarily matters to the question about the\nvoluntariness of belief states.\n\nIf we think about what it is to be in a state voluntarily, this all\nseems beside the point. We can see this by considering what it is to be\nin a political state voluntarily. Consider Shane, who was born into\nVictoria. His coming to be in Victoria was hence not, in any way,\nvoluntary. Shane is now a grown man, and he has heard many travellers'\ntales of far away lands. But the apparent attractions of Sydney and\nother places have no pull on Shane; he has decided to stay in Victoria.\nIf he has the capacity to leave Victoria, then Shane's continued\npresence in Victoria is voluntary. Similarly, we are voluntarily in a\nbelief state if we have the capacity to leave it, but choose not to\nexercise this capacity. Whether the belief was formed voluntarily is\nbeside the point.\n\nIf Shane leaves a state, the natural place to leave is for another\nstate, perhaps New South Wales or South Australia. It might be thought\nthat if we leave a belief state, we have to move into another belief\nstate. So to have this capacity to leave, we need the ability to form\nbeliefs voluntarily. Not at all. The capacity to become uncertain, i.e.\nto not be in any relevant belief state, is capacity enough. (If Shane\nhas a boat, and the capacity to flourish at sea, then perhaps he too can\nhave the capacity to leave Victoria without the capacity to go into\nanother state.)\n\nBut do we have the capacity to become uncertain? Descartes appeared to\nthink so; arguably the point of the First Meditation is to show us how\nto exercise this capacity. Moreover, this capacity need not be one that\nwe exercise in any particularly nearby possible worlds. We might\nexercise our freedom by always doing the right thing. As Descartes goes\non to say in the Fourth Meditation.\n\n> For in order to be free, there is no need for me to be capable of\n> going in each of two directions; on the contrary, the more I incline\n> in one direction -- either because I clearly understand that reasons\n> of truth and goodness point that way, or because of a divinely\n> produced disposition of my inmost thoughts -- the freer is my choice.\n> [@DescartesMeditations 40]\n\nThis seems like an important truth. Someone who is so sure of their own\ninterests and values, and so strong-willed as to always aim to promote\nthem, cannot in a certain sense act against their own self-interest and\nvalues. But this does not make their actions in defence of those\ninterests and values unfree. If it did, we might well wonder what the\nvalue of freedom was. And note that even if there's a sense that our\ncharacter could not have done otherwise, this in no way suggests their\nactions are outside their control. Indeed, a person who systematically\npromotes the interests and values they have seems an exemplar of an\nagent in control. The character I am imagining here is in important\nrespects unlike normal humans. We know we can, and do, act against our\ninterests and values. But we can become more or less like them, and it\nis important to remember, as Descartes does, that in doing so we do not\nsacrifice freedom for values or interests.\n\nJohn @Cottingham2002 interprets Descartes here as suggesting that there\nis a gap between free action and voluntary action, contrasting his\n\"strongly compatibilist notion of human freedom\" (350) with the\n\"doxastic involuntarism\" (355) suggested by the following lines of the\nThird Meditation.\n\n> Yet when I turn to the things themselves which I think I perceive very\n> clearly, I am so convinced by them that I spontaneously declare: let\n> whoever can do so deceive me, he will never bring it about that I am\n> nothing, so long as I continue to think that I am something ...\n> [@DescartesMeditations 25]\n\nNow there are two questions here. The first is whether Descartes\nintended to draw this distinction. That is, whether Descartes thought\nthat the kind of free actions that he discusses in the Fourth\nMeditations, the free action where we are incapable of going in the\nother directions, are nevertheless involuntary. I do not have any\ninformed opinions about this question. The second is whether this kind\nof consideration supports the distinction between the free and the\nvoluntary. And it seems to me that it does not. Just as Descartes says\nthe free person will be moved by reasons in the right way, it seems\nnatural to say that a person who acts voluntarily will be responsive to\nreasons. Voluntary action does require freedom from certain kinds of\ncoercion, but the world does not coerce us when it gives us reason to\nbelieve one thing rather than another. If we have voluntary control over\nour beliefs, then we should be compelled by the sight of rain to believe\nit is raining.\n\nIn her discussion of the puzzle of imaginative resistance, Tamar Szabó\n@Gendler2000 notes that philosophers have a tendency to read too much\ninto intuitions about certain cases. What we can tell from various\nthought experiments is that in certain circumstances we will not do a\ncertain thing. But getting from what we will not do to what we can not\ndo is a tricky matter, and it is a bad mistake to infer from will not to\ncan not too quickly. Matthias @Steup2000 points out that if you or I try\nto stick a knife into our hand, we similarly will not do it. (I assume a\nsomewhat restricted readership here.) But this is no evidence that we\ncannot do it. And Sharon @Ryan2003 notes that we will not bring\nourselves to run over pedestrians for no reason. For most of us, our\nmoral sense prevents acting quite this destructively. Yet our continued\navoiding of pedestrians is a series of free, even voluntary, actions. We\ncould run over the pedestrians, but we will not. Since forming false\nbeliefs is a form of self-harm, it is not surprising that it has a\nsimilar phenomenology, even if it is genuinely possible.\n\nIt might be argued that we will engage in small forms of self-harm that\nwe can do when the financial rewards are great enough. So we should be\nable to form this belief about the United States for a large amount sum\nof money. But I suspect that the only way to exercise the capacity to\nbelieve the United States is still a colony is by first suspending my\nbelief that it is no longer a colony. And the only way I can do that is\nby generally becoming more sceptical of what I have been told over the\nyears. Once I get into such a sceptical mood, I will be sceptical of\nclaims that I will get half a billion dollars should I have this wild\npolitical belief. So I will not form the belief in part because the\n'promisor' lacks the capacity to sufficiently convince me that I will be\nrichly rewarded for doing so. This looks like a lack of capacity on\ntheir part, not my part.\n\nThe final point to make about this argument, and those like it, is that\nif we are to conclude that belief formation is never voluntary, then we\nneed to compare it to all kinds of voluntary action. And Alston really\nonly ever compares belief formation to volitional action. If this does\nnot exhaust the range of voluntary action, then belief formation might\nbe properly analogous to some other voluntary action. Indeed, this turns\nout to be the case. To see so, we need to make a small detour through\nmodern work on self-control.\n\n### How to Control Your Temper\n\nTo start, let's consider three examples of a person failing to keep a\ncommitment they have made about what the good life is. The three ways\nwill be familiar from Gary Watson's discussion of recklessness, weakness\nand compulsion @Watson1977, and the discussion of these cases by\nJeanette Kennett and Michael Smith @KennettSmith1996a\n[@KennettSmith1996b]. My characterisation of the cases will turn out to\ndiffer a little from theirs, but the cases are similar. Each of the\nexamples concerns a character Murray, who has decided that he should not\nswear around his young son Red. He resolves to do this, and has been\nworking on curbing his tendency to swear whenever anything bad happens.\nBut three times over the course of the day he breaks his commitment.[^1]\n\nThe first time comes when Murray puts his hand down on a hot plate that\nhe did not realise was on. The searing pain undermines his self-control,\nand he is unable to stop himself from swearing loudly through the pain.\n\nThe second time comes when Murray drops and breaks a wine glass. Murray\ndoes not lose his self-control, but he does not exercise the\nself-control he has. He temporarily forgets his commitment and so, quite\nliterally, curses his misfortune. On doing so he immediately remembers\nthat Red is around, and the commitment he has made, and regrets what he\ndid.\n\nThe third time comes on the tram home, when Murray gets into a\ndisagreement with a political opponent. Murray can not find the words to\nexpress what he feels about the opponent without breaking his\ncommitment. So he decides, without much reason, that his need to express\nwhat he feels outweighs his commitment, and starts describing his\nopponent using language he would, all things considered, not have used\naround young Red.\n\nThe first and third cases are close to textbook cases of compulsion and\nrecklessness. Note in the first case that when Murray reflects back on\nwhat happened, he might be irritated that his work on reducing his\ntendency to swear has not been more successful. But he will not be upset\nthat he did not exercise more self-control on that occasion. He did not\nhave, no normal person would have, the amount of self-control he would\nhave needed to stop swearing then. All that would help is having the\ndisposition to say different things when his self-control is defeated.\nAnd that is not a disposition he can acquire on the spot.\n\nI have described the first case as one where Murray's self-control is\nundermined. This is a term taken from recent work by Richard Holton and\nStephen Shute [-@HoltonShute2007], who carefully distinguish between\nself-control being undermined by a provocation, and it being overwhelmed\nby a provocation. Undermining occurs when the provocation causes the\nagent to have less self-control than they usually have; overwhelming\noccurs when the provocation is too much for the agent's control. The\ndifference is relevant to them, because they are interested in what it\nis for an agent to lose control. That seems to be what happens here.\nAfter all, the things one would naturally do afterwards (jumping around,\nscreaming, swearing if one's so disposed) do not seem particularly\ncontrolled by any measure.\n\nSimilarly I have accepted Watson's description of cases like the third\nas instances of recklessness, but we should not think this necessarily\ncontrasts with weakness. It might be that in this case Murray is both\nweak and reckless. He is not akratic, if we stipulatively define akrasia\nas acting against one's better judgment. But if we accept Richard\nHolton's view that weakness of will consists in being \"too ready to\nreconsider their intentions\" [@Holton1999 241], then in this case Murray\nis weak-willed.[^2]This seems to be the right way to talk about the case\nto me. With these details in place, we can talk about what's crucial to\nthis essay, the contrast with the second case.\n\nIn the second case Murray fails to exercise self-control. He could have\nprevented himself from swearing in front of his son. Breaking a wine\nglass is irritating, but it neither undermines nor, necessarily,\noverwhelms self-control. Murray had the capacity to think about his\nresolution to not swear in front of Red. And if he had exercised this\ncapacity, he would not have sworn when he did.\n\nIn the first case, Murray will only regret his lack of prior work at\nchanging his dispositions in cases where his control fails. In the\nsecond case he will regret that, but he will also regret what he did on\nthat occasion, for he could have kept his resolution, had only he\nthought of it. This regret seems appropriate, for in the second case he\ndid something wrong at the time he swore, as well perhaps as having done\nsomething wrong earlier. (Namely, not having worked hard enough on his\ndispositions.) This difference in regret does not constitute the\ndifference between compulsion and a case where self-control fails, but\nit is pretty good evidence that this is a failure of self-control.\n\nSo the second case is not one where Murray was compelled. He had the\ncapacity to keep his commitment, and nothing was stopping him exercising\nthis control, but he failed to do so. His failure was a failure of\nself-control. Murray's self-control is, in this case, overwhelmed by the\nprovocation. But it need not have been. Within some fairly broad limits,\nhow much self-control we exercise is up to us.[^3] Murray's failure of\nself-control is culpable because anyone with the capacity for\nself-control Murray has could have avoided breaking his commitment. I am\nnot going to try to offer an analysis of what it is to have a capacity,\nbut I suspect something like the complicated counterfactual analysis\nKennett and Smith offer, and that Smith offers elsewhere\n[@Smith1997; @Smith2003], is broadly correct.[^4]\n\nKennett and Smith stress two things about this capacity that are worth\nnoting here. First, having this kind of capacity is part of what it is\nto be rational. That is, being rational requires thinking of the right\nthing at the right time. As Ryle says, \"Intelligently reflecting how to\nact is, among other things, considering what is pertinent and\ndisregarding what is inappropriate.\"[@Ryle1949 31] Second, Kennett and\nSmith note that exercises of this capacity cannot be volitional.\nFollowing @Davidson1963, they say they cannot be actions. I find this\nterminology somewhat strained. Catching a fast moving ball is an action,\nI would say, but it does not seem to be volitional. So I will use\n'volitional action' for this Davidsonian sense of action.\n\nMany recent philosophers have endorsed the idea that some of the mental\nstates for which we hold people responsible are not voluntary, or at\nleast are not volitional. @Adams1985 [@Heller2000; @Owens2000] and\n@Hieronymi2008 note ways in which we appropriately blame people for\nbeing in certain states, where being in that state is not volitional.\nSomething like this idea seems to be behind Ryle's several regress\narguments against the intellectualist legend. It just is not true that\nwhat we do divides cleanly into outcomes of conscious thought on the one\nhand, and mere bodily movements (a la digestion) on the other.[^5]\nRather there is a spectrum of cases from pure ratiocination at one end\nto pure bodily movement at the other. And some of the things in the\nmiddle of this spectrum are proper subjects of reactive attitudes. The\nfocus in this literature has been on blame, but some states in the\nmiddle of this spectrum are also praiseworthy.\n\nConsider some action that is strikingly imaginative, e.g. a writer's apt\nmetaphor or, say, a cricket captain's imaginative field placements. It\nseems that, assuming the field settings are successful, the captain\ndeserves praise for being so imaginative. But of course the captain did\nnot, really could not, first intend to imagine such field settings, then\ncarry out that intention. So something for which the captain deserves\npraise, his act of imagination, is not volitional. So not all\npraiseworthy things we do are volitional.\n\nThere are two responses to this argument that I can imagine, neither of\nthem particularly plausible. First, we might think that the captain's\nimagination is simply a remarkable feature of nature, as the Great\nBarrier Reef is. It is God, or Mother Nature, who should be praised, not\nthe captain. Now it seems fair to react to some attributes of a person\nthis way. A person does not deserve praise for having great eyesight,\nfor example. But such a reaction seems grossly inappropriate, almost\ndehumanising, in this case. To be sure, we might also praise God or\nMother Nature for yielding such an imaginative person, but we'll do that\nas well as rather than instead of, praising the person. Second, we might\npraise the captain for his work in studying the game, and thinking about\npossible ways to dismiss batsmen, rather than this particular action.\nBut if that is what we praise the captain for, we should equally praise\nthe captain's opponent, a hard working dullard. And that does not seem\nright. The hard-working dullard deserves praise for his hard work in the\nlead up, but the hard-working imaginative skipper deserves praise for\nwhat he does in the game too. So reactive attitudes, particularly\npraise, are appropriately directed at things people do even if these\nthings are not volitional.\n\nThe key point of this section then is that responsibility outruns\nvolition. Some actions are blameworthy because they are failures of\nself-control. Some actions are praiseworthy because they are wonderful\nfeats of imagination. But neither failing to exercise self-control, nor\nexercising imagination, needs be volitional is order to be a locus of\nresponsibility. I will argue in the next section that these\nconsiderations support the idea of responsibility for beliefs.\n\n### Voluntariness about Belief\n\nHere is a situation that will seem familiar to anyone who has spent time\nin a student household. Mark is writing out the shopping list for the\nweekly grocery shop. He goes to the fridge and sees that there is a\ncarton of orange juice in the fridge. He forms the belief that there is\norange juice in the fridge, and hence that he does not need to buy\norange juice. As it turns out both of these beliefs are false. One of\nhis housemates finishes off the orange juice, but stupidly put the empty\ncarton back in the fridge. When Mark finds this out, he is irritated at\nhis housemate, but he is also irritated at himself. He did not have to\ndraw the conclusion that there was orange juice in the fridge. He was,\nafter all, living in a student house where people do all sorts of dumb\nthings. That his housemate might have returned an empty container to the\nfridge was well within the range of live possibilities. Indeed had he\neven considered the possibility he would have thought it was a live\npossibility, and checked whether the container was empty before forming\nbeliefs about what was needed for the shopping.\n\nExamples like this can be easily multiplied. There are all sorts of\nbeliefs that we form in haste, where we could have stopped to consider\nthe various realistic hypotheses consistent with the evidence, and doing\nso would have stopped us forming the belief. Indeed, unless one is a\nreal master of belief formation, it should not be too hard to remember\nsuch episodes frequently from one's everyday life. These conclusions\nthat we leap to are voluntary beliefs; we could have avoided forming\nthem. And not only could we have avoided these formations, but we would\nhave if we had followed the methods for belief formation that we approve\nof. That seems enough, to me, to say the formation is voluntary. This is\nnot the only way that voluntary doings, like calling a relevant\npossibility to mind, can matter to belief. The next example will be a\nlittle more controversial, but it points at the importance of dismissing\nirrelevant possibilities.\n\nLater that evening, Mark is watching his team, Geelong, lose another\nfootball game. Geelong are down by eight goals with fifteen minutes to\ngo. His housemates are leaving to go see a movie, and want to know if\nMark wants to come along. He says that he is watching the end of the\ngame because Geelong might come back. One of his housemates replies, \"I\nguess it is possible they'll win. Like it is possible they'll call you\nup next week to see if you want a game with them.\" Mark replies, \"Yeah,\nyou are right. This one's over. So, which movie?\" Mark does nott just\ngive in to his housemates, he forms the belief that Geelong will lose.\nLater that night, when asked what the result of the game was, he says\nthat he did nott see the final score, but that Geelong lost by a fair\nbit. (In a recent paper [@Weatherson2005-WEACWD] I go into a lot more\ndetail on the relation between not taking possibilities seriously, and\nhaving beliefs. The upshot is that what Mark does can count as belief\nformation, even if his credence that Geelong will lose does not rise.)\n\nNow it is tempting, or perhaps I should say that I am tempted, to view\nthe housemate as offering Mark a reason to believe that Geelong will\nlose. We could view the housemate's comments as shorthand for the\nargument that Geelong's winning is as likely as Mark's playing for\nGeelong, and since the latter will not happen, neither will the former.\nAnd maybe that is part of what the housemate is doing. But the larger\npart is that she is mocking Mark for his misplaced confidence. And the\npoint of mocking someone, at least the point of constructive mockery\nlike this, is to get them to change their attitudes. Mark does so, by\nceasing to take seriously the possibility that Geelong will come back.\nIn doing so, he exercises a capacity he had for a while, the capacity to\ncease taking this unserious possibility seriously, but needed to be\nprompted to use.\n\nIn both cases I say Mark's belief formation is voluntary. In the first\ncase he forms the belief because he does not exercise his doxastic\nself-control. He should have hesitated and not formed a belief until he\nchecked the orange juice. And he would have done so if only he'd thought\nof the possibility that the container was empty. But he did not. And\njust as things we do because we do not bring the right thing to mind,\nlike Murray's swearing in the second case, are voluntary and\nblameworthy, Mark's belief is voluntary and blameworthy. In the second\ncase, he forms the belief by ceasing to take an unserious possibility\nseriously. In most cases of non-perceptual, non-testimonial belief\nformation, there is a counter-possibility that we could have taken\nseriously. Skill at being a believer involves not taking extreme\npossibilities, from Cartesian sceptical scenarios to unlikely\nfootballing heroics, seriously. Exercises of such skill are rarely, if\never, volitional. But just like other mental activities that are not\nvolitional can be voluntary and praiseworthy, not taking an extreme\npossibility seriously can be voluntary and praiseworthy.[^6]\n\nI have made two claims for Mark's beliefs in the above two cases. First,\nthey are instances of voluntary belief formation. In each case he could\nhave done otherwise, either by exercising or failing to exercise his\ncapacity to take various hypotheses seriously. Second, they are\nappropriate subjects of praise and blame. I imagine some people will\nagree with the second point but not the first. They will say that only\nvolitional actions are voluntary, even though things we do like bringing\nrelevant considerations to mind are praiseworthy or blameworthy. Such\npeople will agree with most of what I say in this paper. In particularly\nthey'll agree that the examples involving Mark undermine Alston's\nargument against the applicability of deontological concepts in\nepistemology. So I am not going to die in a ditch over just what we call\nvoluntary. That is, I won't fuss too much over whether we want to say\npremise 2 in Ryan's formulation of the argument is shown to be false by\nthese examples (as I say) or premise 1 is shown to be false (as such an\nobjector will say.) I will just note that it is hard for such people to\nsay intuitive things about the second instance of Murray's swearing, and\nthis seems like a strong reason to not adopt their position.[^7]\n\n### Ryan and Steup\n\nSharon Ryan has a slightly different view. She thinks that the truth of\nvoluntarism consists in the fact that we hold certain beliefs\nintentionally. She does not offer an analysis of what it is to do\nsomething intentionally, except to say that consciously deciding to do\nsomething is not necessary for doing it intentionally, but doing it\npurposefully is [@Ryan2003 70-71] In a similar vein, she says \"When\nthere's a car zooming toward me and I believe that there is, I'm\nbelieving freely because I'm believing what I mean to believe.\"\n[@Ryan2003 74] This is said to be an intentional, and I take it a\nvoluntary, belief.\n\nIt seems to me that there's a large difference between things we\nvoluntarily do, and things we mean to do, or do purposefully. There are\nseveral things we do voluntarily without meaning to do them. Murray's\nswearing in the second example above is one instance. When we misspeak,\nor (as I frequently do) mistype, we do things voluntarily without\nmeaning to do them. I do not mean by mistype cases where we simply hit\nthe wrong key, but such cases as where I write in one more negation than\nI meant to, or, as I did earlier this evening, write \"S is justified in\nbelieving that *p*\" when I meant to write \"S is justified in believing\nthat she is justified in believing that *p*.\" These are voluntary\nactions because I had the capacity to get it right, but did not exercise\nthe capacity. But they are not things I meant to do. (I suspect there\nare also cases where we do things because we mean to do them, but they\nare not voluntary. These include cases where we train ourselves to\nproduce a reflexive response. But I will not stress such cases here.)\n\nMatthias @Steup2008 argues that if compatibilism is true about free\naction, then our beliefs are free. His argument consists in running\nthrough the most plausible candidates to be compatibilist notions of\nfreedom, and for each candidate that is plausible, showing that at least\nsome of our beliefs satisfy the purported conditions on free actions. I\nagree with a lot of what Steup says, indeed this paper has been heavily\ninfluenced by what he says. But one crucial analogy fails I think. Steup\nis concerned to reject the premise that if $\\Phi$-ing is free, one\n$\\Phi$s because one has formed the intention to $\\Phi$. His response\ncentres around 'automatic' actions, such as the things we do when\nstarting our drive to work: inserting the key, shifting into reverse,\netc.\n\n> The question is whether they are caused by any antecedently formed\n> intentions. I don't think they are. ... I didn't form an intention to\n> ... shift into reverse.... I do things like that automatically,\n> without thinking about them, and I assume you do too. But one can't\n> form an intention to $\\Phi$ without thinking about $\\Phi$ing ... Just\n> one more example: I'd like to see the person who, just before brushing\n> her teeth, forms the intention to unscrew the cap of the toothpaste\n> tube. [@Steup2008 383]\n\nI suspect that Steup simply has to look in the mirror. It is true that\nwe do not usually form conscious intentions to shift into reverse, or\nunscrew the cap, but not all intentions are conscious. If we were asked\nlater, perhaps by someone who thought we'd acted wrongly, whether we\nintended to do these things, the natural answer is *yes*. The best\nexplanation of this is that we really did have an intention to do them,\nalbeit an unconscious one. (I am indebted here to Ishani Maitra.)\n\nSteup is right that free actions do not require a prior intention, but\nhis examples do not quite work. The examples I have used above are the\nRylean regress stoppers, such as acts of imagination, and actions that\nwe do because we did not think, like Murray's swearing. If asked later\nwhether he intended to say what he said, Murray would say yes in the\nthird example, but (I think) no in the first and second. Intuitively, I\nthink, he did not have such an intention.[^8]\n\n### Involuntarism about Perceptual Beliefs\n\nIn some early 1990s papers, Daniel Gilbert and colleagues defended a\nrather startling thesis concerning the relation of comprehension and\nbelief\n[@GilbertKrullMalone1990; @Gilbert1991; @GilbertTafarodiMalone1993]\nCasual introspection suggests that when one reads or hears something,\none first comprehends it and then, if it is backed by sufficient\nreasons, believes it. @Gilbert1991 argues against this seeming\nseparation of comprehension and belief, and in favour of a view said to\nderive from Spinoza. When we comprehend a sentence, we add it to our\nstock of beliefs. If the new belief is implausible given our old\nbeliefs, then we \"unbelieve\" it.[^9]\n\nWe may picturesquely compare the two models of belief and comprehension\nto two models for security. The way security works at a nightclub is\nthat anyone can turn up at the door, but only those cleared by the\nguards are allowed in. On the other hand, the way security works at a\nshopping mall is that anyone is allowed in, but security might remove\nthose it regards as undesirable. Intuitively, our minds work on the\nnightclub model. A hypothesis can turn up and ask for admission, but it\nhas to be approved by our cognitive security before we adopt it as a\nbelief. Gilbert's position is that we work on the shopping mall model.\nAny hypothesis put in front of us is allowed in, as a belief, and the\nrole of security is to remove troublemakers once they have been brought\ninside.\n\nNow I do not want to insist Gilbert's theory is correct. The\nexperimental evidence for it is challenged in a recent paper\n[@HassonSimmonsTodorov2005]. But I do want to argue that if it is\ncorrect, then there is a kind of belief that is clearly involuntary. We\ndo not have much control over what claims pass in front of our eyes, or\nto our ears. (We have some indirect control over this -- we could wear\neye shades and ear plugs -- but no direct control, which is what's\nrelevant.) If all such claims are believed, these are involuntary\nbeliefs. To be sure, nothing Gilbert says implies that we can not\nquickly regain voluntary control over our beliefs as we unbelieve the\nunwanted inputs. But in the time it takes to do this, our beliefs are\nout of our control.\n\nGilbert's theory is rather contentious, but there are other kinds of\nmental representations that it seems clear we can not help forming. In\n*The Modularity of Mind*, Jerry @Fodor1983 has a long discussion of how\nthe various input modules that he believes to exist are not under our\nvoluntary control.[^10] If I am sitting on a train opposite some people\nwho are chatting away, I can not help but hear what they say. (Unless,\nperhaps, I put my fingers in my ear.) This is true not just in the sense\nthat I can not help receive the sound waves generated by their\nvocalisations. I also can not help interpreting and comprehending what\nthey are saying. Much as I might like to not be bothered with the\ndetails of their lives, I can not help but hear what they say as a\nstring of English sentences. Not just hearing, but hearing as happens\nautomatically.\n\nThis automatic 'hearing as' is not under my voluntary control. I do not\ndo it because I want to do it, or as part of a general plan that I\nendorse or have chosen to undertake. It does not reflect any deep\nfeatures of my character. (Frankly I would much rather that I just heard\nmost of these conversations as meaningless noise, like the train's\nsound.) But I do it, involuntarily, nonetheless. This involuntariness is\nreflected in some of our practices. A friend tells me not to listen to\nX, because X is so often wrong about everything. Next I see the friend I\nsay that I now believe that *p*, and when the friend asks why, I say it\nis because X said that *p*. The friend might admonish me. They will not\nadmonish me for being within hearing range of X; that might have been\nunavoidable. And, crucially, they will not admonish me for interpreting\nX's utterances. Taken literally, that might be what they were asking me\nnot to do. But they'll know it was unavoidable. What they were really\nasking me not to do was the one relevant thing that I had control over,\nnamely believe what X said.\n\nAs Fodor points out at length, both seeing as and hearing as are\ngenerally outside voluntary control. Our perceptual systems, and by this\nI am including verbal processing systems, quickly produce\nrepresentations that are outside voluntary control in any sense. If any\nof these representations amount to beliefs, then there are some\ninvoluntary beliefs that we have. So we might think that in the case\nabove, although it was up to me to believe that *p*, it was not up to me\nto believe that, say, X said that *p*, because this belief was produced\nby a modular system over which I have no control.\n\nThis is not the position that Fodor takes. He thinks that beliefs are\nnot produced by input modules. Rather, the non-modular part of the mind,\nthe central processor, is solely responsible for forming and fixing\nbeliefs. And the operation of this central processor is generally not\nmandatory, at least not in the sense that the operation of the modules\nis mandatory. Whether this is right seems to turn (in part) on a hard\nquestion to do with the analysis of belief.\n\nLet us quickly review Fodor's views on the behaviour of input modules.\nThe purpose of each module is to, within a specified domain, quickly and\nautomatically produce representations of the world. These are, as on the\nnightclub model, then presented to cognition to be allowed in as beliefs\nor not. Here is how Fodor puts it.\n\n> I am supposing that input systems offer central processes hypotheses\n> about the world, such hypotheses being responsive to the current,\n> local distribution of proximal stimulations. The evaluation of these\n> hypotheses in light of the rest of what one knows is one of the things\n> that central processes are for; indeed, it *is* the fixation of\n> perceptual belief.[@Fodor1983 136]\n\nBut these representations do not just offer hypotheses. They can also\nguide action prior to being 'approved' by the central processes. That,\nat least, seems to be the point of Fodor's discussion of the\nevolutionary advantages of having fast modules [@Fodor1983 70-71]. The\ncore idea is that when one is at risk of being eaten by a panther, there\nis much to be said for a quick, automatic, panther recognition device.\nBut there is just as much to be said for acting immediately on one's\npanther recognition capacities rather than, say, searching for possible\nreasons why this panther appearance might be deceptive. And browsing\nreason space for such evidence of deceptions is just what central\nprocesses, in Fodor's sense, do. So it seems the natural reaction to\nseeing a panther should be, and is, guided more-or-less directly by the\ninput modules not central processes.\n\nSo these 'hypotheses' are representations with belief-like direction of\nfit, i.e. they are responsive to the world, that guide action in the way\nthat beliefs do. These are starting to sound a lot like beliefs. Perhaps\nwe should take a Gilbert-style line and say that we automatically\nbelieve what we perceive, and the role of Fodorian central processes is\nnot to accept or reject mere hypotheses, but to unbelieve undesirable\ninputs.[^11] There are a number of considerations that can be raised for\nand against this idea, and perhaps our concept of belief is not fine\nenough to settle the matter. But let's first look at three reasons for\nthinking these inputs are not beliefs.\n\nFirst, if they are beliefs then we are often led into inconsistency. If\nwe are looking at a scene we know to be illusory, then we might see\nsomething as an *F* when we know it is not an *F*. If the outputs of\nvisual modules are beliefs, then we inconsistently believe both that it\nis and is not *F*. Perhaps this inconsistency is not troubling, however.\nAfter all, one of the two inconsistent beliefs is involuntary, so we are\nnot responsible for it. So this inconsistency is not a sign of\nirrationality, just a sign of defective perception. And that is not\nsomething we should be surprised by; the case by definition is one where\nperception misfires.\n\nSecond, the inputs do not, qua inputs, interact with other beliefs in\nthe right kind of way. Even if we believe that *if p then q*, and\nperceive that *p*, we will not even be disposed to infer that *q* unless\nand until *p* gets processed centrally. On this point, see @Stich1978\nand [@Fodor1983 83-86]. The above considerations in favour of treating\ninputs as beliefs turned heavily on the idea that they have the same\nfunctional characteristics as paradigm beliefs. But as David\nBraddon-Mitchell and Frank Jackson [-@DBMJackson2007 114-123] stress,\nfunctionalism can only be saved from counterexamples if we include these\ninferential connections between belief states in the functional\ncharactisation of belief. So from a functionalist point of view, the\nencapsulation of input states counts heavily against their being\nbeliefs.\n\nFinally, if Fodor is right, then the belief-like representation of the\ncentral processes form something like a natural kind. On the other hand,\nthe class consisting of these representations plus the representations\nof the input modules looks much more like a disjunctive kind. Even if\nall members of the class play the characteristic role of beliefs, we\nmight think it is central to our concept of belief that belief is a\nnatural kind. So these inputs should not count as beliefs.\n\nOn the other hand, we should not overestimate the role of central\nprocesses, even if Fodor is right that central processes are quite\ndifferent to input systems. There are two related features of the way we\nprocess inputs that point towards counting some inputs as beliefs, and\nhence as involuntary beliefs. The first feature is that we do not have\nto put any effort into believing what we see. On the contrary, as both\nDescartes and Hume were well aware, we believe what we see by default,\nand have to put effort into being sceptical. The second feature is that,\ndramatic efforts aside, we can only be so sceptical. Perhaps sustained\nreflection on the possibility of an evil demon can make us doubt all of\nour perceptions at once. But in all probability, at least most of the\ntime, we can not doubt everything we see and hear.[^12] We can perhaps\ndoubt any perceptual input we receive, but we can not doubt them all.\n\nIn the picturesque terms from above, we might think our security system\nis less like a nightclub and more like the way customs appears to work\nat many airports. (Heathrow Airport is especially like this, but I think\nit is not that unusual.) Everyone gets a cursory glance from the customs\nofficials, but most people walk through the customs hall without even\nbeing held up for an instant, and there are not enough officials to stop\neveryone even if they wanted to. Our central processes, faced with the\noverwhelming stream of perceptual inputs, are less the all-powerful\nnightclub bouncer and more the overworked customs official, looking for\nthe occasional smuggler who should not be getting through.\n\nThe fact that inputs turn into fully fledged beliefs by default is some\nreason to say that they are beliefs as they stand. It is noteworthy that\nwhat Gilbert et al's experiments primarily tested was whether sentences\npresented to subjects under cognitive load ended up as beliefs of the\nsubjects. Now this could be because comprehending a sentence implies, at\nleast temporarily, believing it. But perhaps a more natural reading in\nthe first instance is that inputted sentences turn into beliefs unless\nwe do something about it. Gilbert et al are happy inferring that in this\ncase, the inputs are beliefs until and unless we do that something. This\nseems to be evidence that the concept of belief philosophers and\npsychologists use include states that need to be actively rejected if\nthey are not to acquire all the paradigm features of belief. And that\nincludes the inputs from Fodorian modules.\n\nThat argument is fairly speculative, but we can make more of the fact\nthat subjects can not stop everything coming through. This implies that\nthere will be some long disjunctions of perceptual inputs that they will\nend up believing no matter how hard they try. Any given input can be\nrejected, but subjects only have so much capacity to block the flow of\nperceptual inputs. So some long disjunctions will turn up in their\nbeliefs no matter how hard they try to keep them out. I think these are\ninvoluntary beliefs.\n\nSo I conclude tentatively that perceptual inputs are involuntary\nbeliefs, at least for the time it would take the central processes to\nevaluate them were it disposed to do so. And I conclude less tentatively\nthat subjects involuntarily believe long disjunctions of perceptual\ninputs. So some beliefs are involuntary.\n\nSpace considerations prevent a full investigation of this, but there is\nan interesting connection here to some late medieval ideas about\nevidence. In a discussion of how Descartes differed from his medieval\ninfluences, Matthew L. Jones writes \"For Descartes, the realignment of\none's life came about by training oneself to assent only to the evident;\nfor the scholastics, assenting to the evident required no exercise, as\nit was automatic.\" [@Jones2006 84][^13] There is much contemporary\ninterest in the analysis of evidence, with Timothy Williamson's proposal\nthat our evidence is all of our knowledge being a central focus\n[@Williamson2000-WILKAI Ch. 9]. I think there's much to be said for\nusing Fodor's work on automatic input systems to revive the medieval\nidea that the evident is that which we believe automatically, or perhaps\nit is those pieces of knowledge that we came to believe automatically.\nAs I said though, space prevents a full investigation of these\ninteresting issues.\n\n### Epistemological Consequences\n\nSo some of our beliefs, loosely speaking the perceptual beliefs, are\nspontaneous and involuntary, while other beliefs, the inferential\nbeliefs, are voluntary in that we have the capacity to check them by\npaying greater heed to counter-possibilities. (In what follows it will\nnot matter much whether we take the spontaneous beliefs to include all\nthe perceptual inputs, or just the long disjunctions of perceptual\ninputs that are beyond our capacity to reject. I will note the few\npoints where it matters significantly.) This has some epistemological\nconsequences, for the appropriate standards for spontaneous, involuntary\nbeliefs are different to the appropriate standards for considered,\nreflective beliefs. I include in the latter category beliefs that were\nformed when considered reflection was possible, but was not undertaken.\n\nTo think about the standards for spontaneous beliefs, start by\nconsidering the criteria we could use to say that one kind of animal has\na better visual system than another. One dimension along which we could\ncompare the two animals concerns discriminatory capacity -- can one\nanimal distinguish between two things that the other cannot distinguish?\nBut we would also distinguish between two animals with equally\nfine-grained visual representations, and the way we would distinguish is\nin terms of the accuracy of those representations. Some broadly\nexternalist, indeed broadly reliabilist, approach has to be right when\nit comes to evaluating the visual systems of different animals.\n\nThings are a little more complicated when it comes to evaluating\nindividual visual beliefs of different animals, but it is still clear\nthat we will use externalist considerations. So imagine we are looking\nfor standards for evaluating particular visual beliefs of again fairly\nbasic animals. One very crude externalist standard we might use is that\na belief is good iff it is true. Alternatively, we might say that the\nbelief is good iff the process that produces it satisfied some\nexternalist standard, e.g. it is generally reliable. Or we might, in a\nway, combine these and say that the belief is good iff it amounts to\nknowledge, incorporating both the truth and reliability standards. It is\nnot clear which of these is best. Nor is it even clear which, if any,\nanimals without sophisticated cognitive systems can be properly said to\nhave perceptual beliefs. (I will not pretend to be able to evaluate the\nconceptual and empirical considerations that have been brought to bear\non this question.) But what is implausible is to say that these animals\nhave beliefs, and the relevant epistemic standards for evaluating these\nbeliefs are broadly internal.\n\nThis matters to debates about the justificatory standards for our\nbeliefs because we too have perceptual beliefs. And the way we form\nperceptual beliefs is not that different from the way simple animals do.\n(If the representations of input processes are beliefs, then it does not\ndiffer in any significant way.) When we form beliefs in ways that\nresemble those simple believers, most notably when we form perceptual\nbeliefs, we too are best evaluated using externalist standards. The\nquality of our visual beliefs, that is, seems to directly track the\nquality of our visual systems. And the quality of our visual system is\nsensitive to external matters. So the quality of our visual beliefs is\nsensitive to external matters.\n\nOn the other hand, when we reason, we are doing something quite\ndifferent to what a simple animal can do. A belief that is the product\nof considered reflection should be assessed, inter alia, by assessing\nthe standards of the reflection that produced it. To a first\napproximation, such a belief seems to be justified if it is well\nsupported by reasons. Some reasoners will be in reasonable worlds, and\ntheir beliefs will be mostly true. Some reasoners will be in deceptive\nworlds, and many of their beliefs will be false. But this does not seem\nto change what we say about the quality of their reasoning. This, I take\nit, is the core intuition behind the New Evil Demon problem, that we'll\naddress much more below.\n\nSo we're naturally led to a view where epistemic justification has a\nbifurcated structure. A belief that is the product of perception is\njustified iff the perception is reliable; a belief that is (or could\nhave been) the product of reflection is justified iff it is\nwell-supported by reasons.[^14] This position will remind many of Ernest\nSosa's view that there is animal knowledge, and higher knowledge, or\n*scientia* [@Sosa1991; @Sosa1997]. And the position is intentionally\nsimilar to Sosa's. But there is one crucial difference. On my view,\nthere is just one kind of knowledge, and the two types of justification\nkick in depending on the kind of knower, or the kind of knowing, that is\nin question. If we simply form perceptual beliefs, without the\npossibility of reconsidering them (in a timely manner), then if all goes\nwell, our beliefs are knowledge. Not some lesser grade of animal\nknowledge, but simply knowledge. To put it more bluntly, if you're an\nanimal, knowledge just is animal knowledge. On the other hand, someone\nwho has the capacity (and time) to reflect on their perceptions, and\nfails to do so even though they had good evidence that their perceptions\nwere unreliable, does not have knowledge. Their indolence defeats their\nknowledge. Put more prosaically, the more you are capable of doing, the\nmore that is expected of you.\n\n### The New Evil Demon Problem\n\nThe primary virtue of the above account, apart from its intuitive\nplausibility, is that it offers a satisfactory response to the New Evil\nDemon argument. The response in question is not new; it follows fairly\nclosely the recent response due to Clayton @Littlejohn2009, who in turn\nbuilds on responses due to Kent @Bach1985 and Mylan @Engel1992. But I\nthink it is an attractive feature of the view defended in this paper\nthat it coheres so nicely with a familiar and attractive response to the\nargument.\n\nThe New Evil Demon argument concerns victims of deception who satisfy\nall the internal standards we can imagine for being a good epistemic\nagent. So they are always careful to avoid making fallacious inferences,\nthey respect the canons of good inductive and statistical practice, they\ndo not engage in wishful thinking, and so on. The core intuition of the\nNew Evil Demon argument is that although these victims do not have\nknowledge (because their beliefs are false), they do have justified\nbeliefs. Since the beliefs do not satisfy any plausible externalist\ncriteria of justification, we conclude that no externalist criteria can\nbe correct. The argument is set out by Stewart @Cohen1984.\n\nA fairly common response is to note that even according to externalist\nepistemology there will be some favourable epistemic property that the\nvictim's beliefs have, and this can explain our intuition that there is\nsomething epistemically praiseworthy about the victim's beliefs. My\napproach is a version of this, one that is invulnerable to recent\ncriticisms of the move. For both this response and the criticism to it,\nsee James @Pryor2001-PRYHOR. I am going to call my approach the agency\napproach, because the core idea is that the victim of the demon is in\nsome sense a good doxastic agent, in that all their exercises of\ndoxastic agency are appropriate, although their perception is quite poor\nand this undermines their beliefs.\n\nAs was noted above, the quality of our visual beliefs is sensitive to\nexternal matters. This is true even for the clear-thinking victim of\nmassive deception. Denying that the victim's visual beliefs are as good\nas ours is not at all implausible; indeed intuition strongly supports\nthe idea that they are not as good. What they are as good at as we are\nis exercising their epistemic agency. That is to say, they are excellent\nepistemic agents. But since there is more to being a good believer than\nbeing a good epistemic agent, there is also for example the matter of\nbeing a good perceiver, they are not as good at believing as we are.\n\nSo the short version of my response to the New Evil Demon problem is\nthis. There are two things we assess when evaluating someone's beliefs.\nWe evaluate how good an epistemic agent they are. And we evaluate how\ngood they are at getting evidence from the world. Even shorter, we\nevaluate both their collection and processing of evidence. Externalist\nstandards for evidence collection are very plausible, as is made clear\nwhen we consider creatures that do little more than collect evidence.\nThe intuitions that the New Evil Demon argument draws on come from\nconsidering how we process evidence. When we consider beliefs that are\nthe products of agency, such as beliefs that can only be arrived at by\nextensive reflection, we naturally consider the quality of the agency\nthat led to those beliefs. In that respect a victim might do as well as\nwe do, or even better. But that is no threat to the externalist\nconclusion that they are not, all things considered, as good at\nbelieving as we are.\n\nAs I mentioned earlier, this is similar to a familiar response to the\nargument that James Pryor considers and rejects. He considers someone\nwho says that what is in common to us and the clear-thinking victim is\nthat we are both epistemically blameless. The objection he considers\nsays that the intuitions behind the argument come from confusing this\nnotion of being blameless with the more general notion of being\njustified. This is similar to my idea that the victim might be a good\nepistemic agent while still arriving at unjustified beliefs because they\nare so bad at evidence collection. But Pryor argues that this kind of\ndeontological approach cannot capture all of the intuitions around the\nproblem.\n\nPryor considers three victims of massive deception. Victim A uses all\nsorts of faulty reasoning practices to form beliefs, practices that A\ncould, if they were more careful, could see were faulty. Victim B was\nbadly 'brought up', so although they use methods that are subtly\nfallacious, there is no way we could expect B to notice these mistakes.\nVictim C is our paradigm of good reasoning, though of course C still has\nmostly false beliefs because all of their apparent perceptions are\nmisleading. Pryor says that both B and C are epistemically blameless; C\nbecause they are a perfect reasoner and B because they cannot be blamed\nfor their epistemic flaws. But we intuit that C is better, in some\nepistemic respects, than B. So there is some internalist friendly kind\nof evaluation that is stronger than being blameless. Pryor suggests that\nit might be *being justified*, which he takes to be an internalist but\nnon-deontological concept.\n\nThe agency approach has several resources that might be brought to bear\non this case. For one thing, even sticking to deontological concepts we\ncan make some distinctions between B and C. We can, in particular, say\nthat C is epistemically praiseworthy in ways that B is not. Even if B\ncannot be blamed for their flaws, C can be praised for not exemplifying\nthose flaws. It is consistent with the agency approach to say that C can\nbe praised for many of their epistemic practices while saying that,\nsadly, most of C's beliefs are unjustified because they are based on\nfaulty evidence, or on merely apparent evidence.\n\nThe merits of this kind of approach can be brought out by considering\nhow we judge agents who are misled about the nature of the good. Many\nphilosophers think that it is far from obvious which character traits\nare virtues and which are vices. Any particular example is bound to be\ncontroversial, but I think it should be uncontroversial that there are\nsome such examples. So I will assume that, as Simon @Keller2005\nsuggests, it is true but unobvious that patriotism is not a virtue but a\nvice.\n\nNow consider three agents D, E and F. D takes patriotism to extremes,\ndeveloping a quite hostile strand of nationalism, which leads to\nunprovoked attacks on non-compatriots. E is brought up to be patriotic,\nand lives this way without acting with any particular hostility to\nforeigners. F is brought up the same way, but comes to realise that\npatriotism is not at all virtuous, and comes to live according to purely\ncosmopolitan norms. Now it is natural to say that D is blameworthy in a\nway that E and F are not. As long as it seems implausible to blame E for\nnot working through the careful philosophical arguments that tell\nagainst following patriotic norms, we should not blame E for being\nsomewhat patriotic. But it is also natural to say that F is a better\nagent than either D or E. That is because F exemplifies a virtue,\ncosmopolitanism, that D and E do not, and does not exemplify a vice,\npatriotism, that D and E do exemplify. F is in this way praiseworthy,\nwhile D and E are not.\n\nThis rather strongly suggests that when agents are misled about norms, a\ngap will open up between blamelessness and praiseworthiness. We can say\nthat Pryor's victim C is a better epistemic agent than A or B, because\nthey are praiseworthy in a way that A and B are not. And we can say this\neven though we do not say that B is blameworthy and we do not say that\nbeing a good epistemic agent is all there is to being a good believer.\n\nAt this point the internalist might respond with a new form of the\nargument. A victim of deception is, they might intuit, just as\npraiseworthy as a regular person, if they perform the same inferential\nmoves. I think at this point the externalist can simply deny the\nintuitions. In general, praiseworthiness is subject to a degree of luck.\n(Arguably blameworthiness is as well, but saying so sounds somewhat more\ncounterintuitive than saying praiseworthiness is a matter of luck.) For\nexample, imagine two people dive into ponds in which they believe there\nare drowning children. The first saves two children. The second was\nmistaken; there are no children to be rescued in the pond they dive\ninto. Both are praiseworthy for their efforts, but they are not equally\npraiseworthy. The first, in particular, is praiseworthy for rescuing two\nchildren. As we saw in the examples of the writer and the good cricket\ncaptain above, praiseworthiness depends on outputs as well as inputs,\nand if the victim of deception produces beliefs that are defective, i.e.\nfalse, then through no fault of their own they are less praiseworthy.\n\n### Praise and Blame\n\nAs Pryor notes, many philosophers have thought that a deontological\nconception of justification supports an internalist theory of\njustification. I rather think that is mistaken, and that at least one\ncommon deontological understanding of what justification is entails a\nvery strong kind of externalism. This is probably a reason to not adopt\nthat deontological understanding.\n\nAssume, for reductio, that S's belief that *p* is justified iff S is\nblameless in believing that *p*. I will call this principle J=B to note\nthe close connection it posits between justification and blamelessness.\n@Alston1988 seems to identify the deontological conception of\njustification with J=B, or at least to slide between the two when\noffering critiques. But one of Alston's own examples, the 'culturally\nisolated tribesman', suggests a principle that can be used to pull these\ntwo ideas apart. The example, along with Pryor's three brains case,\nsuggests that A1 is true.\n\nA1\n\n:   It is possible for S to have a justified but false belief that her\n    belief in *p* is justified.\n\nA1 is a special instance of the principle that justification does not\nentail truth. Some externalists about justification will want to reject\nthe general principle, but all internalists (and indeed most\nexternalists) will accept it. Now some may think that the general\nprinciple is right, but that beliefs about what we are justified in\nbelieving are special, and if they are justified they are true. But such\nan exception seems intolerably ad hoc. If we can have false but\njustified beliefs about some things, then presumably we can have false\nbut justified beliefs about our evidence, since in principle our\nevidence could be practically anything. So the following situation seems\npossible; indeed it seems likely that something of this form happens\nfrequently in real life. S has a false but justified belief that *e* is\npart of her evidence. S knows both that anyone with evidence *e* is\njustified in believing *p* in the absence of defeaters, and that there\nare no defeaters present. So S comes to believe, quite reasonably, that\nshe is justified in believing that *p*. But S does not have this\nevidence, and in fact all of her evidence points towards \\~*p*.[^15] So\nit is false that she is justified in believing *p*.\n\nThe following principle seems to be a reasonable principle concerning\nblameless inference.\n\nA2\n\n:   If S blamelessly believes that she is justified in believing that\n    *p*, and on the basis of that belief comes to believe that *p*, then\n    she is blameless in believing that *p*.\n\nThis is just a principle of transfer of blameworthiness. The quite\nnatural thought is that you do not become blameworthy by inferring from\n*I am justified in believing p* to *p*. This inference is clearly not\nnecessarily truth-preserving, but that is not a constraint on inferences\nthat transfer blameworthiness, since not all ampliative inferences are\nblameworthy. (Indeed, many are praiseworthy.) And it is hard to imagine\na less blameworthy ampliative inference schema than this one.\n\nWe can see this more clearly with an example of A2. Suzy sees a lot of\n*Fs* and observes they are all *Gs*. She infers that it is justified for\nher to conclude that all *Fs* are *Gs*. Now it turns out this is a bad\ninference. In fact, *G* is a gruesome predicate in her world, so that is\nnot a justified inference. But Suzy, like many people, does not have the\nconcept of gruesomeness, and without it had no reason to suspect that\nthis would be a bad inference. So she is blameless. If all that is\ncorrect, it is hard to imagine that she becomes blameworthy by actually\ninferring from what she has so far that all *Fs* are in fact *Gs*.\nPerhaps you might think her original inference, that it is justified to\nbelieve all *Fs* are *Gs*, was blameworthy, but blame can not kick in\nfor the first time when she moves to the first order belief.\n\nI am now going to derive a contradiction from A1, A2 and J=B, and a\nclearly consistent set of assumptions about a possible case of belief.\n\n1.  S justifiedly, but falsely, believes that she is justified in\n    believing *p*. (Assumption - A1)\n\n2.  On the basis of this belief, S comes to believe that *p*.\n    (Assumption)\n\n3.  S blamelessly believes that she is justified in believing that *p*.\n    (1, J=B)\n\n4.  S blamelessly believes that *p*. (2, 3, A2)\n\n5.  S is justified in believing that *p*. (4, J=B)\n\n6.  It is false that S is justified in believing that *p*. (1)\n\nOne of A1, A2 and J=B has to go. If you accept J=B, I think it has got\nto be A1, since A2 is extremely plausible. But A1 only fails if we\naccept quite a strong externalist principle of justification, namely\nthat justification entails truth. More precisely, we're led to the view\nthat justification entails truth when it comes to propositions about our\nown justification. But as we saw above, that pretty directly implies\nthat justification entails truth when it comes to propositions about our\nown evidence. And, on the plausible assumption that evidence can be\npractically anything, that leads to there being a very wide range of\ncases where justification entails truth. So J=B entails this strong form\nof externalism.\n\nThis does not mean that internalists cannot accept a deontological\nconception of justification. But the kind of deontological conception of\njustification that is left standing by this argument is quite different\nto J=B, and I think to existing deontological conceptions of\njustification. Here's what it would look like. First, we say that a\nbelief's being justified is not a matter of it being blameless, but a\nmatter of it being in a certain way praiseworthy. Second, we say that\nthe inference from *I am justified in believing that p* to *p* is not\npraiseworthy if the premise is false. So if we tried to run the above\nargument against J=P (the premise that justified beliefs are\npraiseworthy) it would fail at step 4. So anyone who wants to hold that\njustification is (even in large part) deontological, and wants to accept\nthat justification can come apart from truth, should hold that\njustification is a kind of praiseworthiness, not a kind of\nblamelessness.\n\n[^1]: The cases, especially the second, were inspired by Richard\n    Holton's discussion of resolutions to prevent 'automatic' actions\n    like smoking or sleeping in. See @Holton2003 [@Holton2004].\n\n[^2]: Whether Murray is akratic is a slightly more complicated question\n    than I have suggested in the text. If akrasia is acting against\n    one's judgment, then he is not; if akrasia is acting against one's\n    *considered* judgment, then he is. 'Akrasia' is a technical term, so\n    I do not think a huge amount turns on what we say about this\n    question.\n\n    There is an interesting historical precedent for Holton's theory of\n    weakness of will. Ryle hints at a similar position to Holton's when\n    he says \"Strength of will is a propensity the exercise of which\n    consist in sticking to tasks' that is, in not being deterred or\n    diverted. Weakness of will is having too little of this propensity.\"\n    [-@Ryle1949 73] But the idea is not well developed in Ryle. We'll\n    return below to the differences between Ryle's and Holton's\n    theories.\n\n[^3]: @Holton2003 compares self-control to a muscle that we can\n    exercise. We can make a similar point to the one in the text about\n    physical muscles. If I try to lift a box of books and fail, that\n    does not show I lack the muscular capacity to lift the box; I might\n    not have been trying hard enough.\n\n[^4]: [@Ryle1949 71ff] also offers a counterfactual account of\n    capacities that seems largely accurate.\n\n[^5]: As I read him, Ryle takes this fact to reveal an important\n    weakness in Descartes' theory of mind.\n\n[^6]: [@Ryle1949 29ff] stresses the importance of calling the right\n    things to mind to rational thought and action. I am using a case\n    here where Mark deliberately casts an option from his mind, but the\n    more general point is that what possibilities we call to mind is a\n    crucial part of rational action, and can be praiseworthy or\n    blameworthy, whether or not it is volitional.\n\n[^7]: Ryle seems to have taken an intermediate position. He holds, I\n    think, the view that voluntary acts are culpable acts where we had\n    the capacity to do otherwise (71). So Mark's belief about the orange\n    juice is voluntary because he had the capacity to retain doubt, and\n    nothing prevented him exercising it. But the belief about the\n    football is not voluntary because we should not talk about\n    praiseworthy acts being voluntary or involuntary. The last point is\n    the kind of error that [@Grice1989 Ch.1] showed us how to avoid.\n\n[^8]: If so, Murray is not weak-willed according to Holton's theory of\n    will, but, since he does not keep his resolution, he is weak-willed\n    according to Ryle's otherwise similar theory. This seems to be an\n    advantage of Holton's theory over Ryle's. Murray's problem is not\n    that his will was weak, it is that it was not called on. More\n    generally, Ryle's identification of weakness of will with\n    irresoluteness seems to fail for people who frequently *forget*\n    their resolutions. These people are surely irresolute, but (in\n    agreement with Holton's theory) I think they are not weak-willed.\n\n[^9]: The evidence for this view is set out in @GilbertKrullMalone1990\n    [@GilbertTafarodiMalone1993].\n\n[^10]: As he says, they have a mandatory operation. See pages 52-55 in\n    particular, but the theme is central to the book.\n\n[^11]: To be clear, the position being considered here is not that we\n    automatically believe *p* when someone says *p* to us, but that we\n    automatically believe that they said that *p*.\n\n[^12]: As noted in the last footnote, when I talk here about what we\n    hear, I mean to include propositions of the form *S said that p*,\n    not necessarily the *p* that *S* says.\n\n[^13]: Jones attributes this view to Scotus and Ockham, and quotes Pedro\n    Fonseca as saying almost explicitly this in his commentary on\n    Aristotle's *Metaphysics*.\n\n[^14]: There is a delicate matter here about individuating beliefs. If I\n    look up, see, and hence believe it is raining outside, that is a\n    perceptual belief. I could have recalled that it was raining hard a\n    couple of minutes ago, and around here that kind of rain does not\n    stop quickly, and formed an inferential belief that it was raining\n    outside. I want to say that that would have been a different belief,\n    although it has the same content. If I do not say that, it is hard\n    to defend the position suggested here when it comes to the\n    justificatory status of perceptual beliefs whose contents I could\n    have otherwise inferred.\n\n[^15]: I am assuming here that evidence of evidence need not be\n    evidence. This seems likely to be true. In Bayesian terms, something\n    can raise the probability of *e*, while lowering the probability of\n    *p*, even though the probability of *p* given *e* is greater than\n    the probability of *p*. Bayesian models are not fully general, but\n    usually things that are possible in Bayesian models are possible in\n    real life.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}