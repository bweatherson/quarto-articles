{
  "hash": "59b9017e39df3a69e0f0357356f77003",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Luminous Margins\"\ndescription: |\n  Timothy Williamson has recently argued that few mental states are luminous, meaning that to be in that state is to be in a position to know that you are in the state. His argument rests on the plausible principle that beliefs only count as knowledge if they are safely true. That is, any belief that could easily have been false is not a piece of knowledge. I argue that the form of the safety rule Williamson uses is inappropriate, and the correct safety rule might not conflict with luminosity.\ndate: July 1 2004\nauthor:\n  - name: Brian Weatherson \n    url: http://brian.weatherson.org\n    affiliation: University of Michigan\n    affiliation_url: https://umich.edu\n    orcid_id: 0000-0002-0830-141X\ndoi: \"10.1080/713659874\"\ncategories:\n  - epistemology\n  - notes\ncitation_url: https://doi.org/10.1080/713659874\njournal:\n    title: \"Australasian Journal of Philosophy\"\n    publisher: \"Taylor and Francis\"\nvolume: 82\nnumber: 3\ncitation: false\nbibliography: ../../../articles/Rbib.bib\nself-contained: false\npreview: luminous.jpg\noutput:\n  distill::distill_article:\n    toc: true\n    toc_depth: 3\n    number_sections: true\n---\n\n\n\n### Luminosity\n\nIn *Knowledge and Its Limits* Timothy Williamson argues that few\nconditions are *luminous*. ^[@Williamson2000-WILKAI Ch. 4; all references\nto this book unless otherwise specified.] A condition is luminous iff we\nknow we are in it whenever we are. Slightly more formally, Williamson\ndefines\n\n<aside>\nPublished in \\textit{Australasian Journal of Philosophy} 83: 373-383. \n\nThanks to Tamar Szabó Gendler, John Hawthorne, Chris Hill, Ernest Sosa and the \\textit{AJP}'s referees.\n</aside>\n\n> A condition C is defined to be *luminous* if and only if (L) holds:\n>\n> \\(L\\)\n>\n> :   For every case ${\\alpha}$, if in ${\\alpha}$ C obtains, then in\n>     ${\\alpha}$ one is in a position to know that C obtains (95).\n\nIntuitively, the argument against this is as follows. The following\nthree conditions are incompatible.\n\nGradual Change\n\n:   There is a series of cases, each very similar to adjacent cases,\n    that starts with a case where C clearly obtains, and ends with a\n    case where C clearly doesn't obtain.\n\nLuminosity\n\n:   Whenever C obtains you can know it does.\n\nSafety\n\n:   Only safe beliefs count as knowledge, so whenever you can know that\n    C obtains, C obtains in all very similar cases.\n\nLuminosity and Safety entail\n\nTolerance\n\n:   Whenever C obtains, it obtains in all very similar cases.\n\nBut Tolerance is incompatible with Gradual Change, since Tolerance\nentails that if the first member of the series is a case where C\nobtains, then every successive member is also a case where C obtains.\nWilliamson argues that for any interesting epistemic condition, Gradual\nChange is a clear possibility. And he argues that Safety is a general\nprinciple about knowledge. So Luminosity must be scrapped. The\ncounterexamples to Luminosity we get from following this proof through\nare always borderline cases of C obtaining. In these cases Luminosity\nfails because any belief that C did obtain would be unsafe, and hence\nnot knowledge.\n\nI will argue, following @Sainsbury1996, that Williamson has\nmisinterpreted the requirement that knowledge be safe. The most\nplausible safety condition might be compatible with Gradual Change and\nLuminosity, if we make certain plausible assumptions about the structure\nof phenomenal beliefs.\n\nOne consequence of the failure of Luminosity is that a certain\nhistorically important kind foundationalist analysis of knowledge fails.\nThis kind of foundationalist takes the foundations to be luminous.\nAlthough I think Williamson's argument against Luminosity does not work,\nmy objections are no help to the foundationalist. As I said, my\nobjection to Williamson rests on certain assumptions about the structure\nof phenomenal beliefs. It is a wide open empirical and philosophical\nquestion whether these assumptions are true. If this kind of\nfoundationalism provided a plausible *analysis* of knowledge, then it\nwould be a wide open question whether our purported knowledge rested on\nany foundations, and hence a wide open question whether we really had\nany knowledge. But this is a closed question. It is a Moorean fact that\nwe know many things. So while I object to Williamson's claim that we\nhave no luminous mental states, I do not object to the weaker claim that\nwe *might* not have any luminous mental states, and this claim is enough\nto do much of the philosophical work to which Williamson puts\nLuminosity.\n\n### Williamson's Example\n\nWilliamson suggests that (L), the formal rendition of Luminosity, fails\nfor all interesting conditions even if we restrict the quantifier to\nthose that are 'physically and psychologically feasible' [94], and I\nwill assume that is what we are quantifying over. To argue that (L)\nfails for any interesting C, Williamson first argues that it fails in a\nspecial case, when C is the condition *feeling cold*, and then argues\nthat the conditions that lead to failure here are met for any other\ninteresting C. So I will also focus on the special case.\n\nMr Davis's apartment faces southwest, so while it is often cold in the\nmornings it always warms up as the midday and afternoon sun streams in.\nThis morning Mr Davis felt cold when he awoke, but now at noon he is\nquite warm, almost hot. But the change from wake-up time to the present\nis rather gradual. Mr Davis does not take a hot bath that morning, nor\ncook a hot breakfast, but sits reading by the window until the sun does\nits daily magic. Assume, for the sake of the argument, that *feeling\ncold* is luminous, so whenever Mr Davis feels cold, he knows he feels\ncold. Williamson argues this leads to a contradiction as follows. (I've\nchanged names and pronouns to conform with my example.)\n\n> Let *t*~0~, *t*~1~, ..., *t~n~* be a series of times at one\n> millisecond intervals from dawn to noon. Let ${\\alpha}$*~i~* be the\n> case at *t~i~* (0 ${\\leq}$ *i* ${\\leq}$ *n*). Consider a time *t~i~*\n> between *t*~0~ and *t~n~*, and suppose that at *t~n~* Mr Davis knows\n> that he feels cold. ... Now at *t~i~*~+1~ he is almost equally\n> confident that he feels cold, by the description of the case. So if he\n> does not feel cold at *t~i~*~+1~, then his confidence at *t~i~* that\n> he feels cold is not reliably based, for his almost equal confidence\n> on a similar basis one millisecond earlier that he felt cold was\n> misplaced ... His confidence at *t~i~* was reliably based in the way\n> required for knowledge only if he feels cold at *t~i~*~+1~. In the\n> terminology of cases...:\n>\n> ([i]{.smallcaps}*~i~*) If in ${\\alpha}$*~i~* he knows that he feels\n> cold, then in ${\\alpha}$*~i~*~+1~ he feels cold. (97)\n\nGiven (L), all instances of ([i]{.smallcaps}*~i~*), and the fact that Mr\nDavis feels cold when he awakes, we get the false conclusion that he now\nfeels cold. So if we accept all instances of ([i]{.smallcaps}*~i~*), we\nmust conclude that (L) is false when C is *feeling cold* and 'one'\ndenotes Mr Davis. Why, then, accept ([i]{.smallcaps}*~i~*)? One move\nWilliamson makes here is purely defensive. He notes that\n([i]{.smallcaps}*~i~*) is different from the conditionals that lead to\nparadox in the Sorites argument. The antecedent of\n([i]{.smallcaps}*~i~*) contains the modal operator *knows that* absent\nfrom its consequent, so we cannot chain together instances of\n([i]{.smallcaps}*~i~*) to produce an implausible conditional claim. If\nthat operator were absent then from all the instances of\n([i]{.smallcaps}*~i~*) it would follow that if Mr Davis feels cold at\ndawn he feels cold at noon, which is false. But by strengthening the\nantecedent, Williamson weakens ([i]{.smallcaps}*~i~*) to avoid that\nconclusion. But the fact that ([i]{.smallcaps}*~i~*) is not paradoxical\nis not sufficient reason to accept it.\n\n### Reliability\n\nIt is useful to separate out two distinct strands in Williamson's\nargument for ([i]{.smallcaps}*~i~*). One strand sees Williamson arguing\nfor ([i]{.smallcaps}*~i~*) by resting on the principle that beliefs\nconstitute knowledge only if they are reliably based. The idea is that\nif Mr Davis's belief that he feels cold is a bit of knowledge, it is\nreliable, and if it is reliable it is true in all similar situations,\nand hence it is true in ${\\alpha}$*~i~*~+1~. The other strand sees him\nappealing to a vague but undoubtedly real requirement that beliefs must\nbe *safely* true in order to be knowledge. Neither argument is\nsuccessful, though the second kind of argument is better than the first.\n\nWilliamson acknowledges Conee and Feldman's arguments that no\nreliabilist epistemologist has yet solved the generality problem (100).\nBut he takes this to be reason to abandon not the concept of\nreliability, but the hope of providing a reductive analysis of it.\nWilliamson thinks we can get a long way by just resting on the intuitive\nconcept of reliability. This seems to be a mistake. There are two\nordinary ways of using 'reliable' in the context of discussing beliefs,\nand neither provides support for ([i]{.smallcaps}*~i~*).\n\nFirst, and this is clearly not what is needed, sometimes 'reliable' just\nmeans true. This is the sense of the word in which we can consistently\nsay, \"It turned out the information that old Ronnie provided us about\nwhere the gov'nor was eating tonight was reliable, which was plenty\nsurprising since Ronnie hadn't been right about anything since the Nixon\nadministration.\" This is the sense in which reliable means just what the\netymology suggests it means, something that can be relied upon. And that\nmeans, in practice, *true*. But that won't help at all, for if\n'reliable' just means true, then nothing follows from the fact that\nknowledge is reliable that does not follow from the fact that it is\nfactive.\n\nSecond, there is a distinctively philosophical sense in which reliable\nmeans something more like true in a wide range of circumstances. This is\nthe sense in which a stopped clock is not even reliable twice a day. At\nfirst, this might look to help Williamson a little more. But if\nphilosophical usage is to be key, the second look is more discouraging.\nFor in its philosophical usage, reliability does not even entail truth.\nAnd if reliability does not entail truth in the actual situation, it\nsurely does not entail truth in nearby situations. But Williamson's\nargument for ([i]{.smallcaps}*~i~*) requires that reliability in\n${\\alpha}$*~i~* entails truth in ${\\alpha}$*~i~*~+1~. So on neither of\nits natural readings does the concept of reliability seal the argument\nhere, and since we have no unnatural reading to fall back upon, the\nargument from reliability for ([i]{.smallcaps}*~i~*) fails. To be fair,\nby chapter 5 of Williamson's book the concept of reliability that seems\nto be employed is little distinguishable from the concept of safety. So\nlet us turn to those arguments.\n\n### Safety\n\nWilliamson at times suggests that the core argument for\n([i]{.smallcaps}*~i~*) is a straight appeal to intuition. \"[E]ven when\nwe can appeal to rigorous rules, they only postpone the moment at which\nwe must apply concepts in particular cases on the basis of good\njudgement. ... The argument for ([i]{.smallcaps}*~i~*) appeals to such\njudgement.\" (101) The appeal to intuition is the royal road to\nscepticism, so we would be justified in being a little wary of it.\n@Weinberg2001 discovered that undergraduates from the same social class\nas Williamson, Mr Davis and I would frequently judge that a subject\ncould not know that mule was a mule unless he could tell it apart from a\ncleverly painted zebra. The judgements of that class are not obviously\nthe basis for a sane epistemology.\n\nWilliamson undersells his argument by making it an appeal to judgement.\nFor there is a principle here, if not a rigorous rule, that grounds the\njudgement. The principle is something like Ernest Sosa's safety\nprinciple. The idea is that a belief does not constitute knowledge if it\nis false in similar situations. \"[N]ot easily would S believe that *p*\nwithout it being the case that *p*.\" [@Sosa1999 142] There is much to be\nsaid here about what is a *similar* situation. (David @Lewis1996b\ndiscusses a concept of similarity in the context of saying that worlds\ncan be *salient*, in his sense, in virtue of being similar to salient\nworlds.) It might turn out that there is no account of similarity that\nmakes it plausible that this is a constraint on knowledge. But for\npresent purposes I am prepared to grant (a) that only safe beliefs count\nas knowledge, and (b) that ${\\alpha}$*~i~*~+1~ is a similar situation to\n${\\alpha}$*~i~*.\n\nThis might seem like too much of a concession to Williamson, for it\nalready conflicts with some platitudes about knowledge. Consider a case\nthat satisfies the following three conditions. Some light reflects off a\nleopard some distance away and strikes our eyes. The impact of that\nlight causes, by the normal processes, a belief that a leopard is nearby\nto appear in our belief box. Beliefs, including leopard-related beliefs,\nthat we form by this kind of process are on the whole very reliable. You\nmight think these conditions are sufficient for our belief to count as\n*knowledge* that a tiger is present. The proponent of Safety denies\nthis. She says that if, for example, there are several cheetahs with a\nparticularly rare mutation that make the look much like leopards around,\nand if we saw them at similar distance we would have mistaken them for\nleopards. Since we could easily have had the belief that a leopard is\nnearby while there were no leopards, only cheetahs, nearby, the belief\nis not safe and so does not count as knowledge.\n\nThere are two reasons to think that safety is too strong here, neither\nof which strike me as completely compelling. (I'm still conceding things\nto Williamson here. If there's a general objection to Safety then his\nargument against Luminosity does not get off the ground. That's not my\nposition. As I'll soon argue, I think Williamson has misinterpreted\nSafety.) The first reason is a worry that if we deny knowledge in a case\nof reliable veridical perception, we are conceding too much to the\nsceptic. But the proponent of Safety has a very good reason to\ndistinguish this case from my current veridical perception of a table -\nmy perception is safe and the perception of a leopard is not. So there\nis no slippery slope to scepticism here. The second is that the\nallegedly similar case is not really that similar, because in that case\nthe belief is caused by a *cheetah*, not a *leopard*. But to regard\ncases where the evidence is different in this way as being dissimilar is\nto make the safety condition impotent, and Sosa has shown that we need\n*some* version of Safety to account for our intuitions about different\ncases.[^1]\n\nSo I think some version of Safety should be adopted. I don't think this\ngives us ([i]{.smallcaps}*~i~*), for reasons related to some concerns\nfirst raised by Mark @Sainsbury1996. The role for Safety condition in a\ntheory of knowledge is to rule out knowledge by lucky guesses. This\nincludes lucky guesses in mathematics. If Mr Davis guesses that 193 plus\n245 is 438, he does not thereby know what 193 plus 245 is. Can Safety\nshow why this is so? Yes, but only if we phrase it in a certain way.\nAssume that we have a certain belief *B* with content *p*. (As it might\nbe, Mr Davis's belief with content 193 + 245 = 438.) Then the following\ntwo conditions both have claims to being the correct analysis of 'safe'\nas it appears in Safety.\n\nContent-safety\n\n:   *B* is safe iff *p* is true in all similar worlds.\n\nBelief-safety\n\n:   *B* is safe iff *B* is true in all similar worlds.\n\nIf we rest with content-safety, then we cannot explain why Mr Davis's\nlucky guess does not count as knowledge. For in all nearby worlds, the\ncontent of the belief he actually has is true. If we use belief-safety\nas our condition though, I think we can show why Mr Davis has not just\ngot some mathematical knowledge. The story requires following Marian\nDavid's good advice for token physicalists and rejecting content\nessentialism about belief (@David2002; see also @Gibbons1993. The part\nof Mr Davis's brain that currently instantiates a belief that 193 plus\n245 is 438 could easily have instantiated a belief that 193 plus 245 is\n338, for Mr Davis is not very good at carrying hundreds while guessing.\nIf, as good physicalists, we identify his belief with the part of the\nbrain that instantiates it, we get the conclusion that this very belief\ncould have had the *false* content that 193 plus 245 is 338. So the\nbelief is not safe, and hence it is not knowledge.\n\nThis lends some credence to the idea that it's belief-safety, not\ncontent-safety, that's the important safety criteria. When talking about\nMr Davis's mathematical hunches, belief-safety is a stronger condition\nthan content-safety. But when talking about his feelings, things may be\nreversed.\n\nLet me tell you a little story about how Mr Davis's mind is\ninstantiated. Mr Davis's phenomenal beliefs do not arise from one part\nof his brain, his belief box or mind's eye, tracking another part, the\npart whose states constitute his feeling cold. Rather, when he is in\nsome phenomenal state, the very same brain states constitute both the\nphenomena and a belief about the phenomena. Mr Davis's brain is so wired\nthat he could not have any sensation of radiant heat (or lack thereof)\nwithout his *thereby* believing that he is having just that sensation,\nbecause he could not have felt cold without that feeling itself being a\nbelief that he felt cold. In that case, belief-safety will not entail\n([i]{.smallcaps}*~i~*). Imagine that at ${\\alpha}$*~i~* Mr Davis feels\ncold, but at ${\\alpha}$*~i~*~+1~ he does not. (I assume here, with\nWilliamson, that there is such an *i*.) At ${\\alpha}$*~i~* he thereby\nbelieves that he feels cold. The content of that belief is a *de se*\nproposition that is false at ${\\alpha}$*~i~*~+1~, so it violates\ncontent-safety. But in ${\\alpha}$*~t~*~+1~ that part of his brain does\nnot constitute his feeling cold (for he does not feel cold), and thereby\ndoes not constitute his believing that he feels cold. By hypothesis, by\nthat time no part of his brain constitutes feeling cold. So the belief\nin ${\\alpha}$*~i~* that he feels cold is not false in\n${\\alpha}$*~i~*~+1~; it either no longer exists, or now has the true\ncontent that Mr Davis does not feel cold. So belief-safety does not\nprevent this belief of Mr Davis's from being knowledge. And indeed, it\nseems rather plausible that it *is* knowledge, for he could not have had\njust *this* belief without it being true. This belief violates\ncontent-safety but not belief-safety, and since we have no reason to\nthink that content-safety rather than belief-safety is the right form of\nthe safety constraint, we have no reason to reject the intuition that\nthis belief, this more or less infallible belief, counts as a bit of\nknowledge.\n\nThis story about Mr Davis's psychology might seem unbelievable, so let\nme clear up some details. Mr Davis has both phenomenal and judgemental\nbeliefs about his phenomenal states. The phenomenal beliefs are present\nwhen and only when the phenomenal states are present. The judgemental\nbeliefs are much more flexible, they are nomically independent of the\nphenomena they describe. The judgemental beliefs are grounded in 'inner\nperceptions' of his phenomenal states. The phenomenal beliefs are not,\nthey just are the phenomenal states. The judgemental beliefs can be\ncomplex, as in a belief that *I feel cold iff it is Monday*, while the\nphenomenal beliefs are always simple. It is logically possible that Mr\nDavis be wired so that he feel cold without believing he feels cold, but\nit is not an accident that *he* is so wired. Most of his conspecifics\nare similarly set up. It is possible that at a particular time Mr Davis\nhas *both* a phenomenal belief and a judgemental belief that he feels\ncold, with the beliefs being instantiated in different parts of his\nbrain. If he has both of these beliefs in ${\\alpha}$*~i~*, then\nWilliamson's argument may well show that the judgemental belief does not\ncount as knowledge, for it could be false in ${\\alpha}$*~i~*~+1~. If he\nhas the judgemental belief that he is not cold in ${\\alpha}$*~i~*, then\nthe phenomenal belief that he is cold may not be knowledge, for it is\nplausible that the existence of a contrary belief defeats a particular\nbelief's claim to knowledge. But that does not mean that he is not *in a\nposition to know* that he is cold in ${\\alpha}$*~i~*.\n\nSome may object that it is conceptually impossible that a brain state\nthat instantiates a phenomenal feel should also instantiate a belief.\nAnd it is true that Mr Davis's phenomenal states do not have some of the\nfeatures that we typically associate with beliefs. These states are\nrelatively unstructured, for example. Anyone who thinks that it is a\nconceptual truth that mental representations are structured like\nlinguistic representations will think that Mr Davis could not have the\nphenomenal beliefs I have ascribed to him. But it is very implausible\nthat this is a *conceptual* truth. The best arguments for the language\nof thought hypothesis rest on empirical facts about believers,\nespecially the facts that mental representation is typically productive\nand systematic. If there are limits to how productive and systematic Mr\nDavis's phenomenal representations are, then it is possible that his\nphenomenal states are beliefs. Certainly those states are correlated\nwith inputs (external states of affairs) and outputs (bodily movements,\nif not actions) to count as beliefs on some functionalist conceptions of\nbelief.\n\nA referee noted that we don't *need* the strong assumption that\nphenomenal states can be beliefs to make the argument here, though it\nprobably is the most illumination example. Either of the following\nstories about Mr Davis's mind could have done. First, Mr Davis's\nphenomenal belief may be of the form \"I feel ${\\phi}$\", where \"I\" and\n\"feel\" are words in Mr Davis's language of thought, and ${\\phi}$ is the\nphenomenal state, functioning as a name for itself. As long as the\nbelief arises whenever Mr Davis is ${\\phi}$, and it has the phenomenal\nstate as a constituent, it can satisfy belief-safety even when\ncontent-safety fails. The second option involves some more contentious\nassumptions. The phenomenal belief may be of the form \"I feel thus\",\nwhere the demonstrative picks out the phenomenal state. As long as it is\nessential to the belief that it includes a demonstrative reference to\nthat phenomenal state, it will satisfy belief-safety. This is more\ncontentious because it might seem plausible that a particular\ndemonstrative belief could have picked out a different state. What won't\nwork, of course, is if the phenomenal belief is \"I feel *F*\", where *F*\nis an attempted description of the phenomenal state. That certainly\nviolates every kind of safety requirement. I think it is plausible that\nphenomenal states could be belief states, but if you do not believe that\nit is worth noting the argument could possibly go through without it, as\nillustrated in this paragraph.\n\nMr Davis is an interesting case because he shows just how strong a\nsafety assumption we need to ground ([i]{.smallcaps}*~i~*). For Mr Davis\nis a counterexample to ([i]{.smallcaps}*~i~*), but his coldness beliefs\nsatisfy many plausible safety-like constraints. For example, his beliefs\nabout whether he feels cold are sensitive to whether he feels cold.\nWilliamson (Ch. 7) shows fairly conclusively that knowledge does not\nentail sensitivity, so one might have thought that in interesting cases\nsensitivity would be too strong for what is needed, not too weak as it\nis here. From this it follows that any safety condition that is strictly\nweaker than sensitivity, such as the condition that the subject could\nnot easily believe *p* and be wrong, is not sufficient to support\n([i]{.smallcaps}*~i~*). Williamson slides over this point by assuming\nthat the subject will be almost as confident that he feels cold at\n${\\alpha}$*~i~*~+1~ as he is at ${\\alpha}$*~i~*. This is no part of the\ndescription of the case, as Mr Davis shows.\n\nMy argument above rests on the denial of content essentialism, which\nmight look like a relatively unsafe premise. So to conclude this\nsection, let's see how far the argument can go without that assumption.\nSainsbury responds to his example, the lucky arithmetic guess, by\nproposing a different version of safety: mechanism-safety.\n\nMechanism-safety\n\n:   *B* is safe iff the mechanism that produced *B* produces true\n    beliefs in all similar worlds.\n\nI didn't want to rest on this too much because I think it's rather hard\nto say exactly what the mechanism is that produces Mr Davis's belief\nthat he feels cold. But if it's just his sensory system, then I think it\nis clear that even at ${\\alpha}$*~i~*, Mr Davis's belief that he feels\ncold satisfies mechanism-safety. The bigger point here is that\ncontent-safety is a very distinctive kind of safety claim, but it's the\nonly kind that justifies ([i]{.smallcaps}*~i~*).\n\n### Retractions\n\nTo close, let me stress how limited my criticisms of Williamson here\nare. Very briefly, the argument is that there can be some\nself-presenting mental states, states that are either token identical\nwith the belief that they exist or are constituents of (the contents of)\nbeliefs that they exist, and these beliefs will satisfy all the safety\nrequirements we should want, even in borderline cases. If some\nconditions are invariably instantiated by self-presenting states, then\nthose conditions will be luminous. And I think it is a live possibility,\nrelative at least to the assumptions Williamson makes, that there are\nsuch self-presenting states. But there aren't very many of them. There\nis a reason I picked *feels cold* as my illustration. It's not laughable\nthat it is self-presenting.\n\nOn the other hand, it is quite implausible that, say, *knowing where to\nbuy the best Guinness* is self-presenting. And for states that are not\nself-presenting, I think Williamson's anti-luminosity argument works.\nThat's because it is very plausible (a) that for a belief to be\nknowledge it must satisfy either belief-safety or mechanism-safety, (b)\na non-self-presenting state satisfies belief-safety or mechanism-safety\nonly if it satisfies content-safety, and (c) as Williamson showed, if\nbeliefs about a state must satisfy content-safety to count as knowledge,\nthen that state is not luminous. So epistemic states, like the state of\nknowing where to buy the best Guinness, are not luminous. That is to\nsay, one can know where to buy the best Guinness without knowing that\none knows this. And saying that (for these reasons) is to just endorse\nWilliamson's arguments against the KK principle. Those arguments are an\nimportant special case of the argument against luminosity, and I don't\nsee how any of my criticisms of the general argument touch the special\ncase.\n\nWilliamson describes his attacks on luminosity as an argument for\ncognitive homelessness. If a state was luminous, that state would be a\ncognitive home. Williamson thinks we are homeless. I think we *may* have\na small home in our phenomenal states. This home is not a mansion,\nperhaps just a small apartment with some afternoon sun, but it may be a\nhome.\n\nDon't be fooled into thinking this supports any kind of foundationalism\nabout knowledge, however. It is true that *if* we have the kind of\nself-presenting states that Mr Davis has (under one of the three\ndescriptions I've offered), then we have the self-justifying beliefs\nthat foundationalism needs to get started. But it is at best a wide-open\nphilosophical and scientific question whether we have any such states,\nwhile it is not a wide-open question whether we have any knowledge, or\nany justified beliefs. If these states are the only things that could\nserve as foundations, it would be at least conceptually possible that we\ncould have knowledge without self-justifying foundations. So the kind of\npossibility exemplified by Mr Davis cannot, on its own, prop up\nfoundationalism.\n\n[^1]: I assume here a relatively conservative epistemological\n    methodology, one that says we should place a high priority on having\n    our theories agree with our intuitive judgments. I'm in favour of a\n    more radical methodology that makes theoretical virtues as important\n    as agreement with particular intuitions @Weatherson2003-WEAWGA. On\n    the radical view Safety might well be abandoned. But on that view\n    knowledge might be merely true belief, or merely justified true\n    belief, so the argument for Luminosity will be a non-starter. But\n    the argument of this paper does not rest on these radical\n    methodological principles. The position I'm defending is that,\n    supposing a standard methodological approach, we should accept a\n    Safety principle. But as I'll argue, the version of Safety\n    Williamson adopts is not appropriate, and the appropriate version\n    does not necessarily support the argument against Luminosity.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}