{
  "hash": "68b98293c4a16db873b6578093577e22",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Interest-Relative Invariantism\"\ndescription: |\n  An opinionated survey of the state of the literature on interest-relative invariantism.\ndate: March 17 2017\nauthor:\n  - name: Brian Weatherson \n    url: http://brian.weatherson.org\n    affiliation: University of Michigan\n    affiliation_url: https://umich.edu\n    orcid_id: 0000-0002-0830-141X\ncategories:\n  - epistemology\n  - interest-relativity\ncitation: false\nbibliography: ../../../articles/Rbib.bib\nself-contained: false\npreview: survey.jpg\noutput:\n  distill::distill_article:\n    toc: true\n    toc_depth: 3\n    number_sections: true\n---\n\n\n\n### Introduction\n\nOne of the initial motivations for epistemological contextualism was\nthat the appropriateness of self-ascriptions of knowledge seemed to\ndepend, in some circumstances, on factors that were traditionally\nthought to be epistemologically irrelevant. So whether our hero *S* was\nprepared to say \"I know that *p*\" would depend not just on how strong\n*S*'s evidence for *p* was, or how strongly they believed it, but on\nfactors such as how much it mattered whether *p* was true, or what\nalternatives to *p* were salient in their thought or talk.\n\n<aside>\nPublished in _Routledge Handbook of Epistemic Contextualism_, edited by Jonathan Jenkins Ichikawa, 2017, 240-253.\n</aside>\n\nIt was immediately noted that this data point, even if accepted, is\nconsistent with a number of theories of the truth of knoweldge\nascriptions. It might be that things like stakes and salient\nalternatives affect the assertability conditions of knowledge\nascriptions, but not their truth conditions  [@Rysiew2016]. But let's\nassume that we've convinced ourselves that this isn't right, and that\nwhether *S* can truly (and not just appropriately) say \"I know that *p*\"\ndepends on things like the stakes or salient alternatives.\n\nIt still doesn't follow that contextualism is true. It might be that in\nall contexts, whether an utterance of \"S knows that *p*\" is true depends\non the stakes for *S*, or on the salient alternatives for *S*. That\nwould be true, the idea is, whether *S* is talking about herself, or\nsomeone else is talking about her. The stakes, or salient alternatives,\nwould affect the truth conditions of *S*'s utterance not because she is\nthe one doing the talking, but the one being talked about. The practical\nand theoretical situation of the ascribee of the knowledge ascription\nmay be relevant, even if the practical and theoretical situation of the\nascribor need not be.\n\nThis line of thought leads to the idea that knowledge itself is\ninterest-relative. Whether an utterance here and now of \"S knows that\n*p*\" is true, i.e., whether *S* knows that *p*, depends on how much it\nmatters to *S* that *p* is true, or on which alternative are salient to\n*S*. The thesis that knowledge is interest-relative is consistent with\ncontextualism. It could be that whether a knowledge ascription is true\ndepends on the interests of both the ascriber, and the ascribee. In this\nentry, however, I'm going to largely focus on the view that knowledge is\ninterest-relative, but contextualism is false. On this view, the\ninterests of the ascribee do matter to the truth of a knowledge\nascription, but the interests of the ascribee do not.\n\nThis view is naturally called **interest-relative invariantism**, since\nit makes knowledge interest-relative, but it is a form of\nanti-contextualism, i.e., invariantism. The view is sometimes called\n**subject-sensitive invariantism**, since it makes knowledge relevant to\nthe stakes and salient alternatives to the subject. But this is a bad\nname; of course whether a knowledge ascription is true is sensitive to\nwho the subject of the ascription is. I know what I had for breakfast\nand you (probably) don't. What is distinctive is which features of the\nsubject's situation that interest-relative invariantism says are\nrelevant, and the name interest-relative invariantism makes it clear\nthat it is the subject's interests. There is one potential downside to\nthis name; it suggests that the practical interests of the subject are\nrelevant to what they know. I intend to use the predicate\n'interest-relative' to pick out a class of theories, including the\ntheory floated by John @Hawthorne2004, where the options that are\nsalient to the subject matter to what the subject knows. If forced to\ndefend the name, I'd argue that salience is relevant to the theoretical\ninterests of the subject, if not necessarily to their practical\ninterests. But the name is still potentially misleading; my main reason\nfor using it is that 'subject-sensitive' is even more misleading. (I'll\nshorten 'interest-relative invariantism' to IRI in what follows. I'll\nreturn to the question of practical and theoretical interests in section\n4.)\n\nThere are a number of ways to motivate and precisify IRI. I'll spend\nmost of this entry going over the choice points, starting with the\npoints where I think there is a clearly preferably option, and ending\nwith the choices where I think it's unclear which way to go. Then I'll\ndiscuss some general objections to IRI, and say how they might be\nanswered.\n\n### Motivations\n\nThere are two primary motivations for IRI. One comes from intuitions\nabout cases, the other from a pair of principles. It turns out the two\nare connected, but it helps to start seeing them separately.\n\nJason @Stanley2005 starts with some versions of the 'bank cases' due\noriginally to Keith @DeRose1992. These turn on idiosyncratic, archaic\ndetails of the US payments system, and I find it hard to have clear\nintuitions about them. A cleaner pair of examples is provided by Angel\n@Pinillos2012; here are slightly modified versions of his examples.\n\n> Ankita and Bojan each have an essay due. They have, surprisingly,\n> written word for word identical papers, and are now checking the paper\n> for typos. The papers have no typos, and each student has checked\n> their paper twice, with the same dictionary, and not found any typos.\n> They are, in general, equally good at finding typos, and have true\n> beliefs about their proficiency at typo-spotting.\n>\n> The only difference between them concerns the consequence of a typo\n> remaining. If the paper is a borderline A/A- paper, a typo might mean\n> Ankita gets an A- rather than an A. But the grade doesn't matter to\n> her; she's already been accepted into a good graduate program next\n> year so long as she gets above a C. But Bojan's instructor is a\n> stickler for spelling. Any typo and he gets a C on the paper. And he\n> has a very lucrative scholarship that he loses if he doesn't get at\n> least a B on this paper. (Compare the Typo-Low and Typo-High examples\n> in @Pinillos2012 [199].)\n\nThe intuition that helps IRI is that Ankita knows she has no typos in\nher paper, and should turn it in, while Bojan does not know this, and\nshould do a third (and perhaps fourth or fifth) check. Contextualists\nhave a hard time explaining this; in this very context I can say \"Ankita\nknows her paper has no typos, but Bojan does not know his paper has no\ntypos\". If the intuition is right, it seems to support\ninterest-relativity, since the difference in practical situation between\nAnkita and Bojan seems best placed to explain their epistemic\ndifference. Alternatively, if there is a single context within which one\ncan truly say \\\"Ankita knows her paper has no typos'', and ''Bojan does\nnot know his paper has no typos'', that's again something an\ninterest-invariant contextualism can't explain. Either way, we have an\nargument from cases for a form of interest-relativity.\n\nThe argument from principles takes off from the idea that knowledge\nplays an important role in good deliberation, and that knowledge does\nnot require maximal confidence. It is easiest to introduce with an\nexample, though note that we aren't going to rely on epistemic\nintuitions about the example. Chika looked at the baseball scores last\nnight before going to bed and saw that the Red Sox won. She remembers\nthis when she wakes up, though she knows that she does sometimes\nmisremember baseball scores. She is then faced with the following\nchoice: take the red ticket, which she knows pays \\$1 if the Red Sox won\nlast night, and nothing otherwise or the blue ticket, which she knows\npays \\$1 iff 2+2=4, and nothing otherwise. Now consider the following\nprinciple, named by Jessica @Brown2013:\n\nK-Suff\n\n:   If *S* knows that *p*, then *S* can rationally take *p* as given in\n    practical deliberation.\n\nThe following trio seems to be inconsistent:\n\n1.  Chika knows the Red Sox won last night.\n\n2.  Chika is rationally required to take the blue ticket.\n\n3.  K-Suff is true.\n\nBy 1 and 3, Chika can take for granted that the Red Sox won last night.\nSo the value of the red ticket, for her, is equal to its value\nconditional on the Red Sox winning. And that is \\$1. So it is at least\nas valuable as the blue ticket. So she can't be rationally required to\ntake the blue ticket. Hence the three propositions are inconsistent.\n\nThis is worrying for two reasons. For one thing, it is intuitive that\nChika knows that the Red Sox won. For another thing, it seems this form\nof argument generalises. For almost any proposition at all, if Chika\nknows the red ticket pays out iff that proposition is true, she should\nprefer the blue ticket. So she knows very little.\n\nHow could this argument be resisted? One move, which we'll return to\nfrequently, is to deny K-Suff. Maybe Chika's knowledge that the Red Sox\nwon is insufficient; she needs to be certain, or to have some higher\norder knowledge. But denying K-Suff alone will not explain why Chika\nshould take the blue ticket. After all, if K-Suff is false, the fact\nthat Chika knows the payout terms of the tickets is not in itself a\nreason for her to choose the blue ticket.\n\nSo perhaps we could deny that she is rationally required to choose the\nblue ticket. This does seem extremely unintuitive to me. Intuitions\naround here do not seem maximally reliable, but this is a strong enough\nintuition to make it worthwhile to explore other options.\n\nAnd IRI provides a clever way out of the dilemma. Chika does not know\nthe Red Sox won last night. But she did know that, before the choice was\noffered. Once she has that choice, her knowledge changes, and now she\ndoes not know. The intuition that she knows is explained by the fact\nthat relative to a more normal choice set, she can take the fact that\nthe Red Sox won as a given. And scepticism is averted because Chika does\nnormally know a lot; it's just in the context of strange choices that\nshe loses knowledge.\n\nThe plotline here, that principles connecting knowledge and action run\nup against anti-sceptical principles in contrived choice situations, and\nthat IRI provides a way out of the tangle, is familiar. It is,\nsimplifying greatly, the argumentative structure put forward by\n@Hawthorne2004, and by @FantlMcGrath2002 [@FantlMcGrath2009], and by\n@Weatherson2012. It does rely on intuitions, but they are intuitions\nabout choices (such as that Chika should choose the blue ticket), not\nabout knowledge directly.\n\nSome discussions of IRI, especially that in @HawthorneStanley2008 use a\nconverse principle. Again following the naming convention suggested by\nJessica @Brown2013, we'll call this K-Nec.\n\nK-Nec\n\n:   An agent can properly use *p* as a reason for action only if she\n    knows that *p*.\n\nI'll mostly set the discussion of K-Nec aside here, since my preferred\nargument for IRI, the argument from Chika's case, merely relies on\nK-Suff. But it is interesting to work through how K-Nec helps plug a gap\nin the argument by cases for IRI.\n\n@BuckwalterSchaffer2015 argue that the intuitions behind Pinillos's\nexamples are not as solid as we might like. It's true that experimental\nsubjects do say that Bojan has to check the paper more times than Ankita\ndoes before he knows that the paper contains no typos. But those\nsubjects also say he has to check more times before he believes that the\npaper has no typos. And, surprisingly, they say that he has to check\nmore time before he guesses the paper has no typos. They suggest that\nthere might be interest-relativity in the modal 'has' as much as in the\nverb 'knows'. To say someone 'has' to X before they Y, typically means\nthat it is improper, in some way, to Y without doing X first. That won't\nbe a problem for the proponent of IRI as long as at least in some of the\ncases Pinillos studies, the relevant senses of propriety are connected\nto knowledge. And that's plausible for belief; Bojan has to know the\npaper is typo free before he (properly) believes it. At least, that's a\nplausible move given K-Nec.[^1]\n\nThere is one other problem for argument from cases for IRI. Imagine that\nafter two checks of the paper, we tell Bojan that Ankita's paper is a\nduplicate of hers, and she has checked her paper in just the same way he\nhas checked his. And we tell him that Ankita does not overly care\nwhether her paper is typo-free, but is confident that it is. We then ask\nhim, does Ankita know her paper is typo free? Many philosophers think\nBojan should answer \"No\" here. And that isn't something IRI can explain.\nAccording to IRI, he should say, \"I don't know.\" He can't say Ankita\ndoes know, since he doesn't know their common paper has no typos. But\nit's hard to see why he should deny knowledge. Keith @DeRose2009 [185]\nthinks this case is particularly hard for IRI to explain, while Brian\n@Kim2015 offers some possible explanations. This objection doesn't tell\nagainst the claim that knowledge is interest-relative, but it does\nthreaten the invariantism. An interest-relative contextualist should say\nthat everyone should deny Bojan knows his paper is typo free, and Bojan\nshould deny Ankita knows her paper is typo-free.\n\n### Odds and Stakes {#oddsandstakes}\n\nInterest-relative invariantism says that the interests of the subject\nmatter to what she knows. This is a fairly vague statement though; there\nare a number of ways to make it precise. Right now I have interests in\npractical questions (such as whether I should keep writing or go to\nlunch) and in theoretical questions (such as whether IRI is true). Do\nboth kinds of interests matter? We'll return to that question in the\nnext section. For now we want to ask a prior question: when do practical\ninterests matter for whether a subject knows that *p*? There are two\nmain answers to this question in the literature.\n\nStakes\n\n:   When the agent has a possible bet on *p* that involves large\n    potential losses, it is harder to know that *p*.\n\nOdds\n\n:   When the agent has a possible bet on *p* that involves long odds, it\n    is harder to know that *p*.\n\nThe difference between these two options becomes clear in a simple class\nof cases. Assume the agent is faced with a choice with the following\nstructure:\n\n-   There is a safe option, with payout *S*.\n\n-   And there is a risky option, with good payout *G* if *p* is true,\n    and bad payout *B* if *p* is false.\n\nThese choices need not involve anything like a 'bet', in the ordinary\nfolk sense. But they are situations where the agent has to make a choice\nbetween a path where the payouts are *p*-dependent, and one where they\nare independent of *p*. And those are quite common situations.\n\nThe **Stakes** option says that the relevant number here is the\nmagnitude $S-B$. If that is large, then the agent is in a high-stakes\nsituation, and knowledge is hard. If it is low, then the agent is in a\nlow stakes situation, and knowledge is relatively easy. (Perhaps the\nmagnitude of $G-S$ is relevant as well, though the focus in the\nliterature has been on examples where $S-B$ is high.)\n\nThe **Odds** option says that the relevant number is is the ratio:\n\n$$\\frac{S-B}{G-S}$$ If that number is high, the agent faces a long odds\nbet, and knowledge is hard. If that number is low, the agent faces a\nshort odds bet, and knowledge is relatively easy.\n\nIf our motivation for IRI came from cases, then it is natural to believe\n**Stakes**. Both Bojan and Chika face bets on *p* at long odds, but\nintuition is more worried about whether Bojan knows that *p* than\nwhether Chika does. (At least my intuition is worried about whether\nBojan knows, and I've seen little evidence that Chika's case is\nintuitively a case of non-knowledge.)\n\nBut if our motivation for IRI came from principles, then it is natural\nto believe **Odds**. One way to think of the argument from principles\nfor IRI is that it is a way to make all four of the following intuitive\nclaims true:\n\n1.  Agents should maximise evidential expected utility; i.e., they\n    should choose the option whose expected utility is highest if the\n    utilities are the agent's own, and the probabilities are the\n    evidential probabilities given the agent's evidence.\n\n2.  If an agent knows that *p*, they can ignore possibilities where *p*\n    is false; i.e., they can make whatever choice is the rational choice\n    given *p*.\n\n3.  Chika cannot ignore possibilities where the Red Sox lost; she should\n    consider those possibilities because it is in virtue of them that\n    the evidential expected utility of taking the red ticket is higher.\n\n4.  Agents with Chika's evidence, background and dispositions typically\n    know that the Red Sox won.\n\nThe first three principles imply that Chika does not know the Red Sox\nwon. The only way to square that with the anti-sceptical fourth\nprinciple is to say that Chika is in some way atypical. And the only way\nshe has been said to be atypical is in the practical choices she faces.\nBut note it is not because she faces a high-stakes choice: precisely one\ndollar is at stake. It is because she faces a long (indeed infinitely\nlong) odds bet.\n\nIn the general case we discussed above, agents maximise expected utility\nby taking the risky choice iff:\n\n$$\\frac{S-B}{G-S} < \\frac{Pr(p)}{1-Pr(p)}$$ where $Pr(p)$ is the\nprobability of *p* given the agent's evidence. The actual magnitudes at\nplay don't matter to what choice maximses expected utility, just the\nodds the agent faces. So if one's motivation to keep IRI is to square\nexpected utility maxmisation with natural principles about knowledge and\naction, it seems the relevant feature of practical situations should be\nthe stakes agents face.\n\nWhy could it seem stakes matter then? I think it is because in high\nstakes situations, the odds an agent faces are typically long ones. It\nis much easier to lose large amounts of utility than to gain large\namounts of utility. Bojan stands to lose a lot from a typo in his paper;\nhe doesn't stand to lose much by taking the time to check it over. So a\nhigh stakes situation will, at least typically, be a long odds\nsituation. So if we say the odds the agent faces are relevant to what\nthey know, we can explain any intuition that the stakes at play are\nrelevant.\n\nJessica @Brown2008 [176] also notes that cases where the agent faces\nlong odds but low stakes raise problems for the stakes-based version of\nIRI.\n\n### What Kind of Interests? {#whatkindofinterests}\n\nLet's return to the question of whether theoretical interests are\nrelevant to knowledge, or only practical interests. There is some\nprecedent for the more restrictive answer. Stanley's book on IRI is\ncalled *Knowledge and Practical Interests*. And he defends a theory on\nwhich what an agent knows depends on the practical questions they face.\nBut there are strong reasons to think that theoretical reasons matter as\nwell.\n\nIn the previous section, I suggested that agents know that *p* only if\nthey would maximise expected utility by choosing the choice that would\nbe rational given *p*. That is, agents know that *p* only if the answer\nto the question \"What choice maximises expected utility?\" is the same\nunconditionally as it is conditional on *p*. My preferred version of\ninterest-relative invariantism generalises this approach. An agent knows\nthat *p* only if the rational answer to a question she faces is the same\nunconditionally as it is conditional on *p*. What it is for an agent to\nface a question is dependent on the agent's interests. If that's how one\nthinks of IRI, the question of this section becomes, should we restrict\nquestions the agent faces to just being questions about what choice to\nmake? Or should they include questions that turn on her thoeretical\ninterests, but which are irrelevant to choices before her. There are two\nprimary motivations for allowing theoretical interests as well as\npractical interests to matter.\n\nThe first comes from the arguments for what Jeremy Fantl and Matthew\nMcGrath call the Unity Thesis  [@FantlMcGrath2009 73--6]. They are\ninterested in the thesis that whether or not *p* is a reason for an\nagent is independent of whether the agent is engaged in practical or\ntheoretical deliberation. But we don't have to be so invested in the\nideology of reasons to appreciate their argument. Note that if only\npractical interests matter, then the agent should come up with different\nanswers to the question \"What to do in situation *S*\" depending on\nwhether the agent is actually in *S*, or they are merely musing about\nhow one would deal with that situation. And it is unintuitive that this\nshould matter.\n\nLet's make that a little less abstract. Imagine Chika is not actually\nfaced with the choice between the red and blue tickets. In fact, she has\nno practical decision to make that turns on whether the Red Sox won. But\nshe is idly musing over what she would do if she were offered the red\nticket and the blue ticket. If she knows the Red Sox won, then she\nshould be indifferent between the tickets. After all, she knows they\nwill both return \\$1. But intuitively she should think the red ticket is\npreferable, even in the abstract setting. And this seems to be the\ntotally general case.\n\nThe general lesson is that if whether one can take *p* for granted is\nrelevant to the choice between A and B, it is similarly relevant to the\ntheoretical question of whether one would choose A or B, given a choice.\nAnd since those questions should receive the same answer, if *p* can't\nbe known while making the practical deliberation between A and B, it\ncan't be known while musing on whether A or B is more choiceworthy.\n\nIn @Weatherson2012 I suggest another reason for including theoretical\ninterests in what's relevant to knowledge. There is something odd about\nthe following reasoning: The probability of *p is precisely x*,\ntherefore *p*, in any case where $x < 1$. It is a little hard to say,\nthough, why this is problematic, since we often take ourselves to know\nthings on what we would admit, if pushed, are purely probabilistic\ngrounds. The version of IRI that includes theoretical interests allows\nfor this. If we are consciously thinking about whether the probability\nof *p* is *x*, then that's a relevant question to us. Conditional on\n*p*, the answer to that question is clearly no, since conditional on\n*p*, the probability of *p* is 1. So anyone who is thinking about the\nprecise probability of *p*, and not thinking it is 1, is not in a\nposition to know *p*. And that's why it is wrong, when thinking about\n*p*'s probability, to infer *p* from its high probability.\n\nPutting the ideas so far together, we get the following picture of how\ninterests matter. An agent knows that *p* only if the evidential\nprobability of *p* is close enough to certainty for all the purposes\nthat are relevant, given the agent's theoretical and practical\ninterests. Assuming the background theory of knowledge is non-sceptical,\nthis will entail that interests matter.\n\n### Global or Partial {#globalorpartial}\n\nSo far I've described three ways to refine the defence of IRI.\n\n1.  The motivation could come from cases or principles.\n\n2.  The relevant feature that makes it hard to have knowledge could be\n    that the agent faces a high-stakes choice, or a long-odds choice.\n\n3.  Only practical interests may be relevant to knowledge, or\n    theoretical interests may matter as well.\n\nFor better or worse, the version of IRI I've defended has fairly clear\ncommitments on all three; in each case, I prefer the latter option. From\nhere on, I'm much less sure of the right way to refine IRI.\n\nIRI, like contextualism, was introduced as a thesis about knowledge. But\nit need not be restricted that way. It could be generalised to a number\nof other epistemically interesting notion. At the extreme, we could\nargue that every epistemologially interesting notion is\ninterest-relative. Doing so gives us a global version of IRI.\n\nJason @Stanley2005 comes close to defending a global version. He notes\nthat if one has both IRI, and a 'knowledge first' epistemology\n [@Williamson2000], then one is a long way to towards globalism. Even if\none doesn't accept the whole knowledge first package, but just accepts\nthe thesis that evidence is all and only what one knows, then one is a\nlong way towards globalism. After all, if evidence is interest-relative,\nthen probability, justification, rationality, and evidential support are\ninterest-relative too.\n\nKatherine @Rubin2015 objects to globalist versions of IRI. But the\nobjections she gives turn, as she notes, on taking stakes not odds to be\nrelevant.\n\nIf a non-global version of IRI could be made to work, it would have some\ntheoretical advantages. It's nice to be able to say that Chika should\ntake the blue ticket because the evidential probability of the Red Sox\nwinning is lower than the evidential probability of two plus two being\nfour. But that won't be a non-circular explanation if we also say that\nsomething is part of Chika's evidence in virtue of being known.\n\nOn the other hand, the motivations for interest-relativity of knowledge\nseem to generalise to all other non-gradable states. In ordinary cases,\nChika could use the fact that the Red Sox won as a given in practical or\ntheoretical reasoning. That is, she could properly treat it as evidence.\nBut she can't treat it as evidence when deciding which ticket to take.\nSo at least what she can properly treat as evidence seems to be\ninterest-relative, and from there it isn't obvious how to deny that\nevidence itself is interest-relative too.\n\nThere remains a question of whether gradable notions, like epistemic\nprobabilities, are also interest-relative. One of the aims of my first\npaper on IRI  [@Weatherson2005] was to argue that probabilistic notions\nare interest-invariant while binary notions are interest-relative. But\nif propositions that are part of one's evidence have maximal probability\n(in the relevant sense of probability), and evidence is\ninterest-relative, that combination won't be sustainable.\n\nIn short, while the non-global version of IRI allows for some nice\nreductive explanations of why interests matter, the global version is\nsupported by the very intuitions that motivated IRI. There is a danger\nhere that whatever way the IRI theorist goes, they will run into\ninsuperable difficulties. @IchikawaEtAl2012 argue strongly that this\ndanger is real; there is no plausible way to fill out IRI. I'm not\nconvinced that the prospects are quite so grim, but I think this is one\nof the more pressing worries for IRI.\n\n### Belief, Justification and Interest {#beliefjustificationandinterest}\n\nIf we decide that not everything in epistemology is interest-relative,\nthen we face a series of questions about which things are, and are not,\ninterest relative. One of these concerns belief. Should we say that what\nan agent believes is sensitive to what her interests are?\n\nNote that the question here concerns whether belief is constitutively\nrelated to interests. It is extremely plausible that belief is causally\nrelated to interests. As Jennifer @Nagel2008 has shown, many agents will\nreact to being in a high-stakes situation by lowering their confidence\nin relevant propositions. In this way, being in a high-stakes situation\nmay cause an agent to lose beliefs. This is not the kind of constitutive\ninterest-relativity that's at issue here, though the fact this happens\nmakes it harder to tell whether there is such a thing as constitutive\ninterest-relativity of belief.\n\nI find it useful to distinguish three classes of views about beliefs and\ninterests.\n\n1.  Beliefs are not interest-relative. If knowledge is\n    interest-relative, the interest-relativity is in the conditions a\n    belief must satisfy in order to count as knowledge.\n\n2.  Beliefs are interest-relative, and the interest-relativity of belief\n    fully explains why knowledge is interest-relative.\n\n3.  Beliefs are interest-relative, but the interest-relativity of belief\n    does not fully explain why knowledge is interest-relative.\n\nIn @Weatherson2005, I suggested an argument for option 2. I now think\nthat argument fails, for reasons given by Jason @Stanley2005. I\noriginally thought option 2 provided the best explanation of cases like\nChika's. Assume Chika does the rational thing, and takes the blue\nticket. She believes it is better to take the blue ticket. But that\nwould be incoherent if she believed the Red Sox won. So she doesn't\nbelieve the Red Sox won. But she did believe the Red Sox won before she\nwas offered the bet, and she hasn't received any new evidence that they\ndid not. So, assuming we can understand an interest-invariant notion of\nconfidence, she is no less confident that the Red Sox won, but she no\nlonger believes it. That's because belief is interest-relative. And if\nall cases of interest-relativity are like Chika's, then they will all be\ncases where the interest-relativity of belief is what is ultimately\nexplanatory.\n\nThe problem, as Stanley had in effect already pointed out, is that not\nall cases are like Chika's. If agents are mistaken about the choice they\nface, the explanation I offered for Chika's case won't go through. This\nis especially clear in cases where the mistake is due to irrationality.\nLet's look at an example of this. Assume Dian faces the same choice as\nChika, and this is clear, but he irrationally believes that the red\nticket pays out \\$2. So he prefers the red ticket to the blue ticket,\nand there is no reason to deny he believes the Red Sox won. Yet taking\nthe red ticket is irrational; he wouldn't do it were he rational. Yet it\nwould be rational if he knew the Red Sox won. So Dian doesn't know the\nRed Sox won, in virtue of his interests, while believing they did.\n\nNote this isn't an argument for option 1. Everything I said about Dian\nis consistent with the Chika-based argument for thinking that belief is\ninterest-relative. It's just that there are cases where the\ninterest-relativity of knowledge can't be explained by the\ninterest-relativity of belief. So I now think option 3 is correct.\n\nWe can ask similiar questions about whether justified belief is\ninterest-relative, and whether if so this explains the\ninterest-relativity of knowledge. I won't go into as much detail here,\nsave to note that on my preferred version of IRI, Dian's belief that the\nRed Sox won is both justified and rational. (Roughly, this is because I\nthink his belief that the Red Sox won just is his high credence that the\nRed Sox won, and his high credence the Red Sox won is justified and\nrational. I defend this picture at more length in \\[Weatherson2005;\\].\nAnd while that paper makes some mistaken suggestions about knowledge, I\nstill think what it says about belief and justification is broadly\ncorrect.) That is, Dian has a justified true belief that the Red Sox\nwon, but does not know it. This is, to put it mildly, not the most\nintuitive of verdicts. I suspect the alternative verdicts lead to worse\nproblems elsewhere. But rather than delving deeper into the details of\nIRI to confirm whether that's true, let's turn to some objections to the\nview.\n\n### Debunking Objections {#debunkingobjections}\n\nMany arguments against IRI are, in effect, debunking arguments. The\nobjector's immediate conclusion is not that IRI is false, but that it is\nunsupported by the arguments given for it.\n\nArguments that people do not have the intuition that, for exaple, Bojan\nlacks knowledge that his paper is typo-free, do not immediately show\nthtat IRI is false. That's because the truth of IRI can be made\ncompatible with that intuition in two ways. For one thing, it is\npossible that people think Bojan knows because they think Bojan betting\nthat his paper is typo free is, in the circumstances, a good bet.[^2]\nFor another thing, intuitions around here might be unreliable. Remember\nthat one of the original motivations for IRI was that it was the lowest\ncost solution to the preface paradox and lottery paradox. We shouldn't\nexpect intuitions to be reliable in the presence of serious paradox.\nThat consideration cuts both ways; it makes debunking objections to\narguments for IRI from intuitions about cases look very promising. And I\nthink those objections are promising; but they don't show IRI is false.\n\nSimilarly, objections to the premises of the argument from principles\ndon't strictly entail that IRI is false. After all, IRI is an\nexistential thesis; it says sometimes interests matter. The principles\nused to defend it are universal claims; they say (for example) it is\nalways permissible to act on knowledge. Weaker versions of these\nprinciples might still be consistent with, or even supporting of, IRI.\nBut this feels a little desperate. If the premises of these arguments\nfail, then IRI looks implausible.\n\nBut there are still two methodological points worth remembering.\nSometimes it seems that critics of principles like K-Suff reason that\nK-Suff entails IRI, and IRI is antecedently implausible, so we should\nstart out suspicious of K-Suff. Now why might IRI be antecedently\nimplausible?\n\nI think to some extent it is because it is thought to be so\nrevolutionary. The denial of interest-relativity is often taken to be a\n\"traditional\" view. This phrasing appears, for example, in @Boyd2015,\nand in @IchikawaEtAl2012, and even in the title of @Buckwalter2014. And\nif this were correct, that would be a mark against interest-relativity.\nThe \"inherited experience and acumen of many generations of men\"\n [@Austin1956 11] should not be lightly forsaken. The problem is that it\nisn't true that IRI is revolutionary. Indeed, in historical terms there\nis nothing particularly novel about contemporary IRI. As Stephen R.\n@Grimm2015 points out, you can see a version of the view in Locke, and\nin Clifford. What's really radical, as Descartes acknowledged, is to\nthink the perspective of the Cartesian meditator is the right one for\nepistemology.\n\nPerhaps what is unintuitive about IRI is that it makes knowledge depend\non factors that are not 'truth-directed', or 'truth-conducive'. There is\na stronger and weaker version of the principle that might be being\nappealed to here. The stronger version is that IRI makes practical\nmatters into one of the factors on which knowledge depends, and this is\nimplausible. But IRI doesn't do this. It is consistent with IRI to say\nthat only truth-conducive features of beliefs are relevant to whether\nthey amount to knowledge, but how much of each feature one needs depends\non practical matters. The weaker principle is that IRI makes knowledge\ncounterfactually sensitive to features irrelevant to the truth,\njustification or reliability of the belief. This is true, but it isn't\nan objection to IRI. Any theory that allows defeaters to knowledge, and\ndefeaters to those defeaters, will make knowledge counterfactually\nsensitive to non-truth-conducive features in just the same way. And it\nis independently plausible that there are defeaters to knowledge, and\nthey can be defeated.[^3]\n\nThese are all reasons to think that IRI is not antecedently implausible.\nThere is one reason to think it is antecedently plausible. On a\nfunctionalist theory of mind, belief is a practical notion. And it is\nplausible that knowledge is a kind of success condition for belief. Now\nit's possible to have non-practical success conditions for a state our\nconcept of which is practical. But I don't find that a natural starting\nassumption. It's mucn more intuitive, to me at least, that the norms of\nbelief and the metaphysics of belief would be tightly integrated. And\nthat suggests that IRI is, if anything, a natural default.\n\nThat's not an argument for IRI, or of course for K-Suff. And there are\nimportant direct objections to K-Suff. Jessica @Brown2008 and Jennifer\n@Lackey2010 have examples of people in high stakes situations who they\nsay are intuitively described as knowing something, but not being in a\nposition to act on it. I'm sympathetic to the two-part reply that\nMasashi @Kasaki2014 makes to these examples. The first thing to note is\nthat these are hard cases, in areas where several paradoxes (e.g.,\nlottery, preface, sceptical) are lurking. Intuitions are less reliable\nthan usual around here. But another thing to notice is that it is very\nhard to say what actions are justified by taking *p* for granted in\nvarious settings. Brown and Lackey both describe cases where doctors\nhave lots of evidence for *p*, and given *p* a certain action would\nmaximise patient-welfare, but where intuitively it would be wrong for\nthe doctor to act that way. As it stands, that's a problem for IRI only\nif doctors should maximise epistemic expected patient-welfare, and that\nprinciple isn't true. Kasaki argues that there isn't a way to fill out\nLackey's example to get around this problem, and I suspect the same is\ntrue for Brown's example.\n\nFinally, note that K-Suff is an extensional claim. Kenneth @Boyd2015 and\nBaron @Reed2014 object to a principle much stronger than K-Suff: the\nprinciple that what an agent knows should explain why some choices are\nrational for them. Both of them say that if IRI is inconsistent with the\nstronger principle, that is a serious problem for IRI. (In Boyd's case\nthis is part of an argument that IRI is unmotivated; in Reed's case he\ntakes it to be a direct objection to IRI.) Now I think IRI is\ninconsistent with this principle. Chika doesn't know the Red Sox won\nbecause she can't rationally choose the red ticket, not the other way\naround. But I don't see why the principle is so plausible. It seems\nplausible to me that something else (e.g., evidence) explains both\nrational choice and knowledge, and the way it explains both things makes\nIRI true.\n\n### Direct Objections {#directobjections}\n\nLet's close with direct arguments against IRI. There are two kinds of\narguments that I won't address here. One of these is the argument,\ndeveloped in @IchikawaEtAl2012 that there isn't a good way to say how\nfar interest-relativity should extend. As I noted above, I agree this is\na deep problem, and don't think there is a good answer to it in the\nexisting literature. The other kind are objections that only apply to\nthe Stakes version of IRI, not the Odds version. One instance of this\nkind is the Dutch Book argument deployed by Baron @Reed2014. I think\nseveral instances of that kind of argument are successful. But the\ntheory they succeed against is not IRI, but a sub-optimal version of\nIRI. So I'll stick to objections that apply to the Odds version.\n\nIRI does allow knowledge to depend on some unexpected factors. But so do\nmost contemporary theories of knowledge. Most contemporary theories\nallow for knowledge to be defeated in certain ways, such as by available\nbut unaccessed evidence  [@Harman1973 75], or by nearby possibilities of\nerror  [@Goldman1976], or by mistakes in the background reasoning. The\nlast category of cases aren't really contemporary; they trace back at\nleast to Dharmottara  [@Nagel2014 58]. And contemporary theories of\nknowledge also allow for defeaters to be defeated. Once we work through\nthe details of what can defeat a defeater, it turns out many surprising\nthings can affect knowledge.\n\nIndeed, for just about any kind of defeater, it is possible to imagine\nsomething that in some ways makes the agent's epistemic position worse,\nwhile simultaneously defeating the defeater.[^4] If interests matter to\nknowledge because they matter to defeaters, as is true on my version of\nIRI, we should expect strange events to correlate with gaining\nknowledge. For example, it isn't surprising that one can gain knowledge\nthat *p* at exactly the moment one's evidential support for *p* falls.\nThis consequence of IRI is taken to be obviously unacceptable by\n@EatonPickavance2015, but it's just a consequence of how defeaters\ngenerally work.\n\nIRI has been criticised for making knowledge depend on agents not\nallowing agents to get knowledge by not caring, as in these vivid\nquotes:\n\n> Not giving a damn, however enviable in other respects, should not be\n> knowledge-making.  [@RussellDoris2008 433]\n\n> If you don't now whether penguins eat fish, but want to know, you\n> might think ... you have to gather evidence. \\[But if IRI\\] were\n> correct, though, you have another option: You could take a drink or\n> shoot heroin.  [@CappelenLepore2006 1044--5]\n\nLet's walk through Cappelen and Lepore's case. IRI says that there are\npeople who both have high confidence that penguins eat fish, and they\nhave this confidence for reasons that are appropriately connected to the\nfact that penguins eat fish. But one of them really worries about\nsceptical doubts, and so won't regard the question of what penguins eat\nas settled. The other brushes off excessive sceptical doubts, and\nrightly so; they are, after all, excessive. IRI says that the latter\nknows and the former does not. If the former were to care a little less,\nin particular if they cared a little less about evil demons and the\nlike, they'd know. Perhaps they could get themselves to care a little\nless by having a drink. That doesn't sound like a bad plan; if a\nsceptical doubt is destroying knowledge, and there is no gain from\nholding on to it, then just let it go. From this perspective, Cappelen\nand Lepore's conclusion does not seem like a reductio. Excessive doubt\ncan destroy knowledge, so people with strong, non-misleading evidence\ncan gain knowledge by setting aside doubts. And drink can set aside\ndoubt. So drink can lead to knowledge.[^5]\n\nBut note that the drink doesn't generate the knowledge. It blocks, or\ndefeats, something that threatens to block knowledge. We should say the\nsame thing to Russell and Doris's objection. Not giving a damn, about\nscepticism for example, is not knowledge-making, but it is\nknowledge-causing. In general, things that cause by double prevention do\nnot make things happen, although later things are counterfactually\ndependent on them  [@Lewis2004a]. And the same is true of not caring.\n\nFinally, it has been argued that IRI makes knowledge unstable in a\ncertain kind of way  [@Lutz2014; @Anderson2015]. Practical circumstances\ncan change quickly; something can become a live choice and cease being\none at a moment's notice. If knowledge is sensitive to what choices are\nlive, then knowledge can change this quickly too. But, say the\nobjectors, it is counterintuitive that knowledge changes this quickly.\n\nNow I'm not sure this is counterintuitive. I think that part of what it\ntakes to know *p* is to treat the question of whether *p* as closed. It\nsounds incoherent to say, \"I know a is the F, but the question of who is\nthe F is still ope\". And whether a question is treated as open or closed\ndoes, I think, change quite rapidly. One can treat a question as closed,\nget some new reason to open it (perhaps new evidence, perhaps an\ninterlocutor who treats it as open), and then quickly dismiss that\nreason. So I'm not sure this is even a problem.\n\nBut to the extent that it is, it is only a problem for a somewhat\nhalf-hearted version of IRI. The puzzles the objectors raise turn on\ncases where the relevant practical options change quickly. But even once\na practical option has ceased to be available, it can be hard in\npractice to dismiss it from one's mind. One may often still think about\nwhat to do if it becomes available again, or about exactly how\nunfortunate it is that the option went away. As long as theoretical as\nwell as practical interests matter to knowledge, it will be unlikely\nthat knowledge will be unstable in just this way. Practical interests\nmay change quickly; theoretical ones typically do not.\n\n[^1]: I'm suggesting here that in some sense, knowledge is a norm of\n    belief. For more on the normative role of knowledge, see\n    @Worsnip2016.\n\n[^2]: Compare the response to @FeltzZarpentine2010 that I make in\n    @Weatherson2011-WEADIR [§1], or the response to @Lackey2010 by\n    Masashi @Kasaki2014 [§5].\n\n[^3]: The argument of the last two sentences is expanded on greatly in\n    @Weatherson2014-ProbScept [§3]. The idea that knowledge allows for\n    defeaters is criticised by Maria @Lasonen-Aarnio2014a.\n    @EatonPickavance2015 make an objection to IRI that does not take\n    this point into account.\n\n[^4]: The argument of the last two sentences is expanded on greatly in\n    @Weatherson2014-ProbScept [§3], where it is credited to Martin\n    Smith. The idea that knowledge allows for defeaters is criticised by\n    Maria @Lasonen-Aarnio2014.\n\n[^5]: @Wright2004 notes that there often is not value in holding on to\n    sceptical doubts, and the considerations of this paragraph are\n    somewhat inspired by his views. That's not to endorse the idea that\n    using alcohol or heroin is preferable to being gripped by sceptical\n    doubts, especially heroin, but I do endorse the general idea that\n    those doubts are not cost-free.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}