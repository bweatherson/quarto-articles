{
  "hash": "3c41a98e68834b24bc41c522898cbc78",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"The Bayesian and the Dogmatist\"\ndescription: |\n It has been argued recently that dogmatism in epistemology is incompatible with Bayesianism. That is, it has been argued that dogmatism cannot be modelled using traditional techniques for Bayesian modelling. I argue that our response to this should not be to throw out dogmatism, but to develop better modelling techniques. I sketch a model for formal learning in which an agent can discover a posteriori fundamental epistemic connections. In this model, there is no formal objection to dogmatism.\ndate: August 1 2007\nauthor:\n  - name: Brian Weatherson \n    url: http://brian.weatherson.org\n    affiliation: University of Michigan\n    affiliation_url: https://umich.edu\n    orcid_id: 0000-0002-0830-141X\ndoi: \"10.1111/j.1467-9264.2007.00217.x\"\ncategories:\n  - epistemology\n  - scepticism\ncitation_url: https://doi.org/10.1111/j.1467-9264.2007.00217.x\njournal:\n    title: \"Proceedings of the Aristotelian Society\"\n    publisher: \"Oxford\"\nvolume: 107\nnumber: 1\ncitation: false\nbibliography: ../../../articles/Rbib.bib\nself-contained: false\npreview: dogmatic.jpg\noutput:\n  distill::distill_article:\n    toc: true\n    toc_depth: 3\n    number_sections: true\n---\n\n\n\nThere is a lot of philosophically interesting work being done in the\nborderlands between traditional and formal epistemology. It is easy to\nthink that this would all be one-way traffic. When we try to formalise a\ntraditional theory, we see that its hidden assumptions are inconsistent\nor otherwise untenable. Or we see that the proponents of the theory had\nbeen conflating two concepts that careful formal work lets us\ndistinguish. Either way, the formalist teaches the traditionalist a\nlesson about what the live epistemological options are. I want to argue,\nmore or less by example, that the traffic here should be two-way. By\nthinking carefully about considerations that move traditional\nepistemologists, we can find grounds for questioning some\npresuppositions that many formal epistemologists make.\n\n<aside>\nPublished in _Proceedings of the Aristotelian Society_ 107: 169-185.\n\nImage by [hiwhataboutyou](https://www.flickr.com/photos/102148845@N07) via [Creative Commons](https://search.creativecommons.org/photos/2490c26c-ce0e-46ce-b4cd-16dfb3fe063b).\n</aside>\n\nTo make this more concrete, I'm going to be looking at a Bayesian\nobjection to a certain kind of dogmatism about justification. Several\nwriters have urged that the incompatibility of dogmatism with a kind of\nBayesianism is a reason to reject dogmatism. I rather think that it is\nreason to question the Bayesianism. To put the point slightly more\ncarefully, there is a simple proof that dogmatism (of the kind I\nenvisage) can't be modelled using standard Bayesian modelling tools.\nRather than conclude that dogmatism is therefore flawed, I conclude that\nwe need better modelling tools. I'll spend a fair bit of this paper on\noutlining a kind of model that (a) allows us to model dogmatic\nreasoning, (b) is motivated by the epistemological considerations that\nmotivate dogmatism, and (c) helps with a familiar problem besetting the\nBayesian.\n\nI'm going to work up to that problem somewhat indirectly. I'll start\nwith looking at the kind of sceptical argument that motivates dogmatism.\nI'll then briefly rehearse the argument that shows dogmatism and\nBayesianism are incompatible. Then in the bulk of the paper I'll suggest\na way of making Bayesian models more flexible so they are no longer\nincompatible with dogmatism. I'll call these new models *dynamic\nKeynesian* models of uncertainty. I'll end with a brief guide to the\nvirtues of my new kind of model.\n\n## Sceptical Arguments\n\nLet *H* be some relatively speculative piece of knowledge that we have,\nsay that G. E. Moore had hands, or that it will snow in Alaska sometime\nnext year. And let *E* be all of our evidence about the external world.\nI'm not going to make many assumptions about what *E* contains, but for\nnow *E* will stay fairly schematic. Now a fairly standard sceptical\nargument goes something like this. Consider a situation *S* in which our\nevidence is unchanged, but in which *H* is false, such as a brain-in-vat\nscenario, or a zombie scenario, or a scenario where the future does not\nresemble the past. Now a fairly standard sceptical argument goes\nsomething like this.\n\n1.  To know *H* we have to be in a position to know we aren't in *S*\n\n2.  We aren't in a position to know that we aren't in *S*\n\n3.  So, we don't know *H*\n\nThere are a few immediate responses one could make, but which I'm going\nto dismiss without argument *here*. These include claiming the setup is\nincoherent (as in, e.g., @Williamson2000-WILKAI), rejecting the closure\nprinciple behind premise 1 (as in, e.g., @Dretske1971, accepting the\nconclusion (the sceptical response), or saying that in different\nsceptical arguments, one or other of these positions is correct. Instead\nI want to look at responses that question premise 2. In particular, I\nwant to look at responses that offer us reasons to accept premise 2,\nsince it seems here that the sceptic is at her strongest. (If the\nsceptic merely insists that premise 2 is reasonable, we can reply either\nthat it isn't, as I'm inclined to think, or that here is a case where\nintuition should be revised.)\n\nMany epistemologists will write papers responding to 'the sceptic'. I\nthink this is a mistake, since there are so many different possible\nsceptics, each with different arguments for premise 2. (And, of course,\nsome sceptics do not argue from sceptical scenarios like this one.) Here\nare, for instance, three arguments that sceptics might give for premise\n2.\n\n1.  Someone in *S* can't discriminate her situation from yours.\n\n2.  Indiscriminability is symmetric.\n\n3.  If you can't discriminate our situation from *S*, you can't know\n    you're not in *S*.\n\n4.  So you can't know you're not in *S*.\n\n\n\n```{=html}\n<!-- -->\n```\n\n\n1.  Someone in *S* has the same evidence as you do.\n\n2.  What you can know supervenes on what your evidence is.\n\n3.  So, you can't know you are not in *S*.\n\n\n\n```{=html}\n<!-- -->\n```\n\n\n1.  There is no non-circular argument to the conclusion that you aren't\n    in *S*.\n\n2.  If you were able to know you're not in *S*, you would be able to\n    produce a non-circular argument that concluded that you aren't in\n    *S*.\n\n3.  So you can't know that you aren't in *S*.\n\nI won't say much about these arguments, save that I think in each case\nthe second premise is very implausible. I suspect that most\nnon-philosophers who are moved by sceptical arguments are tacitly\nrelying on one or other of these arguments, but confirming that would\nrequire a more careful psychological study than I could do. But set\nthose aside, because there's a fourth argument that is more troubling.\nThis argument takes its inspiration from what we might call Hume's\nexhaustive argument for inductive scepticism. Hume said that we can't\njustify induction inductively, and we can't justify it deductively, and\nthat *exhausts* the justifications, so we can't justify induction. A\nsimilar kind of argument helps out the general sceptic.\n\n1.  If you know you aren't in *S*, you know this a priori, or a\n    posteriori\n\n2.  You can't know you aren't in *S* a posteriori\n\n3.  You can't know you aren't in *S* a priori\n\n4.  So, you can't know you aren't in *S*\n\nThis seems to be a really interesting argument to me. To make things\nsimpler, I'll stipulate that by a posteriori knowledge, I just mean\nknowledge that isn't a priori. That makes the first premise pretty\nsecure, as long as we're assuming classical logic.[^1] Lots of\nphilosophers take its third premise for granted. They assume that since\nit is metaphysically possible that you could be in *S*, this can't be\nsomething you can rule out a priori. That strikes me as a rather odd\ncapitulation to infallibilism. But I won't push that here. Instead I'll\nlook at denials of the second premise.\n\n## Dogmatism and a Bayesian Objection\n\nSomeone who denies the second premise says that your empirical evidence\ncan provide the basis for knowing that you aren't in *S*, even though\nyou didn't know this a priori. I'm going to call such a person a\n*dogmatist*, for reasons that will become clear shortly. The dogmatist\nis not a sceptic, so the dogmatist believes that you can know *H*. The\ndogmatist also believes a closure principle, so the dogmatist also\nbelieves you can know *E* ${\\supset}$ *H*. If the dogmatist thought you\ncould know *E* ${\\supset}$ *H* a priori, they'd think that you could\nknow a priori that you weren't in *S*. (This follows by another\napplication of closure.) But they think that isn't possible, so knowing\n*E* ${\\supset}$ *H* a priori isn't possible. Hence you know\n*E* ${\\supset}$ *H* a posteriori.\n\nIf we reflect on the fact that *E* is your total evidence, then we can\ndraw two conclusions. The first is that the dogmatist thinks that you\ncan come to know *H* on the basis of *E* even though you didn't know in\nadvance that if *E* is true, then *H* is true. You don't, that is, need\n*antecedent* knowledge of the conditional in order to be able to learn\n*H* from *E*. That's why I'm calling them a dogmatist. The second point\nis that the dogmatist is now running head on into a piece of Bayesian\northodoxy.\n\nTo see the problem, note that we can easily prove (A), for arbitrary\n*E*, *H* and *K*.[^2]\n\n\\(A\\)\n\n:   *Pr*(*E* ${\\supset}$ *H* *E* ${\\wedge}$ *K*) ${\\leq}$\n    *Pr*(*E* ${\\supset}$ *H* *K*), with equality iff\n    *Pr*(*E* ${\\supset}$ *H* *E* ${\\wedge}$ *K*) = 1\n\nProof:\n\n::: {.center}\n  ----- ------------------------------------------------------------------------------------- --------------\n    1\\. *Pr*(*E* ${\\supset}$ *H* *K*) =                                                       \n        *Pr*(*E* ${\\supset}$ *H* *E* ${\\wedge}$ *K*) *Pr*(*E* *K*) +                          \n        *Pr*(*E* ${\\supset}$ *H* ${\\lnot}$*E* ${\\wedge}$ *K*) *Pr*(${\\lnot}$*E* *K*)          Prob theorem\n    2\\. *Pr*(*E* ${\\supset}$ *H* ${\\lnot}$*E* ${\\wedge}$ *K*) = 1                             Logic\n    3\\. *Pr*(*E* ${\\supset}$ *H*  *E* ${\\wedge}$ *K*) ${\\leq}$ 1                              Prob theorem\n    4\\. *Pr*(*E* ${\\supset}$ *H* *K*) ${\\geq}$                                                \n        *Pr*(*E* ${\\supset}$ *H* *E* ${\\wedge}$ *K*) *Pr*(*E* *K*) +                          \n        *Pr*(*E* ${\\supset}$ *H* *E* ${\\wedge}$ *K*) *Pr*(${\\lnot}$*E* *K*)                   1, 2, 3\n    5\\. *Pr*(*E*  *K*) + *Pr*(${\\lnot}$*E* *K*) = 1                                           Prob theorem\n    6\\. *Pr*(*E* ${\\supset}$ *H* *K*) ${\\geq}$ *Pr*(*E* ${\\supset}$ *H* *E* ${\\wedge}$ *K*)   4, 5\n  ----- ------------------------------------------------------------------------------------- --------------\n:::\n\nIt is clear enough from the proof that line 6 is an equality iff line 3\nis an equality, so we have proven (A). Now some authors have inferred\nfrom this something like (B) from (A).[^3]\n\n\\(B\\)\n\n:   It is impossible to go from not being in a position to know\n    *E* ${\\supset}$ *H* to being in a position to know it just by\n    receiving evidence *E*.\n\nThe transition here should raise an eyebrow or two. (A) is a principle\nof probability statics. (B) is a principle of epistemological\nkinematics. To get from (A) to (B) we need a principle linking\nprobability and epistemology, and a principle linking statics and\nkinematics. Fortunately, orthodox Bayesian confirmation theory offers us\nsuggestions for both principles. We'll write *Cr*(*A*) for the agent's\ncredence in *A*, and *Cr~E~*(*A*) for the agent's credence in *A* when\nupdated by receiving evidence *E*.\n\n[Learning]{.smallcaps}:\n\n:   If *Cr~E~*(*A*) ${\\leq}$ *Cr*(*A*), then it is impossible to go from\n    not being in a position to know *A* to being in a position to know\n    it just by receiving evidence *E*.\n\n[Bayes]{.smallcaps}:\n\n:   *Cr~E~*(*A*) = *Cr*(*A*  *E*). That is, learning goes by\n    conditionalisation.\n\nA quick browse at any of the literature on Bayesian confirmation theory\nwill show that these principles are both widely accepted by Bayesians.\nPhilosophers, even Bayesians, make false assumptions, so neither of\nthese principles is obviously true. Nevertheless, I'm going to accept\n[Learning]{.smallcaps} at least for the sake of argument. I'm going to\nargue instead that the inference from (A) to (B) fails because\n[Bayes]{.smallcaps} fails. That is, I'm going to accept that if we could\nprove a principle I'll call [Lower]{.smallcaps} is true, then dogmatism\nin the sense I'm defending it fails.\n\n[Lower]{.smallcaps}.\n\n:   *Cr~E~*(*E* ${\\supset}$ *H*) is less than or equal to\n    *Cr*(*E* ${\\supset}$ *H*).\n\nNow there is a bad argument around here that the dogmatist might make.\nIt might be argued that since the Bayesian approach (including\n[Bayes]{.smallcaps}) involves so much idealisation it could not be\napplicable to real agents. That's a bad argument because the Bayesian\napproach might provide us with a good model for real agents, and models\ncan be useful without being scale models. As long as the Bayesian model\nis the most appropriate model in the circumstances, then we can draw\nconclusions for the real world from facts about the model. The problem\narises if there are alternative models which seem to fit just as well,\nbut in which principles like [Lower]{.smallcaps} are not true. If there\nare alternative models that seem better suited (or at least just as well\nsuited) to modelling the situation of initial evidence acquisition, and\nthose models do not make [Lower]{.smallcaps} true, then we might think\nthe derivation of [Lower]{.smallcaps} in the Bayesian model is a mere\nconsequence of the arbitrary choice of model. In the next section I will\ndevelop just such a model. I won't argue that it is the best model, let\nalone the only alternative to the Bayesian model. But I will argue that\nit is as good for these purposes as the Bayesian model, and it does not\nimply [Lower]{.smallcaps}.\n\n## Bayes and Keynes\n\nThe traditional Bayesian model of a rational agent starts with the\nfollowing two principles.\n\n-   At any moment, the agent's credal states are represented by a\n    probability function.\n\n-   From moment to moment, the agent's credal states are updated by\n    conditionalisation on the evidence received.\n\nOver recent decades many philosophers have been interested in models\nthat relax those assumptions. One particular model that has got a lot of\nattention (from e.g. Isaac @Levi1974 [@Levi1980], Richard @Jeffrey1983,\nBas @vanFraassen1990, Alan @Hajek2000 [@Hajek2003] and many others) is\nwhat I'll call the *static Keynesian model*. This model has the\nfollowing features.\n\n-   At any moment, the agent's credal states are represented by a set of\n    probability functions, called their representor.\n\n-   The agent holds that *p* is more probable than *q* iff the\n    probability of *p* is greater than the probability of *q* according\n    to all probability functions in their representor. The agent holds\n    that *p* and *q* are equally probable iff the probability of *p* is\n    equal to the probability of *q* according to all probability\n    functions in their representor.\n\n-   From moment to moment, the agent's credal states are updated by\n    conditionalising each of the functions in the representor on the\n    evidence received.\n\nThe second point is the big attraction. It allows that the agent need\nnot hold that *p* is more probable than *q*, or *q* more probable than\n*p*, or that *p* and *q* are equally probable, for arbitrary *p* and\n*q*. And that's good because it isn't a rationality requirement that\nagents make pairwise probability judgments about all pairs of\npropositions. Largely because of this feature, I argued in an earlier\npaper that this model could be use to formalise the key philosophical\nideas in Keynes's *Treatise on Probability*. That's the reason I call\nthis a 'Keynesian' model.\n\nThe modifier 'static' might seem a little strange, because the agent's\nrepresentor does change when she receives new evidence. But the change\nis always of a certain kind. Her 'hypothetical priors' do not change. If\nat *t*~1~ her evidence is *E*~1~ and her representor *R*~1~, and at\n*t*~2~ her evidence is *E*~2~ and her representor *R*~2~, then there is\na 'prior' representor *R*~0~ such that the following two claims are true\nfor all probability functions *Pr*.\n\n-   *Pr* ${\\in}$ *R*~1~ ${\\leftrightarrow}$ [${\\exists}$Pr~0~ ${\\in}$\n    *R*~0~: ${\\forall}$*p* (*Pr*(*p*) = Pr~0~(*p* *E*~1~)]\n\n-   *Pr* ${\\in}$ *R*~2~ ${\\leftrightarrow}$ [${\\exists}$Pr~0~ ${\\in}$\n    *R*~0~: ${\\forall}$*p* (*Pr*(*p*) = Pr~0~(*p* *E*~2~)]\n\nThat is, there is a set of probability functions such that the agent's\nrepresentor at any time is the result of conditionalising each of those\nfunctions on her evidence. I'll call any model with this property a\nstatic model, so the model described above is the static Keynesian\nmodel.\n\nNow there is a lot to like about the static Keynesian model, and I have\nmade extensive use of it previous work. It is a particularly useful\nmodel to use when we need to distinguish between risk and uncertainty in\nthe sense that these terms are used in Keynes's 1937 article \"The\nGeneral Theory of Employment\".[^4] The traditional Bayesian model\nassumes that all propositions are risky, but in real life some\npropositions are uncertain as well, and in positions of radical doubt,\nwhere we have little or no empirical evidence, presumably most\npropositions are extremely uncertain. And using the static Keynesian\nmodel does not mean we have to abandon the great work done in Bayesian\nepistemology and philosophy of science. Since a Bayesian model is a\n(degenerate) static Keynesian model, we can say that in many\ncircumstances (namely circumstances where *uncertainty* can be properly\nignored) the Bayesian model will be appropriate. Indeed, these days it\nis something like a consensus among probabilists or Bayesians that the\nstatic Keynesian model is a useful generalisation of the Bayesian model.\nFor example in @Christensen2005 it is noted, almost as an afterthought,\nthat the static Keynesian model will be more realistic, and hence\npotentially more useful, than the traditional Bayesian model.\nChristensen doesn't appear to take this as any kind of *objection* to\nBayesianism, and I think this is just the right attitude.\n\nBut just as the static Keynesian is more general than the Bayesian\nmodel, there are bound to be interesting models that are more general\nthan the static Keynesian model. One such model is what I call the\n*dynamic* Keynesian model. This model has been used by Seth Yalcin to\nexplicate some interesting semantic theories, but to the best of my\nknowledge it has not been used for epistemological purposes before. That\nshould change. The model is like the static Keynesian model in its use\nof representors, but it changes the way updating is modelled. When an\nagent with representor *R* receives evidence *E*, she should update her\nrepresentor by a two step process.\n\n-   Replace *R* with U(*R*, *E*)\n\n-   Conditionalise U(*R*, *E*), i.e. replace it with {*Pr*( *E*): *Pr*\n    is in U(*R*, *E*)}\n\nIn this story, U is a function that takes two inputs: a representor and\na piece of evidence, and returns a representor that is a subset of the\noriginal representor. Intuitively, this models the effect of learning,\nvia getting evidence *E*, what evidential relationships obtain. In the\nstatic Keynesian model, it is assumed that before the agent receives\nevidence *E*, she could already say which propositions would receive\nprobabilistic support from *E*. All of the relations of evidential\nsupport were encoded in her conditional probabilities. There is no place\nin the model for learning about fundamental evidential relationships. In\nthe dynamic Keynesian model, this is possible. When the agent receives\nevidence *E*, she might learn that certain functions that were\npreviously in her representor misrepresented the relationship between\nevidence and hypotheses, particularly between evidence *E* and other\nhypotheses. In those cases, U(*R*, *E*) will be her old representor *R*,\nminus the functions that *E* teaches her misrepresent these evidential\nrelationships.\n\nThe dynamic Keynesian model seems well suited to the dogmatist, indeed\nto any epistemological theory that allows for fundamental evidential\nrelationships to be only knowable a posteriori. As we'll see below, this\nis a reason to stop here in the presentation of the model and not try\nand say something systematic about the behaviour of U. Instead of\ndeveloping the model by saying more about *U*, we should assess it,\nwhich is what I'll do next.\n\n## In Defence of Dynamism\n\nIn this section I want go over three benefits of the dynamic Keynesian\nmodel, and then say a little about how it relates to the discussion of\nscepticism with which we opened. I'm not going to say much about\npossible objections to the use of the model. That's partially for space\nreasons, partially because what I have to say about the objections I\nknow of is fairly predictable, and partially because the model is new\nenough that I don't really know what the strongest objections might be.\nSo here we'll stick to arguments for the view.\n\n### The Dogmatist and the Keynesian\n\nThe first advantage of the dynamic Keynesian model is that because it\ndoes not verify [Lower]{.smallcaps}, it is consistent with dogmatism.\nNow if you think that dogmatism is obviously false, you won't think this\nis much of an advantage. But I tend to think that dogmatism is one of\nthe small number of not absurd solutions to a very hard epistemological\nproblem with no obvious solution, so we should not rule it out\npre-emptively. Hence I think our formal models should be consistent with\nit. What is tricky is proving that the dynamic Keynesian model is indeed\nconsistent with it.\n\nTo see whether this is true on the dynamic Keynesian model, we need to\nsay what it is to *lower* the credence of some proposition. Since\nrepresentors map propositions onto intervals rather than numbers, we\ncan't simply talk about one 'probability' being a smaller number than\nanother.[^5] On the static Keynesian model, the most natural move is to\nsay that conditionalisation on *E* *lowers* the credence of *p* iff for\nall *Pr* in the representor, *Pr*(*p*) \\> *Pr*(*p*  *E*). This implies\nthat if every function in the representor says that *E* is negatively\nrelevant to *p*, then conditionalising on *E* makes *p* less probable.\nImportantly, it allows this even if the values that *Pr*(*p*) takes\nacross the representor before and after conditionalisation overlap. So\nwhat should we say on the dynamic Keynesian model? The weakest approach\nthat seems viable, and not coincidentally the most plausible approach,\nis to say that updating on *E* lowers the credence of *p* iff the\nfollowing conditions are met:\n\n-   For all *Pr* in U(*R*, *E*), *Pr*(*p* *E*) \\< *Pr*(*p*)\n\n-   For all *Pr* in *R* but not in U(*R*, *E*), there is a *Pr*$^\\prime$\n    in U(*R*, *E*) such that *Pr*$^\\prime$(*p*  *E*) \\< *Pr*(*p*)\n\nIt isn't too hard to show that for some models, updating on *E* does not\nlower the credence of *E* ${\\supset}$ *H*, if lowering is understood\nthis way. The following is an extreme example, but it suffices to make\nthe logical point. Let *R* be the minimal representor, the set of all\nprobability functions that assign probability 1 to a priori certainties.\nAnd let U(*R*, *E*) be the singleton of the following probability\nfunction, defined only over Boolean combinations of *E* and *H*:\n*Pr*(*E* ${\\wedge}$ *H*) = *Pr*(*E* ${\\wedge}$ ${\\lnot}$*H*) =\n*Pr*(${\\lnot}$*E* ${\\wedge}$ *H*) =\n*Pr*(${\\lnot}$*E* ${\\wedge}$ ${\\lnot}$*H*) = $\\frac{1}{4}$. Then the\nprobability of *E* ${\\supset}$ *H* after updating is $\\frac{3}{4}$.\n(More precisely, according to all *Pr* in U(*R*, *E*),\n*Pr*(*E* ${\\supset}$ *H*) = $\\frac{3}{4}$.) Since before updating there\nwere *Pr* in *R* such that *Pr*(*E* ${\\supset}$ *H*) \\< $\\frac{3}{4}$,\nin fact there were *Pr* in *R* such that *Pr*(*E* ${\\supset}$ *H*) = 0,\nupdating on *E* did not *lower* the credence of *E* ${\\supset}$ *H*. So\nthe dynamic Keynesian model does not, in general, have as a consequence\nthat updating on *E* lowers the credence of *E* ${\\supset}$ *H*. This\nsuggests that [Lower]{.smallcaps} in general is not true.\n\nIt might be objected that if evidence *E* supports our knowledge that\n*E* ${\\supset}$ *H*, then updating on *E* should *raise* the credence of\n*E* ${\\supset}$ *H*. And if we define credence raising the same way we\njust defined credence lowering, updating on *E* *never* raises the\ncredence of *E* ${\\supset}$ *H*. From a Keynesian perspective, we should\nsimply deny that evidence has to raise the credence of the propositions\nknown on the basis of that evidence. It might be sufficient that getting\nthis evidence removes the uncertainty associated with those\npropositions. Even on the static Keynesian model, it is possible for\nevidence to remove uncertainty related to propositions without raising\nthe probability of that proposition. A little informally, we might note\nthat whether an agent with representor *R* is sufficiently confident in\n*p* to know that *p* depends on the lowest value that *Pr*(*p*) takes\nfor *Pr* ${\\in}$ *R*, and updating can raise the value of this 'lower\nbound' without raising the value of *Pr*(*p*) according to all functions\nin *R*, and hence without strictly speaking *raising* the credence of\n*p*.\n\nThe above illustration is obviously unrealistic, in part because U could\nnot behave that way. It's tempting at this stage to ask just how U does\nbehave so we can work out if there are more realistic examples. Indeed,\nit's tempting to try to attempt to provide a formal description of U.\nThis temptation should be resisted. The whole point of the model is that\nwe can only learn which hypotheses are supported by certain evidence by\nactually getting that evidence. If we could say just what U is, we would\nbe able to know what was supported by any kind of evidence without\ngetting that evidence. The best we can do with respect to U is to\ndiscover some of its contours with respect to evidence much like our\nown. And the way to make those discoveries will be to do scientific and\nepistemological research. It isn't obvious that, say, looking for nice\nformal properties of U will help at all.\n\n### The Problem of the Priors\n\nOne really nice consequence of the dynamic Keynesian approach is that it\nlets us say what the representor of an agent with no empirical\ninformation should be. Say a proposition is *a priori certain* iff it is\na priori that all rational agents assign credence 1 to that proposition.\nThen the representor of the agent with no empirical evidence is {*Pr*:\n${\\forall}$*p*: If *p* is a priori certain, then *Pr*(*p*) = 1}. This is\nthe minimal representor I mentioned above. Apart from assigning\nprobability 1 to the a priori certainties, the representor is silent.\nHence it treats all propositions that are not a priori certain in\nexactly the same way. This kind of symmetric treatment of propositions\nis not possible on the traditional Bayesian conception for logical\nreasons. (The reasons are set out in the various discussions of the\nparadoxes of indifference, going back to @Bertrand1888.) Such a prior\nrepresentor is consistent with the static Keynesian approach, but it\nyields implausible results, since conditionalising on *E* has no effect\non the distribution of values of Pr(*p*) among functions in the\nrepresentor for any *p* not made a priori certain by *E*. (We'll say *p*\nis made a priori certain by *E* iff *E* ${\\supset}$ *p* is a priori\ncertain.) So if this is our starting representor, we can't even get\nprobabilistic evidence for things that are not made certain by our\nevidence.[^6] So on the static Keynesian model, this attractively\nsymmetric prior representor is not available.\n\nI think one of the motivations of anti-dogmatist thinking is the thought\nthat we *should* be able to tell a priori what is evidence for what. If\nit looking like there is a cow in front of us is a reason to think there\nis a cow in front of us, that should be knowable a priori. I think the\nmotivation for this kind of position shrinks a little when we realise\nthat an a priori prior that represented all the connections between\nevidence and hypotheses would have to give us a lot of guidance as to\nwhat to do (epistemically speaking) in worlds quite unlike our own.\nMoreover, there is no reason we should have lots that information. So\nconsider, for a minute, a soul in a world with no spatial dimensions and\nthree temporal dimensions, where the primary source of evidence for\nsouls is empathic connection with other souls from which they get a\n(fallible) guide to those souls' mental states. When such a soul\nconditionalises on the evidence \"A soul seems to love me\" (that's the\nkind of evidence they get) what should their posterior probability be\nthat there is indeed a soul that loves them? What if the souls have a\nvery alien mental life, so they instantiate mental concepts very unlike\nour own, and souls get fallible evidence of these alien concepts being\ninstantiated through empathy? I think it's pretty clear we *don't* know\nthe answers to these questions. (Note that to answer this question we'd\nhave to know which of these concepts were grue-like, and which were\nprojectable, and there is no reason to believe we are in a position to\nknow that.) Now those souls are presumably just as ignorant about the\nepistemologically appropriate reaction to the kinds of evidence we get,\nlike seeing a cow or hearing a doorbell, as we are about their evidence.\nThe dynamic Keynesian model can allow for this, especially if we use the\nvery weak prior representor described above. When we get the kind of\nevidence we actually get, the effect of U is to shrink our representors\nto sets of probability functions which are broadly speaking\nepistemically appropriate for the kind of world we are in. Before we got\nthat evidence, we didn't know how we should respond to it, just like the\nspaceless empathic souls don't know how to respond to it, just like we\ndon't know how to respond to their evidence.\n\nIt is a commonplace observation that (a) prior probabilities are really\ncrucial in Bayesian epistemology, but (b) we have next to no idea what\nthey look like. I call this the problem of the priors, and note with\nsome satisfaction that the dynamic Keynesian model avoids it. Now a\ncynic might note that all I've done is replace a hand-wavy story about\npriors with a hand-wavy story about updating. That's true, but\nnevertheless I think this is progress. The things I'm being deliberately\nunclear about, such as what U should look like for *E* such as \"Some\nother non-spatial tri-temporal soul seems to love me\" are things that\n(a) my theory says are not a priori knowable, and (b) I don't have any\nevidence concerning. So it isn't surprising that I don't have much to\nsay about them. It isn't clear that the traditional Bayesian can offer\nany story, even by their own lights, as to why they are less clear about\nthe structure of the prior probability conditional on such an *E*.\n\n### The Problem of Old Evidence\n\nWhen we get evidence *E*, the dynamic Keynesian model says that we\nshould do two things. First, we should throw out some probability\nfunctions in our representor. Second, we should conditionalise those\nthat remain. But this is a normative condition, not a description of\nwhat actually happens. Sometimes, when we get evidence *E*, we may not\nrealise that it is evidence that supports some theory *T*. That is, we\nwon't sufficiently cull the representor of those probability functions\nwhere the probability of *T* given *E* is not high. Housecleaning like\nthis is hard, and sometimes we only do it when it becomes essential. In\nthis case, that means we only do it when we start paying serious\nattention to *T*. In that case we may find that evidence *E*, evidence\nwe've already incorporated, in the sense of having used in\nconditionalisation, gives us reason to be more confident than we were in\n*T*. In such a case we'll simply cull those functions where probability\nof *T* given *E* is not high, and we will be more confident in *T*.\nThat's how old evidence can be relevant on the dynamic Keynesian model.\nSince we have a story about how old evidence can be relevant, there is\nno problem of old evidence for the dynamic Keynesian.\n\nFamously, there *is* a problem of old evidence for traditional\nBayesians. Now I'm not going to rehearse all the arguments concerning\nthis problem to convince you that this problem hasn't been solved.\nThat's in part because it would take too long and in part because I'm\nnot sure myself that it hasn't been solved. But I will note that if you\nthink the problem of old evidence *is* a live problem for traditional\nBayesians, then you have a strong reason for taking the dynamic\nKeynesian model seriously.\n\n### Why Should We Care?\n\nThe sceptic's opening move was to appeal to our intuition that\npropositions like *E* ${\\supset}$ *H* are unknowable. We then asked what\nreasons we could be given for accepting this claim, because the sceptic\nseems to want to derive quite a lot from a raw intuition. The sceptic\ncan respond with a wide range of arguments, four of which are mentioned\nabove. Here we focussed on the sceptic's argument from exhaustion.\n*E* ${\\supset}$ *H* isn't knowable a priori, because it could be false,\nand it isn't knowable a posteriori, because, on standard models of\nlearning, our evidence *lowers* its credibility. My response is to say\nthat this is an artefact of the model the sceptic (along with everyone\nelse) is using. There's nothing wrong with using simplified models, in\nfact it is usually the only way to make progress, but we must be always\nwary that our conclusions transfer from the model to the real world. One\nway to argue that a conclusion is a mere artefact of the model is to\ncome up with a model that is sensitive to more features of reality in\nwhich the conclusion does not hold. That's what I've done here. The\ndynamic Keynesian model is sensitive to the facts that (a) there is a\ndistinction between risk and uncertainty and (b) we can learn about\nfundamental evidential connections. In the dynamic Keynesian model, it\nisn't true that our evidence lowers the probability of\n*E* ${\\supset}$ *H*. So the anti-sceptic who says that\n*E* ${\\supset}$ *H* is knowable a posteriori, the person I've called the\ndogmatist, has a defence against this Bayesian argument. If the response\nis successful, then there may well be other applications of the dynamic\nKeynesian model, but for now I'm content to show how the model can be\nused to defend the dogmatic response to scepticism.\n\n[^1]: Perhaps not a wise assumption around here, but one that I'll make\n    throughout in what follows.\n\n[^2]: Again, the proof uses distinctively classical principles, in\n    particular the equivalence of A with (A ${\\wedge}$ B) ${\\vee}$ (A\n    ${\\wedge}$ ${\\lnot}$B.) But I will take classical logic for granted\n    throughout. David Jehle pointed out to me that the proof fails\n    without this classical assumption.\n\n[^3]: Roger @White2006 and Stewart @Cohen2005 endorse probabilistic\n    arguments against people who are, in my sense, dogmatists. John\n    @Hawthorne2002 also makes a similar argument when arguing that\n    certain conditionals, much like E ${\\supset}$ H, are a priori.\n\n[^4]: The clearest statement of the distinction that I know is from that\n    paper.\n\n    > By 'uncertain' knowledge, let me explain, I do not mean merely to\n    > distinguish what is known for certain from what is only probable.\n    > The game of roulette is not subject, in this sense, to\n    > uncertainty; nor is the prospect of a Victory bond being drawn.\n    > Or, again, the expectation of life is only slightly uncertain.\n    > Even the weather is only moderately uncertain. The sense in which\n    > I am using the term is that in which the prospect of a European\n    > war is uncertain, or the price of copper and the rate of interest\n    > twenty years hence, or the obsolescence of a new invention, or the\n    > position of private wealth owners in the social system in 1970.\n    > About these matters there is no scientific basis on which to form\n    > any calculable probability whatever. We simply do not know.\n    > Nevertheless, the necessity for action and decision compels us as\n    > practical men to do our best to overlook this awkward fact and to\n    > behave exactly as we should if we had behind us a good Benthamite\n    > calculation of a series of prospective advantages and\n    > disadvantages, each multiplied by its appropriate probability,\n    > waiting to be summed. [@Keynes1937 114-5]\n\n[^5]: Strictly speaking, the story I've told so far does not guarantee\n    that for any proposition *p*, the values that Pr(*p*) takes (for Pr\n    in the representor) form an interval. But it is usual in more\n    detailed presentations of the model to put constraints on the\n    representor to guarantee that happens, and I'll assume we've done\n    that.\n\n[^6]: The argument in the text goes by a little quickly, because I've\n    defined representors in terms on unconditional probabilities and\n    this leads to complications to do with conditionalising on\n    propositions of zero probability. A better thing to do, as suggested\n    by @Hajek2003, is to take conditional probability as primitive. If\n    we do this we'll define representors as sets of conditional\n    probability functions, and the a priori representor will be {Pr: If\n    *p* ${\\supset}$ *q* is a priori certain, then Pr(*q* *p*) = 1}. Then\n    the claim in the text will follow.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}