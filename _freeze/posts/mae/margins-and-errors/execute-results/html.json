{
  "hash": "18f144d9130a88e0ebeaf114c2a3a7f7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Margins and Errors\"\ndescription: |\n  Timothy Williamson has argued that cases involving fallible measurement show that knowledge comes apart from justified true belief in ways quite distinct from the familiar ‘double luck’ cases. I start by describing some assumptions that are necessary to generate Williamson's conclusion, and arguing that these assumptions are well justified. I then argue that the existence of these cases poses problems for theorists who suppose that knowledge comes apart from justified true belief only in a well defined class of cases. I end with some general discussion of what we can know on the basis of imperfect measuring devices.\ndate: April 25 2013\nauthor:\n  - name: Brian Weatherson \n    url: http://brian.weatherson.org\n    affiliation: University of Michigan\n    affiliation_url: https://umich.edu\n    orcid_id: 0000-0002-0830-141X\ndoi: \"10.1080/0020174X.2013.775015\"\ncategories:\n  - epistemology\ncitation_url: https://doi.org/10.1080/0020174X.2013.775015\njournal:\n    title: \"Inquiry\"\n    publisher: \"Taylor and Francis\"\nvolume: 56\nnumber: 1\ncitation: false\nbibliography: ../../../articles/Rbib.bib\nself-contained: false\npreview: measurement.jpg\noutput:\n  distill::distill_article:\n    toc: true\n    toc_depth: 3\n    number_sections: true\n---\n\n\nRecently, Timothy @WilliamsonLofoten has argued that considerations\nabout margins of errors can generate a new class of cases where agents\nhave justified true beliefs without knowledge. I think this is a great\nargument, and it has a number of interesting philosophical conclusions.\nIn this note I'm going to go over the assumptions of Williamson's\nargument. I'm going to argue that the assumptions which generate the\njustification without knowledge are true. I'm then going to go over some\nof the recent arguments in epistemology that are refuted by Williamson's\nwork. And I'm going to end with an admittedly inconclusive discussion of\nwhat we can know when using an imperfect measuring device.\n\n<aside>\nPublished in _Inquiry_ 56: 63-76.\n\nPicture by [docoverachiever](https://www.flickr.com/photos/90692748@N04) via [Creative Commons](https://search.creativecommons.org/photos/f4d370f5-23bc-4104-a35a-f92238a460d0).\n</aside>\n\n### Measurement, Justification and Knowledge\n\nWilliamson's core example involves detecting the angle of a pointer on a\nwheel by eyesight. For various reasons, I find it easier to think about\na slightly different example: measuring a quantity using a digital\nmeasurement device. This change has some costs relative to Williamson's\nversion -- for one thing, if we are measuring a quantity it might seem\nthat the margin of error is related to the quantity measured. If I\neyeball how many stories tall a building is, my margin of error is 0 if\nthe building is 1-2 stories tall, and over 10 if the building is as tall\nas the World Trade Center. But this problem is not as pressing for\ndigital devices, which are often very *unreliable* for small quantities.\nAnd, at least relative to my preferences, the familiarity of quantities\nmakes up for the loss of symmetry properties involved in angular\nmeasurement.\n\nTo make things explicit, I'll imagine the agent $S$ is using a digital\nscale. The scale has a **margin of error** $m$. That means that if the\nreading, i.e., the **apparent mass** is $a$, then the agent is justified\nin believing that the mass is in $[a-m, a+m]$. We will assume that $a$\nand $m$ are luminous; i.e., the agent knows their values, and knows she\nknows them, and so on. This is a relatively harmless idealisation for\n$a$; it is pretty clear what a digital scale reads.[^1] It is a somewhat\nless plausible assumption for $m$. But we'll assume that $S$ has been\nvery diligent about calibrating her scale, and that the calibration has\nbeen recently and skillfully carried out, so in practice $m$ can be\nassessed very accurately.\n\nWe'll make three further assumptions about $m$ that strike me as\nplausible, but which may I guess be challenged. I need to be a bit\ncareful with terminology to set out the first one. I'll use $V$ and $v$\nas variables that both pick out the **true value** of the mass. The\ndifference is that $v$ picks it out rigidly, while $V$ picks out the\nvalue of the mass in any world under consideration. Think of $V$ as\nshorthand for *the mass of the object* and $v$ as shorthand for *the\nactual mass of the object*. (More carefully, $V$ is a *random* variable,\nwhile $v$ is a standard, rigid, variable.) Our first assumption then is\nthat $m$ is also related to what the agent can know. In particular,\nwe'll assume that if the reading $a$ equals $v$, then the agent can know\nthat $V \\in [a-m, a+m]$, and can't know anything stronger than that.\nThat is, the margin of error for justification equals, in the best case,\nthe margin of error for knowledge. The second is that the scale has a\nreadout that is finer than $m$. This is usually the case; the last digit\non a digital scale is often not significant. The final assumption is\nthat it is metaphysically possible that the scale has an error on an\noccasion that is greater than $m$. This is a kind of fallibilism\nassumption -- saying that the margin of error is $m$ does not mean there\nis anything incoherent about talking about cases where the error on an\noccasion is greater than $m$.\n\nThis error term will do a lot of work in what follows, so I'll use $e$\nto be the **error** of the measurement, i.e., $|a-v|$. For ease of\nexposition, I'll assume that $a \\geq v$, i.e., that any error is on the\nhigh side. But this is entirely dispensible, and just lets me drop some\ndisjunctions later on.\n\nNow we are in a position to state Williamson's argument. Assume that on\na particular occasion, $0 < e < m$. Perhaps $v = 830, m =10$ and\n$a = 832$, so $e = 2$. Williamson appears to make the following two\nassumptions.[^2]\n\n1.  The agent is justified in believing what they would know if\n    appearances matched reality, i.e., if $V$ equalled $a$.\n\n2.  The agent cannot come to know something about $V$ on the basis of a\n    suboptimal measurement that they could not also know on the basis of\n    an optimal measurement.\n\nI'm assuming here that the optimal measurement displays the correct\nmass. I don't assume the actual measurement is *wrong*. That would\nrequire saying something implausible about the semantic content of the\ndisplay. It's not obvious that the display has a content that could be\ntrue or false, and if it does have such a content it might be true. (For\ninstance, the content might be that the object on the scale has a mass\nnear to $a$, or that with a high probability it has a mass near to $a$,\nand both of those things are true.) But the optimal measurement would be\nto have $a = v$, and in this sense the measurement is suboptimal.\n\nThe argument then is pretty quick. From the first assumption, we get\nthat the agent is justified in believing that $V \\in [a - m, a + m]$.\nAssume then that the agent forms this justified belief. This belief is\nincompatible with $V \\in [v - m, a - m)$. But if $a$ equalled $v$, then\nthe agent wouldn't be in a position to rule out that\n$V \\in [v - m, a - m)$. So by premise 2 she can't knowledgeably rule it\nout on the basis of a mismeasurement. So her belief that $V \\geq a - m$\ncannot be knowledge. So this justified true belief is not knowledge.\n\nIf you prefer doing this with numbers, here's the way the example works\nusing the numbers above. The mass of the object is 830. So if the\nreading was correct, the agent would know just that the mass is between\n820 and 840. The reading is 832. So she's justified in believing, and\nwe'll assume she does believe, that the mass is between 822 and 842.\nThat belief is incompatible with the mass being 821. But by premise 2\nshe can't know the mass is greater than 821. So the belief doesn't\namount to knowledge, despite being justified and, crucially, true. After\nall, 830 is between 822 and 842, so her belief that the mass is in this\nrange is true. So simple reflections on the workings on measuring\ndevices let us generate cases of justified true beliefs that are not\nknowledge.\n\nI'll end this section with a couple of objections and replies.\n\n*Objection*: The argument that the agent can't know that\n$V \\in [a - m, a + m]$ is also an argument that the argument can't\njustifiably believe that $V \\in [a - m, a + m]$. After all, why should\nit be possible to get justification from a suboptimal measurement when\nit isn't possible to get the same justification from an optimal\nmeasurement?\n\n*Reply*: It is possible to have justification to believe an outright\nfalsehood. It is widely believed that you can have justification even\nwhen none of your evidential sources are even approximately accurate\n[@Cohen1984]. And even most reliabilists will say that you can have\nfalse justified beliefs if you use a belief forming method that is\nnormally reliable, but which badly misfires on this occasion. In such\ncases we clearly get justification to believe something from a\nmismeasurement that we wouldn't get from a correct measurement. So the\nobjection is based on a mistaken view of justification.\n\n*Objection*: Premise 2 fails in cases using random sampling. Here's an\nillustration. An experimenter wants to know what percentage of $F$s are\n$G$. She designs a survey to ask people whether they are $G$. The survey\nis well designed; everyone gives the correct answer about themselves.\nAnd she designs a process for randomly sampling the $F$s to get a good\nrandom selection of 500. It's an excellent process; every $F$ had an\nequal chance of being selected, and the sample fairly represents the\ndifferent demographically significant subgroups of the $F$s. But by the\nnormal processes of random variation, her group contains slightly more\n$G$s than the average. In her survey, 28% of people said (truly!) that\nthey were $G$, while only 26% of $F$s are $G$s. Assuming a margin of\nerror in such a study of 4%, it seems plausible to say she knows that\nbetween 25 and 32% of $F$s are $G$s. But that's not something she could\nhave known the survey had come back correctly reporting that 26% of $F$s\nare $G$s.\n\n*Reply*: I think the core problem with this argument comes in the last\nsentence. A random survey isn't, in the first instance, a measurement of\na population. It's a measurement of those surveyed, from which we draw\nextrapolations about the population. In that sense, the only\n*measurement* in the imagined example was as good as it could be; 28% of\nsurveyed people are in fact $G$. So the survey was correct, and it is\nfine to conclude that we can in fact know that between 24 and 32 percent\nof $F$s are $G$s.\n\nThere are independent reasons for thinking this is the right way to talk\nabout the case. If a genuine measuring device, like a scale, is off by a\nsmall amount, we regard that as a reason for tinkering with the device,\nand trying to make it more accurate. That's one respect in which the\nmeasurement is suboptimal, even if it is correct within the margin of\nerror. This reason to tinker with the scale is a reason that often will\nbe outweighed. Perhaps it is technologically infeasible to make the\nmachine more accurate. More commonly, the only way to guarantee greater\naccuracy would be more cost and hassle than it is worth. But it remains\na reason. The fact that this experiment came out with a deviation\nbetween the sample and the population is *not* a reason to think that it\ncould have been run in a better way, or that there is some reason to\nimprove the survey. That's just how random sampling goes. If it were a\ngenuine measurement of the population, the deviation between the\n'measurement' and what is being measured would be a reason to do things\ndifferently. There isn't any such reason, so the sample is not truly a\nmeasurement.\n\nSo I don't think this objection works, and I think the general principle\nthat you can't get extra knowledge from a suboptimal measurement is\nright. But note also that we don't need this general principle to\nsuggest that there will be cases of justified true belief without\nknowledge in the cases of measurement. Consider a special case where $e$\nis just less than $m$. For concreteness, say $a = v + 0.95m$, so\n$e = 0.95m$. Now assume that whatever is justifiedly truly believed in\nthis case is known, so $S$ knows that $V \\in [a - m, a + m]$. That is,\n$S$ knows that $V \\in [v - 0.05m, a + m]$.\n\nWe don't need any principles about measurement to show this is false;\nsafety considerations will suffice. @Williamson2000-WILKAI says that a\nbelief that $p$ is safe only if $p$ is true in all nearby worlds. But\ngiven how close $v$ is to the edge of the range $[v - 0.05m, a + m]$.\nRival conceptions of safety don't help much more than this. The most\nprominent of these, suggested by @Sainsbury1996, says that a belief is\nsafe only if the method that produced it doesn't produce a false belief\nin any nearby world. But if the scale was off by $0.95m$, it could have\nbeen off by $1.05m$, so that condition fails too.\n\nI don't want the last two paragraphs to leave too concessive an\nimpression. I think the objection fails because it relies on a\nmisconception of the notion of measurement. But I think that even if the\nobjection works, we can get a safety based argument that some\nmeasurement cases will produce justified true beliefs without knowledge.\nAnd that will matter for the argument of the next two sections.\n\n### The Class of Gettier Cases is Disjunctive\n\nThere's an unfortunate terminological confusion surrounding gaps between\nknowledge and justification. Some philosophers use the phrase 'Gettier\ncase' to describe any case of a justified true belief that isn't\nknowledge. Others use it to describe just cases that look like the cases\nin @Gettier1963, i.e., cases of true belief derived from justified false\nbelief. I don't particularly have strong views on whether either of\nthese uses is *better*, but I do think it is important to keep them\napart.\n\nI'll illustrate the importance of this by discussing a recent argument\ndue to Jeremy Fantl and Matthew McGrath [@FantlMcGrath2009 Ch. 4]. I've\npreviously discussed this argument [@Weatherson2011-WEAKBI], but I don't\nthink I quite got to the heart of why I don't like the kind of reasoning\nthey are using.\n\nThe argument concerns an agent, call her $T$, who has the following\nunfortunate combination of features. She is very confident that $p$. And\nwith good reason; her evidence strongly supports $p$. For normal\nreasoning, she takes $p$ for granted. That is, she doesn't distinguish\nbetween $\\varphi$ is best given $p$, and that $\\varphi$ is simply best.\nAnd that's right too, given the strong evidence that $p$. But she's not\ncrazy. Were she to think that she was facing a bet on extreme odds\nconcerning $p$, she would cease taking $p$ for granted, and revert to\ntrying to maximise expected value given the high probability that $p$.\nBut she doesn't think any such bet is salient, so her disposition to\nretreat from $p$ to *Probably p* has not been triggered. So far, all is\ngoing well. I'm inclined to say that this is enough to say that $T$\njustifiedly believes that $p$. She believes that $p$ in virtue of the\nfact that she takes $p$ for granted in actual reasoning.[^3] She's\ndisposed to stop doing so in some circumstances, but until that\ndisposition is triggered, she has the belief. And this is the right way\nto act given her evidence, so her belief is justified. So far, so good.\n\nUnfortunately, $T$ really does face a bet on long odds about $p$. She\nknows she has to choose between $\\varphi$ and $\\psi$. And she knows that\n$\\varphi$ will produce the better outcome iff $p$. But she thinks the\namount she'll gain by choosing $\\psi$ if $\\neg p$ is roughly the same as\nthe amount she'll gain by choosing $\\varphi$ if $p$. That's wrong, and\nher evidence clearly shows it is wrong. If $p$ is false, then $\\varphi$\nwill be *much* worse than $\\psi$. In fact, the potential loss here is so\ngreat that $\\psi$ has the greater expected value given the correct\nevidential probability of $p$. I think that means she doesn't know that\n$p$. Someone who knows that $p$ can ignore $\\neg p$ possibilities in\npractical reasoning. And someone who could ignore $\\neg p$ possibilities\nin practical reasoning would choose $\\varphi$ over $\\psi$, since it is\nbetter if $p$. But $T$ isn't in a position to make that choice, so she\ndoesn't know that $p$.\n\n(I've said here that $T$ is wrong about the costs of choosing $\\varphi$\nif $p$, and her evidence shows she is wrong. In fact I think she doesn't\nknow $p$ if either of those conditions obtain. But here I only want to\nuse the weaker claim that she doesn't know $p$ if both conditions\nobtain.)\n\nFantl and McGrath agree about the knowledge claim, but disagree about\nthe justified belief claim. They argue as follows (this is my version of\nthe 'Subtraction Argument' from page 97 of their book).\n\n1.  $T$ is justfied in choosing $\\varphi$ iff she knows that $p$.\n\n2.  Whether $T$'s belief that $p$ is true is irrelevant to whether she\n    is justified in choosing $\\varphi$.\n\n3.  Whether $T$'s belief that $p$ is 'Gettiered' is irrelevant to\n    whether she is justified in choosing $\\varphi$.\n\n4.  Knowledge is true, justified, UnGettiered belief.\n\n5.  So $T$ is justfied in choosing $\\varphi$ iff she is justified in\n    believing that $p$.\n\n6.  $T$ is not justified in choosing $\\varphi$.\n\n7.  So $T$ is not justified in believing that $p$.\n\nI think this argument is only plausible if we equivocate on what it is\nfor a belief to be 'Gettiered'.\n\nAssume first that 'Gettiered' means 'derived from a false intermediate\nstep'. Then premise 4 is false, as Williamson's example shows. $S$ has a\njustified true belief that is neither knowledge nor derived from a false\npremise.\n\nAssume then that 'Gettiered' simply means that the true belief is\njustified without being known. In that case we have no reason to accept\npremise 3. After all, the class of true justified beliefs that are not\nknowledge is pretty open ended. Before reading Williamson, we may not\nhave thought that this class included the beliefs of agents using\nmeasuring devices that were functioning properly but imperfectly. But it\ndoes. Prior to the end of epistemology, we simply don't know what other\nkind of beliefs might be in this class. There's no way to survey all the\nways for justification to be insufficient for knowledge, and see if all\nof them are irrelevant to the justification for action. I think one way\na justified belief can fall short of knowledge is if it is tied up with\nfalse beliefs about the stakes of bets. It's hard to say that that is\nirrelevant to the justification of action.\n\nIt is by now reasonably well known that logical subtraction is a very\nmessy and complicated business. See, for instance, @Humberstone2000 for\na clear discussion of the complications. In general, unless it is\nanalytic that $F$s are $G$s and $H$s, for some antecedently understood\n$G$ and $H$, there's nothing interesting to say about the class of\nthings that are $G$ but not $F$. It will just be a disjunctive shambles.\nThe same is true for knowledge and justification. The class of true\nbeliefs that are justified but not known is messy and disjunctive. We\nshouldn't expect to have any neat way of overviewing it. That in part\nmeans we can't say much interesting about it as a class, contra premise\n3 in the above argument. It also means the prospects for 'solving the\nGettier problem' are weak. We'll turn to that issue next.\n\n### There is No Solution to the Gettier Problem\n\nThe kind of example that Edmund @Gettier1963 gives to refute the\njustified true belief theory of knowledge has what Linda Zagzebski\n[-@Zagzebski2009 117] aptly calls a \"double luck\" structure. In\nGettier's original cases, there's some bad luck that leads to a\njustified belief being false. But then there's some good luck that leads\nto an inference from that being true. As was quickly realised in the\nliterature, the good and bad luck doesn't need to apply to separate\ninferential steps. It might be that the one belief that would have been\nfalse due to bad luck also ends up being true due to good luck.\n\nThis has led to a little industry, especially in the virtue epistemology\nsection of the market, of attempts to \"solve the Gettier problem\" by\nadding an anti-luck condition to justification, truth and belief and\nhoping that the result is something like an analysis of knowledge. As\n@Zagzebski1994 showed, this can't be an *independent* condition on\nknowledge. If it doesn't entail truth, then we will be able to recreate\nthe Gettier cases. But maybe a 'fourth' condition that entails truth\n(and perhaps belief) will suffice. Let's quickly review some of these\nproposals.\n\nSo @Zagzebski1996 suggested that the condition is that the belief be\ntrue *because* justified. John @Greco2010 says that the extra condition\nis that the beliefs be \"intellectually creditable\". That is, the primary\nthat the subject ended up with a true belief is that it was the result\nof her reliable cognitive faculties. Ernest @Sosa2007 said that\nknowledge is belief that is true because it manifests intellectual\ncompetence. John @Turri2011 says that knowledge is belief the truth of\nwhich is a manifestation of the agent's intellectual competence.\n\nIt should be pretty clear that no such proposal can work if what I've\nsaid in earlier sections is remotely right. Assume again that\n$v = 830, a = 832$ and $m = 10$. The agent believes that\n$V \\in [822, 842]$. This belief is, we've said, justified and true. Does\nit satisfy these extra conditions?\n\nMy short answer is that it does. My longer answer is that it does if any\nbelief derived from the use of a measuring device does, and since some\nbeliefs derived from the use of measuring devices amount to knowledge,\nthe epistemologists are committed to the belief satisfying the extra\ncondition. Let's go through those arguments in turn.\n\nIn our story, $S$ demonstrates a range of intellectual competencies. She\nuses a well-functioning measuring device. It is the right kind of device\nfor the purpose she is using. By hypothesis, she has had the machine\ncarefully checked, and knows exactly the accuracy of the machine. She\ndoesn't form any belief that is too precise to be justified by the\nmachine. And she ends up with a true belief precisely because she has so\nmany competencies.\n\nNote that if we change the story so $a$ is closer to $v + m$, the case\nthat the belief is true in virtue of $S$ being so competent becomes even\nstronger. Change the case so that $a = 839$, and she forms the true\nbelief that $V \\in [829, 849]$. Now if $S$ had not been so competent,\nshe may have formed a belief with a tighter range, since she could\neasily have guessed that the margin of error of the machine is smaller.\nSo in this case the truth of the belief is very clearly due to her\ncompetence. But as we noted at the end of section 1, in the cases where\n$a$ is near $v + m$, the argument that we have justified true belief\nwithout knowledge is particularly strong. Just when the gap between\njustification and knowledge gets most pronounced, the competence based\napproach to knowledge starts to issue the strongest verdicts *in favour*\nof knowledge.\n\nBut maybe this is all a mistake. After all, the object doesn't have the\nmass it has because of $S$'s intellectual competence. The truth of any\nclaim about its mass is not because of $S$'s competence, or a\nmanifestation of that competence. So maybe these epistemologists get the\ncorrect verdict that $S$ does not know that $V \\in [a - m, a + m]$?\n\nNot so quick. Even had $a$ equalled $v$, all these claims would have\nbeen true. And in that case, $S$ would have known that $V$ was within\n$m$ of the measurement. What is needed for these epistemological\ntheories to be right is that there can be a sense that a belief that $p$\ncan be true in virtue of some cause $C$ without $C$ being a cause of\n$p$. I'm inclined to agree with the virtue epistemologists that such a\nsense can be given. (I think it helps to give up on content essentialism\nfor this project, as suggested by @David2002 and endorsed\nin@Weatherson2004-WEALMT.) But I don't think it will help. There's no\nreal way in which a belief is true because of competencies, or in which\nthe truth of a belief manifests competence, in the good case where\n$a = v$, but not in the bad cases, where $a$ is in $(0, m)$. These\nproposals might help with 'double luck' cases, but there is more to the\nspace between justification and knowledge than those cases. Of course, I\nthink the space in question includes some cases involving false beliefs\nabout the practical significance of $p$, but I don't expect everyone to\nagree with that. Happily, the Williamsonian cases should be less\ncontroversial.\n\n### What Can We Learn from Fallible Machines?\n\nMy presentation of Williamson's argument in section 1 abstracted away\nfrom several features of his presentation. In particular, I didn't make\nany positive assumption about what the agent can know when they find out\nthat the machine reads $a$. Williamson makes a suggestion, though he\noffers it more as the most internalist friendly suggestion than the most\nlikely correct hypothesis.\n\nThe suggestion, which I'll call the **Circular Reading Centred**\nhypothesis, is that the most the agent can know is that\n$V \\in [a - (e + m), a + (e + m)]$. That is, the agent can know that $V$\nis in a region centred on $a$, the 'radius' of which is the margin of\nerror $m$, plus the error on this occasion $e$. This is actually a quite\nattractive suggestion, though not the only suggestion we could make.\nLet's look through some other options and see how well they work.\n\nWe said above that the agent can't know more from a mismeasurement than\nthey can know from an accurate measurement. And we said that given an\naccurate measurement, the most they can know is that\n$V \\in [v - m, v + m]$. So here's one very restrictive suggestion: if\n$a \\in [v - m, v + m]$, then the agent can know that\n$V \\in [v - m, v + m]$. But we can easily rule that out on the basis of\nconsiderations about justification. The strongest proposition the agent\nis justified in believing is that $V \\in [a - m, a + m]$. If the agent\ncould know that $V \\in [v - m, v + m]$, then she could know that\n$V \\notin (v + m, a + m]$, even though she isn't justified in believing\nthis. This is absurd, so that proposal is wrong.\n\nWe now have two principles on the table: $S$ can't know anything by a\nmismeasurement that she knows on the basis of a correct measurement, and\nthat she can only know things she's justified in believing. The first\nprinciple implies that for all $x \\in [v - m, v + m]$, that $V = x$ is\nepistemically possible. The second implies that for all\n$x \\in [a -m, a + m]$, that $V = x$ is epistemically possible. Our next\nproposal is that the epistemic possibilities, given a reading of $a$,\nare just that $V \\in [v - m, v + m] \\cup [a - m, a + m]$.\n\nBut this is fairly clearly absurd too. Assume that $a > v + 2m$. This is\nunlikely, but as we said above not impossible. Now consider the\nhypothesis that $V \\in (v + m, a - m)$. On the current hypothesis, this\nwould be ruled out. That is, she would know it doesn't obtain. But this\nseems bizarre. There are epistemic possibilities all around it, but\nsomehow she's ruled out this little gap, and done so on the basis of a\nhorrifically bad measurement.\n\nThis suggests two other approaches that are consistent with the two\nprinciples, and which do not have such an odd result. I'll list them\nalongside the proposal we mentioned earlier.\n\nCircular Appearance Centred\n\n:   The strongest proposition the agent can know is that\n    $V \\in [a - (e + m), a + (e + m)]$.\n\nCircular Reality Centred\n\n:   The strongest proposition the agent can know is that\n    $V \\in [v - (e + m), v + (e + m)]$.\n\nElliptical\n\n:   The strongest proposition the agent can know is that\n    $V \\in [v - m, a + m]$.\n\nThe last proposal is called **Elliptical** because it in effect says\nthat there are two foci for the range of epistemic possibilities. The\nagent can't rule out anything within $m$ of the true value, or anything\nwithin $m$ of the apparent value, or anything between those.\n\nActually we can motivate the name even more by considering a slight\ngeneralisation of the puzzle that we started with. Assume that $R$ is\ntrying to determine the location of an object in a two-dimensional\narray. As before, she has a digital measuring device, perhaps a GPS\nlocator trained on the object in question. And she knows that margin of\nerror of the device is $m$. The object is actually located at\n$\\langle x_v, y_v \\rangle$, and the device says it is at\n$\\langle x_a, y_a \\rangle$. So the epistemic possibilities, by the\nreasoning given above, should include the circles with radius $m$\ncentred on $\\langle x_v, y_v \\rangle$ and $\\langle x_a, y_a \\rangle$.\nCall these circles $C_v$ and $C_a$. Unless\n$\\langle x_v, y_v \\rangle= \\langle x_a, y_a \\rangle$, the union of these\ncircles will not be convex. If the distance between\n$\\langle x_v, y_v \\rangle$ and $\\langle x_a, y_a \\rangle$ is greater\nthan $2m$, the union won't even be connected. So just as we 'filled in'\nthe gap in the one-dimensional case, the natural thing to say is that\nany point in the convex hull of $C_v$ and $C_a$ is an epistemic\npossibility.\n\nBut now see what happens if we say those are all of the epistemic\npossibilities, i.e., that the agent knows that the true value lies in\nthe convex hull of the two circles. Here's what it might look like.\n\nNow consider the line from $\\langle x_v, y_v \\rangle$ to\n$\\langle x_a, y_a \\rangle$. No matter how bad the measurement is, the\nconvex hull of the two circles $C_v$ and $C_a$ will include no points\nmore than distance $m$ from the line between $\\langle x_v, y_v \\rangle$\nto $\\langle x_a, y_a \\rangle$. That is, the agent can know something\nsurprisingly precise about how close $V$ is to a particular line, even\non the basis of a catastrophically bad measurement.\n\nThere are some circumstances where this wouldn't be counterintuitive.\nAssume that $x_v = x_a$, while $y_v$ and $y_a$ are very very different.\nAnd assume further that $\\langle x_a, y_a \\rangle$ is calculated by\nusing two very different procedures for the $x$ and $y$ coordinates.\n(Much as sailors used to use very different procedures to calculate\nlongitude and latitude.) Then the fact that one process failed badly\ndoesn't, I think, show that we can't get fairly precise knowledge from\nthe other process.\n\nBut that's not the general case. If the machine determines\n$\\langle x_a, y_a \\rangle$ by a more holistic process, then a failure on\none dimension should imply that we get less knowledge on other\ndimensions, since it makes it considerably flukier that we got even one\ndimension right. So I think the space of epistemic possibilities, in a\ncase involving this kind of errant measurement, must be greater than the\nconvex hull of $C_v$ and $C_a$.\n\nFortunately, there are a couple of natural generalisations of the\nelliptical proposal that avoid this complication. One of them says that\nthe space of epistemic possibilities forms an ellipse. In particular, it\nis the set of all points such that the sum of the distance from that\npoint to $\\langle x_v, y_v \\rangle$ and the distance from that point to\n$\\langle x_a, y_a \\rangle$ is less than or equal to $2m + e$, where $e$\nagain is the distance between the measured and actual value. As you can\nquickly verify, that includes all points on the line from\n$\\langle x_v, y_v \\rangle$ to $\\langle x_a, y_a \\rangle$, plus an\nextension of length $m$ beyond in each direction. But it doesn't just\ncontain the straight path between $C_v$ and $C_a$; it 'bulges' in the\nmiddle. And the considerations above suggest that is what should happen.\n\nThe other alternative is to drop the idea that the space of\npossibilities should be elliptical, and have another circular proposal.\nIn particular, we say that the space of possibilities is the circle\nwhose centre is halfway between $\\langle x_v, y_v \\rangle$ and\n$\\langle x_a, y_a \\rangle$, and whose radius is $m + \\nicefrac{e}{2}$.\nAgain, that will include all points on the line from\n$\\langle x_v, y_v \\rangle$ to $\\langle x_a, y_a \\rangle$, plus an\nextension of length $m$ beyond in each direction. But it will include a\nmuch larger space in the middle.\n\nI think both of these are somewhat plausible proposals, though the\nsecond suffers from a slightly weaker version of the objection I'm about\nto mount to the Circular Reality Centred proposal. But they do share one\nweakness that I think counts somewhat against them. It's easy enough to\nsee what the weakness is in the one-dimensional case, so let's return to\nit for the time being, and remember we're assuming that $a > v$.\n\nConsider a case where $e$ is rather large, much larger than $m$. This\naffects how far below $v$ we have to go in order to reach possibilities\nthat are ruled out by the measurement. But it doesn't affect how far\nabove $v$ we have to go in order to reach such possibilities. Indeed, no\nmatter how bad $e$ is, we can be absolutely certain that we know\n$V < a + 2m$, or that we know that $V > a - 2m$. That seems a little\nodd; if the measurement is so badly mistaken, it seems wrong that it can\ngive us such a fine verdict, at least in one direction.\n\nI don't think that's a conclusive objection. Well, I don't think many of\nthe considerations I've listed here are *conclusive*, but this seems\neven weaker. But it is a reason to look away from the elliptical\nproposal and back towards the circular proposals that we started with.\n\nIf we just look at first order knowledge claims, it is hard to feel much\nof an intuitive pull towards one or other of the alternatives. Perhaps\nsafety based considerations favour the Reality Centred over the\nAppearance Centred version, but I don't think the salient safety\nconsideration is that strong.\n\nIf we look at iterated knowledge claims, however, there is a big problem\nwith the Reality Centred approach. The intuition here is clearer if we\nuse numerical examples, so I'll work through a case with numbers first,\nthen do the general version next.\n\nAssume, as above, that $v = 830, a = 834$ and $m = 10$. So we have a\npretty decent measurement here. On the Reality Centred proposal, the\nstrongest thing that $S$ can know is that $V \\in [816, 844]$. So it is\nan epistemic possibility that $V = 816$. Assume that that's the actual\npossibility. Then the measurement is rather bad; the new value for $e$\nis 18. Were $V$ to equal 816, while $a$ equalled 834, then on the\nReality Centred approach, the epistemic possibilities would be a circle\nof radius $e+m$, i.e., 28, around the actual value, i.e., 816. So the\nstrongest thing the agent could know is that $V \\in [788, 844]$. On the\nother hand, if $V$ were 844, the strongest thing the agent could know is\nthat $V \\in [824, 864]$. Putting those together, the strongest thing the\nagent can know that she knows is that $V \\in [788, 864]$. That's a very\nlarge range already. Similar calculations show that the strongest thing\nthe agent can know that she knows that she knows is that\n$V \\in [732, 904]$.\n\nNow I'll grant that intuitions about second and third order knowledge\nare not always maximally sharp. But I think it is very implausible that\na relatively accurate measurement like this could lead to such radical\nignorance in the second and third orders of knowledge. So I think the\nReality Centred approach can't be right.\n\nThe general form the case is as follows. The strongest thing the agent\ncan know is that $V \\in [v - (e + m), a + m]$. The strongest thing she\ncan know that she knows is that $V \\in [v - 3(e + m), a + 3m]$. And the\nstrongest thing she can know that she knows that she knows is that\n$V \\in [v - 7(e + m), a + 7m]$. In general, we have *exponential* growth\nof the possibilities as we add one extra order of knowledge. That seems\nabsurd to me, so the Reality Centred approach is wrong.\n\nNote that this isn't a problem with the Appearance Centred approach. The\nfirst-order epistemic possibilities are that\n$V \\in [a - (e + m), a + e + m]$. If $V$ is at the extremes of this\nrange, then $e$ will be rather large. For example, if $V$ were equal to\n$a + e + m$, then the new error would be $e + m$, since the measured\nvalue is still $a$. So the range of possibilities would be that\n$V \\in [a - ((e + m) + m), a + ((e + m) + m)]$. Somewhat surprisingly,\nthose would also be the possibilities if $V$ were equal to\n$a - (e + m)$, since the only feature of $V$ that affects the epistemic\npossibilities for $V$ is its distance from $a$. So for all $S$ knows\nthat she knows, $V$ could be anything in $[a - (e + 2m), a + (e + 2m)]$.\nSimilar reasoning shows that for all $V$ knows that she knows that she\nknows, $V$ could be anything in $[a - (e + 3m), a + (e + 3m)]$. In\ngeneral, $V$ has $n$'th order knowledge that $V$ is in\n$[a - (e + nm), a + (e + nm)]$. This linear growth in the size of the\nrange of epistemic possibilities is more plausible than the exponential\ngrowth on the Reality Centred approach.\n\nSo all things considered, I think the Circular Appearance Centred\napproach is the right one, as Williamson suggests. Any simple\nalternative seems to have rather counterintuitive consequences.\n\n[^1]: This isn't always true. If a scale flickers between reading 832g\n    and 833g, it takes a bit of skill to determine what *the reading*\n    is. But we'll assume it is clear in this case. On an analogue scale,\n    the luminosity assumption is rather implausible, since it is\n    possible to eyeball with less than perfect accuracy how far between\n    one marker and the next the pointer is.\n\n[^2]: I'm not actually sure whether Williamson *makes* the first, or\n    thinks it is the kind of thing anyone who thinks justification is\n    prior to knowledge should make.\n\n[^3]: There are some circumlocutions here because I'm being careful to\n    be sensitive to the points raised in @SchroederRoss2012 about the\n    relationship between belief and reasoning. I think there's less\n    distance between the view they put forward and the view I defended\n    in @Weatherson2005-WEACWD than they do, but this is a subtle matter,\n    and for this paper's purposes I want to go along with Ross and\n    Schroeder's picture of belief.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}