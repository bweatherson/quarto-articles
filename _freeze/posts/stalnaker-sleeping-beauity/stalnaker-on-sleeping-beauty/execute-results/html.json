{
  "hash": "b305b90442e253661a0c1761bf68bdd9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Stalnaker on Sleeping Beauty\"\ndescription: |\n  A contribution to a book symposium on Stalnaker's Our Knowledge of the Internal World, focussing on the way his framework helps cast new light on the Sleeping Beauty problem.\ndate: September 1 2011\nauthor:\n  - name: Brian Weatherson \n    url: http://brian.weatherson.org\n    affiliation: University of Michigan\n    affiliation_url: https://umich.edu\n    orcid_id: 0000-0002-0830-141X\ndoi: \"10.1007/s11098-010-9613-1\"\ncategories:\n  - epistemology\n  - games and decisions\n  - on books\ncitation_url: https://doi.org/10.1007/s11098-010-9613-1\njournal:\n    title: \"Philosophical Studies\"\n    publisher: \"Springer\"\nvolume: 155\nnumber: 3\ncitation: false\nbibliography: ../../../articles/Rbib.bib\nself-contained: false\npreview: dowitcher.jpg\noutput:\n  distill::distill_article:\n    toc: true\n    toc_depth: 3\n    number_sections: true\n---\n\n\nThe Sleeping Beauty puzzle provides a nice illustration of the approach\nto self-locating belief defended by Robert Stalnaker in *Our Knowledge\nof the Internal World* [@Stalnaker2008], as well as a test of the\nutility of that method. The setup of the Sleeping Beauty puzzle is by\nnow fairly familiar. On Sunday Sleeping Beauty is told the rules of the\ngame, and a (known to be) fair coin is flipped. On Monday, Sleeping\nBeauty is woken, and then put back to sleep. If, and only if, the coin\nlanded tails, she is woken again on Tuesday after having her memory of\nthe Monday awakening erased.[^1] On Wednesday she is woken again and the\ngame ends. There are a few questions we can ask about Beauty's attitudes\nas the game progresses. We'd like to know what her credence that the\ncoin landed heads should be\n\n<aside>\nPublished in _Philosophical Studies_ 155: 445â€“456.\n</aside>\n\n1.  Before she goes to sleep Sunday;\n\n2.  When she wakes on Monday;\n\n3.  When she wakes on Tuesday; and\n\n4.  When she wakes on Wednesday?\n\nStandard treatments of the Sleeping Beauty puzzle ignore (d), run\ntogether (b) and (c) into one (somewhat ill-formed) question, and then\ndivide theorists into 'halfers' or 'thirders' depending on how they\nanswer it. Following Stalnaker, I'm going to focus on (b) here, though\nI'll have a little to say about (c) and (d) as well. I'll be following\northodoxy in taking $\\frac{1}{2}$ to be the clear answer to (a), and in\ntaking the correct answers to (b) and (c) to be independent of how the\ncoin lands, though I'll briefly question that assumption at the end.\n\nAn answer to these four questions should respect two different kinds of\nconstraints. The answer for day $n$ should make sense 'statically'. It\nshould be a sensible answer to the question of what Beauty should do\ngiven what information she then has. And the answer should make sense\n'dynamically'. It should be a sensible answer to the question of how\nBeauty should have updated her credences from some earlier day, given\nrational credences on the earlier day.\n\nAs has been fairly clear since the discussion of the problem in\n@Elga2000, Sleeping Beauty is puzzling because static and dynamic\nconsiderations appear to push in different directions. The static\nconsiderations apparently favour a $\\frac{1}{3}$ answer to (b). When\nBeauty wakes, there are three options available to her: It is Monday and\nthe coin landed heads; It is Monday and the coin landed tails; It is\nTuesday and the coin landed tails. If we can argue that each of those\nare equally probable given her evidence, we get the answer\n$\\frac{1}{3}$. The dynamic considerations apparently favour a\n$\\frac{1}{2}$ answer to (b). The right answer to (a) is $\\frac{1}{2}$.\nNothing happens on Monday or Tuesday that surprises Beauty. And\ncredences should only change if we are surprised. So the right answer to\n(b) is $\\frac{1}{2}$.\n\nSince we must have harmony between dynamic and static considerations,\none of these arguments must be misguided. (In fact, I think both are, to\nsome degree.) These days there is a cottage industry of 'thirders'\ndeveloping accounts of credal dynamics that accord with the\n$\\frac{1}{3}$ answer to (b).[^2] But all of these accounts are\nconsiderably more complex than the traditional,\nconditionalisation-based, dynamic theory that we all grew up with.\n\nThree of the many attractions of Robert Stalnaker's new account of\nself-locating knowledge are (i) that it offers a way to answer all four\nof our questions about Sleeping Beauty, (ii) that it does so while\nremaining both statically and dynamically plausible, and (iii) that the\ndynamic theory involved is, in large part, traditional\nconditionalisation. I spend most of this note setting out Stalnaker's\naccount, and setting out his derivation of a $\\frac{1}{3}$ answer to\n(b). I conclude with some reasons for preferring a slightly different\nsolution of the Sleeping Beauty puzzle within the broad framework\nStalnaker suggests.\n\n### Stalnaker on Self-Location\n\nThe picture of self-locating belief that we get from Lewis's \"Attitudes\n*De Dicto* and *De Se*\" [@Lewis1979b] has been widely adopted in recent\nyears.[^3] On Lewis's picture, the content of an attitude is a set of\ncentered worlds. For current purposes we'll take to centered worlds to\nbe $\\langle$world, agent, time$\\rangle$ triples. To believe that $S$,\nwhere $S$ is a set of centered worlds, is to believe that the triple\n$\\langle$your world, you, now$\\rangle  \\in S$.\n\nThe motivation for this picture comes from reflection on how to\nrepresent locational uncertainty. If you're sure where in New York City\nyou are, you can pick out a point on a map and say \"I'm there\". If\nyou're not sure exactly where you are, but you have some information,\nyou can pick out a region on the map and say \"I'm somewhere in that\nregion\". If you're not sure who you are, but you know where everyone is,\nyou can do the same kind of thing. And it's plausible that this is a\n(somewhat) realistic situation. As one modern-day Lewisian, Andy Egan,\nputs it 'I can believe that my pants are on fire without believing that\nEgan's pants are on fire, and I can hope that someone turns a fire\nextinguisher on me right now without hoping that someone turns a fire\nextinguisher on Egan at 5:41pm.'' [@Egan2004-JACSPA-2 64] There is an\nimportant puzzle here that needs to be addressed, and can't obviously be\naddressed in the framework Lewis accepted before 1979, where the content\nof a propositional attitude is a set of Lewisian concreta. If possible\nworlds are Lewisian concreta, then Lewisians like Egan are correct to\nrespond to puzzles about location by saying, \"sometimes (as when we want\nto know who or where we are) **the world is not enough**\".\n[@Egan2004-JACSPA-2 64]\n\nBut this response is too self-centered. Not all locational thoughts are\nself-locational thoughts. I can be just as uncertain about where *that*\nis as about where *this* is, or as uncertain about who *you* are as\nabout who *I* am. Imagine I'm watching Egan's unfortunate adventures\nwith his infernal trousers on a delayed video tape. I can believe *his*\npants are on fire without believing Egan's pants are on fire, and hope\nthat someone turns a fire extinguisher on him *then* without hoping some\nturns a fire extinguisher on Egan at 5:41pm. Or, at least, that way of\nputting things sounds just as good as Egan's original description of the\ncase.\n\nFor a different example, imagine I wake at night and come to believe it\nis midnight. As Lewis would represent it, I believe\n$\\langle w, \\text{me}, \\text{now}\\rangle  \\in \\{\\langle w, s, t\\rangle : t = \\text{midnight}\\}$.\nWhen I wake, I think back to that belief, and judge that I may have been\nmistaken. How should we represent this? Not that I now believe\n$\\langle w, \\text{me}, \\text{now}\\rangle  \\notin \\{\\langle w, s, t\\rangle : t = \\text{midnight}\\}$.\nThat's obviously true - I know the sun is up. We want to represent\nsomething more contentious.\n\nThe best, I think, the Lewisian can do is to pick out some description\n$D$ of my earlier belief and say what I believe is\n$\\langle w, \\text{me}, \\text{now}\\rangle  \\notin \\{\\langle w, s, t\\rangle : (\\iota x: Dx) x$\nhappens at midnight}. That is, I believe the belief that satisfies $D$\ndoesn't happen at midnight. Is that good enough? Well, we might imagine\nthe debate continuing with the anti-Lewisian proposing cases where $D$\nwill not be unique (because of forgotten similar beliefs) or will not be\nsatisfied (because of a misrecollection of the circumstances of the\nbelief), and so this approach will fail. And we might imagine the\nLewisian responding by complicating $D$, or by denying that in these\ncases we really do have beliefs about our earlier beliefs. In other\nwords, we can imagine the familiar debates about descriptivism about\nnames being replayed as debates about descriptivism about prior beliefs.\nAs enjoyable as that may be, it's interesting to consider a different\napproach.\n\nThere's a more philosophical reason to worry about Lewis's model. If we\nmodel uncertainty as a class of relationships to possible worlds, it\nlooks like there's a lot of actual uncertainty we won't be able to\nmodel. Indeed, there are three kinds of uncertainty that we can't model\nin this framework. First, we can't model uncertainty about logic and\nmathematics. Second, if we accept the necessity of identity, we can't\nmodel uncertainty about identity claims. Whatever it is to be uncertain\nabout whether $a$ is $b$, it won't be a distinctive relation to the set\nof worlds in which $a$ is $b$, since that's all the worlds. Third, we\ncan't model uncertainty about claims about self-identity, like *I'm that\nguy*. Lewis's framework is an improvement on the sets of possible worlds\napproach because it helps with this third class of cases. But it doesn't\nhelp with the first or, more importantly, with the second. We might\nthink that a solution to puzzles about self-identity should generalise\nto solve puzzles about identity more broadly. Lewis's model doesn't. One\nof Stalnaker's key insights is that we should, and can, have a model\nthat addresses both kinds of puzzles about identity.\n\nOn Stalnaker's model, a belief is just a distinction between worlds. The\ncontent of a belief is a set of worlds, not a set of centered worlds.\nBut worlds have more structure than we thought they had. The formal\nmodel is a bit more subtle than what I'll sketch here, but I think I'll\ninclude enough detail to cover the Sleeping Beauty case. In each world,\neach center, in Lewis's sense, has a haecceity. A world is the Cartesian\nproduct of a Lewisian world, i.e. a world without haecceities, and a\nfunction from each contextually salient haecceity to a location. If we\nsee a kiss, and wonder who *she* is, who *he* is, and *when* they are\nkissing, then we can think of the worlds as quadruples consisting of a\nhaecceity-free world (perhaps a Lewisian concreta), a woman, a man and a\ntime. So we can represent three kinds of locational doubts, not just\nself-locational doubt.[^4]\n\nWhen an agent at center $c$ believes something self-locating, e.g. that\nit is Monday, the content of their belief is that $c$'s haecceity is on\na Monday. If they don't know what day it is, there's a sense in which\nthey don't know what they believe, since they don't know whether what\nthey are believing is that $c$'s center is on Monday, or that some other\ncenter's haecceity is on Monday.[^5] But their belief, the belief they\nwould express on Monday by saying \"It is Monday\", has two nice features.\nFirst, it is neither trivial, like the belief that *Monday is Monday*,\nnor changing in value over time, since $c$'s center is always on Monday.\nSecond, it is the kind of belief that people on days other than Monday\ncan share, or dispute. And this belief can be shared by others who have\nthe capacity to think *de re* about $c$, even if they can't uniquely\ndescribe it. It's this last fact that lets Stalnaker handle the cases\nthat proved problematic for Lewis and the neo-Lewisians. For instance,\nit lets Stalnaker model shared uncertainty about identity claims.\n\nWith all that in place, it's time to return to Sleeping Beauty. Let's\nconsider two propositions. The first, $H$, is that the coin landed\nheads. The second, $M$, is what Beauty can express when she wakes on\nMonday by saying \"It is Monday\". That is, it is a singular proposition\nabout a wakening experience that Beauty can now have singular thoughts\nabout (since she is now undergoing it), but which she didn't previously\nhave the capacity to determinately pick out. We'll call this wakening\n$a$. (Beauty might undergo multiple wakenings, but we're going to focus\non one for now, and call it $a$.) Given these three propositions, we can\ndescribe four possibilities. Or, as we'll somewhat inaccurately describe\nthem, four worlds.[^6]\n\n1.  $H \\wedge M$\n\n2.  $H \\wedge \\neg M$\n\n3.  $\\neg H \\wedge M$\n\n4.  $\\neg H \\wedge \\neg M$\n\nOn Sunday, Beauty's credences are distributed over the algebra generated\nby the partition $\\{H, \\neg H\\}$, i.e.,\n$\\{\\{w_1, w_2\\}, \\{w_3, w_4\\}\\}$. The algebra is that course-grained\nbecause she doesn't have the capacity to think $M$ thoughts. And that's\nbecause she's not acquainted with the relevant haecceities. So she can't\ndistinguish between worlds that differ only on whether $M$ is true. On\nSunday then, Beauty's credences are given by\n$Pr(H) = Pr(\\neg H) = \\frac{1}{2}$.\n\nWhen she wakes on Monday, two things happen. First, she becomes\nacquainted with $a$. So she can now think about whether $a$ is on\nMonday. That is, she can now think about whether $M$ is true. So she can\nnow carve the possibility space more finely. Indeed, now her credences\ncan be distributed over all propositions built out of the four\npossibilities noted above. The second thing that happens is that Beauty\nrules out one of these possibilities. In particular, she now knows that\n$H \\wedge \\neg M$, a proposition she couldn't so much as think before,\nis actually false. That's because if the coin landed heads, this very\nwakening could not have taken place on Tuesday.\n\nStalnaker's position on Beauty's credences uses these two facts. First\nBeauty 'recalibrates' her credences to the new algebra, then she updates\nby conditionalising on $\\neg H \\vee M$. If after recalibration, her\ncredences are equally distributed over the four cells of the partition,\nthe conditionalising on $\\neg H \\vee M$ will move $Pr(H)$ to\n$\\frac{1}{3}$. That is, the thirders win!\n\nBut we might wonder why we use just this calibration, the one where all\nfour cells get equal credence. We're going to come back to this question\nbelow. But first, I want to use Stalnaker's framework to respond to an\ninteresting objection to the thirder position.\n\n### Monty Hall\n\nBoth C. S. Jenkins [-@Jenkins2005] and Joseph Halpern [-@Halpern2004]\nhave argued that the 'thirder' solution is undermined by its similarity\nto fallacious reasoning in the Monty Hall case. The idea is easy enough\nto understand if we simply recall the Monty Hall problem. The agent is\nin one of three states $s_1, s_2$ or $s_3$, and has reason to believe\neach is equally likely. She guesses which one she is in. An experimenter\nthen selects a state that is neither the state she is in, nor the state\nshe guessed, and tells her that she is not in that state. If she simply\nconditionalises on the content of the experimenter's report, then her\ncredence that she guessed correctly will go from $\\frac{1}{3}$ to\n$\\frac{1}{2}$. This is a bizarre failure of Reflection, so something\nmust have gone wrong.[^7] Both Jenkins and Halpern suggest that the\nviolation of Reflection that 'thirders' endorse in Sleeping Beauty is\njust as bizarre.\n\nBut the Sleeping Beauty puzzle is not analogous to the Monty Hall\nproblem. That's because in Sleeping Beauty we seem forced to have a\nviolation of Reflection somewhere. Let's think a bit again about\nBeauty's credences on Wednesday, and let's assume that we're trying to\navoid Reflection violations. Then on Monday (and Tuesday) her credence\nin $H$ is $\\frac{1}{2}$. Now when Beauty awakes on those days, there are\nthree possibilities open to her. (Hopefully it won't lead to ambiguity\nif I re-use the name $a$ for the awakening Beauty is undergoing when\nthinking about $H$.)\n\n-   $a$ is Monday and $H$\n\n-   $a$ is Monday and $\\neg H$\n\n-   $a$ is Tuesday and $\\neg H$\n\nWhen she wakes on Wednesday, she's in a position to reflect on these\npossibilities. And she can rule out the second of them. That's what she\nlearns when she wakes and learns it is Wednesday; that if $\\neg H$, then\nthat last awakening was on Tuesday. Now since that last awakening,\nnothing odd has happened to Beauty. She hasn't had her memories erased.\nShe might have had her memories erased between Monday and Tuesday, but\nthat's not relevant to the time period she's considering. Moreover, she\nknows that she hasn't had her memories erased. So I think she's in a\nposition to simply conditionalise on her new evidence. And that new\nevidence is simply that whatever else was going on when she was thinking\nabout those three possibilities, she wasn't in the second possibility.\n\nBut now we face a challenge. Beauty knows that Wednesday will come. So\nif her credence in $H$ on Wednesday isn't $\\frac{1}{2}$, then we'll have\na violation of Reflection. The violation is that on Sunday her credence\nin $H$ is $\\frac{1}{2}$, but she knows it will go up on Wednesday. And\nthat violation is just as bad as the violation of Reflection that\n'thirders' endorse. But if she conditionalises when she wakes up on\nWednesday, then the only way her updated credence in $H$ can be\n$\\frac{1}{2}$ is if her prior credence in the first and third options\nabove were equal. And the only way that can happen is for her credence,\nwhen $a$ is happening, in the proposition that $a$ is Monday and\n$\\neg H$ is 0. But that's bizarre. Whether or not the thirders are right\nto think that she should give equal credence to that possibility as to\nthe two others, she can't give it credence 0. So Reflection will fail\nsomewhere.\n\nTo see why Reflection is failing in these cases, it helps to look back\nat the requirements we need in order to get from conditionalisation to\nReflection. In Rachael Briggs's careful analysis of when Reflection\nholds, in @Briggs2009, Reflection is only guaranteed to hold when agents\nknow what their evidence is. In other cases, even perfect\nconditionalisers may violate Reflection.\n\nThis assumption, namely that agents know what their evidence is, is a\nkind of luminosity assumption. And not surprisingly, it has been\nchallenged by Timothy Williamson [@Williamson2000-WILKAI 230-3]. What is\na little more surprising is that we only need a relatively weak failure\nof luminosity in order to get problems for reflection. The assumption\nthat agents know what their evidence is can be broken into two parts.\n\n-   If $p$ is part of $S$'s evidence, then $S$ knows that $p$ is part of\n    her evidence.\n\n-   If $p$ is not part of $S$'s evidence, then $S$ knows that $p$ is not\n    part of her evidence.\n\nThe first part is, I think, implausible for reasons familiar from\nWilliamson's work. But the second is implausible even if one doesn't\nlike Williamson's style of reasoning. If we think $p$ must be true to be\npart of $S$'s evidence (as I think we should), and we think that\nrational agent's can have false beliefs about anything, as also seems\nplausible by simple observation of how easy it is to be misled, then\neven a rational agent can fail to realise that $p$ is not part of her\nevidence. The easiest way that can happen is if she falsely, but\nreasonably, believes $p$, and hence does not realise that due to its\nfalsity, it is not part of her evidence.\n\nWilliamson provides an interesting model, based on a discussion in\n@Shin1989, of a case where an agent does not know that something is not\npart of her evidence. There are currently three possible states the\nagent could be in: $s_1, s_2$ or $s_3$. An experiment will be run, and\nafter the experiment the agent will get some evidence depending on which\nstate she's in.\n\n-   If she's in $s_1$, her evidence will rule out $s_3$.\n\n-   If she's in $s_2$, her evidence will rule out $s_1$ and $s_3$.\n\n-   If she's in $s_3$, her evidence will rule out $s_1$.\n\nAssume the agent knows these conditionals before the experiment is run,\nand now let's assume the experiment has been run. Let $xRy$ mean that\n$y$ is possible given the evidence $S$ gets in $x$. Then we can see that\n$R$ is transitive. That means that if $p$ is part of $S$'s evidence,\nthen her evidence settles that $p$ is part of her evidence. But $R$ is\nnot Euclidean. So it is possible that $p$ is not part of her evidence,\neven though her evidence does not settle that $p$ is not part of her\nevidence. In particular, if she is in $s_1$, that she isn't in $s_1$ is\nnot part of her evidence. But for all she can tell, she's in $s_2$. And\nif she's in $s_2$, her evidence does rule out her being in $s_1$. So her\nevidence doesn't settle that this is not part of her evidence.\n\nThe model is obviously an abstraction from any kind of real-world case.\nBut as we argued above, it is plausible that there are cases where an\nagent doesn't know what evidence she *lacks*. And this kind of case\nmakes for Reflection failure. Assume that the agent's prior credences\nare (and should be) that each state is equally likely. And assume the\nagent conditionalises on the evidence she gets. Then her credence that\nshe's in $s_2$ will go up no matter what state she's in. And she knows\nin advance this will happen. But there's no obvious irrationality here;\nit's not at all clear what kind of reflection-friendly credal dynamics\nwould be preferably to updating by conditionalisation.[^8]\n\nSo when an agent doesn't know what evidence she lacks, Reflection can\nfail. One way to think about the Sleeping Beauty case is that something\nlike this is going on, although it isn't quite analogous to the\nShin-Williamson example discussed above. In that example, the agent\ndoesn't know what evidence she lacks at the *later* time. In the\nSleeping Beauty case, we can reasonably model Beauty as knowing exactly\nwhat her evidence is when she wakes up. Her evidence does nothing more\nor less than rule out $w_2$. That's something she didn't know before\nwaking up. But in a good sense she didn't know that she didn't know\nthat. That's because she was not in a position to even think about $w_2$\nas such. Since she wasn't in a position to think about $a$, couldn't\ndistinguish, even in thought, between $w_1$ and $w_2$. So any\nproposition she could think about, and investigate whether she knew or\nnot, had to include either both $w_1$ and $w_2$, or include neither of\nthem. So the only way she could know that she didn't know\n$\\{w_1, w_3, w_4\\}$ is if she tacitly knew she didn't know that in\nvirtue of knowing that she didn't know $\\{w_1, w_2, w_3, w_4\\}$. But she\ndidn't know that she didn't know that for the simple reason that she did\nknow that $\\{w_1, w_2, w_3, w_4\\}$, i.e. the universal proposition, is\ntrue. So we have a case where Beauty doesn't know what it is she doesn't\nknow at the earlier time. And like cases where the agent doesn't know\nwhat she doesn't know at the later time, this is a case where reflection\nfails.\n\nSo there are two reasons to be sceptical of reflection-based arguments\nagainst the 'thirder' solution to the Sleeping Beauty puzzle.\n\n-   There is no plausible way for Beauty's credence in $H$ to be\n    $\\frac{1}{2}$ on both Monday and Wednesday, but reflection requires\n    this.\n\n-   Reflection is only plausible when agents know both what evidence\n    they have, and what evidence they lack, throughout the story. And it\n    is implausible that Beauty satisfies this constraint, since she\n    gains conceptual capacities during the story.\n\nBut this isn't a positive argument for the $\\frac{1}{3}$ solution. I'll\nconclude with a discussion of two arguments for the $\\frac{1}{3}$\nsolution. Both arguments are suggested by Stalnaker's framework, but\nonly one of them is ultimately defensible.\n\n### Stalnaker on Sleeping Ugly\n\nWhen we left Stalnaker's discussion of the Sleeping Beauty case, we had\njust noticed that there was a question about why Beauty should respond\nto being able to more finely discriminate between states by\n'recalibrating' to a credal state where each of $w_1$ through $w_4$\nreceive equal credence. This question about calibration is crucial to\nthe Sleeping Beauty puzzle because there are other post-calibration\ndistributions of credence are are *prima facie* viable. Perhaps, given\nwhat Beauty knows about the setup, she should never have assigned any\ncredence to $H \\wedge \\neg M$. Rather, she should have made it so\n$Pr(\\neg H \\wedge M) = Pr(\\neg H \\wedge \\neg M) = \\frac{1}{4}$, and\n$Pr(H \\wedge M) = \\frac{1}{2}$. If she does that, the conditionalising\non $\\neg(H \\wedge \\neg M)$ won't change a thing, and $Pr(H)$ will still\nbe $\\frac{1}{2}$. That is, the halfers win!\n\nOne argument against this, and in favour of the equally weighted\ncalibration, is suggested by Stalnaker's 'Sleeping Ugly' example.\nSleeping Ugly is woken up on Monday and again (with erased memories) on\nTuesday however the coin lands. So when Ugly awakes, he has the capacity\nto think new singular thoughts, but he doesn't get much evidence about\nthem. In particular, he can't share the knowledge Beauty would express\nby saying, \"If the coin landed Heads, this is Monday.\"[^9] Now we might\nthink it is intuitive that Ugly's credences when he wakes up and\nreflects on his situation should be equal over the four possibilities.\nMoreover, *all* Ugly does is recalibrate; since he doesn't learn\nanything about which day it is, his post-awakening credence just is his\nrecalibration. If all this is correct, and if Beauty should recalibrate\nin the same way as Ugly, then Beauty should recalibrate to the 'equally\nweighted calibration'. And now we're back to victory for the thirders!\n\nBut there's little reason to believe the crucial premise about how Ugly\nshould recalibrate his credences. What we know is that Ugly doesn't have\nany reason to give any more credence to any one of the four\npossibilities than to the others. It doesn't at all follow that he has\nreason to give equal credence to each, any more than in general an\nabsence of reasons to treat one of the $X$s differently to the others is\na reason to treat them all the same.[^10]\n\nThe argument I'm considering here is similar to reasoning Adam Elga has\nemployed @Elga2004, and which I have criticised @Weatherson2005-WEACWD.\nA central focus of my criticism was that this kind of reasoning has a\ntendency to lead to countable additivity violations. In an important\nrecent paper, Jacob Ross [-@Ross2010] has shown that many thirder\narguments similarly lead to countable additivity violations. He shows\nthis by deriving what he calls the 'Generalised Thirder Principle'\n(hereafter, GTP) from the premises of these arguments. The GTP is a\nprinciple concerning a generalised version of the Sleeping Beauty\nproblem. Here is Ross's description of this class of problems.\n\n> Let us define a *Sleeping Beauty problem* as a problem in which a\n> fully rational agent, Beauty, will undergo one or more mutually\n> indistinguishable awakenings, and in which the number of awakenings\n> she will undergo is determined by the outcome of a random process. Let\n> $S$ be a partition of alternative hypotheses concerning the outcome of\n> this random process. Beauty knows the objective chances of each\n> hypothesis in $S$, and she also knows how many time she will awaken\n> conditional on each of these hypotheses, but she has no other relevant\n> information. The problem is to determine how her credence should be\n> divided among the hypotheses in $S$ when she first awakens. (Ross ms,\n> 2-3)\n\nThe GTP is a principle about this general class of problem. Here's how\nRoss states it.\n\nGeneralized Thirder Principle\n\n:   In any standard Sleeping Beauty problem, upon first awakening,\n    Beauty's credence in any given hypothesis in $S$ must be\n    proportional to the product of the hypothesis' objective chance and\n    the number of times Beauty will awaken conditional on this\n    hypothesis. \\... [We can] express this principle formally. For any\n    hypothesis $i \\in S$, let $Ch(i)$ be the objective chance that\n    hypothesis $i$ is true, and let $N(i)$ be the number of times Beauty\n    awakens if $i$ is true. Let $P$ be the Beauty's credence function\n    upon first awakening. The GTP states \\...\n\n$$\\text{For all }i, j \\in S, \\frac{P(i)}{P(j)} = \\frac{N(i)Ch(i)}{N(j)Ch(j)} \\text{ whenever }Ch(j) >  0. \\text{ (Ross ms, 6-7)}$$\n\nThe argument I'm considering seems to be committed to the GTP. In a\ngeneralised Sleeping Beauty problem, we can imagine a version of\nSleeping Ugly who will awake every day that Beauty might awake. The\nreasoning that leads one to think that Ugly should give equal credence\nto each of the two days in the original Sleeping Beauty case seems to\ngeneralise to imply that Ugly should give equal credence to each day in\nthis more general case. But if in the general example Beauty calibrates\nto match these credences of Ugly, then conditionalises on the\ninformation she receives, then she'll end up endorsing the GTP. That's\nan unhappy outcome. It would be better to have an argument for the\n$\\frac{1}{3}$ solution that doesn't imply the GTP.\n\nI'm going to argue that when Beauty wakes up her credences should\nsatisfy the following two premises. (As always, I use $a$ to name the\nawakening that Beauty is now undergoing, and I'm using $Cr$ for her\ncredence function on waking.)\n\n1.  $Cr(a$ is Monday and $H) = Cr(a$ is Tuesday and $\\neg H)$\n\n2.  $Cr(a$ is Monday and $H) = Cr(a$ is Monday and $\\neg H)$\n\nThese constraints imply, given what Beauty knows about the setup, that\n$Cr(H) = \\frac{1}{3}$. The arguments for each premise are quite\ndifferent.\n\nThe argument for P1 is one I mentioned above, so I'll just sketch it\nquickly here. On Wednesday, Beauty's credence in $H$ should be back to\n$\\frac{1}{2}$. But what she learns on Wednesday is $\\neg (a$ is on\nMonday and $\\neg H)$. So on Monday, her credence in $H$ conditional on\n$\\neg (a$ is on Monday and $\\neg H)$ should be $\\frac{1}{2}$. But given\nwhat Beauty knows about the setup of the problem, this immediately\nimplies P1.\n\nThe argument for P2 requires a slightly more fanciful version of the\nexample. Imagine that on Sunday night, Beauty is visited by a time\ntraveller from Monday who comes back with a videotape of her waking on\nMonday, and tells her that it was taken on Monday. So Beauty now has the\ncapacity to think about this very awakening, i.e., $a$. This doesn't\nseem to affect her credences in $H$, it should still be $\\frac{1}{2}$.\nNow imagine that her memory of this visit is erased overnight, so when\nshe wakes up on Monday her situation is just like in the original\nSleeping Beauty problem.\n\nCall $Cr_1$ her credence function on Sunday after meeting the time\ntraveller. And call $Cr_2$ her credence function on Monday after she\nwakes up and reflects on her situation. It seems the only relevant\ndifference between the situation on Sunday and the situation on Monday\nis that Beauty has *lost* the information that $a$ is on Monday. The\nfollowing principle about situations where an agent loses information\nseems plausible. If $Cr_{\\text{old}}$ is the pre-loss credence function,\nand $Cr_{\\text{new}}$ is the post-loss credence function, and $E$ is the\ninformation lost, then\n\n-   $Cr_{\\text{old}}(p)$ = $Cr_{\\text{new}}(p | E)$\n\nThe idea here is that information loss is a sort of reverse\nconditionalisation. Applying this, we get that\n$Cr_1(H) = Cr_2(H | a \\text{ is Monday})$, so\n$Cr_2((H | a \\text{ is Monday}) = \\frac{1}{2}$, so $Cr_2(a$ is Monday\nand $H) = Cr_2(a$ is Monday and $\\neg H)$. And since the situation on\nMonday in the revised problem, i.e., the situation when Beauty's\ncredence function is $Cr_2$ is just like the situation in the original\nSleeping Beauty problem on Monday, it follows that P1 is true in the\noriginal problem. And from P1 and P2, it follows that the thirder\nsolution is right.\n\nBut note a limitation of this solution. When Beauty wakes on *Tuesday*\nher credence function is defined over a different algebra of\npropositions to what it was defined over after meeting the time\ntraveller. So there's no time travel based argument that her credences\non Tuesday should satisfy P2, or indeed that on Tuesday her credence in\n$H$ should be $\\frac{1}{3}$. (For similar reasons, this kind of reason\ndoes not support the GTP.)\n\nOne might try and argue that Beauty's situation on Tuesday is\nindistinguishable from her situation on Monday, and so she should have\nthe same credences on Tuesday. Both the premise and the inference here\nseem dubious. On Tuesday, Beauty knows different singular propositions,\nso the situation isn't clearly indistinguishable. But more importantly,\nit is implausible that indistinguishability implies same credences. The\nrelation *should have the same credences in* is a transitive and\nsymmetric relation between states. The relation *is indistinguishable\nfrom* is neither transitive nor symmetric. So I suspect that the kind of\narguments developed here leave it an open question what Beauty's\ncredences should be on Tuesday, and indeed whether there is a unique\nvalue for what her credences then should be.\n\n[^1]: Note that I'm not assuming that Beauty's memories are erased in\n    other cases. This makes the particular version of the case I'm\n    discussing a little different to the version popularised in\n    @Elga2000. This shouldn't make any difference to most analyses of\n    the puzzle, but it helps to clarify some issues.\n\n[^2]: See, for instance, @Titlebaum2008 and the references therein.\n\n[^3]: Including by me. See @Egan2005-EGAEMI\n\n[^4]: Stalnaker thinks we have independent reason to treat these\n    structured entities as simply worlds. The main point of the last few\n    sentences was that we can adopt Stalnaker's model while staying\n    neutral on this metaphysical question.\n\n[^5]: Perhaps it would be better to say that individuals and times have\n    haecceities, rather than saying centers do. I have little idea what\n    could tell between these options, or even if there is a substantive\n    issue here.\n\n[^6]: Of course worlds are considerably more detailed than this, but the\n    extra detail is an unnecessary confusion for the current storyline.\n\n[^7]: The standard response is to say that the agent shouldn't just\n    conditionalise on the content of the experimenter's utterance, but\n    on the fact that the experimenter is making just that utterance.\n    We'll return to this idea below.\n\n[^8]: The idea that we should update by conditionalisation on our\n    evidence, even when we don't know what the evidence is, has an\n    amusing consequence in the Monty Hall problem. The agent guesses\n    that she's in $s_i$, and comes to know she's not in $s_j$, where\n    $i \\neq j$. If she only comes to know that she's not in $s_j$, and\n    not something stronger, such as knowing that she knows she's not in\n    $s_j$, then she really should conditionalise on this, and her\n    credence that her guess was correct will go up. This is the\n    'mistaken' response to the puzzle that is frequently deprecated in\n    the literature. But since the orthodox solutions to the puzzle rely\n    on the agent reflecting on how she came to know $\\neg s_j$, it seems\n    that it is the right solution if she doesn't know that she knows\n    $\\neg s_j$.\n\n[^9]: Stalnaker notes that this is a reason for thinking Beauty does\n    learn something when she wakes up, and so there's a reason her\n    credence in $H$ changes.\n\n[^10]: Compare this argument for giving nothing to charity. There are\n    thousands of worthwhile charities, and I have no reason to give more\n    to one than any of the others. But I can't afford to give large\n    equal amounts to each, and if I gave small equal amounts to each,\n    the administrative costs would mean my donation has no effect. So I\n    should treat each equally, and the only sensible practical way to do\n    this is to give none to each. Note that you really don't have to\n    think one charity is more worthy than the others to think this is a\n    bad argument; sometimes we just have to make arbitrary choices.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}