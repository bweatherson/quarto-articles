{
  "hash": "94af88957f3af2eb552c98e47a45df62",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"The Temporal Generality Problem\"\ndescription: | \n   The traditional generality problem for process reliabilism concerns the difficulty in identifying each belief forming process with a particular kind of process. Thatidentification is necessary since individual belief forming processes are typically of many kinds, and those kinds may vary in reliability. I raise a new kind of generality problem, one which turns on the difficulty of identifying beliefs with processes by which they were formed. This problem arises because individual beliefs may be the culmination of overlapping processes of distinct lengths, and these processes may differ in reliability. I illustrate the force of this problem with a discussion of recent work on the bootstrapping problem.\ndate: January 1 2012\nauthor:\n  - name: Brian Weatherson \n    url: http://brian.weatherson.org\n    affiliation: University of Michigan\n    affiliation_url: https://umich.edu\n    orcid_id: 0000-0002-0830-141X\ndoi: \"10.5840/logos-episteme20123153\"\ncategories:\n  - epistemology\n  - scepticism\n  - notes\ncitation_url: https://doi.org/10.5840/logos-episteme20123153\njournal:\n    title: \"Logos and Episteme\"\n    publisher: \"PDCNet\"\nvolume: 3\nnumber: 1\ncitation: false\nbibliography: ../../../articles/Rbib.bib\nself-contained: false\npreview: clocktower.jpg\noutput:\n  distill::distill_article:\n    toc: true\n    toc_depth: 4\n    number_sections: true\n---\n\n\n### Two Kinds of Generality Problem\n\nThe generality problem is a well-known problem for process reliabilist\ntheories of justification.[^1] Here's how the problem usually gets\nstarted. In the first instance, token processes of belief formation are\nnot themselves reliable or unreliable. Rather, it is *types* of\nprocesses of belief formation that are reliable or unreliable. But any\ntoken process is an instance of many different types. And these types\nmay differ in reliability.\n\n<aside>\nPublished in [Logos and Episteme](https://doi.org/10.5840/logos-episteme20123153) 3: 117-122.\n</aside>\n\nFor instance, imagine I read in the satirical newspaper *The Onion* that\nBarack Obama is the president. On this basis, I come to believe that\nBarack Obama as president. The process I have used to form this belief\nis an instance of each of these types.\n\n::: {.enumerate}\nComing to believe that Barack Obama is the president;\n\nBelieving something because it was written in *The Onion*; and\n\nBelieving something because it was written in a newspaper.\n:::\n\nThe first type of process is very reliable, at least in 2012. The second\nis highly unreliable, and the third is very reliable. So should we say\nthat the token process I used was reliable or unreliable? More\ngenerally, is there a principled way to map token processes to types of\nprocess in a way that lets us systematically say whether a particular\nprocess is reliable or not? Critics of reliabilism argue that there is\nnot.\n\nAs I said, this problem has been around for quite a while, but I don't\nthink the full force of the problem has been appreciated. Reliabilism is\na theory about whether a belief is justified or unjustified. But to\ndetermine whether the belief is justified, we step back from the belief\nitself in two respects. First, we look not to the belief, but to the\ntoken process of belief formation from which it results. Second, we look\nnot just to that process, but to kinds of processes of which it is an\ninstant. When carrying this out, we need to make the following two\nmappings.\n\n::: {.enumerate}\nBelief $\\rightarrow$ Token process of belief formation;\n\nToken process of belief formation $\\rightarrow$ type of process of\nbelief formation\n:::\n\nThe traditional point of the generality problem is that the second of\nthese mappings is one-many, not one-one. Each token process is\nassociated with many, many types of processes. But what hasn't been\nsufficiently appreciated is that the first mapping is one-many as well.\nAnd this generates a new, and potentially harder, form of the generality\nproblem.\n\nThat the first mapping is one-many isn't because of any special\nproperties of beliefs. Typically, an event is the conclusion of more\nthan one process. Imagine that I travel from Michigan to New York to see\na friend. I conclude this journey by walking to the friend's apartment.\nWith the last step I take, I conclude several processes. These include:\n\n::: {.enumerate}\nWalking from the subway station to the apartment;\n\nTravelling by public transit from the airport to the apartment; and\n\nTravelling from Michigan to my friend's apartment.\n:::\n\nIt is possible that one of these is a quite reliable process, while the\nothers are not. If I am good at navigating the Manhattan street grid by\nfoot, but poor at making it to the airport on time, then process one\nwill be a highly reliable process, while process three will not. So\nshould we say that my arrival at my friend's apartment was the result of\na reliable process or not? The best reply to that question is to point\nout that it is ill formed. Given that I made it to the nearest subway\nstation, I used a reliable process to traverse the last few blocks. But\nthe longer process I used was not as reliable.\n\nThis raises a conceptual worry for process reliabilist theories. If\nthere is no such thing as the reliability of a conclusion, but only the\nreliability of a process of getting from one or other starting point to\nthat conclusion, then it seems that in identifying the justifiedness of\na belief with *the* reliability of the process used to generate it, we\ncommit a kind of category mistake. Note that this problem would persist\neven if we had a one-one mapping from token processes to\nepistemologically relevant types of processes that would let us solve\nthe traditional form of the generality problem. We would still need a\nway of saying which of the many processes which terminate in a belief is\nthe epistemologically relevant one. I don't think there's any reason to\nthink there is a good answer to this question. I call this the\n*Temporal* Generality Problem, because the different processes that\nculminate in a belief are typically of different durations.\n\n### Can the Problems be Solved Simultaneously?\n\nI've argued in the previous section that in theory the Temporal\nGenerality Problem is distinct from the traditional version of the\ngenerality problem. But one might think that in practice a solution to\nthe latter will solve problems to do with the former. Consider the\nfollowing three step process.\n\n::: {.enumerate}\nI hear an astrologer say that Napoleon Bonaparte will win the 2013 US\nPresidential election.\n\nI form the belief that Napoleon Bonaparte will win the 2013 US\nPresidential election.\n\nI deduce that there will be a US Presidential election in 2013.\n:::\n\nThe process by which I got from 2 to 3 is, on the face of it, highly\nreliable. Assuming that I'm a mostly sensible person, coming to believe\nobvious logical consequences of my prior beliefs is a highly reliable\nprocess. Yet clearly the process that runs from 1 to 3, i.e., the\nprocess of believing obvious logical consequences of the contents of\nastrological predictions, is not a reliable process. So, one might ask,\nis the resultant belief justified, because it is formed by the reliable\nprocess that runs from 2 to 3, or unjustified, because it is formed by\nthe unreliable process that runs from 1 to 3?\n\nClearly, this is a false dilemma. The salient kind of process I'm using\nbetween 2 and 3 is not *believe obvious logical consequences of a\nbelief*, but *believe obvious logical consequences of a belief **formed\nby an unreliable process***. Once we identify the kind of process used\nat the last stage correctly, we can see that the unreliability of the\nwhole process causes the process used at the last stage to be\nunreliable.\n\nWe might even get cases that go the other way. There are plenty of\noccasions in science where scientists use mathematical techniques which\ncannot be made rigorous, and idealisations that cannot easily be\nreplaced with approximations, or with any other statement known to be\ntrue.[^2] If we looked at such a step in isolation, we would possibly\nthink that it is an unreliable step, even though it is part of a longer,\nreliable process. But the fact that it is part of a reliable process\nmatters. In particular, it matters to the way we identify the step the\nscientist is using with a larger kind of inferential processes. That\nkind won't involve, for instance, all instances of reasoning from false\npremises, or of reasoning with incoherent mathematical models. Rather,\nit will just include the kind of reasoning that is licenced by the norms\nof the science that the scientist is participating in, and that kind\nmight be a very reliable kind of process.\n\nBut there is one very special case where I think this kind of solution\nto the Temporal Generality Problem will not work. It concerns the way in\nwhich a reliabilist will try and solve the bootstrapping problem, as\ndeveloped by Stewart @Cohen2002 and Jonathan @Vogel2000. We'll turn\nnext to that problem.\n\n### Generality and Bootstrapping\n\nHilary @Kornblith2009 has proposed that looking at processes of longer\nduration generates a reliabilist solution to the bootstrapping problem.\nI'm going to argue that Kornblith's solution, which I agree is the kind\nof thing a reliabilist should say, in fact shows that the Temporal\nGenerality Problem is a distinct kind of generality problem, and perhaps\na much harder problem than the traditional generality problem.\n\nLet's start with a very abstract version of the problem. Assume device\n$D$ is highly reliable, and $S$ trusts device $D$ without antecedently\nknowing that it is reliable. Then the following sequence of events take\nplace.\n\n::: {.itemize}\nAt $t_0$, $S$ sees that device $D$ says that $p$.\n\nAt $t_1$, $S$ forms the belief that $D$ says at $t_0$ that $p$on the\nbasis of this perception.[^3]\n\nAt $t_2$, $S$ forms the belief that $p$, on the basis that the machine\nsays so.\n\nAt $t_3$, $S$ forms the belief that the machine is accurate at $t_0$, on\nthe basis of her last two beliefs.\n:::\n\nWhat should a reliabilist say about all this? Well, the process that\nruns from $t_0$ to $t_1$, the process of believing machine readings are\nas they appear, looks pretty reliable, so the belief formed at $t_1$\nlooks pretty reliable. And the process that runs from $t_1$ to $t_2$,\ni.e., the process of believing that things are as machine $D$ says they\nare, also looks pretty reliable, so that belief looks pretty reliable.\nAnd the process that runs from $t_2$ to $t_3$, i.e., the process of\ndrawing obvious logical consequences from beliefs formed by reliable\nprocesses, also looks pretty reliable. It's true that at $t_2$, $S$\ndoesn't know she's using a reliable process. And hence at $t_3$, $S$\ndoesn't know that this is the kind of process that she's using. But none\nof this should matter to an externalist like the reliabilist, since they\nthink what matters is actual reliability, not known reliability.\n\nBut there are two problems lurking in the vicinity. First, many people\nthink that it is very bizarre that $S$ can form a justified belief that\n$D$ is accurate at $t_0$ on the basis of simply looking at $D$. That's\nthe intuition behind the bootstrapping problem. Second, the case looks\nlike an instance of the Temporal Generality Problem. The two problems\nare related. Kornblith's solution to the bootstrapping problem is to\ninsist that the process used is in fact *unreliable*. What he means to\ndraw our attention to is that the process which runs from $t_0$ to $t_3$\nis unreliable. And he's right. That looks like a process of determining\nwhether a machine is accurate by simply looking at the machine and\ntrusting it. Of course, there are several other ways we could classify\nthe process used, but Kornblith argues that this is the best\nclassification, and I think he's right. And if he is right, then we have\npart of a solution to the bootstrapping problem.\n\nBut if Kornblith is right, then we pretty clearly also have a nasty\ninstance of the Temporal Generality Problem. Because now it looks like a\nchain of three reliable processes, those that run from $t_0$ to $t_1$,\nfrom $t_1$ to $t_2$, and from $t_2$ to $t_3$, collectively form an\nunreliable process. The belief that is formed at $t_3$ is the\nculmination of two processes; a reliable one that runs from $t_2$ to\n$t_3$, and an unreliable one that runs from $t_0$ to $t_3$. If a belief\nis justified iff it is the outcome of a reliable process, and\nunjustified iff it is the outcome of an unreliable process, then the\nbelief is both justified and unjustified, which is a contradiction.\n\nHow could the reliabilist escape this problem? I can see only two ways\nout. One is to say that the process that runs from $t_0$ to $t_3$ is in\nfact a reliable process. But that's to fall back into the bootstrapping\nproblem. And in any case, it seems absurd, since that process really\ndoes look like a process of determining whether a machine is reliable by\nsimply looking at it. The other is to say that the process that runs\nfrom $t_2$ to $t_3$ is unreliable. To do that, we'd need to come up with\na natural kind of process which is unreliable, and which this process\ninstantiates. This does not look easy. I'm not going to insist this\ncouldn't be done, but I'll end by noting three challenges that stand in\nthe way of getting it done, and which seem pretty formidible.\n\nFirst, if we say the process that runs from $t_2$ to $t_3$ is\nunreliable, then we are putting general restrictions on how we can\nobtain knowledge by deductive inference. As John @Hawthorne2005Closure\nargues, any such restrictions will be hard to motivate.\n\nSecond, the restrictions will have to be fairly sweeping to cover the\nrange of conclusions that, intuitively, cannot be drawn through this\nkind of reasoning. Imagine a variant on the above example where at\n$t_3$, $S$ concludes that either $D$ is accurate at $t_0$ or it will\nsnow tomorrow. That's entailed, obviously, by what she knows at $t_2$.\nAnd yet the process of getting from $t_0$ to that conclusion seems\nunreliable. So we can't simply say that what's ruled out are cases where\nthe agent draws a conclusion that is simply about $D$.\n\nThird, the classification of the process that runs from $t_2$ to $t_3$\nmust not merely fail to be ad hoc, it must plausibly be the most natural\nclassification available. And yet it seems there is one very natural\nclassification that is not available, namely the classification of the\nprocess as an instance of deduction from known premises, or from\npremises arrived at by highly reliable processes.\n\nSo the challenge this problem raises for reliabilism is substantial. I\ndon't mean to say it is a knock-down drawn-out refutation; philosophical\narguments rarely are. But it does add a new dimension to the generality\nproblem, and as we've seen in the last few paragraphs, put some new\nconstraints on solutions to the old version of the generality problem.\n\n[^1]: On process reliabilism, see [@Goldman1979]. On the generality\n    problem, see [@Feldman1985; @ConeeFeldman1998]\n\n[^2]: On non-rigorous techniques, see [@Davey2003]; on idealisations,\n    see [@Davey2011].\n\n[^3]: On some theories of perception, it might be that $t_0 = t_1$,\n    since perception involves belief formation. I don't mean to rule\n    those theories out; the notation here is meant to be consistent with\n    the hypothesis that $t_0 = t_1$.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}