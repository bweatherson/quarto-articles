{
  "hash": "6b0853b43c640d632f7573c7d154fd0e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Should We Respond to Evil With Indifference?\"\ndescription: |\n In a recent article, Adam Elga outlines a strategy for \"Defeating Dr Evil with Self-Locating Belief\". The strategy relies on an indifference principle that is not up to the task. In general, there are two things to dislike about indifference principles: adopting one normally means confusing risk for uncertainty, and they tend to lead to incoherent views in some 'paradoxical' situations. I argue that both kinds of objection can be levelled against Elga's indifference principle. There are also some difficulties with the concept of evidence that Elga uses, and these create further difficulties for the principle.\ndate: May 1 2005\nauthor:\n  - name: Brian Weatherson \n    url: http://brian.weatherson.org\n    affiliation: University of Michigan\n    affiliation_url: https://umich.edu\n    orcid_id: 0000-0002-0830-141X\ndoi: \"j.1933-1592.2005.tb00417.x\"\ncategories:\n  - epistemology\n  - scepticism\ncitation_url: https://doi.org/j.1933-1592.2005.tb00417.x\njournal:\n    title: \"Philosophy and Phenomenological Research\"\n    publisher: \"Wiley\"\nvolume: 70\nnumber: 3\ncitation: false\nbibliography: ../../../articles/Rbib.bib\nself-contained: false\npreview: evilcat.jpg\noutput:\n  distill::distill_article:\n    toc: true\n    toc_depth: 3\n    number_sections: true\n---\n\n\n\nIn a recent article, Adam @Elga2004 outlines a strategy for \"Defeating\nDr Evil with Self-Locating Belief\". The strategy relies on an\nindifference principle that is not up to the task. In general, there are\ntwo things to dislike about indifference principles: adopting one\nnormally means confusing risk for uncertainty, and they tend to lead to\nincoherent views in some 'paradoxical' situations. Each kind of\nobjection can be levelled against Elga's theory, but because Elga is\nmore careful than anyone has ever been in choosing the circumstances\nunder which his indifference principle applies we have to be similarly\ncareful in focussing the objections. Even with this care the objections\nI put forward here will be less compelling than, say, the objections\n[@Keynes1921 Ch. 4] put forward in his criticisms of earlier\nindifference principles. But there still may be enough to make us reject\nElga's principle. The structure of this note is as follows. In and 2 I\nset out Elga's theory, in and 4 I discuss some initial objections that I\ndon't think are particularly telling, in I discuss some paradoxes to\nwhich Elga's theory seems to lead (this is reprised in where I discuss a\nsomewhat different paradoxical case) and in and 8 I argue that even\nElga's careful indifference principle involves a risk/uncertainty\nconfusion.\n\n<aside>\nPublished in _Philosophy and Phenomenal Research_ 70: 613-35. \n\nThanks to Jamie Dreier, Adam Elga and an anonymous referee for helpful discussions about this paper and suggestions for improvements.\n</aside>\n\n### From Basel to Princeton\n\nIn [-@Lewis1979b] David Lewis argued that the contents of contentful\nmental states were not propositions, but properties. When I think that\nI'm a rock star, I don't attribute truth to the proposition *Brian is a\nrock star*, but rather attribute the property of rock stardom to myself.\nLewis was led to this position by considering cases where a believer is\nmistaken about his own identity. For example, if I believe that I'm a\nrock star without believing that I'm Brian, and in fact while thinking\nthat Brian is an infamous philosopher, it is odd to attribute to me\nbelief in the proposition *Brian is a rock star*. But it is perfectly\nnatural to say I self-attribute rock stardom, and that's just what Lewis\nsays.\n\nIf we accept Lewis's position, there are two paths we can take. First,\nwe can try simply replacing all talk of propositional attitudes with\ntalk of proprietal attitudes, and trusting and hoping that this won't\nmake a difference to our subsequent theorising. Alternatively, we can\nsee if changing the type of entity that is the content of a contentful\nstate has distinctive consequences, and in particular see if it gives us\nthe conceptual resources to make progress on some old problems. That's\nthe approach Adam Elga has taken in a couple of papers, and whatever one\nthinks of his conclusions, the early returns certainly suggest that this\nLewisian outlook will prove remarkably fruitful.\n\nOn the Lewisian approach, credences are defined over properties, and\nproperties are sets of possibilia, i.e. centred worlds. Some properties\nare maximally precise, they are satisfied by exactly one possible\nobject. Elga sometimes calls these maximally specific properties\n*predicaments* because they specify exactly what is happening to the\nagent that instantiates one. Say predicaments *F*~1~ and *F*~2~ are\nsimilar iff the *F*~1~ and the *F*~2~ are worldmates and their\nexperiences are indistinguishable. Elga's principle INDIFFERENCE says\nthat if predicaments *F*~1~ and *F*~2~ are similar then any rational\nagent should assign equal credence to *F*~1~ and *F*~2~. This becomes\nmost interesting when there are similar *F*~1~ and *F*~2~. So, for\ninstance, consider poor O'Leary.\n\nO'LEARY\n\n:   O'Leary is locked in the trunk of his car overnight. He knows that\n    he'll wake up briefly twice during the night (at 1:00 and again at\n    2:00) and that the awakenings will be subjectively indistinguishable\n    (because by 2:00 he'll have forgotten the 1:00 awakening). At 1:00\n    he wakes up.\n\nElga says that when O'Leary wakes up, he should assign equal credence to\nit being 1:00 as to it being 2:00. So, provided O'Leary knows that one\nof these two hypotheses is true, INDIFFERENCE says that he should assign\ncredence 1/2 to it being 1:00 at the wake up.\n\nElga has an argument for INDIFFERENCE, which we shall get to by , but\nfor a while I will look at some immediate consequences of the position.\nI'll start with two reasons to think that INDIFFERENCE needs to be\nstrengthened to play the role he wants it to play.\n\n### Add it Up\n\nOne difficulty with INDIFFERENCE as stated so far is that it applies\nonly to very narrow properties, predicaments, and it is not clear how to\ngeneralise to properties in which we are more interested.\n\nBERNOULLIUM\n\n:   Despite months of research, Leslie still doesn't know what the\n    half-life of Bernoullium, her newly discovered element is. It's\n    between one and two nanoseconds, but she can't manufacture enough of\n    the stuff to get a better measurement than that. She does, however,\n    know that she's locked in the trunk of her car, and that like\n    O'Leary she will have two indistinguishable nocturnal awakenings.\n    She's having one now in fact, but naturally she can't tell whether\n    it is the first or the second.\n\nINDIFFERENCE says that Leslie should assign credence 1/2 to it being the\nfirst wake-up, right? Not yet. All that INDIFFERENCE says is that any\ntwo predicaments should receive equal credence. A predicament is\nmaximally specific, so it specifies, *inter alia*, the half-life of\nBernoullium. But for any *x*, Leslie assigns credence 0 to *x* being the\nhalf-life of Bernoullium, because there are uncountably many candidates\nfor being the half-life, and none of them look better than any of the\nothers. So she assigns credence 0 to every predicament, and so she\nsatisfies INDIFFERENCE no matter what she thinks about what the time is.\nEven if, for no reason at all, she is certain it is her second\nawakening, she still satisfies INDIFFERENCE as it is written, because\nshe assigns credence 0 to every predicament, and hence equal credence to\nsimilar predicaments.\n\nFortunately, we can strengthen INDIFFERENCE to cover this case. To\nstart, note that the motivations for INDIFFERENCE suggest that if two\npredicaments are similar then they should receive equal credence not\njust in the agent's actual state, but even when the agent gets more\nevidence. Leslie should keep assigning equal credence to it being her\nfirst or second wake up if she somehow learns what the half-life of\nBernoullium is, for example. This suggests the following principle:\n\nC-INDIFFERENCE\n\n:   If *F*~1~ and *F*~2~ are similar, and an agent does not *know* that\n    she is in neither, then her conditional credence on being *F*~1~,\n    conditional on being either *F*~1~ or *F*~2~, should be 1/2.[^1]\n\nBut even this doesn't quite resolve our problem. Simplifying Leslie's\nsituation somewhat, the live predicaments are all of the following form:\nthis is the first/second awakening, and the half-life of Bernoullium is\n*x*. C-INDIFFERENCE requires that for any *c*, conditional on the\nhalf-life of Bernoullium being *c*, Leslie assign credence 1/2 to it\nbeing her first awakening. From this and the fact that Leslie's credence\nfunction is a probability function it *doesn't* follow that her credence\nin this being her first awakening is 1/2. So to get INDIFFERENCE to do\nthe work it is meant to do in Leslie's case (and presumably O'Leary's\ncase, since in practice there will be some other propositions about\nwhich O'Leary is deeply uncertain) I think we need to strengthen it to\nthe following.\n\nP-INDIFFERENCE\n\n:   If *G*~1~ and *G*~2~ are properties such that:\n\n    1.  For all worlds *w*, there is at most one *G*~1~ in *w* and at\n        most one *G*~2~ in *w*;\n\n    2.  For all worlds *w*, there is a *G*~1~ in *w* iff there is a\n        *G*~2~ in *w*; and\n\n    3.  For all worlds *w* where there is a *G*~1~ in *w*, the *G*~1~\n        and the *G*~2~ have indistinguishable experiences; then\n\n    *G*~1~ and *G*~2~ deserve equal credence.\n\nElga does not endorse either C-INDIFFERENCE or P-INDIFFERENCE, but I\nsuspect he should given his starting assumptions. It is hard to believe\nif O'Leary is certain about everything save what time it is, then\nrationality imposes very strong constraints on his beliefs about time,\nwhile rationality imposes no such constraints should he (or Leslie) be\nuncertain about the half-life of Bernoullium. Put another way, it is\nhard to believe that in her current state Leslie could rationally assign\ncredence 0.9 to this being her first awakening, but if she decided the\nhalf-life of Bernoullium is 1.415 nanoseconds, then she would be\nrequired to change that credence to 0.5. If we have INDIFFERENCE without\nP-INDIFFERENCE, that is possible. So I will assume in what follows that\nif C-INDIFFERENCE and P-INDIFFERENCE are false then INDIFFERENCE is\nheavily undermined.[^2]\n\n### Out of sight, out of mind\n\nElga's discussion presupposes two kinds of internalism. First, he\nassumes that some internalist theory of experience is true. Second, he\nassumes that some internalist theory of justification is true. If the\nfirst assumption is false it threatens the applicability of the theory.\nIf the second assumption is false it threatens the truth of the theory.\n\nAn externalist theory of experience says that what kind of experience\n*S* is having is determined, inter alia, by what *S* is experiencing.\nWhile setting out such a view, John [@Campbell2002 124-6] says that two\npeople sitting in duplicate prison cells looking at duplicate coffee\ncups will have different experiences, because one will have an\nexperience of the coffee cup in her hand, and the other will not have an\nexperience of that cup. This does not threaten INDIFFERENCE, but it does\nseem to render it trivial. On Campbell's view, if two agents are able to\nmake demonstrative reference to different objects, and there is no\nreason to think Elga's agents in allegedly similar but not numerically\nidentical predicaments cannot, they are having different experiences.\nHence the situations are not really similar after all. Strictly\nspeaking, this is good news for INDIFFERENCE, since it is hard given\nthis view of experience to find counterexamples to it. But I doubt that\nElga will be happy with this defence.\n\nThe second kind of internalist assumption is more threatening. Many\nexternalists about justification think whether a particular experience\njustifies a belief for an agent depends not just on intrinsic features\nof that experience, but on the relationship between experiences of that\nkind and the world around the agent. In some versions of this,\nespecially the version defended by Timothy @Williamson1998-WILCOK,\nwhether an experience either constitutes or produces evidence depends on\nwhether it constitutes or produces knowledge. Since it is not clear that\nany two similar agents know the same thing, since it is clear that they\ndo not have the same *true* *beliefs*, on Williamson's theory it seems\nthat the agents will not have the same evidence. In particular, it is\npossible that part of one agent's evidence is inconsistent with her\nbeing the other agent. If part of her evidence is that she has hands,\nthen she is not a brain-in-a-vat having experiences like hers, and she\nshould not assign high credence to the claim that she is one, no matter\nwhat INDIFFERENCE says. So Elga needs to reject this kind of externalism\nabout evidence. This is not a devastating objection. I am sure that Elga\ndoes reject Campbell's and Williamson's theories, so just raising them\nagainst him without argument would be question-begging. But this does\nmean that the target audience for INDIFFERENCE is smaller than for some\nphilosophical claims, since adherents of Campbell's or Williamson's\nviews will be antecedently disposed to think INDIFFERENCE is useless or\nfalse.\n\n### It's Evidently Intransitive\n\nDakota is sitting in a bright green room. She is trying to reconstruct\nhow she got there when Dr Evil informs her just what happened. An\nepistemology student, not coincidentally called Dakota, was snatched out\nof her study and duplicated 999 times over. The duplicates were then\nnumbered (though we've lost which number was given to the original) each\nput in a coloured cell. The thousand coloured cells rotated slowly\nthrough the colour sphere, starting with cell 0 (the new home of Dakota\nnumber 0) being green, going blueish until cell 250 (for Dakota number\n250) is just blue, then reddish until cell 500 is just red, swinging\nthrough the yellows with pure yellow reached at 750, and then back to\nthe greens, with 999 being practically identical to 1000. For any *n*,\ncells number *n* and *n*+1 are indistinguishable. That means that Dakota\nnumber *n* is similar, in Elga's sense, to Dakota number *n*+1, for\ntheir (apparent) experiences before being in the rooms are identical,\nand their experiences in the rooms are indistinguishable. Hence our\nDakota, sitting in the bright green room, should assign equal credence\nto being Dakota number *n* and Dakota number *n*+1 for any *n*. But this\nis absurd. Since she can see that her walls are green, she should assign\nhigh credence to being Dakota number 0, and credence 0 to being Dakota\nnumber 500.\n\nThe problem here is that Elga wants to define an equivalence relation on\npredicaments, the relation *deserving the same credence as*, out of an\nintransitive relation, *being indistinguishable from*. There are two\npossible responses, each of them perfectly defensible.\n\nFirst, Elga could deny the premise that the adjacent cells are\nindistinguishable. Although there is some prima facie plausibility to\nthe claim that some different colours are indistinguishable, Delia Graff\n@Fara2001 has argued that this is false. It would mean committing to yet\nanother controversial philosophical position, but if Elga endorsed\nGraff's claims, he could easily deal with Dakota.\n\nSecondly, he could tinker with the definition of similarity. Instead of\nsaying that possibilia represent similar predicaments iff they are\nindistinguishable worldmates, he could say that they represent similar\npredicaments iff they are worldmates that are indistinguishable from the\nsame predicaments. (This kind of strategy for generating an equivalence\nrelation from an intransitive relation is borrowed from @Goodman1951.)\nEven if adjacent cells are indistinguishable from each other, they will\nnot be indistinguishable from the same cells. This delivers the\nplausible result that the duplicate Dakotas stuck in the cells do not\ninstantiate similar predicaments. Some might object that this move is ad\nhoc, but once we realise the need to make *similar* an equivalence\nrelation, it seems clear enough that this is the most natural way to do\nthat.\n\n### Morgan and Morgan and Morgan and Morgan\n\nI think I outdid myself this time, said Dr Evil. I was just going along\nduplicating you, or at least someone like you, and the duplication\nprocess was taking less and less time. So I thought, I wonder what is\nthe lower bound here? How quick can we make the duplication process? So\nI tried a few things to cut down the time it took, and I got a little\nbetter with practice, and, well, it turns out that the time taken can be\nmade arbitrarily small. Before I knew it, there were infinitely many of\nyou. Oops.\n\nMorgan was a little shocked. She could cope with having a duplicate or\ntwo around, but having infinitely many duplicates was a little hard to\ntake. On the other hand, and this was hard to think about, perhaps she\nshould be grateful. Maybe she was one of the later ones created, and she\nwouldn't have existed if not for Evil's irrational exuberance. She\nstarted to ponder how likely that was, but she was worried that it\nrequired knowing more about Evil than any mortal could possibly know.\n\nWell, continued Dr Evil, I did one thing right. As each duplicate was\ncreated I gave it a serial number, 0 for the original Morgan, 1 for the\nfirst duplicate and so on, so the bookkeeping will be easier. Don't go\nlooking for it, it's written on your left leg in ectoplasmic ink, and\nyou won't be able to see it.\n\nNow that makes things easier, thought Morgan. By INDIFFERENCE the\nprobability that my serial number is *x* is 1/*n*, where *n* is the\nnumber of duplicates created. So dividing 1 by infinity, that's zero. So\nthe probability that my serial number is less than *x* is the\nprobability that it's zero plus the probability that it's one plus ...\nplus the probability that it's *x*, that's still zero. So if he had\nstopped after *x* for any *x*, I would not exist with probability one.\nI'm liking Evil more and more, though something bothers me about that\ncalculation.\n\nMorgan was right to worry. She's just talked herself, with Elga's help,\ninto a violation of the principle of countable additivity. The\nadditivity axiom in standard probability theory says that for any two\ndisjoint propositions, the probability of their disjunction is the sum\nof their probabilities. The countable additivity axiom says that for any\ncountable set of disjoint propositions, the probability that at least\none of them is true is the sum of each of their probabilities. (It\nfollows from the axioms of probability theory that this sum is always\ndefined.) Here we have to alter these axioms slightly so they apply to\nproperties rather than propositions, but still the principle of\ncountable additivity seems plausible. But Morgan has to violate it. The\nprobability she assigns to having some serial number or other is not\nzero, in fact it is one as long as she takes Evil at his word. But for\neach *x*, the probability that her serial number is *x* is zero. In\nsymbols, we have\n\n-   *Pr*(${\\exists}$*x* (Serial number = *x*)) = 1\n\n-   ${\\Sigma}$*Pr*(Serial number = *x*) = 0\n\nBut countable additivity says that these values should be equal.\n\nOrthodoxy endorses countable additivity, but there are notable\ndissenters that are particularly relevant here. Bruno @deFinetti1974\nargued that countable additivity should be rejected because it rules out\nthe possibility of an even distribution across the natural numbers.\nDeFinetti thought, as Morgan does, that we could rationally be in a\nposition where we know of a particular random variable only that its\nvalue is a non-negative integer, and for every *x*, we assign equal\nprobability to each hypothesis that its value is *x*. Since that is\ninconsistent with countable additivity, all the worse for countable\nadditivity. This is a decent argument, though as de Finetti himself\nnoted, it has some counterintuitive consequences.\n\nI decided, Dr Evil continued, to do something fairly spectacular with\nall these people. By some small tinkering with your physiology I found a\nway to make you immortal. Unfortunately, a quick scan of your psychology\nrevealed that you weren't capable of handling eternity. So every fifty\nyears I will wipe all your memories and return you to the state you were\nin when duplicated. I will write, or perhaps I did write, on your right\nleg the number of times that your memories have been thus wiped. Don't\nlook, it's also in ectoplasmic ink. Just to make things fun, I made\nenough duplicates of myself so that every fifty years I can tell you\nwhat happened. Each fifty-year segment of each physical duplicate will\nbe an epistemic duplicate of every other such segment. How cool is\nthat?[^3]\n\nMorgan was not particularly convinced that it was cool, but an odd\nthought crossed her mind once or twice. She had one number *L* written\non her left leg, and another number *R* written on her right leg. She\nhad no idea what those numbers were, but she thought she might be in a\nposition to figure out the odds that *L* ${\\geq}$ *R*. So she started\nreasoning as follows, making repeated appeals to C-INDIFFERENCE. (She\nmust also appeal to P-INDIFFERENCE at every stage if there are other\npropositions about which she is uncertain. Assume that appeal made.)\n\nLet's say the number on my left leg is 57. Then *L* ${\\geq}$ *R* iff\n*R* \\< 58. But since there are 58 ways for *R* \\< 58 to be true, and\ninfinitely many ways for *R* \\< 58 to be false, and by C-INDIFFERENCE\neach of these ways deserve the same credence conditional on *L* = 57, we\nget *Pr*(*L* ${\\geq}$ *R*  *L* = 57) = 0. But 57 was arbitrary in this\nlittle argument, so I can conclude ${\\forall}$*l*:\n*Pr*(*L* ${\\geq}$ *R*  *L* = *l*) = 0. This seems to imply that\n*Pr*(*L* ${\\geq}$ *R*) = 0, especially since I know *L* takes some value\nor other, but let's not be too hasty.\n\nLet's say the number on my right leg is 68. Then *L* ${\\geq}$ *R* iff\n*L* ${\\geq}$ 68. And since there are 68 ways for *L* ${\\geq}$ 68 to be\nfalse, and infinitely many ways for it to be true, and by C-INDIFFERENCE\neach of these ways deserve the same credence conditional on *R* = 68, we\nget *Pr*(*L* ${\\geq}$ *R*  *R* = 68) = 1. But 68 was arbitrary in this\nlittle argument, so I can conclude ${\\forall}$*r*:\n*Pr*(*L* ${\\geq}$ *R*  *R* = *r*) = 1. This seems to imply that\n*Pr*(*L* ${\\geq}$ *R*) = 1, especially since I know *R* takes some value\nor other, but now I'm just confused.\n\nMorgan is right to be confused. She has not quite been led into\ninconsistency, because as she notes the last step, from\n${\\forall}$*l*: *Pr*(*L* ${\\geq}$ *R*  *L* = *l*) = 0 to\n*Pr*(*L* ${\\geq}$ *R*) = 0 is not *forced*. In fact, the claim that this\nis always a valid inferential step is equivalent to the principle of\ncountable additivity, which we have already seen a proponent of\nINDIFFERENCE in all its variations must reject. But it would be a\nmistake to conclude from this that we just have a standoff. What\nMorgan's case reveals is that accepting the indifference principles that\nElga offers requires giving up on an intuitively plausible principle of\ninference. That principle says that if the probability of *p*\nconditional on any member of a partition is *x*, then the probability of\n*p* is *x*. If we think that principle of inference is *prima facie*\nmore plausible than Elga's principle of indifference, as I think we\nshould, that is pretty good *prima facie* evidence that Elga's principle\nis wrong.\n\nThe next three sections will be devoted to determining whether we can\nconvert this persuasive argument into a knockdown argument (we cannot)\nand whether Elga's arguments in favour of INDIFFERENCE do enough to\novercome this *prima facie* argument that INDIFFERENCE is flawed (they\ndo not). A concluding section notes how to redo this argument so it\nappeals only to potential rather than actual infinities.\n\n### Intermission\n\nCHARYBDIS: I know how to make that argument stronger. Just get\nEvil to offer Morgan a bet on whether *L* ${\\geq}$ *R*. Ask how much\nshe'll pay for a bet that pays €1 if *L* ${\\geq}$ *R* and nothing\notherwise. If she pays anything for it, tell her the value of *L*,\nwhatever it is, and ask her if she'd like to sell that bet back for half\nwhat she paid for it. Since she now assigns probability zero to\n*L* ${\\geq}$ *R* she'll happily do that, and then she'll have lost\nmoney. If she won't pay anything for the bet to start with, offer her\nthe reverse bet. She should pay €1 for that, and now apply the same\ntactics except tell her the value of *R* rather than *L*. Either way the\nstupid person will lose money.\n\nSCYLLA:Very practical Charybdis, but we're not sure it gets to the heart\nof the matter. Not sure. Well, let us say why rather than leaving it\nlike that. For one thing, Morgan might not like playing dice with Evil,\neven if Evil is the source of her life. So she might have a maximum\nprice of 0 for either bet.\n\nCHARYBDIS:But then surely she'll be turning down a sure win. I mean\nbetween the bets she has a sure gain of at least €1.\n\nSCYLLA:And if she is offered both bets at once we're sure she would take\nthat gain, but as we heard your story she wasn't.[^4]\n\nCHARYBDIS:So does this mean her degree of belief in both\n*R* ${\\geq}$ *L* and *L* ${\\geq}$ *R* is 0?\n\nSCYLLA:It might mean that, and of course some smart people have argued\nthat that is coherent, much to the chagrin of your Bayesian friends\nwe're sure.[^5] But more likely it means that she just isn't following\nthe patterns of practical reasoning that you endorse.[^6] Also, we're\nnot so sure about the overall structure of the argument. We think your\nreasoning is as follows. Morgan ends up doing something silly, giving up\nmoney. (Well, we're not sure that's always silly, but let's say it is\nhere.) So something went wrong. So she has silly beliefs. That last step\ngoes by fairly fast we think. From her making some mistake or other, we\ncan only conclude that, well, she made some mistake or other, not that\nshe made some particular mistake in the composition of her\ncredences.[^7]\n\nCHARYBDIS:What other mistake might she have made?\n\nSCYLLA:There are many hidden premises in your chains of reasoning to\nconclusions about how Morgan should behave. For instance, she only\nvalues a €1 bet on *L* ${\\geq}$ *R* at *Pr*(*L* ${\\geq}$ *R*) if she\nknows she can't buy that bet more cheaply elsewhere, or sell it for a\nlarger price elsewhere. Even if those assumptions are *true*, Morgan may\nunreasonably believe they are false, and that might be her mistake.[^8]\nBut even that isn't our main concern. Our main concern is that you\nunderstate how bad Morgan's position is.\n\nCHARYBDIS:What's worse for a mortal than assured loss of money?\n\nSCYLLA:Morgan is not a mortal any more, you know. And immortals we're\nafraid are almost bound to lose money to clever enough tricksters.\nIndeed, a so-called Dutch Book can be made against any agent that (a)\nhas an unbounded utility function and (b) is not overly opinionated, so\nthere are still infinitely many ways the world could be consistent with\ntheir knowledge.[^9] That includes us, and you dear Charybdis. And yet\nwe are not as irrational as that Morgan. I don't think analogising her\nposition to ours really *strengthens* the case that she is irrational.\n\nCHARYBDIS:Next you might say that making money off her, this undeserving\nimmortal, is immoral.\n\nSCYLLA:Perish the thoughts.\n\n### Risky Business?\n\nThere are two kinds of reasons to dislike indifference principles, both\nof them developed most extensively in @Keynes1921. The first, which we\nhave been exploring a bit so far, is that such principles tend to lead\nto incoherence. The second is that such principles promote confusion\nbetween risk and uncertainty.\n\nOften we do not know exactly what the world is like. But not all kinds\nof ignorance are alike. Sometimes, our ignorance is like that of a\nroulette player facing a fair wheel about to be spun. She knows not what\nwill happen, but she can provide good reasons for assigning equal\ncredence to each of the 37 possible outcomes of the spin. Loosely\nfollowing Frank @Knight1921, we will say that a proposition like *The\nball lands in slot number 18* is **risky**. The distinguishing feature\nof such propositions is that we do not know whether they are true or\nfalse, but we have good reason to assign a particular probability to\ntheir truth. Other propositions, like say the proposition that there\nwill be a nuclear attack on an American city this century, are quite\nunlike this. We do not know whether they are true, and we aren't really\nin a position to assign anything like a precise numerical probability to\ntheir truth. Again following Knight, we will say such propositions are\n**uncertain**. In [-@Keynes1937] Keynes described a number of other\nexamples that nicely capture the distinction being drawn here.\n\n> By 'uncertain' knowledge, let me explain, I do not mean merely to\n> distinguish what is known for certain from what is only probable. The\n> game of roulette is not subject, in this sense, to uncertainty; nor is\n> the prospect of a Victory bond being drawn. Or, again, the expectation\n> of life is only slightly uncertain. Even the weather is only\n> moderately uncertain. The sense in which I am using the term is that\n> in which the prospect of a European war is uncertain, or the price of\n> copper and the rate of interest twenty years hence, or the\n> obsolescence of a new invention, or the position of private wealth\n> owners in the social system in 1970. About these matters there is no\n> scientific basis on which to form any calculable probability whatever.\n> We simply do not know. Nevertheless, the necessity for action and\n> decision compels us as practical men to do our best to overlook this\n> awkward fact and to behave exactly as we should if we had behind us a\n> good Benthamite calculation of a series of prospective advantages and\n> disadvantages, each multiplied by its appropriate probability, waiting\n> to be summed. [@Keynes1937 114-115]\n\nNote that the distinction between risky and uncertain propositions is\nnot the distinction between propositions whose objective chance we know\nand those that we don't. This identification would fail twice over.\nFirst, as Keynes notes, whether a proposition is risky or uncertain is a\nmatter of degree, but whether we know something is, I presume, not a\nmatter of degree.[^10] Second, there are risky propositions with an\nunknown chance. Assume that our roulette player turns away from the\ntable at a crucial moment, and misses the ball landing in a particular\nslot. Now the chance that it lands in slot 18 is 1 (if it did so land)\nor 0 (otherwise), and she does not know which. Yet typically, the\nproposition *The ball lands in slot 18* is still risky for her, for she\nhas no reason to change her attitude towards the proposition that it did\nland in slot 18.\n\nMy primary theoretical objection to INDIFFERENCE is that the\npropositions it purports to provide guidance on are really uncertain,\nbut it treats them as risky. Once we acknowledge the risk/uncertainty\ndistinction, it is natural to think that our default state is\nuncertainty. Getting to a position where we can legitimately treat a\nproposition as risky is a cognitive achievement. Traditional\nindifference principles fail because they trivialise this achievement.\nAn extreme version of such a principle says we can justify assigning a\nparticular numerical probability, 0.5, to propositions merely on the\nbasis of ignorance of any evidence telling for or against it. This might\nnot be an issue to those who think that \"probability is a measure of\nyour ignorance.\" [@Poole1998 348] But to those of us who think\nprobability is the very guide to life, such a position is unacceptable.\nIt seems to violate the platitude 'garbage in, garbage out' since it\ntakes ignorance as input, and produces a guide to life as output.\nINDIFFERENCE is more subtle than these traditional indifference\nprinciples, but this theoretical objection remains. The evidence that\nO'Leary or Morgan or Leslie has does not warrant treating propositions\nabout their location or identity as risky rather than uncertain. When\nthey must make decisions that turn on their identity or location, this\nignorance provides little or no guidance, not a well-sharpened guide to\naction.\n\nIn this section I argue that treating these propositions as uncertain\nlets us avoid the traps that Morgan falls into. In the next section I\nargue that the case Elga takes to support INDIFFERENCE says nothing to\nthe theorist who thinks that the INDIFFERENCE principle conflates risk\nand uncertainty. In fact, some features of that case seem to support the\nclaim that the propositions covered by INDIFFERENCE are uncertain, not\nrisky.\n\nIn [-@Keynes1921], Keynes put forward a theory of probability that was\ndesigned to respect the distinction between risky propositions and\nuncertain propositions. He allowed that some propositions, the risky\nones and the ones known to be true or false, had a numerical probability\n(relative to a body of evidence) while other propositions have\nnon-numerical probabilities. Sometimes numerical and non-numerical\nprobabilities can be compared, sometimes they cannot. Arithmetic\noperations are all assumed to be defined over both numerical and\nnon-numerical probabilities. As @RamseyTruthProb pointed out, in\nKeynes's system it is hard to know what ${\\alpha}$ + ${\\beta}$ is\nsupposed to mean when ${\\alpha}$ and ${\\beta}$ are non-numerical\nprobabilities, and it is not even clear that '+' still means *addition*\nin the sense we are used to.\n\nOne popular modern view of probability can help Keynes out here.\nFollowing Ramsey, many people came to the view that the credal states of\na rational agent could be represented by a probability function, that\nfunction being intuitively the function from propositions into the\nagent's degree of belief in that proposition. In the last thirty years,\nthere has been a lot of research on the theory that says we should\nrepresent rational credal states not by a single probability function,\nbut by a set of such probability functions. Within philosophy, the most\nimportant works on this theory are by Henry @Kyburg1974, Isaac @Levi1974\n[@Levi1980], Richard @Jeffrey1983 and Bas @vanFraassen1990. What is\nimportant here about this theory is that many distinctive features of\nKeynes's theory are reflected in it.\n\nLet *S* be the set of probability functions representing the credal\nstates of a rational agent. Then for each proposition *p* we can define\na set *S*(*p*) = {*Pr*(*p*): *Pr* ${\\in}$ *S*}. That is, *S*(*p*) is the\nset of values that *Pr*(*p*) takes for *Pr* being a probability function\nin *S*. We will assume here that *S*(*p*) is an interval. (See the\nearlier works cited for the arguments in favour of this assumption.)\nWhen *p* is risky, *S*(*p*) will be a singleton, the singleton of the\nnumber we have compelling reason to say is the probability of *p*. When\n*p* is a little uncertain, *S*(*p*) will be a fairly narrow interval.\nWhen it is very uncertain, *S*(*p*) will be a wide interval, perhaps as\nwide as [0, 1]. We say that *p* is more probable than *q* iff for all\n*Pr* in *S*, *Pr*(*p*) \\> *Pr*(*q*), and as probable as *q* iff for *Pr*\nin *S*, *Pr*(*p*) = *Pr*(*q*). This leaves open the possibility that\nKeynes explicitly left open, that for some uncertain proposition *p* and\nsome risky proposition *q*, it might be the case that they are not\nequally probable, but neither is one more probable than the other.\nFinally, we assume that when an agent whose credal states are\nrepresented by *S* updates by learning evidence *e*, her new credal\nstates are updated by conditionalising each of the probability functions\nin *S* on *e*. So we can sensibly talk about *S*(*p*  *e*), the set\n{*Pr*(*p*  *e*): *Pr* ${\\in}$ *S*}, and this represents her credal\nstates on learning *e*.\n\n(It is an interesting historical question just how much the theory\nsketched here agrees with the philosophical motivations of Keynes's\ntheory. One may think that the agreement is very close. If we take\nKeynes's entire book to be a contextual definition of his non-numerical\nprobabilities, a reading encouraged by @Lewis1970c, then we should\nconclude he was talking about sets like this, with numerical\nprobabilities being singleton sets.)\n\nThis gives us the resources to provide good advice to Morgan. Pick a\nmonotone increasing function *f* from integers to [0, 1] such that as\n*n* ${\\rightarrow}$ ${\\infty}$, *f*(*n*) ${\\rightarrow}$ 1. It won't\nreally matter which function you pick, though different choices of *f*\nmight make the following story more plausible. Say that\n*S*(*L* ${\\geq}$ *R*  *L* = *l*) = [0, *f*(*l*)]. The rough idea is\nthat if *L* is small, then it is quite improbable that *L*\n ${\\geq}$ *R*, although this is a little uncertain. As *l* gets larger,\n*L* ${\\geq}$ *R* gets more and more uncertain. The overall effect is\nthat we simply do not know what *S*(*L* ${\\geq}$ *R*) will look like\nafter conditionalising on the value of *L*, so we cannot apply the kind\nof reasoning Morgan uses to now come to some conclusions about the\nprobability of *L* ${\\geq}$ *R*.\n\nIf we view the situations described by INDIFFERENCE as involving\nuncertainty rather than risk, this is exactly what we should expect. And\nnote that in so doing, we need not undermine the symmetry intuition that\nlies behind INDIFFERENCE. Assume that *F* and *G* are similar\npredicaments, and I know that I am either *F* or *G*. INDIFFERENCE says\nI should assign equal probability to each, so *S*(I am *F*) = *S*(I am\n*G*) = {0.5}. But once we've seen how attractive non-numerical\nprobabilities can be, we should conclude that all symmetry gives us is\nthat *S*(I am *F*) = *S*(I am *G*), which can be satisfied if each is\n[0.4, 0.6], or [0.2, 0.8] or even [0, 1]. (I think that for\nO'Leary, for example, *S*(It is 1 o'clock) should be a set somehow like\nthis.) Since I would *not* be assigning equal credence to *I am F* and\n*I am G* if I satisfied symmetry using non-numerical probabilities, so I\nwill violate INDIFFERENCE without treating the propositions\nasymmetrically. Such a symmetric violation of INDIFFERENCE has much to\nrecommend it. It avoids the incoherence that INDIFFERENCE leads to in\nMorgan's case. And it avoids saying that ignorance about our identity\ncan be a sharp guide to life.[^11]\n\nA referee noted that the intuitive characterisation here doesn't quite\ncapture the idea that we should treat similar predicaments alike. The\nrequirement that if *F* and *G* are similar then *S*(I am *F*) = *S*(I\nam *G*) does not imply that there will be a symmetric treatment of *F*\nand *G* within *S* if there are more than two similar predicaments. What\nwe need is the following condition. Let *T* be any set of similar\npredicaments, *g* any isomorphism from *T* onto itself, and *Pr* any\nprobability function in *S*. Then there exists a *Pr*$^\\prime$ in *S*\nsuch that for all *A* in *T*, *Pr*(*A*) = *Pr*$^\\prime$(*g*(*A*)). When\nthere are only two similar predicaments *A* and *B* this is equivalent\nto the requirement that *S*(*A*) = *S*(*B*), but in the general case it\nis a much stricter requirement. Still, it is a much weaker constraint\nthan INDIFFERENCE, and not vulnerable to the criticisms of INDIFFERENCE\nset out here.\n\n### Boyfriend in a Coma\n\nElga argues for INDIFFERENCE by arguing it holds in a special case, and\nthen arguing that the special case is effectively arbitrary, so if it\nholds there it holds everywhere. The second step is correct, so we must\nlook seriously at the first step. Elga's conclusions about the special\ncase, DUPLICATION, eventually rest on treating an uncertain proposition\nas risky.\n\nDUPLICATION\n\n:   After Al goes to sleep researchers create a duplicate of him in a\n    duplicate environment. The next morning, Al and the duplicate awaken\n    in subjectively indistinguishable states.\n\nAssume (in all these cases) that before Al goes to sleep he knows the\nrelevant facts of the case. In that case INDIFFERENCE[^12] dictates that\nwhen Al wakes up his credence in *I am Al* should be 0.5. Elga argues\nthis dictate is appropriate by considering a pair of related cases.\n\nTOSS-and-DUPLICATION\n\n:   After Al goes to sleep, researchers toss a coin that has a 10%\n    chance of landing heads. Then (regardless of the toss outcome) they\n    duplicate Al. The next morning, Al and the duplicate awaken in\n    subjectively indistinguishable states.\n\nElga notes, correctly, that the same epistemic norms apply to Al on\nwaking in DUPLICATION as in TOSS-and-DUPLICATION. So if we can show that\nwhen Al wakes in TOSS-and-DUPLICATION his credence in *I am Al* should\nbe 0.5, that too will suffice to prove INDIFFERENCE correct in this\ncase. The argument for that claim has three premises. (I've slightly\nrelabeled the premises for ease of expression.)\n\n1.  *Pr*(H) = 0.1\n\n2.  *Pr*(H (H ${\\wedge}$ A) ${\\vee}$ (T ${\\wedge}$ A)) = 0.1\n\n3.  *Pr*(H (H ${\\wedge}$ A) ${\\vee}$ (T ${\\wedge}$ D)) = 0.1\n\nHere *Pr* is the function from *de se* propositions to Al's degree of\nbelief in them, H = *The coin lands heads*, T = *The coin lands tails*,\nA = *I am Al* and D = *I am Al's duplicate*. From (1), (2) and (3) and\nthe assumption that *Pr* is a probability function it follows that\n*Pr*(*A*) = 0.5, as required. This inference goes through even in the\nKeynesian theory that distinguishes risk from uncertainty. Premise (1)\nis uncontroversial, but both (2) and (3) look dubious. Since the\nargument for (3) would, if successful, support (2), I'll focus, as Elga\ndoes, on (3). The argument for it turns on *another* case.\n\nCOMA\n\n:   As in TOSS-and-DUPLICATION, the experimenters toss a coin and\n    duplicate Al. But the following morning, the experimenters ensure\n    that only one person wakes up: If the coin lands heads, they allow\n    Al to wake up (and put the duplicate into a coma); if the coin lands\n    tails, they allow the duplicate to wake up (and put Al into a coma).\n\n(It's important that no one comes out of this coma, so assume that the\nvictim gets strangled.)\n\nElga then argues for the following two claims. If in COMA Al gets lucky\nand pulls through, his credence in H should be 0.1, as it was before he\nentered the dream world. Al's credence in H in COMA should be the same\nas his conditional credence in H should be the same as his conditional\ncredence in H given (H ${\\wedge}$ A) ${\\vee}$ (T ${\\wedge}$ D) in\nTOSS-and-DUPLICATION. The second premise looks right, so the interest is\non what happens in COMA. Elga argues as follows (notation slightly\nchanged):\n\n> Before Al was put to sleep, he was sure that the chance of the coin\n> landing heads was 10%, and his credence in H should have accorded with\n> this chance: it too should have been 10%. When he wakes up, his\n> epistemic situation with respect to the coin is just the same as it\n> was before he went to sleep. He has neither gained nor lost\n> information relevant to the toss outcome. So his degree of belief in H\n> should continue to accord with the chance of H at the time of the\n> toss. In other words, his degree of belief in H should continue to be\n> 10%.\n\nAnd this, I think, is entirely mistaken. Al has no evidence that his\nevidence is relevant to H, but absence of evidence is not evidence of\nabsence. Four considerations support this conclusion.\n\nFirst, Al gets some evidence of some kind or other on waking. Certain\ncolours are seen, certain pains and sensations are sensed, certain\nfleeting thoughts fleet across his mind. Before he sleeps Al doesn't\nknows what these shall be. Maybe he thinks of the money supply, maybe of\nhis girlfriend, maybe of his heroine, maybe of kidneys. He doesn't\n*know* that the occurrence of these thoughts is probabilistically\nindependent of his being Al rather than Dup, so he does not *know* they\nare probabilistically independent of H. So perhaps he need not retain\nthe credence in H he has before he was drugged. Even if this evidence\nlooks like junk, we can't rule out that it has some force.\n\nSecondly, the kind of internalism about evidence needed to support\nElga's position is remarkably strong. (This is where the concerns raised\nin become most pressing.) Elga notes that he sets himself against both\nan extreme externalist position that says that Al's memories and/or\nperceptions *entail* that he is Al and against an \"intermediate view,\naccording to which Al's beliefs about the setup only partially undermine\nhis memories of being Al. According to such a view, when Al wakes up his\ncredence in H ought to be slightly higher than 10%.\" But matters are\nworse than that. Elga must also reject an even weaker view that says\nthat Al might not know whether externalism about evidence is true, so he\ndoes not know whether his credence in H should change. My view is more\nsympathetic to that position. When Al wakes, he does not know which\ndirection is credences should move, or indeed whether there is such a\ndirection, so his credence in H should be a spread of values including\n0.1.\n\nThirdly, Al's position looks like cases where new evidence makes risky\npropositions uncertain. Mack's betting strategy for the Gold Cup, a\nhorse race with six entrants, is fairly simple. He rolls a fair die, and\nbets on whatever number comes up. Jane knows this is Mack's strategy,\nbut does not how the die landed this time. Nor does she know anything\nabout horses, so the propositions *Horse n wins the Gold Cup* are\nuncertain for Jane for each *n*. Call these propositions *w~n~*, and the\nproposition that Mack's die landed *n* *d~n~*. Right now, *d*~2~ is\nrisky, but *h*~2~ is uncertain. Jane hears a party starting next door.\nMack's won. Jane has learned, *inter alia*,\n*d*~2~ $\\leftrightarrow$ *h*~2~. Now it seems that *d*~2~, *Mack's die\nlanded 2*, inherits the uncertainty of *h*~2~, *Horse number 2 won the\nGold Cup*. The formal theory of uncertainty I sketched allows for this\npossibility. It is possible that there be *p*, *e* such that *S*(*p*) is\na singleton, while *S*(*p*  *e*) is a wide interval, in theory as wide\nas [0, 1]. This is what happens in Jane's case, and it looks like it\nhappens in Al's case too. H used to be risky, but when he wakes he comes\nto learn H ${\\leftrightarrow}$ A, just as Jane learned\n*d*~2~ $\\leftrightarrow$ *h*~2~. In each case, the left-hand clause of\nthe biconditional inherits the uncertainty of the right-hand clause.\n\nFinally, H being uncertain for Al when he wakes in COMA is consistent\nwith the intuition that Al has no reason to change his credences in H in\none direction or another when he says goodbye to his duplicate. (Or, for\nall he knows, to his source.) Perhaps externalist theories of evidence\nprovide some reason to raise these credences, as suggested above, but I\ndo not *rely* on such theories. What I deny is that the absence of a\nreason to move one way or the other is a reason to stay put. Al's\ncredence in H might change in a way that reflects the fact H is now\nuncertain, just like A is in COMA, just like A is in\nTOSS-and-DUPLICATION, and, importantly, just like A is in DUPLICATION. I\nthink the rest of Elga's argument is right. DUPLICATION is a perfectly\ngeneral case. In any such case, Al should be uncertain, in Keynes's\nsense, whether he is the original or the duplicate.\n\n### Shooting Dice can be Dangerous\n\nThe good news, said Dr Evil, is that you are still mortal. Odysseus was\nnot as upset as Dr Evil had expected. The bad news is that I'm thinking\nof torturing you. I'm going to roll this fair die, and if it lands 6 you\nwill be tortured. If it does not, you will be (tentatively) released,\nand I'll create two duplicates of you as you were when you entered this\nroom, repeat this story to both them. Depending on another roll of this\nfair die, I will either torture them both, or create two duplicates of\neach of them, and repeat the process until I get to torture\nsomeone.[^13]\n\nOdysseus thought through this for a bit. So I might be a duplicate\nyou've just created, he said. I might not be Odysseus.\n\nYou might not be, said Dr Evil, although so as to avoid confusion if\nyou're not him I'll use his name for you.\n\nWhat happens if the die never lands 6, asked Odysseus. I've seen some\nodd runs of chance in my time.\n\nI wouldn't be so sure of that, said Dr Evil. Anyway, that's why I said I\nwould tentatively release you. I'll make the die rolls and subsequent\nduplication quicker and quicker so we'll get through the infinite number\nof rolls in a finite amount of time. If we get that far I'll just bring\neveryone back and torture you all. Aren't I fair?\n\nFairness wasn't on Odysseus's mind though. He was trying to figure out\nhow likely it was that he would be tortured. He was also a little\nconcerned about how likely it was that he was the original Odysseus, and\nif he was not whether Penelope too had been duplicated. As it turns out,\nhis torturous computations would assist with the second question, though\nnot the third. Two thoughts crossed his mind.\n\nI will be tortured if that die lands 6, which has a chance of 1 in 6, or\nif it never lands 6 again, which has a chance of 0. So the chance of my\nbeing tortured is 1 in 6. I have no inadmissible evidence, so the\nprobability I should assign to torture is 1 in 6.\n\nLet's think about how many Odysseuses there are in the history of the\nworld. Either there is 1, in which case I'm him, and I shall be\ntortured. Or there are 3, in which case two of them shall be tortured,\nso the probability that I shall be tortured is 2 in 3. Or there are 7,\nin which case four of them shall be tortured, so the probability that I\nshall be tortured is 4 in 7. And so on, it seems like the probability\nthat I shall be tortured approaches 1 in 2 from above as the number of\nOdysseuses approaches infinity. Except, of course, in the case where it\nreaches infinity, when it is again certain that I shall be tortured. So\nit looks like the probability that I will be tortured is above 1 in 2.\nBut I just concluded it is 1 in 6. Where did I go wrong?\n\nIn his second thought, Odysseus appeals frequently to INDIFFERENCE. He\nthen appeals to something like the conglomerability principle that\ntripped up Morgan. The principle Odysseus uses is a little stronger than\nthe principle Morgan used. It says that if there is a partition and\nconditional on each member of the partition, the probability of *p* is\ngreater than *x*, then the probability of *p* is greater than *x*. As we\nnoted, this principle cannot be accepted in its full generality by one\nwho rejects countable additivity. And one who accepts INDIFFERENCE must\nreject countable additivity. So where Odysseus goes wrong is in\nappealing to this inference principle after previously adopting an\nindifference principle inconsistent with it.\n\nThis does not mean the case has no interest. Morgan's case showed that\nwhen we have an actual infinity of duplicates, INDIFFERENCE can lead to\ncounterintuitive results, and that the best way out might be to say that\nMorgan faced a situation of uncertainty, not one of risk. But it might\nhave been thought that something special about Morgan's case, that she\nhas infinitely many duplicates, might be responsible for the problems\nhere. So it may be hoped that INDIFFERENCE can at least be accepted in\nmore everyday cases. Odysseus shows that hope is in vain. All we need is\nthe merest possibility of there being infinitely many duplicates, here a\npossibility with zero probability, to create a failure of\nconglomerability. This suggests that the problems with INDIFFERENCE run\nrelatively deep.\n\nThe details of how Odysseus's case plays out given INDIFFERENCE are also\ninteresting, especially to those readers not convinced by my refutation\nof INDIFFERENCE. For their benefit, I will close with a few observations\nabout how the case plays out.\n\nAs in Morgan's case, we can produce two different partitions of the\npossibility space that *seem* to support different conclusions about\nOdysseus's prospects. Assume for convenience that Dr Evil makes a serial\nnumber for each Odysseus he makes, the Homeric hero being number 1, the\nfirst two duplicates being 2 and 3, and so on. Let *N* stand for the\nnumber of our hero, *M* for the number of Odysseuses that are made, and\n*T* for the property of being tortured. Then given INDIFFERENCE it\nbehoves Odysseus to have his credences governed by the following *Pr*\nfunction.\n\n4.  1.  ${\\forall}$*k* *Pr*(*T*  *M* = 2*^k^* - 1) =\n        2*^k^*^-1^/(2*^k^* - 1)\n\n    2.  *Pr*(*T*  *M* = ${\\infty}$) = 1\n\n5.  ${\\forall}$*n* *Pr*(*T*  *N* = *n*) = 1/6\n\nBetween 4a and 4b we cover all possible values for *M*, and in every\ncase *Pr*(*T*) is greater than 1/2. More interesting are Odysseus's\ncalculations about whether he is the Homeric hero, i.e. about whether\n*N* = 1. Consider first a special case of this, what the value of\n*Pr*(*N* = 1 *N* \\< 8) is. At first glance, it might seem that this\nshould be 1/7, because there are seven possible values for *N* less than\n8. But this is too quick. There are really eleven possibilities to be\nconsidered.\n\n  ----------------------------- ----------------------------- -------------------------------\n  *F*~1~: *N* = 1 and *M* = 1   *F*~2~: *N* = 1 and *M* = 3   *F*~5~: *N* = 1 and *M* \\> 3\n                                *F*~3~: *N* = 2 and *M* = 3   *F*~6~: *N* = 2 and *M* \\> 3\n                                *F*~4~: *N* = 3 and *M* = 3   *F*~7~: *N* = 3 and *M* \\> 3\n                                                              *F*~8~: *N* = 4 and *M* \\> 3\n                                                              *F*~9~: *N* = 5 and *M* \\> 3\n                                                              *F*~10~: *N* = 6 and *M* \\> 3\n                                                              *F*~11~: *N* = 7 and *M* \\> 3\n  ----------------------------- ----------------------------- -------------------------------\n\nBy INDIFFERENCE, each of the properties in each column should be given\nequal probability. So we have\n\n$$\\begin{aligned}\nx &= Pr(F_1 | N < 8)  \\\\\ny &= Pr(F_2 | N < 8) = Pr(F_3 | N < 8) = Pr(F_4 | N < 8)  \\\\\nz &= Pr(F_5 | N < 8) = \\dots = Pr(F_11 | N < 8)  \\end{aligned}$$\n\nWe just have to solve for *x*, *y* and *z*. By the Principal Principle\nwe get\n\n6.  *Pr*(*M* = 1  *N* = 1) = 1/6\\\n    ${\\therefore}$ *x* = (*x* + *y* + *z*) / 6\n\n7.  *Pr*(*M* = 3 *N* = 1 and *M* ${\\geq}$ 3) = 1/6\\\n    ${\\therefore}$ *y* = (*y* + *z*) / 6\n\nAnd since these 11 possibilities are all the possibilities for *N* \\< 8,\nwe have\n\n8.  *x* + 3*y* + 7*z* = 1\n\nSolving for all these, we get *x* = 3/98, *y* = 5/196 and *z* = 25/196,\nso *Pr*(*N* = 1  *N* \\< 8) = *x* + *y* + *z* = 9/49. More generally, we\nhave the following (the proof of this is omitted):\n$$Pr(N = 1 | N < 2^{k+1}) = \\frac{6^k}{\\sum_{i=0}^{k}6^i10^{k-i}}$$\n\nSince the RHS ${\\rightarrow}$ 0 as *k* ${\\rightarrow}$ ${\\infty}$,\n*Pr*(*N* = 1) = 0. Our Odysseus is probably not the real hero. Similar\nreasoning shows that *Pr*(*N* = *n*) = 0 for all *n*. So we have another\nviolation of countable additivity. But we do not have, as in Morgan's\ncase, a constant distribution across the natural numbers. In a sense,\nthis distribution is still weighted towards the bottom, since for any\n*n* \\> 1, *Pr*(*N* = 1  *N* = 1 ${\\vee}$ *N* = *n*) \\> 1/2. Of course, I\ndon't think INDIFFERENCE is true, so these facts about what Odysseus's\ncredence function will look like under INDIFFERENCE are of purely\nmathematical interest to me. But it might be possible that someone more\nenamoured of INDIFFERENCE can use this 'unbalanced' distribution to\nexplain some of the distinctive features of the odd position that\nOdysseus is in.\n\n[^1]: INDIFFERENCE entails C-INDIFFERENCE given the following extra\n    assumptions. First, if INDIFFERENCE is true it is indefeasible, so\n    it must remain true whatever one's evidence is. Secondly, rational\n    agents should update by conditionalisation. Thirdly, it is always\n    possible for an agent to get evidence that tells her she is in\n    *F*~1~ or *F*~2~ and no more. The third premise is at best an\n    idealisation, but it is hard to see how or why that should tell\n    against C-INDIFFERENCE.\n\n[^2]: Note also that if P-INDIFFERENCE is false, then Dr Evil has an\n    easy way out of the 'brain race' that comes up at the end of Elga's\n    paper. He just need be told about some new element without being\n    told its half-life, and magically he is free to assign credence 1 to\n    his being on the spaceship rather than on Earth. This would reduce\n    the interest of the puzzle somewhat I fear.\n\n[^3]: Evil's plan resembles in many respects a situation described by\n    Jamie @Dreier2001 in his \"Boundless Good\". The back story is a\n    little different, but the situation is closely (and intentionally)\n    modelled on his sphere of pain/sphere of pleasure example.\n\n[^4]: Compare the objection to Dutch Book arguments in @Schick1986.\n\n[^5]: For example, @Shafer1976.\n\n[^6]: Compare the state-dependent approach to decision-making discussed\n    in @ChambersQuiggin2000.\n\n[^7]: This point closely resembles an objection to Dutch Book reasoning\n    made in @Hajek2005, though Scylla is much more sceptical about how\n    much we can learn from these pragmatic arguments than Hájek is.\n\n[^8]: Scylla's reasoning here is based on @Milne1991, though of course\n    Milne's argument is much less condensed than that.\n\n[^9]: This is proven in @McGee1999.\n\n[^10]: Though see @Hetherington2001 for an argument to the contrary.\n\n[^11]: Bradley @monton2002 discusses using sets of probability functions\n    to solve another problem proposed by Elga, the Sleeping Beauty\n    problem [@Elga2000-ELGSBA]. Monton notes that if Beauty's credence\n    in *The coin landed heads* is [0, 0.5] when she wakes up on\n    Monday, then she doesn't violate van Fraassen's General Reflection\n    Principle [@vanFraassen1995]. (I assume here familiarity with the\n    Sleeping Beauty problem.) Monton has some criticisms of this move,\n    in particular the consequences it has for updating, that don't seem\n    to carry across to the proposal sketched here. But his discussion is\n    noteworthy as a use of this approach to uncertainty as a way to\n    solve problems to do with similar predicaments.\n\n[^12]: As with earlier cases, strictly speaking we need C-INDIFFERENCE\n    and P-INDIFFERENCE to draw the conclusions suggested unless Al is\n    somehow certain about all other propositions. I will ignore that\n    complication here, and in .\n\n[^13]: Dr Evil's plans create a situation similar to the well known\n    'shooting room' problem. For the best analysis of that problem see\n    @Bartha1999. Dr Evil has changed the numbers involved in the puzzle\n    a little bit to make the subsequent calculations a little more\n    straightforward. He's not very good at arithmetic you see.\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}